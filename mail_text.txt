------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
Submissions to:
Artificial Intelligence
Computation and Language
Computer Vision and Pattern Recognition
Information Retrieval
Machine Learning
received from  Mon 24 Nov 25 19:00:00 GMT  to  Tue 25 Nov 25 19:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2511.19577
Date: Mon, 24 Nov 2025 18:19:56 GMT   (44kb)

Title: Using Wearable Devices to Improve Chronic PainTreatment among Patients
 with Opioid Use Disorder
Authors: Abhay Goyal, Navin Kumar, Kimberly DiMeola, Rafael Trujillo, Soorya
 Ram Shimgekar, Christian Poellabauer, Pi Zonooz, Ermonda Gjoni-Markaj, Declan
 Barry, Lynn Madden
Categories: cs.AI cs.HC
\\
 Chronic pain (CP) and opioid use disorder (OUD) are common and interrelated
chronic medical conditions. Currently, there is a paucity of evidence-based
integrated treatments for CP and OUD among individuals receiving medication for
opioid use disorder (MOUD). Wearable devices have the potential to monitor
complex patient information and inform treatment development for persons with
OUD and CP, including pain variability (e.g., exacerbations of pain or pain
spikes) and clinical correlates (e.g., perceived stress). However, the
application of large language models (LLMs) with wearable data for
understanding pain spikes, remains unexplored. Consequently, the aim of this
pilot study was to examine the clinical correlates of pain spikes using a range
of AI approaches. We found that machine learning models achieved relatively
high accuracy (>0.7) in predicting pain spikes, while LLMs were limited in
providing insights on pain spikes. Real-time monitoring through wearable
devices, combined with advanced AI models, could facilitate early detection of
pain spikes and support personalized interventions that may help mitigate the
risk of opioid relapse, improve adherence to MOUD, and enhance the integration
of CP and OUD care. Given overall limited LLM performance, these findings
highlight the need to develop LLMs which can provide actionable insights in the
OUD/CP context.
\\ ( https://arxiv.org/abs/2511.19577 ,  44kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19663
Date: Mon, 24 Nov 2025 19:56:28 GMT   (8189kb)

Title: Fara-7B: An Efficient Agentic Model for Computer Use
Authors: Ahmed Awadallah, Yash Lara, Raghav Magazine, Hussein Mozannar, Akshay
 Nambi, Yash Pandya, Aravind Rajeswaran, Corby Rosset, Alexey Taymanov, Vibhav
 Vineet, Spencer Whitehead, Andrew Zhao
Categories: cs.AI cs.CL cs.CV
\\
 Progress in computer use agents (CUAs) has been constrained by the absence of
large and high-quality datasets that capture how humans interact with a
computer. While LLMs have thrived on abundant textual data, no comparable
corpus exists for CUA trajectories. To address these gaps, we introduce
FaraGen, a novel synthetic data generation system for multi-step web tasks.
FaraGen can propose diverse tasks from frequently used websites, generate
multiple solution attempts, and filter successful trajectories using multiple
verifiers. It achieves high throughput, yield, and diversity for multi-step web
tasks, producing verified trajectories at approximately $1 each. We use this
data to train Fara-7B, a native CUA model that perceives the computer using
only screenshots, executes actions via predicted coordinates, and is small
enough to run on-device. We find that Fara-7B outperforms other CUA models of
comparable size on benchmarks like WebVoyager, Online-Mind2Web, and
WebTailBench -- our novel benchmark that better captures under-represented web
tasks in pre-existing benchmarks. Furthermore, Fara-7B is competitive with much
larger frontier models, illustrating key benefits of scalable data generation
systems in advancing small efficient agentic models. We are making Fara-7B
open-weight on Microsoft Foundry and HuggingFace, and we are releasing
WebTailBench.
\\ ( https://arxiv.org/abs/2511.19663 ,  8189kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19669
Date: Mon, 24 Nov 2025 20:11:06 GMT   (2670kb)

Title: HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for
 AMS Design Optimization
Authors: Souradip Poddar, Chia-Tung Ho, Ziming Wei, Weidong Cao, Haoxing Ren,
 David Z. Pan
Categories: cs.AI
\\
 Conventional AI-driven AMS design automation algorithms remain constrained by
their reliance on high-quality datasets to capture underlying circuit behavior,
coupled with poor transferability across architectures, and a lack of adaptive
mechanisms. This work proposes HeaRT, a foundational reasoning engine for
automation loops and a first step toward intelligent, adaptive, human-style
design optimization. HeaRT consistently demonstrates reasoning accuracy >97%
and Pass@1 performance >98% across our 40-circuit benchmark repository, even as
circuit complexity increases, while operating at <0.5x real-time token budget
of SOTA baselines. Our experiments show that HeaRT yields >3x faster
convergence in both sizing and topology design adaptation tasks across diverse
optimization approaches, while preserving prior design intent.
\\ ( https://arxiv.org/abs/2511.19669 ,  2670kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19671
Date: Mon, 24 Nov 2025 20:11:44 GMT   (28kb)

Title: FISCAL: Financial Synthetic Claim-document Augmented Learning for
 Efficient Fact-Checking
Authors: Rishab Sharma, Iman Saberi, Elham Alipour, Jie JW Wu, Fatemeh Fard
Categories: cs.AI
Comments: 3 tables, 11 pages, 39th Conference on Neural Information Processing
 Systems (NeurIPS 2025) Workshop: Generative AI in Finance
\\
 Financial applications of large language models (LLMs) require factual
reliability and computational efficiency, yet current systems often hallucinate
details and depend on prohibitively large models. We propose FISCAL (Financial
Synthetic Claim-Document Augmented Learning), a modular framework for
generating synthetic data tailored to financial fact-checking. Using FISCAL, we
generate a dataset called FISCAL-data and use it to train MiniCheck-FISCAL, a
lightweight verifier for numerical financial claims. MiniCheck-FISCAL
outperforms its baseline, surpasses GPT-3.5 Turbo and other open-source peers
of similar size, and approaches the accuracy of much larger systems (20x), such
as Mixtral-8x22B and Command R+. On external datasets FinDVer and Fin-Fact, it
rivals GPT-4o and Claude-3.5 while outperforming Gemini-1.5 Flash. These
results show that domain-specific synthetic data, combined with efficient
fine-tuning, enables compact models to achieve state-of-the-art accuracy,
robustness, and scalability for practical financial AI. The dataset and scripts
are available in the project repository (link provided in the paper).
\\ ( https://arxiv.org/abs/2511.19671 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19749
Date: Mon, 24 Nov 2025 22:12:23 GMT   (1434kb)

Title: Scaling Item-to-Standard Alignment with Large Language Models: Accuracy,
 Limits, and Solutions
Authors: Farzan Karimi-Malekabadi, Pooya Razavi, Sonya Powers
Categories: cs.AI
\\
 As educational systems evolve, ensuring that assessment items remain aligned
with content standards is essential for maintaining fairness and instructional
relevance. Traditional human alignment reviews are accurate but slow and
labor-intensive, especially across large item banks. This study examines
whether Large Language Models (LLMs) can accelerate this process without
sacrificing accuracy. Using over 12,000 item-skill pairs in grades K-5, we
tested three LLMs (GPT-3.5 Turbo, GPT-4o-mini, and GPT-4o) across three tasks
that mirror real-world challenges: identifying misaligned items, selecting the
correct skill from the full set of standards, and narrowing candidate lists
prior to classification. In Study 1, GPT-4o-mini correctly identified alignment
status in approximately 83-94% of cases, including subtle misalignments. In
Study 2, performance remained strong in mathematics but was lower for reading,
where standards are more semantically overlapping. Study 3 demonstrated that
pre-filtering candidate skills substantially improved results, with the correct
skill appearing among the top five suggestions more than 95% of the time. These
findings suggest that LLMs, particularly when paired with candidate filtering
strategies, can significantly reduce the manual burden of item review while
preserving alignment accuracy. We recommend the development of hybrid pipelines
that combine LLM-based screening with human review in ambiguous cases, offering
a scalable solution for ongoing item validation and instructional alignment.
\\ ( https://arxiv.org/abs/2511.19749 ,  1434kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19773
Date: Mon, 24 Nov 2025 22:58:26 GMT   (708kb)

Title: Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in
 VLMs
Authors: Meng Lu, Ran Xu, Yi Fang, Wenxuan Zhang, Yue Yu, Gaurav Srivastava,
 Yuchen Zhuang, Mohamed Elhoseiny, Charles Fleming, Carl Yang, Zhengzhong Tu,
 Yang Xie, Guanghua Xiao, Hanrui Wang, Di Jin, Wenqi Shi, Xuan Wang
Categories: cs.AI cs.CL cs.CV
Comments: 17 pages, 9 figures, work in progress
\\
 While recent vision-language models (VLMs) demonstrate strong image
understanding, their ability to "think with images", i.e., to reason through
multi-step visual interactions, remains limited. We introduce VISTA-Gym, a
scalable training environment for incentivizing tool-integrated visual
reasoning capabilities in VLMs. VISTA-Gym unifies diverse real-world multimodal
reasoning tasks (7 tasks from 13 datasets in total) with a standardized
interface for visual tools (e.g., grounding, parsing), executable interaction
loops, verifiable feedback signals, and efficient trajectory logging, enabling
visual agentic reinforcement learning at scale. While recent VLMs exhibit
strong text-only reasoning, both proprietary and open-source models still
struggle with tool selection, invocation, and coordination. With VISTA-Gym, we
train VISTA-R1 to interleave tool-use with agentic reasoning via multi-turn
trajectory sampling and end-to-end reinforcement learning. Extensive
experiments across 11 public reasoning-intensive VQA benchmarks show that
VISTA-R1-8B outperforms state-of-the-art baselines with similar sizes by
9.51%-18.72%, demonstrating VISTA-Gym as an effective training ground to unlock
the tool-integrated reasoning capabilities for VLMs.
\\ ( https://arxiv.org/abs/2511.19773 ,  708kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19780
Date: Mon, 24 Nov 2025 23:14:45 GMT   (12990kb)

Title: NOEM$^{3}$A: A Neuro-Symbolic Ontology-Enhanced Method for Multi-Intent
 Understanding in Mobile Agents
Authors: Ioannis Tzachristas, Aifen Sui
Categories: cs.AI
\\
 We introduce a neuro-symbolic framework for multi-intent understanding in
mobile AI agents by integrating a structured intent ontology with compact
language models. Our method leverages retrieval-augmented prompting, logit
biasing and optional classification heads to inject symbolic intent structure
into both input and output representations. We formalize a new evaluation
metric-Semantic Intent Similarity (SIS)-based on hierarchical ontology depth,
capturing semantic proximity even when predicted intents differ lexically.
Experiments on a subset of ambiguous/demanding dialogues of MultiWOZ 2.3 (with
oracle labels from GPT-o3) demonstrate that a 3B Llama model with ontology
augmentation approaches GPT-4 accuracy (85% vs 90%) at a tiny fraction of the
energy and memory footprint. Qualitative comparisons show that
ontology-augmented models produce more grounded, disambiguated multi-intent
interpretations. Our results validate symbolic alignment as an effective
strategy for enabling accurate and efficient on-device NLU.
\\ ( https://arxiv.org/abs/2511.19780 ,  12990kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19798
Date: Mon, 24 Nov 2025 23:56:51 GMT   (391kb)

Title: KOM: A Multi-Agent Artificial Intelligence System for Precision
 Management of Knee Osteoarthritis (KOA)
Authors: Weizhi Liu, Xi Chen, Zekun Jiang, Liang Zhao, Kunyuan Jiang, Ruisi
 Tang, Li Wang, Mingke You, Hanyu Zhou, Hongyu Chen, Qiankun Xiong, Yong Nie,
 Kang Li, Jian Li
Categories: cs.AI cs.HC cs.LG cs.MA
\\
 Knee osteoarthritis (KOA) affects more than 600 million individuals globally
and is associated with significant pain, functional impairment, and disability.
While personalized multidisciplinary interventions have the potential to slow
disease progression and enhance quality of life, they typically require
substantial medical resources and expertise, making them difficult to implement
in resource-limited settings. To address this challenge, we developed KOM, a
multi-agent system designed to automate KOA evaluation, risk prediction, and
treatment prescription. This system assists clinicians in performing essential
tasks across the KOA care pathway and supports the generation of tailored
management plans based on individual patient profiles, disease status, risk
factors, and contraindications. In benchmark experiments, KOM demonstrated
superior performance compared to several general-purpose large language models
in imaging analysis and prescription generation. A randomized three-arm
simulation study further revealed that collaboration between KOM and clinicians
reduced total diagnostic and planning time by 38.5% and resulted in improved
treatment quality compared to each approach used independently. These findings
indicate that KOM could help facilitate automated KOA management and, when
integrated into clinical workflows, has the potential to enhance care
efficiency. The modular architecture of KOM may also offer valuable insights
for developing AI-assisted management systems for other chronic conditions.
\\ ( https://arxiv.org/abs/2511.19798 ,  391kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19829
Date: Tue, 25 Nov 2025 01:41:13 GMT   (514kb)

Title: A Unified Evaluation-Instructed Framework for Query-Dependent Prompt
 Optimization
Authors: Ke Chen, Yifeng Wang, Hassan Almosapeeh, Haohan Wang
Categories: cs.AI
\\
 Most prompt-optimization methods refine a single static template, making them
ineffective in complex and dynamic user scenarios. Existing query-dependent
approaches rely on unstable textual feedback or black-box reward models,
providing weak and uninterpretable optimization signals. More fundamentally,
prompt quality itself lacks a unified, systematic definition, resulting in
fragmented and unreliable evaluation signals. Our approach first establishes a
performance-oriented, systematic, and comprehensive prompt evaluation
framework. Furthermore, we develop and finetune an execution-free evaluator
that predicts multi-dimensional quality scores directly from text. The
evaluator then instructs a metric-aware optimizer that diagnoses failure modes
and rewrites prompts in an interpretable, query-dependent manner. Our evaluator
achieves the strongest accuracy in predicting prompt performance, and the
evaluation-instructed optimization consistently surpass both static-template
and query-dependent baselines across eight datasets and on three backbone
models. Overall, we propose a unified, metric-grounded perspective on prompt
quality, and demonstrated that our evaluation-instructed optimization pipeline
delivers stable, interpretable, and model-agnostic improvements across diverse
tasks.
\\ ( https://arxiv.org/abs/2511.19829 ,  514kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19849
Date: Tue, 25 Nov 2025 02:28:02 GMT   (83kb)

Title: Reinforcement Learning with $\omega$-Regular Objectives and Constraints
Authors: Dominik Wagner, Leon Witzman, Luke Ong
Categories: cs.AI cs.LG
\\
 Reinforcement learning (RL) commonly relies on scalar rewards with limited
ability to express temporal, conditional, or safety-critical goals, and can
lead to reward hacking. Temporal logic expressible via the more general class
of $\omega$-regular objectives addresses this by precisely specifying rich
behavioural properties. Even still, measuring performance by a single scalar
(be it reward or satisfaction probability) masks safety-performance trade-offs
that arise in settings with a tolerable level of risk.
 We address both limitations simultaneously by combining $\omega$-regular
objectives with explicit constraints, allowing safety requirements and
optimisation targets to be treated separately. We develop a model-based RL
algorithm based on linear programming, which in the limit produces a policy
maximising the probability of satisfying an $\omega$-regular objective while
also adhering to $\omega$-regular constraints within specified thresholds.
Furthermore, we establish a translation to constrained limit-average problems
with optimality-preserving guarantees.
\\ ( https://arxiv.org/abs/2511.19849 ,  83kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19864
Date: Tue, 25 Nov 2025 03:14:39 GMT   (649kb)

Title: MicroSims: A Framework for AI-Generated, Scalable Educational
 Simulations with Universal Embedding and Adaptive Learning Support
Authors: Valerie Lockhart, Dan McCreary, Troy A. Peterson
Categories: cs.AI
Comments: 42 pages, 4 figures
\\
 Educational simulations have long been recognized as powerful tools for
enhancing learning outcomes, yet their creation has traditionally required
substantial resources and technical expertise. This paper introduces MicroSims
a novel framework for creating lightweight, interactive educational simulations
that can be rapidly generated using artificial intelligence, universally
embedded across digital learning platforms, and easily customized without
programming knowledge. MicroSims occupy a unique position at the intersection
of three key innovations: (1) standardized design patterns that enable
AI-assisted generation, (2) iframe-based architecture that provides universal
embedding and sandboxed security, and (3) transparent, modifiable code that
supports customization and pedagogical transparency. We present a comprehensive
framework encompassing design principles, technical architecture, metadata
standards, and development workflows. Drawing on empirical research from
physics education studies and meta-analyses across STEM disciplines, we
demonstrate that interactive simulations can improve conceptual understanding
by up to 30-40\% compared to traditional instruction. MicroSims extend these
benefits while addressing persistent barriers of cost, technical complexity,
and platform dependence. This work has significant implications for educational
equity, and low-cost intelligent interactive textbooks that enabling educators
worldwide to create customized, curriculum-aligned simulations on demand. We
discuss implementation considerations, present evidence of effectiveness, and
outline future directions for AI-powered adaptive learning systems built on the
MicroSim foundation.
\\ ( https://arxiv.org/abs/2511.19864 ,  649kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19865
Date: Tue, 25 Nov 2025 03:16:30 GMT   (13922kb)

Title: Agentic AI-Empowered Conversational Embodied Intelligence Networks in 6G
Authors: Mingkai Chen, Zijie Feng, Lei Wang, Yaser Khamayseh
Categories: cs.AI
Comments: 7 pages, 8 figures. Preprint submitted to IEEE Vehicle Technology
 Magazine
\\
 In the 6G era, semantic collaboration among multiple embodied intelligent
devices (MEIDs) becomes crucial for complex task execution. However, existing
systems face challenges in multimodal information fusion, adaptive
communication, and decision interpretability. To address these limitations, we
propose a collaborative Conversational Embodied Intelligence Network (CC-EIN)
integrating multimodal feature fusion, adaptive semantic communication, task
coordination, and interpretability. PerceptiNet performs cross-modal fusion of
image and radar data to generate unified semantic representations. An adaptive
semantic communication strategy dynamically adjusts coding schemes and
transmission power according to task urgency and channel quality. A
semantic-driven collaboration mechanism further supports task decomposition and
conflict-free coordination among heterogeneous devices. Finally, the InDec
module enhances decision transparency through Grad-CAM visualization.
Simulation results in post-earthquake rescue scenarios demonstrate that CC-EIN
achieves 95.4% task completion rate and 95% transmission efficiency while
maintaining strong semantic consistency and energy efficiency.
\\ ( https://arxiv.org/abs/2511.19865 ,  13922kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19872
Date: Tue, 25 Nov 2025 03:24:11 GMT   (785kb)

Title: Simulated Self-Assessment in Large Language Models: A Psychometric
 Approach to AI Self-Efficacy
Authors: Daniel I Jackson, Emma L Jensen, Syed-Amad Hussain, Emre Sezgin
Categories: cs.AI
Comments: 25 pages,5 tables, 3 figures
\\
 Self-assessment is a key aspect of reliable intelligence, yet evaluations of
large language models (LLMs) focus mainly on task accuracy. We adapted the
10-item General Self-Efficacy Scale (GSES) to elicit simulated self-assessments
from ten LLMs across four conditions: no task, computational reasoning, social
reasoning, and summarization. GSES responses were highly stable across repeated
administrations and randomized item orders. However, models showed
significantly different self-efficacy levels across conditions, with aggregate
scores lower than human norms. All models achieved perfect accuracy on
computational and social questions, whereas summarization performance varied
widely. Self-assessment did not reliably reflect ability: several low-scoring
models performed accurately, while some high-scoring models produced weaker
summaries. Follow-up confidence prompts yielded modest, mostly downward
revisions, suggesting mild overestimation in first-pass assessments.
Qualitative analysis showed that higher self-efficacy corresponded to more
assertive, anthropomorphic reasoning styles, whereas lower scores reflected
cautious, de-anthropomorphized explanations. Psychometric prompting provides
structured insight into LLM communication behavior but not calibrated
performance estimates.
\\ ( https://arxiv.org/abs/2511.19872 ,  785kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19895
Date: Tue, 25 Nov 2025 04:06:02 GMT   (652kb)

Title: RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo
 Tree Search for Code Generation
Authors: Yuanyuan Lin, Xiangyu Ouyang, Teng Zhang, Kaixin Sui
Categories: cs.AI
Comments: Accepted at AAAI 2026
\\
 Tree search-based methods have made significant progress in enhancing the
code generation capabilities of large language models. However, due to the
difficulty in effectively evaluating intermediate algorithmic steps and the
inability to locate and timely correct erroneous steps, these methods often
generate incorrect code and incur increased computational costs. To tackle
these problems, we propose RPM-MCTS, an effective method that utilizes
Knowledge-Retrieval as Process Reward Model based on Monte Carlo Tree Search to
evaluate intermediate algorithmic steps. By utilizing knowledge base retrieval,
RPM-MCTS avoids the complex training of process reward models. During the
expansion phase, similarity filtering is employed to remove redundant nodes,
ensuring diversity in reasoning paths. Furthermore, our method utilizes sandbox
execution feedback to locate erroneous algorithmic steps during generation,
enabling timely and targeted corrections. Extensive experiments on four public
code generation benchmarks demonstrate that RPM-MCTS outperforms current
state-of-the-art methods while achieving an approximately 15% reduction in
token consumption. Furthermore, full fine-tuning of the base model using the
data constructed by RPM-MCTS significantly enhances its code capabilities.
\\ ( https://arxiv.org/abs/2511.19895 ,  652kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19925
Date: Tue, 25 Nov 2025 05:07:08 GMT   (504kb)

Title: Semantic-KG: Using Knowledge Graphs to Construct Benchmarks for
 Measuring Semantic Similarity
Authors: Qiyao Wei, Edward Morrell, Lea Goetz, Mihaela van der Schaar
Categories: cs.AI
\\
 Evaluating the open-form textual responses generated by Large Language Models
(LLMs) typically requires measuring the semantic similarity of the response to
a (human generated) reference. However, there is evidence that current semantic
similarity methods may capture syntactic or lexical forms over semantic
content. While benchmarks exist for semantic equivalence, they often suffer
from high generation costs due to reliance on subjective human judgment,
limited availability for domain-specific applications, and unclear definitions
of equivalence. This paper introduces a novel method for generating benchmarks
to evaluate semantic similarity methods for LLM outputs, specifically
addressing these limitations. Our approach leverages knowledge graphs (KGs) to
generate pairs of natural-language statements that are semantically similar or
dissimilar, with dissimilar pairs categorized into one of four sub-types. We
generate benchmark datasets in four different domains (general knowledge,
biomedicine, finance, biology), and conduct a comparative study of semantic
similarity methods including traditional natural language processing scores and
LLM-as-a-judge predictions. We observe that the sub-type of semantic variation,
as well as the domain of the benchmark impact the performance of semantic
similarity methods, with no method being consistently superior. Our results
present important implications for the use of LLM-as-a-judge in detecting the
semantic content of text. Code is available at
https://github.com/QiyaoWei/semantic-kg and the dataset is available at
https://huggingface.co/datasets/QiyaoWei/Semantic-KG.
\\ ( https://arxiv.org/abs/2511.19925 ,  504kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19933
Date: Tue, 25 Nov 2025 05:19:23 GMT   (690kb)

Title: A System-Level Taxonomy of Failure Modes in Large Language Model
 Applications
Authors: Vaishali Vinay
Categories: cs.AI
\\
 Large language models (LLMs) are being rapidly integrated into
decision-support tools, automation workflows, and AI-enabled software systems.
However, their behavior in production environments remains poorly understood,
and their failure patterns differ fundamentally from those of traditional
machine learning models. This paper presents a system-level taxonomy of fifteen
hidden failure modes that arise in real-world LLM applications, including
multi-step reasoning drift, latent inconsistency, context-boundary degradation,
incorrect tool invocation, version drift, and cost-driven performance collapse.
Using this taxonomy, we analyze the growing gap in evaluation and monitoring
practices: existing benchmarks measure knowledge or reasoning but provide
little insight into stability, reproducibility, drift, or workflow integration.
We further examine the production challenges associated with deploying LLMs -
including observability limitations, cost constraints, and update-induced
regressions - and outline high-level design principles for building reliable,
maintainable, and cost-aware LLM systems. Finally, we outline high-level design
principles for building reliable, maintainable, and cost-aware LLM-based
systems. By framing LLM reliability as a system-engineering problem rather than
a purely model-centric one, this work provides an analytical foundation for
future research on evaluation methodology, AI system robustness, and dependable
LLM deployment.
\\ ( https://arxiv.org/abs/2511.19933 ,  690kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19969
Date: Tue, 25 Nov 2025 06:29:13 GMT   (3150kb)

Title: M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient
 Multi-Modal Multi-Agent Retrieval-Augmented Generation
Authors: Weizi Shao, Taolin Zhang, Zijie Zhou, Chen Chen, Chengyu Wang,
 Xiaofeng He
Categories: cs.AI
\\
 Recent advancements in multi-modal retrieval-augmented generation (mRAG),
which enhance multi-modal large language models (MLLMs) with external
knowledge, have demonstrated that the collective intelligence of multiple
agents can significantly outperform a single model through effective
communication. Despite impressive performance, existing multi-agent systems
inherently incur substantial token overhead and increased computational costs,
posing challenges for large-scale deployment. To address these issues, we
propose a novel Multi-Modal Multi-agent hierarchical communication graph
PRUNING framework, termed M$^3$Prune. Our framework eliminates redundant edges
across different modalities, achieving an optimal balance between task
performance and token overhead. Specifically, M$^3$Prune first applies
intra-modal graph sparsification to textual and visual modalities, identifying
the edges most critical for solving the task. Subsequently, we construct a
dynamic communication topology using these key edges for inter-modal graph
sparsification. Finally, we progressively prune redundant edges to obtain a
more efficient and hierarchical topology. Extensive experiments on both general
and domain-specific mRAG benchmarks demonstrate that our method consistently
outperforms both single-agent and robust multi-agent mRAG systems while
significantly reducing token consumption.
\\ ( https://arxiv.org/abs/2511.19969 ,  3150kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20048
Date: Tue, 25 Nov 2025 08:15:17 GMT   (388kb)

Title: Reducing Latency of LLM Search Agent via Speculation-based
 Algorithm-System Co-Design
Authors: Zixiao Huang, Wen Zeng, Tianyu Fu, Tengxuan Liu, Yizhou Sun, Ke Hong,
 Xinhao Yang, Chengchun Liu, Yan Li, Quanlu Zhang, Guohao Dai, Zhenhua Zhu, Yu
 Wang
Categories: cs.AI cs.LG cs.PF
\\
 LLM-based search agents achieve strong performance but suffer from severe
latency, as each step requires serialized LLM reasoning followed by action of
tool execution. We revisit this bottleneck through the lens of speculation.
While traditional predict-verify speculation paradigm can break serial
execution, its benefit remains limited, as it retains the full original
workload and adds extra inference overhead. We observe that early agent steps
often involve simple evidence-gathering, where correct actions can often be
predicted without full reasoning. Building on these observations, we present
SPAgent, an algorithm-system co-design framework that expands the role of
speculation in search agents to reduce latency. Algorithmically, SPAgent
introduces a two-phase adaptive speculation mechanism that selectively omits
verification when safe. System-wise, a two-level scheduler regulates
speculative requests based on engine load to ensure speculation remains
beneficial. We implement SPAgent in real-world systems. Across extensive
experimental settings, SPAgent achieves up to $1.65\times$ end-to-end speedup
while maintaining same or even achieving higher accuracy, enabling practical
deployment of multi-step search agents.
\\ ( https://arxiv.org/abs/2511.20048 ,  388kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20067
Date: Tue, 25 Nov 2025 08:40:33 GMT   (70kb)

Title: "Are We Done Yet?": A Vision-Based Judge for Autonomous Task Completion
 of Computer Use Agents
Authors: Marta Sumyk, Oleksandr Kosovan
Categories: cs.AI cs.HC
Comments: This work has been accepted to appear at the AAAI 2026 Workshop on
 Trust and Control in Agentic AI (TrustAgent)
\\
 Computer Use Agents (CUAs) are designed to autonomously operate digital
interfaces, yet they often fail to reliably determine whether a given task has
been completed. We present an autonomous evaluation and feedback framework that
uses vision-language models to assess task completion directly from screenshots
and task descriptions. Our dataset covers 42 built-in macOS applications and
1,260 human-labeled tasks across a wide range of scenarios. Our framework
achieves up to 73 percent accuracy in task success detection and yields an
average relative improvement of 27 percent in overall task success when
evaluator feedback is applied. These results show that vision-based evaluation
can serve as an effective feedback mechanism that improves the reliability and
self-correction of autonomous computer-use agents.
\\ ( https://arxiv.org/abs/2511.20067 ,  70kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20085
Date: Tue, 25 Nov 2025 09:00:28 GMT   (10601kb)

Title: VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for
 Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis
Authors: Chujie Wang, Zhiyuan Luo, Ruiqi Liu, Can Ran, Shenghua Fan, Xi Chen
 and Chu He
Categories: cs.AI cs.MA
\\
 The current remote sensing image analysis task is increasingly evolving from
traditional object recognition to complex intelligence reasoning, which places
higher requirements on the model's reasoning ability and the flexibility of
tool invocation. To this end, we propose a new multimodal agent framework,
Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements
explicit multi-round reasoning by dynamically incorporating visual tools into
the chain of thought. Through a stack-based reasoning structure and a modular
MCP-compatible tool suite, VICoT enables LLMs to efficiently perform
multi-round, interleaved vision-language reasoning tasks with strong
generalization and flexibility.We also propose the Reasoning Stack distillation
method to migrate complex Agent behaviors to small, lightweight models, which
ensures the reasoning capability while significantly reducing complexity.
Experiments on multiple remote sensing benchmarks demonstrate that VICoT
significantly outperforms existing SOTA frameworks in reasoning transparency,
execution efficiency, and generation quality.
\\ ( https://arxiv.org/abs/2511.20085 ,  10601kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20138
Date: Tue, 25 Nov 2025 09:59:56 GMT   (1063kb)

Title: From data to concepts via wiring diagrams
Authors: Jason Lo and Mohammadnima Jafari
Categories: cs.AI cs.DM cs.LG math.CO
Comments: 19 pages
MSC-class: 68T10 (Primary) 68T30, 68R10, 68T40 (Secondary)
ACM-class: I.2.6; I.2.4
\\
 A wiring diagram is a labeled directed graph that represents an abstract
concept such as a temporal process. In this article, we introduce the notion of
a quasi-skeleton wiring diagram graph, and prove that quasi-skeleton wiring
diagram graphs correspond to Hasse diagrams. Using this result, we designed
algorithms that extract wiring diagrams from sequential data. We used our
algorithms in analyzing the behavior of an autonomous agent playing a computer
game, and the algorithms correctly identified the winning strategies. We
compared the performance of our main algorithm with two other algorithms based
on standard clustering techniques (DBSCAN and agglomerative hierarchical),
including when some of the data was perturbed. Overall, this article brings
together techniques in category theory, graph theory, clustering, reinforcement
learning, and data engineering.
\\ ( https://arxiv.org/abs/2511.20138 ,  1063kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20196
Date: Tue, 25 Nov 2025 11:22:45 GMT   (987kb)

Title: Towards Benign Memory Forgetting for Selective Multimodal Large Language
 Model Unlearning
Authors: Zhen Zeng, Leijiang Gu, Zhangling Duan, Feng Li, Zenglin Shi, Cees G.
 M. Snoek, Meng Wang
Categories: cs.AI
\\
 Multimodal Large Language Models (MLLMs) achieve remarkable capabilities but
can inadvertently memorize privacy-sensitive information. Although existing
unlearning methods can remove such knowledge, they fail to achieve benign
forgetting because they often degrade the model's general image understanding
performance. To address this, we propose the Sculpted Memory Forgetting Adapter
(SMFA), which confines forgetting to targeted memory regions while preserving
overall capabilities. SMFA first fine-tunes the model to replace sensitive
responses with refusals, yielding a memory forgetting adapter, and then applies
a retaining anchor-guided masking mechanism to prevent interference with
unrelated knowledge and understanding ability. To systematically evaluate
selective MLLM unlearning, we introduce S-MLLMUn Bench, the first benchmark
designed to jointly assess the removal of sensitive knowledge and retention of
general visual understanding. Extensive experiments show that, unlike prior
methods, SMFA achieves precise and controllable unlearning while maintaining
the model's foundational image understanding.
\\ ( https://arxiv.org/abs/2511.20196 ,  987kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20200
Date: Tue, 25 Nov 2025 11:24:14 GMT   (556kb)

Title: Interactive AI NPCs Powered by LLMs: Technical Report for the CPDC
 Challenge 2025
Authors: Yitian Huang, Yuxuan Lei, Jianxun Lian, Hao Liao
Categories: cs.AI
\\
 This report presents the solution and results of our team MSRA\_SC in the
Commonsense Persona-Grounded Dialogue Challenge (CPDC 2025). We propose a
simple yet effective framework that unifies improvements across both GPU Track
and API Track. Our method centers on two key components. First, Context
Engineering applies dynamic tool pruning and persona clipping for input
compression, combined with post-processing techniques such as parameter
normalization and function merging. Together with manually refined prompts,
this design improves tool call stability, execution reliability, and
role-playing guidance. Second, in the GPU Track, we further adopt GRPO
training, replacing supervised fine-tuning with reinforcement learning directly
optimized by reward signals. This mitigates small-sample overfitting and
significantly enhances task-oriented dialogue performance. In the final
evaluation, our team ranks 1st in Task 2 API, 2nd in Task 1 API, and 3rd in
both Task 3 API and GPU track, demonstrating the effectiveness of our approach.
Our code is publicly available at
https://gitlab.aicrowd.com/nikoo_yu/cpdc-2025-winning-solution
\\ ( https://arxiv.org/abs/2511.20200 ,  556kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20216
Date: Tue, 25 Nov 2025 11:42:28 GMT   (698kb)

Title: CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied
 Agents
Authors: Haebin Seong, Sungmin Kim, Minchan Kim, Yongjun Cho, Myunchul Joe,
 Suhwan Choi, Jaeyoon Jung, Jiyong Youn, Yoonshik Kim, Samwoo Seong, Yubeen
 Park, Youngjae Yu, Yunsung Lee
Categories: cs.AI cs.CE cs.CV cs.LG cs.RO
\\
 Existing navigation benchmarks focus on task success metrics while
overlooking economic viability -- critical for commercial deployment of
autonomous delivery robots. We introduce \emph{CostNav}, a
\textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents
through comprehensive cost-revenue analysis aligned with real-world business
operations. CostNav models the complete economic lifecycle including hardware,
training, energy, maintenance costs, and delivery revenue with service-level
agreements, using industry-derived parameters. \textbf{To our knowledge,
CostNav is the first work to quantitatively expose the gap between navigation
research metrics and commercial viability}, revealing that optimizing for task
success fundamentally differs from optimizing for economic deployment. Our cost
model uses parameters derived from industry data sources (energy rates,
delivery service pricing), and we project from a reduced-scale simulation to
realistic deliveries. Under this projection, the baseline achieves 43.0\% SLA
compliance but is \emph{not} commercially viable: yielding a loss of \$30.009
per run with no finite break-even point, because operating costs are dominated
by collision-induced maintenance, which accounts for 99.7\% of per-run costs
and highlights collision avoidance as a key optimization target. We demonstrate
a learning-based on-device navigation baseline and establish a foundation for
evaluating rule-based navigation, imitation learning, and cost-aware RL
training. CostNav bridges the gap between navigation research and commercial
deployment, enabling data-driven decisions about economic trade-offs across
navigation paradigms.
\\ ( https://arxiv.org/abs/2511.20216 ,  698kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20236
Date: Tue, 25 Nov 2025 12:09:36 GMT   (500kb)

Title: Actionable and diverse counterfactual explanations incorporating domain
 knowledge and causal constraints
Authors: Szymon Bobek, {\L}ukasz Ba{\l}ec, Grzegorz J. Nalepa
Categories: cs.AI cs.LG
\\
 Counterfactual explanations enhance the actionable interpretability of
machine learning models by identifying the minimal changes required to achieve
a desired outcome of the model. However, existing methods often ignore the
complex dependencies in real-world datasets, leading to unrealistic or
impractical modifications. Motivated by cybersecurity applications in the email
marketing domain, we propose a method for generating Diverse, Actionable, and
kNowledge-Constrained Explanations (DANCE), which incorporates feature
dependencies and causal constraints to ensure plausibility and real-world
feasibility of counterfactuals. Our method learns linear and nonlinear
constraints from data or integrates expert-provided dependency graphs, ensuring
counterfactuals are plausible and actionable. By maintaining consistency with
feature relationships, the method produces explanations that align with
real-world constraints. Additionally, it balances plausibility, diversity, and
sparsity, effectively addressing key limitations in existing algorithms. The
work is developed based on a real-life case study with Freshmail, the largest
email marketing company in Poland and supported by a joint R&D project
Sendguard. Furthermore, we provide an extensive evaluation using 140 public
datasets, which highlights its ability to generate meaningful, domain-relevant
counterfactuals that outperform other existing approaches based on widely used
metrics. The source code for reproduction of the results can be found in a
GitHub repository we provide.
\\ ( https://arxiv.org/abs/2511.20236 ,  500kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20285
Date: Tue, 25 Nov 2025 13:13:56 GMT   (814kb)

Title: SMoG: Schema Matching on Graph
Authors: Mingyu Jeon, Jaeyoung Suh, Suwan Cho
Categories: cs.AI
\\
 Schema matching is a critical task in data integration, par- ticularly in the
medical domain where disparate Electronic Health Record (EHR) systems must be
aligned to standard models like OMOP CDM. While Large Language Models (LLMs)
have shown promise in schema matching, they suf- fer from hallucination and
lack of up-to-date domain knowl- edge. Knowledge Graphs (KGs) offer a solution
by pro- viding structured, verifiable knowledge. However, existing KG-augmented
LLM approaches often rely on inefficient complex multi-hop queries or
storage-intensive vector-based retrieval methods. This paper introduces SMoG
(Schema Matching on Graph), a novel framework that leverages iter- ative
execution of simple 1-hop SPARQL queries, inspired by successful strategies in
Knowledge Graph Question An- swering (KGQA). SMoG enhances explainability and
relia- bility by generating human-verifiable query paths while sig- nificantly
reducing storage requirements by directly querying SPARQL endpoints.
Experimental results on real-world med- ical datasets demonstrate that SMoG
achieves performance comparable to state-of-the-art baselines, validating its
effec- tiveness and efficiency in KG-augmented schema matching.
\\ ( https://arxiv.org/abs/2511.20285 ,  814kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20297
Date: Tue, 25 Nov 2025 13:34:54 GMT   (437kb)

Title: Improving Language Agents through BREW
Authors: Shashank Kirtania, Param Biyani, Priyanshu Gupta, Yasharth Bajpai,
 Roshni Iyer, Sumit Gulwani, and Gustavo Soares
Categories: cs.AI
\\
 Large Language Model (LLM)-based agents are increasingly applied to tasks
requiring structured reasoning, tool use, and environmental adaptation, such as
data manipulation, multistep planning, and computer-use automation. However,
despite their versatility, current training paradigms for model weight
optimization methods, like PPO and GRPO, remain relatively impractical with
their high computational overhead for rollout convergence. In addition, the
resulting agent policies are difficult to interpret, adapt, or incrementally
improve. To address this, we investigate creating and refining structured
memory of experiential learning of an agent from its environment as an
alternative route to agent optimization. We introduce BREW (Bootstrapping
expeRientially-learned Environmental knoWledge), a framework for agent
optimization for downstream tasks via KB construction and refinement. In our
formulation, we introduce an effective method for partitioning agent memory for
more efficient retrieval and refinement. BREW uses task graders and behavior
rubrics to learn insights while leveraging state-space search for ensuring
robustness from the noise and non-specificity in natural language. Empirical
results on real world, domain-grounded benchmarks -- OSWorld, $\tau^2$Bench,
and SpreadsheetBench -- show BREW achieves $10-20\%$ improvement in task
precision, $10-15\%$ reduction in API/tool calls leading to faster execution
time, all while maintaining computational efficiency on par with base models.
Unlike prior work where memory is treated as static context, we establish the
KB as a modular and controllable substrate for agent optimization -- an
explicit lever for shaping behavior in a transparent, interpretable, and
extensible manner.
\\ ( https://arxiv.org/abs/2511.20297 ,  437kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20312
Date: Tue, 25 Nov 2025 13:49:48 GMT   (952kb)

Title: Data Augmentation Techniques to Reverse-Engineer Neural Network Weights
 from Input-Output Queries
Authors: Alexander Beiser, Flavio Martinelli, Wulfram Gerstner, Johanni Brea
Categories: cs.AI
Comments: Proceedings of the III edition of the Workshop on Unifying
 Representations in Neural Models (UniReps 2025)
\\
 Network weights can be reverse-engineered given enough informative samples of
a network's input-output function. In a teacher-student setup, this translates
into collecting a dataset of the teacher mapping -- querying the teacher -- and
fitting a student to imitate such mapping. A sensible choice of queries is the
dataset the teacher is trained on. But current methods fail when the teacher
parameters are more numerous than the training data, because the student
overfits to the queries instead of aligning its parameters to the teacher. In
this work, we explore augmentation techniques to best sample the input-output
mapping of a teacher network, with the goal of eliciting a rich set of
representations from the teacher hidden layers. We discover that standard
augmentations such as rotation, flipping, and adding noise, bring little to no
improvement to the identification problem. We design new data augmentation
techniques tailored to better sample the representational space of the
network's hidden layers. With our augmentations we extend the state-of-the-art
range of recoverable network sizes. To test their scalability, we show that we
can recover networks of up to 100 times more parameters than training
data-points.
\\ ( https://arxiv.org/abs/2511.20312 ,  952kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20321
Date: Tue, 25 Nov 2025 13:54:10 GMT   (40kb)

Title: Active Inference in Discrete State Spaces from First Principles
Authors: Patrick Kenny
Categories: cs.AI
Comments: 56 pages
\\
 We seek to clarify the concept of active inference by disentangling it from
the Free Energy Principle. We show how the optimizations that need to be
carried out in order to implement active inference in discrete state spaces can
be formulated as constrained divergence minimization problems which can be
solved by standard mean field methods that do not appeal to the idea of
expected free energy. When it is used to model perception, the
perception/action divergence criterion that we propose coincides with
variational free energy. When it is used to model action, it differs from an
expected free energy functional by an entropy regularizer.
\\ ( https://arxiv.org/abs/2511.20321 ,  40kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20333
Date: Tue, 25 Nov 2025 14:10:44 GMT   (674kb)

Title: NNGPT: Rethinking AutoML with Large Language Models
Authors: Roman Kochnev, Waleed Khalid, Tolgay Atinc Uzun, Xi Zhang, Yashkumar
 Sanjaybhai Dhameliya, Furui Qin, Chandini Vysyaraju, Raghuvir Duvvuri, Avi
 Goyal, Dmitry Ignatov, Radu Timofte
Categories: cs.AI cs.LG cs.NE
\\
 Building self-improving AI systems remains a fundamental challenge in the AI
domain. We present NNGPT, an open-source framework that turns a large language
model (LLM) into a self-improving AutoML engine for neural network development,
primarily for computer vision. Unlike previous frameworks, NNGPT extends the
dataset of neural networks by generating new models, enabling continuous
fine-tuning of LLMs based on closed-loop system of generation, assessment, and
self-improvement. It integrates within one unified workflow five synergistic
LLM-based pipelines: zero-shot architecture synthesis, hyperparameter
optimization (HPO), code-aware accuracy/early-stop prediction,
retrieval-augmented synthesis of scope-closed PyTorch blocks (NN-RAG), and
reinforcement learning. Built on the LEMUR dataset as an audited corpus with
reproducible metrics, NNGPT emits from a single prompt and validates network
architecture, preprocessing code, and hyperparameters, executes them
end-to-end, and learns from result. The PyTorch adapter makes NNGPT
framework-agnostic, enabling strong performance: NN-RAG achieves 73%
executability on 1,289 targets, 3-shot prompting boosts accuracy on common
datasets, and hash-based deduplication saves hundreds of runs. One-shot
prediction matches search-based AutoML, reducing the need for numerous trials.
HPO on LEMUR achieves RMSE 0.60, outperforming Optuna (0.64), while the
code-aware predictor reaches RMSE 0.14 with Pearson r=0.78. The system has
already generated over 5K validated models, proving NNGPT as an autonomous
AutoML engine. Upon acceptance, the code, prompts, and checkpoints will be
released for public access to enable reproducibility and facilitate community
usage.
\\ ( https://arxiv.org/abs/2511.20333 ,  674kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20422
Date: Tue, 25 Nov 2025 15:48:49 GMT   (22890kb)

Title: VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for
 Physically-Consistent Multimodal Learning
Authors: Bo Pang, Chenxi Xu, Jierui Ren, Guoping Wang, Sheng Li
Categories: cs.AI cs.CV cs.GR cs.RO
\\
 Understanding the physical world requires perceptual models grounded in
physical laws rather than mere statistical correlations. However, existing
multimodal learning frameworks, focused on vision and language, lack physical
consistency and overlook the intrinsic causal relationships among an object's
geometry, material, vibration modes, and the sounds it produces. We introduce
VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly
bridges the causal chain from 3D geometry -> physical attributes -> modal
parameters -> acoustic signals. Each 3D model has explicit physical properties
(density, Young's modulus, Poisson's ratio) and volumetric geometry, from which
modal eigenfrequencies and eigenvectors are computed for impact sound synthesis
under controlled excitations. To establish this coherence, we introduce CLASP,
a contrastive learning framework for cross-modal alignment that preserves the
causal correspondence between an object's physical structure and its acoustic
response. This framework enforces physically consistent alignment across
modalities, ensuring that every sample is coherent, traceable to the governing
equations, and embedded within a unified representation space spanning shape,
image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks
for geometry-to-sound prediction, sound-guided shape reconstruction, and
cross-modal representation learning. Extensive validations on these tasks
demonstrate that models trained on VibraVerse exhibit superior accuracy,
interpretability, and generalization across modalities. These results establish
VibraVerse as a benchmark for physically consistent and causally interpretable
multimodal learning, providing a foundation for sound-guided embodied
perception and a deeper understanding of the physical world. The dataset will
be open-sourced.
\\ ( https://arxiv.org/abs/2511.20422 ,  22890kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20468
Date: Tue, 25 Nov 2025 16:33:42 GMT   (2071kb)

Title: DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement
 Learning-Enhanced LLMs
Authors: Yuanhao Li, Mingshan Liu, Hongbo Wang, Yiding Zhang, Yifei Ma, Wei Tan
Categories: cs.AI
\\
 Large Language Models (LLMs) have shown impressive capabilities in multi-step
reasoning and problem-solving.Recent works introduce multi-agent reflection
frameworks where multiple LLM agents critique and refine each other's outputs
using reinforcement learning (RL). However, these approaches often rely on
single-shot responses and lack structural diversity in reasoning exploration.
In this paper, we propose DRAFT-RL, a novel framework that integrates
Chain-of-Draft (CoD) reasoning into multi-agent RL training. Instead of
generating single responses, each agent produces multiple drafts per query,
which are then evaluated by peer agents and a learned reward model to identify
the most promising trajectory. These selected drafts are used to refine future
reasoning strategies through actor-critic learning.DRAFT-RL enables explicit
multi-path exploration, peer-guided reflection, and reward-aligned selection,
resulting in more robust and interpretable LLM agent behavior. We evaluate our
method on complex reasoning tasks including code synthesis, symbolic math, and
knowledge-intensive QA,demonstrating that DRAFT-RL outperforms existing
reflective and RL-based agents by significant margins in both accuracy and
convergence speed
\\ ( https://arxiv.org/abs/2511.20468 ,  2071kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20471
Date: Tue, 25 Nov 2025 16:34:59 GMT   (749kb)

Title: Universe of Thoughts: Enabling Creative Reasoning with Large Language
 Models
Authors: Yuto Suzuki, Farnoush Banaei-Kashani
Categories: cs.AI
\\
 Reasoning based on Large Language Models (LLMs) has garnered increasing
attention due to outstanding performance of these models in mathematical and
complex logical tasks. Beginning with the Chain-of-Thought (CoT) prompting
technique, numerous reasoning methods have emerged that decompose problems into
smaller, sequential steps (or thoughts). However, existing reasoning models
focus on conventional problem-solving and do not necessarily generate creative
solutions by ``creative reasoning''. In domains where the solution space is
expansive and conventional solutions are suboptimal, such as drug discovery or
business strategization, creative reasoning to discover innovative solutions is
crucial. To address this gap, first we introduce a computational framework for
creative reasoning inspired by established cognitive science principles. With
this framework, we propose three core creative reasoning paradigms, namely,
\textit{combinational}, \textit{exploratory}, and \textit{transformative}
reasoning, where each offers specific directions for systematic exploration of
the universe of thoughts to generate creative solutions. Next, to materialize
this framework using LLMs, we introduce the \textit{Universe of Thoughts} (or
\textit{UoT}, for short), a novel set of methods to implement the
aforementioned three creative processes. Finally, we introduce three novel
tasks that necessitate creative problem-solving, along with an evaluation
benchmark to assess creativity from three orthogonal perspectives: feasibility
as constraint, and utility and novelty as metrics. With a comparative analysis
against the state-of-the-art (SOTA) reasoning techniques as well as
representative commercial models with reasoning capability, we show that UoT
demonstrates superior performance in creative reasoning.
\\ ( https://arxiv.org/abs/2511.20471 ,  749kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20497
Date: Tue, 25 Nov 2025 17:04:02 GMT   (218kb)

Title: Quantifying the Privacy Implications of High-Fidelity Synthetic Network
 Traffic
Authors: Van Tran, Shinan Liu, Tian Li, Nick Feamster
Categories: cs.AI
Comments: 14 pages, 13 Figures, 6 Tables
\\
 To address the scarcity and privacy concerns of network traffic data, various
generative models have been developed to produce synthetic traffic. However,
synthetic traffic is not inherently privacy-preserving, and the extent to which
it leaks sensitive information, and how to measure such leakage, remain largely
unexplored. This challenge is further compounded by the diversity of model
architectures, which shape how traffic is represented and synthesized. We
introduce a comprehensive set of privacy metrics for synthetic network traffic,
combining standard approaches like membership inference attacks (MIA) and data
extraction attacks with network-specific identifiers and attributes. Using
these metrics, we systematically evaluate the vulnerability of different
representative generative models and examine the factors that influence attack
success. Our results reveal substantial variability in privacy risks across
models and datasets. MIA success ranges from 0% to 88%, and up to 100% of
network identifiers can be recovered from generated traffic, highlighting
serious privacy vulnerabilities. We further identify key factors that
significantly affect attack outcomes, including training data diversity and how
well the generative model fits the training data. These findings provide
actionable guidance for designing and deploying generative models that minimize
privacy leakage, establishing a foundation for safer synthetic network traffic
generation.
\\ ( https://arxiv.org/abs/2511.20497 ,  218kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20510
Date: Tue, 25 Nov 2025 17:17:54 GMT   (11115kb)

Title: FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic
 Tuning for Drug Lead Optimization
Authors: Yuto Suzuki, Paul Awolade, Daniel V. LaBarbera, Farnoush
 Banaei-Kashani
Categories: cs.AI
\\
 Molecule generation using generative AI is vital for drug discovery, yet
class-specific datasets often contain fewer than 100 training examples. While
fragment-based models handle limited data better than atom-based approaches,
existing heuristic fragmentation limits diversity and misses key fragments.
Additionally, model tuning typically requires slow, indirect collaboration
between medicinal chemists and AI engineers. We introduce FRAGMENTA, an
end-to-end framework for drug lead optimization comprising: 1) a novel
generative model that reframes fragmentation as a "vocabulary selection"
problem, using dynamic Q-learning to jointly optimize fragmentation and
generation; and 2) an agentic AI system that refines objectives via
conversational feedback from domain experts. This system removes the AI
engineer from the loop and progressively learns domain knowledge to eventually
automate tuning. In real-world cancer drug discovery experiments, FRAGMENTA's
Human-Agent configuration identified nearly twice as many high-scoring
molecules as baselines. Furthermore, the fully autonomous Agent-Agent system
outperformed traditional Human-Human tuning, demonstrating the efficacy of
agentic tuning in capturing expert intent.
\\ ( https://arxiv.org/abs/2511.20510 ,  11115kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20526
Date: Tue, 25 Nov 2025 17:31:25 GMT   (1630kb)

Title: Assessing LLMs' Performance: Insights from the Chinese Pharmacist Exam
Authors: Xinran Wang, Boran Zhu, Shujuan Zhou, Ziwen Long, Dehua Zhou, Shu
 Zhang
Categories: cs.AI
Comments: 15 pages, 4 figures
\\
 Background: As large language models (LLMs) become increasingly integrated
into digital health education and assessment workflows, their capabilities in
supporting high-stakes, domain-specific certification tasks remain
underexplored.In China, the national pharmacist licensure exam serves as a
standardized benchmark for evaluating pharmacists' clinical and theoretical
competencies. Objective: This study aimed to compare the performance of two
LLMs: ChatGPT-4o and DeepSeek-R1 on real questions from the Chinese Pharmacist
Licensing Examination (2017-2021), and to discuss the implications of these
performance differences for AI-enabled formative evaluation. Methods: A total
of 2,306 multiple-choice (text-only) questions were compiled from official
exams, training materials, and public databases. Questions containing tables or
images were excluded. Each item was input in its original Chinese format, and
model responses were evaluated for exact accuracy. Pearson's Chi-squared test
was used to compare overall performance, and Fisher's exact test was applied to
year-wise multiple-choice accuracy. Results: DeepSeek-R1 outperformed
ChatGPT-4o with a significantly higher overall accuracy (90.0% vs. 76.1%, p <
0.001). Unit-level analyses revealed consistent advantages for DeepSeek-R1,
particularly in foundational and clinical synthesis modules. While year-by-year
multiple-choice performance also favored DeepSeek-R1, this performance gap did
not reach statistical significance in any specific unit-year (all p > 0.05).
Conclusion: DeepSeek-R1 demonstrated robust alignment with the structural and
semantic demands of the pharmacist licensure exam. These findings suggest that
domain-specific models warrant further investigation for this context, while
also reinforcing the necessity of human oversight in legally and ethically
sensitive contexts.
\\ ( https://arxiv.org/abs/2511.20526 ,  1630kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20531
Date: Tue, 25 Nov 2025 17:34:32 GMT   (935kb)

Title: Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in
 Vision-Language Models
Authors: Shamima Hossain
Categories: cs.AI cs.CV cs.LG
Comments: Accepted as poster at NewInML Workshop ICML, 2025
\\
 Visual Language Models (VLMs) are powerful generative tools but often produce
factually in- accurate outputs due to a lack of robust reason- ing
capabilities. While extensive research has been conducted on integrating
external knowl- edge for reasoning in large language models (LLMs), such
efforts remain underexplored in VLMs, where the challenge is compounded by the
need to bridge multiple modalities seam- lessly. This work introduces a
framework for knowledge-guided reasoning in VLMs, leverag- ing structured
knowledge graphs for multi-hop verification using image-captioning task to il-
lustrate our framework. Our approach enables systematic reasoning across
multiple steps, in- cluding visual entity recognition, knowledge graph
traversal, and fact-based caption refine- ment. We evaluate the framework using
hi- erarchical, triple-based and bullet-point based knowledge representations,
analyzing their ef- fectiveness in factual accuracy and logical infer- ence.
Empirical results show that our approach improves factual accuracy by
approximately 31% on preliminary experiments on a curated dataset of mixtures
from Google Landmarks v2, Conceptual captions and Coco captions re- vealing key
insights into reasoning patterns and failure modes. This work demonstrates the
po- tential of integrating external knowledge for advancing reasoning in VLMs,
paving the way for more reliable and knowledgable multimodal systems.
\\ ( https://arxiv.org/abs/2511.20531 ,  935kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20586
Date: Tue, 25 Nov 2025 18:15:36 GMT   (6165kb)

Title: PaTAS: A Parallel System for Trust Propagation in Neural Networks Using
 Subjective Logic
Authors: Koffi Ismael Ouattara, Ioannis Krontiris, Theo Dimitrakos, Dennis
 Eisermann, and Frank Kargl
Categories: cs.AI cs.LG
\\
 Trustworthiness has become a key requirement for the deployment of artificial
intelligence systems in safety-critical applications. Conventional evaluation
metrics such as accuracy and precision fail to capture uncertainty or the
reliability of model predictions, particularly under adversarial or degraded
conditions. This paper introduces the \emph{Parallel Trust Assessment System
(PaTAS)}, a framework for modeling and propagating trust in neural networks
using Subjective Logic (SL). PaTAS operates in parallel with standard neural
computation through \emph{Trust Nodes} and \emph{Trust Functions} that
propagate input, parameter, and activation trust across the network. The
framework defines a \emph{Parameter Trust Update} mechanism to refine parameter
reliability during training and an \emph{Inference-Path Trust Assessment
(IPTA)} method to compute instance-specific trust at inference. Experiments on
real-world and adversarial datasets demonstrate that PaTAS produces
interpretable, symmetric, and convergent trust estimates that complement
accuracy and expose reliability gaps in poisoned, biased, or uncertain data
scenarios. The results show that PaTAS effectively distinguishes between benign
and adversarial inputs and identifies cases where model confidence diverges
from actual reliability. By enabling transparent and quantifiable trust
reasoning within neural architectures, PaTAS provides a principled foundation
for evaluating model reliability across the AI lifecycle.
\\ ( https://arxiv.org/abs/2511.20586 ,  6165kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20610
Date: Tue, 25 Nov 2025 18:37:55 GMT   (65kb)

Title: Building a Foundation Model for Trajectory from Scratch
Authors: Gaspard Merten, Mahmoud Sakr, Gilles Dejaegere
Categories: cs.AI
DOI: 10.1145/3748636.3758021
\\
 Foundation models are transformative in artificial intelligence, but building
them from scratch, especially for mobility trajectories, is not yet clear or
documented. This tutorial bridges this gap by demonstrating the steps and code
of a minimal implementation of a trajectory-focused foundation model starting
from GPT-2. Through a concise, step-by-step, code-driven process, we
demonstrate adapting GPT-2 for spatiotemporal data. We then review and compare
representative trajectory foundation models, such as TrajFM and TrajGPT,
highlighting their architectural innovations and differences. Additionally, we
introduce complementary techniques from related domains, like TimesFM's
patching approach. Targeted at researchers and practitioners, this tutorial
aims to explain the concepts and terminology of foundation models, at the
implementation level. We find it timely and indispensable to create this
educational material in order to support the SIGSPATIAL community in building
and evaluating mobility foundation models, enhancing both research clarity and
peer-review effectiveness in mobility AI.
\\ ( https://arxiv.org/abs/2511.20610 ,  65kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20623
Date: Tue, 25 Nov 2025 18:46:14 GMT   (415kb)

Title: Copyright Detection in Large Language Models: An Ethical Approach to
 Generative AI Development
Authors: David Szczecina, Senan Gaffori, Edmond Li
Categories: cs.AI
Comments: 4 pages, 3 figures
MSC-class: 68T50
ACM-class: I.2.7
\\
 The widespread use of Large Language Models (LLMs) raises critical concerns
regarding the unauthorized inclusion of copyrighted content in training data.
Existing detection frameworks, such as DE-COP, are computationally intensive,
and largely inaccessible to independent creators. As legal scrutiny increases,
there is a pressing need for a scalable, transparent, and user-friendly
solution. This paper introduce an open-source copyright detection platform that
enables content creators to verify whether their work was used in LLM training
datasets. Our approach enhances existing methodologies by facilitating ease of
use, improving similarity detection, optimizing dataset validation, and
reducing computational overhead by 10-30% with efficient API calls. With an
intuitive user interface and scalable backend, this framework contributes to
increasing transparency in AI development and ethical compliance, facilitating
the foundation for further research in responsible AI development and copyright
enforcement.
\\ ( https://arxiv.org/abs/2511.20623 ,  415kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20627
Date: Tue, 25 Nov 2025 18:48:19 GMT   (1490kb)

Title: Fighting AI with AI: Leveraging Foundation Models for Assuring
 AI-Enabled Safety-Critical Systems
Authors: Anastasia Mavridou, Divya Gopinath, Corina S. P\u{a}s\u{a}reanu
Categories: cs.AI
\\
 The integration of AI components, particularly Deep Neural Networks (DNNs),
into safety-critical systems such as aerospace and autonomous vehicles presents
fundamental challenges for assurance. The opacity of AI systems, combined with
the semantic gap between high-level requirements and low-level network
representations, creates barriers to traditional verification approaches. These
AI-specific challenges are amplified by longstanding issues in Requirements
Engineering, including ambiguity in natural language specifications and
scalability bottlenecks in formalization. We propose an approach that leverages
AI itself to address these challenges through two complementary components.
REACT (Requirements Engineering with AI for Consistency and Testing) employs
Large Language Models (LLMs) to bridge the gap between informal natural
language requirements and formal specifications, enabling early verification
and validation. SemaLens (Semantic Analysis of Visual Perception using large
Multi-modal models) utilizes Vision Language Models (VLMs) to reason about,
test, and monitor DNN-based perception systems using human-understandable
concepts. Together, these components provide a comprehensive pipeline from
informal requirements to validated implementations.
\\ ( https://arxiv.org/abs/2511.20627 ,  1490kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19648
Date: Mon, 24 Nov 2025 19:27:56 GMT   (1243kb)

Title: Efficient Multi-Hop Question Answering over Knowledge Graphs via LLM
 Planning and Embedding-Guided Search
Authors: Manil Shrestha and Edward Kim
Categories: cs.CL cs.AI
\\
 Multi-hop question answering over knowledge graphs remains computationally
challenging due to the combinatorial explosion of possible reasoning paths.
Recent approaches rely on expensive Large Language Model (LLM) inference for
both entity linking and path ranking, limiting their practical deployment.
Additionally, LLM-generated answers often lack verifiable grounding in
structured knowledge. We present two complementary hybrid algorithms that
address both efficiency and verifiability: (1) LLM-Guided Planning that uses a
single LLM call to predict relation sequences executed via breadth-first
search, achieving near-perfect accuracy (micro-F1 > 0.90) while ensuring all
answers are grounded in the knowledge graph, and (2) Embedding-Guided Neural
Search that eliminates LLM calls entirely by fusing text and graph embeddings
through a lightweight 6.7M-parameter edge scorer, achieving over 100 times
speedup with competitive accuracy. Through knowledge distillation, we compress
planning capability into a 4B-parameter model that matches large-model
performance at zero API cost. Evaluation on MetaQA demonstrates that grounded
reasoning consistently outperforms ungrounded generation, with structured
planning proving more transferable than direct answer generation. Our results
show that verifiable multi-hop reasoning does not require massive models at
inference time, but rather the right architectural inductive biases combining
symbolic structure with learned representations.
\\ ( https://arxiv.org/abs/2511.19648 ,  1243kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19719
Date: Mon, 24 Nov 2025 21:29:15 GMT   (2392kb)

Title: Can LLMs Faithfully Explain Themselves in Low-Resource Languages? A Case
 Study on Emotion Detection in Persian
Authors: Mobina Mehrazar, Mohammad Amin Yousefi, Parisa Abolfath Beygi, Behnam
 Bahrak
Categories: cs.CL
\\
 Large language models (LLMs) are increasingly used to generate
self-explanations alongside their predictions, a practice that raises concerns
about the faithfulness of these explanations, especially in low-resource
languages. This study evaluates the faithfulness of LLM-generated explanations
in the context of emotion classification in Persian, a low-resource language,
by comparing the influential words identified by the model against those
identified by human annotators. We assess faithfulness using confidence scores
derived from token-level log-probabilities. Two prompting strategies, differing
in the order of explanation and prediction (Predict-then-Explain and
Explain-then-Predict), are tested for their impact on explanation faithfulness.
Our results reveal that while LLMs achieve strong classification performance,
their generated explanations often diverge from faithful reasoning, showing
greater agreement with each other than with human judgments. These results
highlight the limitations of current explanation methods and metrics,
emphasizing the need for more robust approaches to ensure LLM reliability in
multilingual and low-resource contexts.
\\ ( https://arxiv.org/abs/2511.19719 ,  2392kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19739
Date: Mon, 24 Nov 2025 21:57:09 GMT   (217kb)

Title: Comparative Analysis of LoRA-Adapted Embedding Models for Clinical
 Cardiology Text Representation
Authors: Richard J. Young and Alice M. Matthews
Categories: cs.CL cs.LG
Comments: 25 pages, 13 figures, 5 tables
ACM-class: I.2.7; J.3
\\
 Domain-specific text embeddings are critical for clinical natural language
processing, yet systematic comparisons across model architectures remain
limited. This study evaluates ten transformer-based embedding models adapted
for cardiology through Low-Rank Adaptation (LoRA) fine-tuning on 106,535
cardiology text pairs derived from authoritative medical textbooks. Results
demonstrate that encoder-only architectures, particularly BioLinkBERT, achieve
superior domain-specific performance (separation score: 0.510) compared to
larger decoder-based models, while requiring significantly fewer computational
resources. The findings challenge the assumption that larger language models
necessarily produce better domain-specific embeddings and provide practical
guidance for clinical NLP system development. All models, training code, and
evaluation datasets are publicly available to support reproducible research in
medical informatics.
\\ ( https://arxiv.org/abs/2511.19739 ,  217kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19757
Date: Mon, 24 Nov 2025 22:21:55 GMT   (6159kb)

Title: What does it mean to understand language?
Authors: Colton Casto, Anna Ivanova, Evelina Fedorenko, and Nancy Kanwisher
Categories: cs.CL
\\
 Language understanding entails not just extracting the surface-level meaning
of the linguistic input, but constructing rich mental models of the situation
it describes. Here we propose that because processing within the brain's core
language system is fundamentally limited, deeply understanding language
requires exporting information from the language system to other brain regions
that compute perceptual and motor representations, construct mental models, and
store our world knowledge and autobiographical memories. We review the existing
evidence for this hypothesis, and argue that recent progress in cognitive
neuroscience provides both the conceptual foundation and the methods to
directly test it, thus opening up a new strategy to reveal what it means,
cognitively and neurally, to understand language.
\\ ( https://arxiv.org/abs/2511.19757 ,  6159kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19785
Date: Mon, 24 Nov 2025 23:24:54 GMT   (519kb)

Title: Gender Bias in Emotion Recognition by Large Language Models
Authors: Maureen Herbert, Katie Sun, Angelica Lim, Yasaman Etesam
Categories: cs.CL cs.CY
Comments: Accepted at AAAI 2026 Workshop (WS37)
\\
 The rapid advancement of large language models (LLMs) and their growing
integration into daily life underscore the importance of evaluating and
ensuring their fairness. In this work, we examine fairness within the domain of
emotional theory of mind, investigating whether LLMs exhibit gender biases when
presented with a description of a person and their environment and asked, "How
does this person feel?". Furthermore, we propose and evaluate several debiasing
strategies, demonstrating that achieving meaningful reductions in bias requires
training based interventions rather than relying solely on inference-time
prompt-based approaches such as prompt engineering.
\\ ( https://arxiv.org/abs/2511.19785 ,  519kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19816
Date: Tue, 25 Nov 2025 01:14:25 GMT   (4436kb)

Title: Breaking Bad: Norms for Valence, Arousal, and Dominance for over 10k
 English Multiword Expressions
Authors: Saif M. Mohammad
Categories: cs.CL
Journal-ref: AACL 2025
\\
 Factor analysis studies have shown that the primary dimensions of word
meaning are Valence (V), Arousal (A), and Dominance (D). Existing lexicons such
as the NRC VAD Lexicon, published in 2018, include VAD association ratings for
words. Here, we present a complement to it, which has human ratings of valence,
arousal, and dominance for 10k English Multiword Expressions (MWEs) and their
constituent words. We also increase the coverage of unigrams, especially words
that have become more common since 2018. In all, the new NRC VAD Lexicon v2 now
has entries for 10k MWEs and 25k words, in addition to the entries in v1. We
show that the associations are highly reliable. We use the lexicon to examine
emotional characteristics of MWEs, including: 1. The degree to which MWEs
(idioms, noun compounds, and verb particle constructions) exhibit strong
emotionality; 2. The degree of emotional compositionality in MWEs. The lexicon
enables a wide variety of research in NLP, Psychology, Public Health, Digital
Humanities, and Social Sciences. The NRC VAD Lexicon v2 is freely available
through the project webpage: http://saifmohammad.com/WebPages/nrc-vad.html
\\ ( https://arxiv.org/abs/2511.19816 ,  4436kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19818
Date: Tue, 25 Nov 2025 01:15:54 GMT   (878kb)

Title: Language-Independent Sentiment Labelling with Distant Supervision: A
 Case Study for English, Sepedi and Setswana
Authors: Koena Ronny Mabokela and Tim Schlippe and Mpho Raborife and Turgay
 Celik
Categories: cs.CL cs.AI
Comments: Published in the The Fourth Workshop on Processing Emotions,
 Decisions and Opinions (EDO 2023) at 10th Language & Technology Conference:
 Human Language Technologies as a Challenge for Computer Science and
 Linguistics (LTC 2023), Pozna\'n, Poland, 21-23 April 2023. ISBN:
 978-83-232-4176-8
DOI: 10.14746/amup.9788323241775
\\
 Sentiment analysis is a helpful task to automatically analyse opinions and
emotions on various topics in areas such as AI for Social Good, AI in Education
or marketing. While many of the sentiment analysis systems are developed for
English, many African languages are classified as low-resource languages due to
the lack of digital language resources like text labelled with corresponding
sentiment classes. One reason for that is that manually labelling text data is
time-consuming and expensive. Consequently, automatic and rapid processes are
needed to reduce the manual effort as much as possible making the labelling
process as efficient as possible. In this paper, we present and analyze an
automatic language-independent sentiment labelling method that leverages
information from sentiment-bearing emojis and words. Our experiments are
conducted with tweets in the languages English, Sepedi and Setswana from
SAfriSenti, a multilingual sentiment corpus for South African languages. We
show that our sentiment labelling approach is able to label the English tweets
with an accuracy of 66%, the Sepedi tweets with 69%, and the Setswana tweets
with 63%, so that on average only 34% of the automatically generated labels
remain to be corrected.
\\ ( https://arxiv.org/abs/2511.19818 ,  878kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19852
Date: Tue, 25 Nov 2025 02:31:40 GMT   (2049kb)

Title: Profile-LLM: Dynamic Profile Optimization for Realistic Personality
 Expression in LLMs
Authors: Shi-Wei Dai, Yan-Wei Shie, Tsung-Huan Yang, Lun-Wei Ku, Yung-Hui Li
Categories: cs.CL
\\
 Personalized Large Language Models (LLMs) have been shown to be an effective
way to create more engaging and enjoyable user-AI interactions. While previous
studies have explored using prompts to elicit specific personality traits in
LLMs, they have not optimized these prompts to maximize personality expression.
To address this limitation, we propose PersonaPulse: Dynamic Profile
Optimization for Realistic Personality Expression in LLMs, a framework that
leverages LLMs' inherent knowledge of personality traits to iteratively enhance
role-play prompts while integrating a situational response benchmark as a
scoring tool, ensuring a more realistic and contextually grounded evaluation to
guide the optimization process. Quantitative evaluations demonstrate that the
prompts generated by PersonaPulse outperform those of prior work, which were
designed based on personality descriptions from psychological studies.
Additionally, we explore the relationship between model size and personality
modeling through extensive experiments. Finally, we find that, for certain
personality traits, the extent of personality evocation can be partially
controlled by pausing the optimization process. These findings underscore the
importance of prompt optimization in shaping personality expression within
LLMs, offering valuable insights for future research on adaptive AI
interactions.
\\ ( https://arxiv.org/abs/2511.19852 ,  2049kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19858
Date: Tue, 25 Nov 2025 02:40:49 GMT   (1607kb)

Title: A Systematic Analysis of Large Language Models with RAG-enabled Dynamic
 Prompting for Medical Error Detection and Correction
Authors: Farzad Ahmed, Joniel Augustine Jerome, Meliha Yetisgen, \"Ozlem Uzuner
Categories: cs.CL cs.AI
\\
 Objective: Clinical documentation contains factual, diagnostic, and
management errors that can compromise patient safety. Large language models
(LLMs) may help detect and correct such errors, but their behavior under
different prompting strategies remains unclear. We evaluate zero-shot
prompting, static prompting with random exemplars (SPR), and
retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error
processing: error flag detection, error sentence detection, and error
correction.
 Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs
(GPT, Claude, Gemini, and OpenAI o-series models). We measured performance
using accuracy, recall, false-positive rate (FPR), and an aggregate score of
ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example
outputs to identify failure modes and differences between LLM and clinician
reasoning.
 Results: Zero-shot prompting showed low recall in both detection tasks, often
missing abbreviation-heavy or atypical errors. SPR improved recall but
increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent,
improved recall by 5 to 10 percent in error sentence detection, and generated
more contextually accurate corrections.
 Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting.
Using retrieved exemplars improves detection accuracy, reduces false positives,
and enhances the reliability of medical error correction.
\\ ( https://arxiv.org/abs/2511.19858 ,  1607kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19957
Date: Tue, 25 Nov 2025 06:06:17 GMT   (4048kb)

Title: AppSelectBench: Application-Level Tool Selection Benchmark
Authors: Tianyi Chen, Michael Solodko, Sen Wang, Jongwoo Ko, Junheng Hao, Colby
 Banbury, Sara Abdali, Saeed Amizadeh, Qing Xiao, Yinheng Li, Tianyu Ding,
 Kamran Ghasedi Dizaji, Suzhen Zheng, Hao Fan, Justin Wagle, Pashmina Cameron,
 Kazuhito Koishida
Categories: cs.CL
\\
 Computer Using Agents (CUAs) are increasingly equipped with external tools,
enabling them to perform complex and realistic tasks. For CUAs to operate
effectively, application selection, which refers to deciding which application
to use before invoking fine-grained tools such as APIs, is a fundamental
capability. It determines whether the agent initializes the correct
environment, avoids orchestration confusion, and efficiently focuses on
relevant context. However, existing benchmarks primarily assess fine-grained
API selection, offering limited insight into whether models can reason across
and choose between different applications. To fill this gap, we introduce
AppSelectBench, a comprehensive benchmark for evaluating application selection
in CUAs. AppSelectBench contains a novel user task generation pipeline that
produces realistic, diverse, and semantically grounded user intents at scale,
together with unified evaluation protocols covering random, heuristic,
zero-shot, few-shot, and retrieval-augmented-settings. AppSelectBench covers
one hundred widely used desktop applications and includes more than one hundred
thousand realistic, diverse, and semantically grounded user tasks. Extensive
experiments across both closed-source and open-source large language models
reveal systematic strengths and weaknesses in inter-application reasoning,
showing that even the most capable models still struggle to make consistent
application choices. Together, these results establish AppSelectBench as a
foundation for studying and advancing application level reasoning, an essential
yet underexplored capability of intelligent CUAs. The source is available at
https://github.com/microsoft/appselectbench.
\\ ( https://arxiv.org/abs/2511.19957 ,  4048kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19987
Date: Tue, 25 Nov 2025 06:54:51 GMT   (2677kb)

Title: $\text{R}^2\text{R}$: A Route-to-Rerank Post-Training Framework for
 Multi-Domain Decoder-Only Rerankers
Authors: Xinyu Wang, Hanwei Wu, Qingchen Hu, Zhenghan Tai, Jingrui Tian, Lei
 Ding, Jijun Chi, Hailin He, Tung Sum Thomas Kwok, Yufei Cui, Sicheng Lyu,
 Muzhi Li, Mingze Li, Xinyue Yu, Ling Zhou, Peng Lu
Categories: cs.CL cs.IR
Comments: 13 pages, including 3 figures and 3 tables
\\
 Decoder-only rerankers are central to Retrieval-Augmented Generation (RAG).
However, generalist models miss domain-specific nuances in high-stakes fields
like finance and law, and naive fine-tuning causes surface-form overfitting and
catastrophic forgetting. To address this challenge, we introduce R2R, a
domain-aware framework that combines dynamic expert routing with a two-stage
training strategy, Entity Abstraction for Generalization (EAG). EAG introduces
a counter-shortcut mechanism by masking the most predictive surface cues,
forcing the reranker to learn domain-invariant relevance patterns rather than
memorizing dataset-specific entities. To efficiently activate domain experts,
R2R employs a lightweight Latent Semantic Router that probes internal
representations from the frozen backbone decoder to select the optimal LoRA
expert per query. Extensive experiments across different reranker backbones and
diverse domains (legal, medical, and financial) demonstrate that R2R
consistently surpasses generalist and single-domain fine-tuned baselines. Our
results confirm that R2R is a model-agnostic and modular approach to domain
specialization with strong cross-domain robustness.
\\ ( https://arxiv.org/abs/2511.19987 ,  2677kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19997
Date: Tue, 25 Nov 2025 07:03:20 GMT   (598kb)

Title: Directional Optimization Asymmetry in Transformers: A Synthetic Stress
 Test
Authors: Mihir Sahasrabudhe
Categories: cs.CL cs.AI
Comments: 19 pages, 4 figures. Code available at
 https://github.com/mihirs-0/synass
\\
 Transformers are theoretically reversal-invariant: their function class does
not prefer left-to-right over right-to-left mappings. Yet empirical studies on
natural language repeatedly report a "reversal curse," and recent work on
temporal asymmetry in LLMs suggests that real-world corpora carry their own
arrow of time. This leaves an unresolved question: do directional failures stem
from linguistic statistics, or from the architecture itself? We cut through
this ambiguity with a fully synthetic, entropy-controlled benchmark designed as
a clean-room stress test for directional learning. Using random string mappings
with tunable branching factor K, we construct forward tasks with zero
conditional entropy and inverse tasks with analytically determined entropy
floors. Excess loss above these floors reveals that even scratch-trained GPT-2
models exhibit a strong, reproducible directional optimization gap (e.g., 1.16
nats at K=5), far larger than that of an MLP trained on the same data.
Pre-trained initializations shift optimization behavior but do not eliminate
this gap, while LoRA encounters a sharp capacity wall on high-entropy inverse
mappings. Together, these results isolate a minimal, semantics-free signature
of directional friction intrinsic to causal Transformer training-one that
persists even when linguistic priors, token frequencies, and corpus-level
temporal asymmetries are removed. Our benchmark provides a controlled
instrument for dissecting directional biases in modern sequence models and
motivates deeper mechanistic study of why inversion remains fundamentally
harder for Transformers.
\\ ( https://arxiv.org/abs/2511.19997 ,  598kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20001
Date: Tue, 25 Nov 2025 07:12:09 GMT   (935kb)

Title: A Machine Learning Approach for Detection of Mental Health Conditions
 and Cyberbullying from Social Media
Authors: Edward Ajayi, Martha Kachweka, Mawuli Deku, Emily Aiken
Categories: cs.CL cs.SI
Comments: Accepted for Oral Presentation at the AAAI-26 Bridge Program on AI
 for Medicine and Healthcare (AIMedHealth). To appear in Proceedings of
 Machine Learning Research (PMLR)
\\
 Mental health challenges and cyberbullying are increasingly prevalent in
digital spaces, necessitating scalable and interpretable detection systems.
This paper introduces a unified multiclass classification framework for
detecting ten distinct mental health and cyberbullying categories from social
media data. We curate datasets from Twitter and Reddit, implementing a rigorous
"split-then-balance" pipeline to train on balanced data while evaluating on a
realistic, held-out imbalanced test set. We conducted a comprehensive
evaluation comparing traditional lexical models, hybrid approaches, and several
end-to-end fine-tuned transformers. Our results demonstrate that end-to-end
fine-tuning is critical for performance, with the domain-adapted MentalBERT
emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score
of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline.
Grounded in a comprehensive ethical analysis, we frame the system as a
human-in-the-loop screening aid, not a diagnostic tool. To support this, we
introduce a hybrid SHAPLLM explainability framework and present a prototype
dashboard ("Social Media Screener") designed to integrate model predictions and
their explanations into a practical workflow for moderators. Our work provides
a robust baseline, highlighting future needs for multi-label,
clinically-validated datasets at the critical intersection of online safety and
computational mental health.
\\ ( https://arxiv.org/abs/2511.20001 ,  935kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20056
Date: Tue, 25 Nov 2025 08:25:30 GMT   (1198kb)

Title: Online-PVLM: Advancing Personalized VLMs with Online Concept Learning
Authors: Huiyu Bai, Runze Wang, Zhuoyun Du, Yiyang Zhao, Fengji Zhang, Haoyu
 Chen, Xiaoyong Zhu, Bo Zheng, Xuejiao Zhao
Categories: cs.CL
Comments: Work in Progress
\\
 Personalized Visual Language Models (VLMs) are gaining increasing attention
for their formidable ability in user-specific concepts aligned interactions
(e.g., identifying a user's bike). Existing methods typically require the
learning of separate embeddings for each new concept, which fails to support
real-time adaptation during testing. This limitation becomes particularly
pronounced in large-scale scenarios, where efficient retrieval of concept
embeddings is not achievable. To alleviate this gap, we propose Online-PVLM, a
framework for online concept learning by leveraging hyperbolic representations.
Our approach makes a train-free paradigm for concept embeddings generation at
test time, making the use of personalized VLMs both scalable and efficient. In
addition, we develop OP-Eval, a comprehensive and large-scale benchmark
comprising 1,292 concepts and over 30K high-quality instances with diverse
question types, designed to rigorously assess online concept learning in
realistic scenarios. Extensive experiments demonstrate the state-of-the-art
performance of our proposed framework. Our source code and dataset will be made
available.
\\ ( https://arxiv.org/abs/2511.20056 ,  1198kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20072
Date: Tue, 25 Nov 2025 08:46:09 GMT   (1503kb)

Title: MTA: A Merge-then-Adapt Framework for Personalized Large Language Model
Authors: Xiaopeng Li, Yuanjin Zheng, Wanyu Wang, wenlin zhang, Pengyue Jia,
 Yiqi Wang, Maolin Wang, Xuetao Wei, Xiangyu Zhao
Categories: cs.CL
\\
 Personalized Large Language Models (PLLMs) aim to align model outputs with
individual user preferences, a crucial capability for user-centric
applications. However, the prevalent approach of fine-tuning a separate module
for each user faces two major limitations: (1) storage costs scale linearly
with the number of users, rendering the method unscalable; and (2) fine-tuning
a static model from scratch often yields suboptimal performance for users with
sparse data. To address these challenges, we propose MTA, a Merge-then-Adapt
framework for PLLMs. MTA comprises three key stages. First, we construct a
shared Meta-LoRA Bank by selecting anchor users and pre-training
meta-personalization traits within meta-LoRA modules. Second, to ensure
scalability and enable dynamic personalization combination beyond static
models, we introduce an Adaptive LoRA Fusion stage. This stage retrieves and
dynamically merges the most relevant anchor meta-LoRAs to synthesize a
user-specific one, thereby eliminating the need for user-specific storage and
supporting more flexible personalization. Third, we propose a LoRA Stacking for
Few-Shot Personalization stage, which applies an additional ultra-low-rank,
lightweight LoRA module on top of the merged LoRA. Fine-tuning this module
enables effective personalization under few-shot settings. Extensive
experiments on the LaMP benchmark demonstrate that our approach outperforms
existing SOTA methods across multiple tasks.
\\ ( https://arxiv.org/abs/2511.20072 ,  1503kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20086
Date: Tue, 25 Nov 2025 09:01:08 GMT   (198kb)

Title: More Bias, Less Bias: BiasPrompting for Enhanced Multiple-Choice
 Question Answering
Authors: Duc Anh Vu, Thong Nguyen, Cong-Duy Nguyen, Viet Anh Nguyen, Anh Tuan
 Luu
Categories: cs.CL
Comments: Accepted at the 41st ACM/SIGAPP Symposium On Applied Computing (SAC
 2026), Main Conference
\\
 With the advancement of large language models (LLMs), their performance on
multiple-choice question (MCQ) tasks has improved significantly. However,
existing approaches face key limitations: answer choices are typically
presented to LLMs without contextual grounding or explanation. This absence of
context can lead to incomplete exploration of all possible answers, ultimately
degrading the models' reasoning capabilities. To address these challenges, we
introduce BiasPrompting, a novel inference framework that guides LLMs to
generate and critically evaluate reasoning across all plausible answer options
before reaching a final prediction. It consists of two components: first, a
reasoning generation stage, where the model is prompted to produce supportive
reasonings for each answer option, and then, a reasoning-guided agreement
stage, where the generated reasonings are synthesized to select the most
plausible answer. Through comprehensive evaluations, BiasPrompting demonstrates
significant improvements in five widely used multiple-choice question answering
benchmarks. Our experiments showcase that BiasPrompting enhances the reasoning
capabilities of LLMs and provides a strong foundation for tackling complex and
challenging questions, particularly in settings where existing methods
underperform.
\\ ( https://arxiv.org/abs/2511.20086 ,  198kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20102
Date: Tue, 25 Nov 2025 09:21:57 GMT   (2828kb)

Title: SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention
 Outputs in Feature Space
Authors: Zhenyi Shen, Junru Lu, Lin Gui, Jiazheng Li, Yulan He, Di Yin, Xing
 Sun
Categories: cs.CL
Comments: 28 pages
\\
 The quadratic complexity of full attention limits efficient long-context
processing in large language models (LLMs). Sparse attention mitigates this
cost by restricting each query to attend to a subset of previous tokens;
however, training-free approaches often lead to severe performance degradation.
Native sparse-attention methods (e.g., NSA, MoBA) alleviate this issue, yet
exhibit a critical paradox: they produce lower attention sparsity than
full-attention models, despite aiming to approximate full attention, which may
constrain their effectiveness. We attribute this paradox to gradient update
deficiency: low-ranked key-value pairs excluded during sparse training receive
neither forward contribution nor backward gradients, and thus never learn
proper suppression. To overcome this limitation, we propose SSA (Sparse Sparse
Attention), a unified training framework that considers both sparse and full
attention and enforces bidirectional alignment at every layer. This design
preserves gradient flow to all tokens while explicitly encouraging
sparse-attention outputs to align with their full-attention counterparts,
thereby promoting stronger sparsity. As a result, SSA achieves state-of-the-art
performance under both sparse and full attention inference across multiple
commonsense benchmarks. Furthermore, SSA enables models to adapt smoothly to
varying sparsity budgets; performance improves consistently as more tokens are
allowed to attend, supporting flexible compute-performance trade-offs at
inference time. Finally, we show that native sparse-attention training
surprisingly improves long-context extrapolation by mitigating the
over-allocation of attention values in sink areas, with SSA demonstrating the
strongest extrapolation capability.
\\ ( https://arxiv.org/abs/2511.20102 ,  2828kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20106
Date: Tue, 25 Nov 2025 09:26:15 GMT   (3148kb)

Title: EM2LDL: A Multilingual Speech Corpus for Mixed Emotion Recognition
 through Label Distribution Learning
Authors: Xingfeng Li, Xiaohan Shi, Junjie Li, Yongwei Li, Masashi Unoki, Tomoki
 Toda, Masato Akagi
Categories: cs.CL
Comments: Submitted to IEEE Transactions on Affective computing
\\
 This study introduces EM2LDL, a novel multilingual speech corpus designed to
advance mixed emotion recognition through label distribution learning.
Addressing the limitations of predominantly monolingual and single-label
emotion corpora \textcolor{black}{that restrict linguistic diversity, are
unable to model mixed emotions, and lack ecological validity}, EM2LDL comprises
expressive utterances in English, Mandarin, and Cantonese, capturing the
intra-utterance code-switching prevalent in multilingual regions like Hong Kong
and Macao. The corpus integrates spontaneous emotional expressions from online
platforms, annotated with fine-grained emotion distributions across 32
categories. Experimental baselines using self-supervised learning models
demonstrate robust performance in speaker-independent gender-, age-, and
personality-based evaluations, with HuBERT-large-EN achieving optimal results.
By incorporating linguistic diversity and ecological validity, EM2LDL enables
the exploration of complex emotional dynamics in multilingual settings. This
work provides a versatile testbed for developing adaptive, empathetic systems
for applications in affective computing, including mental health monitoring and
cross-cultural communication. The dataset, annotations, and baseline codes are
publicly available at https://github.com/xingfengli/EM2LDL.
\\ ( https://arxiv.org/abs/2511.20106 ,  3148kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20107
Date: Tue, 25 Nov 2025 09:26:34 GMT   (428kb)

Title: Mispronunciation Detection and Diagnosis Without Model Training: A
 Retrieval-Based Approach
Authors: Huu Tuong Tu, Ha Viet Khanh, Tran Tien Dat, Vu Huan, Thien Van Luong,
 Nguyen Tien Cuong, Nguyen Thi Thu Trang
Categories: cs.CL cs.SD eess.AS
\\
 Mispronunciation Detection and Diagnosis (MDD) is crucial for language
learning and speech therapy. Unlike conventional methods that require scoring
models or training phoneme-level models, we propose a novel training-free
framework that leverages retrieval techniques with a pretrained Automatic
Speech Recognition model. Our method avoids phoneme-specific modeling or
additional task-specific training, while still achieving accurate detection and
diagnosis of pronunciation errors. Experiments on the L2-ARCTIC dataset show
that our method achieves a superior F1 score of 69.60% while avoiding the
complexity of model training.
\\ ( https://arxiv.org/abs/2511.20107 ,  428kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20120
Date: Tue, 25 Nov 2025 09:40:57 GMT   (1467kb)

Title: "When Data is Scarce, Prompt Smarter"... Approaches to Grammatical Error
 Correction in Low-Resource Settings
Authors: Somsubhra De, Harsh Kumar and Arun Prakash A
Categories: cs.CL cs.AI
Comments: 10 pages, 5 figures, 5 tables; Accept-demonstration at BHASHA
 Workshop, IJCNLP-AACL 2025
\\
 Grammatical error correction (GEC) is an important task in Natural Language
Processing that aims to automatically detect and correct grammatical mistakes
in text. While recent advances in transformer-based models and large annotated
datasets have greatly improved GEC performance for high-resource languages such
as English, the progress has not extended equally. For most Indic languages,
GEC remains a challenging task due to limited resources, linguistic diversity
and complex morphology. In this work, we explore prompting-based approaches
using state-of-the-art large language models (LLMs), such as GPT-4.1,
Gemini-2.5 and LLaMA-4, combined with few-shot strategy to adapt them to
low-resource settings. We observe that even basic prompting strategies, such as
zero-shot and few-shot approaches, enable these LLMs to substantially
outperform fine-tuned Indic-language models like Sarvam-22B, thereby
illustrating the exceptional multilingual generalization capabilities of
contemporary LLMs for GEC. Our experiments show that carefully designed prompts
and lightweight adaptation significantly enhance correction quality across
multiple Indic languages. We achieved leading results in the shared
task--ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu
(GLEU: 85.22), 4th in Bangla (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97).
These findings highlight the effectiveness of prompt-driven NLP techniques and
underscore the potential of large-scale LLMs to bridge resource gaps in
multilingual GEC.
\\ ( https://arxiv.org/abs/2511.20120 ,  1467kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20143
Date: Tue, 25 Nov 2025 10:06:50 GMT   (2930kb)

Title: SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting
 Gird-based Discontinuous NER Models
Authors: Wen-Fang Su, Hsiao-Wei Chou, and Wen-Yang Lin
Categories: cs.CL cs.AI cs.IR
Comments: 9 pages, 5 figures
ACM-class: I.2; I.7
\\
 Named Entity Recognition (NER) is a critical task in natural language
processing, yet it remains particularly challenging for discontinuous entities.
The primary difficulty lies in text segmentation, as traditional methods often
missegment or entirely miss cross-sentence discontinuous entities,
significantly affecting recognition accuracy. Therefore, we aim to address the
segmentation and omission issues associated with such entities. Recent studies
have shown that grid-tagging methods are effective for information extraction
due to their flexible tagging schemes and robust architectures. Building on
this, we integrate image data augmentation techniques, such as cropping,
scaling, and padding, into grid-based models to enhance their ability to
recognize discontinuous entities and handle segmentation challenges.
Experimental results demonstrate that traditional segmentation methods often
fail to capture cross-sentence discontinuous entities, leading to decreased
performance. In contrast, our augmented grid models achieve notable
improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1
score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities,
confirming the effectiveness of our approach.
\\ ( https://arxiv.org/abs/2511.20143 ,  2930kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20182
Date: Tue, 25 Nov 2025 11:05:53 GMT   (21kb)

Title: KyrgyzBERT: A Compact, Efficient Language Model for Kyrgyz NLP
Authors: Adilet Metinov, Gulida M. Kudakeeva, Gulnara D. Kabaeva
Categories: cs.CL
Comments: 3 pages, 1 figure, 2 tables. Preprint
ACM-class: I.2.7
\\
 Kyrgyz remains a low-resource language with limited foundational NLP tools.
To address this gap, we introduce KyrgyzBERT, the first publicly available
monolingual BERT-based language model for Kyrgyz. The model has 35.9M
parameters and uses a custom tokenizer designed for the language's
morphological structure. To evaluate performance, we create kyrgyz-sst2, a
sentiment analysis benchmark built by translating the Stanford Sentiment
Treebank and manually annotating the full test set. KyrgyzBERT fine-tuned on
this dataset achieves an F1-score of 0.8280, competitive with a fine-tuned
mBERT model five times larger. All models, data, and code are released to
support future research in Kyrgyz NLP.
\\ ( https://arxiv.org/abs/2511.20182 ,  21kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20233
Date: Tue, 25 Nov 2025 12:06:23 GMT   (832kb)

Title: REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth
 into Style and Substance
Authors: Chuyi Kong, Gao Wei, Jing Ma, Hongzhan Lin, Zhiyuan Fan
Categories: cs.CL
\\
 The prevalence of misinformation on social media threatens public trust,
demanding automated fact-checking systems that provide accurate verdicts with
interpretable explanations. However, existing large language model-based
(LLM-based) approaches often rely heavily on external knowledge sources,
introducing substantial latency and even hallucinations that undermine
reliability, interpretability, and responsiveness, which is crucial for
real-time use. To address these challenges, we propose REason-guided
Fact-checking with Latent EXplanations REFLEX paradigm, a plug-and-play,
self-refining paradigm that leverages the internal knowledge in backbone model
to improve both verdict accuracy and explanation quality. REFLEX reformulates
fact-checking as a role-play dialogue and jointly trains verdict prediction and
explanation generation. It adaptively extracts contrastive activation pairs
between the backbone model and its fine-tuned variant to construct steering
vectors that disentangle truth into style and substance naturally. These
activation-level signals guide inference and suppress noisy explanations,
enabling more faithful and efficient reasoning. Experiments on real-world
datasets show that REFLEX outperforms previous methods that steer toward a
single truth direction and underscores the challenge traditional approaches
face when handling the subtle, human-unknown truth in fact-checking tasks.
Remarkably, with only 465 self-refined training samples, RELFEX achieves
state-of-the-art performance. Furthermore, models trained with explanatory
objectives can effectively guide those without them, yielding up to a 7.57%
improvement, highlighting that internal explanation signals play a dual role in
both interpreting and enhancing factual reasoning.
\\ ( https://arxiv.org/abs/2511.20233 ,  832kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20340
Date: Tue, 25 Nov 2025 14:20:08 GMT   (169kb)

Title: Scaling LLM Speculative Decoding: Non-Autoregressive Forecasting in
 Large-Batch Scenarios
Authors: Luohe Shi, Zuchao Li, Lefei Zhang, Baoyuan Qi, Guoming Liu, Hai Zhao
Categories: cs.CL
Comments: accepted by AAAI-2026
\\
 Speculative decoding accelerates LLM inference by utilizing otherwise idle
computational resources during memory-to-chip data transfer. Current
speculative decoding methods typically assume a considerable amount of
available computing power, then generate a complex and massive draft tree using
a small autoregressive language model to improve overall prediction accuracy.
However, methods like batching have been widely applied in mainstream model
inference systems as a superior alternative to speculative decoding, as they
compress the available idle computing power. Therefore, performing speculative
decoding with low verification resources and low scheduling costs has become an
important research problem. We believe that more capable models that allow for
parallel generation on draft sequences are what we truly need. Recognizing the
fundamental nature of draft models to only generate sequences of limited
length, we propose SpecFormer, a novel architecture that integrates
unidirectional and bidirectional attention mechanisms. SpecFormer combines the
autoregressive model's ability to extract information from the entire input
sequence with the parallel generation benefits of non-autoregressive models.
This design eliminates the reliance on large prefix trees and achieves
consistent acceleration, even in large-batch scenarios. Through lossless
speculative decoding experiments across models of various scales, we
demonstrate that SpecFormer sets a new standard for scaling LLM inference with
lower training demands and reduced computational costs.
\\ ( https://arxiv.org/abs/2511.20340 ,  169kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20344
Date: Tue, 25 Nov 2025 14:23:58 GMT   (4024kb)

Title: The Curious Case of Analogies: Investigating Analogical Reasoning in
 Large Language Models
Authors: Taewhoo Lee, Minju Song, Chanwoong Yoon, Jungwoo Park, Jaewoo Kang
Categories: cs.CL
Comments: AAAI 2026
\\
 Analogical reasoning is at the core of human cognition, serving as an
important foundation for a variety of intellectual activities. While prior work
has shown that LLMs can represent task patterns and surface-level concepts, it
remains unclear whether these models can encode high-level relational concepts
and apply them to novel situations through structured comparisons. In this
work, we explore this fundamental aspect using proportional and story
analogies, and identify three key findings. First, LLMs effectively encode the
underlying relationships between analogous entities; both attributive and
relational information propagate through mid-upper layers in correct cases,
whereas reasoning failures reflect missing relational information within these
layers. Second, unlike humans, LLMs often struggle not only when relational
information is missing, but also when attempting to apply it to new entities.
In such cases, strategically patching hidden representations at critical token
positions can facilitate information transfer to a certain extent. Lastly,
successful analogical reasoning in LLMs is marked by strong structural
alignment between analogous situations, whereas failures often reflect degraded
or misplaced alignment. Overall, our findings reveal that LLMs exhibit emerging
but limited capabilities in encoding and applying high-level relational
concepts, highlighting both parallels and gaps with human cognition.
\\ ( https://arxiv.org/abs/2511.20344 ,  4024kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20399
Date: Tue, 25 Nov 2025 15:26:47 GMT   (669kb)

Title: BengaliFig: A Low-Resource Challenge for Figurative and Culturally
 Grounded Reasoning in Bengali
Authors: Abdullah Al Sefat
Categories: cs.CL cs.AI
\\
 Large language models excel on broad multilingual benchmarks but remain to be
evaluated extensively in figurative and culturally grounded reasoning,
especially in low-resource contexts. We present BengaliFig, a compact yet
richly annotated challenge set that targets this gap in Bengali, a widely
spoken low-resourced language. The dataset contains 435 unique riddles drawn
from Bengali oral and literary traditions. Each item is annotated along five
orthogonal dimensions capturing reasoning type, trap type, cultural depth,
answer category, and difficulty, and is automatically converted to
multiple-choice format through a constraint-aware, AI-assisted pipeline. We
evaluate eight frontier LLMs from major providers under zero-shot and few-shot
chain-of-thought prompting, revealing consistent weaknesses in metaphorical and
culturally specific reasoning. BengaliFig thus contributes both a diagnostic
probe for evaluating LLM robustness in low-resource cultural contexts and a
step toward inclusive and heritage-aware NLP evaluation.
\\ ( https://arxiv.org/abs/2511.20399 ,  669kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20409
Date: Tue, 25 Nov 2025 15:35:42 GMT   (134kb)

Title: A Task-Oriented Evaluation Framework for Text Normalization in Modern
 NLP Pipelines
Authors: Md Abdullah Al Kafi, Raka Moni and Sumit Kumar Banshal
Categories: cs.CL
\\
 Text normalization is an essential preprocessing step in many natural
language processing (NLP) tasks, and stemming is one such normalization
technique that reduces words to their base or root form. However, evaluating
stemming methods is challenging because current evaluation approaches are
limited and do not capture the potential harm caused by excessive stemming;
therefore, it is essential to develop new approaches to evaluate stemming
methods. To address this issue, this study propose a novel, task-oriented
approach to evaluate stemming methods, which considers three aspects: (1) the
utility of stemming using Stemming Effectiveness Score (SES), (2) the impact of
stemming on downstream tasks using Model Performance Delta (MPD), and (3) the
semantic similarity between stemmed and original words using Average Normalized
Levenshtein Distance (ANLD), thus providing a comprehensive evaluation
framework. We apply our evaluation framework to compare two stemmers for Bangla
(BNLTK) and English (Snowball), and our results reveal a significant issue,
prompting us to analyze their performance in detail. While the Bangla stemmer
achieves the highest SES (1.67) due to effective word reduction (CR = 1.90),
SES alone is insufficient because our proposed safety measure, ANLD, reveals
that this high SES is due to harmful over-stemming (ANLD = 0.26), which
correlates with the observed decrease in downstream performance.In contrast,
the English stemmer achieves a moderate SES (1.31) with a safe meaning distance
(ANLD = 0.14), allowing its word reduction to contribute positively to
downstream performance; therefore, it is a more reliable stemmer. Our study
provides a valuable tool for distinguishing between potential efficiency gains
(high SES) and meaning preservation (low ANLD).
\\ ( https://arxiv.org/abs/2511.20409 ,  134kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20459
Date: Tue, 25 Nov 2025 16:25:44 GMT   (1980kb)

Title: Generation, Evaluation, and Explanation of Novelists' Styles with
 Single-Token Prompts
Authors: Mosab Rezaei, Mina Rajaei Moghadam, Abdul Rahman Shaikh, Hamed
 Alhoori, Reva Freedman
Categories: cs.CL cs.AI
\\
 Recent advances in large language models have created new opportunities for
stylometry, the study of writing styles and authorship. Two challenges,
however, remain central: training generative models when no paired data exist,
and evaluating stylistic text without relying only on human judgment. In this
work, we present a framework for both generating and evaluating sentences in
the style of 19th-century novelists. Large language models are fine-tuned with
minimal, single-token prompts to produce text in the voices of authors such as
Dickens, Austen, Twain, Alcott, and Melville. To assess these generative
models, we employ a transformer-based detector trained on authentic sentences,
using it both as a classifier and as a tool for stylistic explanation. We
complement this with syntactic comparisons and explainable AI methods,
including attention-based and gradient-based analyses, to identify the
linguistic cues that drive stylistic imitation. Our findings show that the
generated text reflects the authors' distinctive patterns and that AI-based
evaluation offers a reliable alternative to human assessment. All artifacts of
this work are published online.
\\ ( https://arxiv.org/abs/2511.20459 ,  1980kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20494
Date: Tue, 25 Nov 2025 17:00:31 GMT   (1142kb)

Title: Adversarial Confusion Attack: Disrupting Multimodal Large Language
 Models
Authors: Jakub Hoscilowicz, Artur Janicki
Categories: cs.CL
\\
 We introduce the Adversarial Confusion Attack, a new class of threats against
multimodal large language models (MLLMs). Unlike jailbreaks or targeted
misclassification, the goal is to induce systematic disruption that makes the
model generate incoherent or confidently incorrect outputs. Applications
include embedding adversarial images into websites to prevent MLLM-powered
agents from operating reliably. The proposed attack maximizes next-token
entropy using a small ensemble of open-source MLLMs. In the white-box setting,
we show that a single adversarial image can disrupt all models in the ensemble,
both in the full-image and adversarial CAPTCHA settings. Despite relying on a
basic adversarial technique (PGD), the attack generates perturbations that
transfer to both unseen open-source (e.g., Qwen3-VL) and proprietary (e.g.,
GPT-5.1) models.
\\ ( https://arxiv.org/abs/2511.20494 ,  1142kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20507
Date: Tue, 25 Nov 2025 17:16:38 GMT   (32kb)

Title: The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for
 Aphasia-Like Deficits in Language Models
Authors: Nathan Roll, Jill Kries, Flora Jin, Catherine Wang, Ann Marie Finley,
 Meghan Sumner, Cory Shain, Laura Gwilliams
Categories: cs.CL cs.AI
\\
 Large language models (LLMs) have emerged as a candidate "model organism" for
human language, offering an unprecedented opportunity to study the
computational basis of linguistic disorders like aphasia. However, traditional
clinical assessments are ill-suited for LLMs, as they presuppose human-like
pragmatic pressures and probe cognitive processes not inherent to artificial
architectures. We introduce the Text Aphasia Battery (TAB), a text-only
benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like
deficits in LLMs. The TAB comprises four subtests: Connected Text, Word
Comprehension, Sentence Comprehension, and Repetition. This paper details the
TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we
validate an automated evaluation protocol using Gemini 2.5 Flash, which
achieves reliability comparable to expert human raters (prevalence-weighted
Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human
agreement). We release TAB as a clinically-grounded, scalable framework for
analyzing language deficits in artificial systems.
\\ ( https://arxiv.org/abs/2511.20507 ,  32kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20534
Date: Tue, 25 Nov 2025 17:35:57 GMT   (69kb)

Title: Bridging the Language Gap: Synthetic Voice Diversity via Latent Mixup
 for Equitable Speech Recognition
Authors: Wesley Bian, Xiaofeng Lin, Guang Cheng
Categories: cs.CL
Comments: Accepted at ICML 2025 Workshop on Machine Learning for Audio
\\
 Modern machine learning models for audio tasks often exhibit superior
performance on English and other well-resourced languages, primarily due to the
abundance of available training data. This disparity leads to an unfair
performance gap for low-resource languages, where data collection is both
challenging and costly. In this work, we introduce a novel data augmentation
technique for speech corpora designed to mitigate this gap. Through
comprehensive experiments, we demonstrate that our method significantly
improves the performance of automatic speech recognition systems on
low-resource languages. Furthermore, we show that our approach outperforms
existing augmentation strategies, offering a practical solution for enhancing
speech technology in underrepresented linguistic communities.
\\ ( https://arxiv.org/abs/2511.20534 ,  69kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20547
Date: Tue, 25 Nov 2025 17:46:00 GMT   (2219kb)

Title: From Words to Wisdom: Discourse Annotation and Baseline Models for
 Student Dialogue Understanding
Authors: Farjana Sultana Mim, Shuchin Aeron, Eric Miller and Kristen Wendell
Categories: cs.CL
\\
 Identifying discourse features in student conversations is quite important
for educational researchers to recognize the curricular and pedagogical
variables that cause students to engage in constructing knowledge rather than
merely completing tasks. The manual analysis of student conversations to
identify these discourse features is time-consuming and labor-intensive, which
limits the scale and scope of studies. Leveraging natural language processing
(NLP) techniques can facilitate the automatic detection of these discourse
features, offering educational researchers scalable and data-driven insights.
However, existing studies in NLP that focus on discourse in dialogue rarely
address educational data. In this work, we address this gap by introducing an
annotated educational dialogue dataset of student conversations featuring
knowledge construction and task production discourse. We also establish
baseline models for automatically predicting these discourse properties for
each turn of talk within conversations, using pre-trained large language models
GPT-3.5 and Llama-3.1. Experimental results indicate that these
state-of-the-art models perform suboptimally on this task, indicating the
potential for future research.
\\ ( https://arxiv.org/abs/2511.20547 ,  2219kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20604
Date: Tue, 25 Nov 2025 18:33:24 GMT   (323kb)

Title: On Evaluating LLM Alignment by Evaluating LLMs as Judges
Authors: Yixin Liu, Pengfei Liu, Arman Cohan
Categories: cs.CL cs.AI cs.LG
Comments: NeurIPS 2025 Camera Ready
\\
 Alignment with human preferences is an important evaluation aspect of LLMs,
requiring them to be helpful, honest, safe, and to precisely follow human
instructions. Evaluating large language models' (LLMs) alignment typically
involves directly assessing their open-ended responses, requiring human
annotators or strong LLM judges. Conversely, LLMs themselves have also been
extensively evaluated as judges for assessing alignment. In this work, we
examine the relationship between LLMs' generation and evaluation capabilities
in aligning with human preferences. To this end, we first conduct a
comprehensive analysis of the generation-evaluation consistency
(GE-consistency) among various LLMs, revealing a strong correlation between
their generation and evaluation capabilities when evaluated by a strong LLM
preference oracle. Utilizing this finding, we propose a benchmarking paradigm
that measures LLM alignment with human preferences without directly evaluating
their generated outputs, instead assessing LLMs in their role as evaluators.
Our evaluation shows that our proposed benchmark, AlignEval, matches or
surpasses widely used automatic LLM evaluation benchmarks, such as AlpacaEval
and Arena-Hard, in capturing human preferences when ranking LLMs. Our study
offers valuable insights into the connection between LLMs' generation and
evaluation capabilities, and introduces a benchmark that assesses alignment
without directly evaluating model outputs.
\\ ( https://arxiv.org/abs/2511.20604 ,  323kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20639
Date: Tue, 25 Nov 2025 18:56:57 GMT   (2194kb)

Title: Latent Collaboration in Multi-Agent Systems
Authors: Jiaru Zou, Xiyuan Yang, Ruizhong Qiu, Gaotang Li, Katherine Tieu, Pan
 Lu, Ke Shen, Hanghang Tong, Yejin Choi, Jingrui He, James Zou, Mengdi Wang,
 Ling Yang
Categories: cs.CL cs.AI cs.LG
Comments: Project: https://github.com/Gen-Verse/LatentMAS
\\
 Multi-agent systems (MAS) extend large language models (LLMs) from
independent single-model reasoning to coordinative system-level intelligence.
While existing LLM agents depend on text-based mediation for reasoning and
communication, we take a step forward by enabling models to collaborate
directly within the continuous latent space. We introduce LatentMAS, an
end-to-end training-free framework that enables pure latent collaboration among
LLM agents. In LatentMAS, each agent first performs auto-regressive latent
thoughts generation through last-layer hidden embeddings. A shared latent
working memory then preserves and transfers each agent's internal
representations, ensuring lossless information exchange. We provide theoretical
analyses establishing that LatentMAS attains higher expressiveness and lossless
information preservation with substantially lower complexity than vanilla
text-based MAS. In addition, empirical evaluations across 9 comprehensive
benchmarks spanning math and science reasoning, commonsense understanding, and
code generation show that LatentMAS consistently outperforms strong
single-model and text-based MAS baselines, achieving up to 14.6% higher
accuracy, reducing output token usage by 70.8%-83.7%, and providing 4x-4.3x
faster end-to-end inference. These results demonstrate that our new latent
collaboration framework enhances system-level reasoning quality while offering
substantial efficiency gains without any additional training. Code and data are
fully open-sourced at https://github.com/Gen-Verse/LatentMAS.
\\ ( https://arxiv.org/abs/2511.20639 ,  2194kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19448
Date: Tue, 18 Nov 2025 12:30:15 GMT   (3142kb)

Title: PuzzlePoles: Cylindrical Fiducial Markers Based on the PuzzleBoard
 Pattern
Authors: Juri Zach, Peer Stelldinger
Categories: cs.CV
\\
 Reliable perception of the environment is a key enabler for autonomous
systems, where calibration and localization tasks often rely on robust visual
markers. We introduce the PuzzlePole, a new type of fiducial markers derived
from the recently proposed PuzzleBoard calibration pattern. The PuzzlePole is a
cylindrical marker, enabling reliable recognition and pose estimation from
360{\deg} viewing direction. By leveraging the unique combinatorial structure
of the PuzzleBoard pattern, PuzzlePoles provide a high accuracy in localization
and orientation while being robust to occlusions. The design offers flexibility
for deployment in diverse autonomous systems scenarios, ranging from robot
navigation and SLAM to tangible interfaces.
\\ ( https://arxiv.org/abs/2511.19448 ,  3142kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19458
Date: Fri, 21 Nov 2025 12:04:24 GMT   (8397kb)

Title: Personalized Reward Modeling for Text-to-Image Generation
Authors: Jeongeun Lee, Ryang Heo, Dongha Lee
Categories: cs.CV cs.AI
\\
 Recent text-to-image (T2I) models generate semantically coherent images from
textual prompts, yet evaluating how well they align with individual user
preferences remains an open challenge. Conventional evaluation methods, general
reward functions or similarity-based metrics, fail to capture the diversity and
complexity of personal visual tastes. In this work, we present PIGReward, a
personalized reward model that dynamically generates user-conditioned
evaluation dimensions and assesses images through CoT reasoning. To address the
scarcity of user data, PIGReward adopt a self-bootstrapping strategy that
reasons over limited reference data to construct rich user contexts, enabling
personalization without user-specific training. Beyond evaluation, PIGReward
provides personalized feedback that drives user-specific prompt optimization,
improving alignment between generated images and individual intent. We further
introduce PIGBench, a per-user preference benchmark capturing diverse visual
interpretations of shared prompts. Extensive experiments demonstrate that
PIGReward surpasses existing methods in both accuracy and interpretability,
establishing a scalable and reasoning-based foundation for personalized T2I
evaluation and optimization. Taken together, our findings highlight PIGReward
as a robust steptoward individually aligned T2I generation.
\\ ( https://arxiv.org/abs/2511.19458 ,  8397kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19466
Date: Fri, 21 Nov 2025 19:58:54 GMT   (977kb)

Title: SG-OIF: A Stability-Guided Online Influence Framework for Reliable
 Vision Data
Authors: Penghao Rao, Runmin Jiang, Min Xu
Categories: cs.CV cs.AI cs.LG
\\
 Approximating training-point influence on test predictions is critical for
deploying deep-learning vision models, essential for locating noisy data.
Though the influence function was proposed for attributing how infinitesimal
up-weighting or removal of individual training examples affects model outputs,
its implementation is still challenging in deep-learning vision models:
inverse-curvature computations are expensive, and training non-stationarity
invalidates static approximations. Prior works use iterative solvers and
low-rank surrogates to reduce cost, but offline computation lags behind
training dynamics, and missing confidence calibration yields fragile rankings
that misidentify critical examples. To address these challenges, we introduce a
Stability-Guided Online Influence Framework (SG-OIF), the first framework that
treats algorithmic stability as a real-time controller, which (i) maintains
lightweight anchor IHVPs via stochastic Richardson and preconditioned Neumann;
(ii) proposes modular curvature backends to modulate per-example influence
scores using stability-guided residual thresholds, anomaly gating, and
confidence. Experimental results show that SG-OIF achieves SOTA
(State-Of-The-Art) on noise-label and out-of-distribution detection tasks
across multiple datasets with various corruption. Notably, our approach
achieves 91.1\% accuracy in the top 1\% prediction samples on the CIFAR-10
(20\% asym), and gets 99.8\% AUPR score on MNIST, effectively demonstrating
that this framework is a practical controller for online influence estimation.
\\ ( https://arxiv.org/abs/2511.19466 ,  977kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19474
Date: Sat, 22 Nov 2025 07:37:21 GMT   (6343kb)

Title: Pistachio: Towards Synthetic, Balanced, and Long-Form Video Anomaly
 Benchmarks
Authors: Jie Li, Hongyi Cai, Mingkang Dong, Muxin Pu, Shan You, Fei Wang, Tao
 Huang
Categories: cs.CV cs.AI cs.MM
\\
 Automatically detecting abnormal events in videos is crucial for modern
autonomous systems, yet existing Video Anomaly Detection (VAD) benchmarks lack
the scene diversity, balanced anomaly coverage, and temporal complexity needed
to reliably assess real-world performance. Meanwhile, the community is
increasingly moving toward Video Anomaly Understanding (VAU), which requires
deeper semantic and causal reasoning but remains difficult to benchmark due to
the heavy manual annotation effort it demands. In this paper, we introduce
Pistachio, a new VAD/VAU benchmark constructed entirely through a controlled,
generation-based pipeline. By leveraging recent advances in video generation
models, Pistachio provides precise control over scenes, anomaly types, and
temporal narratives, effectively eliminating the biases and limitations of
Internet-collected datasets. Our pipeline integrates scene-conditioned anomaly
assignment, multi-step storyline generation, and a temporally consistent
long-form synthesis strategy that produces coherent 41-second videos with
minimal human intervention. Extensive experiments demonstrate the scale,
diversity, and complexity of Pistachio, revealing new challenges for existing
methods and motivating future research on dynamic and multi-event anomaly
understanding.
\\ ( https://arxiv.org/abs/2511.19474 ,  6343kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19475
Date: Sat, 22 Nov 2025 09:09:22 GMT   (22641kb)

Title: Tracking and Segmenting Anything in Any Modality
Authors: Tianlu Zhang, Qiang Zhang, Guiguang Ding, Jungong Han
Categories: cs.CV cs.AI cs.MM
Comments: Accpetd by AAAI 2026
\\
 Tracking and segmentation play essential roles in video understanding,
providing basic positional information and temporal association of objects
within video sequences. Despite their shared objective, existing approaches
often tackle these tasks using specialized architectures or modality-specific
parameters, limiting their generalization and scalability. Recent efforts have
attempted to unify multiple tracking and segmentation subtasks from the
perspectives of any modality input or multi-task inference. However, these
approaches tend to overlook two critical challenges: the distributional gap
across different modalities and the feature representation gap across tasks.
These issues hinder effective cross-task and cross-modal knowledge sharing,
ultimately constraining the development of a true generalist model. To address
these limitations, we propose a universal tracking and segmentation framework
named SATA, which unifies a broad spectrum of tracking and segmentation
subtasks with any modality input. Specifically, a Decoupled Mixture-of-Expert
(DeMoE) mechanism is presented to decouple the unified representation learning
task into the modeling process of cross-modal shared knowledge and specific
information, thus enabling the model to maintain flexibility while enhancing
generalization. Additionally, we introduce a Task-aware Multi-object Tracking
(TaMOT) pipeline to unify all the task outputs as a unified set of instances
with calibrated ID information, thereby alleviating the degradation of
task-specific knowledge during multi-task training. SATA demonstrates superior
performance on 18 challenging tracking and segmentation benchmarks, offering a
novel perspective for more generalizable video understanding.
\\ ( https://arxiv.org/abs/2511.19475 ,  22641kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19511
Date: Mon, 24 Nov 2025 02:22:21 GMT   (5986kb)

Title: The Determinant Ratio Matrix Approach to Solving 3D Matching and 2D
 Orthographic Projection Alignment Tasks
Authors: Andrew J. Hanson and Sonya M. Hanson
Categories: cs.CV eess.IV
Comments: 12 pages of main text, 3 figures, 31 pages total (including
 references and 2 appendices, one with algorithm-defining source code)
MSC-class: 68U10
ACM-class: I.4.4; I.4.8
\\
 Pose estimation is a general problem in computer vision with wide
applications. The relative orientation of a 3D reference object can be
determined from a 3D rotated version of that object, or from a projection of
the rotated object to a 2D planar image. This projection can be a perspective
projection (the PnP problem) or an orthographic projection (the OnP problem).
We restrict our attention here to the OnP problem and the full 3D pose
estimation task (the EnP problem). Here we solve the least squares systems for
both the error-free EnP and OnP problems in terms of the determinant ratio
matrix (DRaM) approach. The noisy-data case can be addressed with a
straightforward rotation correction scheme. While the SVD and optimal
quaternion eigensystem methods solve the noisy EnP 3D-3D alignment exactly, the
noisy 3D-2D orthographic (OnP) task has no known comparable closed form, and
can be solved by DRaM-class methods. We note that while previous similar work
has been presented in the literature exploiting both the QR decomposition and
the Moore-Penrose pseudoinverse transformations, here we place these methods in
a larger context that has not previously been fully recognized in the absence
of the corresponding DRaM solution. We term this class of solutions as the DRaM
family, and conduct comparisons of the behavior of the families of solutions
for the EnP and OnP rotation estimation problems. Overall, this work presents
both a new solution to the 3D and 2D orthographic pose estimation problems and
provides valuable insight into these classes of problems. With hindsight, we
are able to show that our DRaM solutions to the exact EnP and OnP problems
possess derivations that could have been discovered in the time of Gauss, and
in fact generalize to all analogous N-dimensional Euclidean pose estimation
problems.
\\ ( https://arxiv.org/abs/2511.19511 ,  5986kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19512
Date: Mon, 24 Nov 2025 02:31:04 GMT   (18553kb)

Title: Single Image to High-Quality 3D Object via Latent Features
Authors: Huanning Dong, Yinuo Huang, Fan Li, Ping Kuang
Categories: cs.CV
\\
 3D assets are essential in the digital age. While automatic 3D generation,
such as image-to-3d, has made significant strides in recent years, it often
struggles to achieve fast, detailed, and high-fidelity generation
simultaneously. In this work, we introduce LatentDreamer, a novel framework for
generating 3D objects from single images. The key to our approach is a
pre-trained variational autoencoder that maps 3D geometries to latent features,
which greatly reducing the difficulty of 3D generation. Starting from latent
features, the pipeline of LatentDreamer generates coarse geometries, refined
geometries, and realistic textures sequentially. The 3D objects generated by
LatentDreamer exhibit high fidelity to the input images, and the entire
generation process can be completed within a short time (typically in 70
seconds). Extensive experiments show that with only a small amount of training,
LatentDreamer demonstrates competitive performance compared to contemporary
approachs.
\\ ( https://arxiv.org/abs/2511.19512 ,  18553kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19515
Date: Mon, 24 Nov 2025 03:10:12 GMT   (3420kb)

Title: Fewer Tokens, Greater Scaling: Self-Adaptive Visual Bases for Efficient
 and Expansive Representation Learning
Authors: Shawn Young, Xingyu Zeng, Lijian Xu
Categories: cs.CV
\\
 This paper investigates the fundamental relationship between model capacity
and the minimal number of visual tokens required to preserve image semantics.
Inspired by the Minimum Description Length principle, we reinterpret image
tokens as vectors in a visual semantic space and define the intrinsic semantic
complexity of an image as the smallest set of basis vectors needed to span this
space. Building on this perspective, we propose Orthogonal Filtering, a
lightweight module that adaptively clusters redundant tokens into a compact set
of orthogonal bases. Through extensive experiments across a range of ViT
models, we reveal a consistent token, model scaling law: larger models require
significantly fewer tokens to span visual semantic space. Besides, we also
contribute a visual long-context dataset.
\\ ( https://arxiv.org/abs/2511.19515 ,  3420kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19516
Date: Mon, 24 Nov 2025 03:11:08 GMT   (19920kb)

Title: Connecting the Dots: Training-Free Visual Grounding via Agentic
 Reasoning
Authors: Liqin Luo, Guangyao Chen, Xiawu Zheng, Yongxing Dai, Yixiong Zou,
 Yonghong Tian
Categories: cs.CV
Comments: AAAI 2025
\\
 Visual grounding, the task of linking textual queries to specific regions
within images, plays a pivotal role in vision-language integration. Existing
methods typically rely on extensive task-specific annotations and fine-tuning,
limiting their ability to generalize effectively to novel or
out-of-distribution scenarios. To address these limitations, we introduce
GroundingAgent, a novel agentic visual grounding framework that operates
without any task-specific fine-tuning. GroundingAgent employs a structured,
iterative reasoning mechanism that integrates pretrained open-vocabulary object
detectors, multimodal large language models (MLLMs), and large language models
(LLMs) to progressively refine candidate regions through joint semantic and
spatial analyses. Remarkably, GroundingAgent achieves an average zero-shot
grounding accuracy of 65.1 % on widely-used benchmarks (RefCOCO, RefCOCO+,
RefCOCOg), entirely without fine-tuning. Furthermore, by substituting
MLLM-generated captions with the original query texts, the accuracy at the
selection stage alone reaches approximately 90 %, closely matching supervised
performance and underscoring the critical role of LLM reasoning capabilities.
GroundingAgent also offers strong interpretability, transparently illustrating
each reasoning step and providing clear insights into its decision-making
process.
\\ ( https://arxiv.org/abs/2511.19516 ,  19920kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19518
Date: Mon, 24 Nov 2025 03:37:14 GMT   (3582kb)

Title: Towards Efficient VLMs: Information-Theoretic Driven Compression via
 Adaptive Structural Pruning
Authors: Zhaoqi Xu, Yingying Zhang, Jian Li, Jianwei Guo, Qiannan Zhu, Hua
 Huang
Categories: cs.CV cs.AI cs.IT cs.LG math.IT
\\
 Recent advances in vision-language models (VLMs) have shown remarkable
performance across multimodal tasks, yet their ever-growing scale poses severe
challenges for deployment and efficiency. Existing compression methods often
rely on heuristic importance metrics or empirical pruning rules, lacking
theoretical guarantees about information preservation. In this work, we propose
InfoPrune, an information-theoretic framework for adaptive structural
compression of VLMs. Grounded in the Information Bottleneck principle, we
formulate pruning as a trade-off between retaining task-relevant semantics and
discarding redundant dependencies. To quantify the contribution of each
attention head, we introduce an entropy-based effective rank (eRank) and employ
the Kolmogorov--Smirnov (KS) distance to measure the divergence between
original and compressed structures. This yields a unified criterion that
jointly considers structural sparsity and informational efficiency. Building on
this foundation, we further design two complementary schemes: (1) a
training-based head pruning guided by the proposed information loss objective,
and (2) a training-free FFN compression via adaptive low-rank approximation.
Extensive experiments on VQAv2, TextVQA, and GQA demonstrate that InfoPrune
achieves up to 3.2x FLOP reduction and 1.8x acceleration with negligible
performance degradation, establishing a theoretically grounded and practically
effective step toward efficient multimodal large models.
\\ ( https://arxiv.org/abs/2511.19518 ,  3582kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19519
Date: Mon, 24 Nov 2025 04:26:42 GMT   (1623kb)

Title: Blinking Beyond EAR: A Stable Eyelid Angle Metric for Driver Drowsiness
 Detection and Data Augmentation
Authors: Mathis Wolter, Julie Stephany Berrio Perez, Mao Shan
Categories: cs.CV cs.LG eess.IV
Comments: 8 pages, 5 figures, 3 tables
\\
 Detecting driver drowsiness reliably is crucial for enhancing road safety and
supporting advanced driver assistance systems (ADAS). We introduce the Eyelid
Angle (ELA), a novel, reproducible metric of eye openness derived from 3D
facial landmarks. Unlike conventional binary eye state estimators or 2D
measures, such as the Eye Aspect Ratio (EAR), the ELA provides a stable
geometric description of eyelid motion that is robust to variations in camera
angle. Using the ELA, we design a blink detection framework that extracts
temporal characteristics, including the closing, closed, and reopening
durations, which are shown to correlate with drowsiness levels. To address the
scarcity and risk of collecting natural drowsiness data, we further leverage
ELA signals to animate rigged avatars in Blender 3D, enabling the creation of
realistic synthetic datasets with controllable noise, camera viewpoints, and
blink dynamics. Experimental results in public driver monitoring datasets
demonstrate that the ELA offers lower variance under viewpoint changes compared
to EAR and achieves accurate blink detection. At the same time, synthetic
augmentation expands the diversity of training data for drowsiness recognition.
Our findings highlight the ELA as both a reliable biometric measure and a
powerful tool for generating scalable datasets in driver state monitoring.
\\ ( https://arxiv.org/abs/2511.19519 ,  1623kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19524
Date: Mon, 24 Nov 2025 07:04:51 GMT   (7548kb)

Title: VideoChat-M1: Collaborative Policy Planning for Video Understanding via
 Multi-Agent Reinforcement Learning
Authors: Boyu Chen, Zikang Wang, Zhengrong Yue, Kainan Yan, Chenyun Yu, Yi
 Huang, Zijun Liu, Yafei Wen, Xiaoxin Chen, Yang Liu, Peng Li, Yali Wang
Categories: cs.CV cs.MA
Comments: 21 pages, 9 figures
\\
 By leveraging tool-augmented Multimodal Large Language Models (MLLMs),
multi-agent frameworks are driving progress in video understanding. However,
most of them adopt static and non-learnable tool invocation mechanisms, which
limit the discovery of diverse clues essential for robust perception and
reasoning regarding temporally or spatially complex videos. To address this
challenge, we propose a novel Multi-agent system for video understanding,
namely VideoChat-M1. Instead of using a single or fixed policy, VideoChat-M1
adopts a distinct Collaborative Policy Planning (CPP) paradigm with multiple
policy agents, which comprises three key processes. (1) Policy Generation: Each
agent generates its unique tool invocation policy tailored to the user's query;
(2) Policy Execution: Each agent sequentially invokes relevant tools to execute
its policy and explore the video content; (3) Policy Communication: During the
intermediate stages of policy execution, agents interact with one another to
update their respective policies. Through this collaborative framework, all
agents work in tandem, dynamically refining their preferred policies based on
contextual insights from peers to effectively respond to the user's query.
Moreover, we equip our CPP paradigm with a concise Multi-Agent Reinforcement
Learning (MARL) method. Consequently, the team of policy agents can be jointly
optimized to enhance VideoChat-M1's performance, guided by both the final
answer reward and intermediate collaborative process feedback. Extensive
experiments demonstrate that VideoChat-M1 achieves SOTA performance across
eight benchmarks spanning four tasks. Notably, on LongVideoBench, our method
outperforms the SOTA model Gemini 2.5 pro by 3.6% and GPT-4o by 15.6%.
\\ ( https://arxiv.org/abs/2511.19524 ,  7548kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19526
Date: Mon, 24 Nov 2025 07:13:21 GMT   (2568kb)

Title: Perceptual Taxonomy: Evaluating and Guiding Hierarchical Scene Reasoning
 in Vision-Language Models
Authors: Jonathan Lee, Xingrui Wang, Jiawei Peng, Luoxin Ye, Zehan Zheng,
 Tiezheng Zhang, Tao Wang, Wufei Ma, Siyi Chen, Yu-Cheng Chou, Prakhar
 Kaushik, Alan Yuille
Categories: cs.CV
\\
 We propose Perceptual Taxonomy, a structured process of scene understanding
that first recognizes objects and their spatial configurations, then infers
task-relevant properties such as material, affordance, function, and physical
attributes to support goal-directed reasoning. While this form of reasoning is
fundamental to human cognition, current vision-language benchmarks lack
comprehensive evaluation of this ability and instead focus on surface-level
recognition or image-text alignment.
 To address this gap, we introduce Perceptual Taxonomy, a benchmark for
physically grounded visual reasoning. We annotate 3173 objects with four
property families covering 84 fine-grained attributes. Using these annotations,
we construct a multiple-choice question benchmark with 5802 images across both
synthetic and real domains. The benchmark contains 28033 template-based
questions spanning four types (object description, spatial reasoning, property
matching, and taxonomy reasoning), along with 50 expert-crafted questions
designed to evaluate models across the full spectrum of perceptual taxonomy
reasoning.
 Experimental results show that leading vision-language models perform well on
recognition tasks but degrade by 10 to 20 percent on property-driven questions,
especially those requiring multi-step reasoning over structured attributes.
These findings highlight a persistent gap in structured visual understanding
and the limitations of current models that rely heavily on pattern matching. We
also show that providing in-context reasoning examples from simulated scenes
improves performance on real-world and expert-curated questions, demonstrating
the effectiveness of perceptual-taxonomy-guided prompting.
\\ ( https://arxiv.org/abs/2511.19526 ,  2568kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19527
Date: Mon, 24 Nov 2025 07:23:10 GMT   (2026kb)

Title: MapRF: Weakly Supervised Online HD Map Construction via NeRF-Guided
 Self-Training
Authors: Hongyu Lyu, Thomas Monninger, Julie Stephany Berrio Perez, Mao Shan,
 Zhenxing Ming, Stewart Worrall
Categories: cs.CV
\\
 Autonomous driving systems benefit from high-definition (HD) maps that
provide critical information about road infrastructure. The online construction
of HD maps offers a scalable approach to generate local maps from on-board
sensors. However, existing methods typically rely on costly 3D map annotations
for training, which limits their generalization and scalability across diverse
driving environments. In this work, we propose MapRF, a weakly supervised
framework that learns to construct 3D maps using only 2D image labels. To
generate high-quality pseudo labels, we introduce a novel Neural Radiance
Fields (NeRF) module conditioned on map predictions, which reconstructs
view-consistent 3D geometry and semantics. These pseudo labels are then
iteratively used to refine the map network in a self-training manner, enabling
progressive improvement without additional supervision. Furthermore, to
mitigate error accumulation during self-training, we propose a Map-to-Ray
Matching strategy that aligns map predictions with camera rays derived from 2D
labels. Extensive experiments on the Argoverse 2 and nuScenes datasets
demonstrate that MapRF achieves performance comparable to fully supervised
methods, attaining around 75% of the baseline while surpassing several
approaches using only 2D labels. This highlights the potential of MapRF to
enable scalable and cost-effective online HD map construction for autonomous
driving.
\\ ( https://arxiv.org/abs/2511.19527 ,  2026kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19529
Date: Mon, 24 Nov 2025 07:58:29 GMT   (6931kb)

Title: Vidi2: Large Multimodal Models for Video Understanding and Creation
Authors: Vidi Team, Celong Liu, Chia-Wen Kuo, Chuang Huang, Dawei Du, Fan Chen,
 Guang Chen, Haoji Zhang, Haojun Zhao, Lingxi Zhang, Lu Guo, Lusha Li, Longyin
 Wen, Qihang Fan, Qingyu Chen, Rachel Deng, Sijie Zhu, Stuart Siew, Tong Jin,
 Weiyan Tao, Wen Zhong, Xiaohui Shen, Xin Gu, Zhenfang Chen, Zuhua Lin
Categories: cs.CV
\\
 Video has emerged as the primary medium for communication and creativity on
the Internet, driving strong demand for scalable, high-quality video
production. Vidi models continue to evolve toward next-generation video
creation and have achieved state-of-the-art performance in multimodal temporal
retrieval (TR). In its second release, Vidi2 advances video understanding with
fine-grained spatio-temporal grounding (STG) and extends its capability to
video question answering (Video QA), enabling comprehensive multimodal
reasoning. Given a text query, Vidi2 can identify not only the corresponding
timestamps but also the bounding boxes of target objects within the output time
ranges. This end-to-end spatio-temporal grounding capability enables potential
applications in complex editing scenarios, such as plot or character
understanding, automatic multi-view switching, and intelligent,
composition-aware reframing and cropping. To enable comprehensive evaluation of
STG in practical settings, we introduce a new benchmark, VUE-STG, which offers
four key improvements over existing STG datasets: 1) Video duration: spans from
roughly 10s to 30 mins, enabling long-context reasoning; 2) Query format:
queries are mostly converted into noun phrases while preserving sentence-level
expressiveness; 3) Annotation quality: all ground-truth time ranges and
bounding boxes are manually annotated with high accuracy; 4) Evaluation metric:
a refined vIoU/tIoU/vIoU-Intersection scheme. In addition, we upgrade the
previous VUE-TR benchmark to VUE-TR-V2, achieving a more balanced video-length
distribution and more user-style queries. Remarkably, the Vidi2 model
substantially outperforms leading proprietary systems, such as Gemini 3 Pro
(Preview) and GPT-5, on both VUE-TR-V2 and VUE-STG, while achieving competitive
results with popular open-source models with similar scale on video QA
benchmarks.
\\ ( https://arxiv.org/abs/2511.19529 ,  6931kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19537
Date: Mon, 24 Nov 2025 10:26:30 GMT   (4662kb)

Title: Cross-Domain Generalization of Multimodal LLMs for Global Photovoltaic
 Assessment
Authors: Muhao Guo, Yang Weng
Categories: cs.CV cs.AI cs.LG eess.IV
Comments: 5 pages, 7 figures
\\
 The rapid expansion of distributed photovoltaic (PV) systems poses challenges
for power grid management, as many installations remain undocumented. While
satellite imagery provides global coverage, traditional computer vision (CV)
models such as CNNs and U-Nets require extensive labeled data and fail to
generalize across regions. This study investigates the cross-domain
generalization of a multimodal large language model (LLM) for global PV
assessment. By leveraging structured prompts and fine-tuning, the model
integrates detection, localization, and quantification within a unified schema.
Cross-regional evaluation using the $\Delta$F1 metric demonstrates that the
proposed model achieves the smallest performance degradation across unseen
regions, outperforming conventional CV and transformer baselines. These results
highlight the robustness of multimodal LLMs under domain shift and their
potential for scalable, transferable, and interpretable global PV mapping.
\\ ( https://arxiv.org/abs/2511.19537 ,  4662kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19538
Date: Mon, 24 Nov 2025 10:35:37 GMT   (153992kb)

Title: Studying Maps at Scale: A Digital Investigation of Cartography and the
 Evolution of Figuration
Authors: Remi Petitpierre
Categories: cs.CV cs.CL cs.DL
Comments: PhD thesis, EPFL. 396 pages, 156 figures
ACM-class: H.3.7; I.4.6; I.4.10; I.5.3; J.5
DOI: 10.5075/epfl-thesis-11559
\\
 This thesis presents methods and datasets to investigate cartographic
heritage on a large scale and from a cultural perspective. Heritage
institutions worldwide have digitized more than one million maps, and automated
techniques now enable large-scale recognition and extraction of map content.
Yet these methods have engaged little with the history of cartography, or the
view that maps are semantic-symbolic systems, and cultural objects reflecting
political and epistemic expectations. This work leverages a diverse corpus of
771,561 map records and 99,715 digitized images aggregated from 38 digital
catalogs. After normalization, the dataset includes 236,925 contributors and
spans six centuries, from 1492 to 1948. These data make it possible to chart
geographic structures and the global chronology of map publication. The spatial
focus of cartography is analyzed in relation to political dynamics, evidencing
links between Atlantic maritime charting, the triangular trade, and colonial
expansion. Further results document the progression of national, domestic focus
and the impact of military conflicts on publication volumes. The research
introduces semantic segmentation techniques and object detection models for the
generic recognition of land classes and cartographic signs, trained on
annotated data and synthetic images. The analysis of land classes shows that
maps are designed images whose framing and composition emphasize features
through centering and semantic symmetries. The study of cartographic figuration
encodes 63 M signs and 25 M fragments into a latent visual space, revealing
figurative shifts such as the replacement of relief hachures by terrain
contours and showing that signs tend to form locally consistent systems.
Analyses of collaboration and diffusion highlight the role of legitimacy,
larger actors, and major cities in the spread of figurative norms and semiotic
cultures.
\\ ( https://arxiv.org/abs/2511.19538 ,  153992kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19542
Date: Mon, 24 Nov 2025 10:59:31 GMT   (24886kb)

Title: Proxy-Free Gaussian Splats Deformation with Splat-Based Surface
 Estimation
Authors: Jaeyeong Kim, Seungwoo Yoo, Minhyuk Sung
Categories: cs.CV
Comments: 17 pages, Accepted to 3DV 2026 (IEEE/CVF International Conference on
 3D Vision)
\\
 We introduce SpLap, a proxy-free deformation method for Gaussian splats (GS)
based on a Laplacian operator computed from our novel surface-aware splat
graph. Existing approaches to GS deformation typically rely on deformation
proxies such as cages or meshes, but they suffer from dependency on proxy
quality and additional computational overhead. An alternative is to directly
apply Laplacian-based deformation techniques by treating splats as point
clouds. However, this often fail to properly capture surface information due to
lack of explicit structure. To address this, we propose a novel method that
constructs a surface-aware splat graph, enabling the Laplacian operator derived
from it to support more plausible deformations that preserve details and
topology. Our key idea is to leverage the spatial arrangement encoded in
splats, defining neighboring splats not merely by the distance between their
centers, but by their intersections. Furthermore, we introduce a Gaussian
kernel adaptation technique that preserves surface structure under deformation,
thereby improving rendering quality after deformation. In our experiments, we
demonstrate the superior performance of our method compared to both proxy-based
and proxy-free baselines, evaluated on 50 challenging objects from the
ShapeNet, Objaverse, and Sketchfab datasets, as well as the NeRF-Synthetic
dataset. Code is available at https://github.com/kjae0/SpLap.
\\ ( https://arxiv.org/abs/2511.19542 ,  24886kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19557
Date: Mon, 24 Nov 2025 14:32:07 GMT   (3670kb)

Title: Think First, Assign Next (ThiFAN-VQA): A Two-stage Chain-of-Thought
 Framework for Post-Disaster Damage Assessment
Authors: Ehsan Karimi, Nhut Le, Maryam Rahnemoonfar
Categories: cs.CV cs.AI cs.LG
\\
 Timely and accurate assessment of damages following natural disasters is
essential for effective emergency response and recovery. Recent AI-based
frameworks have been developed to analyze large volumes of aerial imagery
collected by Unmanned Aerial Vehicles, providing actionable insights rapidly.
However, creating and annotating data for training these models is costly and
time-consuming, resulting in datasets that are limited in size and diversity.
Furthermore, most existing approaches rely on traditional classification-based
frameworks with fixed answer spaces, restricting their ability to provide new
information without additional data collection or model retraining. Using
pre-trained generative models built on in-context learning (ICL) allows for
flexible and open-ended answer spaces. However, these models often generate
hallucinated outputs or produce generic responses that lack domain-specific
relevance. To address these limitations, we propose ThiFAN-VQA, a two-stage
reasoning-based framework for visual question answering (VQA) in disaster
scenarios. ThiFAN-VQA first generates structured reasoning traces using
chain-of-thought (CoT) prompting and ICL to enable interpretable reasoning
under limited supervision. A subsequent answer selection module evaluates the
generated responses and assigns the most coherent and contextually accurate
answer, effectively improve the model performance. By integrating a custom
information retrieval system, domain-specific prompting, and reasoning-guided
answer selection, ThiFAN-VQA bridges the gap between zero-shot and supervised
methods, combining flexibility with consistency. Experiments on FloodNet and
RescueNet-VQA, UAV-based datasets from flood- and hurricane-affected regions,
demonstrate that ThiFAN-VQA achieves superior accuracy, interpretability, and
adaptability for real-world post-disaster damage assessment tasks.
\\ ( https://arxiv.org/abs/2511.19557 ,  3670kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19575
Date: Mon, 24 Nov 2025 17:59:59 GMT   (31568kb)

Title: HunyuanOCR Technical Report
Authors: Hunyuan Vision Team, Pengyuan Lyu, Xingyu Wan, Gengluo Li, Shangpin
 Peng, Weinong Wang, Liang Wu, Huawen Shen, Yu Zhou, Canhui Tang, Qi Yang,
 Qiming Peng, Bin Luo, Hower Yang, Houwen Peng, Hongming Yang, Senhao Xie,
 Binghong Wu, Mana Yang, Sergey Wang, Raccoon Liu, Dick Zhu, Jie Jiang, Linus,
 Han Hu, Chengquan Zhang
Categories: cs.CV cs.AI
\\
 This paper presents HunyuanOCR, a commercial-grade, open-source, and
lightweight (1B parameters) Vision-Language Model (VLM) dedicated to OCR tasks.
The architecture comprises a Native Vision Transformer (ViT) and a lightweight
LLM connected via an MLP adapter. HunyuanOCR demonstrates superior performance,
outperforming commercial APIs, traditional pipelines, and larger models (e.g.,
Qwen3-VL-4B). Specifically, it surpasses current public solutions in perception
tasks (Text Spotting, Parsing) and excels in semantic tasks (IE, Text Image
Translation), securing first place in the ICDAR 2025 DIMT Challenge (Small
Model Track). Furthermore, it achieves state-of-the-art (SOTA) results on
OCRBench among VLMs with fewer than 3B parameters.
 HunyuanOCR achieves breakthroughs in three key aspects: 1) Unifying
Versatility and Efficiency: We implement comprehensive support for core
capabilities including spotting, parsing, IE, VQA, and translation within a
lightweight framework. This addresses the limitations of narrow "OCR expert
models" and inefficient "General VLMs". 2) Streamlined End-to-End Architecture:
Adopting a pure end-to-end paradigm eliminates dependencies on pre-processing
modules (e.g., layout analysis). This fundamentally resolves error propagation
common in traditional pipelines and simplifies system deployment. 3)
Data-Driven and RL Strategies: We confirm the critical role of high-quality
data and, for the first time in the industry, demonstrate that Reinforcement
Learning (RL) strategies yield significant performance gains in OCR tasks.
 HunyuanOCR is officially open-sourced on HuggingFace. We also provide a
high-performance deployment solution based on vLLM, placing its production
efficiency in the top tier. We hope this model will advance frontier research
and provide a solid foundation for industrial applications.
\\ ( https://arxiv.org/abs/2511.19575 ,  31568kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19576
Date: Mon, 24 Nov 2025 18:14:53 GMT   (469kb)

Title: Leveraging Unlabeled Scans for NCCT Image Segmentation in Early Stroke
 Diagnosis: A Semi-Supervised GAN Approach
Authors: Maria Thoma, Michalis A. Savelonas and Dimitris K. Iakovidis
Categories: cs.CV
Journal-ref: Proc. IEEE Int. Conf. BioInformatics and BioEngineering (BIBE),
 Athens, Greece, 2025
DOI: 10.1109/BIBE66822.2025.0007
\\
 Ischemic stroke is a time-critical medical emergency where rapid diagnosis is
essential for improving patient outcomes. Non-contrast computed tomography
(NCCT) serves as the frontline imaging tool, yet it often fails to reveal the
subtle ischemic changes present in the early, hyperacute phase. This limitation
can delay crucial interventions. To address this diagnostic challenge, we
introduce a semi-supervised segmentation method using generative adversarial
networks (GANs) to accurately delineate early ischemic stroke regions. The
proposed method employs an adversarial framework to effectively learn from a
limited number of annotated NCCT scans, while simultaneously leveraging a
larger pool of unlabeled scans. By employing Dice loss, cross-entropy loss, a
feature matching loss and a self-training loss, the model learns to identify
and delineate early infarcts, even when they are faint or their size is small.
Experiments on the publicly available Acute Ischemic Stroke Dataset (AISD)
demonstrate the potential of the proposed method to enhance diagnostic
capabilities, reduce the burden of manual annotation, and support more
efficient clinical decision-making in stroke care.
\\ ( https://arxiv.org/abs/2511.19576 ,  469kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19578
Date: Mon, 24 Nov 2025 18:23:28 GMT   (333kb)

Title: Multiscale Vector-Quantized Variational Autoencoder for Endoscopic Image
 Synthesis
Authors: Dimitrios E. Diamantis and Dimitris K. Iakovidis
Categories: cs.CV
Comments: Accepted in IEEE Int. Conf. Imaging Systems and Techniques (IST
 2025), Strasburg, France
\\
 Gastrointestinal (GI) imaging via Wireless Capsule Endoscopy (WCE) generates
a large number of images requiring manual screening. Deep learning-based
Clinical Decision Support (CDS) systems can assist screening, yet their
performance relies on the existence of large, diverse, training medical
datasets. However, the scarcity of such data, due to privacy constraints and
annotation costs, hinders CDS development. Generative machine learning offers a
viable solution to combat this limitation. While current Synthetic Data
Generation (SDG) methods, such as Generative Adversarial Networks and
Variational Autoencoders have been explored, they often face challenges with
training stability and capturing sufficient visual diversity, especially when
synthesizing abnormal findings. This work introduces a novel VAE-based
methodology for medical image synthesis and presents its application for the
generation of WCE images. The novel contributions of this work include a)
multiscale extension of the Vector Quantized VAE model, named as Multiscale
Vector Quantized Variational Autoencoder (MSVQ-VAE); b) unlike other VAE-based
SDG models for WCE image generation, MSVQ-VAE is used to seamlessly introduce
abnormalities into normal WCE images; c) it enables conditional generation of
synthetic images, enabling the introduction of different types of abnormalities
into the normal WCE images; d) it performs experiments with a variety of
abnormality types, including polyps, vascular and inflammatory conditions. The
utility of the generated images for CDS is assessed via image classification.
Comparative experiments demonstrate that training a CDS classifier using the
abnormal images generated by the proposed methodology yield comparable results
with a classifier trained with only real data. The generality of the proposed
methodology promises its applicability to various domains related to medical
multimedia.
\\ ( https://arxiv.org/abs/2511.19578 ,  333kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19629
Date: Mon, 24 Nov 2025 19:05:28 GMT   (9148kb)

Title: SkillSight: Efficient First-Person Skill Assessment with Gaze
Authors: Chi Hsuan Wu, Kumar Ashutosh, Kristen Grauman
Categories: cs.CV
\\
 Egocentric perception on smart glasses could transform how we learn new
skills in the physical world, but automatic skill assessment remains a
fundamental technical challenge. We introduce SkillSight for power-efficient
skill assessment from first-person data. Central to our approach is the
hypothesis that skill level is evident not only in how a person performs an
activity (video), but also in how they direct their attention when doing so
(gaze). Our two-stage framework first learns to jointly model gaze and
egocentric video when predicting skill level, then distills a gaze-only student
model. At inference, the student model requires only gaze input, drastically
reducing power consumption by eliminating continuous video processing.
Experiments on three datasets spanning cooking, music, and sports establish,
for the first time, the valuable role of gaze in skill understanding across
diverse real-world settings. Our SkillSight teacher model achieves
state-of-the-art performance, while our gaze-only student variant maintains
high accuracy using 73x less power than competing methods. These results pave
the way for in-the-wild AI-supported skill learning.
\\ ( https://arxiv.org/abs/2511.19629 ,  9148kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19641
Date: Mon, 24 Nov 2025 19:15:47 GMT   (19969kb)

Title: On the Utility of Foundation Models for Fast MRI: Vision-Language-Guided
 Image Reconstruction
Authors: Ruimin Feng, Xingxin He, Ronald Mercer, Zachary Stewart, and Fang Liu
Categories: cs.CV cs.AI
\\
 Purpose: To investigate whether a vision-language foundation model can
enhance undersampled MRI reconstruction by providing high-level contextual
information beyond conventional priors. Methods: We proposed a semantic
distribution-guided reconstruction framework that uses a pre-trained
vision-language foundation model to encode both the reconstructed image and
auxiliary information into high-level semantic features. A contrastive
objective aligns the reconstructed representation with the target semantic
distribution, ensuring consistency with high-level perceptual cues. The
proposed objective works with various deep learning-based reconstruction
methods and can flexibly incorporate semantic priors from multimodal sources.
To test the effectiveness of these semantic priors, we evaluated reconstruction
results guided by priors derived from either image-only or image-language
auxiliary information. Results: Experiments on knee and brain datasets
demonstrate that semantic priors from images preserve fine anatomical
structures and achieve superior perceptual quality, as reflected in lower LPIPS
values, higher Tenengrad scores, and improved scores in the reader study,
compared with conventional regularization. The image-language information
further expands the semantic distribution and enables high-level control over
reconstruction attributes. Across all evaluations, the contrastive objective
consistently guided the reconstructed features toward the desired semantic
distributions while maintaining data fidelity, demonstrating the effectiveness
of the proposed optimization framework. Conclusion: The study highlights that
vision-language foundation models can improve undersampled MRI reconstruction
through semantic-space optimization.
\\ ( https://arxiv.org/abs/2511.19641 ,  19969kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19652
Date: Mon, 24 Nov 2025 19:33:56 GMT   (24338kb)

Title: Navigating Gigapixel Pathology Images with Large Multimodal Models
Authors: Thomas A. Buckley, Kian R. Weihrauch, Katherine Latham, Andrew Z.
 Zhou, Padmini A. Manrai, Arjun K. Manrai
Categories: cs.CV
\\
 Despite being widely used to support clinical care, general-purpose large
multimodal models (LMMs) have generally shown poor or inconclusive performance
in medical image interpretation, particularly in pathology, where gigapixel
images are used. However, prior studies have used either low-resolution
thumbnails or random patches, which likely underestimated model performance.
Here, we ask whether LMMs can be adapted to reason coherently and accurately in
the evaluation of such images. In this study, we introduce Gigapixel Image
Agent for Navigating Tissue (GIANT), the first framework that allows LMMs to
iteratively navigate whole-slide images (WSIs) like a pathologist. Accompanying
GIANT, we release MultiPathQA, a new benchmark, which comprises 934 WSI-level
questions, encompassing five clinically-relevant tasks ranging from cancer
diagnosis to open-ended reasoning. MultiPathQA also includes 128 questions,
authored by two professional pathologists, requiring direct slide
interpretation. Using MultiPathQA, we show that our simple agentic system
substantially outperforms conventional patch- and thumbnail-based baselines,
approaching or surpassing the performance of specialized models trained on
millions of images. For example, on pathologist-authored questions, GPT-5 with
GIANT achieves 62.5% accuracy, outperforming specialist pathology models such
as TITAN (43.8%) and SlideChat (37.5%). Our findings reveal the strengths and
limitations of current foundation models and ground future development of LMMs
for expert reasoning in pathology.
\\ ( https://arxiv.org/abs/2511.19652 ,  24338kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19661
Date: Mon, 24 Nov 2025 19:48:46 GMT   (3002kb)

Title: CodeV: Code with Images for Faithful Visual Reasoning via Tool-Aware
 Policy Optimization
Authors: Xinhai Hou, Shaoyuan Xu, Manan Biyani, Mayan Li, Jia Liu, Todd C.
 Hollon, Bryan Wang
Categories: cs.CV
\\
 Agentic vision-language models are increasingly trained to "think with
images" by calling image operations. However, we show that high final-answer
accuracy often hides unfaithful visual reasoning: models may invoke tools on
irrelevant regions or ignore tool outputs entirely, yet still guess the correct
answer. In this work, we first propose a faithfulness evaluation protocol that
measures whether intermediate visual tool outputs (e.g., crops) actually
contain the queried evidence. This reveals that recent visual agents achieve
high final-answer accuracy but exhibit low rates of faithful tool-use on visual
search benchmarks. We then introduce CodeV, a code-based visual agent trained
with Tool-Aware Policy Optimization (TAPO). TAPO is a process-level RL
framework that augments GRPO with dense rewards defined directly on visual tool
inputs and outputs, rather than on chain-of-thought tokens, making supervision
easier to verify and less susceptible to reward hacking. CodeV represents
visual tools as executable Python code, and TAPO assigns step-wise rewards
based solely on the question and tool output, encouraging both necessary and
evidence-consistent tool use. In a two-stage SFT+RL pipeline, CodeV achieves
competitive or superior accuracy while substantially increasing faithful
tool-use rates on related visual search benchmarks. Beyond visual search, CodeV
attains strong performance on a range of multimodal reasoning and math
benchmarks, suggesting that explicitly supervising intermediate tool behavior
is crucial for building trustworthy, agentic visual reasoning systems.
\\ ( https://arxiv.org/abs/2511.19661 ,  3002kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19667
Date: Mon, 24 Nov 2025 20:04:26 GMT   (28475kb)

Title: OncoVision: Integrating Mammography and Clinical Data through
 Attention-Driven Multimodal AI for Enhanced Breast Cancer Diagnosis
Authors: Istiak Ahmed, Galib Ahmed, K. Shahriar Sanjid, Md. Tanzim Hossain, Md.
 Nishan Khan, Md. Misbah Khan, Md. Arifur Rahman, Sheikh Anisul Haque, Sharmin
 Akhtar Rupa, Mohammed Mejbahuddin Mia, Mahmud Hasan Mostofa Kamal, Md.
 Mostafa Kamal Sarker, M. Monir Uddin
Categories: cs.CV
\\
 OncoVision is a multimodal AI pipeline that combines mammography images and
clinical data for better breast cancer diagnosis. Employing an attention-based
encoder-decoder backbone, it jointly segments four ROIs - masses,
calcifications, axillary findings, and breast tissues - with state-of-the-art
accuracy and robustly predicts ten structured clinical features: mass
morphology, calcification type, ACR breast density, and BI-RADS categories. To
fuse imaging and clinical insights, we developed two late-fusion strategies. By
utilizing complementary multimodal data, late fusion strategies improve
diagnostic precision and reduce inter-observer variability. Operationalized as
a secure, user-friendly web application, OncoVision produces structured reports
with dual-confidence scoring and attention-weighted visualizations for
real-time diagnostic support to improve clinician trust and facilitate medical
teaching. It can be easily incorporated into the clinic, making screening
available in underprivileged areas around the world, such as rural South Asia.
Combining accurate segmentation with clinical intuition, OncoVision raises the
bar for AI-based mammography, offering a scalable and equitable solution to
detect breast cancer at an earlier stage and enhancing treatment through timely
interventions.
\\ ( https://arxiv.org/abs/2511.19667 ,  28475kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19676
Date: Mon, 24 Nov 2025 20:24:22 GMT   (694kb)

Title: INTERLACE: Interleaved Layer Pruning and Efficient Adaptation in Large
 Vision-Language Models
Authors: Parsa Madinei, Ryan Solgi, Ziqi Wen, Jonathan Skaza, Miguel Eckstein,
 Ramtin Pedarsani
Categories: cs.CV
\\
 We introduce INTERLACE, a novel framework that prunes redundant layers in
VLMs while maintaining performance through sample-efficient finetuning.
Existing layer pruning methods lead to significant performance drop when
applied to VLMs. Instead, we analyze triplets of consecutive layers to identify
local redundancy, removing the most redundant of the first two layers, finetune
the remaining layer to compensate for the lost capacity, and freeze the third
layer to serve as a stable anchor during finetuning. We found that this
interleaved finetune-freeze design enables rapid convergence with minimal data
after pruning. By finetuning only a subset of layers on just 1% of the
FineVision dataset for one epoch, Interlace achieves 88.9% average performance
retention after dropping 25% of the network, achieving SOTA performance. Our
code is available at: https://github.com/pmadinei/Interlace.git
\\ ( https://arxiv.org/abs/2511.19676 ,  694kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19684
Date: Mon, 24 Nov 2025 20:45:17 GMT   (36940kb)

Title: IndEgo: A Dataset of Industrial Scenarios and Collaborative Work for
 Egocentric Assistants
Authors: Vivek Chavan, Yasmina Imgrund, Tung Dao, Sanwantri Bai, Bosong Wang,
 Ze Lu, Oliver Heimann, J\"org Kr\"uger
Categories: cs.CV cs.AI cs.HC cs.RO
Comments: Accepted to NeurIPS 2025 D&B Track. Project Page:
 https://indego-dataset.github.io/
\\
 We introduce IndEgo, a multimodal egocentric and exocentric dataset
addressing common industrial tasks, including assembly/disassembly, logistics
and organisation, inspection and repair, woodworking, and others. The dataset
contains 3,460 egocentric recordings (approximately 197 hours), along with
1,092 exocentric recordings (approximately 97 hours). A key focus of the
dataset is collaborative work, where two workers jointly perform cognitively
and physically intensive tasks. The egocentric recordings include rich
multimodal data and added context via eye gaze, narration, sound, motion, and
others. We provide detailed annotations (actions, summaries, mistake
annotations, narrations), metadata, processed outputs (eye gaze, hand pose,
semi-dense point cloud), and benchmarks on procedural and non-procedural task
understanding, Mistake Detection, and reasoning-based Question Answering.
Baseline evaluations for Mistake Detection, Question Answering and
collaborative task understanding show that the dataset presents a challenge for
the state-of-the-art multimodal models. Our dataset is available at:
https://huggingface.co/datasets/FraunhoferIPK/IndEgo
\\ ( https://arxiv.org/abs/2511.19684 ,  36940kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19686
Date: Mon, 24 Nov 2025 20:47:44 GMT   (17377kb)

Title: CountXplain: Interpretable Cell Counting with Prototype-Based Density
 Map Estimation
Authors: Abdurahman Ali Mohammed, Wallapak Tavanapong, Catherine Fonder, Donald
 S. Sakaguchi
Categories: cs.CV
Comments: Medical Imaging with Deep Learning 2025
\\
 Cell counting in biomedical imaging is pivotal for various clinical
applications, yet the interpretability of deep learning models in this domain
remains a significant challenge. We propose a novel prototype-based method for
interpretable cell counting via density map estimation. Our approach integrates
a prototype layer into the density estimation network, enabling the model to
learn representative visual patterns for both cells and background artifacts.
The learned prototypes were evaluated through a survey of biologists, who
confirmed the relevance of the visual patterns identified, further validating
the interpretability of the model. By generating interpretations that highlight
regions in the input image most similar to each prototype, our method offers a
clear understanding of how the model identifies and counts cells. Extensive
experiments on two public datasets demonstrate that our method achieves
interpretability without compromising counting effectiveness. This work
provides researchers and clinicians with a transparent and reliable tool for
cell counting, potentially increasing trust and accelerating the adoption of
deep learning in critical biomedical applications. Code is available at
https://github.com/NRT-D4/CountXplain.
\\ ( https://arxiv.org/abs/2511.19686 ,  17377kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19704
Date: Mon, 24 Nov 2025 21:15:01 GMT   (43444kb)

Title: RADSeg: Unleashing Parameter and Compute Efficient Zero-Shot
 Open-Vocabulary Segmentation Using Agglomerative Models
Authors: Omar Alama, Darshil Jariwala, Avigyan Bhattacharya, Seungchan Kim,
 Wenshan Wang, Sebastian Scherer
Categories: cs.CV
\\
 Open-vocabulary semantic segmentation (OVSS) underpins many vision and
robotics tasks that require generalizable semantic understanding. Existing
approaches either rely on limited segmentation training data, which hinders
generalization, or apply zero-shot heuristics to vision-language models (e.g
CLIP), while the most competitive approaches combine multiple models to improve
performance at the cost of high computational and memory demands. In this work,
we leverage an overlooked agglomerative vision foundation model, RADIO, to
improve zero-shot OVSS along three key axes simultaneously: mIoU, latency, and
parameter efficiency. We present the first comprehensive study of RADIO for
zero-shot OVSS and enhance its performance through self-correlating recursive
attention, self-correlating global aggregation, and computationally efficient
mask refinement. Our approach, RADSeg, achieves 6-30% mIoU improvement in the
base ViT class while being 3.95x faster and using 2.5x fewer parameters.
Surprisingly, RADSeg-base (105M) outperforms previous combinations of huge
vision models (850-1350M) in mIoU, achieving state-of-the-art accuracy with
substantially lower computational and memory cost.
\\ ( https://arxiv.org/abs/2511.19704 ,  43444kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19718
Date: Mon, 24 Nov 2025 21:28:55 GMT   (1104kb)

Title: Rethinking Vision Transformer Depth via Structural Reparameterization
Authors: Chengwei Zhou, Vipin Chaudhary, Gourav Datta
Categories: cs.CV
Comments: 21 pages, 6 figures
\\
 The computational overhead of Vision Transformers in practice stems
fundamentally from their deep architectures, yet existing acceleration
strategies have primarily targeted algorithmic-level optimizations such as
token pruning and attention speedup. This leaves an underexplored research
question: can we reduce the number of stacked transformer layers while
maintaining comparable representational capacity? To answer this, we propose a
branch-based structural reparameterization technique that operates during the
training phase. Our approach leverages parallel branches within transformer
blocks that can be systematically consolidated into streamlined single-path
models suitable for inference deployment. The consolidation mechanism works by
gradually merging branches at the entry points of nonlinear components,
enabling both feed-forward networks (FFN) and multi-head self-attention (MHSA)
modules to undergo exact mathematical reparameterization without inducing
approximation errors at test time. When applied to ViT-Tiny, the framework
successfully reduces the original 12-layer architecture to 6, 4, or as few as 3
layers while maintaining classification accuracy on ImageNet-1K. The resulting
compressed models achieve inference speedups of up to 37% on mobile CPU
platforms. Our findings suggest that the conventional wisdom favoring extremely
deep transformer stacks may be unnecessarily restrictive, and point toward new
opportunities for constructing efficient vision transformers.
\\ ( https://arxiv.org/abs/2511.19718 ,  1104kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19728
Date: Mon, 24 Nov 2025 21:45:01 GMT   (13422kb)

Title: Maritime Small Object Detection from UAVs using Deep Learning with
 Altitude-Aware Dynamic Tiling
Authors: Sakib Ahmed, Oscar Pizarro
Categories: cs.CV cs.RO
Comments: This is the author's accepted version of an article that has been
 published by IEEE. The final published version is available at IEEE Xplore
Journal-ref: S. Ahmed and O. Pizarro, "Maritime Small Object Detection from
 UAVs using Deep Learning with Altitude-Aware Dynamic Tiling," OCEANS 2025
 Brest, BREST, France, 2025, pp. 1-9
DOI: 10.1109/OCEANS58557.2025.11104659
\\
 Unmanned Aerial Vehicles (UAVs) are crucial in Search and Rescue (SAR)
missions due to their ability to monitor vast maritime areas. However, small
objects often remain difficult to detect from high altitudes due to low
object-to-background pixel ratios. We propose an altitude-aware dynamic tiling
method that scales and adaptively subdivides the image into tiles for enhanced
small object detection. By integrating altitude-dependent scaling with an
adaptive tiling factor, we reduce unnecessary computation while maintaining
detection performance. Tested on the SeaDronesSee dataset [1] with YOLOv5 [2]
and Slicing Aided Hyper Inference (SAHI) framework [3], our approach improves
Mean Average Precision (mAP) for small objects by 38% compared to a baseline
and achieves more than double the inference speed compared to static tiling.
This approach enables more efficient and accurate UAV-based SAR operations
under diverse conditions.
\\ ( https://arxiv.org/abs/2511.19728 ,  13422kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19741
Date: Mon, 24 Nov 2025 21:59:12 GMT   (12138kb)

Title: Efficient Transferable Optimal Transport via Min-Sliced Transport Plans
Authors: Xinran Liu, Elaheh Akbari, Rocio Diaz Martin, Navid NaderiAlizadeh,
 Soheil Kolouri
Categories: cs.CV
\\
 Optimal Transport (OT) offers a powerful framework for finding
correspondences between distributions and addressing matching and alignment
problems in various areas of computer vision, including shape analysis, image
generation, and multimodal tasks. The computation cost of OT, however, hinders
its scalability. Slice-based transport plans have recently shown promise for
reducing the computational cost by leveraging the closed-form solutions of 1D
OT problems. These methods optimize a one-dimensional projection (slice) to
obtain a conditional transport plan that minimizes the transport cost in the
ambient space. While efficient, these methods leave open the question of
whether learned optimal slicers can transfer to new distribution pairs under
distributional shift. Understanding this transferability is crucial in settings
with evolving data or repeated OT computations across closely related
distributions. In this paper, we study the min-Sliced Transport Plan (min-STP)
framework and investigate the transferability of optimized slicers: can a
slicer trained on one distribution pair yield effective transport plans for
new, unseen pairs? Theoretically, we show that optimized slicers remain close
under slight perturbations of the data distributions, enabling efficient
transfer across related tasks. To further improve scalability, we introduce a
minibatch formulation of min-STP and provide statistical guarantees on its
accuracy. Empirically, we demonstrate that the transferable min-STP achieves
strong one-shot matching performance and facilitates amortized training for
point cloud alignment and flow-based generative modeling.
\\ ( https://arxiv.org/abs/2511.19741 ,  12138kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19751
Date: Mon, 24 Nov 2025 22:16:12 GMT   (38760kb)

Title: Leveraging Foundation Models for Histological Grading in Cutaneous
 Squamous Cell Carcinoma using PathFMTools
Authors: Abdul Rahman Diab, Emily E. Karn, Renchin Wu, Emily S. Ruiz, William
 Lotter
Categories: cs.CV cs.AI
Comments: Proceedings of the 5th Machine Learning for Health (ML4H) Symposium
 (2025)
\\
 Despite the promise of computational pathology foundation models, adapting
them to specific clinical tasks remains challenging due to the complexity of
whole-slide image (WSI) processing, the opacity of learned features, and the
wide range of potential adaptation strategies. To address these challenges, we
introduce PathFMTools, a lightweight, extensible Python package that enables
efficient execution, analysis, and visualization of pathology foundation
models. We use this tool to interface with and evaluate two state-of-the-art
vision-language foundation models, CONCH and MUSK, on the task of histological
grading in cutaneous squamous cell carcinoma (cSCC), a critical criterion that
informs cSCC staging and patient management. Using a cohort of 440 cSCC H&E
WSIs, we benchmark multiple adaptation strategies, demonstrating trade-offs
across prediction approaches and validating the potential of using foundation
model embeddings to train small specialist models. These findings underscore
the promise of pathology foundation models for real-world clinical
applications, with PathFMTools enabling efficient analysis and validation.
\\ ( https://arxiv.org/abs/2511.19751 ,  38760kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19752
Date: Mon, 24 Nov 2025 22:17:24 GMT   (8365kb)

Title: What You See is (Usually) What You Get: Multimodal Prototype Networks
 that Abstain from Expensive Modalities
Authors: Muchang Bahng, Charlie Berens, Jon Donnelly, Eric Chen, Chaofan Chen,
 Cynthia Rudin
Categories: cs.CV
Comments: 19 pages. 16 figures. 10 tables
\\
 Species detection is important for monitoring the health of ecosystems and
identifying invasive species, serving a crucial role in guiding conservation
efforts. Multimodal neural networks have seen increasing use for identifying
species to help automate this task, but they have two major drawbacks. First,
their black-box nature prevents the interpretability of their decision making
process. Second, collecting genetic data is often expensive and requires
invasive procedures, often necessitating researchers to capture or kill the
target specimen. We address both of these problems by extending prototype
networks (ProtoPNets), which are a popular and interpretable alternative to
traditional neural networks, to the multimodal, cost-aware setting. We ensemble
prototypes from each modality, using an associated weight to determine how much
a given prediction relies on each modality. We further introduce methods to
identify cases for which we do not need the expensive genetic information to
make confident predictions. We demonstrate that our approach can intelligently
allocate expensive genetic data for fine-grained distinctions while using
abundant image data for clearer visual classifications and achieving comparable
accuracy to models that consistently use both modalities.
\\ ( https://arxiv.org/abs/2511.19752 ,  8365kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19759
Date: Mon, 24 Nov 2025 22:33:19 GMT   (1380kb)

Title: Vision--Language Enhanced Foundation Model for Semi-supervised Medical
 Image Segmentation
Authors: Jiaqi Guo, Mingzhen Li, Hanyu Su, Santiago L\'opez, Lexiaozi Fan,
 Daniel Kim, and Aggelos Katsaggelos
Categories: cs.CV
\\
 Semi-supervised learning (SSL) has emerged as an effective paradigm for
medical image segmentation, reducing the reliance on extensive expert
annotations. Meanwhile, vision-language models (VLMs) have demonstrated strong
generalization and few-shot capabilities across diverse visual domains. In this
work, we integrate VLM-based segmentation into semi-supervised medical image
segmentation by introducing a Vision-Language Enhanced Semi-supervised
Segmentation Assistant (VESSA) that incorporates foundation-level
visual-semantic understanding into SSL frameworks. Our approach consists of two
stages. In Stage 1, the VLM-enhanced segmentation foundation model VESSA is
trained as a reference-guided segmentation assistant using a template bank
containing gold-standard exemplars, simulating learning from limited labeled
data. Given an input-template pair, VESSA performs visual feature matching to
extract representative semantic and spatial cues from exemplar segmentations,
generating structured prompts for a SAM2-inspired mask decoder to produce
segmentation masks. In Stage 2, VESSA is integrated into a state-of-the-art SSL
framework, enabling dynamic interaction with the student model: as student
predictions become more refined, they are fed back to VESSA as prompts,
allowing it to generate higher-quality pseudo-labels and stronger guidance.
Extensive experiments across multiple segmentation datasets and domains show
that VESSA-augmented SSL significantly enhances segmentation accuracy,
outperforming state-of-the-art baselines under extremely limited annotation
conditions.
\\ ( https://arxiv.org/abs/2511.19759 ,  1380kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19760
Date: Mon, 24 Nov 2025 22:36:09 GMT   (1314kb)

Title: A Storage-Efficient Feature for 3D Concrete Defect Segmentation to
 Replace Normal Vector
Authors: Linxin Hua (1), Jianghua Deng (2), Ye Lu (1) ((1) Department of Civil
 and Environmental Engineering, Monash University, Melbourne, Australia, (2)
 School of Civil Engineering and Architecture, Changzhou Institute of
 Technology, Changzhou, China)
Categories: cs.CV
Comments: 25 pages, 7 figures
ACM-class: I.4.6; I.5.3; J.6
\\
 Point cloud reconstruction of damage offers an effective solution to
image-based methods vulnerable to background noise, yet its application is
constrained by the high volume of 3D data. This study proposes a new feature,
relative angle, computed as the angle between the normal vector of a point and
the average normal vector of its parent point cloud. This single-dimensional
feature provides directionality information equivalent to normal vectors for
concrete surface defect characteristics. Through entropy-based feature
evaluation, this study demonstrates the ability of relative angle to filter out
redundant information in undamaged sections while retaining effective
information in damaged sections. By training and testing with PointNet++,
models based on the relative angles achieved similar performance to that of
models based on normal vectors while delivering 27.6% storage reduction and 83%
input channel compression. This novel feature has the potential to enable
larger-batch execution on resource-constrained hardware without the necessity
of architectural modifications to models.
\\ ( https://arxiv.org/abs/2511.19760 ,  1314kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19765
Date: Mon, 24 Nov 2025 22:40:57 GMT   (7779kb)

Title: Lightweight Transformer Framework for Weakly Supervised Semantic
 Segmentation
Authors: Ali Torabi, Sanjog Gaihre, Yaqoob Majeed
Categories: cs.CV
\\
 Weakly supervised semantic segmentation (WSSS) must learn dense masks from
noisy, under-specified cues. We revisit the SegFormer decoder and show that
three small, synergistic changes make weak supervision markedly more
effective-without altering the MiT backbone or relying on heavy
post-processing. Our method, CrispFormer, augments the decoder with: (1) a
boundary branch that supervises thin object contours using a lightweight edge
head and a boundary-aware loss; (2) an uncertainty-guided refiner that predicts
per-pixel aleatoric uncertainty and uses it to weight losses and gate a
residual correction of the segmentation logits; and (3) a dynamic multi-scale
fusion layer that replaces static concatenation with spatial softmax gating
over multi-resolution features, optionally modulated by uncertainty. The result
is a single-pass model that preserves crisp boundaries, selects appropriate
scales per location, and resists label noise from weak cues. Integrated into a
standard WSSS pipeline (seed, student, and EMA relabeling), CrispFormer
consistently improves boundary F-score, small-object recall, and mIoU over
SegFormer baselines trained on the same seeds, while adding minimal compute.
Our decoder-centric formulation is simple to implement, broadly compatible with
existing SegFormer variants, and offers a reproducible path to higher-fidelity
masks from image-level supervision.
\\ ( https://arxiv.org/abs/2511.19765 ,  7779kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19768
Date: Mon, 24 Nov 2025 22:50:50 GMT   (41239kb)

Title: Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration
 in Embodied Question Answering
Authors: Noah Frahm, Prakrut Patel, Yue Zhang, Shoubin Yu, Mohit Bansal, Roni
 Sengupta
Categories: cs.CV cs.AI cs.RO
Comments: webpage: https://noahfrahm.github.io/Prune-Then-Plan-project-page/
\\
 Large vision-language models (VLMs) have improved embodied question answering
(EQA) agents by providing strong semantic priors for open-vocabulary reasoning.
However, when used directly for step-level exploration, VLMs often exhibit
frontier oscillations, unstable back-and-forth movements caused by
overconfidence and miscalibration, leading to inefficient navigation and
degraded answer quality. We propose Prune-Then-Plan, a simple and effective
framework that stabilizes exploration through step-level calibration. Instead
of trusting raw VLM scores, our method prunes implausible frontier choices
using a Holm-Bonferroni inspired pruning procedure and then delegates final
decisions to a coverage-based planner. This separation converts overconfident
predictions into conservative, interpretable actions by relying on human-level
judgments to calibrate the step-level behavior of VLMs. Integrated into the
3D-Mem EQA framework, our approach achieves relative improvements of up to 49%
and 33% in visually grounded SPL and LLM-Match metrics respectively over
baselines. Overall, our method achieves better scene coverage under equal
exploration budgets on both OpenEQA and EXPRESS-Bench datasets.
\\ ( https://arxiv.org/abs/2511.19768 ,  41239kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19778
Date: Mon, 24 Nov 2025 23:10:15 GMT   (10541kb)

Title: One Attention, One Scale: Phase-Aligned Rotary Positional Embeddings for
 Mixed-Resolution Diffusion Transformer
Authors: Haoyu Wu, Jingyi Xu, Qiaomu Miao, Dimitris Samaras, Hieu Le
Categories: cs.CV
\\
 We identify a core failure mode that occurs when using the usual linear
interpolation on rotary positional embeddings (RoPE) for mixed-resolution
denoising with Diffusion Transformers. When tokens from different spatial grids
are mixed, the attention mechanism collapses. The issue is structural. Linear
coordinate remapping forces a single attention head to compare RoPE phases
sampled at incompatible rates, creating phase aliasing that destabilizes the
score landscape. Pretrained DiTs are especially brittle-many heads exhibit
extremely sharp, periodic phase selectivity-so even tiny cross-rate
inconsistencies reliably cause blur, artifacts, or full collapse.
 To this end, our main contribution is Cross-Resolution Phase-Aligned
Attention (CRPA), a training-free drop-in fix that eliminates this failure at
its source. CRPA modifies only the RoPE index map for each attention call: all
Q/K positions are expressed on the query's stride so that equal physical
distances always induce identical phase increments. This restores the precise
phase patterns that DiTs rely on. CRPA is fully compatible with pretrained
DiTs, stabilizes all heads and layers uniformly. We demonstrate that CRPA
enables high-fidelity and efficient mixed-resolution generation, outperforming
previous state-of-the-art methods on image and video generation.
\\ ( https://arxiv.org/abs/2511.19778 ,  10541kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19806
Date: Tue, 25 Nov 2025 00:24:42 GMT   (1486kb)

Title: Reading Between the Lines: Abstaining from VLM-Generated OCR Errors via
 Latent Representation Probes
Authors: Jihan Yao, Achin Kulshrestha, Nathalie Rauschmayr, Reed Roberts,
 Banghua Zhu, Yulia Tsvetkov, Federico Tombari
Categories: cs.CV
\\
 As VLMs are deployed in safety-critical applications, their ability to
abstain from answering when uncertain becomes crucial for reliability,
especially in Scene Text Visual Question Answering (STVQA) tasks. For example,
OCR errors like misreading "50 mph" as "60 mph" could cause severe traffic
accidents. This leads us to ask: Can VLMs know when they can't see? Existing
abstention methods suggest pessimistic answers: they either rely on
miscalibrated output probabilities or require semantic agreement unsuitable for
OCR tasks. However, this failure may indicate we are looking in the wrong
place: uncertainty signals could be hidden in VLMs' internal representations.
 Building on this insight, we propose Latent Representation Probing (LRP):
training lightweight probes on hidden states or attention patterns. We explore
three probe designs: concatenating representations across all layers,
aggregating attention over visual tokens, and ensembling single layer probes by
majority vote. Experiments on four benchmarks across image and video modalities
show LRP improves abstention accuracy by 7.6\% over best baselines. Our
analysis reveals: probes generalize across various uncertainty sources and
datasets, and optimal signals emerge from intermediate rather than final
layers. This establishes a principled framework for building deployment-ready
AI systems by detecting confidence signals from internal states rather than
unreliable outputs.
\\ ( https://arxiv.org/abs/2511.19806 ,  1486kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19811
Date: Tue, 25 Nov 2025 00:42:09 GMT   (9115kb)

Title: Training-Free Generation of Diverse and High-Fidelity Images via Prompt
 Semantic Space Optimization
Authors: Debin Meng, Chen Jin, Zheng Gao, Yanran Li, Ioannis Patras and
 Georgios Tzimiropoulos
Categories: cs.CV cs.CL cs.LG
Comments: under review
\\
 Image diversity remains a fundamental challenge for text-to-image diffusion
models. Low-diversity models tend to generate repetitive outputs, increasing
sampling redundancy and hindering both creative exploration and downstream
applications. A primary cause is that generation often collapses toward a
strong mode in the learned distribution. Existing attempts to improve
diversity, such as noise resampling, prompt rewriting, or steering-based
guidance, often still collapse to dominant modes or introduce distortions that
degrade image quality. In light of this, we propose Token-Prompt embedding
Space Optimization (TPSO), a training-free and model-agnostic module. TPSO
introduces learnable parameters to explore underrepresented regions of the
token embedding space, reducing the tendency of the model to repeatedly
generate samples from strong modes of the learned distribution. At the same
time, the prompt-level space provides a global semantic constraint that
regulates distribution shifts, preventing quality degradation while maintaining
high fidelity. Extensive experiments on MS-COCO and three diffusion backbones
show that TPSO significantly enhances generative diversity, improving baseline
performance from 1.10 to 4.18 points, without sacrificing image quality. Code
will be released upon acceptance.
\\ ( https://arxiv.org/abs/2511.19811 ,  9115kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19820
Date: Tue, 25 Nov 2025 01:21:26 GMT   (9585kb)

Title: CropVLM: Learning to Zoom for Fine-Grained Vision-Language Perception
Authors: Miguel Carvalho, Helder Dias, Bruno Martins
Categories: cs.CV cs.AI cs.CL cs.LG
\\
 Vision-Language Models (VLMs) often struggle with tasks that require
fine-grained image understanding, such as scene-text recognition or document
analysis, due to perception limitations and visual fragmentation. To address
these challenges, we introduce CropVLM as an external low-cost method for
boosting performance, enabling VLMs to dynamically ''zoom in'' on relevant
image regions, enhancing their ability to capture fine details. CropVLM is
trained using reinforcement learning, without using human-labeled bounding
boxes as a supervision signal, and without expensive synthetic evaluations. The
model is trained once and can be paired with both open-source and proprietary
VLMs to improve their performance. Our approach delivers significant
improvements on tasks that require high-resolution image understanding, notably
for benchmarks that are out-of-domain for the target VLM, without modifying or
fine-tuning the VLM, thus avoiding catastrophic forgetting.
\\ ( https://arxiv.org/abs/2511.19820 ,  9585kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19827
Date: Tue, 25 Nov 2025 01:38:56 GMT   (46794kb)

Title: ReDirector: Creating Any-Length Video Retakes with Rotary Camera
 Encoding
Authors: Byeongjun Park, Byung-Hoon Kim, Hyungjin Chung, Jong Chul Ye
Categories: cs.CV
Comments: Project page: https://byeongjun-park.github.io/ReDirector/
\\
 We present ReDirector, a novel camera-controlled video retake generation
method for dynamically captured variable-length videos. In particular, we
rectify a common misuse of RoPE in previous works by aligning the
spatiotemporal positions of the input video and the target retake. Moreover, we
introduce Rotary Camera Encoding (RoCE), a camera-conditioned RoPE phase shift
that captures and integrates multi-view relationships within and across the
input and target videos. By integrating camera conditions into RoPE, our method
generalizes to out-of-distribution camera trajectories and video lengths,
yielding improved dynamic object localization and static background
preservation. Extensive experiments further demonstrate significant
improvements in camera controllability, geometric consistency, and video
quality across various trajectories and lengths.
\\ ( https://arxiv.org/abs/2511.19827 ,  46794kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19834
Date: Tue, 25 Nov 2025 01:55:23 GMT   (1837kb)

Title: Large Language Model Aided Birt-Hogg-Dube Syndrome Diagnosis with
 Multimodal Retrieval-Augmented Generation
Authors: Haoqing Li, Jun Shi, Xianmeng Chen, Qiwei Jia, Rui Wang, Wei Wei, Hong
 An, Xiaowen Hu
Categories: cs.CV
\\
 Deep learning methods face dual challenges of limited clinical samples and
low inter-class differentiation among Diffuse Cystic Lung Diseases (DCLDs) in
advancing Birt-Hogg-Dube syndrome (BHD) diagnosis via Computed Tomography (CT)
imaging. While Multimodal Large Language Models (MLLMs) demonstrate diagnostic
potential fo such rare diseases, the absence of domain-specific knowledge and
referable radiological features intensify hallucination risks. To address this
problem, we propose BHD-RAG, a multimodal retrieval-augmented generation
framework that integrates DCLD-specific expertise and clinical precedents with
MLLMs to improve BHD diagnostic accuracy. BHDRAG employs: (1) a specialized
agent generating imaging manifestation descriptions of CT images to construct a
multimodal corpus of DCLDs cases. (2) a cosine similarity-based retriever
pinpointing relevant imagedescription pairs for query images, and (3) an MLLM
synthesizing retrieved evidence with imaging data for diagnosis. BHD-RAG is
validated on the dataset involving four types of DCLDs, achieving superior
accuracy and generating evidence-based descriptions closely aligned with expert
insights.
\\ ( https://arxiv.org/abs/2511.19834 ,  1837kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19835
Date: Tue, 25 Nov 2025 02:03:54 GMT   (6121kb)

Title: Rectified SpaAttn: Revisiting Attention Sparsity for Efficient Video
 Generation
Authors: Xuewen Liu, Zhikai Li, Jing Zhang, Mengjuan Chen, and Qingyi Gu
Categories: cs.CV cs.AI
Comments: Code at https://github.com/BienLuky/Rectified-SpaAttn
\\
 Diffusion Transformers dominate video generation, but the quadratic
complexity of attention computation introduces substantial latency. Attention
sparsity reduces computational costs by focusing on critical tokens while
ignoring non-critical tokens. However, existing methods suffer from severe
performance degradation. In this paper, we revisit attention sparsity and
reveal that existing methods induce systematic biases in attention allocation:
(1) excessive focus on critical tokens amplifies their attention weights; (2)
complete neglect of non-critical tokens causes the loss of relevant attention
weights. To address these issues, we propose Rectified SpaAttn, which rectifies
attention allocation with implicit full attention reference, thereby enhancing
the alignment between sparse and full attention maps. Specifically: (1) for
critical tokens, we show that their bias is proportional to the sparse
attention weights, with the ratio governed by the amplified weights.
Accordingly, we propose Isolated-Pooling Attention Reallocation, which
calculates accurate rectification factors by reallocating multimodal pooled
weights. (2) for non-critical tokens, recovering attention weights from the
pooled query-key yields attention gains but also introduces pooling errors.
Therefore, we propose Gain-Aware Pooling Rectification, which ensures that the
rectified gain consistently surpasses the induced error. Moreover, we customize
and integrate the Rectified SpaAttn kernel using Triton, achieving up to 3.33
and 2.08 times speedups on HunyuanVideo and Wan 2.1, respectively, while
maintaining high generation quality. We release Rectified SpaAttn as
open-source at https://github.com/BienLuky/Rectified-SpaAttn .
\\ ( https://arxiv.org/abs/2511.19835 ,  6121kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19836
Date: Tue, 25 Nov 2025 02:05:35 GMT   (3024kb)

Title: 4DWorldBench: A Comprehensive Evaluation Framework for 3D/4D World
 Generation Models
Authors: Yiting Lu, Wei Luo, Peiyan Tu, Haoran Li, Hanxin Zhu, Zihao Yu,
 Xingrui Wang, Xinyi Chen, Xinge Peng, Xin Li and Zhibo Chen
Categories: cs.CV
\\
 World Generation Models are emerging as a cornerstone of next-generation
multimodal intelligence systems. Unlike traditional 2D visual generation, World
Models aim to construct realistic, dynamic, and physically consistent 3D/4D
worlds from images, videos, or text. These models not only need to produce
high-fidelity visual content but also maintain coherence across space, time,
physics, and instruction control, enabling applications in virtual reality,
autonomous driving, embodied intelligence, and content creation. However, prior
benchmarks emphasize different evaluation dimensions and lack a unified
assessment of world-realism capability. To systematically evaluate World
Models, we introduce the 4DWorldBench, which measures models across four key
dimensions: Perceptual Quality, Condition-4D Alignment, Physical Realism, and
4D Consistency. The benchmark covers tasks such as Image-to-3D/4D, Video-to-4D,
Text-to-3D/4D. Beyond these, we innovatively introduce adaptive conditioning
across multiple modalities, which not only integrates but also extends
traditional evaluation paradigms. To accommodate different modality-conditioned
inputs, we map all modality conditions into a unified textual space during
evaluation, and further integrate LLM-as-judge, MLLM-as-judge, and traditional
network-based methods. This unified and adaptive design enables more
comprehensive and consistent evaluation of alignment, physical realism, and
cross-modal coherence. Preliminary human studies further demonstrate that our
adaptive tool selection achieves closer agreement with subjective human
judgments. We hope this benchmark will serve as a foundation for objective
comparisons and improvements, accelerating the transition from "visual
generation" to "world generation." Our project can be found at
https://yeppp27.github.io/4DWorldBench.github.io/.
\\ ( https://arxiv.org/abs/2511.19836 ,  3024kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19846
Date: Tue, 25 Nov 2025 02:23:10 GMT   (2381kb)

Title: Face, Whole-Person, and Object Classification in a Unified Space Via The
 Interleaved Multi-Domain Identity Curriculum
Authors: Thomas M Metz, Matthew Q Hill, Alice J O'Toole
Categories: cs.CV
\\
 Vision foundation models can perform generalized object classification in
zero-shot mode, and face/person recognition when they are fine-tuned. However,
fine-tuned models suffer from catastrophic forgetting. We create models that
perform four tasks (object recognition, face recognition from high- and
low-quality images, and person recognition from whole-body images) in a single
embedding space -- without incurring substantial catastrophic forgetting. To
accomplish this, we introduce two variants of the Interleaved Multi-Domain
Identity Curriculum (IMIC): a gradient-coupled, interleaving training schedule
that fine-tunes a foundation backbone simultaneously on all four tasks. The
IMIC method proved effective with three foundation model bases: DINOv3, CLIP,
and EVA-02. Two of these (EVA-02 and CLIP) performed comparably with domain
experts on all four tasks concurrently and were more accurate than humans at
multi-tasking across face, body, and object datasets. Further, we demonstrate
that our approach does not substantially harm out-of-distribution
generalization, thus maintaining a key property of foundation models. Analysis
of the most accurate model variants (EVA-02 + IMIC A and B) showed linearly
separable representations of the four tasks in the unified embedding space, but
with substantial sharing of features across tasks. Fewer than 100 PCs
calculated from any one task could perform all other tasks with nearly zero
performance degradation.
\\ ( https://arxiv.org/abs/2511.19846 ,  2381kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19850
Date: Tue, 25 Nov 2025 02:28:53 GMT   (37499kb)

Title: DOGE: Differentiable Bezier Graph Optimization for Road Network
 Extraction
Authors: Jiahui Sun, Junran Lu, Jinhui Yin, Yishuo Xu, Yuanqi Li, Yanwen Guo
Categories: cs.CV cs.GR
Comments: 11 pages, 6 figures
\\
 Automatic extraction of road networks from aerial imagery is a fundamental
task, yet prevailing methods rely on polylines that struggle to model
curvilinear geometry. We maintain that road geometry is inherently curve-based
and introduce the B\'ezier Graph, a differentiable parametric curve-based
representation. The primary obstacle to this representation is to obtain the
difficult-to-construct vector ground-truth (GT). We sidestep this bottleneck by
reframing the task as a global optimization problem over the B\'ezier Graph.
Our framework, DOGE, operationalizes this paradigm by learning a parametric
B\'ezier Graph directly from segmentation masks, eliminating the need for curve
GT. DOGE holistically optimizes the graph by alternating between two
complementary modules: DiffAlign continuously optimizes geometry via
differentiable rendering, while TopoAdapt uses discrete operators to refine its
topology. Our method sets a new state-of-the-art on the large-scale SpaceNet
and CityScale benchmarks, presenting a new paradigm for generating
high-fidelity vector maps of road networks. We will release our code and
related data.
\\ ( https://arxiv.org/abs/2511.19850 ,  37499kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19854
Date: Tue, 25 Nov 2025 02:35:00 GMT   (45053kb)

Title: STAvatar: Soft Binding and Temporal Density Control for Monocular 3D
 Head Avatars Reconstruction
Authors: Jiankuo Zhao, Xiangyu Zhu, Zidu Wang, Zhen Lei
Categories: cs.CV
Comments: 17 pages, 14 figures
\\
 Reconstructing high-fidelity and animatable 3D head avatars from monocular
videos remains a challenging yet essential task. Existing methods based on 3D
Gaussian Splatting typically bind Gaussians to mesh triangles and model
deformations solely via Linear Blend Skinning, which results in rigid motion
and limited expressiveness. Moreover, they lack specialized strategies to
handle frequently occluded regions (e.g., mouth interiors, eyelids). To address
these limitations, we propose STAvatar, which consists of two key components:
(1) a UV-Adaptive Soft Binding framework that leverages both image-based and
geometric priors to learn per-Gaussian feature offsets within the UV space.
This UV representation supports dynamic resampling, ensuring full compatibility
with Adaptive Density Control (ADC) and enhanced adaptability to shape and
textural variations. (2) a Temporal ADC strategy, which first clusters
structurally similar frames to facilitate more targeted computation of the
densification criterion. It further introduces a novel fused perceptual error
as clone criterion to jointly capture geometric and textural discrepancies,
encouraging densification in regions requiring finer details. Extensive
experiments on four benchmark datasets demonstrate that STAvatar achieves
state-of-the-art reconstruction performance, especially in capturing
fine-grained details and reconstructing frequently occluded regions. The code
will be publicly available.
\\ ( https://arxiv.org/abs/2511.19854 ,  45053kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19856
Date: Tue, 25 Nov 2025 02:35:48 GMT   (30420kb)

Title: Temporal-Visual Semantic Alignment: A Unified Architecture for
 Transferring Spatial Priors from Vision Models to Zero-Shot Temporal Tasks
Authors: Xiangkai Ma, Han Zhang, Wenzhong Li, Sanglu Lu
Categories: cs.CV
\\
 Large Multimodal Models (LMMs) have achieved remarkable progress in aligning
and generating content across text and image modalities. However, the potential
of using non-visual, continuous sequential, as a conditioning signal for
high-fidelity image generation remains largely unexplored. Furthermore,
existing methods that convert series into "pseudo-images" for temporal
forecasting fail to establish semantic-level alignment. In this paper, we
propose TimeArtist, a temporal-visual conversion framework that pioneers
semantic-level alignment between time series fluctuations and visual concepts.
It pioneers a "warmup-align" paradigm: first, a dual-autoencoder and shared
quantizer are self-supervised trained on large-scale datasets to learn
modality-shared representations. Then, the encoders and quantizer are frozen,
and a projection is introduced to align temporal and visual samples at the
representation level. TimeArtist establishes a versatile cross-modal framework,
enabling high-quality, diverse image generation directly from time series,
while capturing temporal fluctuation patterns to render images as styles
transfer. Extensive experiments show that TimeArtist achieves satisfactory
performance in image generation metrics, while also attaining superior results
in zero-shot temporal tasks. Our work establishes a new paradigm for
cross-modal generation, bridging the gap between temporal dynamics and visual
semantics.
\\ ( https://arxiv.org/abs/2511.19856 ,  30420kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19861
Date: Tue, 25 Nov 2025 03:00:42 GMT   (9996kb)

Title: GigaWorld-0: World Models as Data Engine to Empower Embodied AI
Authors: GigaWorld Team, Angen Ye, Boyuan Wang, Chaojun Ni, Guan Huang,
 Guosheng Zhao, Haoyun Li, Jiagang Zhu, Kerui Li, Mengyuan Xu, Qiuping Deng,
 Siting Wang, Wenkang Qin, Xinze Chen, Xiaofeng Wang, Yankai Wang, Yu Cao,
 Yifan Chang, Yuan Xu, Yun Ye, Yang Wang, Yukun Zhou, Zhengyuan Zhang, Zhehao
 Dong, Zheng Zhu
Categories: cs.CV cs.RO
Comments: Project Page: https://gigaworld0.github.io/
\\
 World models are emerging as a foundational paradigm for scalable,
data-efficient embodied AI. In this work, we present GigaWorld-0, a unified
world model framework designed explicitly as a data engine for
Vision-Language-Action (VLA) learning. GigaWorld-0 integrates two synergistic
components: GigaWorld-0-Video, which leverages large-scale video generation to
produce diverse, texture-rich, and temporally coherent embodied sequences under
fine-grained control of appearance, camera viewpoint, and action semantics; and
GigaWorld-0-3D, which combines 3D generative modeling, 3D Gaussian Splatting
reconstruction, physically differentiable system identification, and executable
motion planning to ensure geometric consistency and physical realism. Their
joint optimization enables the scalable synthesis of embodied interaction data
that is visually compelling, spatially coherent, physically plausible, and
instruction-aligned. Training at scale is made feasible through our efficient
GigaTrain framework, which exploits FP8-precision and sparse attention to
drastically reduce memory and compute requirements. We conduct comprehensive
evaluations showing that GigaWorld-0 generates high-quality, diverse, and
controllable data across multiple dimensions. Critically, VLA model (e.g.,
GigaBrain-0) trained on GigaWorld-0-generated data achieve strong real-world
performance, significantly improving generalization and task success on
physical robots without any real-world interaction during training.
\\ ( https://arxiv.org/abs/2511.19861 ,  9996kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19878
Date: Tue, 25 Nov 2025 03:39:37 GMT   (21457kb)

Title: MAPS: Preserving Vision-Language Representations via Module-Wise
 Proximity Scheduling for Better Vision-Language-Action Generalization
Authors: Chengyue Huang, Mellon M. Zhang, Robert Azarcon, Glen Chou, Zsolt Kira
Categories: cs.CV cs.AI cs.CL cs.LG cs.RO
\\
 Vision-Language-Action (VLA) models inherit strong priors from pretrained
Vision-Language Models (VLMs), but naive fine-tuning often disrupts these
representations and harms generalization. Existing fixes -- freezing modules or
applying uniform regularization -- either overconstrain adaptation or ignore
the differing roles of VLA components. We present MAPS (Module-Wise Proximity
Scheduling), the first robust fine-tuning framework for VLAs. Through
systematic analysis, we uncover an empirical order in which proximity
constraints should be relaxed to balance stability and flexibility. MAPS
linearly schedules this relaxation, enabling visual encoders to stay close to
their pretrained priors while action-oriented language layers adapt more
freely. MAPS introduces no additional parameters or data, and can be seamlessly
integrated into existing VLAs. Across MiniVLA-VQ, MiniVLA-OFT, OpenVLA-OFT, and
challenging benchmarks such as SimplerEnv, CALVIN, LIBERO, as well as
real-world evaluations on the Franka Emika Panda platform, MAPS consistently
boosts both in-distribution and out-of-distribution performance (up to +30%).
Our findings highlight empirically guided proximity to pretrained VLMs as a
simple yet powerful principle for preserving broad generalization in VLM-to-VLA
transfer.
\\ ( https://arxiv.org/abs/2511.19878 ,  21457kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19882
Date: Tue, 25 Nov 2025 03:43:28 GMT   (12172kb)

Title: ChessMamba: Structure-Aware Interleaving of State Spaces for Change
 Detection in Remote Sensing Images
Authors: Lei Ding, Tong Liu, Xuanguang Liu, Xiangyun Liu, Haitao Guo and Jun Lu
Categories: cs.CV
\\
 Change detection (CD) in multitemporal remote sensing imagery presents
significant challenges for fine-grained recognition, owing to heterogeneity and
spatiotemporal misalignment. However, existing methodologies based on vision
transformers or state-space models typically disrupt local structural
consistency during temporal serialization, obscuring discriminative cues under
misalignment and hindering reliable change localization. To address this, we
introduce ChessMamba, a structure-aware framework leveraging interleaved
state-space modeling for robust CD with multi-temporal inputs. ChessMamba
integrates a SpatialMamba encoder with a lightweight cross-source interaction
module, featuring two key innovations: (i) Chessboard interleaving with snake
scanning order, which serializes multi-temporal features into a unified
sequence within a single forward pass, thereby shortening interaction paths and
enabling direct comparison for accurate change localization; and (ii)
Structure-aware fusion via multi-dilated convolutions, selectively capturing
center-and-corner neighborhood contexts within each mono-temporal.
Comprehensive evaluations on three CD tasks, including binary CD, semantic CD
and multimodal building damage assessment, demonstrate that ChessMamba
effectively fuses heterogeneous features and achieves substantial accuracy
improvements over state-of-the-art methods.The relevant code will be available
at: github.com/DingLei14/ChessMamba.
\\ ( https://arxiv.org/abs/2511.19882 ,  12172kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19887
Date: Tue, 25 Nov 2025 03:45:37 GMT   (622kb)

Title: Distilling Cross-Modal Knowledge via Feature Disentanglement
Authors: Junhong Liu, Yuan Zhang, Tao Huang, Wenchao Xu, Renyu Yang
Categories: cs.CV cs.AI
Comments: Accepted by AAAI 2026
\\
 Knowledge distillation (KD) has proven highly effective for compressing large
models and enhancing the performance of smaller ones. However, its
effectiveness diminishes in cross-modal scenarios, such as vision-to-language
distillation, where inconsistencies in representation across modalities lead to
difficult knowledge transfer. To address this challenge, we propose
frequency-decoupled cross-modal knowledge distillation, a method designed to
decouple and balance knowledge transfer across modalities by leveraging
frequency-domain features. We observed that low-frequency features exhibit high
consistency across different modalities, whereas high-frequency features
demonstrate extremely low cross-modal similarity. Accordingly, we apply
distinct losses to these features: enforcing strong alignment in the
low-frequency domain and introducing relaxed alignment for high-frequency
features. We also propose a scale consistency loss to address distributional
shifts between modalities, and employ a shared classifier to unify feature
spaces. Extensive experiments across multiple benchmark datasets show our
method substantially outperforms traditional KD and state-of-the-art
cross-modal KD approaches. Code is available at
https://github.com/Johumliu/FD-CMKD.
\\ ( https://arxiv.org/abs/2511.19887 ,  622kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19889
Date: Tue, 25 Nov 2025 03:52:30 GMT   (8123kb)

Title: LiMT: A Multi-task Liver Image Benchmark Dataset
Authors: Zhe Liu, Kai Han, Siqi Ma, Yan Zhu, Jun Chen, Chongwen Lyu, Xinyi Qiu,
 Chengxuan Qian, Yuqing Song, Yi Liu, Liyuan Tian, Yang Ji, Yuefeng Li
Categories: cs.CV
Comments: IEEE Journal of Biomedical and Health Informatics
\\
 Computer-aided diagnosis (CAD) technology can assist clinicians in evaluating
liver lesions and intervening with treatment in time. Although CAD technology
has advanced in recent years, the application scope of existing datasets
remains relatively limited, typically supporting only single tasks, which has
somewhat constrained the development of CAD technology. To address the above
limitation, in this paper, we construct a multi-task liver dataset (LiMT) used
for liver and tumor segmentation, multi-label lesion classification, and lesion
detection based on arterial phase-enhanced computed tomography (CT),
potentially providing an exploratory solution that is able to explore the
correlation between tasks and does not need to worry about the heterogeneity
between task-specific datasets during training. The dataset includes CT volumes
from 150 different cases, comprising four types of liver diseases as well as
normal cases. Each volume has been carefully annotated and calibrated by
experienced clinicians. This public multi-task dataset may become a valuable
resource for the medical imaging research community in the future. In addition,
this paper not only provides relevant baseline experimental results but also
reviews existing datasets and methods related to liver-related tasks. Our
dataset is available at
https://drive.google.com/drive/folders/1l9HRK13uaOQTNShf5pwgSz3OTanWjkag?usp=sharing.
\\ ( https://arxiv.org/abs/2511.19889 ,  8123kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19899
Date: Tue, 25 Nov 2025 04:14:52 GMT   (16203kb)

Title: VeriSciQA: An Auto-Verified Dataset for Scientific Visual Question
 Answering
Authors: Yuyi Li, Daoyuan Chen, Zhen Wang, Yutong Lu, and Yaliang Li
Categories: cs.CV
\\
 Large Vision-Language Models (LVLMs) show promise for scientific
applications, yet open-source models still struggle with Scientific Visual
Question Answering (SVQA), namely answering questions about figures from
scientific papers. A key bottleneck lies in the lack of public, large-scale,
high-quality SVQA datasets. Although recent work uses LVLMs to synthesize data
at scale, we identify systematic errors in their resulting QA pairs, stemming
from LVLMs' inherent limitations and information asymmetry between figures and
text. To address these challenges, we propose a verification-centric
Generate-then-Verify framework that first generates QA pairs with
figure-associated textual context, then applies cross-modal consistency checks
against figures along with auxiliary filters to eliminate erroneous pairs. We
instantiate this framework to curate VeriSciQA, a dataset of 20,351 QA pairs
spanning 20 scientific domains and 12 figure types. VeriSciQA poses a
challenging benchmark for open-source models, with a substantial accuracy gap
between the leading open-source models (64%) and a proprietary model (82%).
Moreover, models fine-tuned on VeriSciQA achieve consistent improvements on
SVQA benchmarks, with performance gains that scale with data size and surpass
models trained on existing datasets. Human evaluation further validates the
superior correctness of VeriSciQA. Together, these evidences demonstrate that
continued data expansion by our scalable framework can further advance SVQA
capability in the open-source community.
\\ ( https://arxiv.org/abs/2511.19899 ,  16203kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19900
Date: Tue, 25 Nov 2025 04:15:14 GMT   (1809kb)

Title: Agent0-VL: Exploring Self-Evolving Agent for Tool-Integrated
 Vision-Language Reasoning
Authors: Jiaqi Liu, Kaiwen Xiong, Peng Xia, Yiyang Zhou, Haonian Ji, Lu Feng,
 Siwei Han, Mingyu Ding, Huaxiu Yao
Categories: cs.CV cs.AI
\\
 Vision-language agents have achieved remarkable progress in a variety of
multimodal reasoning tasks; however, their learning remains constrained by the
limitations of human-annotated supervision. Recent self-rewarding approaches
attempt to overcome this constraint by allowing models to act as their own
critics or reward providers. Yet, purely text-based self-evaluation struggles
to verify complex visual reasoning steps and often suffers from evaluation
hallucinations. To address these challenges, inspired by recent advances in
tool-integrated reasoning, we propose Agent0-VL, a self-evolving
vision-language agent that achieves continual improvement with tool-integrated
reasoning. Agent0-VL incorporates tool usage not only into reasoning but also
into self-evaluation and self-repair, enabling the model to introspect, verify,
and refine its reasoning through evidence-grounded analysis. It unifies two
synergistic roles within a single LVLM: a Solver that performs multi-turn
tool-integrated reasoning, and a Verifier that generates structured feedback
and fine-grained self-rewards through tool-grounded critique. These roles
interact through a Self-Evolving Reasoning Cycle, where tool-based verification
and reinforcement learning jointly align the reasoning and evaluation
distributions for stable self-improvement. Through this zero-external-reward
evolution, Agent0-VL aligns its reasoning and verification behaviors without
any human annotation or external reward models, achieving continual
self-improvement. Experiments on geometric problem solving and visual
scientific analysis show that Agent0-VL achieves an 12.5% improvement over the
base model. Our code is available at
\href{https://github.com/aiming-lab/Agent0/Agent0-VL}{this https URL}.
\\ ( https://arxiv.org/abs/2511.19900 ,  1809kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19907
Date: Tue, 25 Nov 2025 04:31:12 GMT   (360kb)

Title: MHB: Multimodal Handshape-aware Boundary Detection for Continuous Sign
 Language Recognition
Authors: Mingyu Zhao, Zhanfu Yang, Yang Zhou, Zhaoyang Xia, Can Jin, Xiaoxiao
 He, Carol Neidle, Dimitris N. Metaxas
Categories: cs.CV
\\
 This paper presents a multimodal approach for continuous sign recognition
that first uses machine learning to detect the start and end frames of signs in
videos of American Sign Language (ASL) sentences, and then recognizes the
segmented signs. For improved robustness, we use 3D skeletal features extracted
from sign language videos to capture the convergence of sign properties and
their dynamics, which tend to cluster at sign boundaries. Another focus of this
work is the incorporation of information from 3D handshape for boundary
detection. To detect handshapes normally expected at the beginning and end of
signs, we pretrain a handshape classifier for 87 linguistically defined
canonical handshape categories using a dataset that we created by integrating
and normalizing several existing datasets. A multimodal fusion module is then
used to unify the pretrained sign video segmentation framework and the
handshape classification models. Finally, the estimated boundaries are used for
sign recognition, where the recognition model is trained on a large database
containing both citation-form isolated signs and signs pre-segmented (based on
manual annotations) from continuous signing, as such signs often differ in
certain respects. We evaluate our method on the ASLLRP corpus and demonstrate
significant improvements over previous work.
\\ ( https://arxiv.org/abs/2511.19907 ,  360kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19909
Date: Tue, 25 Nov 2025 04:34:42 GMT   (10051kb)

Title: Motion Marionette: Rethinking Rigid Motion Transfer via Prior Guidance
Authors: Haoxuan Wang, Jiachen Tao, Junyi Wu, Gaowen Liu, Ramana Rao Kompella,
 Yan Yan
Categories: cs.CV
\\
 We present Motion Marionette, a zero-shot framework for rigid motion transfer
from monocular source videos to single-view target images. Previous works
typically employ geometric, generative, or simulation priors to guide the
transfer process, but these external priors introduce auxiliary constraints
that lead to trade-offs between generalizability and temporal consistency. To
address these limitations, we propose guiding the motion transfer process
through an internal prior that exclusively captures the spatial-temporal
transformations and is shared between the source video and any transferred
target video. Specifically, we first lift both the source video and the target
image into a unified 3D representation space. Motion trajectories are then
extracted from the source video to construct a spatial-temporal (SpaT) prior
that is independent of object geometry and semantics, encoding relative spatial
variations over time. This prior is further integrated with the target object
to synthesize a controllable velocity field, which is subsequently refined
using Position-Based Dynamics to mitigate artifacts and enhance visual
coherence. The resulting velocity field can be flexibly employed for efficient
video production. Empirical results demonstrate that Motion Marionette
generalizes across diverse objects, produces temporally consistent videos that
align well with the source motion, and supports controllable video generation.
\\ ( https://arxiv.org/abs/2511.19909 ,  10051kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19912
Date: Tue, 25 Nov 2025 04:40:11 GMT   (3676kb)

Title: Reasoning-VLA: A Fast and General Vision-Language-Action Reasoning Model
 for Autonomous Driving
Authors: Dapeng Zhang, Zhenlong Yuan, Zhangquan Chen, Chih-Ting Liao, Yinda
 Chen, Fei Shen, Qingguo Zhou, Tat-Seng Chua
Categories: cs.CV cs.RO
\\
 Vision-Language-Action (VLA) models have recently shown strong
decision-making capabilities in autonomous driving. However, existing VLAs
often struggle with achieving efficient inference and generalizing to novel
autonomous vehicle configurations and driving scenarios. In this paper, we
propose Reasoning-VLA, a general and fast action-generation VLA framework. The
proposed model employs a set of learnable action queries, initialized via
Gaussian sampling from ground-truth trajectories within the training corpus.
These learnable queries interact with reasoning-enhanced vision-language
features to generate continuous action trajectories in parallel. To promote
robust generalization, we consolidate eight publicly available autonomous
driving datasets into a standardized, Chain-of-Thought reasoning-based, and
easy-to-use data format for model training. Leveraging both supervised learning
and reinforcement learning fine-tuning, extensive empirical evaluations across
multiple benchmarks demonstrate that Reasoning-VLA achieves state-of-the-art
performance, superior generalization capability, and the excellent inference
speed reported to date.
\\ ( https://arxiv.org/abs/2511.19912 ,  3676kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19913
Date: Tue, 25 Nov 2025 04:42:40 GMT   (9311kb)

Title: Coupled Physics-Gated Adaptation: Spatially Decoding Volumetric
 Photochemical Conversion in Complex 3D-Printed Objects
Authors: Maryam Eftekharifar, Churun Zhang, Jialiang Wei, Xudong Cao, Hossein
 Heidari
Categories: cs.CV
\\
 We present a framework that pioneers the prediction of photochemical
conversion in complex three-dimensionally printed objects, introducing a
challenging new computer vision task: predicting dense, non-visual volumetric
physical properties from 3D visual data. This approach leverages the
largest-ever optically printed 3D specimen dataset, comprising a large family
of parametrically designed complex minimal surface structures that have
undergone terminal chemical characterisation. Conventional vision models are
ill-equipped for this task, as they lack an inductive bias for the coupled,
non-linear interactions of optical physics (diffraction, absorption) and
material physics (diffusion, convection) that govern the final chemical state.
To address this, we propose Coupled Physics-Gated Adaptation (C-PGA), a novel
multimodal fusion architecture. Unlike standard concatenation, C-PGA explicitly
models physical coupling by using sparse geometrical and process parameters
(e.g., surface transport, print layer height) as a Query to dynamically gate
and adapt the dense visual features via feature-wise linear modulation (FiLM).
This mechanism spatially modulates dual 3D visual streams-extracted by parallel
3D-CNNs processing raw projection stacks and their diffusion-diffraction
corrected counterparts allowing the model to recalibrate its visual perception
based on the physical context. This approach offers a breakthrough in virtual
chemical characterisation, eliminating the need for traditional post-print
measurements and enabling precise control over the chemical conversion state.
\\ ( https://arxiv.org/abs/2511.19913 ,  9311kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19917
Date: Tue, 25 Nov 2025 04:53:03 GMT   (4096kb)

Title: Scale Where It Matters: Training-Free Localized Scaling for Diffusion
 Models
Authors: Qin Ren, Yufei Wang, Lanqing Guo, Wen Zhang, Zhiwen Fan, Chenyu You
Categories: cs.CV
\\
 Diffusion models have become the dominant paradigm in text-to-image
generation, and test-time scaling (TTS) further improves quality by allocating
more computation during inference. However, existing TTS methods operate at the
full-image level, overlooking the fact that image quality is often spatially
heterogeneous. This leads to unnecessary computation on already satisfactory
regions and insufficient correction of localized defects. In this paper, we
explore a new direction - Localized TTS - that adaptively resamples defective
regions while preserving high-quality regions, thereby substantially reducing
the search space. This paradigm poses two central challenges: accurately
localizing defects and maintaining global consistency. We propose LoTTS, the
first fully training-free framework for localized TTS. For defect localization,
LoTTS contrasts cross- and self-attention signals under quality-aware prompts
(e.g., high-quality vs. low-quality) to identify defective regions, and then
refines them into coherent masks. For consistency, LoTTS perturbs only
defective regions and denoises them locally, ensuring that corrections remain
confined while the rest of the image remains undisturbed. Extensive experiments
on SD2.1, SDXL, and FLUX demonstrate that LoTTS achieves state-of-the-art
performance: it consistently improves both local quality and global fidelity,
while reducing GPU cost by 2-4x compared to Best-of-N sampling. These findings
establish localized TTS as a promising new direction for scaling diffusion
models at inference time.
\\ ( https://arxiv.org/abs/2511.19917 ,  4096kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19919
Date: Tue, 25 Nov 2025 04:53:47 GMT   (19353kb)

Title: HybriDLA: Hybrid Generation for Document Layout Analysis
Authors: Yufan Chen, Omar Moured, Ruiping Liu, Junwei Zheng, Kunyu Peng,
 Jiaming Zhang, Rainer Stiefelhagen
Categories: cs.CV
Comments: Accepted by AAAI 2026 (Oral). Project page at
 https://yufanchen96.github.io/projects/HybriDLA
\\
 Conventional document layout analysis (DLA) traditionally depends on
empirical priors or a fixed set of learnable queries executed in a single
forward pass. While sufficient for early-generation documents with a small,
predetermined number of regions, this paradigm struggles with contemporary
documents, which exhibit diverse element counts and increasingly complex
layouts. To address challenges posed by modern documents, we present HybriDLA,
a novel generative framework that unifies diffusion and autoregressive decoding
within a single layer. The diffusion component iteratively refines bounding-box
hypotheses, whereas the autoregressive component injects semantic and
contextual awareness, enabling precise region prediction even in highly varied
layouts. To further enhance detection quality, we design a multi-scale
feature-fusion encoder that captures both fine-grained and high-level visual
cues. This architecture elevates performance to 83.5% mean Average Precision
(mAP). Extensive experiments on the DocLayNet and M$^6$Doc benchmarks
demonstrate that HybriDLA sets a state-of-the-art performance, outperforming
previous approaches. All data and models will be made publicly available at
https://yufanchen96.github.io/projects/HybriDLA.
\\ ( https://arxiv.org/abs/2511.19919 ,  19353kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19920
Date: Tue, 25 Nov 2025 04:54:49 GMT   (6137kb)

Title: Intelligent Image Search Algorithms Fusing Visual Large Models
Authors: Kehan Wang, Tingqiong Cui, Yang Zhang, Yu Chen, Shifeng Wu, Zhenzhang
 Li
Categories: cs.CV
Comments: 31 pages,7 figures
\\
 Fine-grained image retrieval, which aims to find images containing specific
object components and assess their detailed states, is critical in fields like
security and industrial inspection. However, conventional methods face
significant limitations: manual features (e.g., SIFT) lack robustness; deep
learning-based detectors (e.g., YOLO) can identify component presence but
cannot perform state-specific retrieval or zero-shot search; Visual Large
Models (VLMs) offer semantic and zero-shot capabilities but suffer from poor
spatial grounding and high computational cost, making them inefficient for
direct retrieval. To bridge these gaps, this paper proposes DetVLM, a novel
intelligent image search framework that synergistically fuses object detection
with VLMs. The framework pioneers a search-enhancement paradigm via a two-stage
pipeline: a YOLO detector first conducts efficient, high-recall component-level
screening to determine component presence; then, a VLM acts as a
recall-enhancement unit, performing secondary verification for components
missed by the detector. This architecture directly enables two advanced
capabilities: 1) State Search: Guided by task-specific prompts, the VLM refines
results by verifying component existence and executing sophisticated state
judgments (e.g., "sun visor lowered"), allowing retrieval based on component
state. 2) Zero-shot Search: The framework leverages the VLM's inherent
zero-shot capability to recognize and retrieve images containing unseen
components or attributes (e.g., "driver wearing a mask") without any
task-specific training. Experiments on a vehicle component dataset show DetVLM
achieves a state-of-the-art overall retrieval accuracy of 94.82\%,
significantly outperforming detection-only baselines. It also attains 94.95\%
accuracy in zero-shot search for driver mask-wearing and over 90\% average
accuracy in state search tasks.
\\ ( https://arxiv.org/abs/2511.19920 ,  6137kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19923
Date: Tue, 25 Nov 2025 04:59:55 GMT   (2321kb)

Title: CounterVQA: Evaluating and Improving Counterfactual Reasoning in
 Vision-Language Models for Video Understanding
Authors: Yuefei Chen, Jiang Liu, Xiaodong Lin, Ruixiang Tang
Categories: cs.CV cs.CL
\\
 Vision Language Models (VLMs) have recently shown significant advancements in
video understanding, especially in feature alignment, event reasoning, and
instruction-following tasks. However, their capability for counterfactual
reasoning, inferring alternative outcomes under hypothetical conditions,
remains underexplored. This capability is essential for robust video
understanding, as it requires identifying underlying causal structures and
reasoning about unobserved possibilities, rather than merely recognizing
observed patterns. To systematically evaluate this capability, we introduce
CounterVQA, a video-based benchmark featuring three progressive difficulty
levels that assess different aspects of counterfactual reasoning. Through
comprehensive evaluation of both state-of-the-art open-source and closed-source
models, we uncover a substantial performance gap: while these models achieve
reasonable accuracy on simple counterfactual questions, performance degrades
significantly on complex multi-hop causal chains. To address these limitations,
we develop a post-training method, CFGPT, that enhances a model's visual
counterfactual reasoning ability by distilling its counterfactual reasoning
capability from the language modality, yielding consistent improvements across
all CounterVQA difficulty levels. Dataset and code will be further released.
\\ ( https://arxiv.org/abs/2511.19923 ,  2321kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19928
Date: Tue, 25 Nov 2025 05:12:17 GMT   (27730kb)

Title: Context-Aware Token Pruning and Discriminative Selective Attention for
 Transformer Tracking
Authors: Janani Kugarajeevan, Thanikasalam Kokul, Amirthalingam Ramanan, Subha
 Fernando
Categories: cs.CV
\\
 One-stream Transformer-based trackers have demonstrated remarkable
performance by concatenating template and search region tokens, thereby
enabling joint attention across all tokens. However, enabling an excessive
proportion of background search tokens to attend to the target template tokens
weakens the tracker's discriminative capability. Several token pruning methods
have been proposed to mitigate background interference; however, they often
remove tokens near the target, leading to the loss of essential contextual
information and degraded tracking performance. Moreover, the presence of
distractors within the search tokens further reduces the tracker's ability to
accurately identify the target. To address these limitations, we propose
CPDATrack, a novel tracking framework designed to suppress interference from
background and distractor tokens while enhancing computational efficiency.
First, a learnable module is integrated between two designated encoder layers
to estimate the probability of each search token being associated with the
target. Based on these estimates, less-informative background tokens are pruned
from the search region while preserving the contextual cues surrounding the
target. To further suppress background interference, a discriminative selective
attention mechanism is employed that fully blocks search-to-template attention
in the early layers. In the subsequent encoder layers, high-probability target
tokens are selectively extracted from a localized region to attend to the
template tokens, thereby reducing the influence of background and distractor
tokens. The proposed CPDATrack achieves state-of-the-art performance across
multiple benchmarks, particularly on GOT-10k, where it attains an average
overlap of 75.1 percent.
\\ ( https://arxiv.org/abs/2511.19928 ,  27730kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19936
Date: Tue, 25 Nov 2025 05:21:23 GMT   (773kb)

Title: Image Diffusion Models Exhibit Emergent Temporal Propagation in Videos
Authors: Youngseo Kim, Dohyun Kim, Geohee Han, and Paul Hongsuck Seo
Categories: cs.CV
\\
 Image diffusion models, though originally developed for image generation,
implicitly capture rich semantic structures that enable various recognition and
localization tasks beyond synthesis. In this work, we investigate their
self-attention maps can be reinterpreted as semantic label propagation kernels,
providing robust pixel-level correspondences between relevant image regions.
Extending this mechanism across frames yields a temporal propagation kernel
that enables zero-shot object tracking via segmentation in videos. We further
demonstrate the effectiveness of test-time optimization strategies-DDIM
inversion, textual inversion, and adaptive head weighting-in adapting diffusion
features for robust and consistent label propagation. Building on these
findings, we introduce DRIFT, a framework for object tracking in videos
leveraging a pretrained image diffusion model with SAM-guided mask refinement,
achieving state-of-the-art zero-shot performance on standard video object
segmentation benchmarks.
\\ ( https://arxiv.org/abs/2511.19936 ,  773kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19945
Date: Tue, 25 Nov 2025 05:35:32 GMT   (18586kb)

Title: Low-Resolution Editing is All You Need for High-Resolution Editing
Authors: Junsung Lee, Hyunsoo Lee, Yong Jae Lee, Bohyung Han
Categories: cs.CV
Comments: 14 pages, 8 figures, 2 tables
\\
 High-resolution content creation is rapidly emerging as a central challenge
in both the vision and graphics communities. While images serve as the most
fundamental modality for visual expression, content generation that aligns with
the user intent requires effective, controllable high-resolution image
manipulation mechanisms. However, existing approaches remain limited to
low-resolution settings, typically supporting only up to 1K resolution. In this
work, we introduce the task of high-resolution image editing and propose a
test-time optimization framework to address it. Our method performs patch-wise
optimization on high-resolution source images, followed by a fine-grained
detail transfer module and a novel synchronization strategy to maintain
consistency across patches. Extensive experiments show that our method produces
high-quality edits, facilitating the way toward high-resolution content
creation.
\\ ( https://arxiv.org/abs/2511.19945 ,  18586kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19953
Date: Tue, 25 Nov 2025 05:58:33 GMT   (26819kb)

Title: Supervise Less, See More: Training-free Nuclear Instance Segmentation
 with Prototype-Guided Prompting
Authors: Wen Zhang, Qin Ren, Wenjing Liu, Haibin Ling, Chenyu You
Categories: cs.CV
Comments: Preprint; 40 pages, 25 figures, 18 tables
\\
 Accurate nuclear instance segmentation is a pivotal task in computational
pathology, supporting data-driven clinical insights and facilitating downstream
translational applications. While large vision foundation models have shown
promise for zero-shot biomedical segmentation, most existing approaches still
depend on dense supervision and computationally expensive fine-tuning.
Consequently, training-free methods present a compelling research direction,
yet remain largely unexplored. In this work, we introduce SPROUT, a fully
training- and annotation-free prompting framework for nuclear instance
segmentation. SPROUT leverages histology-informed priors to construct
slide-specific reference prototypes that mitigate domain gaps. These prototypes
progressively guide feature alignment through a partial optimal transport
scheme. The resulting foreground and background features are transformed into
positive and negative point prompts, enabling the Segment Anything Model (SAM)
to produce precise nuclear delineations without any parameter updates.
Extensive experiments across multiple histopathology benchmarks demonstrate
that SPROUT achieves competitive performance without supervision or retraining,
establishing a novel paradigm for scalable, training-free nuclear instance
segmentation in pathology.
\\ ( https://arxiv.org/abs/2511.19953 ,  26819kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19958
Date: Tue, 25 Nov 2025 06:07:26 GMT   (23642kb)

Title: GFT-GCN: Privacy-Preserving 3D Face Mesh Recognition with Spectral
 Diffusion
Authors: Hichem Felouat, Hanrui Wang, Isao Echizen
Categories: cs.CV
Comments: 13 pages, 8 figures, WACV 2026
\\
 3D face recognition offers a robust biometric solution by capturing facial
geometry, providing resilience to variations in illumination, pose changes, and
presentation attacks. Its strong spoof resistance makes it suitable for
high-security applications, but protecting stored biometric templates remains
critical. We present GFT-GCN, a privacy-preserving 3D face recognition
framework that combines spectral graph learning with diffusion-based template
protection. Our approach integrates the Graph Fourier Transform (GFT) and Graph
Convolutional Networks (GCN) to extract compact, discriminative spectral
features from 3D face meshes. To secure these features, we introduce a spectral
diffusion mechanism that produces irreversible, renewable, and unlinkable
templates. A lightweight client-server architecture ensures that raw biometric
data never leaves the client device. Experiments on the BU-3DFE and FaceScape
datasets demonstrate high recognition accuracy and strong resistance to
reconstruction attacks. Results show that GFT-GCN effectively balances privacy
and performance, offering a practical solution for secure 3D face
authentication.
\\ ( https://arxiv.org/abs/2511.19958 ,  23642kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19963
Date: Tue, 25 Nov 2025 06:18:18 GMT   (2652kb)

Title: MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential
 Processing
Authors: Changho Choi and Minho Kim and Jinkyu Kim
Categories: cs.CV cs.AI
Comments: Code will be released in github
\\
 Despite decades of progress, a truly input-size agnostic visual encoder-a
fundamental characteristic of human vision-has remained elusive. We address
this limitation by proposing \textbf{MambaEye}, a novel, causal sequential
encoder that leverages the low complexity and causal-process based pure Mamba2
backbone. Unlike previous Mamba-based vision encoders that often employ
bidirectional processing, our strictly unidirectional approach preserves the
inherent causality of State Space Models, enabling the model to generate a
prediction at any point in its input sequence. A core innovation is our use of
relative move embedding, which encodes the spatial shift between consecutive
patches, providing a strong inductive bias for translation invariance and
making the model inherently adaptable to arbitrary image resolutions and
scanning patterns. To achieve this, we introduce a novel diffusion-inspired
loss function that provides dense, step-wise supervision, training the model to
build confidence as it gathers more visual evidence. We demonstrate that
MambaEye exhibits robust performance across a wide range of image resolutions,
especially at higher resolutions such as $1536^2$ on the ImageNet-1K
classification task. This feat is achieved while maintaining linear time and
memory complexity relative to the number of patches.
\\ ( https://arxiv.org/abs/2511.19963 ,  2652kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19965
Date: Tue, 25 Nov 2025 06:24:25 GMT   (4258kb)

Title: HiCoGen: Hierarchical Compositional Text-to-Image Generation in
 Diffusion Models via Reinforcement Learning
Authors: Hongji Yang, Yucheng Zhou, Wencheng Han, Runzhou Tao, Zhongying Qiu,
 Jianfei Yang, Jianbing Shen
Categories: cs.CV
Comments: 9 pages
\\
 Recent advances in diffusion models have demonstrated impressive capability
in generating high-quality images for simple prompts. However, when confronted
with complex prompts involving multiple objects and hierarchical structures,
existing models struggle to accurately follow instructions, leading to issues
such as concept omission, confusion, and poor compositionality. To address
these limitations, we propose a Hierarchical Compositional Generative framework
(HiCoGen) built upon a novel Chain of Synthesis (CoS) paradigm. Instead of
monolithic generation, HiCoGen first leverages a Large Language Model (LLM) to
decompose complex prompts into minimal semantic units. It then synthesizes
these units iteratively, where the image generated in each step provides
crucial visual context for the next, ensuring all textual concepts are
faithfully constructed into the final scene. To further optimize this process,
we introduce a reinforcement learning (RL) framework. Crucially, we identify
that the limited exploration of standard diffusion samplers hinders effective
RL. We theoretically prove that sample diversity is maximized by concentrating
stochasticity in the early generation stages and, based on this insight,
propose a novel Decaying Stochasticity Schedule to enhance exploration. Our RL
algorithm is then guided by a hierarchical reward mechanism that jointly
evaluates the image at the global, subject, and relationship levels. We also
construct HiCoPrompt, a new text-to-image benchmark with hierarchical prompts
for rigorous evaluation. Experiments show our approach significantly
outperforms existing methods in both concept coverage and compositional
accuracy.
\\ ( https://arxiv.org/abs/2511.19965 ,  4258kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19971
Date: Tue, 25 Nov 2025 06:30:22 GMT   (8328kb)

Title: VGGT4D: Mining Motion Cues in Visual Geometry Transformers for 4D Scene
 Reconstruction
Authors: Yu Hu, Chong Cheng, Sicheng Yu, Xiaoyang Guo, Hao Wang
Categories: cs.CV
\\
 Reconstructing dynamic 4D scenes is challenging, as it requires robust
disentanglement of dynamic objects from the static background. While 3D
foundation models like VGGT provide accurate 3D geometry, their performance
drops markedly when moving objects dominate. Existing 4D approaches often rely
on external priors, heavy post-optimization, or require fine-tuning on 4D
datasets. In this paper, we propose VGGT4D, a training-free framework that
extends the 3D foundation model VGGT for robust 4D scene reconstruction. Our
approach is motivated by the key finding that VGGT's global attention layers
already implicitly encode rich, layer-wise dynamic cues. To obtain masks that
decouple static and dynamic elements, we mine and amplify global dynamic cues
via gram similarity and aggregate them across a temporal window. To further
sharpen mask boundaries, we introduce a refinement strategy driven by
projection gradient. We then integrate these precise masks into VGGT's
early-stage inference, effectively mitigating motion interference in both pose
estimation and geometric reconstruction. Across six datasets, our method
achieves superior performance in dynamic object segmentation, camera pose
estimation, and dense reconstruction. It also supports single-pass inference on
sequences longer than 500 frames.
\\ ( https://arxiv.org/abs/2511.19971 ,  8328kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19972
Date: Tue, 25 Nov 2025 06:31:57 GMT   (2036kb)

Title: Boosting Reasoning in Large Multimodal Models via Activation Replay
Authors: Yun Xing, Xiaobin Hu, Qingdong He, Jiangning Zhang, Shuicheng Yan,
 Shijian Lu, Yu-Gang Jiang
Categories: cs.CV
Comments: 11 figures, 10 tables
\\
 Recently, Reinforcement Learning with Verifiable Rewards (RLVR) has emerged
as an effective approach to incentivizing reasoning capability in Large
Multimodal Models (LMMs), while the underlying mechanisms behind this
post-training paradigm are poorly understood. We begin by exploring how input
activations are affected by RLVR through the perspective of logit lens. Our
systematic investigations across multiple post-trained LMMs suggest that RLVR
shifts low-entropy activations unexpectedly, while high-entropy ones are less
affected. We further demonstrate that such phenomena are associated with LMM
reasoning by controlled experiments, suggesting a potentially beneficial role
of modulating low-entropy activations. To this end, we propose Activation
Replay, a novel simple yet effective training-free approach that boosts
multimodal reasoning of post-trained LMMs without requiring expensive policy
optimization. Our design involves manipulation of visual tokens at test time,
replaying low-entropy activations from the input context of base LMMs to
regulating the RLVR counterparts. Activation Replay triggers better reasoning
across diverse scenarios, including mathematics, o3-like visual agents, and
video reasoning. We further show that Activation Replay boosts Pass@K and
mitigates narrower reasoning coverage of RLVR. Our design is compared against
alternative choices, such as replaying high-entropy activations instead of
low-entropy ones, or direct cross-model intervention instead of manipulating
input tokens, demonstrating the superiority of our implementation. Codes will
be made publicly available.
\\ ( https://arxiv.org/abs/2511.19972 ,  2036kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19982
Date: Tue, 25 Nov 2025 06:51:15 GMT   (5806kb)

Title: EmoFeedback2: Reinforcement of Continuous Emotional Image Generation via
 LVLM-based Reward and Textual Feedback
Authors: Jingyang Jia, Kai Shu, Gang Yang, Long Xing, Xun Chen, Aiping Liu
Categories: cs.CV cs.AI
\\
 Continuous emotional image generation (C-EICG) is emerging rapidly due to its
ability to produce images aligned with both user descriptions and continuous
emotional values. However, existing approaches lack emotional feedback from
generated images, limiting the control of emotional continuity. Additionally,
their simple alignment between emotions and naively generated texts fails to
adaptively adjust emotional prompts according to image content, leading to
insufficient emotional fidelity. To address these concerns, we propose a novel
generation-understanding-feedback reinforcement paradigm (EmoFeedback2) for
C-EICG, which exploits the reasoning capability of the fine-tuned large
vision-language model (LVLM) to provide reward and textual feedback for
generating high-quality images with continuous emotions. Specifically, we
introduce an emotion-aware reward feedback strategy, where the LVLM evaluates
the emotional values of generated images and computes the reward against target
emotions, guiding the reinforcement fine-tuning of the generative model and
enhancing the emotional continuity of images. Furthermore, we design a
self-promotion textual feedback framework, in which the LVLM iteratively
analyzes the emotional content of generated images and adaptively produces
refinement suggestions for the next-round prompt, improving the emotional
fidelity with fine-grained content. Extensive experimental results demonstrate
that our approach effectively generates high-quality images with the desired
emotions, outperforming existing state-of-the-art methods in our custom
dataset. The code and dataset will be released soon.
\\ ( https://arxiv.org/abs/2511.19982 ,  5806kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19985
Date: Tue, 25 Nov 2025 06:53:48 GMT   (33014kb)

Title: SONIC: Spectral Optimization of Noise for Inpainting with Consistency
Authors: Seungyeon Baek, Erqun Dong, Shadan Namazifard, Mark J. Matthews, Kwang
 Moo Yi
Categories: cs.CV
\\
 We propose a novel training-free method for inpainting with off-the-shelf
text-to-image models. While guidance-based methods in theory allow generic
models to be used for inverse problems such as inpainting, in practice, their
effectiveness is limited, leading to the necessity of specialized
inpainting-specific models. In this work, we argue that the missing ingredient
for training-free inpainting is the optimization (guidance) of the initial seed
noise. We propose to optimize the initial seed noise to approximately match the
unmasked parts of the data - with as few as a few tens of optimization steps.
We then apply conventional training-free inpainting methods on top of our
optimized initial seed noise. Critically, we propose two core ideas to
effectively implement this idea: (i) to avoid the costly unrolling required to
relate the initial noise and the generated outcome, we perform linear
approximation; and (ii) to stabilize the optimization, we optimize the initial
seed noise in the spectral domain. We demonstrate the effectiveness of our
method on various inpainting tasks, outperforming the state of the art. Project
page: https://ubc-vision.github.io/sonic/
\\ ( https://arxiv.org/abs/2511.19985 ,  33014kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19988
Date: Tue, 25 Nov 2025 06:55:39 GMT   (1082kb)

Title: GazeProphetV2: Head-Movement-Based Gaze Prediction Enabling Efficient
 Foveated Rendering on Mobile VR
Authors: Farhaan Ebadulla, Chiraag Mudlpaur, Shreya Chaurasia, Gaurav BV
Categories: cs.CV
\\
 Predicting gaze behavior in virtual reality environments remains a
significant challenge with implications for rendering optimization and
interface design. This paper introduces a multimodal approach to VR gaze
prediction that combines temporal gaze patterns, head movement data, and visual
scene information. By leveraging a gated fusion mechanism with cross-modal
attention, the approach learns to adaptively weight gaze history, head
movement, and scene content based on contextual relevance. Evaluations using a
dataset spanning 22 VR scenes with 5.3M gaze samples demonstrate improvements
in predictive accuracy when combining modalities compared to using individual
data streams alone. The results indicate that integrating past gaze
trajectories with head orientation and scene content enhances prediction
accuracy across 1-3 future frames. Cross-scene generalization testing shows
consistent performance with 93.1% validation accuracy and temporal consistency
in predicted gaze trajectories. These findings contribute to understanding
attention mechanisms in virtual environments while suggesting potential
applications in rendering optimization, interaction design, and user experience
evaluation. The approach represents a step toward more efficient virtual
reality systems that can anticipate user attention patterns without requiring
expensive eye tracking hardware.
\\ ( https://arxiv.org/abs/2511.19988 ,  1082kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19990
Date: Tue, 25 Nov 2025 06:57:49 GMT   (44240kb)

Title: OmniRefiner: Reinforcement-Guided Local Diffusion Refinement
Authors: Yaoli Liu, Ziheng Ouyang, Shengtao Lou, Yiren Song
Categories: cs.CV
\\
 Reference-guided image generation has progressed rapidly, yet current
diffusion models still struggle to preserve fine-grained visual details when
refining a generated image using a reference. This limitation arises because
VAE-based latent compression inherently discards subtle texture information,
causing identity- and attribute-specific cues to vanish. Moreover, post-editing
approaches that amplify local details based on existing methods often produce
results inconsistent with the original image in terms of lighting, texture, or
shape. To address this, we introduce \ourMthd{}, a detail-aware refinement
framework that performs two consecutive stages of reference-driven correction
to enhance pixel-level consistency. We first adapt a single-image diffusion
editor by fine-tuning it to jointly ingest the draft image and the reference
image, enabling globally coherent refinement while maintaining structural
fidelity. We then apply reinforcement learning to further strengthen localized
editing capability, explicitly optimizing for detail accuracy and semantic
consistency. Extensive experiments demonstrate that \ourMthd{} significantly
improves reference alignment and fine-grained detail preservation, producing
faithful and visually coherent edits that surpass both open-source and
commercial models on challenging reference-guided restoration benchmarks.
\\ ( https://arxiv.org/abs/2511.19990 ,  44240kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19995
Date: Tue, 25 Nov 2025 07:00:42 GMT   (7806kb)

Title: CREward: A Type-Specific Creativity Reward Model
Authors: Jiyeon Han, Ali Mahdavi-Amiri, Hao Zhang, and Haedong Jeong
Categories: cs.CV
\\
 Creativity is a complex phenomenon. When it comes to representing and
assessing creativity, treating it as a single undifferentiated quantity would
appear naive and underwhelming. In this work, we learn the \emph{first
type-specific creativity reward model}, coined CREward, which spans three
creativity ``axes," geometry, material, and texture, to allow us to view
creativity through the lens of the image formation pipeline. To build our
reward model, we first conduct a human benchmark evaluation to capture human
perception of creativity for each type across various creative images. We then
analyze the correlation between human judgments and predictions by large
vision-language models (LVLMs), confirming that LVLMs exhibit strong alignment
with human perception. Building on this observation, we collect LVLM-generated
labels to train our CREward model that is applicable to both evaluation and
generation of creative images. We explore three applications of CREward:
creativity assessment, explainable creativity, and creative sample acquisition
for both human design inspiration and guiding creative generation through
low-rank adaptation.
\\ ( https://arxiv.org/abs/2511.19995 ,  7806kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20002
Date: Tue, 25 Nov 2025 07:13:13 GMT   (10395kb)

Title: On the Feasibility of Hijacking MLLMs' Decision Chain via One
 Perturbation
Authors: Changyue Li, Jiaying Li, Youliang Yuan, Jiaming He, Zhicong Huang and
 Pinjia He
Categories: cs.CV cs.AI cs.CR
\\
 Conventional adversarial attacks focus on manipulating a single decision of
neural networks. However, real-world models often operate in a sequence of
decisions, where an isolated mistake can be easily corrected, but cascading
errors can lead to severe risks.
 This paper reveals a novel threat: a single perturbation can hijack the whole
decision chain. We demonstrate the feasibility of manipulating a model's
outputs toward multiple, predefined outcomes, such as simultaneously
misclassifying "non-motorized lane" signs as "motorized lane" and "pedestrian"
as "plastic bag".
 To expose this threat, we introduce Semantic-Aware Universal Perturbations
(SAUPs), which induce varied outcomes based on the semantics of the inputs. We
overcome optimization challenges by developing an effective algorithm, which
searches for perturbations in normalized space with a semantic separation
strategy. To evaluate the practical threat of SAUPs, we present RIST, a new
real-world image dataset with fine-grained semantic annotations. Extensive
experiments on three multimodal large language models demonstrate their
vulnerability, achieving a 70% attack success rate when controlling five
distinct targets using just an adversarial frame.
\\ ( https://arxiv.org/abs/2511.20002 ,  10395kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20008
Date: Tue, 25 Nov 2025 07:18:12 GMT   (1770kb)

Title: Pedestrian Crossing Intention Prediction Using Multimodal Fusion Network
Authors: Yuanzhe Li and Steffen M\"uller
Categories: cs.CV cs.AI
\\
 Pedestrian crossing intention prediction is essential for the deployment of
autonomous vehicles (AVs) in urban environments. Ideal prediction provides AVs
with critical environmental cues, thereby reducing the risk of
pedestrian-related collisions. However, the prediction task is challenging due
to the diverse nature of pedestrian behavior and its dependence on multiple
contextual factors. This paper proposes a multimodal fusion network that
leverages seven modality features from both visual and motion branches, aiming
to effectively extract and integrate complementary cues across different
modalities. Specifically, motion and visual features are extracted from the raw
inputs using multiple Transformer-based extraction modules. Depth-guided
attention module leverages depth information to guide attention towards salient
regions in another modality through comprehensive spatial feature interactions.
To account for the varying importance of different modalities and frames,
modality attention and temporal attention are designed to selectively emphasize
informative modalities and effectively capture temporal dependencies. Extensive
experiments on the JAAD dataset validate the effectiveness of the proposed
network, achieving superior performance compared to the baseline methods.
\\ ( https://arxiv.org/abs/2511.20008 ,  1770kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20011
Date: Tue, 25 Nov 2025 07:24:49 GMT   (2367kb)

Title: Multi-Context Fusion Transformer for Pedestrian Crossing Intention
 Prediction in Urban Environments
Authors: Yuanzhe Li, Hang Zhong, Steffen M\"uller
Categories: cs.CV cs.AI
\\
 Pedestrian crossing intention prediction is essential for autonomous vehicles
to improve pedestrian safety and reduce traffic accidents. However, accurate
pedestrian intention prediction in urban environments remains challenging due
to the multitude of factors affecting pedestrian behavior. In this paper, we
propose a multi-context fusion Transformer (MFT) that leverages diverse
numerical contextual attributes across four key dimensions, encompassing
pedestrian behavior context, environmental context, pedestrian localization
context and vehicle motion context, to enable accurate pedestrian intention
prediction. MFT employs a progressive fusion strategy, where mutual
intra-context attention enables reciprocal interactions within each context,
thereby facilitating feature sequence fusion and yielding a context token as a
context-specific representation. This is followed by mutual cross-context
attention, which integrates features across contexts with a global CLS token
serving as a compact multi-context representation. Finally, guided
intra-context attention refines context tokens within each context through
directed interactions, while guided cross-context attention strengthens the
global CLS token to promote multi-context fusion via guided information
propagation, yielding deeper and more efficient integration. Experimental
results validate the superiority of MFT over state-of-the-art methods,
achieving accuracy rates of 73%, 93%, and 90% on the JAADbeh, JAADall, and PIE
datasets, respectively. Extensive ablation studies are further conducted to
investigate the effectiveness of the network architecture and contribution of
different input context. Our code is open-source:
https://github.com/ZhongHang0307/Multi-Context-Fusion-Transformer.
\\ ( https://arxiv.org/abs/2511.20011 ,  2367kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20020
Date: Tue, 25 Nov 2025 07:41:11 GMT   (1818kb)

Title: ACIT: Attention-Guided Cross-Modal Interaction Transformer for
 Pedestrian Crossing Intention Prediction
Authors: Yuanzhe Li and Steffen M\"uller
Categories: cs.CV
\\
 Predicting pedestrian crossing intention is crucial for autonomous vehicles
to prevent pedestrian-related collisions. However, effectively extracting and
integrating complementary cues from different types of data remains one of the
major challenges. This paper proposes an attention-guided cross-modal
interaction Transformer (ACIT) for pedestrian crossing intention prediction.
ACIT leverages six visual and motion modalities, which are grouped into three
interaction pairs: (1) Global semantic map and global optical flow, (2) Local
RGB image and local optical flow, and (3) Ego-vehicle speed and pedestrian's
bounding box. Within each visual interaction pair, a dual-path attention
mechanism enhances salient regions within the primary modality through
intra-modal self-attention and facilitates deep interactions with the auxiliary
modality (i.e., optical flow) via optical flow-guided attention. Within the
motion interaction pair, cross-modal attention is employed to model the
cross-modal dynamics, enabling the effective extraction of complementary motion
features. Beyond pairwise interactions, a multi-modal feature fusion module
further facilitates cross-modal interactions at each time step. Furthermore, a
Transformer-based temporal feature aggregation module is introduced to capture
sequential dependencies. Experimental results demonstrate that ACIT outperforms
state-of-the-art methods, achieving accuracy rates of 70% and 89% on the
JAADbeh and JAADall datasets, respectively. Extensive ablation studies are
further conducted to investigate the contribution of different modules of ACIT.
\\ ( https://arxiv.org/abs/2511.20020 ,  1818kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20022
Date: Tue, 25 Nov 2025 07:47:27 GMT   (11397kb)

Title: WaymoQA: A Multi-View Visual Question Answering Dataset for
 Safety-Critical Reasoning in Autonomous Driving
Authors: Seungjun Yu, Seonho Lee, Namho Kim, Jaeyo Shin, Junsung Park, Wonjeong
 Ryu, Raehyuk Jung, Hyunjung Shim
Categories: cs.CV cs.AI
\\
 Recent advancements in multimodal large language models (MLLMs) have shown
strong understanding of driving scenes, drawing interest in their application
to autonomous driving. However, high-level reasoning in safety-critical
scenarios, where avoiding one traffic risk can create another, remains a major
challenge. Such reasoning is often infeasible with only a single front view and
requires a comprehensive view of the environment, which we achieve through
multi-view inputs. We define Safety-Critical Reasoning as a new task that
leverages multi-view inputs to address this challenge. Then, we distill
Safety-Critical Reasoning into two stages: first resolve the immediate risk,
then mitigate the decision-induced downstream risks. To support this, we
introduce WaymoQA, a dataset of 35,000 human-annotated question-answer pairs
covering complex, high-risk driving scenarios. The dataset includes
multiple-choice and open-ended formats across both image and video modalities.
Experiments reveal that existing MLLMs underperform in safety-critical
scenarios compared to normal scenes, but fine-tuning with WaymoQA significantly
improves their reasoning ability, highlighting the effectiveness of our dataset
in developing safer and more reasoning-capable driving agents.
\\ ( https://arxiv.org/abs/2511.20022 ,  11397kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20027
Date: Tue, 25 Nov 2025 07:52:07 GMT   (8483kb)

Title: SAM-MI: A Mask-Injected Framework for Enhancing Open-Vocabulary Semantic
 Segmentation with SAM
Authors: Lin Chen, Yingjian Zhu, Qi Yang, Xin Niu, Kun Ding, Shiming Xiang
Categories: cs.CV
DOI: 10.1007/s11633-025-1615-8
\\
 Open-vocabulary semantic segmentation (OVSS) aims to segment and recognize
objects universally. Trained on extensive high-quality segmentation data, the
segment anything model (SAM) has demonstrated remarkable universal segmentation
capabilities, offering valuable support for OVSS. Although previous methods
have made progress in leveraging SAM for OVSS, there are still some challenges:
(1) SAM's tendency to over-segment and (2) hard combinations between fixed
masks and labels. This paper introduces a novel mask-injected framework,
SAM-MI, which effectively integrates SAM with OVSS models to address these
challenges. Initially, SAM-MI employs a Text-guided Sparse Point Prompter to
sample sparse prompts for SAM instead of previous dense grid-like prompts, thus
significantly accelerating the mask generation process. The framework then
introduces Shallow Mask Aggregation (SMAgg) to merge partial masks to mitigate
the SAM's over-segmentation issue. Finally, Decoupled Mask Injection (DMI)
incorporates SAM-generated masks for guidance at low-frequency and
high-frequency separately, rather than directly combining them with labels.
Extensive experiments on multiple benchmarks validate the superiority of
SAM-MI. Notably, the proposed method achieves a 16.7% relative improvement in
mIoU over Grounded-SAM on the MESS benchmark, along with a 1.6$\times$ speedup.
We hope SAM-MI can serve as an alternative methodology to effectively equip the
OVSS model with SAM.
\\ ( https://arxiv.org/abs/2511.20027 ,  8483kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20032
Date: Tue, 25 Nov 2025 07:58:57 GMT   (11035kb)

Title: Tell Model Where to Look: Mitigating Hallucinations in MLLMs by
 Vision-Guided Attention
Authors: Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng, Zhixing Tan
Categories: cs.CV
Comments: Under Review
\\
 Visual attention serves as the primary mechanism through which MLLMs
interpret visual information; however, its limited localization capability
often leads to hallucinations. We observe that although MLLMs can accurately
extract visual semantics from visual tokens, they fail to fully leverage this
advantage during subsequent inference. To address this limitation, we propose
Vision-Guided Attention (VGA), a training-free method that first constructs
precise visual grounding by exploiting the semantic content of visual tokens,
and then uses this grounding to guide the model's focus toward relevant visual
regions. In image captioning, VGA further refines this guidance dynamically
during generation by suppressing regions that have already been described. In
VGA, each token undergoes only a single forward pass, introducing a negligible
latency overhead of just 4.36\%. In addition, VGA is fully compatible with
efficient attention implementations such as FlashAttention. Extensive
experiments across diverse MLLMs and multiple hallucination benchmarks
demonstrate that VGA achieves state-of-the-art dehallucination performance.
Further analysis confirms that explicit visual guidance plays a crucial role in
enhancing the visual understanding capabilities of MLLMs.
\\ ( https://arxiv.org/abs/2511.20032 ,  11035kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20034
Date: Tue, 25 Nov 2025 08:01:04 GMT   (31274kb)

Title: Clair Obscur: an Illumination-Aware Method for Real-World Image
 Vectorization
Authors: Xingyue Lin, Shuai Peng, Xiangyu Xie, Jianhua Zhu, Yuxuan Zhou,
 Liangcai Gao
Categories: cs.CV
\\
 Image vectorization aims to convert raster images into editable, scalable
vector representations while preserving visual fidelity. Existing vectorization
methods struggle to represent complex real-world images, often producing
fragmented shapes at the cost of semantic conciseness. In this paper, we
propose COVec, an illumination-aware vectorization framework inspired by the
Clair-Obscur principle of light-shade contrast. COVec is the first to introduce
intrinsic image decomposition in the vector domain, separating an image into
albedo, shade, and light layers in a unified vector representation. A
semantic-guided initialization and two-stage optimization refine these layers
with differentiable rendering. Experiments on various datasets demonstrate that
COVec achieves higher visual fidelity and significantly improved editability
compared to existing methods.
\\ ( https://arxiv.org/abs/2511.20034 ,  31274kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20041
Date: Tue, 25 Nov 2025 08:10:56 GMT   (3620kb)

Title: MFM-point: Multi-scale Flow Matching for Point Cloud Generation
Authors: Petr Molodyk, Jaemoo Choi, David W. Romero, Ming-Yu Liu, Yongxin Chen
Categories: cs.CV cs.AI cs.LG
\\
 In recent years, point cloud generation has gained significant attention in
3D generative modeling. Among existing approaches, point-based methods directly
generate point clouds without relying on other representations such as latent
features, meshes, or voxels. These methods offer low training cost and
algorithmic simplicity, but often underperform compared to representation-based
approaches. In this paper, we propose MFM-Point, a multi-scale Flow Matching
framework for point cloud generation that substantially improves the
scalability and performance of point-based methods while preserving their
simplicity and efficiency. Our multi-scale generation algorithm adopts a
coarse-to-fine generation paradigm, enhancing generation quality and
scalability without incurring additional training or inference overhead. A key
challenge in developing such a multi-scale framework lies in preserving the
geometric structure of unordered point clouds while ensuring smooth and
consistent distributional transitions across resolutions. To address this, we
introduce a structured downsampling and upsampling strategy that preserves
geometry and maintains alignment between coarse and fine resolutions. Our
experimental results demonstrate that MFM-Point achieves best-in-class
performance among point-based methods and challenges the best
representation-based methods. In particular, MFM-point demonstrates strong
results in multi-category and high-resolution generation tasks.
\\ ( https://arxiv.org/abs/2511.20041 ,  3620kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20045
Date: Tue, 25 Nov 2025 08:13:15 GMT   (5967kb)

Title: History-Augmented Contrastive Meta-Learning for Unsupervised Blind
 Super-Resolution of Planetary Remote Sensing Images
Authors: Huijia Zhao, Jie Lu, Yunqing Jiang, Xiao-Ping Lu, Kaichang Di
Categories: cs.CV
Comments: 13pages
\\
 Planetary remote sensing images are affected by diverse and unknown
degradations caused by imaging environments and hardware constraints. These
factors limit image quality and hinder supervised blind super-resolution due to
the lack of ground-truth images. This work presents History-Augmented
Contrastive Blind Super-Resolution (HACBSR), an unsupervised framework for
blind super-resolution that operates without ground-truth images and external
kernel priors. HACBSR comprises two components: (1) a contrastive kernel
sampling mechanism with kernel similarity control to mitigate distribution bias
from Gaussian sampling, and (2) a history-augmented contrastive learning that
uses historical models to generate negative samples to enable less greedy
optimization and to induce strong convexity without ground-truth. A convergence
analysis of the history-augmented contrastive learning is given in the
Appendix. To support evaluation in planetary applications, we introduce
Ceres-50, a dataset with diverse geological features simulated degradation
patterns. Experiments show that HACBSR achieves competitive performance
compared with state-of-the-art unsupervised methods across multiple upscaling
factors. The code is available at https://github.com/2333repeat/HACBSR, and the
dataset is available at https://github.com/2333repeat/Ceres-50.
\\ ( https://arxiv.org/abs/2511.20045 ,  5967kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20058
Date: Tue, 25 Nov 2025 08:29:03 GMT   (14620kb)

Title: DeLightMono: Enhancing Self-Supervised Monocular Depth Estimation in
 Endoscopy by Decoupling Uneven Illumination
Authors: Mingyang Ou, Haojin Li, Yifeng Zhang, Ke Niu, Zhongxi Qiu, Heng Li,
 Jiang Liu
Categories: cs.CV
\\
 Self-supervised monocular depth estimation serves as a key task in the
development of endoscopic navigation systems. However, performance degradation
persists due to uneven illumination inherent in endoscopic images, particularly
in low-intensity regions. Existing low-light enhancement techniques fail to
effectively guide the depth network. Furthermore, solutions from other fields,
like autonomous driving, require well-lit images, making them unsuitable and
increasing data collection burdens. To this end, we present DeLight-Mono - a
novel self-supervised monocular depth estimation framework with illumination
decoupling. Specifically, endoscopic images are represented by a designed
illumination-reflectance-depth model, and are decomposed with auxiliary
networks. Moreover, a self-supervised joint-optimizing framework with novel
losses leveraging the decoupled components is proposed to mitigate the effects
of uneven illumination on depth estimation. The effectiveness of the proposed
methods was rigorously verified through extensive comparisons and an ablation
study performed on two public datasets.
\\ ( https://arxiv.org/abs/2511.20058 ,  14620kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20065
Date: Tue, 25 Nov 2025 08:37:49 GMT   (8638kb)

Title: FLaTEC: Frequency-Disentangled Latent Triplanes for Efficient
 Compression of LiDAR Point Clouds
Authors: Xiaoge Zhang, Zijie Wu, Mingtao Feng, Zichen Geng, Mehwish Nasim,
 Saeed Anwar, Ajmal Mian
Categories: cs.CV
\\
 Point cloud compression methods jointly optimize bitrates and reconstruction
distortion. However, balancing compression ratio and reconstruction quality is
difficult because low-frequency and high-frequency components contribute
differently at the same resolution. To address this, we propose FLaTEC, a
frequency-aware compression model that enables the compression of a full scan
with high compression ratios. Our approach introduces a frequency-aware
mechanism that decouples low-frequency structures and high-frequency textures,
while hybridizing latent triplanes as a compact proxy for point cloud.
Specifically, we convert voxelized embeddings into triplane representations to
reduce sparsity, computational cost, and storage requirements. We then devise a
frequency-disentangling technique that extracts compact low-frequency content
while collecting high-frequency details across scales. The decoupled
low-frequency and high-frequency components are stored in binary format. During
decoding, full-spectrum signals are progressively recovered via a modulation
block. Additionally, to compensate for the loss of 3D correlation, we introduce
an efficient frequency-based attention mechanism that fosters local
connectivity and outputs arbitrary resolution points. Our method achieves
state-of-the-art rate-distortion performance and outperforms the standard
codecs by 78\% and 94\% in BD-rate on both SemanticKITTI and Ford datasets.
\\ ( https://arxiv.org/abs/2511.20065 ,  8638kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20068
Date: Tue, 25 Nov 2025 08:40:48 GMT   (35919kb)

Title: PRADA: Probability-Ratio-Based Attribution and Detection of
 Autoregressive-Generated Images
Authors: Simon Damm, Jonas Ricker, Henning Petzka, Asja Fischer
Categories: cs.CV
\\
 Autoregressive (AR) image generation has recently emerged as a powerful
paradigm for image synthesis. Leveraging the generation principle of large
language models, they allow for efficiently generating deceptively real-looking
images, further increasing the need for reliable detection methods. However, to
date there is a lack of work specifically targeting the detection of images
generated by AR image generators. In this work, we present PRADA
(Probability-Ratio-Based Attribution and Detection of Autoregressive-Generated
Images), a simple and interpretable approach that can reliably detect
AR-generated images and attribute them to their respective source model. The
key idea is to inspect the ratio of a model's conditional and unconditional
probability for the autoregressive token sequence representing a given image.
Whenever an image is generated by a particular model, its probability ratio
shows unique characteristics which are not present for images generated by
other models or real images. We exploit these characteristics for
threshold-based attribution and detection by calibrating a simple,
model-specific score function. Our experimental evaluation shows that PRADA is
highly effective against eight class-to-image and four text-to-image models.
\\ ( https://arxiv.org/abs/2511.20068 ,  35919kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20073
Date: Tue, 25 Nov 2025 08:46:11 GMT   (7479kb)

Title: Learning Procedural-aware Video Representations through State-Grounded
 Hierarchy Unfolding
Authors: Jinghan Zhao, Yifei Huang, Feng Lu
Categories: cs.CV
Comments: Accepted by AAAI 2026. 15 pages, 12 figures
\\
 Learning procedural-aware video representations is a key step towards
building agents that can reason about and execute complex tasks. Existing
methods typically address this problem by aligning visual content with textual
descriptions at the task and step levels to inject procedural semantics into
video representations. However, due to their high level of abstraction, 'task'
and 'step' descriptions fail to form a robust alignment with the concrete,
observable details in visual data. To address this, we introduce 'states',
i.e., textual snapshots of object configurations, as a visually-grounded
semantic layer that anchors abstract procedures to what a model can actually
see. We formalize this insight in a novel Task-Step-State (TSS) framework,
where tasks are achieved via steps that drive transitions between observable
states. To enforce this structure, we propose a progressive pre-training
strategy that unfolds the TSS hierarchy, forcing the model to ground
representations in states while associating them with steps and high-level
tasks. Extensive experiments on the COIN and CrossTask datasets show that our
method outperforms baseline models on multiple downstream tasks, including task
recognition, step recognition, and next step prediction. Ablation studies show
that introducing state supervision is a key driver of performance gains across
all tasks. Additionally, our progressive pretraining strategy proves more
effective than standard joint training, as it better enforces the intended
hierarchical structure.
\\ ( https://arxiv.org/abs/2511.20073 ,  7479kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20081
Date: Tue, 25 Nov 2025 08:52:46 GMT   (6356kb)

Title: Blind Adaptive Local Denoising for CEST Imaging
Authors: Chu Chen, Aitor Artola, Yang Liu, Se Weon Park, Raymond H. Chan,
 Jean-Michel Morel and Kannie W. Y. Chan
Categories: cs.CV
\\
 Chemical Exchange Saturation Transfer (CEST) MRI enables molecular-level
visualization of low-concentration metabolites by leveraging proton exchange
dynamics. However, its clinical translation is hindered by inherent challenges:
spatially varying noise arising from hardware limitations, and complex imaging
protocols introduce heteroscedasticity in CEST data, perturbing the accuracy of
quantitative contrast mapping such as amide proton transfer (APT) imaging.
Traditional denoising methods are not designed for this complex noise and often
alter the underlying information that is critical for biomedical analysis. To
overcome these limitations, we propose a new Blind Adaptive Local Denoising
(BALD) method. BALD exploits the self-similar nature of CEST data to derive an
adaptive variance-stabilizing transform that equalizes the noise distributions
across CEST pixels without prior knowledge of noise characteristics. Then, BALD
performs two-stage denoising on a linear transformation of data to disentangle
molecular signals from noise. A local SVD decomposition is used as a linear
transform to prevent spatial and spectral denoising artifacts. We conducted
extensive validation experiments on multiple phantoms and \textit{in vivo} CEST
scans. In these experiments, BALD consistently outperformed state-of-the-art
CEST denoisers in both denoising metrics and downstream tasks such as molecular
concentration maps estimation and cancer detection.
\\ ( https://arxiv.org/abs/2511.20081 ,  6356kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20088
Date: Tue, 25 Nov 2025 09:03:30 GMT   (6007kb)

Title: Explainable Visual Anomaly Detection via Concept Bottleneck Models
Authors: Arianna Stropeni, Valentina Zaccaria, Francesco Borsatti, Davide Dalle
 Pezze, Manuel Barusco, Gian Antonio Susto
Categories: cs.CV cs.AI
\\
 In recent years, Visual Anomaly Detection (VAD) has gained significant
attention due to its ability to identify anomalous images using only normal
images during training. Many VAD models work without supervision but are still
able to provide visual explanations by highlighting the anomalous regions
within an image. However, although these visual explanations can be helpful,
they lack a direct and semantically meaningful interpretation for users. To
address this limitation, we propose extending Concept Bottleneck Models (CBMs)
to the VAD setting. By learning meaningful concepts, the network can provide
human-interpretable descriptions of anomalies, offering a novel and more
insightful way to explain them. Our contributions are threefold: (i) we develop
a Concept Dataset to support research on CBMs for VAD; (ii) we improve the CBM
architecture to generate both concept-based and visual explanations, bridging
semantic and localization interpretability; and (iii) we introduce a pipeline
for synthesizing artificial anomalies, preserving the VAD paradigm of
minimizing dependence on rare anomalous samples. Our approach, Concept-Aware
Visual Anomaly Detection (CONVAD), achieves performance comparable to classic
VAD methods while providing richer, concept-driven explanations that enhance
interpretability and trust in VAD systems.
\\ ( https://arxiv.org/abs/2511.20088 ,  6007kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20095
Date: Tue, 25 Nov 2025 09:12:06 GMT   (982kb)

Title: WPT: World-to-Policy Transfer via Online World Model Distillation
Authors: Guangfeng Jiang, Yueru Luo, Jun Liu, Yi Huang, Yiyao Zhu, Zhan Qu,
 Dave Zhenyu Chen, Bingbing Liu, Xu Yan
Categories: cs.CV
\\
 Recent years have witnessed remarkable progress in world models, which
primarily aim to capture the spatio-temporal correlations between an agent's
actions and the evolving environment. However, existing approaches often suffer
from tight runtime coupling or depend on offline reward signals, resulting in
substantial inference overhead or hindering end-to-end optimization. To
overcome these limitations, we introduce WPT, a World-to-Policy Transfer
training paradigm that enables online distillation under the guidance of an
end-to-end world model. Specifically, we develop a trainable reward model that
infuses world knowledge into a teacher policy by aligning candidate
trajectories with the future dynamics predicted by the world model.
Subsequently, we propose policy distillation and world reward distillation to
transfer the teacher's reasoning ability into a lightweight student policy,
enhancing planning performance while preserving real-time deployability.
Extensive experiments on both open-loop and closed-loop benchmarks show that
our WPT achieves state-of-the-art performance with a simple policy
architecture: it attains a 0.11 collision rate (open-loop) and achieves a 79.23
driving score (closed-loop) surpassing both world-model-based and
imitation-learning methods in accuracy and safety. Moreover, the student
sustains up to 4.9x faster inference, while retaining most of the gains.
\\ ( https://arxiv.org/abs/2511.20095 ,  982kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20096
Date: Tue, 25 Nov 2025 09:13:07 GMT   (4088kb)

Title: Exploring State-of-the-art models for Early Detection of Forest Fires
Authors: Sharjeel Ahmed, Daim Armaghan, Fatima Naweed, Umair Yousaf, Ahmad
 Zubair, Murtaza Taj
Categories: cs.CV
\\
 There have been many recent developments in the use of Deep Learning Neural
Networks for fire detection. In this paper, we explore an early warning system
for detection of forest fires. Due to the lack of sizeable datasets and models
tuned for this task, existing methods suffer from missed detection. In this
work, we first propose a dataset for early identification of forest fires
through visual analysis. Unlike existing image corpuses that contain images of
wide-spread fire, our dataset consists of multiple instances of smoke plumes
and fire that indicates the initiation of fire. We obtained this dataset
synthetically by utilising game simulators such as Red Dead Redemption 2. We
also combined our dataset with already published images to obtain a more
comprehensive set. Finally, we compared image classification and localisation
methods on the proposed dataset. More specifically we used YOLOv7 (You Only
Look Once) and different models of detection transformer.
\\ ( https://arxiv.org/abs/2511.20096 ,  4088kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20101
Date: Tue, 25 Nov 2025 09:19:20 GMT   (2208kb)

Title: Multi Head Attention Enhanced Inception v3 for Cardiomegaly Detection
Authors: Abishek Karthik, Pandiyaraju V
Categories: cs.CV
\\
 The healthcare industry has been revolutionized significantly by novel
imaging technologies, not just in the diagnosis of cardiovascular diseases but
also by the visualization of structural abnormalities like cardiomegaly. This
article explains an integrated approach to the use of deep learning tools and
attention mechanisms for automatic detection of cardiomegaly using X-ray
images. The initiation of the project is grounded on a strong Data Collection
phase and gathering the data of annotated X-ray images of various types. Then,
while the Preprocessing module fine-tunes image quality, it is feasible to
utilize the best out of the data quality in the proposed system. In our
proposed system, the process is a CNN configuration leveraging the inception V3
model as one of the key blocks. Besides, we also employ a multilayer attention
mechanism to enhance the strength. The most important feature of the method is
the multi-head attention mechanism that can learn features automatically. By
exact selective focusing on only some regions of input, the model can thus
identify cardiomegaly in a sensitive manner. Attention rating is calculated,
duplicated, and applied to enhance representation of main data, and therefore
there is a successful diagnosis. The Evaluation stage will be extremely strict
and it will thoroughly evaluate the model based on such measures as accuracy
and precision. This will validate that the model can identify cardiomegaly and
will also show the clinical significance of this method. The model has accuracy
of 95.6, precision of 95.2, recall of 96.2, sensitivity of 95.7, specificity of
96.1 and an Area Under Curve(AUC) of 96.0 and their respective graphs are
plotted for visualisation.
\\ ( https://arxiv.org/abs/2511.20101 ,  2208kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20116
Date: Tue, 25 Nov 2025 09:38:10 GMT   (745kb)

Title: LungEvaty: A Scalable, Open-Source Transformer-based Deep Learning Model
 for Lung Cancer Risk Prediction in LDCT Screening
Authors: Johannes Brandt, Maulik Chevli, Rickmer Braren, Georgios Kaissis,
 Philip M\"uller, Daniel Rueckert
Categories: cs.CV cs.AI
\\
 Lung cancer risk estimation is gaining increasing importance as more
countries introduce population-wide screening programs using low-dose CT
(LDCT). As imaging volumes grow, scalable methods that can process entire lung
volumes efficiently are essential to tap into the full potential of these large
screening datasets. Existing approaches either over-rely on pixel-level
annotations, limiting scalability, or analyze the lung in fragments, weakening
performance. We present LungEvaty, a fully transformer-based framework for
predicting 1-6 year lung cancer risk from a single LDCT scan. The model
operates on whole-lung inputs, learning directly from large-scale screening
data to capture comprehensive anatomical and pathological cues relevant for
malignancy risk. Using only imaging data and no region supervision, LungEvaty
matches state-of-the-art performance, refinable by an optional Anatomically
Informed Attention Guidance (AIAG) loss that encourages anatomically focused
attention. In total, LungEvaty was trained on more than 90,000 CT scans,
including over 28,000 for fine-tuning and 6,000 for evaluation. The framework
offers a simple, data-efficient, and fully open-source solution that provides
an extensible foundation for future research in longitudinal and multimodal
lung cancer risk prediction.
\\ ( https://arxiv.org/abs/2511.20116 ,  745kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20123
Date: Tue, 25 Nov 2025 09:44:10 GMT   (28753kb)

Title: UltraViCo: Breaking Extrapolation Limits in Video Diffusion Transformers
Authors: Min Zhao, Hongzhou Zhu, Yingze Wang, Bokai Yan, Jintao Zhang, Guande
 He, Ling Yang, Chongxuan Li, Jun Zhu
Categories: cs.CV
Comments: Project page: https://thu-ml.github.io/UltraViCo.github.io/
\\
 Despite advances, video diffusion transformers still struggle to generalize
beyond their training length, a challenge we term video length extrapolation.
We identify two failure modes: model-specific periodic content repetition and a
universal quality degradation. Prior works attempt to solve repetition via
positional encodings, overlooking quality degradation and achieving only
limited extrapolation. In this paper, we revisit this challenge from a more
fundamental view: attention maps, which directly govern how context influences
outputs. We identify that both failure modes arise from a unified cause:
attention dispersion, where tokens beyond the training window dilute learned
attention patterns. This leads to quality degradation and repetition emerges as
a special case when this dispersion becomes structured into periodic attention
patterns, induced by harmonic properties of positional encodings. Building on
this insight, we propose UltraViCo, a training-free, plug-and-play method that
suppresses attention for tokens beyond the training window via a constant decay
factor. By jointly addressing both failure modes, we outperform a broad set of
baselines largely across models and extrapolation ratios, pushing the
extrapolation limit from 2x to 4x. Remarkably, it improves Dynamic Degree and
Imaging Quality by 233% and 40.5% over the previous best method at 4x
extrapolation. Furthermore, our method generalizes seamlessly to downstream
tasks such as controllable video synthesis and editing.
\\ ( https://arxiv.org/abs/2511.20123 ,  28753kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20145
Date: Tue, 25 Nov 2025 10:07:57 GMT   (2149kb)

Title: Vision-Language Models for Automated 3D PET/CT Report Generation
Authors: Wenpei Jiao, Kun Shang, Hui Li, Ke Yan, Jiajin Zhang, Guangjie Yang,
 Lijuan Guo, Yan Wan, Xing Yang, Dakai Jin, Zhaoheng Xie
Categories: cs.CV
\\
 Positron emission tomography/computed tomography (PET/CT) is essential in
oncology, yet the rapid expansion of scanners has outpaced the availability of
trained specialists, making automated PET/CT report generation (PETRG)
increasingly important for reducing clinical workload. Compared with structural
imaging (e.g., X-ray, CT, and MRI), functional PET poses distinct challenges:
metabolic patterns vary with tracer physiology, and whole-body 3D contextual
information is required rather than local-region interpretation. To advance
PETRG, we propose PETRG-3D, an end-to-end 3D dual-branch framework that
separately encodes PET and CT volumes and incorporates style-adaptive prompts
to mitigate inter-hospital variability in reporting practices. We construct
PETRG-Lym, a multi-center lymphoma dataset collected from four hospitals (824
reports w/ 245,509 paired PET/CT slices), and construct AutoPET-RG-Lym, a
publicly accessible PETRG benchmark derived from open imaging data but equipped
with new expert-written, clinically validated reports (135 cases). To assess
clinical utility, we introduce PETRG-Score, a lymphoma-specific evaluation
protocol that jointly measures metabolic and structural findings across curated
anatomical regions. Experiments show that PETRG-3D substantially outperforms
existing methods on both natural language metrics (e.g., +31.49\% ROUGE-L) and
clinical efficacy metrics (e.g., +8.18\% PET-All), highlighting the benefits of
volumetric dual-modality modeling and style-aware prompting. Overall, this work
establishes a foundation for future PET/CT-specific models emphasizing
disease-aware reasoning and clinically reliable evaluation. Codes, models, and
AutoPET-RG-Lym will be released.
\\ ( https://arxiv.org/abs/2511.20145 ,  2149kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20151
Date: Tue, 25 Nov 2025 10:21:42 GMT   (2031kb)

Title: Hybrid Convolution and Frequency State Space Network for Image
 Compression
Authors: Haodong Pan, Hao Wei, Yusong Wang, Nanning Zheng, Caigui Jiang
Categories: cs.CV
Comments: 36 pages, 8 figures
\\
 Learned image compression (LIC) has recently benefited from Transformer based
and state space model (SSM) based architectures. Convolutional neural networks
(CNNs) effectively capture local high frequency details, whereas Transformers
and SSMs provide strong long range modeling capabilities but may cause
structural information loss or ignore frequency characteristics that are
crucial for compression. In this work we propose HCFSSNet, a Hybrid Convolution
and Frequency State Space Network for LIC. HCFSSNet uses CNNs to extract local
high frequency structures and introduces a Vision Frequency State Space (VFSS)
block that models long range low frequency information. The VFSS block combines
an Omni directional Neighborhood State Space (VONSS) module, which scans
features horizontally, vertically and diagonally, with an Adaptive Frequency
Modulation Module (AFMM) that applies content adaptive weighting of discrete
cosine transform frequency components for more efficient bit allocation. To
further reduce redundancy in the entropy model, we integrate AFMM with a Swin
Transformer to form a Frequency Swin Transformer Attention Module (FSTAM) for
frequency aware side information modeling. Experiments on the Kodak, Tecnick
and CLIC Professional Validation datasets show that HCFSSNet achieves
competitive rate distortion performance compared with recent SSM based codecs
such as MambaIC, while using significantly fewer parameters. On Kodak, Tecnick
and CLIC, HCFSSNet reduces BD rate over the VTM anchor by 18.06, 24.56 and
22.44 percent, respectively, providing an efficient and interpretable hybrid
architecture for future learned image compression systems.
\\ ( https://arxiv.org/abs/2511.20151 ,  2031kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20152
Date: Tue, 25 Nov 2025 10:22:26 GMT   (35091kb)

Title: Restora-Flow: Mask-Guided Image Restoration with Flow Matching
Authors: Arnela Hadzic, Franz Thaler, Lea Bogensperger, Simon Johannes Joham,
 Martin Urschler
Categories: cs.CV
Comments: Accepted for WACV 2026
\\
 Flow matching has emerged as a promising generative approach that addresses
the lengthy sampling times associated with state-of-the-art diffusion models
and enables a more flexible trajectory design, while maintaining high-quality
image generation. This capability makes it suitable as a generative prior for
image restoration tasks. Although current methods leveraging flow models have
shown promising results in restoration, some still suffer from long processing
times or produce over-smoothed results. To address these challenges, we
introduce Restora-Flow, a training-free method that guides flow matching
sampling by a degradation mask and incorporates a trajectory correction
mechanism to enforce consistency with degraded inputs. We evaluate our approach
on both natural and medical datasets across several image restoration tasks
involving a mask-based degradation, i.e., inpainting, super-resolution and
denoising. We show superior perceptual quality and processing time compared to
diffusion and flow matching-based reference methods.
\\ ( https://arxiv.org/abs/2511.20152 ,  35091kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20154
Date: Tue, 25 Nov 2025 10:28:37 GMT   (391kb)

Title: Alzheimers Disease Progression Prediction Based on Manifold Mapping of
 Irregularly Sampled Longitudinal Data
Authors: Xin Hong, Ying Shi, Yinhao Li, and Yen-Wei Chen
Categories: cs.CV
Comments: 10 pages, 3 figures
\\
 The uncertainty of clinical examinations frequently leads to irregular
observation intervals in longitudinal imaging data, posing challenges for
modeling disease progression.Most existing imaging-based disease prediction
models operate in Euclidean space, which assumes a flat representation of data
and fails to fully capture the intrinsic continuity and nonlinear geometric
structure of irregularly sampled longitudinal images. To address the challenge
of modeling Alzheimers disease (AD) progression from irregularly sampled
longitudinal structural Magnetic Resonance Imaging (sMRI) data, we propose a
Riemannian manifold mapping, a Time-aware manifold Neural ordinary differential
equation, and an Attention-based riemannian Gated recurrent unit (R-TNAG)
framework. Our approach first projects features extracted from high-dimensional
sMRI into a manifold space to preserve the intrinsic geometry of disease
progression. On this representation, a time-aware Neural Ordinary Differential
Equation (TNODE) models the continuous evolution of latent states between
observations, while an Attention-based Riemannian Gated Recurrent Unit (ARGRU)
adaptively integrates historical and current information to handle irregular
intervals. This joint design improves temporal consistency and yields robust AD
trajectory prediction under irregular sampling.Experimental results demonstrate
that the proposed method consistently outperforms state-of-the-art models in
both disease status prediction and cognitive score regression. Ablation studies
verify the contributions of each module, highlighting their complementary roles
in enhancing predictive accuracy. Moreover, the model exhibits stable
performance across varying sequence lengths and missing data rates, indicating
strong temporal generalizability. Cross-dataset validation further confirms its
robustness and applicability in diverse clinical settings.
\\ ( https://arxiv.org/abs/2511.20154 ,  391kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20156
Date: Tue, 25 Nov 2025 10:30:26 GMT   (10186kb)

Title: Map-World: Masked Action planning and Path-Integral World Model for
 Autonomous Driving
Authors: Bin Hu, Zijian Lu, Haicheng Liao, Chengran Yuan, Bin Rao, Yongkang Li,
 Guofa Li, Zhiyong Cui, Cheng-zhong Xu, Zhenning Li
Categories: cs.CV cs.RO
\\
 Motion planning for autonomous driving must handle multiple plausible futures
while remaining computationally efficient. Recent end-to-end systems and
world-model-based planners predict rich multi-modal trajectories, but typically
rely on handcrafted anchors or reinforcement learning to select a single best
mode for training and control. This selection discards information about
alternative futures and complicates optimization. We propose MAP-World, a
prior-free multi-modal planning framework that couples masked action planning
with a path-weighted world model. The Masked Action Planning (MAP) module
treats future ego motion as masked sequence completion: past waypoints are
encoded as visible tokens, future waypoints are represented as mask tokens, and
a driving-intent path provides a coarse scaffold. A compact latent planning
state is expanded into multiple trajectory queries with injected noise,
yielding diverse, temporally consistent modes without anchor libraries or
teacher policies. A lightweight world model then rolls out future BEV semantics
conditioned on each candidate trajectory. During training, semantic losses are
computed as an expectation over modes, using trajectory probabilities as
discrete path weights, so the planner learns from the full distribution of
plausible futures instead of a single selected path. On NAVSIM, our method
matches anchor-based approaches and achieves state-of-the-art performance among
world-model-based methods, while avoiding reinforcement learning and
maintaining real-time inference latency.
\\ ( https://arxiv.org/abs/2511.20156 ,  10186kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20157
Date: Tue, 25 Nov 2025 10:33:17 GMT   (42310kb)

Title: SKEL-CF: Coarse-to-Fine Biomechanical Skeleton and Surface Mesh Recovery
Authors: Da Li, Ji-Ping Jin, Xuanlong Yu, Wei Liu, Xiaodong Cun, Kai Chen, Rui
 Fan, Jiangang Kong, Shen Xi
Categories: cs.CV
Comments: 15 pages, 10 figures
\\
 Parametric 3D human models such as SMPL have driven significant advances in
human pose and shape estimation, yet their simplified kinematics limit
biomechanical realism. The recently proposed SKEL model addresses this
limitation by re-rigging SMPL with an anatomically accurate skeleton. However,
estimating SKEL parameters directly remains challenging due to limited training
data, perspective ambiguities, and the inherent complexity of human
articulation. We introduce SKEL-CF, a coarse-to-fine framework for SKEL
parameter estimation. SKEL-CF employs a transformer-based encoder-decoder
architecture, where the encoder predicts coarse camera and SKEL parameters, and
the decoder progressively refines them in successive layers. To ensure
anatomically consistent supervision, we convert the existing SMPL-based dataset
4DHuman into a SKEL-aligned version, 4DHuman-SKEL, providing high-quality
training data for SKEL estimation. In addition, to mitigate depth and scale
ambiguities, we explicitly incorporate camera modeling into the SKEL-CF
pipeline and demonstrate its importance across diverse viewpoints. Extensive
experiments validate the effectiveness of the proposed design. On the
challenging MOYO dataset, SKEL-CF achieves 85.0 MPJPE / 51.4 PA-MPJPE,
significantly outperforming the previous SKEL-based state-of-the-art HSMR
(104.5 / 79.6). These results establish SKEL-CF as a scalable and anatomically
faithful framework for human motion analysis, bridging the gap between computer
vision and biomechanics. Our implementation is available on the project page:
https://pokerman8.github.io/SKEL-CF/.
\\ ( https://arxiv.org/abs/2511.20157 ,  42310kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20158
Date: Tue, 25 Nov 2025 10:34:51 GMT   (1485kb)

Title: Harmonious Parameter Adaptation in Continual Visual Instruction Tuning
 for Safety-Aligned MLLMs
Authors: Ziqi Wang, Chang Che, Qi Wang, Hui Ma, Zenglin Shi, Cees G. M. Snoek,
 Meng Wang
Categories: cs.CV
\\
 While continual visual instruction tuning (CVIT) has shown promise in
adapting multimodal large language models (MLLMs), existing studies
predominantly focus on models without safety alignment. This critical oversight
ignores the fact that real-world MLLMs inherently require such mechanisms to
mitigate potential risks. In this work, we shift our focus to CVIT for
safety-aligned MLLMs and observe that during continual adaptation, the model
not only suffers from task forgetting but also exhibits degradation in its
safety. Achieving a harmonious balance between safety and task performance
remains a crucial challenge. To address this, we propose Harmonious Parameter
Adaptation (HPA), a post-training framework composed of focusing-based
parameter partition, harmoniously balanced parameter selection, and orthogonal
parameter adjustment. Specifically, HPA partitions parameters into two types
based on their focus on safety or task performance, and selects the focused
ones to preserve from a balanced perspective. In addition, HPA imposes
orthogonality constraints on parameter updates to further alleviate
catastrophic forgetting. Extensive experiments on the CVIT benchmark and safety
evaluation datasets demonstrate that HPA better maintains high safety and
mitigates forgetting than existing baselines.
\\ ( https://arxiv.org/abs/2511.20158 ,  1485kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20162
Date: Tue, 25 Nov 2025 10:38:41 GMT   (1526kb)

Title: While recognizing actions, LMMs struggle to detect core interaction
 events
Authors: Daniel Harari, Michael Sidorov, Liel David, Chen Shterental, Abrham
 Kahsay Gebreselasie, Muhammad Haris Khan
Categories: cs.CV cs.AI q-bio.NC
\\
 Large multi-modal models (LMMs) show increasing performance in realistic
visual tasks for images and, more recently, for videos. For example, given a
video sequence, such models are able to describe in detail objects, the
surroundings and dynamic actions. In this study, we explored the extent to
which these models ground their semantic understanding in the actual visual
input. Specifically, given sequences of hands interacting with objects, we
asked models when and where the interaction begins or ends. For this purpose,
we introduce a first of its kind, large-scale dataset with more than 20K
annotated interactions on videos from the Something-Something-V2 dataset. 250
AMTurk human annotators labeled core interaction events, particularly when and
where objects and agents become attached ('contact') or detached ('release').
We asked two LMMs (Qwen-2.5VL and GPT-4o) to locate these events in short
videos, each with a single event. The results show that although the models can
reliably name the target objects, identify the action and provide coherent
reasoning, they consistently fail to identify the frame where the interaction
begins or ends and cannot localize the event within the scene. Our findings
suggest that in struggling to pinpoint the moment and location of physical
contact that defines the interaction, the models lack the perceptual grounding
required for deeper understanding of dynamic scenes.
\\ ( https://arxiv.org/abs/2511.20162 ,  1526kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20169
Date: Tue, 25 Nov 2025 10:47:48 GMT   (12161kb)

Title: ADNet: A Large-Scale and Extensible Multi-Domain Benchmark for Anomaly
 Detection Across 380 Real-World Categories
Authors: Hai Ling, Jia Guo, Zhulin Tao, Yunkang Cao, Donglin Di, Hongyan Xu,
 Xiu Su, Yang Song, Lei Fan
Categories: cs.CV
\\
 Anomaly detection (AD) aims to identify defects using normal-only training
data. Existing anomaly detection benchmarks (e.g., MVTec-AD with 15 categories)
cover only a narrow range of categories, limiting the evaluation of
cross-context generalization and scalability. We introduce ADNet, a
large-scale, multi-domain benchmark comprising 380 categories aggregated from
49 publicly available datasets across Electronics, Industry, Agrifood,
Infrastructure, and Medical domains. The benchmark includes a total of 196,294
RGB images, consisting of 116,192 normal samples for training and 80,102 test
images, of which 60,311 are anomalous. All images are standardized with
MVTec-style pixel-level annotations and structured text descriptions spanning
both spatial and visual attributes, enabling multimodal anomaly detection
tasks. Extensive experiments reveal a clear scalability challenge: existing
state-of-the-art methods achieve 90.6% I-AUROC in one-for-one settings but drop
to 78.5% when scaling to all 380 categories in a multi-class setting. To
address this, we propose Dinomaly-m, a context-guided Mixture-of-Experts
extension of Dinomaly that expands decoder capacity without increasing
inference cost. It achieves 83.2% I-AUROC and 93.1% P-AUROC, demonstrating
superior performance over existing approaches. ADNet is designed as a
standardized and extensible benchmark, supporting the community in expanding
anomaly detection datasets across diverse domains and providing a scalable
foundation for future anomaly detection foundation models. Dataset:
https://grainnet.github.io/ADNet
\\ ( https://arxiv.org/abs/2511.20169 ,  12161kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20175
Date: Tue, 25 Nov 2025 10:58:23 GMT   (11536kb)

Title: Realizing Fully-Integrated, Low-Power, Event-Based Pupil Tracking with
 Neuromorphic Hardware
Authors: Federico Paredes-Valles, Yoshitaka Miyatani, Kirk Y. W. Scheper
Categories: cs.CV
Comments: 17 pages, 14 figures, 3 tables
\\
 Eye tracking is fundamental to numerous applications, yet achieving robust,
high-frequency tracking with ultra-low power consumption remains challenging
for wearable platforms. While event-based vision sensors offer microsecond
resolution and sparse data streams, they have lacked fully integrated,
low-power processing solutions capable of real-time inference. In this work, we
present the first battery-powered, wearable pupil-center-tracking system with
complete on-device integration, combining event-based sensing and neuromorphic
processing on the commercially available Speck2f system-on-chip with
lightweight coordinate decoding on a low-power microcontroller. Our solution
features a novel uncertainty-quantifying spiking neural network with gated
temporal decoding, optimized for strict memory and bandwidth constraints,
complemented by systematic deployment mechanisms that bridge the reality gap.
We validate our system on a new multi-user dataset and demonstrate a wearable
prototype with dual neuromorphic devices achieving robust binocular pupil
tracking at 100 Hz with an average power consumption below 5 mW per eye. Our
work demonstrates that end-to-end neuromorphic computing enables practical,
always-on eye tracking for next-generation energy-efficient wearable systems.
\\ ( https://arxiv.org/abs/2511.20175 ,  11536kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20186
Date: Tue, 25 Nov 2025 11:08:37 GMT   (33601kb)

Title: Exo2EgoSyn: Unlocking Foundation Video Generation Models for
 Exocentric-to-Egocentric Video Synthesis
Authors: Mohammad Mahdi, Yuqian Fu, Nedko Savov, Jiancheng Pan, Danda Pani
 Paudel, Luc Van Gool
Categories: cs.CV
\\
 Foundation video generation models such as WAN 2.2 exhibit strong text- and
image-conditioned synthesis abilities but remain constrained to the same-view
generation setting. In this work, we introduce Exo2EgoSyn, an adaptation of WAN
2.2 that unlocks Exocentric-to-Egocentric(Exo2Ego) cross-view video synthesis.
Our framework consists of three key modules. Ego-Exo View
Alignment(EgoExo-Align) enforces latent-space alignment between exocentric and
egocentric first-frame representations, reorienting the generative space from
the given exo view toward the ego view. Multi-view Exocentric Video
Conditioning (MultiExoCon) aggregates multi-view exocentric videos into a
unified conditioning signal, extending WAN2.2 beyond its vanilla single-image
or text conditioning. Furthermore, Pose-Aware Latent Injection (PoseInj)
injects relative exo-to-ego camera pose information into the latent state,
guiding geometry-aware synthesis across viewpoints. Together, these modules
enable high-fidelity ego view video generation from third-person observations
without retraining from scratch. Experiments on ExoEgo4D validate that
Exo2EgoSyn significantly improves Ego2Exo synthesis, paving the way for
scalable cross-view video generation with foundation models. Source code and
models will be released publicly.
\\ ( https://arxiv.org/abs/2511.20186 ,  33601kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20190
Date: Tue, 25 Nov 2025 11:14:39 GMT   (2507kb)

Title: SFA: Scan, Focus, and Amplify toward Guidance-aware Answering for Video
 TextVQA
Authors: Haibin He, Qihuang Zhong, Juhua Liu, Bo Du, Peng Wang, Jing Zhang
Categories: cs.CV
\\
 Video text-based visual question answering (Video TextVQA) task aims to
answer questions about videos by leveraging the visual text appearing within
the videos. This task poses significant challenges, requiring models to
accurately perceive and comprehend scene text that varies in scale,
orientation, and clarity across frames, while effectively integrating temporal
and semantic context to generate precise answers. Moreover, the model must
identify question-relevant textual cues and filter out redundant or irrelevant
information to ensure answering is guided by the most relevant and informative
cues. To address these challenges, we propose SFA, a training-free framework
and the first Video-LLM-based method tailored for Video TextVQA, motivated by
the human process of answering questions. By adaptively scanning video frames,
selectively focusing on key regions, and directly amplifying them, SFA
effectively guides the Video-LLM's attention toward essential cues, enabling it
to generate more accurate answers. SFA achieves new state-of-the-art results
across several public Video TextVQA datasets and surpasses previous methods by
a substantial margin, demonstrating its effectiveness and generalizability.
\\ ( https://arxiv.org/abs/2511.20190 ,  2507kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20201
Date: Tue, 25 Nov 2025 11:24:25 GMT   (1865kb)

Title: GHR-VQA: Graph-guided Hierarchical Relational Reasoning for Video
 Question Answering
Authors: Dionysia Danai Brilli, Dimitrios Mallis, Vassilis Pitsikalis, Petros
 Maragos
Categories: cs.CV
\\
 We propose GHR-VQA, Graph-guided Hierarchical Relational Reasoning for Video
Question Answering (Video QA), a novel human-centric framework that
incorporates scene graphs to capture intricate human-object interactions within
video sequences. Unlike traditional pixel-based methods, each frame is
represented as a scene graph and human nodes across frames are linked to a
global root, forming the video-level graph and enabling cross-frame reasoning
centered on human actors. The video-level graphs are then processed by Graph
Neural Networks (GNNs), transforming them into rich, context-aware embeddings
for efficient processing. Finally, these embeddings are integrated with
question features in a hierarchical network operating across different
abstraction levels, enhancing both local and global understanding of video
content. This explicit human-rooted structure enhances interpretability by
decomposing actions into human-object interactions and enables a more profound
understanding of spatiotemporal dynamics. We validate our approach on the
Action Genome Question Answering (AGQA) dataset, achieving significant
performance improvements, including a 7.3% improvement in object-relation
reasoning over the state of the art.
\\ ( https://arxiv.org/abs/2511.20201 ,  1865kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20202
Date: Tue, 25 Nov 2025 11:26:10 GMT   (2245kb)

Title: Robust 3D Brain MRI Inpainting with Random Masking Augmentation
Authors: Juexin Zhang, Ying Weng, Ke Chen
Categories: cs.CV
Comments: Accepted by the International Brain Tumor Segmentation (BraTS)
 challenge organized at MICCAI 2025 conference
\\
 The ASNR-MICCAI BraTS-Inpainting Challenge was established to mitigate
dataset biases that limit deep learning models in the quantitative analysis of
brain tumor MRI. This paper details our submission to the 2025 challenge, a
novel deep learning framework for synthesizing healthy tissue in 3D scans. The
core of our method is a U-Net architecture trained to inpaint synthetically
corrupted regions, enhanced with a random masking augmentation strategy to
improve generalization. Quantitative evaluation confirmed the efficacy of our
approach, yielding an SSIM of 0.873$\pm$0.004, a PSNR of 24.996$\pm$4.694, and
an MSE of 0.005$\pm$0.087 on the validation set. On the final online test set,
our method achieved an SSIM of 0.919$\pm$0.088, a PSNR of 26.932$\pm$5.057, and
an RMSE of 0.052$\pm$0.026. This performance secured first place in the
BraTS-Inpainting 2025 challenge and surpassed the winning solutions from the
2023 and 2024 competitions on the official leaderboard.
\\ ( https://arxiv.org/abs/2511.20202 ,  2245kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20211
Date: Tue, 25 Nov 2025 11:34:51 GMT   (13025kb)

Title: OmniAlpha: A Sequence-to-Sequence Framework for Unified Multi-Task RGBA
 Generation
Authors: Hao Yu, Jiabo Zhan, Zile Wang, Jinglin Wang, Huaisong Zhang, Hongyu
 Li, Xinrui Chen, Yongxian Wei, Chun Yuan
Categories: cs.CV cs.AI
\\
 Generative models have excelled in RGB synthesis, but real-world applications
require RGBA manipulation. This has led to a fragmented landscape: specialized,
single-task models handle alpha but lack versatility, while unified multi-task
frameworks are confined to the RGB domain. To bridge this critical gap, we
propose OmniAlpha, the first unified, multi-task generative framework for
sequence-to-sequence RGBA image generation and editing. Its architecture
features MSRoPE-BiL, a novel RoPE method with a bi-directionally extendable
layer axis for its Diffusion Transformer (DiT) backbone, enabling the
concurrent processing of multiple input and target RGBA layers. To power this
framework, we introduce AlphaLayers, a new dataset of 1,000 high-quality,
multi-layer triplets, built via a novel automated synthesis and filter
pipeline. Jointly training OmniAlpha on this dataset across a comprehensive
suite of 21 diverse tasks, extensive experiments demonstrate that our unified
approach consistently outperforms strong, specialized baselines. Most notably,
OmniAlpha achieves a dramatic 84.8% relative reduction in SAD for mask-free
matting on AIM-500 and wins over 90% of human preferences in layer-conditioned
completion. Our work proves that a unified, multi-task model can learn a
superior shared representation for RGBA, paving the way for more powerful,
layer-aware generative systems.
\\ ( https://arxiv.org/abs/2511.20211 ,  13025kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20218
Date: Tue, 25 Nov 2025 11:43:58 GMT   (20145kb)

Title: Text-guided Controllable Diffusion for Realistic Camouflage Images
 Generation
Authors: Yuhang Qian, Haiyan Chen, Wentong Li, Ningzhong Liu, Jie Qin
Categories: cs.CV
Comments: Accepted by AAAI 2026
\\
 Camouflage Images Generation (CIG) is an emerging research area that focuses
on synthesizing images in which objects are harmoniously blended and exhibit
high visual consistency with their surroundings. Existing methods perform CIG
by either fusing objects into specific backgrounds or outpainting the
surroundings via foreground object-guided diffusion. However, they often fail
to obtain natural results because they overlook the logical relationship
between camouflaged objects and background environments. To address this issue,
we propose CT-CIG, a Controllable Text-guided Camouflage Images Generation
method that produces realistic and logically plausible camouflage images.
Leveraging Large Visual Language Models (VLM), we design a Camouflage-Revealing
Dialogue Mechanism (CRDM) to annotate existing camouflage datasets with
high-quality text prompts. Subsequently, the constructed image-prompt pairs are
utilized to finetune Stable Diffusion, incorporating a lightweight controller
to guide the location and shape of camouflaged objects for enhanced camouflage
scene fitness. Moreover, we design a Frequency Interaction Refinement Module
(FIRM) to capture high-frequency texture features, facilitating the learning of
complex camouflage patterns. Extensive experiments, including CLIPScore
evaluation and camouflage effectiveness assessment, demonstrate the semantic
alignment of our generated text prompts and CT-CIG's ability to produce
photorealistic camouflage images.
\\ ( https://arxiv.org/abs/2511.20218 ,  20145kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20221
Date: Tue, 25 Nov 2025 11:49:18 GMT   (1265kb)

Title: Patch-Level Glioblastoma Subregion Classification with a Contrastive
 Learning-Based Encoder
Authors: Juexin Zhang, Qifeng Zhong, Ying Weng, Ke Chen
Categories: cs.CV
Comments: Accepted by the International Brain Tumor Segmentation (BraTS)
 challenge organized at MICCAI 2025 conference
\\
 The significant molecular and pathological heterogeneity of glioblastoma, an
aggressive brain tumor, complicates diagnosis and patient stratification. While
traditional histopathological assessment remains the standard, deep learning
offers a promising path toward objective and automated analysis of whole slide
images. For the BraTS-Path 2025 Challenge, we developed a method that
fine-tunes a pre-trained Vision Transformer (ViT) encoder with a dedicated
classification head on the official training dataset. Our model's performance
on the online validation set, evaluated via the Synapse platform, yielded a
Matthews Correlation Coefficient (MCC) of 0.7064 and an F1-score of 0.7676. On
the final test set, the model achieved an MCC of 0.6509 and an F1-score of
0.5330, which secured our team second place in the BraTS-Pathology 2025
Challenge. Our results establish a solid baseline for ViT-based
histopathological analysis, and future efforts will focus on bridging the
performance gap observed on the unseen validation data.
\\ ( https://arxiv.org/abs/2511.20221 ,  1265kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20223
Date: Tue, 25 Nov 2025 11:51:17 GMT   (11485kb)

Title: V-Attack: Targeting Disentangled Value Features for Controllable
 Adversarial Attacks on LVLMs
Authors: Sen Nie, Jie Zhang, Jianxin Yan, Shiguang Shan, Xilin Chen
Categories: cs.CV
Comments: 21 pages
\\
 Adversarial attacks have evolved from simply disrupting predictions on
conventional task-specific models to the more complex goal of manipulating
image semantics on Large Vision-Language Models (LVLMs). However, existing
methods struggle with controllability and fail to precisely manipulate the
semantics of specific concepts in the image. We attribute this limitation to
semantic entanglement in the patch-token representations on which adversarial
attacks typically operate: global context aggregated by self-attention in the
vision encoder dominates individual patch features, making them unreliable
handles for precise local semantic manipulation. Our systematic investigation
reveals a key insight: value features (V) computed within the transformer
attention block serve as much more precise handles for manipulation. We show
that V suppresses global-context channels, allowing it to retain high-entropy,
disentangled local semantic information. Building on this discovery, we propose
V-Attack, a novel method designed for precise local semantic attacks. V-Attack
targets the value features and introduces two core components: (1) a Self-Value
Enhancement module to refine V's intrinsic semantic richness, and (2) a
Text-Guided Value Manipulation module that leverages text prompts to locate
source concept and optimize it toward a target concept. By bypassing the
entangled patch features, V-Attack achieves highly effective semantic control.
Extensive experiments across diverse LVLMs, including LLaVA, InternVL,
DeepseekVL and GPT-4o, show that V-Attack improves the attack success rate by
an average of 36% over state-of-the-art methods, exposing critical
vulnerabilities in modern visual-language understanding. Our code and data are
available https://github.com/Summu77/V-Attack.
\\ ( https://arxiv.org/abs/2511.20223 ,  11485kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20245
Date: Tue, 25 Nov 2025 12:20:50 GMT   (27848kb)

Title: HistoSpeckle-Net: Mutual Information-Guided Deep Learning for
 high-fidelity reconstruction of complex OrganAMNIST images via perturbed
 Multimode Fibers
Authors: Jawaria Maqbool and M. Imran Cheema
Categories: cs.CV physics.optics
\\
 Existing deep learning methods in multimode fiber (MMF) imaging often focus
on simpler datasets, limiting their applicability to complex, real-world
imaging tasks. These models are typically data-intensive, a challenge that
becomes more pronounced when dealing with diverse and complex images. In this
work, we propose HistoSpeckle-Net, a deep learning architecture designed to
reconstruct structurally rich medical images from MMF speckles. To build a
clinically relevant dataset, we develop an optical setup that couples laser
light through a spatial light modulator (SLM) into an MMF, capturing output
speckle patterns corresponding to input OrganAMNIST images. Unlike previous MMF
imaging approaches, which have not considered the underlying statistics of
speckles and reconstructed images, we introduce a distribution-aware learning
strategy. We employ a histogram-based mutual information loss to enhance model
robustness and reduce reliance on large datasets. Our model includes a
histogram computation unit that estimates smooth marginal and joint histograms
for calculating mutual information loss. It also incorporates a unique
Three-Scale Feature Refinement Module, which leads to multiscale Structural
Similarity Index Measure (SSIM) loss computation. Together, these two loss
functions enhance both the structural fidelity and statistical alignment of the
reconstructed images. Our experiments on the complex OrganAMNIST dataset
demonstrate that HistoSpeckle-Net achieves higher fidelity than baseline models
such as U-Net and Pix2Pix. It gives superior performance even with limited
training samples and across varying fiber bending conditions. By effectively
reconstructing complex anatomical features with reduced data and under fiber
perturbations, HistoSpeckle-Net brings MMF imaging closer to practical
deployment in real-world clinical environments.
\\ ( https://arxiv.org/abs/2511.20245 ,  27848kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20250
Date: Tue, 25 Nov 2025 12:25:20 GMT   (9093kb)

Title: Uplifting Table Tennis: A Robust, Real-World Application for 3D
 Trajectory and Spin Estimation
Authors: Daniel Kienzle, Katja Ludwig, Julian Lorenz, Shin'ichi Satoh, Rainer
 Lienhart
Categories: cs.CV cs.AI cs.LG
ACM-class: I.2.6; I.2.10; I.4.5
\\
 Obtaining the precise 3D motion of a table tennis ball from standard
monocular videos is a challenging problem, as existing methods trained on
synthetic data struggle to generalize to the noisy, imperfect ball and table
detections of the real world. This is primarily due to the inherent lack of 3D
ground truth trajectories and spin annotations for real-world video. To
overcome this, we propose a novel two-stage pipeline that divides the problem
into a front-end perception task and a back-end 2D-to-3D uplifting task. This
separation allows us to train the front-end components with abundant 2D
supervision from our newly created TTHQ dataset, while the back-end uplifting
network is trained exclusively on physically-correct synthetic data. We
specifically re-engineer the uplifting model to be robust to common real-world
artifacts, such as missing detections and varying frame rates. By integrating a
ball detector and a table keypoint detector, our approach transforms a
proof-of-concept uplifting method into a practical, robust, and high-performing
end-to-end application for 3D table tennis trajectory and spin analysis.
\\ ( https://arxiv.org/abs/2511.20250 ,  9093kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20251
Date: Tue, 25 Nov 2025 12:25:41 GMT   (35446kb)

Title: PromptMoG: Enhancing Diversity in Long-Prompt Image Generation via
 Prompt Embedding Mixture-of-Gaussian Sampling
Authors: Bo-Kai Ruan, Teng-Fang Hsiao, Ling Lo, Yi-Lun Wu, Hong-Han Shuai
Categories: cs.CV
Comments: Technical Report
\\
 Recent advances in text-to-image (T2I) generation have achieved remarkable
visual outcomes through large-scale rectified flow models. However, how these
models behave under long prompts remains underexplored. Long prompts encode
rich content, spatial, and stylistic information that enhances fidelity but
often suppresses diversity, leading to repetitive and less creative outputs. In
this work, we systematically study this fidelity-diversity dilemma and reveal
that state-of-the-art models exhibit a clear drop in diversity as prompt length
increases. To enable consistent evaluation, we introduce LPD-Bench, a benchmark
designed for assessing both fidelity and diversity in long-prompt generation.
Building on our analysis, we develop a theoretical framework that increases
sampling entropy through prompt reformulation and propose a training-free
method, PromptMoG, which samples prompt embeddings from a Mixture-of-Gaussians
in the embedding space to enhance diversity while preserving semantics.
Extensive experiments on four state-of-the-art models, SD3.5-Large,
Flux.1-Krea-Dev, CogView4, and Qwen-Image, demonstrate that PromptMoG
consistently improves long-prompt generation diversity without semantic
drifting.
\\ ( https://arxiv.org/abs/2511.20251 ,  35446kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20253
Date: Tue, 25 Nov 2025 12:29:06 GMT   (12230kb)

Title: Zoo3D: Zero-Shot 3D Object Detection at Scene Level
Authors: Andrey Lemeshko, Bulat Gabdullin, Nikita Drozdov, Anton Konushin,
 Danila Rukhovich, Maksim Kolodiazhnyi
Categories: cs.CV
\\
 3D object detection is fundamental for spatial understanding. Real-world
environments demand models capable of recognizing diverse, previously unseen
objects, which remains a major limitation of closed-set methods. Existing
open-vocabulary 3D detectors relax annotation requirements but still depend on
training scenes, either as point clouds or images. We take this a step further
by introducing Zoo3D, the first training-free 3D object detection framework.
Our method constructs 3D bounding boxes via graph clustering of 2D instance
masks, then assigns semantic labels using a novel open-vocabulary module with
best-view selection and view-consensus mask generation. Zoo3D operates in two
modes: the zero-shot Zoo3D$_0$, which requires no training at all, and the
self-supervised Zoo3D$_1$, which refines 3D box prediction by training a
class-agnostic detector on Zoo3D$_0$-generated pseudo labels. Furthermore, we
extend Zoo3D beyond point clouds to work directly with posed and even unposed
images. Across ScanNet200 and ARKitScenes benchmarks, both Zoo3D$_0$ and
Zoo3D$_1$ achieve state-of-the-art results in open-vocabulary 3D object
detection. Remarkably, our zero-shot Zoo3D$_0$ outperforms all existing
self-supervised methods, hence demonstrating the power and adaptability of
training-free, off-the-shelf approaches for real-world 3D understanding. Code
is available at https://github.com/col14m/zoo3d .
\\ ( https://arxiv.org/abs/2511.20253 ,  12230kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20254
Date: Tue, 25 Nov 2025 12:29:10 GMT   (816kb)

Title: XiCAD: Camera Activation Detection in the Da Vinci Xi User Interface
Authors: Alexander C. Jenke, Gregor Just, Claas de Boer, Martin Wagner,
 Sebastian Bodenstedt, Stefanie Speidel
Categories: cs.CV cs.AI
\\
 Purpose: Robot-assisted minimally invasive surgery relies on endoscopic video
as the sole intraoperative visual feedback. The DaVinci Xi system overlays a
graphical user interface (UI) that indicates the state of each robotic arm,
including the activation of the endoscope arm. Detecting this activation
provides valuable metadata such as camera movement information, which can
support downstream surgical data science tasks including tool tracking, skill
assessment, or camera control automation.
 Methods: We developed a lightweight pipeline based on a ResNet18
convolutional neural network to automatically identify the position of the
camera tile and its activation state within the DaVinci Xi UI. The model was
fine-tuned on manually annotated data from the SurgToolLoc dataset and
evaluated across three public datasets comprising over 70,000 frames.
 Results: The model achieved F1-scores between 0.993 and 1.000 for the binary
detection of active cameras and correctly localized the camera tile in all
cases without false multiple-camera detections.
 Conclusion: The proposed pipeline enables reliable, real-time extraction of
camera activation metadata from surgical videos, facilitating automated
preprocessing and analysis for diverse downstream applications. All code,
trained models, and annotations are publicly available.
\\ ( https://arxiv.org/abs/2511.20254 ,  816kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20256
Date: Tue, 25 Nov 2025 12:35:57 GMT   (41534kb)

Title: The Image as Its Own Reward: Reinforcement Learning with Adversarial
 Reward for Image Generation
Authors: Weijia Mao, Hao Chen, Zhenheng Yang, Mike Zheng Shou
Categories: cs.CV
\\
 A reliable reward function is essential for reinforcement learning (RL) in
image generation. Most current RL approaches depend on pre-trained preference
models that output scalar rewards to approximate human preferences. However,
these rewards often fail to capture human perception and are vulnerable to
reward hacking, where higher scores do not correspond to better images. To
address this, we introduce Adv-GRPO, an RL framework with an adversarial reward
that iteratively updates both the reward model and the generator. The reward
model is supervised using reference images as positive samples and can largely
avoid being hacked. Unlike KL regularization that constrains parameter updates,
our learned reward directly guides the generator through its visual outputs,
leading to higher-quality images. Moreover, while optimizing existing reward
functions can alleviate reward hacking, their inherent biases remain. For
instance, PickScore may degrade image quality, whereas OCR-based rewards often
reduce aesthetic fidelity. To address this, we take the image itself as a
reward, using reference images and vision foundation models (e.g., DINO) to
provide rich visual rewards. These dense visual signals, instead of a single
scalar, lead to consistent gains across image quality, aesthetics, and
task-specific metrics. Finally, we show that combining reference samples with
foundation-model rewards enables distribution transfer and flexible style
customization. In human evaluation, our method outperforms Flow-GRPO and SD3,
achieving 70.0% and 72.4% win rates in image quality and aesthetics,
respectively. Code and models have been released.
\\ ( https://arxiv.org/abs/2511.20256 ,  41534kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20258
Date: Tue, 25 Nov 2025 12:38:28 GMT   (4843kb)

Title: Modality-Balanced Collaborative Distillation for Multi-Modal Domain
 Generalization
Authors: Xiaohan Wang, Zhangtao Cheng, Ting Zhong, Leiting Chen, Fan Zhou
Categories: cs.CV cs.LG
\\
 Weight Averaging (WA) has emerged as a powerful technique for enhancing
generalization by promoting convergence to a flat loss landscape, which
correlates with stronger out-of-distribution performance. However, applying WA
directly to multi-modal domain generalization (MMDG) is challenging:
differences in optimization speed across modalities lead WA to overfit to
faster-converging ones in early stages, suppressing the contribution of slower
yet complementary modalities, thereby hindering effective modality fusion and
skewing the loss surface toward sharper, less generalizable minima. To address
this issue, we propose MBCD, a unified collaborative distillation framework
that retains WA's flatness-inducing advantages while overcoming its
shortcomings in multi-modal contexts. MBCD begins with adaptive modality
dropout in the student model to curb early-stage bias toward dominant
modalities. A gradient consistency constraint then aligns learning signals
between uni-modal branches and the fused representation, encouraging
coordinated and smoother optimization. Finally, a WA-based teacher conducts
cross-modal distillation by transferring fused knowledge to each uni-modal
branch, which strengthens cross-modal interactions and steer convergence toward
flatter solutions. Extensive experiments on MMDG benchmarks show that MBCD
consistently outperforms existing methods, achieving superior accuracy and
robustness across diverse unseen domains.
\\ ( https://arxiv.org/abs/2511.20258 ,  4843kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20263
Date: Tue, 25 Nov 2025 12:42:26 GMT   (4193kb)

Title: Advancing Image Classification with Discrete Diffusion Classification
 Modeling
Authors: Omer Belhasin, Shelly Golan, Ran El-Yaniv, Michael Elad
Categories: cs.CV
\\
 Image classification is a well-studied task in computer vision, and yet it
remains challenging under high-uncertainty conditions, such as when input
images are corrupted or training data are limited. Conventional classification
approaches typically train models to directly predict class labels from input
images, but this might lead to suboptimal performance in such scenarios. To
address this issue, we propose Discrete Diffusion Classification Modeling
(DiDiCM), a novel framework that leverages a diffusion-based procedure to model
the posterior distribution of class labels conditioned on the input image.
DiDiCM supports diffusion-based predictions either on class probabilities or on
discrete class labels, providing flexibility in computation and memory
trade-offs. We conduct a comprehensive empirical study demonstrating the
superior performance of DiDiCM over standard classifiers, showing that a few
diffusion iterations achieve higher classification accuracy on the ImageNet
dataset compared to baselines, with accuracy gains increasing as the task
becomes more challenging. We release our code at
https://github.com/omerb01/didicm .
\\ ( https://arxiv.org/abs/2511.20263 ,  4193kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20270
Date: Tue, 25 Nov 2025 12:53:53 GMT   (1006kb)

Title: DRL-Guided Neural Batch Sampling for Semi-Supervised Pixel-Level Anomaly
 Detection
Authors: Amirhossein Khadivi Noghredeh, Abdollah Safari, Fatemeh Ziaeetabar,
 Firoozeh Haghighi
Categories: cs.CV
\\
 Anomaly detection in industrial visual inspection is challenging due to the
scarcity of defective samples. Most existing methods rely on unsupervised
reconstruction using only normal data, often resulting in overfitting and poor
detection of subtle defects. We propose a semi-supervised deep reinforcement
learning framework that integrates a neural batch sampler, an autoencoder, and
a predictor. The RL-based sampler adaptively selects informative patches by
balancing exploration and exploitation through a composite reward. The
autoencoder generates loss profiles highlighting abnormal regions, while the
predictor performs segmentation in the loss-profile space. This interaction
enables the system to effectively learn both normal and defective patterns with
limited labeled data. Experiments on the MVTec AD dataset demonstrate that our
method achieves higher accuracy and better localization of subtle anomalies
than recent state-of-the-art approaches while maintaining low complexity,
yielding an average improvement of 0.15 in F1_max and 0.06 in AUC, with a
maximum gain of 0.37 in F1_max in the best case.
\\ ( https://arxiv.org/abs/2511.20270 ,  1006kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20272
Date: Tue, 25 Nov 2025 12:58:32 GMT   (13538kb)

Title: VKnowU: Evaluating Visual Knowledge Understanding in Multimodal LLMs
Authors: Tianxiang Jiang, Sheng Xia, Yicheng Xu, Linquan Wu, Xiangyu Zeng,
 Limin Wang, Yu Qiao, Yi Wang
Categories: cs.CV
Comments: Data & Code: this https URL
\\
 While Multimodal Large Language Models (MLLMs) have become adept at
recognizing objects, they often lack the intuitive, human-like understanding of
the world's underlying physical and social principles. This high-level
vision-grounded semantics, which we term visual knowledge, forms a bridge
between perception and reasoning, yet remains an underexplored area in current
MLLMs. To systematically evaluate this capability, we present VKnowU, a
comprehensive benchmark featuring 1,680 questions in 1,249 videos, covering 8
core types of visual knowledge spanning both world-centric (e.g., intuitive
physics) and human-centric (e.g., subjective intentions). Evaluation of 23 SOTA
MLLMs reveals that leading models still fall short of human performance, with
particularly notable gaps in the world-centric. To bridge this gap, we
introduce a new dataset, VKnowQA, and VideoKnow+, a baseline model that
explicitly incorporates visual knowledge into MLLMs. VideoKnow+ follows a
structured See-Think-Answer paradigm and adopts reinforcement learning with
visual knowledge reward, achieving a +3.7% improvement on VKnowU and consistent
gains on MVBench, Video-MME, and MMVU. Our work highlights visual knowledge as
a missing cornerstone for developing more generalizable MLLMs that can not only
see but also truly understand our physical and social worlds.
\\ ( https://arxiv.org/abs/2511.20272 ,  13538kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20274
Date: Tue, 25 Nov 2025 12:59:31 GMT   (10736kb)

Title: ScenarioCLIP: Pretrained Transferable Visual Language Models and
 Action-Genome Dataset for Natural Scene Analysis
Authors: Advik Sinha and Saurabh Atreya and Aashutosh A V and Sk Aziz Ali and
 Abhijit Das
Categories: cs.CV
\\
 Until recently, the general corpus of CLIP-type fundamental models has widely
explored either the retrieval of short descriptions or the classification of
objects in the scene as SINGLE-object image classification task. The same holds
for retrieving the image embedding (image retrieval task) given a text prompt.
However, real-world scene images exhibit rich compositional structure involving
multiple objects and actions. The latest methods in the CLIP-based literature
improve class-level discrimination by mining harder negative image-text pairs
and by refining permanent text prompts, often using LLMs. However, these
improvements remain confined to predefined class lists and do not explicitly
model relational or compositional structure. PyramidCLIP partially addresses
this gap by aligning global and local visual features, yet it still lacks
explicit modeling of inter-object relations. Hence, to further leverage this
aspect for scene analysis, the proposed ScenarioCLIP model accepts input texts,
grounded relations, and input images, along with focused regions highlighting
relations. The proposed model is pretrained on curated scenario data, and
finetuned for specialized downstream tasks, such as cross-modal retrieval and
fine-grained visual understanding tasks. To address the lack of domain-specific
datasets, we generate a novel dataset by extending image-text pairs from
existing diverse indoor and outdoor scenario datasets that are publicly
available. We used a pipeline of existing language models to ground action,
object, and relations, filled by manual and automatic curation. We established
a comprehensive benchmark for several scenario-based tasks and compared it with
many baseline methods. ScenarioCLIP demonstrates robust zero-shot and finetune
performance on various domain-specific tasks. Our code and dataset are
available at https://github.com/scenario-clip/ScenarioCLIP
\\ ( https://arxiv.org/abs/2511.20274 ,  10736kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20278
Date: Tue, 25 Nov 2025 13:07:27 GMT   (7486kb)

Title: DAPointMamba: Domain Adaptive Point Mamba for Point Cloud Completion
Authors: Yinghui Li, Qianyu Zhou, Di Shao, Hao Yang, Ye Zhu, Richard Dazeley,
 Xuequan Lu
Categories: cs.CV
Comments: Accepted to AAAI 2026
\\
 Domain adaptive point cloud completion (DA PCC) aims to narrow the geometric
and semantic discrepancies between the labeled source and unlabeled target
domains. Existing methods either suffer from limited receptive fields or
quadratic complexity due to using CNNs or vision Transformers. In this paper,
we present the first work that studies the adaptability of State Space Models
(SSMs) in DA PCC and find that directly applying SSMs to DA PCC will encounter
several challenges: directly serializing 3D point clouds into 1D sequences
often disrupts the spatial topology and local geometric features of the target
domain. Besides, the overlook of designs in the learning domain-agnostic
representations hinders the adaptation performance. To address these issues, we
propose a novel framework, DAPointMamba for DA PCC, that exhibits strong
adaptability across domains and has the advantages of global receptive fields
and efficient linear complexity. It has three novel modules. In particular,
Cross-Domain Patch-Level Scanning introduces patch-level geometric
correspondences, enabling effective local alignment. Cross-Domain Spatial SSM
Alignment further strengthens spatial consistency by modulating patch features
based on cross-domain similarity, effectively mitigating fine-grained
structural discrepancies. Cross-Domain Channel SSM Alignment actively addresses
global semantic gaps by interleaving and aligning feature channels. Extensive
experiments on both synthetic and real-world benchmarks demonstrate that our
DAPointMamba outperforms state-of-the-art methods with less computational
complexity and inference latency.
\\ ( https://arxiv.org/abs/2511.20278 ,  7486kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20279
Date: Tue, 25 Nov 2025 13:08:09 GMT   (642kb)

Title: SelfMOTR: Revisiting MOTR with Self-Generating Detection Priors
Authors: Fabian G\"ulhan, Emil Mededovic, Yuli Wu, Johannes Stegmaier
Categories: cs.CV
Comments: 11 pages, 5 figures, 10 tables
\\
 Despite progress toward end-to-end tracking with transformer architectures,
poor detection performance and the conflict between detection and association
in a joint architecture remain critical concerns. Recent approaches aim to
mitigate these issues by (i) employing advanced denoising or label assignment
strategies, or (ii) incorporating detection priors from external object
detectors via distillation or anchor proposal techniques. Inspired by the
success of integrating detection priors and by the key insight that MOTR-like
models are secretly strong detection models, we introduce SelfMOTR, a novel
tracking transformer that relies on self-generated detection priors. Through
extensive analysis and ablation studies, we uncover and demonstrate the hidden
detection capabilities of MOTR-like models, and present a practical set of
tools for leveraging them effectively. On DanceTrack, SelfMOTR achieves strong
performance, competing with recent state-of-the-art end-to-end tracking
methods.
\\ ( https://arxiv.org/abs/2511.20279 ,  642kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20280
Date: Tue, 25 Nov 2025 13:09:03 GMT   (2374kb)

Title: Bootstrapping Physics-Grounded Video Generation through VLM-Guided
 Iterative Self-Refinement
Authors: Yang Liu, Xilin Zhao, Peisong Wen, Siran Dai, Qingming Huang
Categories: cs.CV
Comments: ICCV 2025 Physics-IQ Challenge Third Place Solution
\\
 Recent progress in video generation has led to impressive visual quality, yet
current models still struggle to produce results that align with real-world
physical principles. To this end, we propose an iterative self-refinement
framework that leverages large language models and vision-language models to
provide physics-aware guidance for video generation. Specifically, we introduce
a multimodal chain-of-thought (MM-CoT) process that refines prompts based on
feedback from physical inconsistencies, progressively enhancing generation
quality. This method is training-free and plug-and-play, making it readily
applicable to a wide range of video generation models. Experiments on the PhyIQ
benchmark show that our method improves the Physics-IQ score from 56.31 to
62.38. We hope this work serves as a preliminary exploration of
physics-consistent video generation and may offer insights for future research.
\\ ( https://arxiv.org/abs/2511.20280 ,  2374kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20295
Date: Tue, 25 Nov 2025 13:31:30 GMT   (4584kb)

Title: Back to the Feature: Explaining Video Classifiers with Video
 Counterfactual Explanations
Authors: Chao Wang, Chengan Che, Xinyue Chen, Sophia Tsoka, Luis C.
 Garcia-Peraza-Herrera
Categories: cs.CV
\\
 Counterfactual explanations (CFEs) are minimal and semantically meaningful
modifications of the input of a model that alter the model predictions. They
highlight the decisive features the model relies on, providing contrastive
interpretations for classifiers. State-of-the-art visual counterfactual
explanation methods are designed to explain image classifiers. The generation
of CFEs for video classifiers remains largely underexplored. For the
counterfactual videos to be useful, they have to be physically plausible,
temporally coherent, and exhibit smooth motion trajectories. Existing CFE
image-based methods, designed to explain image classifiers, lack the capacity
to generate temporally coherent, smooth and physically plausible video CFEs. To
address this, we propose Back To The Feature (BTTF), an optimization framework
that generates video CFEs. Our method introduces two novel features, 1) an
optimization scheme to retrieve the initial latent noise conditioned by the
first frame of the input video, 2) a two-stage optimization strategy to enable
the search for counterfactual videos in the vicinity of the input video. Both
optimization processes are guided solely by the target classifier, ensuring the
explanation is faithful. To accelerate convergence, we also introduce a
progressive optimization strategy that incrementally increases the number of
denoising steps. Extensive experiments on video datasets such as Shape-Moving
(motion classification), MEAD (emotion classification), and NTU RGB+D (action
classification) show that our BTTF effectively generates valid, visually
similar and realistic counterfactual videos that provide concrete insights into
the classifier's decision-making mechanism.
\\ ( https://arxiv.org/abs/2511.20295 ,  4584kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20296
Date: Tue, 25 Nov 2025 13:31:53 GMT   (13689kb)

Title: Prompting Lipschitz-constrained network for multiple-in-one sparse-view
 CT reconstruction
Authors: Baoshun Shi, Ke Jiang, Qiusheng Lian, Xinran Yu, and Huazhu Fu
Categories: cs.CV cs.AI
DOI: 10.1109/TMI.2025.3627305
\\
 Despite significant advancements in deep learning-based sparse-view computed
tomography (SVCT) reconstruction algorithms, these methods still encounter two
primary limitations: (i) It is challenging to explicitly prove that the prior
networks of deep unfolding algorithms satisfy Lipschitz constraints due to
their empirically designed nature. (ii) The substantial storage costs of
training a separate model for each setting in the case of multiple views hinder
practical clinical applications. To address these issues, we elaborate an
explicitly provable Lipschitz-constrained network, dubbed LipNet, and integrate
an explicit prompt module to provide discriminative knowledge of different
sparse sampling settings, enabling the treatment of multiple sparse view
configurations within a single model. Furthermore, we develop a storage-saving
deep unfolding framework for multiple-in-one SVCT reconstruction, termed
PromptCT, which embeds LipNet as its prior network to ensure the convergence of
its corresponding iterative algorithm. In simulated and real data experiments,
PromptCT outperforms benchmark reconstruction algorithms in multiple-in-one
SVCT reconstruction, achieving higher-quality reconstructions with lower
storage costs. On the theoretical side, we explicitly demonstrate that LipNet
satisfies boundary property, further proving its Lipschitz continuity and
subsequently analyzing the convergence of the proposed iterative algorithms.
The data and code are publicly available at
https://github.com/shibaoshun/PromptCT.
\\ ( https://arxiv.org/abs/2511.20296 ,  13689kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20302
Date: Tue, 25 Nov 2025 13:41:59 GMT   (9327kb)

Title: CrossEarth-Gate: Fisher-Guided Adaptive Tuning Engine for Efficient
 Adaptation of Cross-Domain Remote Sensing Semantic Segmentation
Authors: Shilei Cao, Ziyang Gong, Hehai Lin, Yang Liu, Jiashun Cheng, Xiaoxing
 Hu, Haoyuan Liang, Guowen Li, Chengwei Qin, Hong Cheng, Xue Yang, Juepeng
 Zheng, Haohuan Fu
Categories: cs.CV
\\
 In Remote Sensing (RS), Parameter-Efficient Fine-Tuning (PEFT) has emerged as
a key approach to activate the generalizable representation ability of
foundation models for downstream tasks. However, existing specialized PEFT
methods often fail when applied to large-scale Earth observation tasks, as they
are unable to fully handle the multifaceted and unpredictable domain gaps (\eg,
spatial, semantic, and frequency shifts) inherent in RS data. To overcome this,
we propose CrossEarth-Gate, which introduces two primary contributions. First,
we establish a comprehensive RS module toolbox to address multifaceted domain
gaps, comprising spatial, semantic, and frequency modules. Second, we develop a
Fisher-guided adaptive selection mechanism that operates on this toolbox. This
selection is guided by Fisher Information to quantify each module's importance
by measuring its contribution to the task-specific gradient flow. It
dynamically activates only the most critical modules at the appropriate layers,
guiding the gradient flow to maximize adaptation effectiveness and efficiency.
Comprehensive experiments validate the efficacy and generalizability of our
method, where CrossEarth-Gate achieves state-of-the-art performance across 16
cross-domain benchmarks for RS semantic segmentation. The code of the work will
be released.
\\ ( https://arxiv.org/abs/2511.20302 ,  9327kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20306
Date: Tue, 25 Nov 2025 13:44:29 GMT   (3188kb)

Title: TaCo: Capturing Spatio-Temporal Semantic Consistency in Remote Sensing
 Change Detection
Authors: Han Guo, Chenyang Liu, Haotian Zhang, Bowen Chen, Zhengxia Zou,
 Zhenwei Shi
Categories: cs.CV
\\
 Remote sensing change detection (RSCD) aims to identify surface changes
across bi-temporal satellite images. Most previous methods rely solely on mask
supervision, which effectively guides spatial localization but provides limited
constraints on the temporal semantic transitions. Consequently, they often
produce spatially coherent predictions while still suffering from unresolved
semantic inconsistencies. To address this limitation, we propose TaCo, a
spatio-temporal semantic consistent network, which enriches the existing
mask-supervised framework with a spatio-temporal semantic joint constraint.
TaCo conceptualizes change as a semantic transition between bi-temporal states,
in which one temporal feature representation can be derived from the other via
dedicated transition features. To realize this, we introduce a Text-guided
Transition Generator that integrates textual semantics with bi-temporal visual
features to construct the cross-temporal transition features. In addition, we
propose a spatio-temporal semantic joint constraint consisting of bi-temporal
reconstruct constraints and a transition constraint: the former enforces
alignment between reconstructed and original features, while the latter
enhances discrimination for changes. This design can yield substantial
performance gains without introducing any additional computational overhead
during inference. Extensive experiments on six public datasets, spanning both
binary and semantic change detection tasks, demonstrate that TaCo consistently
achieves SOTA performance.
\\ ( https://arxiv.org/abs/2511.20306 ,  3188kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20307
Date: Tue, 25 Nov 2025 13:46:05 GMT   (15903kb)

Title: TReFT: Taming Rectified Flow Models For One-Step Image Translation
Authors: Shengqian Li, Ming Gao, Yi Liu, Zuzeng Lin, Feng Wang, Feng Dai
Categories: cs.CV
\\
 Rectified Flow (RF) models have advanced high-quality image and video
synthesis via optimal transport theory. However, when applied to image-to-image
translation, they still depend on costly multi-step denoising, hindering
real-time applications. Although the recent adversarial training paradigm,
CycleGAN-Turbo, works in pretrained diffusion models for one-step image
translation, we find that directly applying it to RF models leads to severe
convergence issues. In this paper, we analyze these challenges and propose
TReFT, a novel method to Tame Rectified Flow models for one-step image
Translation. Unlike previous works, TReFT directly uses the velocity predicted
by pretrained DiT or UNet as output-a simple yet effective design that tackles
the convergence issues under adversarial training with one-step inference. This
design is mainly motivated by a novel observation that, near the end of the
denoising process, the velocity predicted by pretrained RF models converges to
the vector from origin to the final clean image, a property we further justify
through theoretical analysis. When applying TReFT to large pretrained RF models
such as SD3.5 and FLUX, we introduce memory-efficient latent cycle-consistency
and identity losses during training, as well as lightweight architectural
simplifications for faster inference. Pretrained RF models finetuned with TReFT
achieve performance comparable to sota methods across multiple image
translation datasets while enabling real-time inference.
\\ ( https://arxiv.org/abs/2511.20307 ,  15903kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20319
Date: Tue, 25 Nov 2025 13:53:54 GMT   (603kb)

Title: IrisNet: Infrared Image Status Awareness Meta Decoder for Infrared Small
 Targets Detection
Authors: Xuelin Qian, Jiaming Lu, Zixuan Wang, Wenxuan Wang, Zhongling Huang,
 Dingwen Zhang, Junwei Han
Categories: cs.CV
Comments: 10pages,5figures
\\
 Infrared Small Target Detection (IRSTD) faces significant challenges due to
low signal-to-noise ratios, complex backgrounds, and the absence of discernible
target features. While deep learning-based encoder-decoder frameworks have
advanced the field, their static pattern learning suffers from pattern drift
across diverse scenarios (\emph{e.g.}, day/night variations,
sky/maritime/ground domains), limiting robustness. To address this, we propose
IrisNet, a novel meta-learned framework that dynamically adapts detection
strategies to the input infrared image status. Our approach establishes a
dynamic mapping between infrared image features and entire decoder parameters
via an image-to-decoder transformer. More concretely, we represent the
parameterized decoder as a structured 2D tensor preserving hierarchical layer
correlations and enable the transformer to model inter-layer dependencies
through self-attention while generating adaptive decoding patterns via
cross-attention. To further enhance the perception ability of infrared images,
we integrate high-frequency components to supplement target-position and
scene-edge information. Experiments on NUDT-SIRST, NUAA-SIRST, and IRSTD-1K
datasets demonstrate the superiority of our IrisNet, achieving state-of-the-art
performance.
\\ ( https://arxiv.org/abs/2511.20319 ,  603kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20325
Date: Tue, 25 Nov 2025 13:57:24 GMT   (4028kb)

Title: AD-R1: Closed-Loop Reinforcement Learning for End-to-End Autonomous
 Driving with Impartial World Models
Authors: Tianyi Yan, Tao Tang, Xingtai Gui, Yongkang Li, Jiasen Zhesng, Weiyao
 Huang, Lingdong Kong, Wencheng Han, Xia Zhou, Xueyang Zhang, Yifei Zhan, Kun
 Zhan, Cheng-zhong Xu, Jianbing Shen
Categories: cs.CV
\\
 End-to-end models for autonomous driving hold the promise of learning complex
behaviors directly from sensor data, but face critical challenges in safety and
handling long-tail events. Reinforcement Learning (RL) offers a promising path
to overcome these limitations, yet its success in autonomous driving has been
elusive. We identify a fundamental flaw hindering this progress: a deep seated
optimistic bias in the world models used for RL. To address this, we introduce
a framework for post-training policy refinement built around an Impartial World
Model. Our primary contribution is to teach this model to be honest about
danger. We achieve this with a novel data synthesis pipeline, Counterfactual
Synthesis, which systematically generates a rich curriculum of plausible
collisions and off-road events. This transforms the model from a passive scene
completer into a veridical forecaster that remains faithful to the causal link
between actions and outcomes. We then integrate this Impartial World Model into
our closed-loop RL framework, where it serves as an internal critic. During
refinement, the agent queries the critic to ``dream" of the outcomes for
candidate actions. We demonstrate through extensive experiments, including on a
new Risk Foreseeing Benchmark, that our model significantly outperforms
baselines in predicting failures. Consequently, when used as a critic, it
enables a substantial reduction in safety violations in challenging
simulations, proving that teaching a model to dream of danger is a critical
step towards building truly safe and intelligent autonomous agents.
\\ ( https://arxiv.org/abs/2511.20325 ,  4028kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20332
Date: Tue, 25 Nov 2025 14:09:44 GMT   (708kb)

Title: 3D Motion Perception of Binocular Vision Target with PID-CNN
Authors: Shi Jiazhao, Pan Pan, Shi Haotian
Categories: cs.CV cs.AI
Comments: 7 pages, 9 figures, 2 tables
\\
 This article trained a network for perceiving three-dimensional motion
information of binocular vision target, which can provide real-time
three-dimensional coordinate, velocity, and acceleration, and has a basic
spatiotemporal perception capability. Understood the ability of neural networks
to fit nonlinear problems from the perspective of PID. Considered a
single-layer neural network as using a second-order difference equation and a
nonlinearity to describe a local problem. Multilayer networks gradually
transform the raw representation to the desired representation through multiple
such combinations. Analysed some reference principles for designing neural
networks. Designed a relatively small PID convolutional neural network, with a
total of 17 layers and 413 thousand parameters. Implemented a simple but
practical feature reuse method by concatenation and pooling. The network was
trained and tested using the simulated randomly moving ball datasets, and the
experimental results showed that the prediction accuracy was close to the upper
limit that the input image resolution can represent. Analysed the experimental
results and errors, as well as the existing shortcomings and possible
directions for improvement. Finally, discussed the advantages of
high-dimensional convolution in improving computational efficiency and feature
space utilization. As well as the potential advantages of using PID information
to implement memory and attention mechanisms.
\\ ( https://arxiv.org/abs/2511.20332 ,  708kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20335
Date: Tue, 25 Nov 2025 14:14:17 GMT   (4744kb)

Title: ShelfRectNet: Single View Shelf Image Rectification with Homography
 Estimation
Authors: Onur Berk Tore, Ibrahim Samil Yalciner, Server Calap
Categories: cs.CV
\\
 Estimating homography from a single image remains a challenging yet
practically valuable task, particularly in domains like retail, where only one
viewpoint is typically available for shelf monitoring and product alignment. In
this paper, we present a deep learning framework that predicts a 4-point
parameterized homography matrix to rectify shelf images captured from arbitrary
angles. Our model leverages a ConvNeXt-based backbone for enhanced feature
representation and adopts normalized coordinate regression for improved
stability. To address data scarcity and promote generalization, we introduce a
novel augmentation strategy by modeling and sampling synthetic homographies.
Our method achieves a mean corner error of 1.298 pixels on the test set. When
compared with both classical computer vision and deep learning-based
approaches, our method demonstrates competitive performance in both accuracy
and inference speed. Together, these results establish our approach as a robust
and efficient solution for realworld single-view rectification. To encourage
further research in this domain, we will make our dataset, ShelfRectSet, and
code publicly available
\\ ( https://arxiv.org/abs/2511.20335 ,  4744kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20343
Date: Tue, 25 Nov 2025 14:23:04 GMT   (48626kb)

Title: AMB3R: Accurate Feed-forward Metric-scale 3D Reconstruction with Backend
Authors: Hengyi Wang, Lourdes Agapito
Categories: cs.CV
Comments: Project page: https://hengyiwang.github.io/projects/amber
\\
 We present AMB3R, a multi-view feed-forward model for dense 3D reconstruction
on a metric-scale that addresses diverse 3D vision tasks. The key idea is to
leverage a sparse, yet compact, volumetric scene representation as our backend,
enabling geometric reasoning with spatial compactness. Although trained solely
for multi-view reconstruction, we demonstrate that AMB3R can be seamlessly
extended to uncalibrated visual odometry (online) or large-scale structure from
motion without the need for task-specific fine-tuning or test-time
optimization. Compared to prior pointmap-based models, our approach achieves
state-of-the-art performance in camera pose, depth, and metric-scale
estimation, 3D reconstruction, and even surpasses optimization-based SLAM and
SfM methods with dense reconstruction priors on common benchmarks.
\\ ( https://arxiv.org/abs/2511.20343 ,  48626kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20348
Date: Tue, 25 Nov 2025 14:25:19 GMT   (12558kb)

Title: Material-informed Gaussian Splatting for 3D World Reconstruction in a
 Digital Twin
Authors: Jo\~ao Malheiro Silva, Andy Huynh, Tong Duy Son, Holger Caesar
Categories: cs.CV cs.RO
Comments: 8 pages, 5 figures. Submitted to IEEE Intelligent Vehicles Symposium
 (IV) 2026 for possible publication
\\
 3D reconstruction for Digital Twins often relies on LiDAR-based methods,
which provide accurate geometry but lack the semantics and textures naturally
captured by cameras. Traditional LiDAR-camera fusion approaches require complex
calibration and still struggle with certain materials like glass, which are
visible in images but poorly represented in point clouds. We propose a
camera-only pipeline that reconstructs scenes using 3D Gaussian Splatting from
multi-view images, extracts semantic material masks via vision models, converts
Gaussian representations to mesh surfaces with projected material labels, and
assigns physics-based material properties for accurate sensor simulation in
modern graphics engines and simulators. This approach combines photorealistic
reconstruction with physics-based material assignment, providing sensor
simulation fidelity comparable to LiDAR-camera fusion while eliminating
hardware complexity and calibration requirements. We validate our camera-only
method using an internal dataset from an instrumented test vehicle, leveraging
LiDAR as ground truth for reflectivity validation alongside image similarity
metrics.
\\ ( https://arxiv.org/abs/2511.20348 ,  12558kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20351
Date: Tue, 25 Nov 2025 14:30:10 GMT   (36877kb)

Title: Thinking in 360{\deg}: Humanoid Visual Search in the Wild
Authors: Heyang Yu, Yinan Han, Xiangyu Zhang, Baiqiao Yin, Bowen Chang, Xiangyu
 Han, Xinhao Liu, Jing Zhang, Marco Pavone, Chen Feng, Saining Xie, Yiming Li
Categories: cs.CV
\\
 Humans rely on the synergistic control of head (cephalomotor) and eye
(oculomotor) to efficiently search for visual information in 360{\deg}.
However, prior approaches to visual search are limited to a static image,
neglecting the physical embodiment and its interaction with the 3D world. How
can we develop embodied visual search agents as efficient as humans while
bypassing the constraints imposed by real-world hardware? To this end, we
propose humanoid visual search where a humanoid agent actively rotates its head
to search for objects or paths in an immersive world represented by a 360{\deg}
panoramic image. To study visual search in visually-crowded real-world
scenarios, we build H* Bench, a new benchmark that moves beyond household
scenes to challenging in-the-wild scenes that necessitate advanced
visual-spatial reasoning capabilities, such as transportation hubs, large-scale
retail spaces, urban streets, and public institutions. Our experiments first
reveal that even top-tier proprietary models falter, achieving only ~30%
success in object and path search. We then use post-training techniques to
enhance the open-source Qwen2.5-VL, increasing its success rate by over
threefold for both object search (14.83% to 47.38%) and path search (6.44% to
24.94%). Notably, the lower ceiling of path search reveals its inherent
difficulty, which we attribute to the demand for sophisticated spatial
commonsense. Our results not only show a promising path forward but also
quantify the immense challenge that remains in building MLLM agents that can be
seamlessly integrated into everyday human life.
\\ ( https://arxiv.org/abs/2511.20351 ,  36877kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20354
Date: Tue, 25 Nov 2025 14:33:31 GMT   (2396kb)

Title: GS-Checker: Tampering Localization for 3D Gaussian Splatting
Authors: Haoliang Han, Ziyuan Luo, Jun Qi, Anderson Rocha, Renjie Wan
Categories: cs.CV
Comments: Accepted by AAAI2026
\\
 Recent advances in editing technologies for 3D Gaussian Splatting (3DGS) have
made it simple to manipulate 3D scenes. However, these technologies raise
concerns about potential malicious manipulation of 3D content. To avoid such
malicious applications, localizing tampered regions becomes crucial. In this
paper, we propose GS-Checker, a novel method for locating tampered areas in
3DGS models. Our approach integrates a 3D tampering attribute into the 3D
Gaussian parameters to indicate whether the Gaussian has been tampered.
Additionally, we design a 3D contrastive mechanism by comparing the similarity
of key attributes between 3D Gaussians to seek tampering cues at 3D level.
Furthermore, we introduce a cyclic optimization strategy to refine the 3D
tampering attribute, enabling more accurate tampering localization. Notably,
our approach does not require expensive 3D labels for supervision. Extensive
experimental results demonstrate the effectiveness of our proposed method to
locate the tampered 3DGS area.
\\ ( https://arxiv.org/abs/2511.20354 ,  2396kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20359
Date: Tue, 25 Nov 2025 14:39:17 GMT   (1848kb)

Title: From Passive Perception to Active Memory: A Weakly Supervised Image
 Manipulation Localization Framework Driven by Coarse-Grained Annotations
Authors: Zhiqing Guo, Dongdong Xi, Songlin Li, Gaobo Yang
Categories: cs.CV cs.AI
Comments: Accepted by AAAI 2026
\\
 Image manipulation localization (IML) faces a fundamental trade-off between
minimizing annotation cost and achieving fine-grained localization accuracy.
Existing fully-supervised IML methods depend heavily on dense pixel-level mask
annotations, which limits scalability to large datasets or real-world
deployment.In contrast, the majority of existing weakly-supervised IML
approaches are based on image-level labels, which greatly reduce annotation
effort but typically lack precise spatial localization. To address this
dilemma, we propose BoxPromptIML, a novel weakly-supervised IML framework that
effectively balances annotation cost and localization performance.
Specifically, we propose a coarse region annotation strategy, which can
generate relatively accurate manipulation masks at lower cost. To improve model
efficiency and facilitate deployment, we further design an efficient
lightweight student model, which learns to perform fine-grained localization
through knowledge distillation from a fixed teacher model based on the Segment
Anything Model (SAM). Moreover, inspired by the human subconscious memory
mechanism, our feature fusion module employs a dual-guidance strategy that
actively contextualizes recalled prototypical patterns with real-time
observational cues derived from the input. Instead of passive feature
extraction, this strategy enables a dynamic process of knowledge recollection,
where long-term memory is adapted to the specific context of the current image,
significantly enhancing localization accuracy and robustness. Extensive
experiments across both in-distribution and out-of-distribution datasets show
that BoxPromptIML outperforms or rivals fully-supervised models, while
maintaining strong generalization, low annotation cost, and efficient
deployment characteristics.
\\ ( https://arxiv.org/abs/2511.20359 ,  1848kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20366
Date: Tue, 25 Nov 2025 14:45:59 GMT   (19385kb)

Title: VGGTFace: Topologically Consistent Facial Geometry Reconstruction in the
 Wild
Authors: Xin Ming, Yuxuan Han, Tianyu Huang, Feng Xu
Categories: cs.CV
\\
 Reconstructing topologically consistent facial geometry is crucial for the
digital avatar creation pipelines. Existing methods either require tedious
manual efforts, lack generalization to in-the-wild data, or are constrained by
the limited expressiveness of 3D Morphable Models. To address these
limitations, we propose VGGTFace, an automatic approach that innovatively
applies the 3D foundation model, \emph{i.e.} VGGT, for topologically consistent
facial geometry reconstruction from in-the-wild multi-view images captured by
everyday users. Our key insight is that, by leveraging VGGT, our method
naturally inherits strong generalization ability and expressive power from its
large-scale training and point map representation. However, it is unclear how
to reconstruct a topologically consistent mesh from VGGT, as the topology
information is missing in its prediction. To this end, we augment VGGT with
Pixel3DMM for injecting topology information via pixel-aligned UV values. In
this manner, we convert the pixel-aligned point map of VGGT to a point cloud
with topology. Tailored to this point cloud with known topology, we propose a
novel Topology-Aware Bundle Adjustment strategy to fuse them, where we
construct a Laplacian energy for the Bundle Adjustment objective. Our method
achieves high-quality reconstruction in 10 seconds for 16 views on a single
NVIDIA RTX 4090. Experiments demonstrate state-of-the-art results on benchmarks
and impressive generalization to in-the-wild data. Code is available at
https://github.com/grignarder/vggtface.
\\ ( https://arxiv.org/abs/2511.20366 ,  19385kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20390
Date: Tue, 25 Nov 2025 15:12:10 GMT   (820kb)

Title: FREE: Uncertainty-Aware Autoregression for Parallel Diffusion
 Transformers
Authors: Xinwan Wen, Bowen Li, Jiajun Luo, Ye Li, Zhi Wang
Categories: cs.CV
\\
 Diffusion Transformers (DiTs) achieve state-of-the-art generation quality but
require long sequential denoising trajectories, leading to high inference
latency. Recent speculative inference methods enable lossless parallel sampling
in U-Net-based diffusion models via a drafter-verifier scheme, but their
acceleration is limited on DiTs due to insufficient draft accuracy during
verification. To address this limitation, we analyze the DiTs' feature dynamics
and find the features of the final transformer layer (top-block) exhibit strong
temporal consistency and rich semantic abstraction. Based on this insight, we
propose FREE, a novel framework that employs a lightweight drafter to perform
feature-level autoregression with parallel verification, guaranteeing lossless
acceleration with theoretical and empirical support. Meanwhile, prediction
variance (uncertainty) of DiTs naturally increases in later denoising steps,
reducing acceptance rates under speculative sampling. To mitigate this effect,
we further introduce an uncertainty-guided relaxation strategy, forming FREE
(relax), which dynamically adjusts the acceptance probability in response to
uncertainty levels. Experiments on ImageNet-$512^2$ show that FREE achieves up
to $1.86 \times$ acceleration, and FREE (relax) further reaches $2.25 \times$
speedup while maintaining high perceptual and quantitative fidelity in
generation quality.
\\ ( https://arxiv.org/abs/2511.20390 ,  820kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20401
Date: Tue, 25 Nov 2025 15:28:10 GMT   (8109kb)

Title: A Training-Free Approach for Multi-ID Customization via Attention
 Adjustment and Spatial Control
Authors: Jiawei Lin, Guanlong Jiao, Jianjin Xu
Categories: cs.CV
\\
 Multi-ID customization is an interesting topic in computer vision and
attracts considerable attention recently. Given the ID images of multiple
individuals, its purpose is to generate a customized image that seamlessly
integrates them while preserving their respective identities. Compared to
single-ID customization, multi-ID customization is much more difficult and
poses two major challenges. First, since the multi-ID customization model is
trained to reconstruct an image from the cropped person regions, it often
encounters the copy-paste issue during inference, leading to lower quality.
Second, the model also suffers from inferior text controllability. The
generated result simply combines multiple persons into one image, regardless of
whether it is aligned with the input text. In this work, we propose MultiID to
tackle this challenging task in a training-free manner. Since the existing
single-ID customization models have less copy-paste issue, our key idea is to
adapt these models to achieve multi-ID customization. To this end, we present
an ID-decoupled cross-attention mechanism, injecting distinct ID embeddings
into the corresponding image regions and thus generating multi-ID outputs. To
enhance the generation controllability, we introduce three critical strategies,
namely the local prompt, depth-guided spatial control, and extended
self-attention, making the results more consistent with the text prompts and ID
images. We also carefully build a benchmark, called IDBench, for evaluation.
The extensive qualitative and quantitative results demonstrate the
effectiveness of MultiID in solving the aforementioned two challenges. Its
performance is comparable or even better than the training-based multi-ID
customization methods.
\\ ( https://arxiv.org/abs/2511.20401 ,  8109kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20410
Date: Tue, 25 Nov 2025 15:36:20 GMT   (17353kb)

Title: Image-Free Timestep Distillation via Continuous-Time Consistency with
 Trajectory-Sampled Pairs
Authors: Bao Tang, Shuai Zhang, Yueting Zhu, Jijun Xiang, Xin Yang, Li Yu,
 Wenyu Liu, Xinggang Wang
Categories: cs.CV
\\
 Timestep distillation is an effective approach for improving the generation
efficiency of diffusion models. The Consistency Model (CM), as a
trajectory-based framework, demonstrates significant potential due to its
strong theoretical foundation and high-quality few-step generation.
Nevertheless, current continuous-time consistency distillation methods still
rely heavily on training data and computational resources, hindering their
deployment in resource-constrained scenarios and limiting their scalability to
diverse domains. To address this issue, we propose Trajectory-Backward
Consistency Model (TBCM), which eliminates the dependence on external training
data by extracting latent representations directly from the teacher model's
generation trajectory. Unlike conventional methods that require VAE encoding
and large-scale datasets, our self-contained distillation paradigm
significantly improves both efficiency and simplicity. Moreover, the
trajectory-extracted samples naturally bridge the distribution gap between
training and inference, thereby enabling more effective knowledge transfer.
Empirically, TBCM achieves 6.52 FID and 28.08 CLIP scores on MJHQ-30k under
one-step generation, while reducing training time by approximately 40% compared
to Sana-Sprint and saving a substantial amount of GPU memory, demonstrating
superior efficiency without sacrificing quality. We further reveal the
diffusion-generation space discrepancy in continuous-time consistency
distillation and analyze how sampling strategies affect distillation
performance, offering insights for future distillation research. GitHub Link:
https://github.com/hustvl/TBCM.
\\ ( https://arxiv.org/abs/2511.20410 ,  17353kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20415
Date: Tue, 25 Nov 2025 15:40:12 GMT   (12301kb)

Title: MajutsuCity: Language-driven Aesthetic-adaptive City Generation with
 Controllable 3D Assets and Layouts
Authors: Zilong Huang, Jun He, Xiaobin Huang, Ziyi Xiong, Yang Luo, Junyan Ye,
 Weijia Li, Yiping Chen, Ting Han
Categories: cs.CV
Comments: 13 pages, 6 figures
\\
 Generating realistic 3D cities is fundamental to world models, virtual
reality, and game development, where an ideal urban scene must satisfy both
stylistic diversity, fine-grained, and controllability. However, existing
methods struggle to balance the creative flexibility offered by text-based
generation with the object-level editability enabled by explicit structural
representations. We introduce MajutsuCity, a natural language-driven and
aesthetically adaptive framework for synthesizing structurally consistent and
stylistically diverse 3D urban scenes. MajutsuCity represents a city as a
composition of controllable layouts, assets, and materials, and operates
through a four-stage pipeline. To extend controllability beyond initial
generation, we further integrate MajutsuAgent, an interactive language-grounded
editing agent} that supports five object-level operations. To support
photorealistic and customizable scene synthesis, we also construct
MajutsuDataset, a high-quality multimodal dataset} containing 2D semantic
layouts and height maps, diverse 3D building assets, and curated PBR materials
and skyboxes, each accompanied by detailed annotations. Meanwhile, we develop a
practical set of evaluation metrics, covering key dimensions such as structural
consistency, scene complexity, material fidelity, and lighting atmosphere.
Extensive experiments demonstrate MajutsuCity reduces layout FID by 83.7%
compared with CityDreamer and by 20.1% over CityCraft. Our method ranks first
across all AQS and RDR scores, outperforming existing methods by a clear
margin. These results confirm MajutsuCity as a new state-of-the-art in
geometric fidelity, stylistic adaptability, and semantic controllability for 3D
city generation. We expect our framework can inspire new avenues of research in
3D city generation. Our dataset and code will be released at
https://github.com/LongHZ140516/MajutsuCity.
\\ ( https://arxiv.org/abs/2511.20415 ,  12301kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20418
Date: Tue, 25 Nov 2025 15:42:33 GMT   (19918kb)

Title: StableTrack: Stabilizing Multi-Object Tracking on Low-Frequency
 Detections
Authors: Matvei Shelukhan, Timur Mamedov, Karina Kvanchiani
Categories: cs.CV cs.AI cs.LG
\\
 Multi-object tracking (MOT) is one of the most challenging tasks in computer
vision, where it is important to correctly detect objects and associate these
detections across frames. Current approaches mainly focus on tracking objects
in each frame of a video stream, making it almost impossible to run the model
under conditions of limited computing resources. To address this issue, we
propose StableTrack, a novel approach that stabilizes the quality of tracking
on low-frequency detections. Our method introduces a new two-stage matching
strategy to improve the cross-frame association between low-frequency
detections. We propose a novel Bbox-Based Distance instead of the conventional
Mahalanobis distance, which allows us to effectively match objects using the
Re-ID model. Furthermore, we integrate visual tracking into the Kalman Filter
and the overall tracking pipeline. Our method outperforms current
state-of-the-art trackers in the case of low-frequency detections, achieving
$\textit{11.6%}$ HOTA improvement at $\textit{1}$ Hz on MOT17-val, while
keeping up with the best approaches on the standard MOT17, MOT20, and
DanceTrack benchmarks with full-frequency detections.
\\ ( https://arxiv.org/abs/2511.20418 ,  19918kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20426
Date: Tue, 25 Nov 2025 15:52:58 GMT   (19414kb)

Title: Block Cascading: Training Free Acceleration of Block-Causal Video Models
Authors: Hmrishav Bandyopadhyay, Nikhil Pinnaparaju, Rahim Entezari, Jim Scott,
 Yi-Zhe Song, Varun Jampani
Categories: cs.CV cs.AI
\\
 Block-causal video generation faces a stark speed-quality trade-off: small
1.3B models manage only 16 FPS while large 14B models crawl at 4.5 FPS, forcing
users to choose between responsiveness and quality. Block Cascading
significantly mitigates this trade-off through training-free parallelization.
Our key insight: future video blocks do not need fully denoised current blocks
to begin generation. By starting block generation with partially denoised
context from predecessors, we transform sequential pipelines into parallel
cascades where multiple blocks denoise simultaneously. With 5 GPUs exploiting
temporal parallelism, we achieve ~2x acceleration across all model scales: 1.3B
models accelerate from 16 to 30 FPS, 14B models from 4.5 to 12.5 FPS. Beyond
inference speed, Block Cascading eliminates overhead from KV-recaching (of
~200ms) during context switches for interactive generation. Extensive
evaluations validated against multiple block-causal pipelines demonstrate no
significant loss in generation quality when switching from block-causal to
Block Cascading pipelines for inference. Project Page:
https://hmrishavbandy.github.io/block_cascading_page/
\\ ( https://arxiv.org/abs/2511.20426 ,  19414kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20431
Date: Tue, 25 Nov 2025 16:03:38 GMT   (7931kb)

Title: BRIC: Bridging Kinematic Plans and Physical Control at Test Time
Authors: Dohun Lim, Minji Kim, Jaewoon Lim, Sungchan Kim
Categories: cs.CV cs.RO
\\
 We propose BRIC, a novel test-time adaptation (TTA) framework that enables
long-term human motion generation by resolving execution discrepancies between
diffusion-based kinematic motion planners and reinforcement learning-based
physics controllers. While diffusion models can generate diverse and expressive
motions conditioned on text and scene context, they often produce physically
implausible outputs, leading to execution drift during simulation. To address
this, BRIC dynamically adapts the physics controller to noisy motion plans at
test time, while preserving pre-trained skills via a loss function that
mitigates catastrophic forgetting. In addition, BRIC introduces a lightweight
test-time guidance mechanism that steers the diffusion model in the signal
space without updating its parameters. By combining both adaptation strategies,
BRIC ensures consistent and physically plausible long-term executions across
diverse environments in an effective and efficient manner. We validate the
effectiveness of BRIC on a variety of long-term tasks, including motion
composition, obstacle avoidance, and human-scene interaction, achieving
state-of-the-art performance across all tasks.
\\ ( https://arxiv.org/abs/2511.20431 ,  7931kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20439
Date: Tue, 25 Nov 2025 16:12:32 GMT   (1522kb)

Title: Object-Centric Vision Token Pruning for Vision Language Models
Authors: Guangyuan Li, Rongzhen Zhao, Jinhong Deng, Yanbo Wang, Joni Pajarinen
Categories: cs.CV cs.AI
\\
 In Vision Language Models (VLMs), vision tokens are quantity-heavy yet
information-dispersed compared with language tokens, thus consume too much
unnecessary computation. Pruning redundant vision tokens for high VLM inference
efficiency has been continuously studied but all existing methods resort to
indirect and non-guaranteed ways. We propose OC-VTP, a direct and guaranteed
approach to select the most representative vision tokens for high-efficiency
yet accuracy-preserving VLM inference. Our OC-VTP requires merely light-weight
pre-training of a small object-centric vision token pruner, which can then be
inserted into existing VLMs, without fine-tuning of any models on any datasets.
It is gauranteed that the most representative vision tokens are kept by
minimizing the error in reconstructing the original unpruned tokens from the
selected ones. Across any vision pruning ratios, i.e., inference efficiency,
our OC-VTP consistently helps mainstream VLMs to preserve the highest inference
accuracy. Our pruning also demonstrates interesting interpretability. Our codes
are available at https://github.com/GarryLarry010131/OC-VTP.
\\ ( https://arxiv.org/abs/2511.20439 ,  1522kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20446
Date: Tue, 25 Nov 2025 16:17:23 GMT   (46829kb)

Title: Learning to Generate Human-Human-Object Interactions from Textual
 Descriptions
Authors: Jeonghyeon Na, Sangwon Baik, Inhee Lee, Junyoung Lee, Hanbyul Joo
Categories: cs.CV
Comments: Project Page: https://tlb-miss.github.io/hhoi/
\\
 The way humans interact with each other, including interpersonal distances,
spatial configuration, and motion, varies significantly across different
situations. To enable machines to understand such complex, context-dependent
behaviors, it is essential to model multiple people in relation to the
surrounding scene context. In this paper, we present a novel research problem
to model the correlations between two people engaged in a shared interaction
involving an object. We refer to this formulation as Human-Human-Object
Interactions (HHOIs). To overcome the lack of dedicated datasets for HHOIs, we
present a newly captured HHOIs dataset and a method to synthesize HHOI data by
leveraging image generative models. As an intermediary, we obtain individual
human-object interaction (HOIs) and human-human interaction (HHIs) from the
HHOIs, and with these data, we train an text-to-HOI and text-to-HHI model using
score-based diffusion model. Finally, we present a unified generative framework
that integrates the two individual model, capable of synthesizing complete
HHOIs in a single advanced sampling process. Our method extends HHOI generation
to multi-human settings, enabling interactions involving more than two
individuals. Experimental results show that our method generates realistic
HHOIs conditioned on textual descriptions, outperforming previous approaches
that focus only on single-human HOIs. Furthermore, we introduce multi-human
motion generation involving objects as an application of our framework.
\\ ( https://arxiv.org/abs/2511.20446 ,  46829kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20460
Date: Tue, 25 Nov 2025 16:25:54 GMT   (26633kb)

Title: Look Where It Matters: Training-Free Ultra-HR Remote Sensing VQA via
 Adaptive Zoom Search
Authors: Yunqi Zhou and Chengjie Jiang and Chun Yuan and Jing Li
Categories: cs.CV
Comments: 17 pages, 8 figures
\\
 With advances in satellite constellations, sensor technologies, and imaging
pipelines, ultra-high-resolution (Ultra-HR) remote sensing imagery is becoming
increasingly widespread. However, current remote sensing foundation models are
ill-suited to such inputs: full-image encoding exhausts token and memory
budgets, while resize-based preprocessing loses fine-grained and
answer-critical details. In this context, guiding the model look where it
matters before prediction becomes crucial. Therefore, we present ZoomSearch, a
training-free, plug-and-play pipeline that decouples 'where to look' from 'how
to answer' for Ultra-HR Remote Sensing Visual Question Answering (RS-VQA).
ZoomSearch combines Adaptive Multi-Branch Zoom Search, which performs a
hierarchical search over image patches to localize query-relevant regions, with
Layout-Aware Patch Reassembly, which reorganizes the selected patches into a
compact, layout-faithful canvas. We conduct comprehensive experiments on
Ultra-HR RS-VQA benchmarks MME-RealWorld-RS and LRS-VQA, comparing against (i)
strong general foundation models, (ii) remote sensing foundation models, (iii)
Ultra-HR RS-VQA methods, and (iv) plug-and-play search-based VQA methods. When
integrated with LLaVA-ov, ZoomSearch attains state-of-the-art accuracy across
diverse tasks, improving the LLaVA-ov baseline by 26.3% on LRS-VQA and 114.8\%
on MME-RealWorld-RS. Meanwhile, it achieves much higher inference efficiency,
outperforming prior search-based methods by 20%~44% in speed.
\\ ( https://arxiv.org/abs/2511.20460 ,  26633kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20462
Date: Tue, 25 Nov 2025 16:27:58 GMT   (33368kb)

Title: STARFlow-V: End-to-End Video Generative Modeling with Normalizing Flow
Authors: Jiatao Gu, Ying Shen, Tianrong Chen, Laurent Dinh, Yuyang Wang, Miguel
 Angel Bautista, David Berthelot, Josh Susskind, Shuangfei Zhai
Categories: cs.CV cs.LG
Comments: 21 pages
\\
 Normalizing flows (NFs) are end-to-end likelihood-based generative models for
continuous data, and have recently regained attention with encouraging progress
on image generation. Yet in the video generation domain, where spatiotemporal
complexity and computational cost are substantially higher, state-of-the-art
systems almost exclusively rely on diffusion-based models. In this work, we
revisit this design space by presenting STARFlow-V, a normalizing flow-based
video generator with substantial benefits such as end-to-end learning, robust
causal prediction, and native likelihood estimation. Building upon the recently
proposed STARFlow, STARFlow-V operates in the spatiotemporal latent space with
a global-local architecture which restricts causal dependencies to a global
latent space while preserving rich local within-frame interactions. This eases
error accumulation over time, a common pitfall of standard autoregressive
diffusion model generation. Additionally, we propose flow-score matching, which
equips the model with a light-weight causal denoiser to improve the video
generation consistency in an autoregressive fashion. To improve the sampling
efficiency, STARFlow-V employs a video-aware Jacobi iteration scheme that
recasts inner updates as parallelizable iterations without breaking causality.
Thanks to the invertible structure, the same model can natively support
text-to-video, image-to-video as well as video-to-video generation tasks.
Empirically, STARFlow-V achieves strong visual fidelity and temporal
consistency with practical sampling throughput relative to diffusion-based
baselines. These results present the first evidence, to our knowledge, that NFs
are capable of high-quality autoregressive video generation, establishing them
as a promising research direction for building world models. Code and generated
samples are available at https://github.com/apple/ml-starflow.
\\ ( https://arxiv.org/abs/2511.20462 ,  33368kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20469
Date: Tue, 25 Nov 2025 16:33:45 GMT   (1258kb)

Title: Dance Style Classification using Laban-Inspired and Frequency-Domain
 Motion Features
Authors: Ben Hamscher, Arnold Brosch, Nicolas Binninger, Maksymilian Jan Dejna
 and Kira Maag
Categories: cs.CV cs.LG
\\
 Dance is an essential component of human culture and serves as a tool for
conveying emotions and telling stories. Identifying and distinguishing dance
genres based on motion data is a complex problem in human activity recognition,
as many styles share similar poses, gestures, and temporal motion patterns.
This work presents a lightweight framework for classifying dance styles that
determines motion characteristics based on pose estimates extracted from
videos. We propose temporal-spatial descriptors inspired by Laban Movement
Analysis. These features capture local joint dynamics such as velocity,
acceleration, and angular movement of the upper body, enabling a structured
representation of spatial coordination. To further encode rhythmic and periodic
aspects of movement, we integrate Fast Fourier Transform features that
characterize movement patterns in the frequency domain. The proposed approach
achieves robust classification of different dance styles with low computational
effort, as complex model architectures are not required, and shows that
interpretable motion representations can effectively capture stylistic nuances.
\\ ( https://arxiv.org/abs/2511.20469 ,  1258kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20474
Date: Tue, 25 Nov 2025 16:35:42 GMT   (2251kb)

Title: Modular Deep Learning Framework for Assistive Perception: Gaze, Affect,
 and Speaker Identification
Authors: Akshit Pramod Anchan, Jewelith Thomas, Sritama Roy
Categories: cs.CV cs.LG
Comments: 10 pages, 9 figures, and 3 tables
MSC-class: 68T45
ACM-class: I.2.10; I.2.7; I.5.4
\\
 Developing comprehensive assistive technologies requires the seamless
integration of visual and auditory perception. This research evaluates the
feasibility of a modular architecture inspired by core functionalities of
perceptive systems like 'Smart Eye.' We propose and benchmark three independent
sensing modules: a Convolutional Neural Network (CNN) for eye state detection
(drowsiness/attention), a deep CNN for facial expression recognition, and a
Long Short-Term Memory (LSTM) network for voice-based speaker identification.
Utilizing the Eyes Image, FER2013, and customized audio datasets, our models
achieved accuracies of 93.0%, 97.8%, and 96.89%, respectively. This study
demonstrates that lightweight, domain-specific models can achieve high fidelity
on discrete tasks, establishing a validated foundation for future real-time,
multimodal integration in resource-constrained assistive devices.
\\ ( https://arxiv.org/abs/2511.20474 ,  2251kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20501
Date: Tue, 25 Nov 2025 17:08:14 GMT   (3650kb)

Title: A Physics-Informed Loss Function for Boundary-Consistent and Robust
 Artery Segmentation in DSA Sequences
Authors: Muhammad Irfan, Nasir Rahim and Khalid Mahmood Malik
Categories: cs.CV cs.LG
\\
 Accurate extraction and segmentation of the cerebral arteries from digital
subtraction angiography (DSA) sequences is essential for developing reliable
clinical management models of complex cerebrovascular diseases. Conventional
loss functions often rely solely on pixel-wise overlap, overlooking the
geometric and physical consistency of vascular boundaries, which can lead to
fragmented or unstable vessel predictions. To overcome this limitation, we
propose a novel \textit{Physics-Informed Loss} (PIL) that models the
interaction between the predicted and ground-truth boundaries as an elastic
process inspired by dislocation theory in materials physics. This formulation
introduces a physics-based regularization term that enforces smooth contour
evolution and structural consistency, allowing the network to better capture
fine vascular geometry. The proposed loss is integrated into several
segmentation architectures, including U-Net, U-Net++, SegFormer, and MedFormer,
and evaluated on two public benchmarks: DIAS and DSCA. Experimental results
demonstrate that PIL consistently outperforms conventional loss functions such
as Cross-Entropy, Dice, Active Contour, and Surface losses, achieving superior
sensitivity, F1 score, and boundary coherence. These findings confirm that the
incorporation of physics-based boundary interactions into deep neural networks
improves both the precision and robustness of vascular segmentation in dynamic
angiographic imaging. The implementation of the proposed method is publicly
available at https://github.com/irfantahir301/Physicsis_loss.
\\ ( https://arxiv.org/abs/2511.20501 ,  3650kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20513
Date: Tue, 25 Nov 2025 17:19:10 GMT   (3644kb)

Title: DesignPref: Capturing Personal Preferences in Visual Design Generation
Authors: Yi-Hao Peng, Jeffrey P. Bigham, Jason Wu
Categories: cs.CV cs.AI cs.CL cs.HC
\\
 Generative models, such as large language models and text-to-image diffusion
models, are increasingly used to create visual designs like user interfaces
(UIs) and presentation slides. Finetuning and benchmarking these generative
models have often relied on datasets of human-annotated design preferences.
Yet, due to the subjective and highly personalized nature of visual design,
preference varies widely among individuals. In this paper, we study this
problem by introducing DesignPref, a dataset of 12k pairwise comparisons of UI
design generation annotated by 20 professional designers with multi-level
preference ratings. We found that among trained designers, substantial levels
of disagreement exist (Krippendorff's alpha = 0.25 for binary preferences).
Natural language rationales provided by these designers indicate that
disagreements stem from differing perceptions of various design aspect
importance and individual preferences. With DesignPref, we demonstrate that
traditional majority-voting methods for training aggregated judge models often
do not accurately reflect individual preferences. To address this challenge, we
investigate multiple personalization strategies, particularly fine-tuning or
incorporating designer-specific annotations into RAG pipelines. Our results
show that personalized models consistently outperform aggregated baseline
models in predicting individual designers' preferences, even when using 20
times fewer examples. Our work provides the first dataset to study personalized
visual design evaluation and support future research into modeling individual
design taste.
\\ ( https://arxiv.org/abs/2511.20513 ,  3644kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20515
Date: Tue, 25 Nov 2025 17:19:47 GMT   (8213kb)

Title: AlignBench: Benchmarking Fine-Grained Image-Text Alignment with
 Synthetic Image-Caption Pairs
Authors: Kuniaki Saito, Risa Shinoda, Shohei Tanaka, Tosho Hirasawa, Fumio
 Okura, Yoshitaka Ushiku
Categories: cs.CV
Comments: Project Page: https://dahlian00.github.io/AlignBench/
\\
 Assessing image-text alignment models such as CLIP is crucial for bridging
visual and linguistic representations. Yet existing benchmarks rely on
rule-based perturbations or short captions, limiting their ability to measure
fine-grained alignment. We introduce AlignBench, a benchmark that provides a
new indicator of image-text alignment by evaluating detailed image-caption
pairs generated by diverse image-to-text and text-to-image models. Each
sentence is annotated for correctness, enabling direct assessment of VLMs as
alignment evaluators. Benchmarking a wide range of decoder-based VLMs reveals
three key findings: (i) CLIP-based models, even those tailored for
compositional reasoning, remain nearly blind; (ii) detectors systematically
over-score early sentences; and (iii) they show strong self-preference,
favoring their own outputs and harming detection performance. Our project page
will be available at https://dahlian00.github.io/AlignBench/.
\\ ( https://arxiv.org/abs/2511.20515 ,  8213kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20520
Date: Tue, 25 Nov 2025 17:23:38 GMT   (8159kb)

Title: HBridge: H-Shape Bridging of Heterogeneous Experts for Unified
 Multimodal Understanding and Generation
Authors: Xiang Wang, Zhifei Zhang, He Zhang, Zhe Lin, Yuqian Zhou, Qing Liu,
 Shiwei Zhang, Yijun Li, Shaoteng Liu, Haitian Zheng, Jason Kuen, Yuehuan
 Wang, Changxin Gao, Nong Sang
Categories: cs.CV
\\
 Recent unified models integrate understanding experts (e.g., LLMs) with
generative experts (e.g., diffusion models), achieving strong multimodal
performance. However, recent advanced methods such as BAGEL and LMFusion follow
the Mixture-of-Transformers (MoT) paradigm, adopting a symmetric design that
mirrors one expert to another for convenient initialization and fusion, which
remains suboptimal due to inherent modality discrepancies. In this work, we
propose HBridge, an asymmetric H-shaped architecture that enables heterogeneous
experts to optimally leverage pretrained priors from their respective modality
domains. Unlike prior dense fusion strategies that straightforwardly connect
all layers between experts via shared attention, HBridge selectively bridges
intermediate layers, reducing over 40% attention sharing, which improves
efficiency and enhances generation quality. Shallow and deep layers, which
capture modality-specific representations, are decoupled, while mid-layer
bridging promotes semantic alignment. To further strengthen cross-modal
coherence, we introduce semantic reconstruction tokens that explicitly guide
the generative expert to reconstruct visual semantic tokens of the target
image. Extensive experiments across multiple benchmarks demonstrate the
effectiveness and superior performance of HBridge, establishing a new paradigm
for unified multimodal generation.
\\ ( https://arxiv.org/abs/2511.20520 ,  8159kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20525
Date: Tue, 25 Nov 2025 17:29:12 GMT   (14302kb)

Title: Mistake Attribution: Fine-Grained Mistake Understanding in Egocentric
 Videos
Authors: Yayuan Li, Aadit Jain, Filippos Bellos, Jason J. Corso
Categories: cs.CV
Comments: 11 pages, 4 figures, 6 tables
\\
 We introduce Mistake Attribution (MATT), a task for fine-grained
understanding of human mistakes in egocentric video. Unlike prior mistake
understanding work, which lacks fine-grained output, MATT concretely attributes
mistakes to the input instruction text or the attempt video. MATT determines
what part of the instruction is violated (semantic role), when the deviation
becomes irreversible (the Point-of-No-Return, PNR), and where the mistake
appears in the PNR frame. We develop MisEngine, a data engine that
automatically constructs attribution-rich mistake samples from existing
datasets and inherits their annotations. Applied to large egocentric corpora,
MisEngine yields EPIC-KITCHENS-M and Ego4D-M, two datasets that are up to two
orders of magnitude larger than prior mistake datasets. We then present
MisFormer, a unified attention-based model for mistake attribution across
semantic (what), temporal (when), and spatial (where) dimensions, trained using
MisEngine supervision. Experiments on our new datasets and prior benchmarks
show that MisFormer outperforms strong video-language, temporal localization,
hand-object interaction, and mistake-detection baselines.
\\ ( https://arxiv.org/abs/2511.20525 ,  14302kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20541
Date: Tue, 25 Nov 2025 17:42:11 GMT   (9494kb)

Title: Automated Monitoring of Cultural Heritage Artifacts Using Semantic
 Segmentation
Authors: Andrea Ranieri and Giorgio Palmieri and Silvia Biasotti
Categories: cs.CV cs.AI cs.LG
Comments: Keywords: Cultural Heritage, Monitoring, Deep Learning, U-Nets,
 Semantic Segmentation
\\
 This paper addresses the critical need for automated crack detection in the
preservation of cultural heritage through semantic segmentation. We present a
comparative study of U-Net architectures, using various convolutional neural
network (CNN) encoders, for pixel-level crack identification on statues and
monuments. A comparative quantitative evaluation is performed on the test set
of the OmniCrack30k dataset [1] using popular segmentation metrics including
Mean Intersection over Union (mIoU), Dice coefficient, and Jaccard index. This
is complemented by an out-of-distribution qualitative evaluation on an
unlabeled test set of real-world cracked statues and monuments. Our findings
provide valuable insights into the capabilities of different CNN- based
encoders for fine-grained crack segmentation. We show that the models exhibit
promising generalization capabilities to unseen cultural heritage contexts,
despite never having been explicitly trained on images of statues or monuments.
\\ ( https://arxiv.org/abs/2511.20541 ,  9494kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20544
Date: Tue, 25 Nov 2025 17:44:50 GMT   (15637kb)

Title: New York Smells: A Large Multimodal Dataset for Olfaction
Authors: Ege Ozguroglu, Junbang Liang, Ruoshi Liu, Mia Chiquier, Michael
 DeTienne, Wesley Wei Qian, Alexandra Horowitz, Andrew Owens, Carl Vondrick
Categories: cs.CV cs.AI cs.LG
Comments: Project website at https://smell.cs.columbia.edu
\\
 While olfaction is central to how animals perceive the world, this rich
chemical sensory modality remains largely inaccessible to machines. One key
bottleneck is the lack of diverse, multimodal olfactory training data collected
in natural settings. We present New York Smells, a large dataset of paired
image and olfactory signals captured ``in the wild.'' Our dataset contains
7,000 smell-image pairs from 3,500 distinct objects across indoor and outdoor
environments, with approximately 70$\times$ more objects than existing
olfactory datasets. Our benchmark has three tasks: cross-modal smell-to-image
retrieval, recognizing scenes, objects, and materials from smell alone, and
fine-grained discrimination between grass species. Through experiments on our
dataset, we find that visual data enables cross-modal olfactory representation
learning, and that our learned olfactory representations outperform widely-used
hand-crafted features.
\\ ( https://arxiv.org/abs/2511.20544 ,  15637kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20549
Date: Tue, 25 Nov 2025 17:47:11 GMT   (23958kb)

Title: Flash-DMD: Towards High-Fidelity Few-Step Image Generation with
 Efficient Distillation and Joint Reinforcement Learning
Authors: Guanjie Chen, Shirui Huang, Kai Liu, Jianchen Zhu, Xiaoye Qu, Peng
 Chen, Yu Cheng, Yifu Sun
Categories: cs.CV cs.AI
\\
 Diffusion Models have emerged as a leading class of generative models, yet
their iterative sampling process remains computationally expensive. Timestep
distillation is a promising technique to accelerate generation, but it often
requires extensive training and leads to image quality degradation.
Furthermore, fine-tuning these distilled models for specific objectives, such
as aesthetic appeal or user preference, using Reinforcement Learning (RL) is
notoriously unstable and easily falls into reward hacking. In this work, we
introduce Flash-DMD, a novel framework that enables fast convergence with
distillation and joint RL-based refinement. Specifically, we first propose an
efficient timestep-aware distillation strategy that significantly reduces
training cost with enhanced realism, outperforming DMD2 with only $2.1\%$ its
training cost. Second, we introduce a joint training scheme where the model is
fine-tuned with an RL objective while the timestep distillation training
continues simultaneously. We demonstrate that the stable, well-defined loss
from the ongoing distillation acts as a powerful regularizer, effectively
stabilizing the RL training process and preventing policy collapse. Extensive
experiments on score-based and flow matching models show that our proposed
Flash-DMD not only converges significantly faster but also achieves
state-of-the-art generation quality in the few-step sampling regime,
outperforming existing methods in visual quality, human preference, and
text-image alignment metrics. Our work presents an effective paradigm for
training efficient, high-fidelity, and stable generative models. Codes are
coming soon.
\\ ( https://arxiv.org/abs/2511.20549 ,  23958kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20561
Date: Tue, 25 Nov 2025 17:58:48 GMT   (2234kb)

Title: Does Understanding Inform Generation in Unified Multimodal Models? From
 Analysis to Path Forward
Authors: Yuwei Niu, Weiyang Jin, Jiaqi Liao, Chaoran Feng, Peng Jin, Bin Lin,
 Zongjian Li, Bin Zhu, Weihao Yu, Li Yuan
Categories: cs.CV cs.CL
\\
 Recent years have witnessed significant progress in Unified Multimodal
Models, yet a fundamental question remains: Does understanding truly inform
generation? To investigate this, we introduce UniSandbox, a decoupled
evaluation framework paired with controlled, synthetic datasets to avoid data
leakage and enable detailed analysis. Our findings reveal a significant
understanding-generation gap, which is mainly reflected in two key dimensions:
reasoning generation and knowledge transfer. Specifically, for reasoning
generation tasks, we observe that explicit Chain-of-Thought (CoT) in the
understanding module effectively bridges the gap, and further demonstrate that
a self-training approach can successfully internalize this ability, enabling
implicit reasoning during generation. Additionally, for knowledge transfer
tasks, we find that CoT assists the generative process by helping retrieve
newly learned knowledge, and also discover that query-based architectures
inherently exhibit latent CoT-like properties that affect this transfer.
UniSandbox provides preliminary insights for designing future unified
architectures and training strategies that truly bridge the gap between
understanding and generation. Code and data are available at
https://github.com/PKU-YuanGroup/UniSandBox
\\ ( https://arxiv.org/abs/2511.20561 ,  2234kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20562
Date: Tue, 25 Nov 2025 17:59:04 GMT   (30046kb)

Title: PhysChoreo: Physics-Controllable Video Generation with Part-Aware
 Semantic Grounding
Authors: Haoze Zhang, Tianyu Huang, Zichen Wan, Xiaowei Jin, Hongzhi Zhang, Hui
 Li, Wangmeng Zuo
Categories: cs.CV
\\
 While recent video generation models have achieved significant visual
fidelity, they often suffer from the lack of explicit physical controllability
and plausibility. To address this, some recent studies attempted to guide the
video generation with physics-based rendering. However, these methods face
inherent challenges in accurately modeling complex physical properties and
effectively control ling the resulting physical behavior over extended temporal
sequences. In this work, we introduce PhysChoreo, a novel framework that can
generate videos with diverse controllability and physical realism from a single
image. Our method consists of two stages: first, it estimates the static
initial physical properties of all objects in the image through part-aware
physical property reconstruction. Then, through temporally instructed and
physically editable simulation, it synthesizes high-quality videos with rich
dynamic behaviors and physical realism. Experimental results show that
PhysChoreo can generate videos with rich behaviors and physical realism,
outperforming state-of-the-art methods on multiple evaluation metrics.
\\ ( https://arxiv.org/abs/2511.20562 ,  30046kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20563
Date: Tue, 25 Nov 2025 17:59:07 GMT   (12337kb)

Title: A Reason-then-Describe Instruction Interpreter for Controllable Video
 Generation
Authors: Shengqiong Wu and Weicai Ye and Yuanxing Zhang and Jiahao Wang and
 Quande Liu and Xintao Wang and Pengfei Wan and Kun Gai and Hao Fei and
 Tat-Seng Chua
Categories: cs.CV
Comments: 27 pages, 13 figures, 13 tables, Project Page:
 https://sqwu.top/ReaDe/
\\
 Diffusion Transformers have significantly improved video fidelity and
temporal coherence, however, practical controllability remains limited.
Concise, ambiguous, and compositionally complex user inputs contrast with the
detailed prompts used in training, yielding an intent-output mismatch. We
propose ReaDe, a universal, model-agnostic interpreter that converts raw
instructions into precise, actionable specifications for downstream video
generators. ReaDe follows a reason-then-describe paradigm: it first analyzes
the user request to identify core requirements and resolve ambiguities, then
produces detailed guidance that enables faithful, controllable generation. We
train ReaDe via a two-stage optimization: (i) reasoning-augmented supervision
imparts analytic parsing with stepwise traces and dense captions, and (ii) a
multi-dimensional reward assigner enables stable, feedback-driven refinement
for natural-style captions. Experiments across single- and multi-condition
scenarios show consistent gains in instruction fidelity, caption accuracy, and
downstream video quality, with strong generalization to reasoning-intensive and
unseen inputs. ReaDe offers a practical route to aligning controllable video
generation with accurately interpreted user intent. Project Page:
https://sqwu.top/ReaDe/.
\\ ( https://arxiv.org/abs/2511.20563 ,  12337kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20565
Date: Tue, 25 Nov 2025 18:00:00 GMT   (45009kb)

Title: DINO-Tok: Adapting DINO for Visual Tokenizers
Authors: Mingkai Jia, Mingxiao Li, Liaoyuan Fan, Tianxing Shi, Jiaxin Guo,
 Zeming Li, Xiaoyang Guo, Xiao-Xiao Long, Qian Zhang, Ping Tan, Wei Yin
Categories: cs.CV
\\
 Recent advances in visual generation have highlighted the rise of Latent
Generative Models (LGMs), which rely on effective visual tokenizers to bridge
pixels and semantics. However, existing tokenizers are typically trained from
scratch and struggle to balance semantic representation and reconstruction
fidelity, particularly in high-dimensional latent spaces. In this work, we
introduce DINO-Tok, a DINO-based visual tokenizer that unifies hierarchical
representations into an information-complete latent space. By integrating
shallow features that retain fine-grained details with deep features encoding
global semantics, DINO-Tok effectively bridges pretrained representations and
visual generation. We further analyze the challenges of vector quantization
(VQ) in this high-dimensional space, where key information is often lost and
codebook collapse occurs. We thus propose a global PCA reweighting mechanism to
stabilize VQ and preserve essential information across dimensions. On ImageNet
256$\times$256, DINO-Tok achieves state-of-the-art reconstruction performance,
reaching 28.54 PSNR for autoencoding and 23.98 PSNR for VQ-based modeling,
significantly outperforming prior tokenizers and comparable to billion-level
data trained models (such as Hunyuan and Wan). These results demonstrate that
adapting powerful pretrained vision models like DINO for tokenization enables
semantically aligned and high-fidelity latent representations, enabling
next-generation visual generative models. Code will be publicly available at
https://github.com/MKJia/DINO-Tok.
\\ ( https://arxiv.org/abs/2511.20565 ,  45009kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20573
Date: Tue, 25 Nov 2025 18:06:22 GMT   (38166kb)

Title: VQ-VA World: Towards High-Quality Visual Question-Visual Answering
Authors: Chenhui Gou, Zilong Chen, Zeyu Wang, Feng Li, Deyao Zhu, Zicheng Duan,
 Kunchang Li, Chaorui Deng, Hongyi Yuan, Haoqi Fan, Cihang Xie, Jianfei Cai,
 Hamid Rezatofighi
Categories: cs.CV
\\
 This paper studies Visual Question-Visual Answering (VQ-VA): generating an
image, rather than text, in response to a visual question -- an ability that
has recently emerged in proprietary systems such as NanoBanana and GPT-Image.
To also bring this capability to open-source models, we introduce VQ-VA World,
a data-centric framework built around an agentic pipeline for large-scale,
targeted data construction. Leveraging web-scale deployment, this pipeline
crawls a massive amount of ~1.8M high-quality, interleaved image-text samples
for model training. For evaluation, we further release IntelligentBench, a
human-curated benchmark that systematically assesses VQ-VA along the aspects of
world knowledge, design knowledge, and reasoning. Training with VQ-VA World
data yields strong empirical gains: it helps LightFusion attain 53.06 on
IntelligentBench, substantially surpassing the best prior open-source baselines
(i.e., 7.78 from vanilla LightFusion; 1.94 from UniWorld-V1), and significantly
narrowing the gap toward leading proprietary systems (e.g., 81.67 from
NanoBanana; 82.64 from GPT-Image). By releasing the full suite of model
weights, datasets, and pipelines, we hope to stimulate future research on
VQ-VA.
\\ ( https://arxiv.org/abs/2511.20573 ,  38166kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20614
Date: Tue, 25 Nov 2025 18:40:25 GMT   (15917kb)

Title: The Consistency Critic: Correcting Inconsistencies in Generated Images
 via Reference-Guided Attentive Alignment
Authors: Ziheng Ouyang, Yiren Song, Yaoli Liu, Shihao Zhu, Qibin Hou, Ming-Ming
 Cheng, Mike Zheng Shou
Categories: cs.CV
Comments: Project page: https://ouyangziheng.github.io/ImageCritic-Page/
\\
 Previous works have explored various customized generation tasks given a
reference image, but they still face limitations in generating consistent
fine-grained details. In this paper, our aim is to solve the inconsistency
problem of generated images by applying a reference-guided post-editing
approach and present our ImageCritic. We first construct a dataset of
reference-degraded-target triplets obtained via VLM-based selection and
explicit degradation, which effectively simulates the common inaccuracies or
inconsistencies observed in existing generation models. Furthermore, building
on a thorough examination of the model's attention mechanisms and intrinsic
representations, we accordingly devise an attention alignment loss and a detail
encoder to precisely rectify inconsistencies. ImageCritic can be integrated
into an agent framework to automatically detect inconsistencies and correct
them with multi-round and local editing in complex scenarios. Extensive
experiments demonstrate that ImageCritic can effectively resolve detail-related
issues in various customized generation scenarios, providing significant
improvements over existing methods.
\\ ( https://arxiv.org/abs/2511.20614 ,  15917kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20615
Date: Tue, 25 Nov 2025 18:40:48 GMT   (704kb)

Title: Evaluating the Performance of Deep Learning Models in Whole-body Dynamic
 3D Posture Prediction During Load-reaching Activities
Authors: Seyede Niloofar Hosseini, Ali Mojibi, Mahdi Mohseni, Navid Arjmand,
 Alireza Taheri
Categories: cs.CV cs.AI
Comments: 10 pages, 6 figures, 7 tables
\\
 This study aimed to explore the application of deep neural networks for
whole-body human posture prediction during dynamic load-reaching activities.
Two time-series models were trained using bidirectional long short-term memory
(BLSTM) and transformer architectures. The dataset consisted of 3D full-body
plug-in gait dynamic coordinates from 20 normal-weight healthy male individuals
each performing 204 load-reaching tasks from different load positions while
adapting various lifting and handling techniques. The model inputs consisted of
the 3D position of the hand-load position, lifting (stoop, full-squat and
semi-squat) and handling (one- and two-handed) techniques, body weight and
height, and the 3D coordinate data of the body posture from the first 25% of
the task duration. These inputs were used by the models to predict body
coordinates during the remaining 75% of the task period. Moreover, a novel
method was proposed to improve the accuracy of the previous and present posture
prediction networks by enforcing constant body segment lengths through the
optimization of a new cost function. The results indicated that the new cost
function decreased the prediction error of the models by approximately 8% and
21% for the arm and leg models, respectively. We indicated that utilizing the
transformer architecture, with a root-mean-square-error of 47.0 mm, exhibited
~58% more accurate long-term performance than the BLSTM-based model. This study
merits the use of neural networks that capture time series dependencies in 3D
motion frames, providing a unique approach for understanding and predict motion
dynamics during manual material handling activities.
\\ ( https://arxiv.org/abs/2511.20615 ,  704kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20620
Date: Tue, 25 Nov 2025 18:43:55 GMT   (21484kb)

Title: Wanderland: Geometrically Grounded Simulation for Open-World Embodied AI
Authors: Xinhao Liu, Jiaqi Li, Youming Deng, Ruxin Chen, Yingjia Zhang, Yifei
 Ma, Li Guo, Yiming Li, Jing Zhang, Chen Feng
Categories: cs.CV cs.RO
\\
 Reproducible closed-loop evaluation remains a major bottleneck in Embodied AI
such as visual navigation. A promising path forward is high-fidelity simulation
that combines photorealistic sensor rendering with geometrically grounded
interaction in complex, open-world urban environments. Although recent
video-3DGS methods ease open-world scene capturing, they are still unsuitable
for benchmarking due to large visual and geometric sim-to-real gaps. To address
these challenges, we introduce Wanderland, a real-to-sim framework that
features multi-sensor capture, reliable reconstruction, accurate geometry, and
robust view synthesis. Using this pipeline, we curate a diverse dataset of
indoor-outdoor urban scenes and systematically demonstrate how image-only
pipelines scale poorly, how geometry quality impacts novel view synthesis, and
how all of these adversely affect navigation policy learning and evaluation
reliability. Beyond serving as a trusted testbed for embodied navigation,
Wanderland's rich raw sensor data further allows benchmarking of 3D
reconstruction and novel view synthesis models. Our work establishes a new
foundation for reproducible research in open-world embodied AI. Project website
is at https://ai4ce.github.io/wanderland/.
\\ ( https://arxiv.org/abs/2511.20620 ,  21484kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20624
Date: Tue, 25 Nov 2025 18:47:27 GMT   (42308kb)

Title: ShapeGen: Towards High-Quality 3D Shape Synthesis
Authors: Yangguang Li, Xianglong He, Zi-Xin Zou, Zexiang Liu, Wanli Ouyang,
 Ding Liang, Yan-Pei Cao
Categories: cs.CV
Comments: Accepted to SIGGRAPH Asia 2025
\\
 Inspired by generative paradigms in image and video, 3D shape generation has
made notable progress, enabling the rapid synthesis of high-fidelity 3D assets
from a single image. However, current methods still face challenges, including
the lack of intricate details, overly smoothed surfaces, and fragmented
thin-shell structures. These limitations leave the generated 3D assets still
one step short of meeting the standards favored by artists. In this paper, we
present ShapeGen, which achieves high-quality image-to-3D shape generation
through 3D representation and supervision improvements, resolution scaling up,
and the advantages of linear transformers. These advancements allow the
generated assets to be seamlessly integrated into 3D pipelines, facilitating
their widespread adoption across various applications. Through extensive
experiments, we validate the impact of these improvements on overall
performance. Ultimately, thanks to the synergistic effects of these
enhancements, ShapeGen achieves a significant leap in image-to-3D generation,
establishing a new state-of-the-art performance.
\\ ( https://arxiv.org/abs/2511.20624 ,  42308kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20629
Date: Tue, 25 Nov 2025 18:49:21 GMT   (41102kb)

Title: MapReduce LoRA: Advancing the Pareto Front in Multi-Preference
 Optimization for Generative Models
Authors: Chieh-Yun Chen, Zhonghao Wang, Qi Chen, Zhifan Ye, Min Shi, Yue Zhao,
 Yinan Zhao, Hui Qu, Wei-An Lin, Yiru Shen, Ajinkya Kale, Irfan Essa, Humphrey
 Shi
Categories: cs.CV cs.AI cs.LG
\\
 Reinforcement learning from human feedback (RLHF) with reward models has
advanced alignment of generative models to human aesthetic and perceptual
preferences. However, jointly optimizing multiple rewards often incurs an
alignment tax, improving one dimension while degrading others. To address this,
we introduce two complementary methods: MapReduce LoRA and Reward-aware Token
Embedding (RaTE). MapReduce LoRA trains preference-specific LoRA experts in
parallel and iteratively merges them to refine a shared base model; RaTE learns
reward-specific token embeddings that compose at inference for flexible
preference control. Experiments on Text-to-Image generation (Stable Diffusion
3.5 Medium and FLUX.1-dev) show improvements of 36.1%, 4.6%, and 55.7%, and
32.7%, 4.3%, and 67.1% on GenEval, PickScore, and OCR, respectively. On
Text-to-Video generation (HunyuanVideo), visual and motion quality improve by
48.1% and 90.0%, respectively. On the language task, Helpful Assistant, with
Llama-2 7B, helpful and harmless improve by 43.4% and 136.7%, respectively. Our
framework sets a new state-of-the-art multi-preference alignment recipe across
modalities.
\\ ( https://arxiv.org/abs/2511.20629 ,  41102kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20635
Date: Tue, 25 Nov 2025 18:54:16 GMT   (26482kb)

Title: iMontage: Unified, Versatile, Highly Dynamic Many-to-many Image
 Generation
Authors: Zhoujie Fu, Xianfang Zeng, Jinghong Lan, Xinyao Liao, Cheng Chen,
 Junyi Chen, Jiacheng Wei, Wei Cheng, Shiyu Liu, Yunuo Chen, Gang Yu, Guosheng
 Lin
Categories: cs.CV
\\
 Pre-trained video models learn powerful priors for generating high-quality,
temporally coherent content. While these models excel at temporal coherence,
their dynamics are often constrained by the continuous nature of their training
data. We hypothesize that by injecting the rich and unconstrained content
diversity from image data into this coherent temporal framework, we can
generate image sets that feature both natural transitions and a far more
expansive dynamic range. To this end, we introduce iMontage, a unified
framework designed to repurpose a powerful video model into an all-in-one image
generator. The framework consumes and produces variable-length image sets,
unifying a wide array of image generation and editing tasks. To achieve this,
we propose an elegant and minimally invasive adaptation strategy, complemented
by a tailored data curation process and training paradigm. This approach allows
the model to acquire broad image manipulation capabilities without corrupting
its invaluable original motion priors. iMontage excels across several
mainstream many-in-many-out tasks, not only maintaining strong cross-image
contextual consistency but also generating scenes with extraordinary dynamics
that surpass conventional scopes. Find our homepage at:
https://kr1sjfu.github.io/iMontage-web/.
\\ ( https://arxiv.org/abs/2511.20635 ,  26482kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20640
Date: Tue, 25 Nov 2025 18:57:25 GMT   (37350kb)

Title: MotionV2V: Editing Motion in a Video
Authors: Ryan Burgert, Charles Herrmann, Forrester Cole, Michael S Ryoo, Neal
 Wadhwa, Andrey Voynov, and Nataniel Ruiz
Categories: cs.CV cs.AI cs.GR cs.LG
\\
 While generative video models have achieved remarkable fidelity and
consistency, applying these capabilities to video editing remains a complex
challenge. Recent research has explored motion controllability as a means to
enhance text-to-video generation or image animation; however, we identify
precise motion control as a promising yet under-explored paradigm for editing
existing videos. In this work, we propose modifying video motion by directly
editing sparse trajectories extracted from the input. We term the deviation
between input and output trajectories a "motion edit" and demonstrate that this
representation, when coupled with a generative backbone, enables powerful video
editing capabilities. To achieve this, we introduce a pipeline for generating
"motion counterfactuals", video pairs that share identical content but distinct
motion, and we fine-tune a motion-conditioned video diffusion architecture on
this dataset. Our approach allows for edits that start at any timestamp and
propagate naturally. In a four-way head-to-head user study, our model achieves
over 65 percent preference against prior work. Please see our project page:
https://ryanndagreat.github.io/MotionV2V
\\ ( https://arxiv.org/abs/2511.20640 ,  37350kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20641
Date: Tue, 25 Nov 2025 18:57:28 GMT   (10988kb)

Title: Unleashing the Power of Vision-Language Models for Long-Tailed
 Multi-Label Visual Recognition
Authors: Wei Tang, Zuo-Zheng Wang, Kun Zhang, Tong Wei, and Min-Ling Zhang
Categories: cs.CV cs.LG
\\
 Long-tailed multi-label visual recognition poses a significant challenge, as
images typically contain multiple labels with highly imbalanced class
distributions, leading to biased models that favor head classes while
underperforming on tail classes. Recent efforts have leveraged pre-trained
vision-language models, such as CLIP, alongside long-tailed learning techniques
to exploit rich visual-textual priors for improved performance. However,
existing methods often derive semantic inter-class relationships directly from
imbalanced datasets, resulting in unreliable correlations for tail classes due
to data scarcity. Moreover, CLIP's zero-shot paradigm is optimized for
single-label image-text matching, making it suboptimal for multi-label tasks.
To address these issues, we propose the correlation adaptation prompt network
(CAPNET), a novel end-to-end framework that explicitly models label
correlations from CLIP's textual encoder. The framework incorporates a graph
convolutional network for label-aware propagation and learnable soft prompts
for refined embeddings. It utilizes a distribution-balanced Focal loss with
class-aware re-weighting for optimized training under imbalance. Moreover, it
improves generalization through test-time ensembling and realigns
visual-textual modalities using parameter-efficient fine-tuning to avert
overfitting on tail classes without compromising head class performance.
Extensive experiments and ablation studies on benchmarks including VOC-LT,
COCO-LT, and NUS-WIDE demonstrate that CAPNET achieves substantial improvements
over state-of-the-art methods, validating its effectiveness for real-world
long-tailed multi-label visual recognition.
\\ ( https://arxiv.org/abs/2511.20641 ,  10988kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20643
Date: Tue, 25 Nov 2025 18:58:07 GMT   (8241kb)

Title: Concept-Aware Batch Sampling Improves Language-Image Pretraining
Authors: Adhiraj Ghosh, Vishaal Udandarao, Thao Nguyen, Matteo Farina, Mehdi
 Cherti, Jenia Jitsev, Sewoong Oh, Elisa Ricci, Ludwig Schmidt, Matthias
 Bethge
Categories: cs.CV cs.LG
Comments: Tech Report
\\
 What data should a vision-language model be trained on? To answer this
question, many data curation efforts center on the quality of a dataset.
However, most of these existing methods are (i) offline, i.e. they produce a
static dataset from a set of predetermined filtering criteria, and (ii)
concept-agnostic, i.e. they use model-based filters which induce additional
data biases. In this work, we go beyond such offline, concept-agnostic methods
and advocate for more flexible, task-adaptive online concept-based curation.
Our first contribution is DataConcept, a collection of 128M web-crawled
image-text pairs annotated with fine-grained details about their concept
composition. Building on DataConcept, we introduce Concept-Aware Batch Sampling
(CABS), a simple yet effective batch sampling framework that flexibly
constructs batches on-the-fly based on specific target distributions. We
propose two variants: (i) Diversity Maximization (CABS-DM) to curate batches
with a broad coverage of available concepts, and (ii) Frequency Maximization
(CABS-FM) to curate batches with high object multiplicity. Through extensive
evaluations across 28 benchmarks, we demonstrate that our CABS method
significantly benefits CLIP/SigLIP model classes and yields highly performant
models. Overall, CABS represents a strong open-source alternative to
proprietary online data curation algorithms, enabling practitioners to define
custom concept distributions that optimize for specific downstream tasks.
\\ ( https://arxiv.org/abs/2511.20643 ,  8241kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20644
Date: Tue, 25 Nov 2025 18:59:02 GMT   (2521kb)

Title: Vision-Language Memory for Spatial Reasoning
Authors: Zuntao Liu, Yi Du, Taimeng Fu, Shaoshu Su, Cherie Ho, Chen Wang
Categories: cs.CV
\\
 Spatial reasoning is a critical capability for intelligent robots, yet
current vision-language models (VLMs) still fall short of human-level
performance in video-based spatial reasoning. This gap mainly stems from two
challenges: a semantic-geometric misalignment that prevents consistent 3D
understanding, and the absence of persistent memory to retain 3D representation
and understanding over time. To address these limitations, we present VLM$^2$,
a Vision-Language Model with persistent Memory for spatial reasoning with a
view-consistent, 3D-aware representation purely from 2D video. Specifically, to
enhance long-horizon reasoning, we incorporate a dual-memory module, consisting
of a working memory that operates as a sliding window to focus on immediate
context, and an episodic memory that consolidates and stores critical long-term
information. This design enables efficient and long-horizon spatial reasoning
with a fixed computational cost. Extensive experiments on multiple benchmarks
show that VLM$^2$ achieves state-of-the-art performance among video-only
models, significantly advancing the frontier of visual-spatial intelligence.
\\ ( https://arxiv.org/abs/2511.20644 ,  2521kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20645
Date: Tue, 25 Nov 2025 18:59:25 GMT   (18384kb)

Title: PixelDiT: Pixel Diffusion Transformers for Image Generation
Authors: Yongsheng Yu, Wei Xiong, Weili Nie, Yichen Sheng, Shiqiu Liu, Jiebo
 Luo
Categories: cs.CV
\\
 Latent-space modeling has been the standard for Diffusion Transformers
(DiTs). However, it relies on a two-stage pipeline where the pretrained
autoencoder introduces lossy reconstruction, leading to error accumulation
while hindering joint optimization. To address these issues, we propose
PixelDiT, a single-stage, end-to-end model that eliminates the need for the
autoencoder and learns the diffusion process directly in the pixel space.
PixelDiT adopts a fully transformer-based architecture shaped by a dual-level
design: a patch-level DiT that captures global semantics and a pixel-level DiT
that refines texture details, enabling efficient training of a pixel-space
diffusion model while preserving fine details. Our analysis reveals that
effective pixel-level token modeling is essential to the success of pixel
diffusion. PixelDiT achieves 1.61 FID on ImageNet 256x256, surpassing existing
pixel generative models by a large margin. We further extend PixelDiT to
text-to-image generation and pretrain it at the 1024x1024 resolution in pixel
space. It achieves 0.74 on GenEval and 83.5 on DPG-bench, approaching the best
latent diffusion models.
\\ ( https://arxiv.org/abs/2511.20645 ,  18384kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20646
Date: Tue, 25 Nov 2025 18:59:34 GMT   (5112kb)

Title: 3D-Aware Multi-Task Learning with Cross-View Correlations for Dense
 Scene Understanding
Authors: Xiaoye Wang and Chen Tang and Xiangyu Yue and Wei-Hong Li
Categories: cs.CV
Comments: 3D-aware Multi-task Learning, Cross-view Correlations, Code will be
 available at https://github.com/WeiHongLee/CrossView3DMTL
\\
 This paper addresses the challenge of training a single network to jointly
perform multiple dense prediction tasks, such as segmentation and depth
estimation, i.e., multi-task learning (MTL). Current approaches mainly capture
cross-task relations in the 2D image space, often leading to unstructured
features lacking 3D-awareness. We argue that 3D-awareness is vital for modeling
cross-task correlations essential for comprehensive scene understanding. We
propose to address this problem by integrating correlations across views, i.e.,
cost volume, as geometric consistency in the MTL network. Specifically, we
introduce a lightweight Cross-view Module (CvM), shared across tasks, to
exchange information across views and capture cross-view correlations,
integrated with a feature from MTL encoder for multi-task predictions. This
module is architecture-agnostic and can be applied to both single and
multi-view data. Extensive results on NYUv2 and PASCAL-Context demonstrate that
our method effectively injects geometric consistency into existing MTL methods
to improve performance.
\\ ( https://arxiv.org/abs/2511.20646 ,  5112kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20647
Date: Tue, 25 Nov 2025 18:59:45 GMT   (25309kb)

Title: Diverse Video Generation with Determinantal Point Process-Guided Policy
 Optimization
Authors: Tahira Kazimi, Connor Dunlop, Pinar Yanardag
Categories: cs.CV
Comments: Project webpage: https://diverse-video.github.io/
\\
 While recent text-to-video (T2V) diffusion models have achieved impressive
quality and prompt alignment, they often produce low-diversity outputs when
sampling multiple videos from a single text prompt. We tackle this challenge by
formulating it as a set-level policy optimization problem, with the goal of
training a policy that can cover the diverse range of plausible outcomes for a
given prompt. To address this, we introduce DPP-GRPO, a novel framework for
diverse video generation that combines Determinantal Point Processes (DPPs) and
Group Relative Policy Optimization (GRPO) theories to enforce explicit reward
on diverse generations. Our objective turns diversity into an explicit signal
by imposing diminishing returns on redundant samples (via DPP) while supplies
groupwise feedback over candidate sets (via GRPO). Our framework is
plug-and-play and model-agnostic, and encourages diverse generations across
visual appearance, camera motions, and scene structure without sacrificing
prompt fidelity or perceptual quality. We implement our method on WAN and
CogVideoX, and show that our method consistently improves video diversity on
state-of-the-art benchmarks such as VBench, VideoScore, and human preference
studies. Moreover, we release our code and a new benchmark dataset of 30,000
diverse prompts to support future research.
\\ ( https://arxiv.org/abs/2511.20647 ,  25309kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20648
Date: Tue, 25 Nov 2025 18:59:45 GMT   (10311kb)

Title: LocateAnything3D: Vision-Language 3D Detection with Chain-of-Sight
Authors: Yunze Man, Shihao Wang, Guowen Zhang, Johan Bjorck, Zhiqi Li,
 Liang-Yan Gui, Jim Fan, Jan Kautz, Yu-Xiong Wang, Zhiding Yu
Categories: cs.CV
Comments: Tech report. Project page: https://nvlabs.github.io/LocateAnything3D/
\\
 To act in the world, a model must name what it sees and know where it is in
3D. Today's vision-language models (VLMs) excel at open-ended 2D description
and grounding, yet multi-object 3D detection remains largely missing from the
VLM toolbox. We present LocateAnything3D, a VLM-native recipe that casts 3D
detection as a next-token prediction problem. The key is a short, explicit
Chain-of-Sight (CoS) sequence that mirrors how human reason from images: find
an object in 2D, then infer its distance, size, and pose. The decoder first
emits 2D detections as a visual chain-of-thought, then predicts 3D boxes under
an easy-to-hard curriculum: across objects, a near-to-far order reduces early
ambiguity and matches ego-centric utility; within each object, a
center-from-camera, dimensions, and rotation factorization ranks information by
stability and learnability. This VLM-native interface preserves open-vocabulary
and visual-prompting capability without specialized heads. On the challenging
Omni3D benchmark, our model achieves state-of-the-art results, with 49.89
AP_3D, surpassing the previous best by +15.51 absolute improvement even when
the baseline is given ground-truth 2D boxes. It also generalizes zero-shot to
held-out categories with strong robustness. By turning 3D detection into a
disciplined next-token problem, LocateAnything3D offers a practical foundation
for models to perceive in 3D.
\\ ( https://arxiv.org/abs/2511.20648 ,  10311kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20649
Date: Tue, 25 Nov 2025 18:59:46 GMT   (15405kb)

Title: Infinity-RoPE: Action-Controllable Infinite Video Generation Emerges
 From Autoregressive Self-Rollout
Authors: Hidir Yesiltepe, Tuna Han Salih Meral, Adil Kaan Akan, Kaan Oktay,
 Pinar Yanardag
Categories: cs.CV
Comments: Project Page: https://infinity-rope.github.io/
\\
 Current autoregressive video diffusion models are constrained by three core
bottlenecks: (i) the finite temporal horizon imposed by the base model's 3D
Rotary Positional Embedding (3D-RoPE), (ii) slow prompt responsiveness in
maintaining fine-grained action control during long-form rollouts, and (iii)
the inability to realize discontinuous cinematic transitions within a single
generation stream. We introduce $\infty$-RoPE, a unified inference-time
framework that addresses all three limitations through three interconnected
components: Block-Relativistic RoPE, KV Flush, and RoPE Cut. Block-Relativistic
RoPE reformulates temporal encoding as a moving local reference frame, where
each newly generated latent block is rotated relative to the base model's
maximum frame horizon while earlier blocks are rotated backward to preserve
relative temporal geometry. This relativistic formulation eliminates fixed
temporal positions, enabling continuous video generation far beyond the base
positional limits. To obtain fine-grained action control without re-encoding,
KV Flush renews the KV cache by retaining only two latent frames, the global
sink and the last generated latent frame, thereby ensuring immediate prompt
responsiveness. Finally, RoPE Cut introduces controlled discontinuities in
temporal RoPE coordinates, enabling multi-cut scene transitions within a single
continuous rollout. Together, these components establish $\infty$-RoPE as a
training-free foundation for infinite-horizon, controllable, and cinematic
video diffusion. Comprehensive experiments show that $\infty$-RoPE consistently
surpasses previous autoregressive models in overall VBench scores.
\\ ( https://arxiv.org/abs/2511.20649 ,  15405kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20650
Date: Tue, 25 Nov 2025 18:59:53 GMT   (4878kb)

Title: MedROV: Towards Real-Time Open-Vocabulary Detection Across Diverse
 Medical Imaging Modalities
Authors: Tooba Tehreem Sheikh and Jean Lahoud and Rao Muhammad Anwer and Fahad
 Shahbaz Khan and Salman Khan and Hisham Cholakkal
Categories: cs.CV cs.AI
\\
 Traditional object detection models in medical imaging operate within a
closed-set paradigm, limiting their ability to detect objects of novel labels.
Open-vocabulary object detection (OVOD) addresses this limitation but remains
underexplored in medical imaging due to dataset scarcity and weak text-image
alignment. To bridge this gap, we introduce MedROV, the first Real-time Open
Vocabulary detection model for medical imaging. To enable open-vocabulary
learning, we curate a large-scale dataset, Omnis, with 600K detection samples
across nine imaging modalities and introduce a pseudo-labeling strategy to
handle missing annotations from multi-source datasets. Additionally, we enhance
generalization by incorporating knowledge from a large pre-trained foundation
model. By leveraging contrastive learning and cross-modal representations,
MedROV effectively detects both known and novel structures. Experimental
results demonstrate that MedROV outperforms the previous state-of-the-art
foundation model for medical image detection with an average absolute
improvement of 40 mAP50, and surpasses closed-set detectors by more than 3
mAP50, while running at 70 FPS, setting a new benchmark in medical detection.
Our source code, dataset, and trained model are available at
https://github.com/toobatehreem/MedROV.
\\ ( https://arxiv.org/abs/2511.20650 ,  4878kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20651
Date: Tue, 25 Nov 2025 18:59:55 GMT   (4855kb)

Title: RubricRL: Simple Generalizable Rewards for Text-to-Image Generation
Authors: Xuelu Feng, Yunsheng Li, Ziyu Wan, Zixuan Gao, Junsong Yuan, Dongdong
 Chen, Chunming Qiao
Categories: cs.CV
\\
 Reinforcement learning (RL) has recently emerged as a promising approach for
aligning text-to-image generative models with human preferences. A key
challenge, however, lies in designing effective and interpretable rewards.
Existing methods often rely on either composite metrics (e.g., CLIP, OCR, and
realism scores) with fixed weights or a single scalar reward distilled from
human preference models, which can limit interpretability and flexibility. We
propose RubricRL, a simple and general framework for rubric-based reward design
that offers greater interpretability, composability, and user control. Instead
of using a black-box scalar signal, RubricRL dynamically constructs a
structured rubric for each prompt--a decomposable checklist of fine-grained
visual criteria such as object correctness, attribute accuracy, OCR fidelity,
and realism--tailored to the input text. Each criterion is independently
evaluated by a multimodal judge (e.g., o4-mini), and a prompt-adaptive
weighting mechanism emphasizes the most relevant dimensions. This design not
only produces interpretable and modular supervision signals for policy
optimization (e.g., GRPO or PPO), but also enables users to directly adjust
which aspects to reward or penalize. Experiments with an autoregressive
text-to-image model demonstrate that RubricRL improves prompt faithfulness,
visual detail, and generalizability, while offering a flexible and extensible
foundation for interpretable RL alignment across text-to-image architectures.
\\ ( https://arxiv.org/abs/2511.20651 ,  4855kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19514
Date: Mon, 24 Nov 2025 03:00:04 GMT   (2777kb)

Title: SCoTER: Structured Chain-of-Thought Transfer for Enhanced Recommendation
Authors: Yang Wu, Qian Li, Yuling Xiong, Hongbo Tang, Xun Liu, Jun Zhang, Huan
 Yu, Jie Jiang, Hailong Shi
Categories: cs.IR
Comments: 12 pages,4 figures
\\
 Harnessing the reasoning power of Large Language Models (LLMs) for
recommender systems is hindered by two fundamental challenges. First, current
approaches lack a mechanism for automated, data-driven discovery of effective
reasoning patterns, relying instead on brittle manual templates or unstable
zero-shot prompting. Second, they employ structure-collapsing integration:
direct prompting incurs prohibitive online inference costs, while feature
extraction collapses reasoning chains into single vectors, discarding stepwise
logic. To address these challenges, we propose SCoTER (Structured
Chain-of-Thought Transfer for Enhanced Recommendation), a unified framework
that treats pattern discovery and structure-aware transfer as a jointly
optimized problem. Specifically, SCoTER operationalizes this through two
synergistic components: a GVM pipeline for automated pattern discovery and a
structure-preserving integration architecture that transfers stepwise logic to
efficient models. Formally, we provide information-theoretic justification
proving that structure-preserving transfer achieves tighter performance bounds
than structure-agnostic alternatives. Empirically, experiments on four
benchmarks demonstrate improvements of 3.75\%-11.59\% over a strong TIGER
backbone. Moreover, in production deployment on the Tencent Advertising
Platform, SCoTER achieved a 2.14\% lift in Gross Merchandise Value (GMV) while
eliminating online LLM inference costs. Overall, SCoTER establishes a
principled and production-validated blueprint for transferring structured LLM
reasoning to large-scale recommender systems.
\\ ( https://arxiv.org/abs/2511.19514 ,  2777kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19931
Date: Tue, 25 Nov 2025 05:18:04 GMT   (3123kb)

Title: LLM-EDT: Large Language Model Enhanced Cross-domain Sequential
 Recommendation with Dual-phase Training
Authors: Ziwei Liu, Qidong Liu, Wanyu Wang, Yejing Wang, Tong Xu, Wei Huang,
 Chong Chen, Peng Chuan, Xiangyu Zhao
Categories: cs.IR cs.AI
\\
 Cross-domain Sequential Recommendation (CDSR) has been proposed to enrich
user-item interactions by incorporating information from various domains.
Despite current progress, the imbalance issue and transition issue hinder
further development of CDSR. The former one presents a phenomenon that the
interactions in one domain dominate the entire behavior, leading to difficulty
in capturing the domain-specific features in the other domain. The latter
points to the difficulty in capturing users' cross-domain preferences within
the mixed interaction sequence, resulting in poor next-item prediction
performance for specific domains. With world knowledge and powerful reasoning
ability, Large Language Models (LLMs) partially alleviate the above issues by
performing as a generator and an encoder. However, current LLMs-enhanced CDSR
methods are still under exploration, which fail to recognize the irrelevant
noise and rough profiling problems. Thus, to make peace with the aforementioned
challenges, we proposed an LLMs Enhanced Cross-domain Sequential Recommendation
with Dual-phase Training ({LLM-EDT}). To address the imbalance issue while
introducing less irrelevant noise, we first propose the transferable item
augmenter to adaptively generate possible cross-domain behaviors for users.
Then, to alleviate the transition issue, we introduce a dual-phase training
strategy to empower the domain-specific thread with a domain-shared background.
As for the rough profiling problem, we devise a domain-aware profiling module
to summarize the user's preference in each domain and adaptively aggregate them
to generate comprehensive user profiles. The experiments on three public
datasets validate the effectiveness of our proposed LLM-EDT. To ease
reproducibility, we have released the detailed code online at
{https://anonymous.4open.science/r/LLM-EDT-583F}.
\\ ( https://arxiv.org/abs/2511.19931 ,  3123kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19979
Date: Tue, 25 Nov 2025 06:49:14 GMT   (58kb)

Title: The 2nd Workshop on Human-Centered Recommender Systems
Authors: Kaike Zhang, Jiakai Tang, Du Su, Shuchang Liu, Julian McAuley, Lina
 Yao, Qi Cao, Yue Feng, Fei Sun
Categories: cs.IR
\\
 Recommender systems shape how people discover information, form opinions, and
connect with society. Yet, as their influence grows, traditional metrics, e.g.,
accuracy, clicks, and engagement, no longer capture what truly matters to
humans. The workshop on Human-Centered Recommender Systems (HCRS) calls for a
paradigm shift from optimizing engagement toward designing systems that truly
understand, involve, and benefit people. It brings together researchers in
recommender systems, human-computer interaction, AI safety, and social
computing to explore how human values, e.g., trust, safety, fairness,
transparency, and well-being, can be integrated into recommendation processes.
Centered around three thematic axes-Human Understanding, Human Involvement, and
Human Impact-HCRS features keynotes, panels, and papers covering topics from
LLM-based interactive recommenders to societal welfare optimization. By
fostering interdisciplinary collaboration, HCRS aims to shape the next decade
of responsible and human-aligned recommendation research.
\\ ( https://arxiv.org/abs/2511.19979 ,  58kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19999
Date: Tue, 25 Nov 2025 07:07:36 GMT   (138kb)

Title: Popularity Bias Alignment Estimates
Authors: Anton Lyubinin
Categories: cs.IR cs.AI stat.ML
MSC-class: 68T05 (Primary) 68P20, 15A42, 05C50 (Secondary)
ACM-class: H.3.3; I.2.6; G.1.3
\\
 We are extending Popularity Bias Memorization theorem from
arXiv:archive/2404.12008 in several directions. We extend it to arbitrary
degree distributions and also prove both upper and lower estimates for the
alignment with top-k singular hyperspace.
\\ ( https://arxiv.org/abs/2511.19999 ,  138kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20009
Date: Tue, 25 Nov 2025 07:23:05 GMT   (1258kb)

Title: Adaptive Knowledge Transfer for Cross-Disciplinary Cold-Start Knowledge
 Tracing
Authors: Yulong Deng, Zheng Guan, Min He, Xue Wang, Jie Liu, Zheng Li
Categories: cs.IR
Comments: 10 pages, 5 figures
ACM-class: H.1.2
\\
 Cross-Disciplinary Cold-start Knowledge Tracing (CDCKT) faces a critical
challenge: insufficient student interaction data in the target discipline
prevents effective knowledge state modeling and performance prediction.
Existing cross-disciplinary methods rely on overlapping entities between
disciplines for knowledge transfer through simple mapping functions, but suffer
from two key limitations: (1) overlapping entities are scarce in real-world
scenarios, and (2) simple mappings inadequately capture cross-disciplinary
knowledge complexity. To overcome these challenges, we propose Mixed of Experts
and Adversarial Generative Network-based Cross-disciplinary Cold-start
Knowledge Tracing Framework. Our approach consists of three key components:
First, we pre-train a source discipline model and cluster student knowledge
states into K categories. Second, these cluster attributes guide a
mixture-of-experts network through a gating mechanism, serving as a
cross-domain mapping bridge. Third, an adversarial discriminator enforces
feature separation by pulling same-attribute student features closer while
pushing different-attribute features apart, effectively mitigating small-sample
limitations. We validate our method's effectiveness across 20 extreme
cross-disciplinary cold-start scenarios.
\\ ( https://arxiv.org/abs/2511.20009 ,  1258kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20122
Date: Tue, 25 Nov 2025 09:43:00 GMT   (1704kb)

Title: Towards A Tri-View Diffusion Framework for Recommendation
Authors: Ximing Chen, Pui Ieng Lei, Yijun Sheng, Yanyan Liu, Zhiguo Gong
Categories: cs.IR
Comments: 13 pages, 11 figures, accepted by KDD2026 (First Cycle)
\\
 Diffusion models (DMs) have recently gained significant interest for their
exceptional potential in recommendation tasks. This stems primarily from their
prominent capability in distilling, modeling, and generating comprehensive user
preferences. However, previous work fails to examine DMs in recommendation
tasks through a rigorous lens. In this paper, we first experimentally
investigate the completeness of recommender models from a thermodynamic view.
We reveal that existing DM-based recommender models operate by maximizing the
energy, while classic recommender models operate by reducing the entropy. Based
on this finding, we propose a minimalistic diffusion framework that
incorporates both factors via the maximization of Helmholtz free energy.
Meanwhile, to foster the optimization, our reverse process is armed with a
well-designed denoiser to maintain the inherent anisotropy, which measures the
user-item cross-correlation in the context of bipartite graphs. Finally, we
adopt an Acceptance-Rejection Gumbel Sampling Process (AR-GSP) to prioritize
the far-outnumbered unobserved interactions for model robustness. AR-GSP
integrates an acceptance-rejection sampling to ensure high-quality hard
negative samples for general recommendation tasks, and a timestep-dependent
Gumbel Softmax to handle an adaptive sampling strategy for diffusion models.
Theoretical analyses and extensive experiments demonstrate that our proposed
framework has distinct superiority over baselines in terms of accuracy and
efficiency.
\\ ( https://arxiv.org/abs/2511.20122 ,  1704kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20177
Date: Tue, 25 Nov 2025 10:59:38 GMT   (1039kb)

Title: Enhancing Sequential Recommendation with World Knowledge from Large
 Language Models
Authors: Tianjie Dai, Xu Chen, Yunmeng Shu, Jinsong Lan, Xiaoyong Zhu,
 Jiangchao Yao, Bo Zheng
Categories: cs.IR
\\
 Sequential Recommendation System~(SRS) has become pivotal in modern society,
which predicts subsequent actions based on the user's historical behavior.
However, traditional collaborative filtering-based sequential recommendation
models often lead to suboptimal performance due to the limited information of
their collaborative signals. With the rapid development of LLMs, an increasing
number of works have incorporated LLMs' world knowledge into sequential
recommendation. Although they achieve considerable gains, these approaches
typically assume the correctness of LLM-generated results and remain
susceptible to noise induced by LLM hallucinations. To overcome these
limitations, we propose GRASP (Generation Augmented Retrieval with Holistic
Attention for Sequential Prediction), a flexible framework that integrates
generation augmented retrieval for descriptive synthesis and similarity
retrieval, and holistic attention enhancement which employs multi-level
attention to effectively employ LLM's world knowledge even with hallucinations
and better capture users' dynamic interests. The retrieved similar users/items
serve as auxiliary contextual information for the later holistic attention
enhancement module, effectively mitigating the noisy guidance of
supervision-based methods. Comprehensive evaluations on two public benchmarks
and one industrial dataset reveal that GRASP consistently achieves
state-of-the-art performance when integrated with diverse backbones. The code
is available at: https://anonymous.4open.science/r/GRASP-SRS.
\\ ( https://arxiv.org/abs/2511.20177 ,  1039kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20227
Date: Tue, 25 Nov 2025 11:59:52 GMT   (3152kb)

Title: HKRAG: Holistic Knowledge Retrieval-Augmented Generation Over
 Visually-Rich Documents
Authors: Anyang Tong, Xiang Niu, ZhiPing Liu, Chang Tian, Yanyan Wei, Zenglin
 Shi, and Meng Wang
Categories: cs.IR
\\
 Existing multimodal Retrieval-Augmented Generation (RAG) methods for visually
rich documents (VRD) are often biased towards retrieving salient
knowledge(e.g., prominent text and visual elements), while largely neglecting
the critical fine-print knowledge(e.g., small text, contextual details). This
limitation leads to incomplete retrieval and compromises the generator's
ability to produce accurate and comprehensive answers. To bridge this gap, we
propose HKRAG, a new holistic RAG framework designed to explicitly capture and
integrate both knowledge types. Our framework features two key components: (1)
a Hybrid Masking-based Holistic Retriever that employs explicit masking
strategies to separately model salient and fine-print knowledge, ensuring a
query-relevant holistic information retrieval; and (2) an Uncertainty-guided
Agentic Generator that dynamically assesses the uncertainty of initial answers
and actively decides how to integrate the two distinct knowledge streams for
optimal response generation. Extensive experiments on open-domain visual
question answering benchmarks show that HKRAG consistently outperforms existing
methods in both zero-shot and supervised settings, demonstrating the critical
importance of holistic knowledge retrieval for VRD understanding.
\\ ( https://arxiv.org/abs/2511.20227 ,  3152kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20235
Date: Tue, 25 Nov 2025 12:07:56 GMT   (252kb)

Title: HHFT: Hierarchical Heterogeneous Feature Transformer for Recommendation
 Systems
Authors: Liren Yu, Wenming Zhang, Silu Zhou, Zhixuan Zhang, Dan Ou
Categories: cs.IR
\\
 We propose HHFT (Hierarchical Heterogeneous Feature Transformer), a
Transformer-based architecture tailored for industrial CTR prediction. HHFT
addresses the limitations of DNN through three key designs: (1) Semantic
Feature Partitioning: Grouping heterogeneous features (e.g. user profile, item
information, behaviour sequennce) into semantically coherent blocks to preserve
domain-specific information; (2) Heterogeneous Transformer Encoder: Adopting
block-specific QKV projections and FFNs to avoid semantic confusion between
distinct feature types; (3) Hiformer Layer: Capturing high-order interactions
across features. Our findings reveal that Transformers significantly outperform
DNN baselines, achieving a +0.4% improvement in CTR AUC at scale. We have
successfully deployed the model on Taobao's production platform, observing a
significant uplift in key business metrics, including a +0.6% increase in Gross
Merchandise Value (GMV).
\\ ( https://arxiv.org/abs/2511.20235 ,  252kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19465
Date: Fri, 21 Nov 2025 19:58:17 GMT   (288kb)

Title: Hidden markov model to predict tourists visited place
Authors: Theo Demessance, Chongke Bi, Sonia Djebali, Guillaume Guerard
Categories: cs.LG cs.AI
Journal-ref: 2021 22nd IEEE International Conference on Mobile Data Management
 (MDM)
DOI: 10.1109/MDM52706.2021.00041
\\
 Nowadays, social networks are becoming a popular way of analyzing tourist
behavior, thanks to the digital traces left by travelers during their stays on
these networks. The massive amount of data generated; by the propensity of
tourists to share comments and photos during their trip; makes it possible to
model their journeys and analyze their behavior. Predicting the next movement
of tourists plays a key role in tourism marketing to understand demand and
improve decision support. In this paper, we propose a method to understand and
to learn tourists' movements based on social network data analysis to predict
future movements. The method relies on a machine learning grammatical inference
algorithm. A major contribution in this paper is to adapt the grammatical
inference algorithm to the context of big data. Our method produces a hidden
Markov model representing the movements of a group of tourists. The hidden
Markov model is flexible and editable with new data. The capital city of
France, Paris is selected to demonstrate the efficiency of the proposed
methodology.
\\ ( https://arxiv.org/abs/2511.19465 ,  288kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19470
Date: Sat, 22 Nov 2025 05:02:58 GMT   (9411kb)

Title: Quantifying Modality Contributions via Disentangling Multimodal
 Representations
Authors: Padegal Amit, Omkar Mahesh Kashyap, Namitha Rayasam, Nidhi Shekhar,
 Surabhi Narayan
Categories: cs.LG cs.AI cs.CL
Comments: 16 pages, 11 figures
\\
 Quantifying modality contributions in multimodal models remains a challenge,
as existing approaches conflate the notion of contribution itself. Prior work
relies on accuracy-based approaches, interpreting performance drops after
removing a modality as indicative of its influence. However, such
outcome-driven metrics fail to distinguish whether a modality is inherently
informative or whether its value arises only through interaction with other
modalities. This distinction is particularly important in cross-attention
architectures, where modalities influence each other's representations. In this
work, we propose a framework based on Partial Information Decomposition (PID)
that quantifies modality contributions by decomposing predictive information in
internal embeddings into unique, redundant, and synergistic components. To
enable scalable, inference-only analysis, we develop an algorithm based on the
Iterative Proportional Fitting Procedure (IPFP) that computes layer and
dataset-level contributions without retraining. This provides a principled,
representation-level view of multimodal behavior, offering clearer and more
interpretable insights than outcome-based metrics.
\\ ( https://arxiv.org/abs/2511.19470 ,  9411kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19472
Date: Sat, 22 Nov 2025 06:43:43 GMT   (2918kb)

Title: PrefixGPT: Prefix Adder Optimization by a Generative Pre-trained
 Transformer
Authors: Ruogu Ding, Xin Ning, Ulf Schlichtmann, Weikang Qian
Categories: cs.LG cs.AI cs.AR
Comments: An extended version that has been accepted by AAAI-2026 conference
\\
 Prefix adders are widely used in compute-intensive applications for their
high speed. However, designing optimized prefix adders is challenging due to
strict design rules and an exponentially large design space. We introduce
PrefixGPT, a generative pre-trained Transformer (GPT) that directly generates
optimized prefix adders from scratch. Our approach represents an adder's
topology as a two-dimensional coordinate sequence and applies a legality mask
during generation, ensuring every design is valid by construction. PrefixGPT
features a customized decoder-only Transformer architecture. The model is first
pre-trained on a corpus of randomly synthesized valid prefix adders to learn
design rules and then fine-tuned to navigate the design space for optimized
design quality. Compared with existing works, PrefixGPT not only finds a new
optimal design with a 7.7% improved area-delay product (ADP) but exhibits
superior exploration quality, lowering the average ADP by up to 79.1%. This
demonstrates the potential of GPT-style models to first master complex hardware
design principles and then apply them for more efficient design optimization.
\\ ( https://arxiv.org/abs/2511.19472 ,  2918kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19473
Date: Sat, 22 Nov 2025 07:33:00 GMT   (606kb)

Title: WavefrontDiffusion: Dynamic Decoding Schedule or Improved Reasoning
Authors: Haojin Yang, Rui Hu, Zequn Sun, Rui Zhou, Yujun Cai, Yiwei Wang
Categories: cs.LG cs.AI
Comments: 19 pages. 3 figures
\\
 Diffusion Language Models (DLMs) have shown strong potential for text
generation and are becoming a competitive alternative to autoregressive models.
The denoising strategy plays an important role in determining the quality of
their outputs. Mainstream denoising strategies include Standard Diffusion and
BlockDiffusion. Standard Diffusion performs global denoising without
restricting the update range, often finalizing incomplete context and causing
premature end-of-sequence predictions. BlockDiffusion updates fixed-size blocks
in a preset order, but its rigid structure can break apart coherent semantic
units and disrupt reasoning. We present WavefrontDiffusion, a dynamic decoding
approach that expands a wavefront of active tokens outward from finalized
positions. This adaptive process follows the natural flow of semantic structure
while keeping computational cost equal to block-based methods. Across four
benchmarks in reasoning and code generation, WavefrontDiffusion achieves
state-of-the-art performance while producing outputs with higher semantic
fidelity, showing the value of adaptive scheduling for more coherent and
efficient generation.
\\ ( https://arxiv.org/abs/2511.19473 ,  606kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19480
Date: Sat, 22 Nov 2025 20:08:29 GMT   (57kb)

Title: Exploiting the Experts: Unauthorized Compression in MoE-LLMs
Authors: Pinaki Prasad Guha Neogi, Ahmad Mohammadshirazi, Dheeraj Kulshrestha,
 Rajiv Ramnath
Categories: cs.LG cs.AI
\\
 Mixture-of-Experts (MoE) architectures are increasingly adopted in large
language models (LLMs) for their scalability and efficiency. However, their
modular structure introduces a unique vulnerability: adversaries can attempt to
compress or repurpose models by pruning experts and cheaply fine-tuning the
remainder, effectively bypassing licensing and security constraints. In this
paper, we systematically study the prunability of MoE-LLMs under task-specific
usage. We first develop an expert attribution framework that identifies the
subset of experts most responsible for a given task, then evaluate the
performance trade-offs of pruning and re-aligning these experts using active
learning-driven fine-tuning. Our findings reveal a critical knowledge
loss--recovery trade-off: while certain experts can be isolated to retain task
accuracy, significant degradation occurs without targeted re-alignment. Based
on this analysis, we propose defense strategies that aim to make MoE models
harder to compress and fine-tune without authorization, including entangled
expert training and selective fine-tuning protocols that resist unauthorized
adaptation. By positioning expert pruning as both a threat vector and a defense
target, this work highlights the dual-use nature of MoE modularity and provides
the first systematic evaluation framework for secure specialization of
MoE-LLMs.
\\ ( https://arxiv.org/abs/2511.19480 ,  57kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19481
Date: Sat, 22 Nov 2025 21:43:04 GMT   (633kb)

Title: Quality analysis and evaluation prediction of RAG retrieval based on
 machine learning algorithms
Authors: Ruoxin Zhang, Zhizhao Wen, Chao Wang, Chenchen Tang, Puyang Xu, Yifan
 Jiang
Categories: cs.LG
\\
 With the rapid evolution of large language models, retrieval enhanced
generation technology has been widely used due to its ability to integrate
external knowledge to improve output accuracy. However, the performance of the
system is highly dependent on the quality of the retrieval module. If the
retrieval results have low relevance to user needs or contain noisy
information, it will directly lead to distortion of the generated content. In
response to the performance bottleneck of existing models in processing tabular
features, this paper proposes an XGBoost machine learning regression model
based on feature engineering and particle swarm optimization. Correlation
analysis shows that answer_quality is positively correlated with doc_delevance
by 0.66, indicating that document relevance has a significant positive effect
on answer quality, and improving document relevance may enhance answer quality;
The strong negative correlations between semantic similarity, redundancy, and
diversity were -0.89 and -0.88, respectively, indicating a trade- off between
semantic similarity, redundancy, and diversity. In other words, as the former
two increased, diversity significantly decreased. The experimental results
comparing decision trees, AdaBoost, etc. show that the VMD PSO BiLSTM model is
superior in all evaluation indicators, with significantly lower MSE, RMSE, MAE,
and MAPE compared to the comparison model. The R2 value is higher, indicating
that its prediction accuracy, stability, and data interpretation ability are
more outstanding. This achievement provides an effective path for optimizing
the retrieval quality and improving the generation effect of RAG system, and
has important value in promoting the implementation and application of related
technologies.
\\ ( https://arxiv.org/abs/2511.19481 ,  633kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19485
Date: Sun, 23 Nov 2025 05:17:22 GMT   (768kb)

Title: OmniTFT: Omni Target Forecasting for Vital Signs and Laboratory Result
 Trajectories in Multi Center ICU Data
Authors: Wanzhe Xu, Yutong Dai, Yitao Yang, Martin Loza, Weihang Zhang, Yang
 Cui, Xin Zeng, Sung Joon Park and Kenta Nakai
Categories: cs.LG
Comments: 23 pages, 5 figures, 2 tables
\\
 Accurate multivariate time-series prediction of vital signs and laboratory
results is crucial for early intervention and precision medicine in intensive
care units (ICUs). However, vital signs are often noisy and exhibit rapid
fluctuations, while laboratory tests suffer from missing values, measurement
lags, and device-specific bias, making integrative forecasting highly
challenging. To address these issues, we propose OmniTFT, a deep learning
framework that jointly learns and forecasts high-frequency vital signs and
sparsely sampled laboratory results based on the Temporal Fusion Transformer
(TFT). Specifically, OmniTFT implements four novel strategies to enhance
performance: sliding window equalized sampling to balance physiological states,
frequency-aware embedding shrinkage to stabilize rare-class representations,
hierarchical variable selection to guide model attention toward informative
feature clusters, and influence-aligned attention calibration to enhance
robustness during abrupt physiological changes. By reducing the reliance on
target-specific architectures and extensive feature engineering, OmniTFT
enables unified modeling of multiple heterogeneous clinical targets while
preserving cross-institutional generalizability. Across forecasting tasks,
OmniTFT achieves substantial performance improvement for both vital signs and
laboratory results on the MIMIC-III, MIMIC-IV, and eICU datasets. Its attention
patterns are interpretable and consistent with known pathophysiology,
underscoring its potential utility for quantitative decision support in
clinical care.
\\ ( https://arxiv.org/abs/2511.19485 ,  768kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19486
Date: Sun, 23 Nov 2025 05:23:21 GMT   (468kb)

Title: Efficient Inference Using Large Language Models with Limited Human Data:
 Fine-Tuning then Rectification
Authors: Lei Wang, Zikun Ye, Jinglong Zhao
Categories: cs.LG cs.AI
\\
 Driven by recent advances in artificial intelligence (AI), a growing body of
work demonstrates the potential of using large language models (LLMs) to
generate human-like responses in market research and social science
applications. Two primary approaches can be applied to improve the performance
of LLMs: fine-tuning, which aligns LLM predictions more closely with human
responses, and rectification, which corrects biases in LLM outputs. In this
paper, we develop a framework that combines fine-tuning and rectification, and
optimally allocates limited labeled samples across the two stages. Unlike the
conventional objective that minimizes the mean squared prediction errors, we
propose to minimize the variance of the prediction errors as the fine-tuning
objective, which is optimal for the downstream rectification stage. Building on
this insight, we leverage empirical scaling laws to develop a data-driven
method for optimally splitting samples between the fine-tuning and
rectification stages. Empirical analysis validates our framework, demonstrating
improved estimation and inference performance compared to using either
fine-tuning or rectification alone.
\\ ( https://arxiv.org/abs/2511.19486 ,  468kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19487
Date: Sun, 23 Nov 2025 05:50:53 GMT   (147kb)

Title: The Generalized Proximity Forest
Authors: Ben Shaw, Adam Rustad, Sofia Pelagalli Maia, Jake S. Rhodes, Kevin R.
 Moon
Categories: cs.LG stat.ML
\\
 Recent work has demonstrated the utility of Random Forest (RF) proximities
for various supervised machine learning tasks, including outlier detection,
missing data imputation, and visualization. However, the utility of the RF
proximities depends upon the success of the RF model, which itself is not the
ideal model in all contexts. RF proximities have recently been extended to time
series by means of the distance-based Proximity Forest (PF) model, among
others, affording time series analysis with the benefits of RF proximities. In
this work, we introduce the generalized PF model, thereby extending RF
proximities to all contexts in which supervised distance-based machine learning
can occur. Additionally, we introduce a variant of the PF model for regression
tasks. We also introduce the notion of using the generalized PF model as a
meta-learning framework, extending supervised imputation capability to any
pre-trained classifier. We experimentally demonstrate the unique advantages of
the generalized PF model compared with both the RF model and the $k$-nearest
neighbors model.
\\ ( https://arxiv.org/abs/2511.19487 ,  147kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19490
Date: Sun, 23 Nov 2025 10:25:23 GMT   (1869kb)

Title: Generative Model-Aided Continual Learning for CSI Feedback in FDD
 mMIMO-OFDM Systems
Authors: Guijun Liu, Yuwen Cao, Tomoaki Ohtsuki, Jiguang He, Shahid Mumtaz
Categories: cs.LG cs.AI cs.IT math.IT
\\
 Deep autoencoder (DAE) frameworks have demonstrated their effectiveness in
reducing channel state information (CSI) feedback overhead in massive
multiple-input multiple-output (mMIMO) orthogonal frequency division
multiplexing (OFDM) systems. However, existing CSI feedback models struggle to
adapt to dynamic environments caused by user mobility, requiring retraining
when encountering new CSI distributions. Moreover, returning to previously
encountered environments often leads to performance degradation due to
catastrophic forgetting. Continual learning involves enabling models to
incorporate new information while maintaining performance on previously learned
tasks. To address these challenges, we propose a generative adversarial network
(GAN)-based learning approach for CSI feedback. By using a GAN generator as a
memory unit, our method preserves knowledge from past environments and ensures
consistently high performance across diverse scenarios without forgetting.
Simulation results show that the proposed approach enhances the generalization
capability of the DAE framework while maintaining low memory overhead.
Furthermore, it can be seamlessly integrated with other advanced CSI feedback
models, highlighting its robustness and adaptability.
\\ ( https://arxiv.org/abs/2511.19490 ,  1869kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19491
Date: Sun, 23 Nov 2025 10:27:19 GMT   (697kb)

Title: OpenCML: End-to-End Framework of Open-world Machine Learning to Learn
 Unknown Classes Incrementally
Authors: Jitendra Parmar and Praveen Singh Thakur
Categories: cs.LG
Comments: Introduces an open-world machine learning model for continual and
 adaptive learning Discovers unknown classes and dynamically creates new class
 categories.Performs class-incremental learning to retain and extend prior
 knowledge. Enables continuous model improvement across multiple learning
 iterations. Achieved superior performance with an average accuracy of 82.54
\\
 Open-world machine learning is an emerging technique in artificial
intelligence, where conventional machine learning models often follow
closed-world assumptions, which can hinder their ability to retain previously
learned knowledge for future tasks. However, automated intelligence systems
must learn about novel classes and previously known tasks. The proposed model
offers novel learning classes in an open and continuous learning environment.
It consists of two different but connected tasks. First, it discovers unknown
classes in the data and creates novel classes; next, it learns how to perform
class incrementally for each new class. Together, they enable continual
learning, allowing the system to expand its understanding of the data and
improve over time. The proposed model also outperformed existing approaches in
open-world learning. Furthermore, it demonstrated strong performance in
continuous learning, achieving a highest average accuracy of 82.54% over four
iterations and a minimum accuracy of 65.87%.
\\ ( https://arxiv.org/abs/2511.19491 ,  697kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19493
Date: Sun, 23 Nov 2025 12:00:33 GMT   (1719kb)

Title: RFX: High-Performance Random Forests with GPU Acceleration and QLORA
 Compression
Authors: Chris Kuchar
Categories: cs.LG stat.ME stat.ML
Comments: 39 pages, 9 tables, 4 figures
MSC-class: 62H30 (secondary)
\\
 RFX (Random Forests X), where X stands for compression or quantization,
presents a production-ready implementation of Breiman and Cutler's Random
Forest classification methodology in Python. RFX v1.0 provides complete
classification: out-of-bag error estimation, overall and local importance
measures, proximity matrices with QLORA compression, case-wise analysis, and
interactive visualization (rfviz)--all with CPU and GPU acceleration.
Regression, unsupervised learning, CLIQUE importance, and RF-GAP proximity are
planned for v2.0.
 This work introduces four solutions addressing the proximity matrix memory
bottleneck limiting Random Forest analysis to ~60,000 samples: (1) QLORA
(Quantized Low-Rank Adaptation) compression for GPU proximity matrices,
reducing memory from 80GB to 6.4MB for 100k samples (12,500x compression with
INT8 quantization) while maintaining 99% geometric structure preservation, (2)
CPU TriBlock proximity--combining upper-triangle storage with block-sparse
thresholding--achieving 2.7x memory reduction with lossless quality, (3)
SM-aware GPU batch sizing achieving 95% GPU utilization, and (4)
GPU-accelerated 3D MDS visualization computing embeddings directly from
low-rank factors using power iteration.
 Validation across four implementation modes (GPU/CPU x
case-wise/non-case-wise) demonstrates correct implementation. GPU achieves 1.4x
speedup over CPU for overall importance with 500+ trees. Proximity computation
scales from 1,000 to 200,000+ samples (requiring GPU QLORA), with CPU TriBlock
filling the gap for medium-scale datasets (10K-50K samples). RFX v1.0
eliminates the proximity memory bottleneck, enabling proximity-based Random
Forest analysis on datasets orders of magnitude larger than previously
feasible. Open-source production-ready classification following Breiman and
Cutler's original methodology.
\\ ( https://arxiv.org/abs/2511.19493 ,  1719kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19495
Date: Sun, 23 Nov 2025 12:46:56 GMT   (26kb)

Title: A Systematic Study of Compression Ordering for Large Language Models
Authors: Shivansh Chhawri, Rahul Mahadik, Suparna Rooj
Categories: cs.LG cs.AI
\\
 Large Language Models (LLMs) require substantial computational resources,
making model compression essential for efficient deployment in constrained
environments. Among the dominant compression techniques: knowledge
distillation, structured pruning, and low-bit quantization, their individual
effects are well studied, but their interactions and optimal sequencing remain
unclear. This work systematically examines how these techniques perform both
independently and in combination when applied to the Qwen2.5 3B model. We
evaluate multiple compression pipelines, including single, and proposed
three-technique sequences, using perplexity, G-Eval, clarity, prompt alignment,
and compression ratio as metrics. Our experiments show that quantization
provides the greatest standalone compression, while pruning introduces moderate
quality degradation. Critically, the ordering of techniques significantly
affects the final model quality: the sequence Pruning, Knowledge Distillation,
Quantization (P-KD-Q) yields the best balance, achieving a 3.68x compression
ratio while preserving strong instruction-following and language understanding
capabilities. Conversely, pipelines applying quantization early suffer severe
performance degradation due to irreversible information loss that impairs
subsequent training. Overall, this study offers practical insight into
designing effective, ordering-aware compression pipelines for deploying LLMs in
resource-limited settings.
\\ ( https://arxiv.org/abs/2511.19495 ,  26kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19496
Date: Sun, 23 Nov 2025 13:00:47 GMT   (65kb)

Title: Xmodel-2.5: 1.3B Data-Efficient Reasoning SLM
Authors: Yang Liu, Xiaolong Zhong and Ling Jiang
Categories: cs.LG cs.AI
\\
 Large language models deliver strong reasoning and tool-use skills, yet their
computational demands make them impractical for edge or cost-sensitive
deployments. We present \textbf{Xmodel-2.5}, a 1.3-billion-parameter small
language model designed as a \emph{drop-in agent core}. Training with
maximal-update parameterization ($\mu$P) allows hyper-parameters tuned on a
20M-parameter proxy to transfer directly to the full model, even under the
parameter-tied \emph{tie-word-embedding} architecture. A 1.4T-token
Warmup--Stable--Decay curriculum is used, and we further show that
\textbf{switching from AdamW to Muon during the decay phase} improves the
13-task reasoning average by 4.58\,\% while keeping every other hyper-parameter
fixed, verifying that early AdamW stability can be paired with late Muon
sharpening for better downstream performance. FP8-mixed-precision training
balances accuracy and throughput. All checkpoints, recipes, and evaluation code
are released under the Apache-2.0
license.\footnote{https://huggingface.co/XiaoduoAILab/Xmodel-2.5 and
https://huggingface.co/XiaoduoAILab/Xmodel-2.5-history (training checkpoints).}
Training code and evaluation harness:
https://github.com/XiaoduoAILab/Xmodel-2.5.
\\ ( https://arxiv.org/abs/2511.19496 ,  65kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19497
Date: Sun, 23 Nov 2025 14:47:38 GMT   (440kb)

Title: PeriodNet: Boosting the Potential of Attention Mechanism for Time Series
 Forecasting
Authors: Bowen Zhao, Huanlai Xing, Zhiwen Xiao, Jincheng Peng, Li Feng, Xinhan
 Wang, Rong Qu, Hui Li
Categories: cs.LG cs.AI
\\
 The attention mechanism has demonstrated remarkable potential in sequence
modeling, exemplified by its successful application in natural language
processing with models such as Bidirectional Encoder Representations from
Transformers (BERT) and Generative Pre-trained Transformer (GPT). Despite these
advancements, its utilization in time series forecasting (TSF) has yet to meet
expectations. Exploring a better network structure for attention in TSF holds
immense significance across various domains. In this paper, we present
PeriodNet with a brand new structure to forecast univariate and multivariate
time series. PeriodNet incorporates period attention and sparse period
attention mechanism for analyzing adjacent periods. It enhances the mining of
local characteristics, periodic patterns, and global dependencies. For
efficient cross-variable modeling, we introduce an iterative grouping mechanism
which can directly reduce the cross-variable redundancy. To fully leverage the
extracted features on the encoder side, we redesign the entire architecture of
the vanilla Transformer and propose a period diffuser for precise multi-period
prediction. Through comprehensive experiments conducted on eight datasets, we
demonstrate that PeriodNet outperforms six state-of-the-art models in both
univariate and multivariate TSF scenarios in terms of mean square error and
mean absolute error. In particular, PeriodNet achieves a relative improvement
of 22% when forecasting time series with a length of 720, in comparison to
other models based on the conventional encoder-decoder Transformer
architecture.
\\ ( https://arxiv.org/abs/2511.19497 ,  440kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19498
Date: Sun, 23 Nov 2025 15:28:19 GMT   (623kb)

Title: Hierarchical Dual-Strategy Unlearning for Biomedical and Healthcare
 Intelligence Using Imperfect and Privacy-Sensitive Medical Data
Authors: Yi Zhang, Tianxiang Xu, Zijian Li, Chao Zhang, Kunyu Zhang, Zhan Gao,
 Meinuo Li, Xiaohan Zhang, Qichao Qi, Bing Chen
Categories: cs.LG cs.AI cs.CR
\\
 Large language models (LLMs) exhibit exceptional performance but pose
substantial privacy risks due to training data memorization, particularly
within healthcare contexts involving imperfect or privacy-sensitive patient
information. We present a hierarchical dual-strategy framework for selective
knowledge unlearning that precisely removes specialized knowledge while
preserving fundamental medical competencies. Our approach synergistically
integrates geometric-constrained gradient updates to selectively modulate
target parameters with concept-aware token-level interventions that distinguish
between preservation-critical and unlearning-targeted tokens via a unified
four-level medical concept hierarchy. Comprehensive evaluations on the MedMCQA
(surgical) and MHQA (anxiety, depression, trauma) datasets demonstrate superior
performance, achieving an 82.7% forgetting rate and 88.5% knowledge
preservation. Notably, our framework maintains robust privacy guarantees while
requiring modification of only 0.1% of parameters, addressing critical needs
for regulatory compliance, auditability, and ethical standards in clinical
research.
\\ ( https://arxiv.org/abs/2511.19498 ,  623kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19499
Date: Sun, 23 Nov 2025 16:02:27 GMT   (1212kb)

Title: Beyond Binary Classification: A Semi-supervised Approach to Generalized
 AI-generated Image Detection
Authors: Hong-Hanh Nguyen-Le, Van-Tuan Tran, Dinh-Thuc Nguyen, and Nhien-An
 Le-Khac
Categories: cs.LG cs.AI cs.CR cs.CV
Comments: Accepted to The 40th Annual AAAI Conference on Artificial
 Intelligence - 2025
\\
 The rapid advancement of generators (e.g., StyleGAN, Midjourney, DALL-E) has
produced highly realistic synthetic images, posing significant challenges to
digital media authenticity. These generators are typically based on a few core
architectural families, primarily Generative Adversarial Networks (GANs) and
Diffusion Models (DMs). A critical vulnerability in current forensics is the
failure of detectors to achieve cross-generator generalization, especially when
crossing architectural boundaries (e.g., from GANs to DMs). We hypothesize that
this gap stems from fundamental differences in the artifacts produced by these
\textbf{distinct architectures}. In this work, we provide a theoretical
analysis explaining how the distinct optimization objectives of the GAN and DM
architectures lead to different manifold coverage behaviors. We demonstrate
that GANs permit partial coverage, often leading to boundary artifacts, while
DMs enforce complete coverage, resulting in over-smoothing patterns. Motivated
by this analysis, we propose the \textbf{Tri}archy \textbf{Detect}or
(TriDetect), a semi-supervised approach that enhances binary classification by
discovering latent architectural patterns within the "fake" class. TriDetect
employs balanced cluster assignment via the Sinkhorn-Knopp algorithm and a
cross-view consistency mechanism, encouraging the model to learn fundamental
architectural distincts. We evaluate our approach on two standard benchmarks
and three in-the-wild datasets against 13 baselines to demonstrate its
generalization capability to unseen generators.
\\ ( https://arxiv.org/abs/2511.19499 ,  1212kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19504
Date: Sun, 23 Nov 2025 20:23:23 GMT   (548kb)

Title: Position: The Complexity of Perfect AI Alignment -- Formalizing the RLHF
 Trilemma
Authors: Subramanyam Sahoo, Aman Chadha, Vinija Jain, Divya Chaudhary
Categories: cs.LG stat.ML
Comments: Accepted at NeurIPS 2025 Workshop on Socially Responsible and
 Trustworthy Foundation Models (ResponsibleFM)
\\
 Reinforcement Learning from Human Feedback (RLHF) is widely used for aligning
large language models, yet practitioners face a persistent puzzle: improving
safety often reduces fairness, scaling to diverse populations becomes
computationally intractable, and making systems robust often amplifies majority
biases. We formalize this tension as the Alignment Trilemma: no RLHF system can
simultaneously achieve (i) epsilon-representativeness across diverse human
values, (ii) polynomial tractability in sample and compute complexity, and
(iii) delta-robustness against adversarial perturbations and distribution
shift. Through a complexity-theoretic analysis integrating statistical learning
theory and robust optimization, we prove that achieving both representativeness
(epsilon <= 0.01) and robustness (delta <= 0.001) for global-scale populations
requires Omega(2^{d_context}) operations, which is super-polynomial in the
context dimensionality. We show that current RLHF implementations resolve this
trilemma by sacrificing representativeness: they collect only 10^3--10^4
samples from homogeneous annotator pools while 10^7--10^8 samples are needed
for true global representation. Our framework provides a unified explanation
for documented RLHF pathologies including preference collapse, sycophancy, and
systematic bias amplification. We conclude with concrete directions for
navigating these fundamental trade-offs through strategic relaxations of
alignment requirements.
\\ ( https://arxiv.org/abs/2511.19504 ,  548kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19506
Date: Sun, 23 Nov 2025 22:44:17 GMT   (1137kb)

Title: Profile Generators: A Link between the Narrative and the Binary Matrix
 Representation
Authors: Raoul H. Kutil, Georg Zimmermann, Barbara Strasser-Kirchweger,
 Christian Borgelt
Categories: cs.LG cs.LO
Comments: 31 pages, 8 figures, 4 tables
MSC-class: 68T30 (Primary) 68R05 05A05 (Secondary)
ACM-class: I.2.4; J.3; F.2.2
\\
 Mental health disorders, particularly cognitive disorders defined by deficits
in cognitive abilities, are described in detail in the DSM-5, which includes
definitions and examples of signs and symptoms. A simplified,
machine-actionable representation was developed to assess the similarity and
separability of these disorders, but it is not suited for the most complex
cases. Generating or applying a full binary matrix for similarity calculations
is infeasible due to the vast number of symptom combinations. This research
develops an alternative representation that links the narrative form of the
DSM-5 with the binary matrix representation and enables automated generation of
valid symptom combinations. Using a strict pre-defined format of lists, sets,
and numbers with slight variations, complex diagnostic pathways involving
numerous symptom combinations can be represented. This format, called the
symptom profile generator (or simply generator), provides a readable,
adaptable, and comprehensive alternative to a binary matrix while enabling easy
generation of symptom combinations (profiles). Cognitive disorders, which
typically involve multiple diagnostic criteria with several symptoms, can thus
be expressed as lists of generators. Representing several psychotic disorders
in generator form and generating all symptom combinations showed that matrix
representations of complex disorders become too large to manage. The MPCS
(maximum pairwise cosine similarity) algorithm cannot handle matrices of this
size, prompting the development of a profile reduction method using targeted
generator manipulation to find specific MPCS values between disorders. The
generators allow easier creation of binary representations for large matrices
and make it possible to calculate specific MPCS cases between complex disorders
through conditional generators.
\\ ( https://arxiv.org/abs/2511.19506 ,  1137kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19509
Date: Mon, 24 Nov 2025 00:43:59 GMT   (3853kb)

Title: TouchFormer: A Robust Transformer-based Framework for Multimodal
 Material Perception
Authors: Kailin Lyu, Long Xiao, Jianing Zeng, Junhao Dong, Xuexin Liu, Zhuojun
 Zou, Haoyue Yang, Lin Shu, Jie Hao
Categories: cs.LG
Comments: 9 pages, 7 figures, Accepted by AAAI 2026
\\
 Traditional vision-based material perception methods often experience
substantial performance degradation under visually impaired conditions, thereby
motivating the shift toward non-visual multimodal material perception. Despite
this, existing approaches frequently perform naive fusion of multimodal inputs,
overlooking key challenges such as modality-specific noise, missing modalities
common in real-world scenarios, and the dynamically varying importance of each
modality depending on the task. These limitations lead to suboptimal
performance across several benchmark tasks. In this paper, we propose a robust
multimodal fusion framework, TouchFormer. Specifically, we employ a
Modality-Adaptive Gating (MAG) mechanism and intra- and inter-modality
attention mechanisms to adaptively integrate cross-modal features, enhancing
model robustness. Additionally, we introduce a Cross-Instance Embedding
Regularization(CER) strategy, which significantly improves classification
accuracy in fine-grained subcategory material recognition tasks. Experimental
results demonstrate that, compared to existing non-visual methods, the proposed
TouchFormer framework achieves classification accuracy improvements of 2.48%
and 6.83% on SSMC and USMC tasks, respectively. Furthermore, real-world robotic
experiments validate TouchFormer's effectiveness in enabling robots to better
perceive and interpret their environment, paving the way for its deployment in
safety-critical applications such as emergency response and industrial
automation. The code and datasets will be open-source, and the videos are
available in the supplementary materials.
\\ ( https://arxiv.org/abs/2511.19509 ,  3853kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19513
Date: Mon, 24 Nov 2025 02:58:38 GMT   (779kb)

Title: Row-stochastic matrices can provably outperform doubly stochastic
 matrices in decentralized learning
Authors: Bing Liu, Boao Kong, Limin Lu, Kun Yuan, and Chengcheng Zhao
Categories: cs.LG
Comments: 41 pages, 38 figures
\\
 Decentralized learning often involves a weighted global loss with
heterogeneous node weights $\lambda$. We revisit two natural strategies for
incorporating these weights: (i) embedding them into the local losses to retain
a uniform weight (and thus a doubly stochastic matrix), and (ii) keeping the
original losses while employing a $\lambda$-induced row-stochastic matrix.
Although prior work shows that both strategies yield the same expected descent
direction for the global loss, it remains unclear whether the Euclidean-space
guarantees are tight and what fundamentally differentiates their behaviors. To
clarify this, we develop a weighted Hilbert-space framework
$L^2(\lambda;\mathbb{R}^d)$ and obtain convergence rates that are strictly
tighter than those from Euclidean analysis. In this geometry, the
row-stochastic matrix becomes self-adjoint whereas the doubly stochastic one
does not, creating additional penalty terms that amplify consensus error,
thereby slowing convergence. Consequently, the difference in convergence arises
not only from spectral gaps but also from these penalty terms. We then derive
sufficient conditions under which the row-stochastic design converges faster
even with a smaller spectral gap. Finally, by using a Rayleigh-quotient and
Loewner-order eigenvalue comparison, we further obtain topology conditions that
guarantee this advantage and yield practical topology-design guidelines.
\\ ( https://arxiv.org/abs/2511.19513 ,  779kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19517
Date: Mon, 24 Nov 2025 03:15:11 GMT   (1467kb)

Title: Automating Deception: Scalable Multi-Turn LLM Jailbreaks
Authors: Adarsh Kumarappan, Ananya Mujoo
Categories: cs.LG
\\
 Multi-turn conversational attacks, which leverage psychological principles
like Foot-in-the-Door (FITD), where a small initial request paves the way for a
more significant one, to bypass safety alignments, pose a persistent threat to
Large Language Models (LLMs). Progress in defending against these attacks is
hindered by a reliance on manual, hard-to-scale dataset creation. This paper
introduces a novel, automated pipeline for generating large-scale,
psychologically-grounded multi-turn jailbreak datasets. We systematically
operationalize FITD techniques into reproducible templates, creating a
benchmark of 1,500 scenarios across illegal activities and offensive content.
We evaluate seven models from three major LLM families under both multi-turn
(with history) and single-turn (without history) conditions. Our results reveal
stark differences in contextual robustness: models in the GPT family
demonstrate a significant vulnerability to conversational history, with Attack
Success Rates (ASR) increasing by as much as 32 percentage points. In contrast,
Google's Gemini 2.5 Flash exhibits exceptional resilience, proving nearly
immune to these attacks, while Anthropic's Claude 3 Haiku shows strong but
imperfect resistance. These findings highlight a critical divergence in how
current safety architectures handle conversational context and underscore the
need for defenses that can resist narrative-based manipulation.
\\ ( https://arxiv.org/abs/2511.19517 ,  1467kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19525
Date: Mon, 24 Nov 2025 07:09:08 GMT   (2037kb)

Title: Shortcut Invariance: Targeted Jacobian Regularization in Disentangled
 Latent Space
Authors: Shivam Pal, Sakshi Varshney, Piyush Rai
Categories: cs.LG cs.CV stat.ML
\\
 Deep neural networks are prone to learning shortcuts, spurious and easily
learned correlations in training data that cause severe failures in
out-of-distribution (OOD) generalization. A dominant line of work seeks
robustness by learning a robust representation, often explicitly partitioning
the latent space into core and spurious components; this approach can be
complex, brittle, and difficult to scale. We take a different approach, instead
of a robust representation, we learn a robust function. We present a simple and
effective training method that renders the classifier functionally invariant to
shortcut signals. Our method operates within a disentangled latent space, which
is essential as it isolates spurious and core features into distinct
dimensions. This separation enables the identification of candidate shortcut
features by their strong correlation with the label, used as a proxy for
semantic simplicity. The classifier is then desensitized to these features by
injecting targeted, anisotropic latent noise during training. We analyze this
as targeted Jacobian regularization, which forces the classifier to ignore
spurious features and rely on more complex, core semantic signals. The result
is state-of-the-art OOD performance on established shortcut learning
benchmarks.
\\ ( https://arxiv.org/abs/2511.19525 ,  2037kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19544
Date: Mon, 24 Nov 2025 11:22:29 GMT   (282kb)

Title: Learning to Solve Weighted Maximum Satisfiability with a Co-Training
 Architecture
Authors: Kaidi Wan, Minghao Liu, Yong Lai
Categories: cs.LG
Comments: 10 pages, 4 figures
\\
 Wepropose SplitGNN, a graph neural network (GNN)-based
 approach that learns to solve weighted maximum satisfiabil ity (MaxSAT)
problem. SplitGNN incorporates a co-training
 architecture consisting of supervised message passing mech anism and
unsupervised solution boosting layer. A new graph
 representation called edge-splitting factor graph is proposed
 to provide more structural information for learning, which is
 based on spanning tree generation and edge classification. To
 improve the solutions on challenging and weighted instances,
 we implement a GPU-accelerated layer applying efficient
 score calculation and relaxation-based optimization. Exper iments show that
SplitGNN achieves 3* faster convergence
 and better predictions compared with other GNN-based ar chitectures. More
notably, SplitGNN successfully finds solu tions that outperform modern
heuristic MaxSAT solvers on
 much larger and harder weighted MaxSAT benchmarks, and
 demonstrates exceptional generalization abilities on diverse
 structural instances.
\\ ( https://arxiv.org/abs/2511.19544 ,  282kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19548
Date: Mon, 24 Nov 2025 12:34:40 GMT   (782kb)

Title: When Should Neural Data Inform Welfare? A Critical Framework for Policy
 Uses of Neuroeconomics
Authors: Yiven (Louis) Zhu
Categories: cs.LG cs.AI cs.CY econ.GN q-bio.NC q-fin.EC
Comments: Durham Economic Journal 2025
\\
 Neuroeconomics promises to ground welfare analysis in neural and
computational evidence about how people value outcomes, learn from experience
and exercise self-control. At the same time, policy and commercial actors
increasingly invoke neural data to justify paternalistic regulation,
"brain-based" interventions and new welfare measures. This paper asks under
what conditions neural data can legitimately inform welfare judgements for
policy rather than merely describing behaviour. I develop a non-empirical,
model-based framework that links three levels: neural signals, computational
decision models and normative welfare criteria. Within an actor-critic
reinforcement-learning model, I formalise the inference path from neural
activity to latent values and prediction errors and then to welfare claims. I
show that neural evidence constrains welfare judgements only when the
neural-computational mapping is well validated, the decision model identifies
"true" interests versus context-dependent mistakes, and the welfare criterion
is explicitly specified and defended. Applying the framework to addiction,
neuromarketing and environmental policy, I derive a Neuroeconomic Welfare
Inference Checklist for regulators and for designers of NeuroAI systems. The
analysis treats brains and artificial agents as value-learning systems while
showing that internal reward signals, whether biological or artificial, are
computational quantities and cannot be treated as welfare measures without an
explicit normative model.
\\ ( https://arxiv.org/abs/2511.19548 ,  782kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19555
Date: Mon, 24 Nov 2025 14:19:51 GMT   (423kb)

Title: Online Sparse Feature Selection in Data Streams via Differential
 Evolution
Authors: Ruiyang Xu
Categories: cs.LG cs.AI
\\
 The processing of high-dimensional streaming data commonly utilizes online
streaming feature selection (OSFS) techniques. However, practical
implementations often face challenges with data incompleteness due to equipment
failures and technical constraints. Online Sparse Streaming Feature Selection
(OS2FS) tackles this issue through latent factor analysis-based missing data
imputation. Despite this advancement, existing OS2FS approaches exhibit
substantial limitations in feature evaluation, resulting in performance
deterioration. To address these shortcomings, this paper introduces a novel
Online Differential Evolution for Sparse Feature Selection (ODESFS) in data
streams, incorporating two key innovations: (1) missing value imputation using
a latent factor analysis model, and (2) feature importance evaluation through
differential evolution. Comprehensive experiments conducted on six real-world
datasets demonstrate that ODESFS consistently outperforms state-of-the-art OSFS
and OS2FS methods by selecting optimal feature subsets and achieving superior
accuracy.
\\ ( https://arxiv.org/abs/2511.19555 ,  423kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19561
Date: Mon, 24 Nov 2025 15:27:47 GMT   (7939kb)

Title: Merging without Forgetting: Continual Fusion of Task-Specific Models via
 Optimal Transport
Authors: Zecheng Pan, Zhikang Chen, Ding Li, Min Zhang, Sen Cui, Hongshuo Jin,
 Luqi Tao, Yi Yang, Deheng Ye, Yu Zhang, Tingting Zhu, Tianling Ren
Categories: cs.LG cs.AI cs.CV
\\
 Merging models fine-tuned for different tasks into a single unified model has
become an increasingly important direction for building versatile, efficient
multi-task systems. Existing approaches predominantly rely on parameter
interpolation in weight space, which we show introduces significant
distribution shift in the feature space and undermines task-specific knowledge.
In this paper, we propose OTMF (Optimal Transport-based Masked Fusion), a novel
model merging framework rooted in optimal transport theory to address the
distribution shift that arises from naive parameter interpolation. Instead of
directly aggregating features or weights, OTMF aligns the semantic geometry of
task-specific models by discovering common masks applied to task vectors
through optimal transport plans. These masks selectively extract transferable
and task-agnostic components while preserving the unique structural identities
of each task. To ensure scalability in real-world settings, OTMF further
supports a continual fusion paradigm that incrementally integrates each new
task vector without revisiting previous ones, maintaining a bounded memory
footprint and enabling efficient fusion across a growing number of tasks. We
conduct comprehensive experiments on multiple vision and language benchmarks,
and results show that OTMF achieves state-of-the-art performance in terms of
both accuracy and efficiency. These findings highlight the practical and
theoretical value of our approach to model merging.
\\ ( https://arxiv.org/abs/2511.19561 ,  7939kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19566
Date: Mon, 24 Nov 2025 15:56:24 GMT   (4344kb)

Title: ModHiFi: Identifying High Fidelity predictive components for Model
 Modification
Authors: Dhruva Kashyap, Chaitanya Murti, Pranav K Nayak, Tanay Narshana,
 Chiranjib Bhattacharyya
Categories: cs.LG stat.ML
Comments: NeurIPS 2025 (Spotlight). Our code is available at
 https://github.com/DhruvaKashyap/modhifi
\\
 Open weight models, which are ubiquitous, rarely provide access to their
training data or loss function. This makes modifying such models for tasks such
as pruning or unlearning constrained by this unavailability an active area of
research. Existing techniques typically require gradients or ground-truth
labels, rendering them infeasible in settings with limited computational
resources. In this work, we investigate the fundamental question of identifying
components that are critical to the model's predictive performance, without
access to either gradients or the loss function, and with only distributional
access such as synthetic data. We theoretically demonstrate that the global
reconstruction error is linearly bounded by local reconstruction errors for
Lipschitz-continuous networks such as CNNs and well-trained Transformers
(which, contrary to existing literature, we find exhibit Lipschitz continuity).
This motivates using the locally reconstructive behavior of component subsets
to quantify their global importance, via a metric that we term Subset Fidelity.
In the uncorrelated features setting, selecting individual components via their
Subset Fidelity scores is optimal, which we use to propose ModHiFi, an
algorithm for model modification that requires no training data or loss
function access. ModHiFi-P, for structured pruning, achieves an 11% speedup
over the current state of the art on ImageNet models and competitive
performance on language models. ModHiFi-U, for classwise unlearning, achieves
complete unlearning on CIFAR-10 without fine-tuning and demonstrates
competitive performance on Swin Transformers.
\\ ( https://arxiv.org/abs/2511.19566 ,  4344kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19569
Date: Mon, 24 Nov 2025 17:29:40 GMT   (1365kb)

Title: An Invariant Latent Space Perspective on Language Model Inversion
Authors: Wentao Ye, Jiaqi Hu, Haobo Wang, Xinpeng Ti, Zhiqing Xiao, Hao Chen,
 Liyao Li, Lei Feng, Sai Wu, Junbo Zhao
Categories: cs.LG
Comments: The Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)
\\
 Language model inversion (LMI), i.e., recovering hidden prompts from outputs,
emerges as a concrete threat to user privacy and system security. We recast LMI
as reusing the LLM's own latent space and propose the Invariant Latent Space
Hypothesis (ILSH): (1) diverse outputs from the same source prompt should
preserve consistent semantics (source invariance), and (2) input<->output
cyclic mappings should be self-consistent within a shared latent space (cyclic
invariance). Accordingly, we present Inv^2A, which treats the LLM as an
invariant decoder and learns only a lightweight inverse encoder that maps
outputs to a denoised pseudo-representation. When multiple outputs are
available, they are sparsely concatenated at the representation layer to
increase information density. Training proceeds in two stages: contrastive
alignment (source invariance) and supervised reinforcement (cyclic invariance).
An optional training-free neighborhood search can refine local performance.
Across 9 datasets covering user and system prompt scenarios, Inv^2A outperforms
baselines by an average of 4.77% BLEU score while reducing dependence on large
inverse corpora. Our analysis further shows that prevalent defenses provide
limited protection, underscoring the need for stronger strategies. The source
code and data involved in this paper can be found in
https://github.com/yyy01/Invariant_Attacker.
\\ ( https://arxiv.org/abs/2511.19569 ,  1365kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19573
Date: Mon, 24 Nov 2025 17:51:42 GMT   (797kb)

Title: Neural Tractability via Structure: Learning-Augmented Algorithms for
 Graph Combinatorial Optimization
Authors: Jialiang Li, Weitong Chen, Mingyu Guo
Categories: cs.LG stat.ML
\\
 Neural models have shown promise in solving NP-hard graph combinatorial
optimization (CO) problems. Once trained, they offer fast inference and
reasonably high-quality solutions for in-distribution testing instances, but
they generally fall short in terms of absolute solution quality compared to
classical search-based algorithms that are admittedly slower but offer
optimality guarantee once search finishes.
 We propose a novel framework that combines the inference efficiency and
exploratory power of neural models with the solution quality guarantee of
search-based algorithms. In particular, we use parameterized algorithms (PAs)
as the search component. PAs are dedicated to identifying easy instances of
generally NP-hard problems, and allow for practically efficient search by
exploiting structural simplicity (of the identified easy instances). Under our
framework, we use parameterized analysis to identify the structurally hard
parts of a CO instance. The neural model handles the hard parts by generating
advisory signals based on its data-driven understanding. The PA-based search
component then integrates the advisory signals to systematically and
efficiently searches through the remaining structurally easy parts. Notably,
our framework is agnostic to the choice of neural model and produces strictly
better solutions than neural solvers alone.
 We examine our framework on multiple CO tasks. Empirical results show that it
achieves superior solution quality, competitive with that of commercial
solvers. Furthermore, by using the neural model only for exploratory advisory
signals, our framework exhibits improved out-of-distribution generalization,
addressing a key limitation of existing neural CO solvers.
\\ ( https://arxiv.org/abs/2511.19573 ,  797kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19584
Date: Mon, 24 Nov 2025 18:57:19 GMT   (6779kb)

Title: Learning Massively Multitask World Models for Continuous Control
Authors: Nicklas Hansen, Hao Su, Xiaolong Wang
Categories: cs.LG cs.CV cs.RO
Comments: Webpage: https://www.nicklashansen.com/NewtWM
\\
 General-purpose control demands agents that act across many tasks and
embodiments, yet research on reinforcement learning (RL) for continuous control
remains dominated by single-task or offline regimes, reinforcing a view that
online RL does not scale. Inspired by the foundation model recipe (large-scale
pretraining followed by light RL) we ask whether a single agent can be trained
on hundreds of tasks with online interaction. To accelerate research in this
direction, we introduce a new benchmark with 200 diverse tasks spanning many
domains and embodiments, each with language instructions, demonstrations, and
optionally image observations. We then present \emph{Newt}, a
language-conditioned multitask world model that is first pretrained on
demonstrations to acquire task-aware representations and action priors, and
then jointly optimized with online interaction across all tasks. Experiments
show that Newt yields better multitask performance and data-efficiency than a
set of strong baselines, exhibits strong open-loop control, and enables rapid
adaptation to unseen tasks. We release our environments, demonstrations, code
for training and evaluation, as well as 200+ checkpoints.
\\ ( https://arxiv.org/abs/2511.19584 ,  6779kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19636
Date: Mon, 24 Nov 2025 19:12:26 GMT   (3585kb)

Title: Many Ways to be Right: Rashomon Sets for Concept-Based Neural Networks
Authors: Shihan Feng, Cheng Zhang, Michael Xi, Ethan Hsu, Lesia Semenova, Chudi
 Zhong
Categories: cs.LG cs.AI
\\
 Modern neural networks rarely have a single way to be right. For many tasks,
multiple models can achieve identical performance while relying on different
features or reasoning patterns, a property known as the Rashomon Effect.
However, uncovering this diversity in deep architectures is challenging as
their continuous parameter spaces contain countless near-optimal solutions that
are numerically distinct but often behaviorally similar. We introduce Rashomon
Concept Bottleneck Models, a framework that learns multiple neural networks
which are all accurate yet reason through distinct human-understandable
concepts. By combining lightweight adapter modules with a diversity-regularized
training objective, our method constructs a diverse set of deep concept-based
models efficiently without retraining from scratch. The resulting networks
provide fundamentally different reasoning processes for the same predictions,
revealing how concept reliance and decision making vary across equally
performing solutions. Our framework enables systematic exploration of
data-driven reasoning diversity in deep models, offering a new mechanism for
auditing, comparison, and alignment across equally accurate solutions.
\\ ( https://arxiv.org/abs/2511.19636 ,  3585kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19656
Date: Mon, 24 Nov 2025 19:43:40 GMT   (109kb)

Title: Lower Complexity Bounds for Nonconvex-Strongly-Convex Bilevel
 Optimization with First-Order Oracles
Authors: Kaiyi Ji
Categories: cs.LG math.OC stat.ML
Comments: 24 pages, 1 figure
\\
 Although upper bound guarantees for bilevel optimization have been widely
studied, progress on lower bounds has been limited due to the complexity of the
bilevel structure. In this work, we focus on the smooth
nonconvex-strongly-convex setting and develop new hard instances that yield
nontrivial lower bounds under deterministic and stochastic first-order oracle
models. In the deterministic case, we prove that any first-order
zero-respecting algorithm requires at least $\Omega(\kappa^{3/2}\epsilon^{-2})$
oracle calls to find an $\epsilon$-accurate stationary point, improving the
optimal lower bounds known for single-level nonconvex optimization and for
nonconvex-strongly-convex min-max problems. In the stochastic case, we show
that at least $\Omega(\kappa^{5/2}\epsilon^{-4})$ stochastic oracle calls are
necessary, again strengthening the best known bounds in related settings. Our
results expose substantial gaps between current upper and lower bounds for
bilevel optimization and suggest that even simplified regimes, such as those
with quadratic lower-level objectives, warrant further investigation toward
understanding the optimal complexity of bilevel optimization under standard
first-order oracles.
\\ ( https://arxiv.org/abs/2511.19656 ,  109kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19657
Date: Mon, 24 Nov 2025 19:44:46 GMT   (5855kb)

Title: Structured Noise Modeling for Enhanced Time-Series Forecasting
Authors: Sepideh Koohfar
Categories: cs.LG
\\
 Time-series forecasting remains difficult in real-world settings because
temporal patterns operate at multiple scales, from broad contextual trends to
fast, fine-grained fluctuations that drive critical decisions. Existing neural
models often struggle to represent these interacting dynamics, leading to
unstable predictions and reduced reliability in downstream applications. This
work introduces a forecast-blur-denoise framework that improves temporal
fidelity through structured noise modeling. The approach incorporates a
learnable Gaussian Process module that generates smooth, correlated
perturbations, encouraging the forecasting backbone to capture long-range
structure while a dedicated refinement model restores high-resolution temporal
detail. Training the components jointly enables natural competence division and
avoids the artifacts commonly produced by isotropic corruption methods.
Experiments across electricity, traffic, and solar datasets show consistent
gains in multi-horizon accuracy and stability. The modular design also allows
the blur-denoise layer to operate as a lightweight enhancement for pretrained
models, supporting efficient adaptation in limited-data scenarios. By
strengthening the reliability and interpretability of fine-scale temporal
predictions, this framework contributes to more trustworthy AI systems used in
forecasting-driven decision support across energy, infrastructure, and other
time-critical domains.
\\ ( https://arxiv.org/abs/2511.19657 ,  5855kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19664
Date: Mon, 24 Nov 2025 19:58:45 GMT   (3486kb)

Title: Demystifying Diffusion Objectives: Reweighted Losses are Better
 Variational Bounds
Authors: Jiaxin Shi, Michalis K. Titsias
Categories: cs.LG stat.ML
\\
 We derive a new theoretical interpretation of the reweighted losses that are
widely used for training diffusion models. Our method is based on constructing
a cascade of time-dependent variational lower bounds on the data
log-likelihood, that provably improves upon the standard evidence lower bound
and results in reduced data-model KL-divergences. Combining such bounds gives
rise to reweighted objectives that can be applied to any generative diffusion
model including both continuous Gaussian diffusion and masked (discrete)
diffusion models. Then, we showcase this framework in masked diffusion and
report significant improvements over previous training losses in pixel-space
image modeling, approaching sample quality comparable to continuous diffusion
models. Our results also provide a theoretical justification for the simple
weighting scheme widely used in masked image models.
\\ ( https://arxiv.org/abs/2511.19664 ,  3486kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19693
Date: Mon, 24 Nov 2025 20:57:31 GMT   (3783kb)

Title: TREASURE: A Transformer-Based Foundation Model for High-Volume
 Transaction Understanding
Authors: Chin-Chia Michael Yeh, Uday Singh Saini, Xin Dai, Xiran Fan, Shubham
 Jain, Yujie Fan, Jiarui Sun, Junpeng Wang, Menghai Pan, Yingtong Dou, Yuzhong
 Chen, Vineeth Rakesh, Liang Wang, Yan Zheng, Mahashweta Das
Categories: cs.LG cs.AI
\\
 Payment networks form the backbone of modern commerce, generating high
volumes of transaction records from daily activities. Properly modeling this
data can enable applications such as abnormal behavior detection and
consumer-level insights for hyper-personalized experiences, ultimately
improving people's lives. In this paper, we present TREASURE, TRansformer
Engine As Scalable Universal transaction Representation Encoder, a multipurpose
transformer-based foundation model specifically designed for transaction data.
The model simultaneously captures both consumer behavior and payment network
signals (such as response codes and system flags), providing comprehensive
information necessary for applications like accurate recommendation systems and
abnormal behavior detection. Verified with industry-grade datasets, TREASURE
features three key capabilities: 1) an input module with dedicated sub-modules
for static and dynamic attributes, enabling more efficient training and
inference; 2) an efficient and effective training paradigm for predicting
high-cardinality categorical attributes; and 3) demonstrated effectiveness as
both a standalone model that increases abnormal behavior detection performance
by 111% over production systems and an embedding provider that enhances
recommendation models by 104%. We present key insights from extensive ablation
studies, benchmarks against production models, and case studies, highlighting
valuable knowledge gained from developing TREASURE.
\\ ( https://arxiv.org/abs/2511.19693 ,  3783kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19694
Date: Mon, 24 Nov 2025 20:57:55 GMT   (889kb)

Title: TiCT: A Synthetically Pre-Trained Foundation Model for Time Series
 Classification
Authors: Chin-Chia Michael Yeh, Uday Singh Saini, Junpeng Wang, Xin Dai, Xiran
 Fan, Jiarui Sun, Yujie Fan, Yan Zheng
Categories: cs.LG cs.AI
\\
 The ubiquity of time series data creates a strong demand for general-purpose
foundation models, yet developing them for classification remains a significant
challenge, largely due to the high cost of labeled data. Foundation models
capable of in-context learning (ICL) offer a powerful solution, adapting to new
tasks with minimal examples and reducing the need for extensive retraining.
However, prior work on large-scale time series models has predominantly focused
on forecasting, leaving a critical gap for versatile, fine-tuning-free
classification. To address this, we introduce TiCT (Time-series in-Context
Transformer), a transformer-based model pre-trained exclusively on synthetic
data to perform in-context classification. We make two primary technical
contributions: 1) a novel architecture featuring a scalable bit-based label
encoding and a special output attention mechanism to handle an arbitrary number
of classes; and 2) a synthetic pre-training framework that combines a
Mixup-inspired process with data augmentation to foster generalization and
noise invariance. Extensive evaluations on the UCR Archive show that TiCT
achieves competitive performance against state-of-the-art supervised methods.
Crucially, this is accomplished using only in-context examples at inference
time, without updating a single model weight.
\\ ( https://arxiv.org/abs/2511.19694 ,  889kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19705
Date: Mon, 24 Nov 2025 21:15:16 GMT   (325kb)

Title: CafeQ: Calibration-free Quantization via Learned Transformations and
 Adaptive Rounding
Authors: Ziteng Sun and Adrian Benton and Samuel Kushnir and Asher Trockman and
 Vikas Singh and Suhas Diggavi and Ananda Theertha Suresh
Categories: cs.LG
\\
 Post-training quantization is an effective method for reducing the serving
cost of large language models, where the standard approach is to use a
round-to-nearest quantization level scheme. However, this often introduces
large errors due to outliers in the weights. Proposed mitigation mechanisms
include applying adaptive rounding, random rotation transformations or
committing to a post-training target using calibration data. Unfortunately,
this reliance on calibration data can be severely limiting in some real-world
scenarios as such data may be unavailable or subject to privacy regulations. In
this paper, we propose algorithms to optimize transformations and adaptive
rounding without access to any calibration data. The optimization is achieved
by designing a suitable proxy function for the quantization loss without
calibration data. To maintain inference efficiency, we perform structured
matrix transformations for single matrices. For paired weights that interact
directly in the computation graph, we use dual matrix transformations and
adaptive rounding methods. We conduct experiments on Gemma 2 models, and
observe consistent improvement over the baselines. For Gemma 2 9B quantization,
our method improves the average benchmark score from 61.9 to 62.4 for 4-bit
quantization and from 52.0 to 60.6 for 3-bit quantization, while adding less
than 3% of computation overhead. Furthermore, our method achieves performance
comparable to the commonly used GPTQ method, which requires calibration data.
\\ ( https://arxiv.org/abs/2511.19705 ,  325kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19730
Date: Mon, 24 Nov 2025 21:46:29 GMT   (12679kb)

Title: Training-Free Active Learning Framework in Materials Science with Large
 Language Models
Authors: Hongchen Wang, Rafael Espinosa Casta\~neda, Jay R. Werber, Yao Fehlis,
 Edward Kim, Jason Hattrick-Simpers
Categories: cs.LG cond-mat.mtrl-sci
\\
 Active learning (AL) accelerates scientific discovery by prioritizing the
most informative experiments, but traditional machine learning (ML) models used
in AL suffer from cold-start limitations and domain-specific feature
engineering, restricting their generalizability. Large language models (LLMs)
offer a new paradigm by leveraging their pretrained knowledge and universal
token-based representations to propose experiments directly from text-based
descriptions. Here, we introduce an LLM-based active learning framework
(LLM-AL) that operates in an iterative few-shot setting and benchmark it
against conventional ML models across four diverse materials science datasets.
We explored two prompting strategies: one using concise numerical inputs suited
for datasets with more compositional and structured features, and another using
expanded descriptive text suited for datasets with more experimental and
procedural features to provide additional context. Across all datasets, LLM-AL
could reduce the number of experiments needed to reach top-performing
candidates by over 70% and consistently outperformed traditional ML models. We
found that LLM-AL performs broader and more exploratory searches while still
reaching the optima with fewer iterations. We further examined the stability
boundaries of LLM-AL given the inherent non-determinism of LLMs and found its
performance to be broadly consistent across runs, within the variability range
typically observed for traditional ML approaches. These results demonstrate
that LLM-AL can serve as a generalizable alternative to conventional AL
pipelines for more efficient and interpretable experiment selection and
potential LLM-driven autonomous discovery.
\\ ( https://arxiv.org/abs/2511.19730 ,  12679kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19750
Date: Mon, 24 Nov 2025 22:16:07 GMT   (137kb)

Title: DISCO: A Browser-Based Privacy-Preserving Framework for Distributed
 Collaborative Learning
Authors: Julien T. T. Vignoud, Val\'erian Rousset, Hugo El Guedj, Ignacio
 Aleman, Walid Bennaceur, Batuhan Faik Derinbay, Eduard \v{D}urech, Damien
 Gengler, Lucas Giordano, Felix Grimberg, Franziska Lippoldt, Christina
 Kopidaki, Jiafan Liu, Lauris Lopata, Nathan Maire, Paul Mansat, Martin
 Milenkoski, Emmanuel Omont, G\"une\c{s} \"Ozg\"un, Mina Petrovi\'c, Francesco
 Posa, Morgan Ridel, Giorgio Savini, Marcel Torne, Lucas Trognon, Alyssa
 Unell, Olena Zavertiaieva, Sai Praneeth Karimireddy, Tahseen Rabbani,
 Mary-Anne Hartley, Martin Jaggi
Categories: cs.LG
\\
 Data is often impractical to share for a range of well considered reasons,
such as concerns over privacy, intellectual property, and legal constraints.
This not only fragments the statistical power of predictive models, but creates
an accessibility bias, where accuracy becomes inequitably distributed to those
who have the resources to overcome these concerns. We present DISCO: an
open-source DIStributed COllaborative learning platform accessible to
non-technical users, offering a means to collaboratively build machine learning
models without sharing any original data or requiring any programming
knowledge. DISCO's web application trains models locally directly in the
browser, making our tool cross-platform out-of-the-box, including smartphones.
The modular design of \disco offers choices between federated and decentralized
paradigms, various levels of privacy guarantees and several approaches to
weight aggregation strategies that allow for model personalization and bias
resilience in the collaborative training. Code repository is available at
https://github.com/epfml/disco and a showcase web interface at
https://discolab.ai
\\ ( https://arxiv.org/abs/2511.19750 ,  137kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19794
Date: Mon, 24 Nov 2025 23:50:27 GMT   (422kb)

Title: When +1% Is Not Enough: A Paired Bootstrap Protocol for Evaluating Small
 Improvements
Authors: Wenzhang Du
Categories: cs.LG stat.ML
Comments: 13 pages, 3 figures
MSC-class: 62F40, 62G09
ACM-class: I.5.2; G.3; H.3.4
\\
 Recent machine learning papers often report 1-2 percentage point improvements
from a single run on a benchmark. These gains are highly sensitive to random
seeds, data ordering, and implementation details, yet are rarely accompanied by
uncertainty estimates or significance tests. It is therefore unclear when a
reported +1-2% reflects a real algorithmic advance versus noise.
 We revisit this problem under realistic compute budgets, where only a few
runs are affordable. We propose a simple, PC-friendly evaluation protocol based
on paired multi-seed runs, bias-corrected and accelerated (BCa) bootstrap
confidence intervals, and a sign-flip permutation test on per-seed deltas. The
protocol is intentionally conservative and is meant as a guardrail against
over-claiming.
 We instantiate it on CIFAR-10, CIFAR-10N, and AG News using synthetic
no-improvement, small-gain, and medium-gain scenarios. Single runs and unpaired
t-tests often suggest significant gains for 0.6-2.0 point improvements,
especially on text. With only three seeds, our paired protocol never declares
significance in these settings. We argue that such conservative evaluation is a
safer default for small gains under tight budgets.
\\ ( https://arxiv.org/abs/2511.19794 ,  422kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19797
Date: Mon, 24 Nov 2025 23:55:45 GMT   (2361kb)

Title: Terminal Velocity Matching
Authors: Linqi Zhou, Mathias Parger, Ayaan Haque, Jiaming Song
Categories: cs.LG cs.AI cs.CV stat.ML
Comments: Code available at: https://github.com/lumalabs/tvm
\\
 We propose Terminal Velocity Matching (TVM), a generalization of flow
matching that enables high-fidelity one- and few-step generative modeling. TVM
models the transition between any two diffusion timesteps and regularizes its
behavior at its terminal time rather than at the initial time. We prove that
TVM provides an upper bound on the $2$-Wasserstein distance between data and
model distributions when the model is Lipschitz continuous. However, since
Diffusion Transformers lack this property, we introduce minimal architectural
changes that achieve stable, single-stage training. To make TVM efficient in
practice, we develop a fused attention kernel that supports backward passes on
Jacobian-Vector Products, which scale well with transformer architectures. On
ImageNet-256x256, TVM achieves 3.29 FID with a single function evaluation (NFE)
and 1.99 FID with 4 NFEs. It similarly achieves 4.32 1-NFE FID and 2.94 4-NFE
FID on ImageNet-512x512, representing state-of-the-art performance for
one/few-step models from scratch.
\\ ( https://arxiv.org/abs/2511.19797 ,  2361kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19803
Date: Tue, 25 Nov 2025 00:11:39 GMT   (357kb)

Title: Scalable Data Attribution via Forward-Only Test-Time Inference
Authors: Sibo Ma, Julian Nyarko
Categories: cs.LG
Comments: 8 pages. Work in progress
\\
 Data attribution seeks to trace model behavior back to the training examples
that shaped it, enabling debugging, auditing, and data valuation at scale.
Classical influence-function methods offer a principled foundation but remain
impractical for modern networks because they require expensive backpropagation
or Hessian inversion at inference. We propose a data attribution method that
preserves the same first-order counterfactual target while eliminating
per-query backward passes. Our approach simulates each training example's
parameter influence through short-horizon gradient propagation during training
and later reads out attributions for any query using only forward evaluations.
This design shifts computation from inference to simulation, reflecting real
deployment regimes where a model may serve billions of user queries but
originate from a fixed, finite set of data sources (for example, a large
language model trained on diverse corpora while compensating a specific
publisher such as the New York Times). Empirically, on standard MLP benchmarks,
our estimator matches or surpasses state-of-the-art baselines such as TRAK on
standard attribution metrics (LOO and LDS) while offering orders-of-magnitude
lower inference cost. By combining influence-function fidelity with first-order
scalability, our method provides a theoretical framework for practical,
real-time data attribution in large pretrained models.
\\ ( https://arxiv.org/abs/2511.19803 ,  357kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19808
Date: Tue, 25 Nov 2025 00:32:03 GMT   (283kb)

Title: Learning to Clean: Reinforcement Learning for Noisy Label Correction
Authors: Marzi Heidari, Hanping Zhang, Yuhong Guo
Categories: cs.LG cs.AI
Comments: NeurIPS 2025
\\
 The challenge of learning with noisy labels is significant in machine
learning, as it can severely degrade the performance of prediction models if
not addressed properly. This paper introduces a novel framework that
conceptualizes noisy label correction as a reinforcement learning (RL) problem.
The proposed approach, Reinforcement Learning for Noisy Label Correction
(RLNLC), defines a comprehensive state space representing data and their
associated labels, an action space that indicates possible label corrections,
and a reward mechanism that evaluates the efficacy of label corrections. RLNLC
learns a deep feature representation based policy network to perform label
correction through reinforcement learning, utilizing an actor-critic method.
The learned policy is subsequently deployed to iteratively correct noisy
training labels and facilitate the training of the prediction model. The
effectiveness of RLNLC is demonstrated through extensive experiments on
multiple benchmark datasets, where it consistently outperforms existing
state-of-the-art techniques for learning with noisy labels.
\\ ( https://arxiv.org/abs/2511.19808 ,  283kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19810
Date: Tue, 25 Nov 2025 00:33:26 GMT   (450kb)

Title: Provably Outlier-resistant Semi-parametric Regression for Transferable
 Calibration of Low-cost Air-quality Sensors
Authors: Divyansh Chaurasia and Manoj Daram and Roshan Kumar and Nihal
 Thukarama Rao and Vipul Sangode and Pranjal Srivastava and Avnish Tripathi
 and Shoubhik Chakraborty and Akanksha and Ambasht Kumar and Davender Sethi
 and Sachchida Nand Tripathi and Purushottam Kar
Categories: cs.LG stat.ML
Comments: 20 pages, 14 figures, under peer review
\\
 We present a case study for the calibration of Low-cost air-quality (LCAQ) CO
sensors from one of the largest
multi-site-multi-season-multi-sensor-multi-pollutant mobile air-quality
monitoring network deployments in India. LCAQ sensors have been shown to play a
critical role in the establishment of dense, expansive air-quality monitoring
networks and combating elevated pollution levels. The calibration of LCAQ
sensors against regulatory-grade monitors is an expensive, laborious and
time-consuming process, especially when a large number of sensors are to be
deployed in a geographically diverse layout. In this work, we present the
RESPIRE technique to calibrate LCAQ sensors to detect ambient CO (Carbon
Monoxide) levels. RESPIRE offers specific advantages over baseline calibration
methods popular in literature, such as improved prediction in cross-site,
cross-season, and cross-sensor settings. RESPIRE offers a training algorithm
that is provably resistant to outliers and an explainable model with the
ability to flag instances of model overfitting. Empirical results are presented
based on data collected during an extensive deployment spanning four sites, two
seasons and six sensor packages. RESPIRE code is available at
https://github.com/purushottamkar/respire.
\\ ( https://arxiv.org/abs/2511.19810 ,  450kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19822
Date: Tue, 25 Nov 2025 01:24:41 GMT   (424kb)

Title: Mosaic Pruning: A Hierarchical Framework for Generalizable Pruning of
 Mixture-of-Experts Models
Authors: Wentao Hu, Mingkuan Zhao, Shuangyong Song, Xiaoyan Zhu, Xin Lai,
 Jiayin Wang
Categories: cs.LG cs.AI
\\
 Sparse Mixture-of-Experts (SMoE) architectures have enabled a new frontier in
scaling Large Language Models (LLMs), offering superior performance by
activating only a fraction of their total parameters during inference. However,
their practical deployment is severely hampered by substantial static memory
overhead, as all experts must be loaded into memory. Existing post-training
pruning methods, while reducing model size, often derive their pruning criteria
from a single, general-purpose corpus. This leads to a critical limitation: a
catastrophic performance degradation when the pruned model is applied to other
domains, necessitating a costly re-pruning for each new domain. To address this
generalization gap, we introduce Mosaic Pruning (MoP). The core idea of MoP is
to construct a functionally comprehensive set of experts through a structured
``cluster-then-select" process. This process leverages a similarity metric that
captures expert performance across different task domains to functionally
cluster the experts, and subsequently selects the most representative expert
from each cluster based on our proposed Activation Variability Score. Unlike
methods that optimize for a single corpus, our proposed Mosaic Pruning ensures
that the pruned model retains a functionally complementary set of experts, much
like the tiles of a mosaic that together form a complete picture of the
original model's capabilities, enabling it to handle diverse downstream
tasks.Extensive experiments on various MoE models demonstrate the superiority
of our approach. MoP significantly outperforms prior work, achieving a 7.24\%
gain on general tasks and 8.92\% on specialized tasks like math reasoning and
code generation.
\\ ( https://arxiv.org/abs/2511.19822 ,  424kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19837
Date: Tue, 25 Nov 2025 02:07:30 GMT   (1996kb)

Title: GED-Consistent Disentanglement of Aligned and Unaligned Substructures
 for Graph Similarity Learning
Authors: Zhentao Zhan, Xiaoliang Xu, Jingjing Wang, Junmei Wang
Categories: cs.LG cs.AI cs.DB
\\
 Graph Similarity Computation (GSC) is a fundamental graph related task where
Graph Edit Distance (GED) serves as a prevalent metric. GED is determined by an
optimal alignment between a pair of graphs that partitions each into aligned
(zero-cost) and unaligned (cost-incurring) substructures. Due to NP-hard nature
of exact GED computation, GED approximations based on Graph Neural Network(GNN)
have emerged. Existing GNN-based GED approaches typically learn node embeddings
for each graph and then aggregate pairwise node similarities to estimate the
final similarity. Despite their effectiveness, we identify a mismatch between
this prevalent node-centric matching paradigm and the core principles of GED.
This discrepancy leads to two critical limitations: (1) a failure to capture
the global structural correspondence for optimal alignment, and (2) a
misattribution of edit costs driven by spurious node level signals. To address
these limitations, we propose GCGSim, a GED-consistent graph similarity
learning framework centering on graph-level matching and substructure-level
edit costs. Specifically, we make three core technical contributions. Extensive
experiments on four benchmark datasets show that GCGSim achieves
state-of-the-art performance. Our comprehensive analyses further validate that
the framework effectively learns disentangled and semantically meaningful
substructure representations.
\\ ( https://arxiv.org/abs/2511.19837 ,  1996kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19841
Date: Tue, 25 Nov 2025 02:12:52 GMT   (11074kb)

Title: Cisco Time Series Model Technical Report
Authors: Liang Gou, Archit Khare, Praneet Pabolu, Prachi Patel, Joseph Ross,
 Hercy Shen, Yuhan (Ellen) Song, Jingze Sun, Kristal Curtis, Vedant
 Dharnidharka, Abhinav Mathur, Hao Yang
Categories: cs.LG cs.AI stat.ML
\\
 We introduce the Cisco Time Series Model, a univariate zero-shot forecaster.
This time series foundation model is the result of a general architectural
innovation to a time series model enabling it to accept multiresolution input,
applied to a popular decoder-only time series model (TimesFM). The resulting
multiresolution decoder-only model is trained on over 300B unique data points,
with more than half coming from the observability domain. Quantitative and
qualitative evaluations demonstrate that the resulting model achieves superior
performance on observability datasets while retaining very similar performance
on a standard general-purpose forecasting benchmark (GIFT-Eval), and suggest
that the multiresolution structure enables the model to make more accurate
predictions on long context input.
\\ ( https://arxiv.org/abs/2511.19841 ,  11074kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19845
Date: Tue, 25 Nov 2025 02:23:04 GMT   (45590kb)

Title: SX-GeoTree: Self-eXplaining Geospatial Regression Tree Incorporating the
 Spatial Similarity of Feature Attributions
Authors: Chaogui Kang and Lijian Luo and Qingfeng Guan and Yu Liu
Categories: cs.LG cs.CY stat.ML
Comments: 41 pages, 7 figures, 12 tables
\\
 Decision trees remain central for tabular prediction but struggle with (i)
capturing spatial dependence and (ii) producing locally stable (robust)
explanations. We present SX-GeoTree, a self-explaining geospatial regression
tree that integrates three coupled objectives during recursive splitting:
impurity reduction (MSE), spatial residual control (global Moran's I), and
explanation robustness via modularity maximization on a consensus similarity
network formed from (a) geographically weighted regression (GWR) coefficient
distances (stimulus-response similarity) and (b) SHAP attribution distances
(explanatory similarity). We recast local Lipschitz continuity of feature
attributions as a network community preservation problem, enabling scalable
enforcement of spatially coherent explanations without per-sample neighborhood
searches. Experiments on two exemplar tasks (county-level GDP in Fujian, n=83;
point-wise housing prices in Seattle, n=21,613) show SX-GeoTree maintains
competitive predictive accuracy (within 0.01 $R^{2}$ of decision trees) while
improving residual spatial evenness and doubling attribution consensus
(modularity: Fujian 0.19 vs 0.09; Seattle 0.10 vs 0.05). Ablation confirms
Moran's I and modularity terms are complementary; removing either degrades both
spatial residual structure and explanation stability. The framework
demonstrates how spatial similarity - extended beyond geometric proximity
through GWR-derived local relationships - can be embedded in interpretable
models, advancing trustworthy geospatial machine learning and offering a
transferable template for domain-aware explainability.
\\ ( https://arxiv.org/abs/2511.19845 ,  45590kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19851
Date: Tue, 25 Nov 2025 02:29:22 GMT   (1487kb)

Title: Accelerating Wireless Distributed Learning via Hybrid Split and
 Federated Learning Optimization
Authors: Kun Guo, Xuefei Li, Xijun Wang, Howard H. Yang, Wei Feng, and Tony Q.
 S. Quek
Categories: cs.LG cs.DC
\\
 Federated learning (FL) and split learning (SL) are two effective distributed
learning paradigms in wireless networks, enabling collaborative model training
across mobile devices without sharing raw data. While FL supports low-latency
parallel training, it may converge to less accurate model. In contrast, SL
achieves higher accuracy through sequential training but suffers from increased
delay. To leverage the advantages of both, hybrid split and federated learning
(HSFL) allows some devices to operate in FL mode and others in SL mode. This
paper aims to accelerate HSFL by addressing three key questions: 1) How does
learning mode selection affect overall learning performance? 2) How does it
interact with batch size? 3) How can these hyperparameters be jointly optimized
alongside communication and computational resources to reduce overall learning
delay? We first analyze convergence, revealing the interplay between learning
mode and batch size. Next, we formulate a delay minimization problem and
propose a two-stage solution: a block coordinate descent method for a relaxed
problem to obtain a locally optimal solution, followed by a rounding algorithm
to recover integer batch sizes with near-optimal performance. Experimental
results demonstrate that our approach significantly accelerates convergence to
the target accuracy compared to existing methods.
\\ ( https://arxiv.org/abs/2511.19851 ,  1487kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19893
Date: Tue, 25 Nov 2025 04:04:04 GMT   (8365kb)

Title: Frailty-Aware Transformer for Recurrent Survival Modeling of Driver
 Retention in Ride-Hailing Platforms
Authors: Shuoyan Xu, Yu Zhang, Eric J. Miller
Categories: cs.LG
Comments: 13 pages, 6 figures, under review, Accepted by KDD Workshop 2025
\\
 Ride-hailing platforms are characterized by high-frequency, behavior-driven
environments. Although survival analysis has been applied to recurrent events
in other domains, its use in modeling ride-hailing driver behavior remains
largely unexplored. This study formulates idle behavior as a recurrent survival
process using large-scale platform data and proposes a Transformer-based
framework that captures long-term temporal dependencies with causal masking and
incorporates driver-specific embeddings to model latent heterogeneity. Results
on Toronto ride-hailing data demonstrate that the proposed Frailty-Aware Cox
Transformer (FACT) achieves the highest time-dependent C-indices and lowest
Brier Scores, outperforming classical and deep learning survival models. This
approach enables more accurate risk estimation, supports platform retention
strategies, and provides policy-relevant insights.
\\ ( https://arxiv.org/abs/2511.19893 ,  8365kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19935
Date: Tue, 25 Nov 2025 05:20:17 GMT   (361kb)

Title: EfficientXpert: Efficient Domain Adaptation for Large Language Models
 via Propagation-Aware Pruning
Authors: Songlin Zhao, Michael Pitts, Zhuwei Qin
Categories: cs.LG cs.CL
\\
 The rapid advancement of large language models (LLMs) has increased the
demand for domain-specialized variants in areas such as law, healthcare, and
finance. However, their large size remains a barrier to deployment in
resource-constrained environments, and existing compression methods either
generalize poorly across domains or incur high overhead. In this work, we
propose \textbf{EfficientXpert}, a lightweight domain-pruning framework that
combines a propagation-aware pruning criterion (Foresight Mask) with an
efficient adapter-update algorithm (Partial Brain Surgeon). Integrated into the
LoRA fine-tuning process, EfficientXpert enables a one-step transformation of
general pretrained models into sparse, domain-adapted experts. Across health
and legal tasks, it retains up to 98% of dense-model performance at 40%
sparsity, outperforming state-of-the-art methods. Further analysis reveals
substantial domain-dependent structural shifts that degrade the effectiveness
of general pruning masks, underscoring the need for adaptive, domain-aware
pruning strategies tailored to each domain.
\\ ( https://arxiv.org/abs/2511.19935 ,  361kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19937
Date: Tue, 25 Nov 2025 05:23:10 GMT   (785kb)

Title: Adaptivity and Universality: Problem-dependent Universal Regret for
 Online Convex Optimization
Authors: Peng Zhao, Yu-Hu Yan, Hang Yu, Zhi-Hua Zhou
Categories: cs.LG math.OC stat.ML
\\
 Universal online learning aims to achieve optimal regret guarantees without
requiring prior knowledge of the curvature of online functions. Existing
methods have established minimax-optimal regret bounds for universal online
learning, where a single algorithm can simultaneously attain
$\mathcal{O}(\sqrt{T})$ regret for convex functions, $\mathcal{O}(d \log T)$
for exp-concave functions, and $\mathcal{O}(\log T)$ for strongly convex
functions, where $T$ is the number of rounds and $d$ is the dimension of the
feasible domain. However, these methods still lack problem-dependent
adaptivity. In particular, no universal method provides regret bounds that
scale with the gradient variation $V_T$, a key quantity that plays a crucial
role in applications such as stochastic optimization and fast-rate convergence
in games. In this work, we introduce UniGrad, a novel approach that achieves
both universality and adaptivity, with two distinct realizations:
UniGrad.Correct and UniGrad.Bregman. Both methods achieve universal regret
guarantees that adapt to gradient variation, simultaneously attaining
$\mathcal{O}(\log V_T)$ regret for strongly convex functions and $\mathcal{O}(d
\log V_T)$ regret for exp-concave functions. For convex functions, the regret
bounds differ: UniGrad.Correct achieves an $\mathcal{O}(\sqrt{V_T \log V_T})$
bound while preserving the RVU property that is crucial for fast convergence in
online games, whereas UniGrad.Bregman achieves the optimal
$\mathcal{O}(\sqrt{V_T})$ regret bound through a novel design. Both methods
employ a meta algorithm with $\mathcal{O}(\log T)$ base learners, which
naturally requires $\mathcal{O}(\log T)$ gradient queries per round. To enhance
computational efficiency, we introduce UniGrad++, which retains the regret
while reducing the gradient query to just $1$ per round via surrogate
optimization. We further provide various implications.
\\ ( https://arxiv.org/abs/2511.19937 ,  785kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19941
Date: Tue, 25 Nov 2025 05:27:30 GMT   (661kb)

Title: Optimize Flip Angle Schedules In MR Fingerprinting Using Reinforcement
 Learning
Authors: Shenjun Zhong, Zhifeng Chen, Zhaolin Chen
Categories: cs.LG cs.AI cs.CE
Comments: 4 pages, 5 figures, submitted to conference
\\
 Magnetic Resonance Fingerprinting (MRF) leverages transient-state signal
dynamics generated by the tunable acquisition parameters, making the design of
an optimal, robust sequence a complex, high-dimensional sequential decision
problem, such as optimizing one of the key parameters, flip angle.
Reinforcement learning (RL) offers a promising approach to automate parameter
selection, to optimize pulse sequences that maximize the distinguishability of
fingerprints across the parameter space. In this work, we introduce an RL
framework for optimizing the flip-angle schedule in MRF and demonstrate a
learned schedule exhibiting non-periodic patterns that enhances fingerprint
separability. Additionally, an interesting observation is that the RL-optimized
schedule may enable a reduction in the number of repetition time, potentially
accelerate MRF acquisitions.
\\ ( https://arxiv.org/abs/2511.19941 ,  661kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19942
Date: Tue, 25 Nov 2025 05:28:55 GMT   (3413kb)

Title: Differential Smoothing Mitigates Sharpening and Improves LLM Reasoning
Authors: Jingchu Gai, Guanning Zeng, Huaqing Zhang, Aditi Raghunathan
Categories: cs.LG
\\
 It is widely recognized that reinforcement learning (RL) fine-tuning of large
language models often leads to \textit{diversity collapse}, where outputs lack
variety. Prior work has proposed a range of heuristics to counteract this
effect, but these methods are ad hoc: they frequently trade off correctness for
diversity, their effectiveness varies across tasks, and in some cases they even
contradict one another. In this work, we place these observations on a rigorous
foundation. We first provide a formal proof of why RL fine-tuning exhibits
diversity collapse via a selection and reinforcement bias. Next, we make a key
observation that any reward modification to address diversity collapse only
needs to be applied on the correct trajectories. Building directly on this
analysis, we introduce a principled method -- \textit{differential smoothing}
-- that provably improves both correctness and diversity, outperforming vanilla
RL as well as widely used entropy-based heuristics. Our theory precisely
characterizes when existing heuristics help and why they fail, while showing
that differential smoothing is universally superior. Extensive experiments with
models from 1B to 7B parameters, across domains including CountDown and
real-world mathematical reasoning, demonstrate consistent gains. Differential
smoothing improves both Pass@1 and Pass@k, with up to 6.7\% improvements on
AIME24 dataset.
\\ ( https://arxiv.org/abs/2511.19942 ,  3413kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19952
Date: Tue, 25 Nov 2025 05:57:29 GMT   (1231kb)

Title: Hierarchical Spatio-Temporal Attention Network with Adaptive Risk-Aware
 Decision for Forward Collision Warning in Complex Scenarios
Authors: Haoran Hu, Junren Shi, Shuo Jiang, Kun Cheng, Xia Yang, Changhao Piao
Categories: cs.LG
\\
 Forward Collision Warning systems are crucial for vehicle safety and
autonomous driving, yet current methods often fail to balance precise
multi-agent interaction modeling with real-time decision adaptability,
evidenced by the high computational cost for edge deployment and the
unreliability stemming from simplified interaction models.To overcome these
dual challenges-computational complexity and modeling insufficiency-along with
the high false alarm rates of traditional static-threshold warnings, this paper
introduces an integrated FCW framework that pairs a Hierarchical
Spatio-Temporal Attention Network with a Dynamic Risk Threshold Adjustment
algorithm. HSTAN employs a decoupled architecture (Graph Attention Network for
spatial, cascaded GRU with self-attention for temporal) to achieve superior
performance and efficiency, requiring only 12.3 ms inference time (73% faster
than Transformer methods) and reducing the Average Displacement Error (ADE) to
0.73m (42.2% better than Social_LSTM) on the NGSIM dataset. Furthermore,
Conformalized Quantile Regression enhances reliability by generating prediction
intervals (91.3% coverage at 90% confidence), which the DTRA module then
converts into timely warnings via a physics-informed risk potential function
and an adaptive threshold mechanism inspired by statistical process
control.Tested across multi-scenario datasets, the complete system demonstrates
high efficacy, achieving an F1 score of 0.912, a low false alarm rate of 8.2%,
and an ample warning lead time of 2.8 seconds, validating the framework's
superior performance and practical deployment feasibility in complex
environments.
\\ ( https://arxiv.org/abs/2511.19952 ,  1231kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19956
Date: Tue, 25 Nov 2025 06:05:47 GMT   (2257kb)

Title: Prompt Fairness: Sub-group Disparities in LLMs
Authors: Meiyu Zhong, Noel Teku, Ravi Tandon
Categories: cs.LG cs.IT math.IT
\\
 Large Language Models (LLMs), though shown to be effective in many
applications, can vary significantly in their response quality. In this paper,
we investigate this problem of prompt fairness: specifically, the phrasing of a
prompt by different users/styles, despite the same question being asked in
principle, may elicit different responses from an LLM. To quantify this
disparity, we propose to use information-theoretic metrics that can capture two
dimensions of bias: subgroup sensitivity, the variability of responses within a
subgroup and cross group consistency, the variability of responses across
subgroups. Our analysis reveals that certain subgroups exhibit both higher
internal variability and greater divergence from others. Our empirical analysis
reveals that certain demographic sub groups experience both higher internal
variability and greater divergence from others, indicating structural
inequities in model behavior. To mitigate these disparities, we propose
practical interventions, including majority voting across multiple generations
and prompt neutralization, which together improve response stability and
enhance fairness across user populations. In the experiments, we observe clear
prompt sensitivity disparities across demographic subgroups: before mitigation,
cross-group divergence values reach 0.28 and typically fall in the from 0.14 to
0.22 range. After applying our neutralization and multi generation strategy,
these divergences consistently decrease, with the largest gap reduced to 0.22
and many distances falling to 0.17 or below, indicating more stable and
consistent outputs across subgroups.
\\ ( https://arxiv.org/abs/2511.19956 ,  2257kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19959
Date: Tue, 25 Nov 2025 06:09:21 GMT   (891kb)

Title: ParaBlock: Communication-Computation Parallel Block Coordinate Federated
 Learning for Large Language Models
Authors: Yujia Wang, Yuanpu Cao, Jinghui Chen
Categories: cs.LG cs.DC
Comments: 32 pages, 2 figures
\\
 Federated learning (FL) has been extensively studied as a privacy-preserving
training paradigm. Recently, federated block coordinate descent scheme has
become a popular option in training large-scale models, as it allows clients to
train only a subset of the model locally instead of the entire model. However,
in the era of large language models (LLMs), even a single block can contain a
significant number of parameters, posing substantial communication latency,
particularly for resource-constrained clients. To address this challenge in
federated training/fine-tuning LLMs, we propose ParaBlock, a novel approach
that establishes two parallel threads for communication and computation to
enhance communication efficiency. We theoretically prove that the proposed
ParaBlock achieves the same convergence rate as the standard federated block
coordinate descent methods. Empirical evaluations on fine-tuning LLMs on
general instruction following and mathematical reasoning confirm that ParaBlock
not only maintains strong performance but also significantly improves
communication efficiency.
\\ ( https://arxiv.org/abs/2511.19959 ,  891kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19966
Date: Tue, 25 Nov 2025 06:25:25 GMT   (45kb)

Title: Stragglers Can Contribute More: Uncertainty-Aware Distillation for
 Asynchronous Federated Learning
Authors: Yujia Wang, Fenglong Ma, Jinghui Chen
Categories: cs.LG cs.DC
Comments: 28 pages
\\
 Asynchronous federated learning (FL) has recently gained attention for its
enhanced efficiency and scalability, enabling local clients to send model
updates to the server at their own pace without waiting for slower
participants. However, such a design encounters significant challenges, such as
the risk of outdated updates from straggler clients degrading the overall model
performance and the potential bias introduced by faster clients dominating the
learning process, especially under heterogeneous data distributions. Existing
methods typically address only one of these issues, creating a conflict where
mitigating the impact of outdated updates can exacerbate the bias created by
faster clients, and vice versa. To address these challenges, we propose
FedEcho, a novel framework that incorporates uncertainty-aware distillation to
enhance the asynchronous FL performances under large asynchronous delays and
data heterogeneity. Specifically, uncertainty-aware distillation enables the
server to assess the reliability of predictions made by straggler clients,
dynamically adjusting the influence of these predictions based on their
estimated uncertainty. By prioritizing more certain predictions while still
leveraging the diverse information from all clients, FedEcho effectively
mitigates the negative impacts of outdated updates and data heterogeneity.
Through extensive experiments, we demonstrate that FedEcho consistently
outperforms existing asynchronous federated learning baselines, achieving
robust performance without requiring access to private client data.
\\ ( https://arxiv.org/abs/2511.19966 ,  45kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19976
Date: Tue, 25 Nov 2025 06:45:13 GMT   (170kb)

Title: Rethinking Semi-Supervised Node Classification with Self-Supervised
 Graph Clustering
Authors: Songbo Wang, Renchi Yang, Yurui Lai, Xiaoyang Lin, Tsz Nam Chan
Categories: cs.LG cs.SI
Comments: 14 pages
\\
 The emergence of graph neural networks (GNNs) has offered a powerful tool for
semi-supervised node classification tasks. Subsequent studies have achieved
further improvements through refining the message passing schemes in GNN models
or exploiting various data augmentation techniques to mitigate limited
supervision. In real graphs, nodes often tend to form tightly-knit
communities/clusters, which embody abundant signals for compensating label
scarcity in semi-supervised node classification but are not explored in prior
methods.
 Inspired by this, this paper presents NCGC that integrates self-supervised
graph clustering and semi-supervised classification into a unified framework.
Firstly, we theoretically unify the optimization objectives of GNNs and
spectral graph clustering, and based on that, develop soft orthogonal GNNs
(SOGNs) that leverage a refined message passing paradigm to generate node
representations for both classification and clustering. On top of that, NCGC
includes a self-supervised graph clustering module that enables the training of
SOGNs for learning representations of unlabeled nodes in a self-supervised
manner. Particularly, this component comprises two non-trivial clustering
objectives and a Sinkhorn-Knopp normalization that transforms predicted cluster
assignments into balanced soft pseudo-labels. Through combining the foregoing
clustering module with the classification model using a multi-task objective
containing the supervised classification loss on labeled data and
self-supervised clustering loss on unlabeled data, NCGC promotes synergy
between them and achieves enhanced model capacity. Our extensive experiments
showcase that the proposed NCGC framework consistently and considerably
outperforms popular GNN models and recent baselines for semi-supervised node
classification on seven real graphs, when working with various classic GNN
backbones.
\\ ( https://arxiv.org/abs/2511.19976 ,  170kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19980
Date: Tue, 25 Nov 2025 06:49:25 GMT   (2826kb)

Title: Operator Learning at Machine Precision
Authors: Aras Bacho, Aleksei G. Sorokin, Xianjin Yang, Th\'eo Bourdais, Edoardo
 Calvello, Matthieu Darcy, Alexander Hsu, Bamdad Hosseini, Houman Owhadi
Categories: cs.LG cs.NA math.NA
\\
 Neural operator learning methods have garnered significant attention in
scientific computing for their ability to approximate infinite-dimensional
operators. However, increasing their complexity often fails to substantially
improve their accuracy, leaving them on par with much simpler approaches such
as kernel methods and more traditional reduced-order models. In this article,
we set out to address this shortcoming and introduce CHONKNORIS (Cholesky
Newton--Kantorovich Neural Operator Residual Iterative System), an operator
learning paradigm that can achieve machine precision. CHONKNORIS draws on
numerical analysis: many nonlinear forward and inverse PDE problems are
solvable by Newton-type methods. Rather than regressing the solution operator
itself, our method regresses the Cholesky factors of the elliptic operator
associated with Tikhonov-regularized Newton--Kantorovich updates. The resulting
unrolled iteration yields a neural architecture whose machine-precision
behavior follows from achieving a contractive map, requiring far lower accuracy
than end-to-end approximation of the solution operator. We benchmark CHONKNORIS
on a range of nonlinear forward and inverse problems, including a nonlinear
elliptic equation, Burgers' equation, a nonlinear Darcy flow problem, the
Calder\'{o}n problem, an inverse wave scattering problem, and a problem from
seismic imaging. We also present theoretical guarantees for the convergence of
CHONKNORIS in terms of the accuracy of the emulated Cholesky factors.
Additionally, we introduce a foundation model variant, FONKNORIS (Foundation
Newton--Kantorovich Neural Operator Residual Iterative System), which
aggregates multiple pre-trained CHONKNORIS experts for diverse PDEs to emulate
the solution map of a novel nonlinear PDE. Our FONKNORIS model is able to
accurately solve unseen nonlinear PDEs such as the Klein--Gordon and
Sine--Gordon equations.
\\ ( https://arxiv.org/abs/2511.19980 ,  2826kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19984
Date: Tue, 25 Nov 2025 06:52:35 GMT   (88kb)

Title: Rethinking Message Passing Neural Networks with Diffusion
 Distance-guided Stress Majorization
Authors: Haoran Zheng, Renchi Yang, Yubo Zhou, Jianliang Xu
Categories: cs.LG
Comments: Accepted by SIGKDD 2026. The code is available at
 https://github.com/HaoranZ99/DDSM
\\
 Message passing neural networks (MPNNs) have emerged as go-to models for
learning on graph-structured data in the past decade. Despite their
effectiveness, most of such models still incur severe issues such as
over-smoothing and -correlation, due to their underlying objective of
minimizing the Dirichlet energy and the derived neighborhood aggregation
operations. In this paper, we propose the DDSM, a new MPNN model built on an
optimization framework that includes the stress majorization and orthogonal
regularization for overcoming the above issues. Further, we introduce the
diffusion distances for nodes into the framework to guide the new message
passing operations and develop efficient algorithms for distance
approximations, both backed by rigorous theoretical analyses. Our comprehensive
experiments showcase that DDSM consistently and considerably outperforms 15
strong baselines on both homophilic and heterophilic graphs.
\\ ( https://arxiv.org/abs/2511.19984 ,  88kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19986
Date: Tue, 25 Nov 2025 06:54:04 GMT   (6874kb)

Title: On-Demand Multi-Task Sparsity for Efficient Large-Model Deployment on
 Edge Devices
Authors: Lianming Huang, Haibo Hu, Qiao Li, Nan Guan, Chun Jason Xue
Categories: cs.LG cs.AI cs.CV
\\
 Sparsity is essential for deploying large models on resource constrained edge
platforms. However, optimizing sparsity patterns for individual tasks in
isolation ignores the significant I/O overhead incurred during frequent task
switching. We introduce an on-demand multi-task sparsity framework specifically
designed to minimize switching costs by maximizing parameter reuse. Unlike
monolithic approaches, we decompose weights into reusable block-granular units
and align sparse structures across tasks to maximize overlap. By dynamically
loading only the small differential set of blocks required for the next task,
our method effectively mitigates the cold-start latency inherent in traditional
monolithic approaches.Experiments on a real-world autonomous driving platform
demonstrate that our framework achieves superior switching efficiency,
accelerating task switching by over 6.6X on average compared to existing
sparsity methods.
\\ ( https://arxiv.org/abs/2511.19986 ,  6874kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19996
Date: Tue, 25 Nov 2025 07:02:56 GMT   (8452kb)

Title: RankOOD - Class Ranking-based Out-of-Distribution Detection
Authors: Dishanika Denipitiyage, Naveen Karunanayake, Suranga Seneviratne,
 Sanjay Chawla
Categories: cs.LG
\\
 We propose RankOOD, a rank-based Out-of-Distribution (OOD) detection approach
based on training a model with the Placket-Luce loss, which is now extensively
used for preference alignment tasks in foundational models. Our approach is
based on the insight that with a deep learning model trained using the Cross
Entropy Loss, in-distribution (ID) class prediction induces a ranking pattern
for each ID class prediction. The RankOOD framework formalizes the insight by
first extracting a rank list for each class using an initial classifier and
then uses another round of training with the Plackett-Luce loss, where the
class rank, a fixed permutation for each class, is the predicted variable. An
OOD example may get assigned with high probability to an ID example, but the
probability of it respecting the ranking classification is likely to be small.
RankOOD, achieves SOTA performance on the near-ODD TinyImageNet evaluation
benchmark, reducing FPR95 by 4.3%.
\\ ( https://arxiv.org/abs/2511.19996 ,  8452kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19998
Date: Tue, 25 Nov 2025 07:04:44 GMT   (10kb)

Title: REWA: Witness-Overlap Theory -- Foundations for Composable Binary
 Similarity Systems
Authors: Nikit Phadke
Categories: cs.LG cs.DS cs.IR
\\
 REWA introduces a general theory of similarity based on witness-overlap
structures. We show that whenever similarity between concepts can be expressed
as monotone witness overlap -- whether arising from graph neighborhoods, causal
relations, temporal structure, topological features, symbolic patterns, or
embedding-based neighborhoods -- it admits a reduction to compact encodings
with provable ranking preservation guarantees. REWA systems consist of: (1)
finite witness sets $W(v)$, (2) semi-random bit assignments generated from each
witness, and (3) monotonicity of expected similarity in the overlap $\Delta(u,
v) = |W(u) \cap W(v)|$. We prove that under an overlap-gap condition on the
final witness sets -- independent of how they were constructed -- top-$k$
rankings are preserved using $m = O(\log(|V|/\delta))$ bits. The witness-set
formulation is compositional: any sequence of structural, temporal, causal,
topological, information-theoretic, or learned transformations can be combined
into pipelines that terminate in discrete witness sets. The theory applies to
the final witness overlap, enabling modular construction of similarity systems
from reusable primitives. This yields a vast design space: millions of
composable similarity definitions inherit logarithmic encoding complexity. REWA
subsumes and unifies Bloom filters, minhash, LSH bitmaps, random projections,
sketches, and hierarchical filters as special cases. It provides a principled
foundation for similarity systems whose behavior is governed by witness overlap
rather than hash-function engineering. This manuscript presents the axioms, the
main reducibility theorem, complete proofs with explicit constants, and a
detailed discussion of compositional design, limitations, and future extensions
including multi-bit encodings, weighted witnesses, and non-set representations.
\\ ( https://arxiv.org/abs/2511.19998 ,  10kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20004
Date: Tue, 25 Nov 2025 07:14:50 GMT   (5129kb)

Title: Zero-Shot Transfer Capabilities of the Sundial Foundation Model for Leaf
 Area Index Forecasting
Authors: Peining Zhang, Hongchen Qin, Haochen Zhang, Ziqi Guo, Guiling Wang,
 Jinbo Bi
Categories: cs.LG cs.AI cs.CV
\\
 This work investigates the zero-shot forecasting capability of time-series
foundation models for Leaf Area Index (LAI) forecasting in agricultural
monitoring. Using the HiQ dataset (U.S., 2000-2022), we systematically compare
statistical baselines, a fully supervised LSTM, and the Sundial foundation
model under multiple evaluation protocols. We find that Sundial, in the
zero-shot setting, can outperform a fully trained LSTM provided that the input
context window is sufficiently long-specifically, when covering more than one
or two full seasonal cycles. This demonstrates, for the first time, that a
general-purpose foundation model can surpass specialized supervised models on
remote-sensing time series prediction without any task-specific tuning. These
results highlight the strong potential of pretrained time-series foundation
models to serve as effective plug-and-play forecasters in agricultural and
environmental applications.
\\ ( https://arxiv.org/abs/2511.20004 ,  5129kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20015
Date: Tue, 25 Nov 2025 07:32:49 GMT   (1837kb)

Title: iRadioDiff: Physics-Informed Diffusion Model for Indoor Radio Map
 Construction and Localization
Authors: Xiucheng Wang and Tingwei Yuan and Yang Cao and Nan Cheng and Ruijin
 Sun and Weihua Zhuang
Categories: cs.LG cs.SY eess.SY
\\
 Radio maps (RMs) serve as environment-aware electromagnetic (EM)
representations that connect scenario geometry and material properties to the
spatial distribution of signal strength, enabling localization without costly
in-situ measurements. However, constructing high-fidelity indoor RMs remains
challenging due to the prohibitive latency of EM solvers and the limitations of
learning-based methods, which often rely on sparse measurements or assumptions
of homogeneous material, which are misaligned with the heterogeneous and
multipath-rich nature of indoor environments. To overcome these challenges, we
propose iRadioDiff, a sampling-free diffusion-based framework for indoor RM
construction. iRadioDiff is conditioned on access point (AP) positions, and
physics-informed prompt encoded by material reflection and transmission
coefficients. It further incorporates multipath-critical priors, including
diffraction points, strong transmission boundaries, and line-of-sight (LoS)
contours, to guide the generative process via conditional channels and
boundary-weighted objectives. This design enables accurate modeling of
nonstationary field discontinuities and efficient construction of physically
consistent RMs. Experiments demonstrate that iRadioDiff achieves
state-of-the-art performance in indoor RM construction and received signal
strength based indoor localization, which offers effective generalization
across layouts and material configurations. Code is available at
https://github.com/UNIC-Lab/iRadioDiff.
\\ ( https://arxiv.org/abs/2511.20015 ,  1837kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20030
Date: Tue, 25 Nov 2025 07:56:40 GMT   (7360kb)

Title: Cross-Contrastive Clustering for Multimodal Attributed Graphs with Dual
 Graph Filtering
Authors: Haoran Zheng, Renchi Yang, Hongtao Wang, Jianliang Xu
Categories: cs.LG
Comments: Accepted by SIGKDD 2026. The code is available at
 https://github.com/HaoranZ99/DGF
\\
 Multimodal Attributed Graphs (MMAGs) are an expressive data model for
representing the complex interconnections among entities that associate
attributes from multiple data modalities (text, images, etc.). Clustering over
such data finds numerous practical applications in real scenarios, including
social community detection, medical data analytics, etc. However, as revealed
by our empirical studies, existing multi-view clustering solutions largely rely
on the high correlation between attributes across various views and overlook
the unique characteristics (e.g., low modality-wise correlation and intense
feature-wise noise) of multimodal attributes output by large pre-trained
language and vision models in MMAGs, leading to suboptimal clustering
performance.
 Inspired by foregoing empirical observations and our theoretical analyses
with graph signal processing, we propose the Dual Graph Filtering (DGF) scheme,
which innovatively incorporates a feature-wise denoising component into node
representation learning, thereby effectively overcoming the limitations of
traditional graph filters adopted in the extant multi-view graph clustering
approaches. On top of that, DGF includes a tri-cross contrastive training
strategy that employs instance-level contrastive learning across modalities,
neighborhoods, and communities for learning robust and discriminative node
representations. Our comprehensive experiments on eight benchmark MMAG datasets
exhibit that DGF is able to outperform a wide range of state-of-the-art
baselines consistently and significantly in terms of clustering quality
measured against ground-truth labels.
\\ ( https://arxiv.org/abs/2511.20030 ,  7360kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20044
Date: Tue, 25 Nov 2025 08:11:41 GMT   (2499kb)

Title: RED-F: Reconstruction-Elimination based Dual-stream Contrastive
 Forecasting for Multivariate Time Series Anomaly Prediction
Authors: PengYu Chen, Xiaohou Shi, Yuan Chang, Yan Sun, and Sajal K. Das
Categories: cs.LG
Comments: 13 pages, 12 figures
\\
 The proactive prediction of anomalies (AP) in mul- tivariate time series
(MTS) is a critical challenge to ensure system dependability. The difficulty
lies in identifying subtle anomaly precursors concealed within normal signals.
However, existing unsupervised methods, trained exclusively on normal data,
demonstrate a fundamental propensity to reconstruct normal patterns.
Consequently, when confronted with weak precursors, their predictions are
dominated by the normal pattern, submerging the very signal required for
prediction. To contend with the limitation, we propose RED-F, a Reconstruction-
Elimination based Dual-stream Contrastive Forecasting frame- work, comprising
the Reconstruction-Elimination Model (REM) and the Dual-stream Contrastive
Forecasting Model (DFM). The REM utilizes a hybrid time-frequency mechanism to
mitigate the precursor, generating a purified, normal-pattern baseline. The DFM
then receives this purified baseline and the original sequence which retains
the precursor as parallel inputs. At the core of our framework, RED-F employs a
contrastive forecast that transforms the difficult task of absolute signal
detection into a simpler, more robust task of relative trajectory comparison by
computing the divergence between these two predictive streams. This contrastive
mechanism serves to amplify the faint precursor signal. Furthermore, the DFM is
trained with a novel Multi-Series Prediction (MSP) objective, which leverages
distant future con- text to enhance its predictive sensitivity. Extensive
experiments on six real-world datasets demonstrate the superior capability of
RED-F in anomaly prediction tasks.
\\ ( https://arxiv.org/abs/2511.20044 ,  2499kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20066
Date: Tue, 25 Nov 2025 08:39:21 GMT   (10100kb)

Title: SOMBRL: Scalable and Optimistic Model-Based RL
Authors: Bhavya Sukhija, Lenart Treven, Carmelo Sferrazza, Florian D\"orfler,
 Pieter Abbeel, Andreas Krause
Categories: cs.LG
\\
 We address the challenge of efficient exploration in model-based
reinforcement learning (MBRL), where the system dynamics are unknown and the RL
agent must learn directly from online interactions. We propose Scalable and
Optimistic MBRL (SOMBRL), an approach based on the principle of optimism in the
face of uncertainty. SOMBRL learns an uncertainty-aware dynamics model and
greedily maximizes a weighted sum of the extrinsic reward and the agent's
epistemic uncertainty. SOMBRL is compatible with any policy optimizers or
planners, and under common regularity assumptions on the system, we show that
SOMBRL has sublinear regret for nonlinear dynamics in the (i) finite-horizon,
(ii) discounted infinite-horizon, and (iii) non-episodic settings.
Additionally, SOMBRL offers a flexible and scalable solution for principled
exploration. We evaluate SOMBRL on state-based and visual-control environments,
where it displays strong performance across all tasks and baselines. We also
evaluate SOMBRL on a dynamic RC car hardware and show SOMBRL outperforms the
state-of-the-art, illustrating the benefits of principled exploration for MBRL.
\\ ( https://arxiv.org/abs/2511.20066 ,  10100kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20099
Date: Tue, 25 Nov 2025 09:17:32 GMT   (3777kb)

Title: QiMeng-CRUX: Narrowing the Gap between Natural Language and Verilog via
 Core Refined Understanding eXpression
Authors: Lei Huang, Rui Zhang, Jiaming Guo, Yang Zhang, Di Huang, Shuyao Cheng,
 Pengwei Jin, Chongxiao Li, Zidong Du, Xing Hu, Qi Guo, Yunji Chen
Categories: cs.LG cs.AR cs.PL
Comments: Accepted by the AAAI26 Conference Main Track
\\
 Large language models (LLMs) have shown promising capabilities in hardware
description language (HDL) generation. However, existing approaches often rely
on free-form natural language descriptions that are often ambiguous, redundant,
and unstructured, which poses significant challenges for downstream Verilog
code generation. We treat hardware code generation as a complex transformation
from an open-ended natural language space to a domain-specific, highly
constrained target space. To bridge this gap, we introduce Core Refined
Understanding eXpression (CRUX), a structured intermediate space that captures
the essential semantics of user intent while organizing the expression for
precise Verilog code generation. We further design a two-stage training
framework, comprising Joint Expression Modeling and Dual-Space Optimization, to
enhance the quality of both CRUX and Verilog code. Experiments across multiple
Verilog generation benchmarks demonstrate that our model, CRUX-V, achieves
state-of-the-art performance among general models, particularly under
challenging design tasks. Furthermore, the CRUX space proves transferable and
beneficial when used as input prompts for other code models, highlighting its
effectiveness in narrowing the gap between free-form natural language
descriptions and precise Verilog generation.
\\ ( https://arxiv.org/abs/2511.20099 ,  3777kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20104
Date: Tue, 25 Nov 2025 09:25:33 GMT   (14798kb)

Title: The Devil in the Details: Emergent Misalignment, Format and Coherence in
 Open-Weights LLMs
Authors: Craig Dickson
Categories: cs.LG cs.AI cs.CL
\\
 Prior work has shown that fine-tuning models on a narrow domain with
misaligned data can lead to broad misalignment - a phenomenon termed "emergent
misalignment" (Betley et al. 2025). While all tested models were susceptible to
emergent misalignment, some models showed more resistance than others.
Specifically the Qwen-2.5 family proved to be relatively resistant, while
GPT-4o exhibited the strongest misalignment. In this paper we evaluate if
current-generation open-weights models exhibit similar resistance to the
Qwen-2.5 family and measure misalignment robustness over a range of model
architectures and scales.
 We replicate the effect across nine modern open-weights models (Gemma 3 and
Qwen 3 families, 1B-32B parameters). Models fine-tuned on insecure code
generation show a 0.68% misalignment rate (compared to 0.07% for base models),
matching the lower end of prior open-model results but dramatically lower than
GPT-4o's 20%.
 We identify a critical format-dependent vulnerability: requiring JSON output
doubles misalignment rates compared to natural language prompts (0.96% vs
0.42%). This suggests that structural constraints may bypass safety training by
reducing the model's 'degrees of freedom' to refuse. These findings confirm
emergent misalignment as a reproducible phenomenon in modern open-weights
models, with rates substantially lower than observed in proprietary systems.
\\ ( https://arxiv.org/abs/2511.20104 ,  14798kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20105
Date: Tue, 25 Nov 2025 09:26:13 GMT   (4281kb)

Title: Multivariate Forecasting of Bitcoin Volatility with Gradient Boosting:
 Deterministic, Probabilistic, and Feature Importance Perspectives
Authors: Grzegorz Dudek, Mateusz Kasprzyk, Pawe{\l} Pe{\l}ka
Categories: cs.LG
DOI: 10.1016/j.eswa.2025.130404
\\
 This study investigates the application of the Light Gradient Boosting
Machine (LGBM) model for both deterministic and probabilistic forecasting of
Bitcoin realized volatility. Utilizing a comprehensive set of 69 predictors --
encompassing market, behavioral, and macroeconomic indicators -- we evaluate
the performance of LGBM-based models and compare them with both econometric and
machine learning baselines. For probabilistic forecasting, we explore two
quantile-based approaches: direct quantile regression using the pinball loss
function, and a residual simulation method that transforms point forecasts into
predictive distributions. To identify the main drivers of volatility, we employ
gain-based and permutation feature importance techniques, consistently
highlighting the significance of trading volume, lagged volatility measures,
investor attention, and market capitalization. The results demonstrate that
LGBM models effectively capture the nonlinear and high-variance characteristics
of cryptocurrency markets while providing interpretable insights into the
underlying volatility dynamics.
\\ ( https://arxiv.org/abs/2511.20105 ,  4281kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20109
Date: Tue, 25 Nov 2025 09:27:33 GMT   (3289kb)

Title: CLIMATEAGENT: Multi-Agent Orchestration for Complex Climate Data Science
 Workflows
Authors: Hyeonjae Kim, Chenyue Li, Wen Deng, Mengxi Jin, Wen Huang, Mengqian
 Lu, Binhang Yuan
Categories: cs.LG
Comments: 30 pages, 6 figures, 3 tables
\\
 Climate science demands automated workflows to transform comprehensive
questions into data-driven statements across massive, heterogeneous datasets.
However, generic LLM agents and static scripting pipelines lack
climate-specific context and flexibility, thus, perform poorly in practice. We
present ClimateAgent, an autonomous multi-agent framework that orchestrates
end-to-end climate data analytic workflows. ClimateAgent decomposes user
questions into executable sub-tasks coordinated by an Orchestrate-Agent and a
Plan-Agent; acquires data via specialized Data-Agents that dynamically
introspect APIs to synthesize robust download scripts; and completes analysis
and reporting with a Coding-Agent that generates Python code, visualizations,
and a final report with a built-in self-correction loop. To enable systematic
evaluation, we introduce Climate-Agent-Bench-85, a benchmark of 85 real-world
tasks spanning atmospheric rivers, drought, extreme precipitation, heat waves,
sea surface temperature, and tropical cyclones. On Climate-Agent-Bench-85,
ClimateAgent achieves 100% task completion and a report quality score of 8.32,
outperforming GitHub-Copilot (6.27) and a GPT-5 baseline (3.26). These results
demonstrate that our multi-agent orchestration with dynamic API awareness and
self-correcting execution substantially advances reliable, end-to-end
automation for climate science analytic tasks.
\\ ( https://arxiv.org/abs/2511.20109 ,  3289kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20141
Date: Tue, 25 Nov 2025 10:02:21 GMT   (1434kb)

Title: IDAP++: Advancing Divergence-Based Pruning via Filter-Level and
 Layer-Level Optimization
Authors: Aleksei Samarin, Artem Nazarenko, Egor Kotenko, Valentin Malykh,
 Alexander Savelev, Aleksei Toropov
Categories: cs.LG cs.AI
Comments: 65 pages, 4 figures, 38 tables
\\
 This paper presents a novel approach to neural network compression that
addresses redundancy at both the filter and architectural levels through a
unified framework grounded in information flow analysis. Building on the
concept of tensor flow divergence, which quantifies how information is
transformed across network layers, we develop a two-stage optimization process.
The first stage employs iterative divergence-aware pruning to identify and
remove redundant filters while preserving critical information pathways. The
second stage extends this principle to higher-level architecture optimization
by analyzing layer-wise contributions to information propagation and
selectively eliminating entire layers that demonstrate minimal impact on
network performance. The proposed method naturally adapts to diverse
architectures, including convolutional networks, transformers, and hybrid
designs, providing a consistent metric for comparing the structural importance
across different layer types. Experimental validation across multiple modern
architectures and datasets reveals that this combined approach achieves
substantial model compression while maintaining competitive accuracy. The
presented approach achieves parameter reduction results that are globally
comparable to those of state-of-the-art solutions and outperforms them across a
wide range of modern neural network architectures, from convolutional models to
transformers. The results demonstrate how flow divergence serves as an
effective guiding principle for both filter-level and layer-level optimization,
offering practical benefits for deployment in resource-constrained
environments.
\\ ( https://arxiv.org/abs/2511.20141 ,  1434kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20168
Date: Tue, 25 Nov 2025 10:47:05 GMT   (207kb)

Title: On the Limits of Momentum in Decentralized and Federated Optimization
Authors: Riccardo Zaccone, Sai Praneeth Karimireddy, Carlo Masone
Categories: cs.LG cs.AI
Comments: Accepted at the 17th Workshop on Optimization for Machine Learning
 (OPT@NeurIPS2025)
\\
 Recent works have explored the use of momentum in local methods to enhance
distributed SGD. This is particularly appealing in Federated Learning (FL),
where momentum intuitively appears as a solution to mitigate the effects of
statistical heterogeneity. Despite recent progress in this direction, it is
still unclear if momentum can guarantee convergence under unbounded
heterogeneity in decentralized scenarios, where only some workers participate
at each round. In this work we analyze momentum under cyclic client
participation, and theoretically prove that it remains inevitably affected by
statistical heterogeneity. Similarly to SGD, we prove that decreasing
step-sizes do not help either: in fact, any schedule decreasing faster than
$\Theta\left(1/t\right)$ leads to convergence to a constant value that depends
on the initialization and the heterogeneity bound. Numerical results
corroborate the theory, and deep learning experiments confirm its relevance for
realistic settings.
\\ ( https://arxiv.org/abs/2511.20168 ,  207kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20170
Date: Tue, 25 Nov 2025 10:50:06 GMT   (3511kb)

Title: AdaCap: An Adaptive Contrastive Approach for Small-Data Neural Networks
Authors: Bruno Belucci, Karim Lounici, Katia Meziani
Categories: cs.LG
Comments: Submitted to ESANN 2026
ACM-class: I.5.1; I.2.6
\\
 Neural networks struggle on small tabular datasets, where tree-based models
remain dominant. We introduce Adaptive Contrastive Approach (AdaCap), a
training scheme that combines a permutation-based contrastive loss with a
Tikhonov-based closed-form output mapping. Across 85 real-world regression
datasets and multiple architectures, AdaCap yields consistent and statistically
significant improvements in the small-sample regime, particularly for residual
models. A meta-predictor trained on dataset characteristics (size, skewness,
noise) accurately anticipates when AdaCap is beneficial. These results show
that AdaCap acts as a targeted regularization mechanism, strengthening neural
networks precisely where they are most fragile. All results and code are
publicly available at https://github.com/BrunoBelucci/adacap.
\\ ( https://arxiv.org/abs/2511.20170 ,  3511kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20189
Date: Tue, 25 Nov 2025 11:13:05 GMT   (1862kb)

Title: Learning Subgroups with Maximum Treatment Effects without Causal
 Heuristics
Authors: Lincen Yang, Zhong Li, Matthijs van Leeuwen, Saber Salehkaleybar
Categories: cs.LG
Comments: The full version (including the Appendix). Accepted at AAAI 2026
\\
 Discovering subgroups with the maximum average treatment effect is crucial
for targeted decision making in domains such as precision medicine, public
policy, and education. While most prior work is formulated in the potential
outcome framework, the corresponding structural causal model (SCM) for this
task has been largely overlooked. In practice, two approaches dominate. The
first estimates pointwise conditional treatment effects and then fits a tree on
those estimates, effectively turning subgroup estimation into the harder
problem of accurate pointwise estimation. The second constructs decision trees
or rule sets with ad-hoc 'causal' heuristics, typically without rigorous
justification for why a given heuristic may be used or whether such heuristics
are necessary at all. We address these issues by studying the problem directly
under the SCM framework. Under the assumption of a partition-based model, we
show that optimal subgroup discovery reduces to recovering the data-generating
models and hence a standard supervised learning problem (regression or
classification). This allows us to adopt any partition-based methods to learn
the subgroup from data. We instantiate the approach with CART, arguably one of
the most widely used tree-based methods, to learn the subgroup with maximum
treatment effect. Finally, on a large collection of synthetic and
semi-synthetic datasets, we compare our method against a wide range of
baselines and find that our approach, which avoids such causal heuristics, more
accurately identifies subgroups with maximum treatment effect. Our source code
is available at https://github.com/ylincen/causal-subgroup.
\\ ( https://arxiv.org/abs/2511.20189 ,  1862kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20194
Date: Tue, 25 Nov 2025 11:19:58 GMT   (921kb)

Title: In-Context Compositional Learning via Sparse Coding Transformer
Authors: Wei Chen, Jingxi Yu, Zichen Miao, Qiang Qiu
Categories: cs.LG
Comments: NeurIPS 2025
\\
 Transformer architectures have achieved remarkable success across language,
vision, and multimodal tasks, and there is growing demand for them to address
in-context compositional learning tasks. In these tasks, models solve the
target problems by inferring compositional rules from context examples, which
are composed of basic components structured by underlying rules. However, some
of these tasks remain challenging for Transformers, which are not inherently
designed to handle compositional tasks and offer limited structural inductive
bias. In this work, inspired by the principle of sparse coding, we propose a
reformulation of the attention to enhance its capability for compositional
tasks. In sparse coding, data are represented as sparse combinations of
dictionary atoms with coefficients that capture their compositional rules.
Specifically, we reinterpret the attention block as a mapping of inputs into
outputs through projections onto two sets of learned dictionary atoms: an
encoding dictionary and a decoding dictionary. The encoding dictionary
decomposes the input into a set of coefficients, which represent the
compositional structure of the input. To enhance structured representations, we
impose sparsity on these coefficients. The sparse coefficients are then used to
linearly combine the decoding dictionary atoms to generate the output.
Furthermore, to assist compositional generalization tasks, we propose
estimating the coefficients of the target problem as a linear combination of
the coefficients obtained from the context examples. We demonstrate the
effectiveness of our approach on the S-RAVEN and RAVEN datasets. For certain
compositional generalization tasks, our method maintains performance even when
standard Transformers fail, owing to its ability to learn and apply
compositional rules.
\\ ( https://arxiv.org/abs/2511.20194 ,  921kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20220
Date: Tue, 25 Nov 2025 11:47:47 GMT   (996kb)

Title: Communication-Efficient Learning for Satellite Constellations
Authors: Ruxandra-Stefania Tudose, Moritz H.W. Gr\"uss, Grace Ra Kim, Karl H.
 Johansson, Nicola Bastianello
Categories: cs.LG cs.SY eess.SY math.OC
\\
 Satellite constellations in low-Earth orbit are now widespread, enabling
positioning, Earth imaging, and communications. In this paper we address the
solution of learning problems using these satellite constellations. In
particular, we focus on a federated approach, where satellites collect and
locally process data, with the ground station aggregating local models. We
focus on designing a novel, communication-efficient algorithm that still yields
accurate trained models. To this end, we employ several mechanisms to reduce
the number of communications with the ground station (local training) and their
size (compression). We then propose an error feedback mechanism that enhances
accuracy, which yields, as a byproduct, an algorithm-agnostic error feedback
scheme that can be more broadly applied. We analyze the convergence of the
resulting algorithm, and compare it with the state of the art through
simulations in a realistic space scenario, showcasing superior performance.
\\ ( https://arxiv.org/abs/2511.20220 ,  996kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20222
Date: Tue, 25 Nov 2025 11:50:34 GMT   (384kb)

Title: Decoupling and Damping: Structurally-Regularized Gradient Matching for
 Multimodal Graph Condensation
Authors: Lian Shen, Zhendan Chen, Yinhui jiang, Meijia Song, Ziming Su, Juan
 Liu, Xiangrong Liu
Categories: cs.LG
Comments: 11pages,5 figures,6 tables
\\
 In critical web applications such as e-commerce and recommendation systems,
multimodal graphs integrating rich visual and textual attributes are
increasingly central, yet their large scale introduces substantial
computational burdens for training Graph Neural Networks (GNNs). While Graph
Condensation (GC) offers a promising solution by synthesizing smaller datasets,
existing methods falter in the multimodal setting. We identify a dual challenge
causing this failure: (1) conflicting gradients arising from semantic
misalignments between modalities, and (2) the GNN's message-passing
architecture pathologically amplifying this gradient noise across the graph
structure. To address this, we propose Structurally-Regularized Gradient
Matching (SR-GM), a novel condensation framework tailored for multimodal
graphs. SR-GM introduces two synergistic components: first, a gradient
decoupling mechanism that resolves inter-modality conflicts at their source via
orthogonal projection; and second, a structural damping regularizer that acts
directly on the gradient field. By leveraging the graph's Dirichlet energy,
this regularizer transforms the topology from a noise amplifier into a
stabilizing force during optimization. Extensive experiments demonstrate that
SR-GM significantly improves accuracy and accelerates convergence compared to
baseline methods. Ablation studies confirm that addressing both gradient
conflict and structural amplification in tandem is essential for achieving
superior performance. Moreover, the condensed multimodal graphs exhibit strong
cross-architecture generalization and promise to accelerate applications like
Neural Architecture Search. This research provides a scalable methodology for
multimodal graph-based learning in resource-constrained environments.
\\ ( https://arxiv.org/abs/2511.20222 ,  384kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20225
Date: Tue, 25 Nov 2025 11:55:02 GMT   (342kb)

Title: DiCaP: Distribution-Calibrated Pseudo-labeling for Semi-Supervised
 Multi-Label Learning
Authors: Bo Han, Zhuoming Li, Xiaoyu Wang, Yaxin Hou, Hui Liu, Junhui Hou,
 Yuheng Jia
Categories: cs.LG
Comments: Accepted by AAAI-26
\\
 Semi-supervised multi-label learning (SSMLL) aims to address the challenge of
limited labeled data in multi-label learning (MLL) by leveraging unlabeled data
to improve the model's performance. While pseudo-labeling has become a dominant
strategy in SSMLL, most existing methods assign equal weights to all
pseudo-labels regardless of their quality, which can amplify the impact of
noisy or uncertain predictions and degrade the overall performance. In this
paper, we theoretically verify that the optimal weight for a pseudo-label
should reflect its correctness likelihood. Empirically, we observe that on the
same dataset, the correctness likelihood distribution of unlabeled data remains
stable, even as the number of labeled training samples varies. Building on this
insight, we propose Distribution-Calibrated Pseudo-labeling (DiCaP), a
correctness-aware framework that estimates posterior precision to calibrate
pseudo-label weights. We further introduce a dual-thresholding mechanism to
separate confident and ambiguous regions: confident samples are pseudo-labeled
and weighted accordingly, while ambiguous ones are explored by unsupervised
contrastive learning. Experiments conducted on multiple benchmark datasets
verify that our method achieves consistent improvements, surpassing
state-of-the-art methods by up to 4.27%.
\\ ( https://arxiv.org/abs/2511.20225 ,  342kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20234
Date: Tue, 25 Nov 2025 12:07:25 GMT   (343kb)

Title: Leveraging weights signals - Predicting and improving generalizability
 in reinforcement learning
Authors: Olivier Moulin, Vincent Francois-lavet, Paul Elbers, Mark Hoogendoorn
Categories: cs.LG cs.AI
\\
 Generalizability of Reinforcement Learning (RL) agents (ability to perform on
environments different from the ones they have been trained on) is a key
problem as agents have the tendency to overfit to their training environments.
In order to address this problem and offer a solution to increase the
generalizability of RL agents, we introduce a new methodology to predict the
generalizability score of RL agents based on the internal weights of the
agent's neural networks. Using this prediction capability, we propose some
changes in the Proximal Policy Optimization (PPO) loss function to boost the
generalization score of the agents trained with this upgraded version.
Experimental results demonstrate that our improved PPO algorithm yields agents
with stronger generalizability compared to the original version.
\\ ( https://arxiv.org/abs/2511.20234 ,  343kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20257
Date: Tue, 25 Nov 2025 12:36:27 GMT   (473kb)

Title: Interpretable Air Pollution Forecasting by Physics-Guided Spatiotemporal
 Decoupling
Authors: Zhiguo Zhang and Xiaoliang Ma and Daniel Schlesinger
Categories: cs.LG cs.AI
Comments: Accepted to 2025 IEEE International Conference on Big Data
\\
 Accurate and interpretable air pollution forecasting is crucial for public
health, but most models face a trade-off between performance and
interpretability. This study proposes a physics-guided, interpretable-by-design
spatiotemporal learning framework. The model decomposes the spatiotemporal
behavior of air pollutant concentrations into two transparent, additive
modules. The first is a physics-guided transport kernel with directed weights
conditioned on wind and geography (advection). The second is an explainable
attention mechanism that learns local responses and attributes future
concentrations to specific historical lags and exogenous drivers. Evaluated on
a comprehensive dataset from the Stockholm region, our model consistently
outperforms state-of-the-art baselines across multiple forecasting horizons.
Our model's integration of high predictive performance and spatiotemporal
interpretability provides a more reliable foundation for operational
air-quality management in real-world applications.
\\ ( https://arxiv.org/abs/2511.20257 ,  473kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20273
Date: Tue, 25 Nov 2025 12:59:15 GMT   (2458kb)

Title: Beyond Components: Singular Vector-Based Interpretability of Transformer
 Circuits
Authors: Areeb Ahmad and Abhinav Joshi and Ashutosh Modi
Categories: cs.LG cs.AI cs.CL
Comments: Accepted at NeurIPS 2025
\\
 Transformer-based language models exhibit complex and distributed behavior,
yet their internal computations remain poorly understood. Existing mechanistic
interpretability methods typically treat attention heads and multilayer
perceptron layers (MLPs) (the building blocks of a transformer architecture) as
indivisible units, overlooking possibilities of functional substructure learned
within them. In this work, we introduce a more fine-grained perspective that
decomposes these components into orthogonal singular directions, revealing
superposed and independent computations within a single head or MLP. We
validate our perspective on widely used standard tasks like Indirect Object
Identification (IOI), Gender Pronoun (GP), and Greater Than (GT), showing that
previously identified canonical functional heads, such as the name mover,
encode multiple overlapping subfunctions aligned with distinct singular
directions. Nodes in a computational graph, that are previously identified as
circuit elements show strong activation along specific low-rank directions,
suggesting that meaningful computations reside in compact subspaces. While some
directions remain challenging to interpret fully, our results highlight that
transformer computations are more distributed, structured, and compositional
than previously assumed. This perspective opens new avenues for fine-grained
mechanistic interpretability and a deeper understanding of model internals.
\\ ( https://arxiv.org/abs/2511.20273 ,  2458kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20277
Date: Tue, 25 Nov 2025 13:05:40 GMT   (4939kb)

Title: HVAdam: A Full-Dimension Adaptive Optimizer
Authors: Yiheng Zhang, Shaowu Wu, Yuanzhuo Xu, Jiajun Wu, Shang Xu, Steve Drew,
 Xiaoguang Niu
Categories: cs.LG cs.AI
\\
 Adaptive optimizers such as Adam have achieved great success in training
large-scale models like large language models and diffusion models. However,
they often generalize worse than non-adaptive methods, such as SGD on classical
architectures like CNNs. We identify a key cause of this performance gap:
adaptivity in pre-conditioners, which limits the optimizer's ability to adapt
to diverse optimization landscapes. To address this, we propose Anon
(Adaptivity Non-restricted Optimizer with Novel convergence technique), a novel
optimizer with continuously tunable adaptivity
 , allowing it to interpolate between SGD-like and Adam-like behaviors and
even extrapolate beyond both. To ensure convergence across the entire
adaptivity spectrum, we introduce incremental delay update (IDU), a novel
mechanism that is more flexible than AMSGrad's hard max-tracking strategy and
enhances robustness to gradient noise. We theoretically establish convergence
guarantees under both convex and non-convex settings. Empirically, Anon
consistently outperforms state-of-the-art optimizers on representative image
classification, diffusion, and language modeling tasks. These results
demonstrate that adaptivity can serve as a valuable tunable design principle,
and Anon provides the first unified and reliable framework capable of bridging
the gap between classical and modern optimizers and surpassing their
advantageous properties.
\\ ( https://arxiv.org/abs/2511.20277 ,  4939kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20315
Date: Tue, 25 Nov 2025 13:52:46 GMT   (2332kb)

Title: Geometry of Decision Making in Language Models
Authors: Abhinav Joshi and Divyanshu Bhatt and Ashutosh Modi
Categories: cs.LG cs.AI cs.CL
Comments: Accepted at NeurIPS 2025
\\
 Large Language Models (LLMs) show strong generalization across diverse tasks,
yet the internal decision-making processes behind their predictions remain
opaque. In this work, we study the geometry of hidden representations in LLMs
through the lens of \textit{intrinsic dimension} (ID), focusing specifically on
decision-making dynamics in a multiple-choice question answering (MCQA)
setting. We perform a large-scale study, with 28 open-weight transformer models
and estimate ID across layers using multiple estimators, while also quantifying
per-layer performance on MCQA tasks. Our findings reveal a consistent ID
pattern across models: early layers operate on low-dimensional manifolds,
middle layers expand this space, and later layers compress it again, converging
to decision-relevant representations. Together, these results suggest LLMs
implicitly learn to project linguistic inputs onto structured, low-dimensional
manifolds aligned with task-specific decisions, providing new geometric
insights into how generalization and reasoning emerge in language models.
\\ ( https://arxiv.org/abs/2511.20315 ,  2332kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20327
Date: Tue, 25 Nov 2025 13:58:53 GMT   (1087kb)

Title: MXtalTools: A Toolkit for Machine Learning on Molecular Crystals
Authors: Michael Kilgour and Mark E. Tuckerman and Jutta Rogal
Categories: cs.LG
Comments: 16 pages, 11 figures
\\
 We present MXtalTools, a flexible Python package for the data-driven
modelling of molecular crystals, facilitating machine learning studies of the
molecular solid state. MXtalTools comprises several classes of utilities: (1)
synthesis, collation, and curation of molecule and crystal datasets, (2)
integrated workflows for model training and inference, (3) crystal
parameterization and representation, (4) crystal structure sampling and
optimization, (5) end-to-end differentiable crystal sampling, construction and
analysis. Our modular functions can be integrated into existing workflows or
combined and used to build novel modelling pipelines. MXtalTools leverages CUDA
acceleration to enable high-throughput crystal modelling. The Python code is
available open-source on our GitHub page, with detailed documentation on
ReadTheDocs.
\\ ( https://arxiv.org/abs/2511.20327 ,  1087kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20347
Date: Tue, 25 Nov 2025 14:25:19 GMT   (631kb)

Title: Soft Adaptive Policy Optimization
Authors: Chang Gao, Chujie Zheng, Xiong-Hui Chen, Kai Dang, Shixuan Liu, Bowen
 Yu, An Yang, Shuai Bai, Jingren Zhou, Junyang Lin
Categories: cs.LG cs.AI cs.CL
\\
 Reinforcement learning (RL) plays an increasingly important role in enhancing
the reasoning capabilities of large language models (LLMs), yet stable and
performant policy optimization remains challenging. Token-level importance
ratios often exhibit high variance-a phenomenon exacerbated in
Mixture-of-Experts models-leading to unstable updates. Existing group-based
policy optimization methods, such as GSPO and GRPO, alleviate this problem via
hard clipping, making it difficult to maintain both stability and effective
learning. We propose Soft Adaptive Policy Optimization (SAPO), which replaces
hard clipping with a smooth, temperature-controlled gate that adaptively
attenuates off-policy updates while preserving useful learning signals.
Compared with GSPO and GRPO, SAPO is both sequence-coherent and token-adaptive.
Like GSPO, SAPO maintains sequence-level coherence, but its soft gating forms a
continuous trust region that avoids the brittle hard clipping band used in
GSPO. When a sequence contains a few highly off-policy tokens, GSPO suppresses
all gradients for that sequence, whereas SAPO selectively down-weights only the
offending tokens and preserves the learning signal from the near-on-policy
ones, improving sample efficiency. Relative to GRPO, SAPO replaces hard
token-level clipping with smooth, temperature-controlled scaling, enabling more
informative and stable updates. Empirical results on mathematical reasoning
benchmarks indicate that SAPO exhibits improved training stability and higher
Pass@1 performance under comparable training budgets. Moreover, we employ SAPO
to train the Qwen3-VL model series, demonstrating that SAPO yields consistent
performance gains across diverse tasks and different model sizes. Overall, SAPO
provides a more reliable, scalable, and effective optimization strategy for RL
training of LLMs.
\\ ( https://arxiv.org/abs/2511.20347 ,  631kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20349
Date: Tue, 25 Nov 2025 14:25:57 GMT   (701kb)

Title: Complexity Reduction Study Based on RD Costs Approximation for VVC Intra
 Partitioning
Authors: M.E.A. Kherchouche, F. Galpin, T. Dumas, F. Schnitzler, D. Menard, L.
 Zhang
Categories: cs.LG
Comments: 2025 Data Compression Conference (DCC)
DOI: 10.1109/DCC62719.2025.00064
\\
 In this paper, a complexity study is conducted for Versatile Video Codec
(VVC) intra partitioning to accelerate the exhaustive search involved in
Rate-Distortion Optimization (RDO) process. To address this problem, two main
machine learning techniques are proposed and compared. Unlike existing methods,
the proposed approaches are size independent and incorporate the
Rate-Distortion (RD) costs of neighboring blocks as input features. The first
method is a regression based technique that predicts normalized RD costs of a
given Coding Unit (CU). As partitioning possesses the Markov property, the
associated decision-making problem can be modeled as a Markov Decision Process
(MDP) and solved by Reinforcement Learning (RL). The second approach is a RL
agent learned from trajectories of CU decision across two depths with Deep
Q-Network (DQN) algorithm. Then a pre-determined thresholds are applied for
both methods to select a suitable split for the current CU.
\\ ( https://arxiv.org/abs/2511.20349 ,  701kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20362
Date: Tue, 25 Nov 2025 14:43:14 GMT   (14707kb)

Title: PRISM: Periodic Representation with multIscale and Similarity graph
 Modelling for enhanced crystal structure property prediction
Authors: \`Alex Sol\'e, Albert Mosella-Montoro, Joan Cardona, Daniel Aravena,
 Silvia G\'omez-Coca, Eliseo Ruiz, Javier Ruiz-Hidalgo
Categories: cs.LG cond-mat.mtrl-sci
\\
 Crystal structures are characterised by repeating atomic patterns within unit
cells across three-dimensional space, posing unique challenges for graph-based
representation learning. Current methods often overlook essential periodic
boundary conditions and multiscale interactions inherent to crystalline
structures. In this paper, we introduce PRISM, a graph neural network framework
that explicitly integrates multiscale representations and periodic feature
encoding by employing a set of expert modules, each specialised in encoding
distinct structural and chemical aspects of periodic systems. Extensive
experiments across crystal structure-based benchmarks demonstrate that PRISM
improves state-of-the-art predictive accuracy, significantly enhancing crystal
property prediction.
\\ ( https://arxiv.org/abs/2511.20362 ,  14707kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20382
Date: Tue, 25 Nov 2025 15:04:06 GMT   (6807kb)

Title: MoRE: Batch-Robust Multi-Omics Representations from Frozen Pre-trained
 Transformers
Authors: Audrey Pei-Hsuan Chen
Categories: cs.LG q-bio.GN
\\
 Representation learning on multi-omics data is challenging due to extreme
dimensionality, modality heterogeneity, and cohort-specific batch effects.
While pre-trained transformer backbones have shown broad generalization
capabilities in biological sequence modeling, their application to multi-omics
integration remains underexplored. We present MoRE (Multi-Omics Representation
Embedding), a framework that repurposes frozen pre-trained transformers to
align heterogeneous assays into a shared latent space. Unlike purely generative
approaches, MoRE employs a parameter-efficient fine-tuning (PEFT) strategy,
prioritizing cross-sample and cross-modality alignment over simple sequence
reconstruction. Specifically, MoRE attaches lightweight, modality-specific
adapters and a task-adaptive fusion layer to the frozen backbone. It optimizes
a masked modeling objective jointly with supervised contrastive and
batch-invariant alignment losses, yielding structure-preserving embeddings that
generalize across unseen cell types and platforms. We benchmark MoRE against
established baselines, including scGPT, scVI, and Harmony with scArches,
evaluating integration fidelity, rare population detection, and modality
transfer. Our results demonstrate that MoRE achieves competitive batch
robustness and biological conservation while significantly reducing trainable
parameters compared to fully fine-tuned models. This work positions MoRE as a
practical step toward general-purpose omics foundation models.
\\ ( https://arxiv.org/abs/2511.20382 ,  6807kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20395
Date: Tue, 25 Nov 2025 15:19:57 GMT   (418kb)

Title: Identifying environmental factors associated with tetrodotoxin
 contamination in bivalve mollusks using eXplainable AI
Authors: M.C. Schoppema, B.H.M. van der Velden, A. H\"urriyeto\u{g}lu, M.D.
 Klijnstra, E.J. Faassen, A. Gerssen, H.J. van der Fels-Klerx
Categories: cs.LG
Comments: 18 pages, 6 figures, submitted to Nature Food
\\
 Since 2012, tetrodotoxin (TTX) has been found in seafoods such as bivalve
mollusks in temperate European waters. TTX contamination leads to food safety
risks and economic losses, making early prediction of TTX contamination vital
to the food industry and competent authorities. Recent studies have pointed to
shallow habitats and water temperature as main drivers to TTX contamination in
bivalve mollusks. However, the temporal relationships between abiotic factors,
biotic factors, and TTX contamination remain unexplored.
 We have developed an explainable, deep learning-based model to predict TTX
contamination in the Dutch Zeeland estuary. Inputs for the model were
meteorological and hydrological features; output was the presence or absence of
TTX contamination.
 Results showed that the time of sunrise, time of sunset, global radiation,
water temperature, and chloride concentration contributed most to TTX
contamination. Thus, the effective number of sun hours, represented by day
length and global radiation, was an important driver for tetrodotoxin
contamination in bivalve mollusks.
 To conclude, our explainable deep learning model identified the
aforementioned environmental factors (number of sun hours, global radiation,
water temperature, and water chloride concentration) to be associated with
tetrodotoxin contamination in bivalve mollusks; making our approach a valuable
tool to mitigate marine toxin risks for food industry and competent
authorities.
\\ ( https://arxiv.org/abs/2511.20395 ,  418kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20397
Date: Tue, 25 Nov 2025 15:21:00 GMT   (497kb)

Title: Model-Based Learning of Whittle indices
Authors: Jo\"el Charles-Rebuff\'e, Nicolas Gast, Bruno Gaujal
Categories: cs.LG cs.DS cs.NA math.NA
Comments: 31 pages, 8 figures, submitted to TOMPECS
ACM-class: F.2.1; G.3; K.3.2
\\
 We present BLINQ, a new model-based algorithm that learns the Whittle indices
of an indexable, communicating and unichain Markov Decision Process (MDP). Our
approach relies on building an empirical estimate of the MDP and then computing
its Whittle indices using an extended version of a state-of-the-art existing
algorithm. We provide a proof of convergence to the Whittle indices we want to
learn as well as a bound on the time needed to learn them with arbitrary
precision. Moreover, we investigate its computational complexity. Our numerical
experiments suggest that BLINQ significantly outperforms existing Q-learning
approaches in terms of the number of samples needed to get an accurate
approximation. In addition, it has a total computational cost even lower than
Q-learning for any reasonably high number of samples. These observations
persist even when the Q-learning algorithms are speeded up using pre-trained
neural networks to predict Q-values.
\\ ( https://arxiv.org/abs/2511.20397 ,  497kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20406
Date: Tue, 25 Nov 2025 15:34:46 GMT   (102kb)

Title: Short-Range Oversquashing
Authors: Yaaqov Mishayev, Yonatan Sverdlov, Tal Amir, Nadav Dym
Categories: cs.LG cs.AI
Comments: Accepted to Learning on Graphs (LoG) 2025. Version identical to the
 camera-ready paper
\\
 Message Passing Neural Networks (MPNNs) are widely used for learning on
graphs, but their ability to process long-range information is limited by the
phenomenon of oversquashing. This limitation has led some researchers to
advocate Graph Transformers as a better alternative, whereas others suggest
that it can be mitigated within the MPNN framework, using virtual nodes or
other rewiring techniques.
 In this work, we demonstrate that oversquashing is not limited to long-range
tasks, but can also arise in short-range problems. This observation allows us
to disentangle two distinct mechanisms underlying oversquashing: (1) the
bottleneck phenomenon, which can arise even in low-range settings, and (2) the
vanishing gradient phenomenon, which is closely associated with long-range
tasks.
 We further show that the short-range bottleneck effect is not captured by
existing explanations for oversquashing, and that adding virtual nodes does not
resolve it. In contrast, transformers do succeed in such tasks, positioning
them as the more compelling solution to oversquashing, compared to specialized
MPNNs.
\\ ( https://arxiv.org/abs/2511.20406 ,  102kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20407
Date: Tue, 25 Nov 2025 15:34:59 GMT   (27kb)

Title: Tight Margin-Based Generalization Bounds for Voting Classifiers over
 Finite Hypothesis Sets
Authors: Kasper Green Larsen and Natascha Schalburg
Categories: cs.LG math.ST stat.TH
\\
 We prove the first margin-based generalization bound for voting classifiers,
that is asymptotically tight in the tradeoff between the size of the hypothesis
set, the margin, the fraction of training points with the given margin, the
number of training samples and the failure probability.
\\ ( https://arxiv.org/abs/2511.20407 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20445
Date: Tue, 25 Nov 2025 16:17:12 GMT   (1726kb)

Title: Diffusion for Fusion: Designing Stellarators with Generative AI
Authors: Misha Padidar, Teresa Huang, Andrew Giuliani, Marina Spivak
Categories: cs.LG physics.plasm-ph
\\
 Stellarators are a prospective class of fusion-based power plants that
confine a hot plasma with three-dimensional magnetic fields. Typically framed
as a PDE-constrained optimization problem, stellarator design is a
time-consuming process that can take hours to solve on a computing cluster.
Developing fast methods for designing stellarators is crucial for advancing
fusion research. Given the recent development of large datasets of optimized
stellarators, machine learning approaches have emerged as a potential
candidate. Motivated by this, we present an open inverse problem to the machine
learning community: to rapidly generate high-quality stellarator designs which
have a set of desirable characteristics. As a case study in the problem space,
we train a conditional diffusion model on data from the QUASR database to
generate quasisymmetric stellarator designs with desirable characteristics
(aspect ratio and mean rotational transform). The diffusion model is applied to
design stellarators with characteristics not seen during training. We provide
evaluation protocols and show that many of the generated stellarators exhibit
solid performance: less than 5% deviation from quasisymmetry and the target
characteristics. The modest deviation from quasisymmetry highlights an
opportunity to reach the sub 1% target. Beyond the case study, we share
multiple promising avenues for generative modeling to advance stellarator
design.
\\ ( https://arxiv.org/abs/2511.20445 ,  1726kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20456
Date: Tue, 25 Nov 2025 16:24:29 GMT   (3326kb)

Title: Towards Trustworthy Wi-Fi Sensing: Systematic Evaluation of Deep
 Learning Model Robustness to Adversarial Attacks
Authors: Shreevanth Krishnaa Gopalakrishnan, Stephen Hailes
Categories: cs.LG
Comments: 19 pages, 8 figures, 7 tables
\\
 Machine learning has become integral to Channel State Information (CSI)-based
human sensing systems and is expected to power applications such as device-free
activity recognition and identity detection in future cellular and Wi-Fi
generations. However, these systems rely on models whose decisions can be
subtly perturbed, raising concerns for security and reliability in ubiquitous
sensing. Quantifying and understanding the robustness of such models, defined
as their ability to maintain accurate predictions under adversarial
perturbations, is therefore critical before wireless sensing can be safely
deployed in real-world environments.
 This work presents a systematic evaluation of the robustness of CSI deep
learning models under diverse threat models (white-box, black-box/transfer, and
universal perturbations) and varying degrees of attack realism. We establish a
framework to compare compact temporal autoencoder models with larger deep
architectures across three public datasets, quantifying how model scale,
training regime, and physical constraints influence robustness. Our experiments
show that smaller models, while efficient and equally performant on clean data,
are markedly less robust. We further confirm that physically realizable
signal-space perturbations, designed to be feasible in real wireless channels,
significantly reduce attack success compared to unconstrained feature-space
attacks. Adversarial training mitigates these vulnerabilities, improving mean
robust accuracy with only moderate degradation in clean performance across both
model classes. As wireless sensing advances towards reliable, cross-domain
operation, these findings provide quantitative baselines for robustness
estimation and inform design principles for secure and trustworthy
human-centered sensing systems.
\\ ( https://arxiv.org/abs/2511.20456 ,  3326kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20478
Date: Tue, 25 Nov 2025 16:41:25 GMT   (2444kb)

Title: NVIDIA Nemotron Parse 1.1
Authors: Kateryna Chumachenko, Amala Sanjay Deshmukh, Jarno Seppanen, Ilia
 Karmanov, Chia-Chih Chen, Lukas Voegtle, Philipp Fischer, Marek Wawrzos,
 Saeid Motiian, Roman Ageev, Kedi Wu, Alexandre Milesi, Maryam Moosaei,
 Krzysztof Pawelec, Padmavathy Subramanian, Mehrzad Samadi, Xin Yu, Celina
 Dear, Sarah Stoddard, Jenna Diamond, Jesse Oliver, Leanna Chraghchian,
 Patrick Skelly, Tom Balough, Yao Xu, Jane Polak Scowcroft, Daniel Korzekwa,
 Darragh Hanley, Sandip Bhaskar, Timo Roman, Karan Sapra, Andrew Tao, Bryan
 Catanzaro
Categories: cs.LG
\\
 We introduce Nemotron-Parse-1.1, a lightweight document parsing and OCR model
that advances the capabilities of its predecessor, Nemoretriever-Parse-1.0.
Nemotron-Parse-1.1 delivers improved capabilities across general OCR, markdown
formatting, structured table parsing, and text extraction from pictures,
charts, and diagrams. It also supports a longer output sequence length for
visually dense documents. As with its predecessor, it extracts bounding boxes
of text segments, as well as corresponding semantic classes. Nemotron-Parse-1.1
follows an encoder-decoder architecture with 885M parameters, including a
compact 256M-parameter language decoder. It achieves competitive accuracy on
public benchmarks making it a strong lightweight OCR solution. We release the
model weights publicly on Huggingface, as well as an optimized NIM container,
along with a subset of the training data as part of the broader Nemotron-VLM-v2
dataset. Additionally, we release Nemotron-Parse-1.1-TC which operates on a
reduced vision token length, offering a 20% speed improvement with minimal
quality degradation.
\\ ( https://arxiv.org/abs/2511.20478 ,  2444kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20480
Date: Tue, 25 Nov 2025 16:42:12 GMT   (3319kb)

Title: Ranking-Enhanced Anomaly Detection Using Active Learning-Assisted
 Attention Adversarial Dual AutoEncoders
Authors: Sidahmed Benabderrahmane, James Cheney, Talal Rahwan
Categories: cs.LG cs.AI cs.CR cs.NE
\\
 Advanced Persistent Threats (APTs) pose a significant challenge in
cybersecurity due to their stealthy and long-term nature. Modern supervised
learning methods require extensive labeled data, which is often scarce in
real-world cybersecurity environments. In this paper, we propose an innovative
approach that leverages AutoEncoders for unsupervised anomaly detection,
augmented by active learning to iteratively improve the detection of APT
anomalies. By selectively querying an oracle for labels on uncertain or
ambiguous samples, we minimize labeling costs while improving detection rates,
enabling the model to improve its detection accuracy with minimal data while
reducing the need for extensive manual labeling. We provide a detailed
formulation of the proposed Attention Adversarial Dual AutoEncoder-based
anomaly detection framework and show how the active learning loop iteratively
enhances the model. The framework is evaluated on real-world imbalanced
provenance trace databases produced by the DARPA Transparent Computing program,
where APT-like attacks constitute as little as 0.004\% of the data. The
datasets span multiple operating systems, including Android, Linux, BSD, and
Windows, and cover two attack scenarios. The results have shown significant
improvements in detection rates during active learning and better performance
compared to other existing approaches.
\\ ( https://arxiv.org/abs/2511.20480 ,  3319kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20490
Date: Tue, 25 Nov 2025 16:56:25 GMT   (38071kb)

Title: MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in
 Oncology
Authors: Kiril Vasilev, Alexandre Misrahi, Eeshaan Jain, Phil F Cheng, Petros
 Liakopoulos, Olivier Michielin, Michael Moor, Charlotte Bunne
Categories: cs.LG cs.AI
Comments: Accepted to NeurIPS 2025
\\
 Multimodal Large Language Models (LLMs) hold promise for biomedical
reasoning, but current benchmarks fail to capture the complexity of real-world
clinical workflows. Existing evaluations primarily assess unimodal,
decontextualized question-answering, overlooking multi-agent decision-making
environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse
experts in oncology, where diagnostic and prognostic tasks require integrating
heterogeneous data and evolving insights over time. Current benchmarks lack
this longitudinal and multimodal complexity. We introduce MTBBench, an agentic
benchmark simulating MTB-style decision-making through clinically challenging,
multimodal, and longitudinal oncology questions. Ground truth annotations are
validated by clinicians via a co-developed app, ensuring clinical relevance. We
benchmark multiple open and closed-source LLMs and show that, even at scale,
they lack reliability -- frequently hallucinating, struggling with reasoning
from time-resolved data, and failing to reconcile conflicting evidence or
different modalities. To address these limitations, MTBBench goes beyond
benchmarking by providing an agentic framework with foundation model-based
tools that enhance multi-modal and longitudinal reasoning, leading to
task-level performance gains of up to 9.0% and 11.2%, respectively. Overall,
MTBBench offers a challenging and realistic testbed for advancing multimodal
LLM reasoning, reliability, and tool-use with a focus on MTB environments in
precision oncology.
\\ ( https://arxiv.org/abs/2511.20490 ,  38071kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20500
Date: Tue, 25 Nov 2025 17:07:41 GMT   (10229kb)

Title: From One Attack Domain to Another: Contrastive Transfer Learning with
 Siamese Networks for APT Detection
Authors: Sidahmed Benabderrahmane, Talal Rahwan
Categories: cs.LG cs.AI cs.CR cs.NE
\\
 Advanced Persistent Threats (APT) pose a major cybersecurity challenge due to
their stealth, persistence, and adaptability. Traditional machine learning
detectors struggle with class imbalance, high dimensional features, and scarce
real world traces. They often lack transferability-performing well in the
training domain but degrading in novel attack scenarios. We propose a hybrid
transfer framework that integrates Transfer Learning, Explainable AI (XAI),
contrastive learning, and Siamese networks to improve cross-domain
generalization. An attention-based autoencoder supports knowledge transfer
across domains, while Shapley Additive exPlanations (SHAP) select stable,
informative features to reduce dimensionality and computational cost. A Siamese
encoder trained with a contrastive objective aligns source and target
representations, increasing anomaly separability and mitigating feature drift.
We evaluate on real-world traces from the DARPA Transparent Computing (TC)
program and augment with synthetic attack scenarios to test robustness. Across
source to target transfers, the approach delivers improved detection scores
with classical and deep baselines, demonstrating a scalable, explainable, and
transferable solution for APT detection.
\\ ( https://arxiv.org/abs/2511.20500 ,  10229kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20509
Date: Tue, 25 Nov 2025 17:17:48 GMT   (121kb)

Title: DP-MicroAdam: Private and Frugal Algorithm for Training and Fine-tuning
Authors: Mihaela Hudi\c{s}teanu, Edwige Cyffers, Nikita P. Kalinin
Categories: cs.LG
\\
 Adaptive optimizers are the de facto standard in non-private training as they
often enable faster convergence and improved performance. In contrast,
differentially private (DP) training is still predominantly performed with
DP-SGD, typically requiring extensive compute and hyperparameter tuning. We
propose DP-MicroAdam, a memory-efficient and sparsity-aware adaptive DP
optimizer. We prove that DP-MicroAdam converges in stochastic non-convex
optimization at the optimal $\mathcal{O}(1/\sqrt{T})$ rate, up to
privacy-dependent constants. Empirically, DP-MicroAdam outperforms existing
adaptive DP optimizers and achieves competitive or superior accuracy compared
to DP-SGD across a range of benchmarks, including CIFAR-10, large-scale
ImageNet training, and private fine-tuning of pretrained transformers. These
results demonstrate that adaptive optimization can improve both performance and
stability under differential privacy.
\\ ( https://arxiv.org/abs/2511.20509 ,  121kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20516
Date: Tue, 25 Nov 2025 17:20:40 GMT   (98kb)

Title: Adam Simplified: Bias Correction Simplified
Authors: Sam Laing, Antonio Orvieto
Categories: cs.LG
\\
 The Adam optimizer is a cornerstone of modern deep learning, yet the
empirical necessity of each of its individual components is often taken for
granted. This paper presents a focused investigation into the role of
bias-correction, a feature whose contribution remains poorly understood.
Through a series of systematic ablations on vision and language modelling
tasks, we demonstrate that the conventional wisdom surrounding bias correction
is misleading. In particular, we demonstrate that in the optimal
hyper-parameter configuration, the inclusion of bias correction leads to no
improvement in final test performance. Moreover, unless appropriate learning
rate scheduling is implemented, the inclusion of bias correction can sometimes
be detrimental to performance. We further reinterpret bias correction as a form
of implicit learning rate scheduling whose behaviour is strongly dependent on
the choice of smoothing hyper-parameters $\beta_1, \beta_2 \in [0,1)$. Our
findings challenge the universal inclusion of this component.
\\ ( https://arxiv.org/abs/2511.20516 ,  98kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20543
Date: Tue, 25 Nov 2025 17:44:28 GMT   (2626kb)

Title: Feature-Modulated UFNO for Improved Prediction of Multiphase Flow in
 Porous Media
Authors: Alhasan Abdellatif, Hannah P. Menke, Ahmed H. Elsheikh, Florian
 Doster, and Kamaljit Singh
Categories: cs.LG
\\
 The UNet-enhanced Fourier Neural Operator (UFNO) extends the Fourier Neural
Operator (FNO) by incorporating a parallel UNet pathway, enabling the retention
of both high- and low-frequency components. While UFNO improves predictive
accuracy over FNO, it inefficiently treats scalar inputs (e.g., temperature,
injection rate) as spatially distributed fields by duplicating their values
across the domain. This forces the model to process redundant constant signals
within the frequency domain. Additionally, its standard loss function does not
account for spatial variations in error sensitivity, limiting performance in
regions of high physical importance. We introduce UFNO-FiLM, an enhanced
architecture that incorporates two key innovations. First, we decouple scalar
inputs from spatial features using a Feature-wise Linear Modulation (FiLM)
layer, allowing the model to modulate spatial feature maps without introducing
constant signals into the Fourier transform. Second, we employ a spatially
weighted loss function that prioritizes learning in critical regions. Our
experiments on subsurface multiphase flow demonstrate a 21\% reduction in gas
saturation Mean Absolute Error (MAE) compared to UFNO, highlighting the
effectiveness of our approach in improving predictive accuracy.
\\ ( https://arxiv.org/abs/2511.20543 ,  2626kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20564
Date: Tue, 25 Nov 2025 17:59:22 GMT   (525kb)

Title: E2E-GRec: An End-to-End Joint Training Framework for Graph Neural
 Networks and Recommender Systems
Authors: Rui Xue, Shichao Zhu, Liang Qin, Guangmou Pan, Yang Song, Tianfu Wu
Categories: cs.LG
\\
 Graph Neural Networks (GNNs) have emerged as powerful tools for modeling
graph-structured data and have been widely used in recommender systems, such as
for capturing complex user-item and item-item relations. However, most
industrial deployments adopt a two-stage pipeline: GNNs are first pre-trained
offline to generate node embeddings, which are then used as static features for
downstream recommender systems. This decoupled paradigm leads to two key
limitations: (1) high computational overhead, since large-scale GNN inference
must be repeatedly executed to refresh embeddings; and (2) lack of joint
optimization, as the gradient from the recommender system cannot directly
influence the GNN learning process, causing the GNN to be suboptimally
informative for the recommendation task. In this paper, we propose E2E-GRec, a
novel end-to-end training framework that unifies GNN training with the
recommender system. Our framework is characterized by three key components: (i)
efficient subgraph sampling from a large-scale cross-domain heterogeneous graph
to ensure training scalability and efficiency; (ii) a Graph Feature
Auto-Encoder (GFAE) serving as an auxiliary self-supervised task to guide the
GNN to learn structurally meaningful embeddings; and (iii) a two-level feature
fusion mechanism combined with Gradnorm-based dynamic loss balancing, which
stabilizes graph-aware multi-task end-to-end training. Extensive offline
evaluations, online A/B tests (e.g., a +0.133% relative improvement in stay
duration, a 0.3171% reduction in the average number of videos a user skips) on
large-scale production data, together with theoretical analysis, demonstrate
that E2E-GRec consistently surpasses traditional approaches, yielding
significant gains across multiple recommendation metrics.
\\ ( https://arxiv.org/abs/2511.20564 ,  525kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20577
Date: Tue, 25 Nov 2025 18:09:42 GMT   (529kb)

Title: MSTN: Fast and Efficient Multivariate Time Series Model
Authors: Sumit S Shevtekar, Chandresh K Maurya, and Gourab Sil
Categories: cs.LG
Comments: 21 pages, 1 figure, 5 tables
MSC-class: 68T07 (Primary) 62M10, 68T05 (Secondary)
\\
 Real-world time-series data is highly non stationary and complex in dynamics
that operate across multiple timescales, ranging from fast, short-term changes
to slow, long-term trends. Most existing models rely on fixed-scale structural
priors, such as patch-based tokenization, fixed frequency transformations, or
frozen backbone architectures. This often leads to over-regularization of
temporal dynamics, which limits their ability to adaptively model the full
spectrum of temporal variations and impairs their performance on unpredictable,
Sudden, high-magnitude events. To address this, we introduce the Multi-scale
Temporal Network (MSTN), a novel deep learning architecture founded on a
hierarchical multi-scale and sequence modeling principle. The MSTN framework
integrates: (i) a multi-scale convolutional encoder that constructs a
hierarchical feature pyramid for local patterns (ii) a sequence modeling
component for long-range temporal dependencies. We empirically validate this
with BiLSTM and Transformer variants, establishing a flexible foundation for
future architectural advancements. and (iii) a gated fusion mechanism augmented
with squeeze-and-excitation (SE) and multi-head temporal attention (MHTA) for
dynamic, context-aware feature integration. This design enables MSTN to
adaptively model temporal patterns from milliseconds to long-range dependencies
within a unified framework. Extensive evaluations across time-series
long-horizon forecasting, imputation, classification and generalizability study
demonstrate that MSTN achieves competitive state-of-the-art (SOTA) performance,
showing improvements over contemporary approaches including EMTSF, LLM4TS,
HiMTM, TIME-LLM, MTST, SOFTS, iTransformer, TimesNet, and PatchTST. In total,
MSTN establishes new SOTA performance on 24 of 32 benchmark datasets,
demonstrating its consistent performance across diverse temporal tasks.
\\ ( https://arxiv.org/abs/2511.20577 ,  529kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20584
Date: Tue, 25 Nov 2025 18:13:53 GMT   (136kb)

Title: A Tale of Two Geometries: Adaptive Optimizers and Non-Euclidean Descent
Authors: Shuo Xie, Tianhao Wang, Beining Wu, Zhiyuan Li
Categories: cs.LG
\\
 Adaptive optimizers can reduce to normalized steepest descent (NSD) when only
adapting to the current gradient, suggesting a close connection between the two
algorithmic families. A key distinction between their analyses, however, lies
in the geometries, e.g., smoothness notions, they rely on. In the convex
setting, adaptive optimizers are governed by a stronger adaptive smoothness
condition, while NSD relies on the standard notion of smoothness. We extend the
theory of adaptive smoothness to the nonconvex setting and show that it
precisely characterizes the convergence of adaptive optimizers. Moreover, we
establish that adaptive smoothness enables acceleration of adaptive optimizers
with Nesterov momentum in the convex setting, a guarantee unattainable under
standard smoothness for certain non-Euclidean geometry. We further develop an
analogous comparison for stochastic optimization by introducing adaptive
gradient variance, which parallels adaptive smoothness and leads to
dimension-free convergence guarantees that cannot be achieved under standard
gradient variance for certain non-Euclidean geometry.
\\ ( https://arxiv.org/abs/2511.20584 ,  136kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20587
Date: Tue, 25 Nov 2025 18:18:16 GMT   (15771kb)

Title: Anatomica: Localized Control over Geometric and Topological Properties
 for Anatomical Diffusion Models
Authors: Karim Kadry, Abdallah Abdelwahed, Shoaib Goraya, Ajay Manicka,
 Naravich Chutisilp, Farhad Nezami, Elazer Edelman
Categories: cs.LG
Comments: 8 pages, 10 figures
\\
 We present Anatomica: an inference-time framework for generating multi-class
anatomical voxel maps with localized geo-topological control. During
generation, we use cuboidal control domains of varying dimensionality,
location, and shape to slice out relevant substructures. These local
substructures are used to compute differentiable penalty functions that steer
the sample towards target constraints. We control geometric features such as
size, shape, and position through voxel-wise moments, while topological
features such as connected components, loops, and voids are enforced through
persistent homology. Lastly, we implement Anatomica for latent diffusion
models, where neural field decoders partially extract substructures, enabling
the efficient control of anatomical properties. Anatomica applies flexibly
across diverse anatomical systems, composing constraints to control complex
structures over arbitrary dimensions and coordinate systems, thereby enabling
the rational design of synthetic datasets for virtual trials or machine
learning workflows.
\\ ( https://arxiv.org/abs/2511.20587 ,  15771kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20591
Date: Tue, 25 Nov 2025 18:20:42 GMT   (7037kb)

Title: Attention Trajectories as a Diagnostic Axis for Deep Reinforcement
 Learning
Authors: Charlotte Beylier, Hannah Selder, Arthur Fleig, Simon M. Hofmann, Nico
 Scherf
Categories: cs.LG
\\
 The learning process of a reinforcement learning (RL) agent remains poorly
understood beyond the mathematical formulation of its learning algorithm. To
address this gap, we introduce attention-oriented metrics (ATOMs) to
investigate the development of an RL agent's attention during training. In a
controlled experiment, we tested ATOMs on three variations of a Pong game, each
designed to teach the agent distinct behaviours, complemented by a behavioural
assessment. ATOMs successfully delineate the attention patterns of an agent
trained on each game variation, and that these differences in attention
patterns translate into differences in the agent's behaviour. Through
continuous monitoring of ATOMs during training, we observed that the agent's
attention developed in phases, and that these phases were consistent across
game variations. Overall, we believe that ATOM could help improve our
understanding of the learning processes of RL agents and better understand the
relationship between attention and learning.
\\ ( https://arxiv.org/abs/2511.20591 ,  7037kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20592
Date: Tue, 25 Nov 2025 18:21:33 GMT   (2133kb)

Title: Latent Diffusion Inversion Requires Understanding the Latent Space
Authors: Mingxing Rao, Bowen Qu, Daniel Moyer
Categories: cs.LG cs.CV
Comments: 14 pages, 4 figures, 4 tables
\\
 The recovery of training data from generative models (``model inversion'')
has been extensively studied for diffusion models in the data domain. The
encoder/decoder pair and corresponding latent codes have largely been ignored
by inversion techniques applied to latent space generative models, e.g., Latent
Diffusion models (LDMs). In this work we describe two key findings: (1) The
diffusion model exhibits non-uniform memorization across latent codes, tending
to overfit samples located in high-distortion regions of the decoder pullback
metric. (2) Even within a single latent code, different dimensions contribute
unequally to memorization. We introduce a principled method to rank latent
dimensions by their per-dimensional contribution to the decoder pullback
metric, identifying those most responsible for memorization. Empirically,
removing less-memorizing dimensions when computing attack statistics for
score-based membership inference attacker significantly improves performance,
with average AUROC gains of 2.7\% and substantial increases in TPR@1\%FPR
(6.42\%) across diverse datasets including CIFAR-10, CelebA, ImageNet-1K,
Pok\'emon, MS-COCO, and Flickr. This indicates stronger confidence in
identifying members under extremely low false-positive tolerance. Our results
highlight the overlooked influence of the auto-encoder geometry on LDM
memorization and provide a new perspective for analyzing privacy risks in
diffusion-based generative models.
\\ ( https://arxiv.org/abs/2511.20592 ,  2133kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20597
Date: Tue, 25 Nov 2025 18:28:35 GMT   (1449kb)

Title: BrowseSafe: Understanding and Preventing Prompt Injection Within AI
 Browser Agents
Authors: Kaiyuan Zhang, Mark Tenenholtz, Kyle Polley, Jerry Ma, Denis Yarats,
 Ninghui Li
Categories: cs.LG cs.AI cs.CR
\\
 The integration of artificial intelligence (AI) agents into web browsers
introduces security challenges that go beyond traditional web application
threat models. Prior work has identified prompt injection as a new attack
vector for web agents, yet the resulting impact within real-world environments
remains insufficiently understood.
 In this work, we examine the landscape of prompt injection attacks and
synthesize a benchmark of attacks embedded in realistic HTML payloads. Our
benchmark goes beyond prior work by emphasizing injections that can influence
real-world actions rather than mere text outputs, and by presenting attack
payloads with complexity and distractor frequency similar to what real-world
agents encounter. We leverage this benchmark to conduct a comprehensive
empirical evaluation of existing defenses, assessing their effectiveness across
a suite of frontier AI models. We propose a multi-layered defense strategy
comprising both architectural and model-based defenses to protect against
evolving prompt injection attacks. Our work offers a blueprint for designing
practical, secure web agents through a defense-in-depth approach.
\\ ( https://arxiv.org/abs/2511.20597 ,  1449kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20601
Date: Tue, 25 Nov 2025 18:30:55 GMT   (46kb)

Title: The Driver-Blindness Phenomenon: Why Deep Sequence Models Default to
 Autocorrelation in Blood Glucose Forecasting
Authors: Heman Shakeri
Categories: cs.LG cs.AI
Comments: 7 pages, 1 figure
\\
 Deep sequence models for blood glucose forecasting consistently fail to
leverage clinically informative drivers--insulin, meals, and activity--despite
well-understood physiological mechanisms. We term this Driver-Blindness and
formalize it via $\Delta_{\text{drivers}}$, the performance gain of
multivariate models over matched univariate baselines. Across the literature,
$\Delta_{\text{drivers}}$ is typically near zero. We attribute this to three
interacting factors: architectural biases favoring autocorrelation (C1), data
fidelity gaps that render drivers noisy and confounded (C2), and physiological
heterogeneity that undermines population-level models (C3). We synthesize
strategies that partially mitigate Driver-Blindness--including physiological
feature encoders, causal regularization, and personalization--and recommend
that future work routinely report $\Delta_{\text{drivers}}$ to prevent
driver-blind models from being considered state-of-the-art.
\\ ( https://arxiv.org/abs/2511.20601 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20605
Date: Tue, 25 Nov 2025 18:34:33 GMT   (307kb)

Title: How to Purchase Labels? A Cost-Effective Approach Using Active Learning
 Markets
Authors: Xiwen Huang and Pierre Pinson
Categories: cs.LG stat.ML
Comments: Submitted as a preprint. 34 pages, 14 figures, 4 tables
\\
 We introduce and analyse active learning markets as a way to purchase labels,
in situations where analysts aim to acquire additional data to improve model
fitting, or to better train models for predictive analytics applications. This
comes in contrast to the many proposals that already exist to purchase features
and examples. By originally formalising the market clearing as an optimisation
problem, we integrate budget constraints and improvement thresholds into the
label acquisition process. We focus on a single-buyer-multiple-seller setup and
propose the use of two active learning strategies (variance based and
query-by-committee based), paired with distinct pricing mechanisms. They are
compared to a benchmark random sampling approach. The proposed strategies are
validated on real-world datasets from two critical application domains: real
estate pricing and energy forecasting. Results demonstrate the robustness of
our approach, consistently achieving superior performance with fewer labels
acquired compared to conventional methods. Our proposal comprises an
easy-to-implement practical solution for optimising data acquisition in
resource-constrained environments.
\\ ( https://arxiv.org/abs/2511.20605 ,  307kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20609
Date: Tue, 25 Nov 2025 18:36:47 GMT   (1819kb)

Title: Adaptive Hopfield Network: Rethinking Similarities in Associative Memory
Authors: Shurong Wang, Yuqi Pan, Zhuoyang Shen, Meng Zhang, Hongwei Wang and
 Guoqi Li
Categories: cs.LG
\\
 Associative memory models are content-addressable memory systems fundamental
to biological intelligence and are notable for their high interpretability.
However, existing models evaluate the quality of retrieval based on proximity,
which cannot guarantee that the retrieved pattern has the strongest association
with the query, failing correctness. We reframe this problem by proposing that
a query is a generative variant of a stored memory pattern, and define a
variant distribution to model this subtle context-dependent generative process.
Consequently, correct retrieval should return the memory pattern with the
maximum a posteriori probability of being the query's origin. This perspective
reveals that an ideal similarity measure should approximate the likelihood of
each stored pattern generating the query in accordance with variant
distribution, which is impossible for fixed and pre-defined similarities used
by existing associative memories. To this end, we develop adaptive similarity,
a novel mechanism that learns to approximate this insightful but unknown
likelihood from samples drawn from context, aiming for correct retrieval. We
theoretically prove that our proposed adaptive similarity achieves optimal
correct retrieval under three canonical and widely applicable types of
variants: noisy, masked, and biased. We integrate this mechanism into a novel
adaptive Hopfield network (A-Hop), and empirical results show that it achieves
state-of-the-art performance across diverse tasks, including memory retrieval,
tabular classification, image classification, and multiple instance learning.
\\ ( https://arxiv.org/abs/2511.20609 ,  1819kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20612
Date: Tue, 25 Nov 2025 18:39:50 GMT   (33438kb)

Title: Sparse-to-Field Reconstruction via Stochastic Neural Dynamic Mode
 Decomposition
Authors: Yujin Kim and Sarah Dean
Categories: cs.LG cs.SY eess.SY
\\
 Many consequential real-world systems, like wind fields and ocean currents,
are dynamic and hard to model. Learning their governing dynamics remains a
central challenge in scientific machine learning. Dynamic Mode Decomposition
(DMD) provides a simple, data-driven approximation, but practical use is
limited by sparse/noisy observations from continuous fields, reliance on linear
approximations, and the lack of principled uncertainty quantification. To
address these issues, we introduce Stochastic NODE-DMD, a probabilistic
extension of DMD that models continuous-time, nonlinear dynamics while
remaining interpretable. Our approach enables continuous spatiotemporal
reconstruction at arbitrary coordinates and quantifies predictive uncertainty.
Across four benchmarks, a synthetic setting and three physics-based flows, it
surpasses a baseline in reconstruction accuracy when trained from only 10%
observation density. It further recovers the dynamical structure by aligning
learned modes and continuous-time eigenvalues with ground truth. Finally, on
datasets with multiple realizations, our method learns a calibrated
distribution over latent dynamics that preserves ensemble variability rather
than averaging across regimes. Our code is available at:
https://github.com/sedan-group/Stochastic-NODE-DMD
\\ ( https://arxiv.org/abs/2511.20612 ,  33438kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20613
Date: Tue, 25 Nov 2025 18:40:22 GMT   (312kb)

Title: Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding
 Tournament on Market-driven Strategic Planning
Authors: Panayiotis Danassis, Naman Goel
Categories: cs.LG cs.AI cs.MA
\\
 The rapid proliferation of Large Language Models (LLMs) has revolutionized
AI-assisted code generation. This rapid development of LLMs has outpaced our
ability to properly benchmark them. Prevailing benchmarks emphasize unit-test
pass rates and syntactic correctness. Such metrics understate the difficulty of
many real-world problems that require planning, optimization, and strategic
interaction. We introduce a multi-agent reasoning-driven benchmark based on a
real-world logistics optimization problem (Auction, Pickup, and Delivery
Problem) that couples competitive auctions with capacity-constrained routing.
The benchmark requires building agents that can (i) bid strategically under
uncertainty and (ii) optimize planners that deliver tasks while maximizing
profit. We evaluate 40 LLM-coded agents (by a wide range of state-of-the-art
LLMs under multiple prompting methodologies, including vibe coding) against 17
human-coded agents developed before the advent of LLMs. Our results over 12
double all-play-all tournaments and $\sim 40$k matches demonstrate (i) a clear
superiority of human(graduate students)-coded agents: the top 5 spots are
consistently won by human-coded agents, (ii) the majority of LLM-coded agents
(33 out of 40) are beaten by very simple baselines, and (iii) given the best
human solution as an input and prompted to improve upon, the best performing
LLM makes the solution significantly worse instead of improving it. Our results
highlight a gap in LLMs' ability to produce code that works competitively in
the real-world, and motivate new evaluations that emphasize reasoning-driven
code synthesis in real-world scenarios.
\\ ( https://arxiv.org/abs/2511.20613 ,  312kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20621
Date: Tue, 25 Nov 2025 18:44:22 GMT   (478kb)

Title: DiFR: Inference Verification Despite Nondeterminism
Authors: Adam Karvonen, Daniel Reuter, Roy Rinberg, Luke Marks, Adri\`a
 Garriga-Alonso, Keri Warr
Categories: cs.LG cs.AI
\\
 As demand for LLM inference grows, it is becoming increasingly important that
providers and their customers can verify that inference processes are performed
correctly, without errors or tampering. However, re-running the same inference
process twice often leads to different results due to benign numerical noise,
making it difficult to distinguish legitimate variation from actual problems.
To address this problem, we introduce Token-DiFR
(Token-Divergence-From-Reference), a method for verifying inference outputs by
comparing generated tokens against predictions made by a trusted reference
implementation conditioned on the same random seed. Sampling seed
synchronization tightly constrains valid outputs, leaving providers minimal
room to deviate from correct inference, which allows output tokens themselves
to serve as auditable evidence of correctness at zero additional cost to the
provider. Token-DiFR reliably identifies sampling errors, simulated bugs, and
model quantization, detecting 4-bit quantization with AUC $>$ 0.999 within 300
output tokens. For applications requiring sample-efficient forward-pass
verification, we additionally introduce Activation-DiFR, a scheme that uses
random orthogonal projections to compress activations into compact fingerprints
for subsequent verification. Activation-DiFR detects 4-bit quantization with
AUC $>$ 0.999 using just 2 output tokens, while reducing communication overhead
by 25-75% relative to existing methods. We release an open-source integration
with vLLM to accelerate practical deployment of verifiable inference.
\\ ( https://arxiv.org/abs/2511.20621 ,  478kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20626
Date: Tue, 25 Nov 2025 18:48:05 GMT   (459kb)

Title: ROOT: Robust Orthogonalized Optimizer for Neural Network Training
Authors: Wei He, Kai Han, Hang Zhou, Hanting Chen, Zhicheng Liu, Xinghao Chen,
 Yunhe Wang
Categories: cs.LG cs.AI
\\
 The optimization of large language models (LLMs) remains a critical
challenge, particularly as model scaling exacerbates sensitivity to algorithmic
imprecision and training instability. Recent advances in optimizers have
improved convergence efficiency through momentum orthogonalization, but suffer
from two key robustness limitations: dimensional fragility in orthogonalization
precision and vulnerability to outlier-induced noise. To address these
robustness challenges, we introduce ROOT, a Robust Orthogonalized Optimizer
that enhances training stability through dual robustness mechanisms. First, we
develop a dimension-robust orthogonalization scheme using adaptive Newton
iterations with fine-grained coefficients tailored to specific matrix sizes,
ensuring consistent precision across diverse architectural configurations.
Second, we introduce an optimization-robust framework via proximal optimization
that suppresses outlier noise while preserving meaningful gradient directions.
Extensive experiments demonstrate that ROOT achieves significantly improved
robustness, with faster convergence and superior final performance compared to
both Muon and Adam-based optimizers, particularly in noisy and non-convex
scenarios. Our work establishes a new paradigm for developing robust and
precise optimizers capable of handling the complexities of modern large-scale
model training. The code will be available at
https://github.com/huawei-noah/noah-research/tree/master/ROOT.
\\ ( https://arxiv.org/abs/2511.20626 ,  459kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20636
Date: Tue, 25 Nov 2025 18:55:12 GMT   (6362kb)

Title: Image2Gcode: Image-to-G-code Generation for Additive Manufacturing Using
 Diffusion-Transformer Model
Authors: Ziyue Wang, Yayati Jadhav, Peter Pak, and Amir Barati Farimani
Categories: cs.LG
\\
 Mechanical design and manufacturing workflows conventionally begin with
conceptual design, followed by the creation of a computer-aided design (CAD)
model and fabrication through material-extrusion (MEX) printing. This process
requires converting CAD geometry into machine-readable G-code through slicing
and path planning. While each step is well established, dependence on CAD
modeling remains a major bottleneck: constructing object-specific 3D geometry
is slow and poorly suited to rapid prototyping. Even minor design variations
typically necessitate manual updates in CAD software, making iteration
time-consuming and difficult to scale. To address this limitation, we introduce
Image2Gcode, an end-to-end data-driven framework that bypasses the CAD stage
and generates printer-ready G-code directly from images and part drawings.
Instead of relying on an explicit 3D model, a hand-drawn or captured 2D image
serves as the sole input. The framework first extracts slice-wise structural
cues from the image and then employs a denoising diffusion probabilistic model
(DDPM) over G-code sequences. Through iterative denoising, the model transforms
Gaussian noise into executable print-move trajectories with corresponding
extrusion parameters, establishing a direct mapping from visual input to native
toolpaths. By producing structured G-code directly from 2D imagery, Image2Gcode
eliminates the need for CAD or STL intermediates, lowering the entry barrier
for additive manufacturing and accelerating the design-to-fabrication cycle.
This approach supports on-demand prototyping from simple sketches or visual
references and integrates with upstream 2D-to-3D reconstruction modules to
enable an automated pipeline from concept to physical artifact. The result is a
flexible, computationally efficient framework that advances accessibility in
design iteration, repair workflows, and distributed manufacturing.
\\ ( https://arxiv.org/abs/2511.20636 ,  6362kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2511.19457 (*cross-listing*)
Date: Fri, 21 Nov 2025 09:45:28 GMT   (556kb)

Title: SparOA: Sparse and Operator-aware Hybrid Scheduling for Edge DNN
 Inference
Authors: Ziyang Zhang, Jie Liu, Luca Mottola
Categories: cs.DC cs.AI
Comments: 14 pages, 12 figures
\\
 The resource demands of deep neural network (DNN) models introduce
significant performance challenges, especially when deployed on
resource-constrained edge devices. Existing solutions like model compression
often sacrifice accuracy, while specialized hardware remains costly and
inflexible. Hybrid inference methods, however, typically overlook how operator
characteristics impact performance. In this work, we present SparOA, a CPU-GPU
hybrid inference framework, which leverages both sparsity and computational
intensity to optimize operator scheduling. SparOA embraces aforementioned
challenges through three key components: (1) a threshold predictor that
accurately determines optimal sparsity and computational intensity thresholds;
(2) a reinforcement learning-based scheduler that dynamically optimizes
resource allocation based on real-time hardware states; and (3) a hybrid
inference engine that enhances efficiency through asynchronous execution and
batch size optimization.Extensive results show that SparOA achieves an average
speedup of 1.22-1.31x compared to all baselines, and outperforms the CPU-Only
by up to 50.7x. Also, SparOA achieves optimal energy-per-inference, consuming
7\%-16\% less energy than the SOTA co-execution baseline.
\\ ( https://arxiv.org/abs/2511.19457 ,  556kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19460 (*cross-listing*)
Date: Fri, 21 Nov 2025 14:51:23 GMT   (2035kb)

Title: Systemic approach for modeling a generic smart grid
Authors: Sofiane Ben Amor, Guillaume Guerard, Loup-No\'e Levy
Categories: cs.DC cs.AI cs.SY eess.SY
Journal-ref: Proceedings of the 10th International Symposium on Information and
 Communication Technology 2019
DOI: 10.1145/3368926.3369665
\\
 Smart grid technological advances present a recent class of complex
interdisciplinary modeling and increasingly difficult simulation problems to
solve using traditional computational methods. To simulate a smart grid
requires a systemic approach to integrated modeling of power systems, energy
markets, demand-side management, and much other resources and assets that are
becoming part of the current paradigm of the power grid. This paper presents a
backbone model of a smart grid to test alternative scenarios for the grid. This
tool simulates disparate systems to validate assumptions before the human scale
model. Thanks to a distributed optimization of subsystems, the production and
consumption scheduling is achieved while maintaining flexibility and
scalability.
\\ ( https://arxiv.org/abs/2511.19460 ,  2035kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19464 (*cross-listing*)
Date: Fri, 21 Nov 2025 19:37:09 GMT   (271kb)

Title: Temperature in SLMs: Impact on Incident Categorization in On-Premises
 Environments
Authors: Marcio Pohlmann, Alex Severo, Geft\'e Almeida, Diego Kreutz, Tiago
 Heinrich, Louren\c{c}o Pereira
Categories: cs.DC cs.AI cs.CR cs.LG cs.PF
Comments: 5 pages, 3 figures, 2 tables, submitted to ERRC/WRSeg 2025
MSC-class: 68T01
ACM-class: I.2
\\
 SOCs and CSIRTs face increasing pressure to automate incident categorization,
yet the use of cloud-based LLMs introduces costs, latency, and confidentiality
risks. We investigate whether locally executed SLMs can meet this challenge. We
evaluated 21 models ranging from 1B to 20B parameters, varying the temperature
hyperparameter and measuring execution time and precision across two distinct
architectures. The results indicate that temperature has little influence on
performance, whereas the number of parameters and GPU capacity are decisive
factors.
\\ ( https://arxiv.org/abs/2511.19464 ,  271kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19471 (*cross-listing*)
Date: Sat, 22 Nov 2025 05:29:27 GMT   (1860kb)

Title: Not Quite Anything: Overcoming SAMs Limitations for 3D Medical Imaging
Authors: Keith Moore
Categories: eess.IV cs.AI cs.CV
Comments: Preprint; Paper accepted at AIAS 2025
\\
 Foundation segmentation models such as SAM and SAM-2 perform well on natural
images but struggle with brain MRIs where structures like the caudate and
thalamus lack sharp boundaries and have low contrast. Rather than fine tune
these models (for example MedSAM), we propose a compositional alternative where
the foundation model output is treated as an additional input channel and
passed alongside the MRI to highlight regions of interest.
 We generate SAM-2 prompts by using a lightweight 3D U-Net that was previously
trained on MRI segmentation. The U-Net may have been trained on a different
dataset, so its guesses are often imprecise but usually in the correct region.
The edges of the resulting foundation model guesses are smoothed to improve
alignment with the MRI. We also test prompt free segmentation using DINO
attention maps in the same framework.
 This has-a architecture avoids modifying foundation weights and adapts to
domain shift without retraining the foundation model. It reaches about 96
percent volume accuracy on basal ganglia segmentation, which is sufficient for
our study of longitudinal volume change. The approach is fast, label efficient,
and robust to out of distribution scans. We apply it to study inflammation
linked changes in sudden onset pediatric OCD.
\\ ( https://arxiv.org/abs/2511.19471 ,  1860kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19476 (*cross-listing*)
Date: Sat, 22 Nov 2025 09:24:57 GMT   (1699kb)

Title: FAST: Topology-Aware Frequency-Domain Distribution Matching for Coreset
 Selection
Authors: Jin Cui (1), Boran Zhao (2), Jiajun Xu (2), Jiaqi Guo (3), Shuo Guan
 (2), Pengju Ren (1) ((1) State Key Laboratory of Human-Machine Hybrid
 Augmented Intelligence, National Engineering Research Center for Visual
 Information and Applications, and Institute of Artificial Intelligence and
 Robotics, Xi'an Jiaotong University, (2) School of Software Engineering,
 Xi'an Jiaotong University, (3) School of Mathematical Sciences, Nankai
 University)
Categories: stat.ML cs.AI cs.LG
\\
 Coreset selection compresses large datasets into compact, representative
subsets, reducing the energy and computational burden of training deep neural
networks. Existing methods are either: (i) DNN-based, which are tied to
model-specific parameters and introduce architectural bias; or (ii) DNN-free,
which rely on heuristics lacking theoretical guarantees. Neither approach
explicitly constrains distributional equivalence, largely because continuous
distribution matching is considered inapplicable to discrete sampling.
Moreover, prevalent metrics (e.g., MSE, KL, MMD, CE) cannot accurately capture
higher-order moment discrepancies, leading to suboptimal coresets. In this
work, we propose FAST, the first DNN-free distribution-matching coreset
selection framework that formulates the coreset selection task as a
graph-constrained optimization problem grounded in spectral graph theory and
employs the Characteristic Function Distance (CFD) to capture full
distributional information in the frequency domain. We further discover that
naive CFD suffers from a "vanishing phase gradient" issue in medium and
high-frequency regions; to address this, we introduce an Attenuated
Phase-Decoupled CFD. Furthermore, for better convergence, we design a
Progressive Discrepancy-Aware Sampling strategy that progressively schedules
frequency selection from low to high, preserving global structure before
refining local details and enabling accurate matching with fewer frequencies
while avoiding overfitting. Extensive experiments demonstrate that FAST
significantly outperforms state-of-the-art coreset selection methods across all
evaluated benchmarks, achieving an average accuracy gain of 9.12%. Compared to
other baseline coreset methods, it reduces power consumption by 96.57% and
achieves a 2.2x average speedup, underscoring its high performance and energy
efficiency.
\\ ( https://arxiv.org/abs/2511.19476 ,  1699kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19482 (*cross-listing*)
Date: Sun, 23 Nov 2025 01:14:17 GMT   (4591kb)

Title: Human Experts' Evaluation of Generative AI for Contextualizing STEAM
 Education in the Global South
Authors: Matthew Nyaaba, Macharious Nabang, Patrick Kyeremeh, Ibrahim Nantomah,
 Collins Owusu-Fordjour, Martin Ako, Bismark Nyaaba Akanzire, Kassim Korah
 Nantom, Cecilia Issaka, Xiaoming Zhai
Categories: cs.CY cs.AI
\\
 This study investigates how human experts evaluate the capacity of Generative
AI (GenAI) to contextualize STEAM education in the Global South, with a focus
on Ghana. Using a convergent mixed-methods design, four STEAM specialists
assessed GenAI-generated lesson plans created with a customized Culturally
Responsive Lesson Planner (CRLP) and compared them to standardized lesson plans
from the Ghana National Council for Curriculum and Assessment (NaCCA).
Quantitative ratings were based on a validated 25-item Culturally Responsive
Pedagogy Rubric measuring bias awareness, cultural representation, contextual
relevance, linguistic responsiveness, and teacher agency. Qualitative
reflections provided additional insight into how GenAI handles cultural and
pedagogical appropriateness.
 Findings show that GenAI, when paired with the CRLP tool, can support
contextualized STEAM instruction by linking abstract curriculum standards to
learners' cultural knowledge, community practices, and everyday experiences.
Experts rated GenAI-assisted lessons as more culturally grounded and
pedagogically responsive than NaCCA plans, integrating Indigenous knowledge,
bilingual elements, and locally relevant examples. However, GenAI struggled to
represent Ghana's cultural pluralism, often offering surface-level references
to language, history, and identity. These weaknesses were most evident in
Mathematics and Computing, where cultural nuance was limited. The results
highlight the need for continued teacher mediation, community involvement, and
culturally attuned refinement of AI outputs. Future work should include
classroom trials, expanded expert participation, and model fine-tuning using
Indigenous language corpora to strengthen cultural fidelity in Global South
contexts.
\\ ( https://arxiv.org/abs/2511.19482 ,  4591kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19483 (*cross-listing*)
Date: Sun, 23 Nov 2025 03:59:14 GMT   (5611kb)

Title: Z-Space: A Multi-Agent Tool Orchestration Framework for Enterprise-Grade
 LLM Automation
Authors: Qingsong He, Jing Nan, Jiayu Jiao, Liangjie Tang, Xiaodong Xu,
 Mengmeng Sun, Qingyao Wang, Minghui Yan
Categories: cs.SE cs.AI
\\
 Large Language Models can break through knowledge and timeliness limitations
by invoking external tools within the Model Context Protocol framework to
achieve automated execution of complex tasks. However, with the rapid growth of
enterprise-scale MCP services, efficiently and accurately matching target
functionalities among thousands of heterogeneous tools has become a core
challenge restricting system practicality. Existing approaches generally rely
on full-prompt injection or static semantic retrieval, facing issues including
semantic disconnection between user queries and tool descriptions, context
inflation in LLM input, and high inference latency. To address these
challenges, this paper proposes Z-Space, a data-generation-oriented multi-agent
collaborative tool invocation framework Z-Space. The Z-Space framework
establishes a multi-agent collaborative architecture and tool filtering
algorithm: (1) A structured semantic understanding of user queries is achieved
through an intent parsing model; (2) A tool filtering module (FSWW) based on
fused subspace weighted algorithm realizes fine-grained semantic alignment
between intents and tools without parameter tuning; (3) An inference execution
agent is constructed to support dynamic planning and fault-tolerant execution
for multi-step tasks. This framework has been deployed in the Eleme platform's
technical division, serving large-scale test data generation scenarios across
multiple business units including Taotian, Gaode, and Hema. Production data
demonstrates that the system reduces average token consumption in tool
inference by 96.26\% while achieving a 92\% tool invocation accuracy rate,
significantly enhancing the efficiency and reliability of intelligent test data
generation systems.
\\ ( https://arxiv.org/abs/2511.19483 ,  5611kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19488 (*cross-listing*)
Date: Sun, 23 Nov 2025 07:18:57 GMT   (31kb)

Title: Building Resilient Information Ecosystems: Large LLM-Generated Dataset
 of Persuasion Attacks
Authors: Hsien-Te Kao, Aleksey Panasyuk, Peter Bautista, William Dupree,
 Gabriel Ganberg, Jeffrey M. Beaubien, Laura Cassani, Svitlana Volkova
Categories: cs.CY cs.AI
\\
 Organization's communication is essential for public trust, but the rise of
generative AI models has introduced significant challenges by generating
persuasive content that can form competing narratives with official messages
from government and commercial organizations at speed and scale. This has left
agencies in a reactive position, often unaware of how these models construct
their persuasive strategies, making it more difficult to sustain communication
effectiveness. In this paper, we introduce a large LLM-generated persuasion
attack dataset, which includes 134,136 attacks generated by GPT-4, Gemma 2, and
Llama 3.1 on agency news. These attacks span 23 persuasive techniques from
SemEval 2023 Task 3, directed toward 972 press releases from ten agencies. The
generated attacks come in two mediums, press release statements and social
media posts, covering both long-form and short-form communication strategies.
We analyzed the moral resonance of these persuasion attacks to understand their
attack vectors. GPT-4's attacks mainly focus on Care, with Authority and
Loyalty also playing a role. Gemma 2 emphasizes Care and Authority, while Llama
3.1 centers on Loyalty and Care. Analyzing LLM-generated persuasive attacks
across models will enable proactive defense, allow to create the reputation
armor for organizations, and propel the development of both effective and
resilient communications in the information ecosystem.
\\ ( https://arxiv.org/abs/2511.19488 ,  31kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19489 (*cross-listing*)
Date: Sun, 23 Nov 2025 08:20:01 GMT   (601kb)

Title: Evolution without an Oracle: Driving Effective Evolution with LLM Judges
Authors: Zhe Zhao, Yuheng Yang, Haibin Wen, Xiaojie Qiu, Zaixi Zhang, Qingfu
 Zhang
Categories: cs.SE cs.AI
Comments: 14 pages, 5 figures
\\
 The integration of Large Language Models (LLMs) with Evolutionary Computation
(EC) has unlocked new frontiers in scientific discovery but remains shackled by
a fundamental constraint: the reliance on an Oracle--an objective,
machine-computable fitness function. This paper breaks this barrier by asking:
Can evolution thrive in a purely subjective landscape governed solely by LLM
judges? We introduce MADE (Multi-Agent Decomposed Evolution), a framework that
tames the inherent noise of subjective evaluation through "Problem
Specification." By decomposing vague instructions into specific, verifiable
sub-requirements, MADE transforms high-variance LLM feedback into stable,
precise selection pressure. The results are transformative: across complex
benchmarks like DevAI and InfoBench, MADE outperforms strong baselines by over
50% in software requirement satisfaction (39.9% to 61.9%) and achieves a 95%
perfect pass rate on complex instruction following. This work validates a
fundamental paradigm shift: moving from optimizing "computable metrics" to
"describable qualities," thereby unlocking evolutionary optimization for the
vast open-ended domains where no ground truth exists.
\\ ( https://arxiv.org/abs/2511.19489 ,  601kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19492 (*cross-listing*)
Date: Sun, 23 Nov 2025 10:46:10 GMT   (2773kb)

Title: Forecasting AI Time Horizon Under Compute Slowdowns
Authors: Parker Whitfill, Ben Snodin, Joel Becker
Categories: cs.CY cs.AI
\\
 METR's time horizon metric has grown exponentially since 2019, along with
compute. However, it is unclear whether compute scaling will persist at current
rates through 2030, raising the question of how possible compute slowdowns
might impact AI agent capability forecasts. Given a model of time horizon as a
function of training compute and algorithms, along with a model of how compute
investment spills into algorithmic progress (which, notably, precludes the
possibility of a software-only singularity), and the empirical fact that both
time horizon and compute have grown at constant rates over 2019--2025, we
derive that time horizon growth must be proportional to compute growth. We
provide additional, albeit limited, experimental evidence consistent with this
theory. We use our model to project time horizon growth under OpenAI's compute
projection, finding substantial projected delays in some cases. For example,
1-month time horizons at $80\%$ reliability occur $7$ years later than simple
trend extrapolation suggests.
\\ ( https://arxiv.org/abs/2511.19492 ,  2773kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19500 (*cross-listing*)
Date: Sun, 23 Nov 2025 16:31:11 GMT   (2706kb)

Title: CycleChemist: A Dual-Pronged Machine Learning Framework for Organic
 Photovoltaic Discovery
Authors: Hou Hei Lam, Jiangjie Qiu, Xiuyuan Hu, Wentao Li, Fankun Zeng, Siwei
 Fu, Hao Zhang, Xiaonan Wang
Categories: cond-mat.mtrl-sci cs.AI cs.LG
\\
 Organic photovoltaic (OPV) materials offer a promising path toward
sustainable energy generation, but their development is limited by the
difficulty of identifying high performance donor and acceptor pairs with strong
power conversion efficiencies (PCEs). Existing design strategies typically
focus on either the donor or the acceptor alone, rather than using a unified
approach capable of modeling both components. In this work, we introduce a dual
machine learning framework for OPV discovery that combines predictive modeling
with generative molecular design. We present the Organic Photovoltaic Donor
Acceptor Dataset (OPV2D), the largest curated dataset of its kind, containing
2000 experimentally characterized donor acceptor pairs. Using this dataset, we
develop the Organic Photovoltaic Classifier (OPVC) to predict whether a
material exhibits OPV behavior, and a hierarchical graph neural network that
incorporates multi task learning and donor acceptor interaction modeling. This
framework includes the Molecular Orbital Energy Estimator (MOE2) for predicting
HOMO and LUMO energy levels, and the Photovoltaic Performance Predictor (P3)
for estimating PCE. In addition, we introduce the Material Generative
Pretrained Transformer (MatGPT) to produce synthetically accessible organic
semiconductors, guided by a reinforcement learning strategy with three
objective policy optimization. By linking molecular representation learning
with performance prediction, our framework advances data driven discovery of
high performance OPV materials.
\\ ( https://arxiv.org/abs/2511.19500 ,  2706kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19528 (*cross-listing*)
Date: Mon, 24 Nov 2025 07:54:49 GMT   (10382kb)

Title: Discover, Learn, and Reinforce: Scaling Vision-Language-Action
 Pretraining with Diverse RL-Generated Trajectories
Authors: Rushuai Yang, Zhiyuan Feng, Tianxiang Zhang, Kaixin Wang, Chuheng
 Zhang, Li Zhao, Xiu Su, Yi Chen, and Jiang Bian
Categories: cs.RO cs.AI
\\
 Scaling vision-language-action (VLA) model pre-training requires large
volumes of diverse, high-quality manipulation trajectories. Most current data
is obtained via human teleoperation, which is expensive and difficult to scale.
Reinforcement learning (RL) methods learn useful skills through autonomous
exploration, making them a viable approach for generating data. However,
standard RL training collapses to a narrow execution pattern, limiting its
utility for large-scale pre-training. We propose Discover, Lea rn and Reinforce
(DLR), an information-theoretic pattern discovery framework that generates
multiple distinct, high-success behavioral patterns for VLA pretraining.
Empirically, DLR generates a markedly more diverse trajectory corpus on LIBERO.
Specifically, it learns multiple distinct, high-success strategies for the same
task where standard RL discovers only one, and hence it covers substantially
broader regions of the state-action space. When adapted to unseen downstream
task suites, VLA models pretrained on our diverse RL data surpass counterparts
trained on equal-sized standard RL datasets. Moreover, DLR exhibits positive
data-scaling behavior that single-pattern RL lacks. These results position
multi-pattern RL as a practical, scalable data engine for embodied foundation
models.
\\ ( https://arxiv.org/abs/2511.19528 ,  10382kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19536 (*cross-listing*)
Date: Mon, 24 Nov 2025 10:14:14 GMT   (951kb)

Title: AttackPilot: Autonomous Inference Attacks Against ML Services With
 LLM-Based Agents
Authors: Yixin Wu and Rui Wen and Chi Cui and Michael Backes and Yang Zhang
Categories: cs.CR cs.AI
\\
 Inference attacks have been widely studied and offer a systematic risk
assessment of ML services; however, their implementation and the attack
parameters for optimal estimation are challenging for non-experts. The
emergence of advanced large language models presents a promising yet largely
unexplored opportunity to develop autonomous agents as inference attack
experts, helping address this challenge. In this paper, we propose AttackPilot,
an autonomous agent capable of independently conducting inference attacks
without human intervention. We evaluate it on 20 target services. The
evaluation shows that our agent, using GPT-4o, achieves a 100.0% task
completion rate and near-expert attack performance, with an average token cost
of only $0.627 per run. The agent can also be powered by many other
representative LLMs and can adaptively optimize its strategy under service
constraints. We further perform trace analysis, demonstrating that design
choices, such as a multi-agent framework and task-specific action spaces,
effectively mitigate errors such as bad plans, inability to follow
instructions, task context loss, and hallucinations. We anticipate that such
agents could empower non-expert ML service providers, auditors, or regulators
to systematically assess the risks of ML services without requiring deep domain
expertise.
\\ ( https://arxiv.org/abs/2511.19536 ,  951kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19550 (*cross-listing*)
Date: Mon, 24 Nov 2025 13:06:29 GMT   (97kb)

Title: The Semiotic Channel Principle: Measuring the Capacity for Meaning in
 LLM Communication
Authors: Davide Picca
Categories: cs.IT cs.AI math.IT
\\
 This paper proposes a novel semiotic framework for analyzing Large Language
Models (LLMs), conceptualizing them as stochastic semiotic engines whose
outputs demand active, asymmetric human interpretation. We formalize the
trade-off between expressive richness (semiotic breadth) and interpretive
stability (decipherability) using information-theoretic tools. Breadth is
quantified as source entropy, and decipherability as the mutual information
between messages and human interpretations. We introduce a generative
complexity parameter (lambda) that governs this trade-off, as both breadth and
decipherability are functions of lambda. The core trade-off is modeled as an
emergent property of their distinct responses to $\lambda$. We define a
semiotic channel, parameterized by audience and context, and posit a capacity
constraint on meaning transmission, operationally defined as the maximum
decipherability by optimizing lambda. This reframing shifts analysis from
opaque model internals to observable textual artifacts, enabling empirical
measurement of breadth and decipherability. We demonstrate the framework's
utility across four key applications: (i) model profiling; (ii) optimizing
prompt/context design; (iii) risk analysis based on ambiguity; and (iv)
adaptive semiotic systems. We conclude that this capacity-based semiotic
approach offers a rigorous, actionable toolkit for understanding, evaluating,
and designing LLM-mediated communication.
\\ ( https://arxiv.org/abs/2511.19550 ,  97kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19558 (*cross-listing*)
Date: Mon, 24 Nov 2025 14:46:20 GMT   (26729kb)

Title: SPQR: A Standardized Benchmark for Modern Safety Alignment Methods in
 Text-to-Image Diffusion Models
Authors: Mohammed Talha Alam, Nada Saadi, Fahad Shamshad, Nils Lukas, Karthik
 Nandakumar, Fahkri Karray, Samuele Poppi
Categories: cs.CR cs.AI cs.CV cs.LG
Comments: 20 pages, 8 figures, 10 tables
\\
 Text-to-image diffusion models can emit copyrighted, unsafe, or private
content. Safety alignment aims to suppress specific concepts, yet evaluations
seldom test whether safety persists under benign downstream fine-tuning
routinely applied after deployment (e.g., LoRA personalization, style/domain
adapters). We study the stability of current safety methods under benign
fine-tuning and observe frequent breakdowns. As true safety alignment must
withstand even benign post-deployment adaptations, we introduce the SPQR
benchmark (Safety-Prompt adherence-Quality-Robustness). SPQR is a single-scored
metric that provides a standardized and reproducible framework to evaluate how
well safety-aligned diffusion models preserve safety, utility, and robustness
under benign fine-tuning, by reporting a single leaderboard score to facilitate
comparisons. We conduct multilingual, domain-specific, and out-of-distribution
analyses, along with category-wise breakdowns, to identify when safety
alignment fails after benign fine-tuning, ultimately showcasing SPQR as a
concise yet comprehensive benchmark for T2I safety alignment techniques for T2I
models.
\\ ( https://arxiv.org/abs/2511.19558 ,  26729kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19562 (*cross-listing*)
Date: Mon, 24 Nov 2025 15:31:51 GMT   (1891kb)

Title: Trust-Based Social Learning for Communication (TSLEC) Protocol Evolution
 in Multi-Agent Reinforcement Learning
Authors: Abraham Itzhak Weinberg
Categories: cs.MA cs.AI
\\
 Emergent communication in multi-agent systems typically occurs through
independent learning, resulting in slow convergence and potentially suboptimal
protocols. We introduce TSLEC (Trust-Based Social Learning with Emergent
Communication), a framework where agents explicitly teach successful strategies
to peers, with knowledge transfer modulated by learned trust relationships.
Through experiments with 100 episodes across 30 random seeds, we demonstrate
that trust-based social learning reduces episodes-to-convergence by 23.9% (p <
0.001, Cohen's d = 1.98) compared to independent emergence, while producing
compositional protocols (C = 0.38) that remain robust under dynamic objectives
(Phi > 0.867 decoding accuracy). Trust scores strongly correlate with teaching
quality (r = 0.743, p < 0.001), enabling effective knowledge filtering. Our
results establish that explicit social learning fundamentally accelerates
emergent communication in multi-agent coordination.
\\ ( https://arxiv.org/abs/2511.19562 ,  1891kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19565 (*cross-listing*)
Date: Mon, 24 Nov 2025 15:49:06 GMT   (52kb)

Title: Deductive Systems for Logic Programs with Counting
Authors: Jorge Fandinno and Vladimir Lifschitz
Categories: cs.LO cs.AI
Comments: Under consideration in Theory and Practice of Logic Programming
 (TPLP)
\\
 In answer set programming, two groups of rules are considered strongly
equivalent if they have the same meaning in any context. Strong equivalence of
two programs can be sometimes established by deriving rules of each program
from rules of the other in an appropriate deductive system. This paper shows
how to extend this method of proving strong equivalence to programs containing
the counting aggregate.
\\ ( https://arxiv.org/abs/2511.19565 ,  52kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19580 (*cross-listing*)
Date: Mon, 24 Nov 2025 18:29:29 GMT   (2015kb)

Title: Towards Synergistic Teacher-AI Interactions with Generative Artificial
 Intelligence
Authors: Mutlu Cukurova, Wannapon Suraworachet, Qi Zhou, Sahan Bulathwela
Categories: cs.CY cs.AI cs.HC
Comments: 18 pages, 6 pages
\\
 Generative artificial intelligence (GenAI) is increasingly used in education,
posing significant challenges for teachers adapting to these changes. GenAI
offers unprecedented opportunities for accessibility, scalability and
productivity in educational tasks. However, the automation of teaching tasks
through GenAI raises concerns about reduced teacher agency, potential cognitive
atrophy, and the broader deprofessionalisation of teaching. Drawing findings
from prior literature on AI in Education, and refining through a recent
systematic literature review, this chapter presents a conceptualisation of five
levels of teacher-AI teaming: transactional, situational, operational, praxical
and synergistic teaming. The framework aims to capture the nuanced dynamics of
teacher-AI interactions, particularly with GenAI, that may lead to the
replacement, complementarity, or augmentation of teachers' competences and
professional practice. GenAI technological affordances required in supporting
teaming, along with empirical studies, are discussed. Drawing on empirical
observations, we outline a future vision that moves beyond individual teacher
agency toward collaborative decision-making between teachers and AI, in which
both agents engage in negotiation, constructive challenge, and co-reasoning
that enhance each other's capabilities and enable outcomes neither could
realise independently. Further discussion of socio-technical factors beyond
teacher-AI teaming is also included to streamline the synergy of teachers and
AI in education ethically and practically.
\\ ( https://arxiv.org/abs/2511.19580 ,  2015kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19644 (*cross-listing*)
Date: Mon, 24 Nov 2025 19:21:09 GMT   (352kb)

Title: IRSDA: An Agent-Orchestrated Framework for Enterprise Intrusion Response
Authors: Damodar Panigrahi, Raj Patel, Shaswata Mitra, Sudip Mittal, Shahram
 Rahimi
Categories: cs.CR cs.AI
Comments: 10 pages, 4 figures
\\
 Modern enterprise systems face escalating cyber threats that are increasingly
dynamic, distributed, and multi-stage in nature. Traditional intrusion
detection and response systems often rely on static rules and manual workflows,
which limit their ability to respond with the speed and precision required in
high-stakes environments. To address these challenges, we present the Intrusion
Response System Digital Assistant (IRSDA), an agent-based framework designed to
deliver autonomous and policy-compliant cyber defense. IRSDA combines
Self-Adaptive Autonomic Computing Systems (SA-ACS) with the Knowledge guided
Monitor, Analyze, Plan, and Execute (MAPE-K) loop to support real-time,
partition-aware decision-making across enterprise infrastructure.
 IRSDA incorporates a knowledge-driven architecture that integrates contextual
information with AI-based reasoning to support system-guided intrusion
response. The framework leverages retrieval mechanisms and structured
representations to inform decision-making while maintaining alignment with
operational policies. We assess the system using a representative real-world
microservices application, demonstrating its ability to automate containment,
enforce compliance, and provide traceable outputs for security analyst
interpretation. This work outlines a modular and agent-driven approach to cyber
defense that emphasizes explainability, system-state awareness, and operational
control in intrusion response.
\\ ( https://arxiv.org/abs/2511.19644 ,  352kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19647 (*cross-listing*)
Date: Mon, 24 Nov 2025 19:23:04 GMT   (9613kb)

Title: Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual
 Data Collection and Foundation Model Adaptation
Authors: Jennifer Grannen, Michelle Pan, Kenneth Llontop, Cherie Ho, Mark
 Zolotas, Jeannette Bohg, Dorsa Sadigh
Categories: cs.RO cs.AI
\\
 Foundation models (FM) have unlocked powerful zero-shot capabilities in
vision and language, yet their reliance on internet pretraining data leaves
them brittle in unstructured, real-world settings. The messy, real-world data
encountered during deployment (e.g. occluded or multilingual text) remains
massively underrepresented in existing corpora. Robots, as embodied agents, are
uniquely positioned to close this gap: they can act in physical environments to
collect large-scale, real-world data that enriches FM training with precisely
the examples current models lack. We introduce the Robot-Powered Data Flywheel,
a framework that transforms robots from FM consumers into data generators. By
deploying robots equipped with FMs in the wild, we enable a virtuous cycle:
robots perform useful tasks while collecting real-world data that improves both
domain-specific adaptation and domain-adjacent generalization. We instantiate
this framework with Scanford, a mobile manipulator deployed in the East Asia
Library for 2 weeks. Scanford autonomously scans shelves, identifies books
using a vision-language model (VLM), and leverages the library catalog to label
images without human annotation. This deployment both aids librarians and
produces a dataset to finetune the underlying VLM, improving performance on the
domain-specific in-the-wild library setting and on domain-adjacent multilingual
OCR benchmarks. Using data collected from 2103 shelves, Scanford improves VLM
performance on book identification from 32.0% to 71.8% and boosts
domain-adjacent multilingual OCR from 24.8% to 46.6% (English) and 30.8% to
38.0% (Chinese), while saving an ~18.7 hrs of human time. These results
highlight how robot-powered data flywheels can both reduce human effort in real
deployments and unlock new pathways for continually adapting FMs to the
messiness of reality. More details are at: https://scanford-robot.github.io
\\ ( https://arxiv.org/abs/2511.19647 ,  9613kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19649 (*cross-listing*)
Date: Mon, 24 Nov 2025 19:27:58 GMT   (1005kb)

Title: Synthetic Data: AI's New Weapon Against Android Malware
Authors: Angelo Gaspar Diniz Nogueira, Kayua Oleques Paim, Hendrio
 Bragan\c{c}a, Rodrigo Brand\~ao Mansilha, Diego Kreutz
Categories: cs.CR cs.AI cs.LG
Comments: 23 pages, 18 figures, 8 tables. Accepted for publication at the JBCS
MSC-class: 68T001
ACM-class: I.2
\\
 The ever-increasing number of Android devices and the accelerated evolution
of malware, reaching over 35 million samples by 2024, highlight the critical
importance of effective detection methods. Attackers are now using Artificial
Intelligence to create sophisticated malware variations that can easily evade
traditional detection techniques. Although machine learning has shown promise
in malware classification, its success relies heavily on the availability of
up-to-date, high-quality datasets. The scarcity and high cost of obtaining and
labeling real malware samples presents significant challenges in developing
robust detection models. In this paper, we propose MalSynGen, a Malware
Synthetic Data Generation methodology that uses a conditional Generative
Adversarial Network (cGAN) to generate synthetic tabular data. This data
preserves the statistical properties of real-world data and improves the
performance of Android malware classifiers. We evaluated the effectiveness of
this approach using various datasets and metrics that assess the fidelity of
the generated data, its utility in classification, and the computational
efficiency of the process. Our experiments demonstrate that MalSynGen can
generalize across different datasets, providing a viable solution to address
the issues of obsolescence and low quality data in malware detection.
\\ ( https://arxiv.org/abs/2511.19649 ,  1005kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19654 (*cross-listing*)
Date: Mon, 24 Nov 2025 19:37:13 GMT   (834kb)

Title: Accuracy and Efficiency Trade-Offs in LLM-Based Malware Detection and
 Explanation: A Comparative Study of Parameter Tuning vs. Full Fine-Tuning
Authors: Stephen C. Gravereaux and Sheikh Rabiul Islam
Categories: cs.CR cs.AI
Comments: Accepted in IEEE Big Data 2025
Journal-ref: IEEE Big Data 2025
\\
 This study examines whether Low-Rank Adaptation (LoRA) fine-tuned Large
Language Models (LLMs) can approximate the performance of fully fine-tuned
models in generating human-interpretable decisions and explanations for malware
classification. Achieving trustworthy malware detection, particularly when LLMs
are involved, remains a significant challenge. We developed an evaluation
framework using Bilingual Evaluation Understudy (BLEU), Recall-Oriented
Understudy for Gisting Evaluation (ROUGE), and Semantic Similarity Metrics to
benchmark explanation quality across five LoRA configurations and a fully
fine-tuned baseline. Results indicate that full fine-tuning achieves the
highest overall scores, with BLEU and ROUGE improvements of up to 10% over LoRA
variants. However, mid-range LoRA models deliver competitive performance
exceeding full fine-tuning on two metrics while reducing model size by
approximately 81% and training time by over 80% on a LoRA model with 15.5%
trainable parameters. These findings demonstrate that LoRA offers a practical
balance of interpretability and resource efficiency, enabling deployment in
resource-constrained environments without sacrificing explanation quality. By
providing feature-driven natural language explanations for malware
classifications, this approach enhances transparency, analyst confidence, and
operational scalability in malware detection systems.
\\ ( https://arxiv.org/abs/2511.19654 ,  834kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19699 (*cross-listing*)
Date: Mon, 24 Nov 2025 21:06:14 GMT   (65kb)

Title: A Layered Protocol Architecture for the Internet of Agents
Authors: Charles Fleming and Vijoy Pandey and Ramana Kompella and Luca
 Muscariello
Categories: cs.NI cs.AI cs.MA
\\
 Large Language Models (LLMs) have demonstrated remarkable performance
improvements and the ability to learn domain-specific languages (DSLs),
including APIs and tool interfaces. This capability has enabled the creation of
AI agents that can perform preliminary computations and act through tool
calling, now being standardized via protocols like MCP. However, LLMs face
fundamental limitations: their context windows cannot grow indefinitely,
constraining their memory and computational capacity. Agent collaboration
emerges as essential for solving increasingly complex problems, mirroring how
computational systems rely on different types of memory to scale. The "Internet
of Agents" (IoA) represents the communication stack that enables agents to
scale by distributing computation across collaborating entities.
 Current network architectural stacks (OSI and TCP/IP) were designed for data
delivery between hosts and processes, not for agent collaboration with semantic
understanding. To address this gap, we propose two new layers: an \textbf{Agent
Communication Layer (L8)} and an \textbf{Agent Semantic Negotiation Layer
(L9)}. L8 formalizes the \textit{structure} of communication, standardizing
message envelopes, speech-act performatives (e.g., REQUEST, INFORM), and
interaction patterns (e.g., request-reply, publish-subscribe), building on
protocols like MCP. L9, which does not exist today, formalizes the
\textit{meaning} of communication, enabling agents to discover, negotiate, and
lock a "Shared Context" -- a formal schema defining the concepts, tasks, and
parameters relevant to their interaction. Together, these layers provide the
foundation for scalable, distributed agent collaboration, enabling the next
generation of multi-agentic systems.
\\ ( https://arxiv.org/abs/2511.19699 ,  65kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19703 (*cross-listing*)
Date: Mon, 24 Nov 2025 21:09:42 GMT   (30kb)

Title: The Alexander-Hirschowitz theorem for neurovarieties
Authors: A. Massarenti, M. Mella
Categories: math.AG cs.AI cs.LG math.AC
Comments: 21 pages
MSC-class: Primary 14N07, Secondary 14N05, 14N15
\\
 We study neurovarieties for polynomial neural networks and fully characterize
when they attain the expected dimension in the single-output case. As
consequences, we establish non-defectiveness and global identifiability for
multi-output architectures.
\\ ( https://arxiv.org/abs/2511.19703 ,  30kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19711 (*cross-listing*)
Date: Mon, 24 Nov 2025 21:21:55 GMT   (492kb)

Title: CrypTorch: PyTorch-based Auto-tuning Compiler for Machine Learning with
 Multi-party Computation
Authors: Jinyu Liu, Gang Tan, and Kiwan Maeng
Categories: cs.CR cs.AI cs.PL
Comments: 28 pages, 17 figures. Submitted to PLDI 2026
\\
 Machine learning (ML) involves private data and proprietary model parameters.
MPC-based ML allows multiple parties to collaboratively run an ML workload
without sharing their private data or model parameters using multi-party
computing (MPC). Because MPC cannot natively run ML operations such as Softmax
or GELU, existing frameworks use different approximations. Our study shows
that, on a well-optimized framework, these approximations often become the
dominating bottleneck. Popular approximations are often insufficiently accurate
or unnecessarily slow, and these issues are hard to identify and fix in
existing frameworks. To tackle this issue, we propose a compiler for MPC-based
ML, CrypTorch. CrypTorch disentangles these approximations with the rest of the
MPC runtime, allows easily adding new approximations through its programming
interface, and automatically selects approximations to maximize both
performance and accuracy. Built as an extension to PyTorch 2's compiler, we
show that CrypTorch's auto-tuning alone provides 1.20--1.7$\times$ immediate
speedup without sacrificing accuracy, and 1.31--1.8$\times$ speedup when some
accuracy degradation is allowed, compared to our well-optimized baseline.
Combined with better engineering and adoption of state-of-the-art practices,
the entire framework brings 3.22--8.6$\times$ end-to-end speedup compared to
the popular framework, CrypTen.
\\ ( https://arxiv.org/abs/2511.19711 ,  492kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19726 (*cross-listing*)
Date: Mon, 24 Nov 2025 21:41:45 GMT   (28kb)

Title: An Adaptive, Data-Integrated Agent-Based Modeling Framework for
 Explainable and Contestable Policy Design
Authors: Roberto Garrone
Categories: cs.MA cs.AI cs.LG cs.SY eess.SY
Comments: 27 pages, 2 case studies (emissions and smart grids). Preprint
 prepared during the author's PhD research at the Open University of Cyprus
 and the University of Milano-Bicocca. Introduces a unified framework for
 adaptive multi-agent learning with information-theoretic, causal, and
 clustering diagnostics
MSC-class: 90C90
ACM-class: I.6.3; I.2.11; J.4
\\
 Multi-agent systems often operate under feedback, adaptation, and
non-stationarity, yet many simulation studies retain static decision rules and
fixed control parameters. This paper introduces a general adaptive multi-agent
learning framework that integrates: (i) four dynamic regimes distinguishing
static versus adaptive agents and fixed versus adaptive system parameters; (ii)
information-theoretic diagnostics (entropy rate, statistical complexity, and
predictive information) to assess predictability and structure; (iii)
structural causal models for explicit intervention semantics; (iv) procedures
for generating agent-level priors from aggregate or sample data; and (v)
unsupervised methods for identifying emergent behavioral regimes. The framework
offers a domain-neutral architecture for analyzing how learning agents and
adaptive controls jointly shape system trajectories, enabling systematic
comparison of stability, performance, and interpretability across
non-equilibrium, oscillatory, or drifting dynamics. Mathematical definitions,
computational operators, and an experimental design template are provided,
yielding a structured methodology for developing explainable and contestable
multi-agent decision processes.
\\ ( https://arxiv.org/abs/2511.19726 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19727 (*cross-listing*)
Date: Mon, 24 Nov 2025 21:44:33 GMT   (712kb)

Title: Prompt Fencing: A Cryptographic Approach to Establishing Security
 Boundaries in Large Language Model Prompts
Authors: Steven Peh
Categories: cs.CR cs.AI
Comments: 44 pages, 1 figure
ACM-class: I.2.7; D.2.11
\\
 Large Language Models (LLMs) remain vulnerable to prompt injection attacks,
representing the most significant security threat in production deployments. We
present Prompt Fencing, a novel architectural approach that applies
cryptographic authentication and data architecture principles to establish
explicit security boundaries within LLM prompts. Our approach decorates prompt
segments with cryptographically signed metadata including trust ratings and
content types, enabling LLMs to distinguish between trusted instructions and
untrusted content. While current LLMs lack native fence awareness, we
demonstrate that simulated awareness through prompt instructions achieved
complete prevention of injection attacks in our experiments, reducing success
rates from 86.7% (260/300 successful attacks) to 0% (0/300 successful attacks)
across 300 test cases with two leading LLM providers. We implement a
proof-of-concept fence generation and verification pipeline with a total
overhead of 0.224 seconds (0.130s for fence generation, 0.094s for validation)
across 100 samples. Our approach is platform-agnostic and can be incrementally
deployed as a security layer above existing LLM infrastructure, with the
expectation that future models will be trained with native fence awareness for
optimal security.
\\ ( https://arxiv.org/abs/2511.19727 ,  712kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19830 (*cross-listing*)
Date: Tue, 25 Nov 2025 01:41:49 GMT   (1457kb)

Title: Beyond Relational: Semantic-Aware Multi-Modal Analytics with LLM-Native
 Query Optimization
Authors: Junhao Zhu, Lu Chen, Xiangyu Ke, Ziquan Fang, Tianyi Li, Yunjun Gao,
 Christian S. Jensen
Categories: cs.DB cs.AI
\\
 Multi-modal analytical processing has the potential to transform applications
in e-commerce, healthcare, entertainment, and beyond. However, real-world
adoption remains elusive due to the limited ability of traditional relational
query operators to capture query semantics. The emergence of foundation models,
particularly the large language models (LLMs), opens up new opportunities to
develop flexible, semantic-aware data analytics systems that transcend the
relational paradigm.
 We present Nirvana, a multi-modal data analytics framework that incorporates
programmable semantic operators while leveraging both logical and physical
query optimization strategies, tailored for LLM-driven semantic query
processing. Nirvana addresses two key challenges. First, it features an agentic
logical optimizer that uses natural language-specified transformation rules and
random-walk-based search to explore vast spaces of semantically equivalent
query plans -- far beyond the capabilities of conventional optimizers. Second,
it introduces a cost-aware physical optimizer that selects the most effective
LLM backend for each operator using a novel improvement-score metric. To
further enhance efficiency, Nirvana incorporates computation reuse and
evaluation pushdown techniques guided by model capability hypotheses.
Experimental evaluations on three real-world benchmarks demonstrate that
Nirvana is able to reduce end-to-end runtime by 10%--85% and reduces system
processing costs by 76% on average, outperforming state-of-the-art systems at
both efficiency and scalability.
\\ ( https://arxiv.org/abs/2511.19830 ,  1457kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19874 (*cross-listing*)
Date: Tue, 25 Nov 2025 03:33:04 GMT   (60kb)

Title: Cross-LLM Generalization of Behavioral Backdoor Detection in AI Agent
 Supply Chains
Authors: Arun Chowdary Sanna
Categories: cs.CR cs.AI cs.LG
Comments: 10 pages, 2 figures, 8 tables. Evaluation across 6 production LLMs
 with 1,198 traces
ACM-class: K.6.5; I.2.6
\\
 As AI agents become integral to enterprise workflows, their reliance on
shared tool libraries and pre-trained components creates significant supply
chain vulnerabilities. While previous work has demonstrated behavioral backdoor
detection within individual LLM architectures, the critical question of
cross-LLM generalization remains unexplored, a gap with serious implications
for organizations deploying multiple AI systems. We present the first
systematic study of cross-LLM behavioral backdoor detection, evaluating
generalization across six production LLMs (GPT-5.1, Claude Sonnet 4.5, Grok
4.1, Llama 4 Maverick, GPT-OSS 120B, and DeepSeek Chat V3.1). Through 1,198
execution traces and 36 cross-model experiments, we quantify a critical
finding: single-model detectors achieve 92.7% accuracy within their training
distribution but only 49.2% across different LLMs, a 43.4 percentage point
generalization gap equivalent to random guessing. Our analysis reveals that
this gap stems from model-specific behavioral signatures, particularly in
temporal features (coefficient of variation > 0.8), while structural features
remain stable across architectures. We show that model-aware detection
incorporating model identity as an additional feature achieves 90.6% accuracy
universally across all evaluated models. We release our multi-LLM trace dataset
and detection framework to enable reproducible research.
\\ ( https://arxiv.org/abs/2511.19874 ,  60kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19875 (*cross-listing*)
Date: Tue, 25 Nov 2025 03:33:57 GMT   (2290kb)

Title: CodeFuse-CommitEval: Towards Benchmarking LLM's Power on Commit Message
 and Code Change Inconsistency Detection
Authors: Qingyu Zhang and Puzhuo Liu and Peng Di and Chenxiong Qian
Categories: cs.SE cs.AI
\\
 Version control relies on commit messages to convey the rationale for code
changes, but these messages are often low quality and, more critically,
inconsistent with their diffs-known as message-code inconsistency (MCI). MCIs
mislead reviewers, hinder maintenance, contaminate research datasets, and may
obscure security patches. Yet, no dedicated benchmark exists to evaluate models
for MCI detection. We introduce CODEFUSE-COMMITEVAL, the first benchmark
designed for MCI detection using large language models (LLMs). Built on the
ApacheCM dataset for diversity and quality, we generate seven types of
inconsistent messages through rule-guided mutations of originally consistent
commits and apply two-fold validation to verify both positive and negative
samples. Using this labeled dataset of message-diff pairs, we evaluate six
state-of-the-art open-source LLMs under a vanilla setting and with three
augmentation strategies: few-shot prompting, chain-of-thought, and extended
context. Results show models detect inconsistent commits more reliably than
consistent ones (average Recall 85.95%, Precision 80.28%, Specificity 63.8%);
gpt-oss-20B performs best overall but uses over twice the tokens of others.
Augmentation effects vary: adjacent context helps larger models but adds noise
for smaller ones; few-shot improves accuracy and reduces token use, yet
increases universally incorrect predictions; chain-of-thought boosts precision
and specificity at the cost of recall and higher token consumption. Type-wise
analysis reveals higher detectability for component, file-path, and operation
inconsistencies, but lower accuracy and higher token cost for intent-level
"purpose" inconsistencies. CODEFUSE-COMMITEVAL provides a rigorous foundation
for measuring, comparing, and advancing MCI detection, highlighting the need
for richer context and balanced data to capture high-level semantic gaps.
\\ ( https://arxiv.org/abs/2511.19875 ,  2290kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19902 (*cross-listing*)
Date: Tue, 25 Nov 2025 04:19:16 GMT   (658kb)

Title: Zero-Knowledge Proof Based Verifiable Inference of Models
Authors: Yunxiao Wang
Categories: cs.CR cs.AI
\\
 Recent advances in artificial intelligence (AI), particularly deep learning,
have led to widespread adoption across various applications. Yet, a fundamental
challenge persists: how can we verify the correctness of AI model inference
when model owners cannot (or will not) reveal their parameters? These
parameters represent enormous training costs and valuable intellectual
property, making transparent verification difficult. In this paper, we
introduce a zero-knowledge framework capable of verifying deep learning
inference without exposing model internal parameters. Built on recursively
composed zero-knowledge proofs and requiring no trusted setup, our framework
supports both linear and nonlinear neural network layers, including matrix
multiplication, normalization, softmax, and SiLU. Leveraging the Fiat-Shamir
heuristic, we obtain a succinct non-interactive argument of knowledge (zkSNARK)
with constant-size proofs. To demonstrate the practicality of our approach, we
translate the DeepSeek model into a fully SNARK-verifiable version named
ZK-DeepSeek and show experimentally that our framework delivers both efficiency
and flexibility in real-world AI verification workloads.
\\ ( https://arxiv.org/abs/2511.19902 ,  658kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19943 (*cross-listing*)
Date: Tue, 25 Nov 2025 05:31:26 GMT   (3385kb)

Title: AI/ML based Joint Source and Channel Coding for HARQ-ACK Payload
Authors: Akash Doshi, Pinar Sen, Kirill Ivanov, Wei Yang, June Namgoong, Runxin
 Wang, Rachel Wang, Taesang Yoo, Jing Jiang and Tingfang Ji
Categories: eess.SP cs.AI cs.LG
Comments: 39 pages, 15 figures. Under consideration for publication in Journal
 of Sel. Areas in Information Theory. This paper was presented in part at the
 International Symposium on Topics in Coding, August 2025 in the Session for
 Coding and AI
\\
 Channel coding from 2G to 5G has assumed the inputs bits at the physical
layer to be uniformly distributed. However, hybrid automatic repeat request
acknowledgement (HARQ-ACK) bits transmitted in the uplink are inherently
non-uniformly distributed. For such sources, significant performance gains
could be obtained by employing joint source channel coding, aided by deep
learning-based techniques. In this paper, we learn a transformer-based encoder
using a novel "free-lunch" training algorithm and propose per-codeword power
shaping to exploit the source prior at the encoder whilst being robust to small
changes in the HARQ-ACK distribution. Furthermore, any HARQ-ACK decoder has to
achieve a low negative acknowledgement (NACK) error rate to avoid radio link
failures resulting from multiple NACK errors. We develop an extension of the
Neyman-Pearson test to a coded bit system with multiple information bits to
achieve Unequal Error Protection of NACK over ACK bits at the decoder. Finally,
we apply the proposed encoder and decoder designs to a 5G New Radio (NR)
compliant uplink setup under a fading channel, describing the optimal receiver
design and a low complexity coherent approximation to it. Our results
demonstrate 3-6 dB reduction in the average transmit power required to achieve
the target error rates compared to the NR baseline, while also achieving a 2-3
dB reduction in the maximum transmit power, thus providing for significant
coverage gains and power savings.
\\ ( https://arxiv.org/abs/2511.19943 ,  3385kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20006 (*cross-listing*)
Date: Tue, 25 Nov 2025 07:16:49 GMT   (2672kb)

Title: BERT-APC: A Reference-free Framework for Automatic Pitch Correction via
 Musical Context Inference
Authors: Sungjae Kim, Kihyun Na, Jinyoung Choi, Injung Kim
Categories: eess.AS cs.AI cs.SD
Comments: 12 pages, 6 figures, 5 tables
\\
 Automatic Pitch Correction (APC) enhances vocal recordings by aligning pitch
deviations with the intended musical notes. However, existing APC systems
either rely on reference pitches, which limits their practical applicability,
or employ simple pitch estimation algorithms that often fail to preserve
expressiveness and naturalness. We propose BERT-APC, a novel reference-free APC
framework that corrects pitch errors while maintaining the natural
expressiveness of vocal performances. In BERT-APC, a novel stationary pitch
predictor first estimates the perceived pitch of each note from the detuned
singing voice. A context-aware note pitch predictor estimates the intended
pitch sequence by leveraging a music language model repurposed to incorporate
musical context. Finally, a note-level correction algorithm fixes pitch errors
while preserving intentional pitch deviations for emotional expression. In
addition, we introduce a learnable data augmentation strategy that improves the
robustness of the music language model by simulating realistic detuning
patterns. Compared to two recent singing voice transcription models, BERT-APC
demonstrated superior performance in note pitch prediction, outperforming the
second-best model, ROSVOT, by 10.49%p on highly detuned samples in terms of the
raw pitch accuracy. In the MOS test, BERT-APC achieved the highest score of
$4.32 \pm 0.15$, which is significantly higher than those of the widely-used
commercial APC tools, AutoTune ($3.22 \pm 0.18$) and Melodyne ($3.08 \pm
0.18$), while maintaining a comparable ability to preserve expressive nuances.
To the best of our knowledge, this is the first APC model that leverages a
music language model to achieve reference-free pitch correction with symbolic
musical context. The corrected audio samples of BERT-APC are available online.
\\ ( https://arxiv.org/abs/2511.20006 ,  2672kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20018 (*cross-listing*)
Date: Tue, 25 Nov 2025 07:38:50 GMT   (1523kb)

Title: Energy Costs and Neural Complexity Evolution in Changing Environments
Authors: Sian Heesom-Green, Jonathan Shock, Geoff Nitschke
Categories: cs.NE cs.AI
Comments: Presented at ALIFE 2025, proceedings forthcoming (MIT Press)
\\
 The Cognitive Buffer Hypothesis (CBH) posits that larger brains evolved to
enhance survival in changing conditions. However, larger brains also carry
higher energy demands, imposing additional metabolic burdens. Alongside brain
size, brain organization plays a key role in cognitive ability and, with
suitable architectures, may help mitigate energy challenges. This study evolves
Artificial Neural Networks (ANNs) used by Reinforcement Learning (RL) agents to
investigate how environmental variability and energy costs influence the
evolution of neural complexity, defined in terms of ANN size and structure.
Results indicate that under energy constraints, increasing seasonality led to
smaller ANNs. This challenges CBH and supports the Expensive Brain Hypothesis
(EBH), as highly seasonal environments reduced net energy intake and thereby
constrained brain size. ANN structural complexity primarily emerged as a
byproduct of size, where energy costs promoted the evolution of more efficient
networks. These results highlight the role of energy constraints in shaping
neural complexity, offering in silico support for biological theory and
energy-efficient robotic design.
\\ ( https://arxiv.org/abs/2511.20018 ,  1523kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20090 (*cross-listing*)
Date: Tue, 25 Nov 2025 09:08:48 GMT   (287kb)

Title: R3A: Reliable RTL Repair Framework with Multi-Agent Fault Localization
 and Stochastic Tree-of-Thoughts Patch Generation
Authors: Zizhang Luo, Fan Cui, Kexing Zhou, Runlin Guo, Mile Xia, Hongyuan Hou,
 Yun Lian
Categories: cs.AR cs.AI
\\
 Repairing RTL bugs is crucial for hardware design and verification.
Traditional automatic program repair (APR) methods define dedicated search
spaces to locate and fix bugs with program synthesis. However, they heavily
rely on fixed templates and can only deal with limited bugs. As an alternative,
Large Language Models with the ability to understand code semantics can be
explored for RTL repair. However, they suffer from unreliable outcomes due to
inherent randomness and long input contexts of RTL code and waveform. To
address these challenges, we propose R3A, an LLM-based automatic RTL program
repair framework upon the basic model to improve reliability. R3A proposes the
stochastic Tree-Of-Thoughts method to control a patch generation agent to
explore a validated solution for the bug. The algorithm samples search states
according to a heuristic function to balance between exploration and
exploitation for a reliable outcome. Besides, R3A proposes a multi-agent fault
localization method to find fault candidates as the starting points for the
patch generation agent, further increasing the reliability. Experiments show
R3A can fix 90.6% of bugs in the RTL-repair dataset within a given time limit,
which covers 45% more bugs than traditional methods and other LLM-based
approaches, while achieving an 86.7% pass@5 rate on average, showing a high
reliability.
\\ ( https://arxiv.org/abs/2511.20090 ,  287kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20094 (*cross-listing*)
Date: Tue, 25 Nov 2025 09:10:03 GMT   (293kb)

Title: The Making of Digital Ghosts: Designing Ethical AI Afterlives
Authors: Giovanni Spitale, Federico Germani
Categories: cs.CY cs.AI cs.HC
\\
 Advances in artificial intelligence now make it possible to simulate the dead
through chatbots, voice clones, and video avatars trained on a person's digital
traces. These "digital ghosts" are moving from fiction to commercial reality,
reshaping how people mourn and remember. This paper offers a conceptual and
ethical analysis of AI-mediated digital afterlives. We define what counts as a
digital ghost, trace their rise across personal, commercial, and institutional
contexts, and identify core ethical tensions around grief and well-being,
truthfulness and deception, consent and posthumous privacy, dignity and
misrepresentation, and the commercialization of mourning. To analyze these
challenges, we propose a nine-dimensional taxonomy of digital afterlife
technologies and, building on it, outline the features of an ethically
acceptable digital ghost: premortem intent, mutual consent, transparent and
limited data use, clear disclosure, restricted purposes and access, family or
estate stewardship, and minimal behavioral agency. We argue for targeted
regulation and professional guidelines to ensure that digital ghosts can aid
remembrance without slipping into forms of deception.
\\ ( https://arxiv.org/abs/2511.20094 ,  293kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20172 (*cross-listing*)
Date: Tue, 25 Nov 2025 10:51:43 GMT   (1958kb)

Title: Beluga: A CXL-Based Memory Architecture for Scalable and Efficient LLM
 KVCache Management
Authors: Xinjun Yang, Qingda Hu, Junru Li, Feifei Li, Yuqi Zhou, Yicong Zhu,
 Qiuru Lin, Jian Dai, Yang Kong, Jiayu Zhang, Guoqiang Xu, Qiang Liu
Categories: cs.DC cs.AI
Comments: 13 pages, accepted by SIGMOD'26
\\
 The rapid increase in LLM model sizes and the growing demand for long-context
inference have made memory a critical bottleneck in GPU-accelerated serving
systems. Although high-bandwidth memory (HBM) on GPUs offers fast access, its
limited capacity necessitates reliance on host memory (CPU DRAM) to support
larger working sets such as the KVCache. However, the maximum DRAM capacity is
constrained by the limited number of memory channels per CPU socket. To
overcome this limitation, current systems often adopt RDMA-based disaggregated
memory pools, which introduce significant challenges including high access
latency, complex communication protocols, and synchronization overhead.
Fortunately, the emerging CXL technology introduces new opportunities in
KVCache design. In this paper, we propose Beluga, a novel memory architecture
that enables GPUs and CPUs to access a shared, large-scale memory pool through
CXL switches. By supporting native load/store access semantics over the CXL
fabric, our design delivers near-local memory latency, while reducing
programming complexity and minimizing synchronization overhead. We conduct a
systematic characterization of a commercial CXL switch-based memory pool and
propose a set of design guidelines. Based on Beluga, we design and implement
Beluga-KVCache, a system tailored for managing the large-scale KVCache in LLM
inference. Beluga-KVCache achieves an 89.6% reduction in Time-To-First-Token
(TTFT) and 7.35x throughput improvement in the vLLM inference engine compared
to RDMA-based solutions. To the best of our knowledge, Beluga is the first
system that enables GPUs to directly access large-scale memory pools through
CXL switches, marking a significant step toward low-latency, shared access to
vast memory resources by GPUs.
\\ ( https://arxiv.org/abs/2511.20172 ,  1958kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20179 (*cross-listing*)
Date: Tue, 25 Nov 2025 11:00:39 GMT   (11323kb)

Title: Human-computer interactions predict mental health
Authors: Veith Weilnhammer, Jefferson Ortega, David Whitney
Categories: q-bio.NC cs.AI cs.HC
\\
 Scalable assessments of mental illness, the leading driver of disability
worldwide, remain a critical roadblock toward accessible and equitable care.
Here, we show that human-computer interactions encode multiple dimensions of
self-reported mental health and their changes over time.
 We introduce MAILA, a MAchine-learning framework for Inferring Latent mental
states from digital Activity. We trained MAILA to predict 1.3 million
mental-health self-reports from 20,000 cursor and touchscreen recordings
recorded in 9,000 online participants. The dataset includes 2,000 individuals
assessed longitudinally, 1,500 diagnosed with depression, and 500 with
obsessive-compulsive disorder. MAILA tracks dynamic mental states along three
orthogonal dimensions, generalizes across contexts, and achieves near-ceiling
accuracy when predicting group-level mental health. The model translates from
general to clinical populations, identifies individuals living with mental
illness, and captures signatures of psychological function that are not
conveyed by language.
 Our results demonstrate how everyday human-computer interactions can power
passive, reliable, dynamic, and maximally scalable mental health assessments.
The ability to decode mental states at zero marginal cost sets new benchmarks
for precision medicine and public health, while raising important questions
about privacy, agency, and autonomy online.
\\ ( https://arxiv.org/abs/2511.20179 ,  11323kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20224 (*cross-listing*)
Date: Tue, 25 Nov 2025 11:53:57 GMT   (3426kb)

Title: DUO-TOK: Dual-Track Semantic Music Tokenizer for Vocal-Accompaniment
 Generation
Authors: Rui Lin, Zhiyue Wu, Jiahe Le, Kangdi Wang, Weixiong Chen, Junyu Dai,
 Tao Jiang
Categories: cs.SD cs.AI
Comments: 17 pages, 5 figures, 8 tables. Project page:
 https://eps-acoustic-revolution-lab.github.io/DUO_TOK/
\\
 Duo-Tok is a source-aware dual-codebook tokenizer for vocal-accompaniment
music that targets the growing tension between reconstruction quality and
language-model (LM) learnability in modern lyrics-to-song systems. Existing
codecs either prioritize high-fidelity reconstruction with difficult-to-model
acoustic tokens or compress aggressively into semantic tokens that are
LM-friendly but lossy, and they rarely make the tokenizer itself aware of
dual-track structure. Duo-Tok follows a four-stage, SSL-centered pipeline: we
first pretrain a BEST-RQ-style encoder on large-scale audio, then stabilize and
factorize the representation with Gaussian replacement noise and multi-task
supervision, before freezing the encoder to learn SimVQ-based dual codebooks
with hard routing for vocals and accompaniment, and finally training latent
diffusion decoders on top of the discrete tokens. Duo-Tok at 0.75 kbps shifts
the empirical reconstruction-generation Pareto frontier, achieving the best
music-tagging AP and the lowest vocabulary-normalized LM perplexity among
compared codecs while maintaining reconstruction quality comparable to
state-of-the-art music tokenizers.
\\ ( https://arxiv.org/abs/2511.20224 ,  3426kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20284 (*cross-listing*)
Date: Tue, 25 Nov 2025 13:11:23 GMT   (619kb)

Title: Can LLMs Make (Personalized) Access Control Decisions?
Authors: Friederike Groschupp, Daniele Lain, Aritra Dhar, Lara Magdalena
 Lazier, Srdjan \v{C}apkun
Categories: cs.CR cs.AI
\\
 Precise access control decisions are crucial to the security of both
traditional applications and emerging agent-based systems. Typically, these
decisions are made by users during app installation or at runtime. Due to the
increasing complexity and automation of systems, making these access control
decisions can add a significant cognitive load on users, often overloading them
and leading to suboptimal or even arbitrary access control decisions. To
address this problem, we propose to leverage the processing and reasoning
capabilities of large language models (LLMs) to make dynamic, context-aware
decisions aligned with the user's security preferences. For this purpose, we
conducted a user study, which resulted in a dataset of 307 natural-language
privacy statements and 14,682 access control decisions made by users. We then
compare these decisions against those made by two versions of LLMs: a general
and a personalized one, for which we also gathered user feedback on 1,446 of
its decisions.
 Our results show that in general, LLMs can reflect users' preferences well,
achieving up to 86\% accuracy when compared to the decision made by the
majority of users. Our study also reveals a crucial trade-off in personalizing
such a system: while providing user-specific privacy preferences to the LLM
generally improves agreement with individual user decisions, adhering to those
preferences can also violate some security best practices. Based on our
findings, we discuss design and risk considerations for implementing a
practical natural-language-based access control system that balances
personalization, security, and utility.
\\ ( https://arxiv.org/abs/2511.20284 ,  619kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20293 (*cross-listing*)
Date: Tue, 25 Nov 2025 13:25:59 GMT   (275kb)

Title: Forgetting by Pruning: Data Deletion in Join Cardinality Estimation
Authors: Chaowei He, Yuanjun Liu, Qingzhi Ma, Shenyuan Ren, Xizhao Luo, Lei
 Zhao and An Liu
Categories: cs.DB cs.AI cs.LG
Comments: AAAI26
\\
 Machine unlearning in learned cardinality estimation (CE) systems presents
unique challenges due to the complex distributional dependencies in multi-table
relational data. Specifically, data deletion, a core component of machine
unlearning, faces three critical challenges in learned CE models:
attribute-level sensitivity, inter-table propagation and domain disappearance
leading to severe overestimation in multi-way joins. We propose Cardinality
Estimation Pruning (CEP), the first unlearning framework specifically designed
for multi-table learned CE systems. CEP introduces Distribution Sensitivity
Pruning, which constructs semi-join deletion results and computes sensitivity
scores to guide parameter pruning, and Domain Pruning, which removes support
for value domains entirely eliminated by deletion. We evaluate CEP on
state-of-the-art architectures NeuroCard and FACE across IMDB and TPC-H
datasets. Results demonstrate CEP consistently achieves the lowest Q-error in
multi-table scenarios, particularly under high deletion ratios, often
outperforming full retraining. Furthermore, CEP significantly reduces
convergence iterations, incurring negligible computational overhead of
0.3%-2.5% of fine-tuning time.
\\ ( https://arxiv.org/abs/2511.20293 ,  275kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20305 (*cross-listing*)
Date: Tue, 25 Nov 2025 13:43:44 GMT   (620kb)

Title: RIS-Assisted Downlink Pinching-Antenna Systems: GNN-Enabled Optimization
 Approaches
Authors: Changpeng He, Yang Lu, Yanqing Xu, Chong-Yung Chi, Bo Ai, and Arumugam
 Nallanathan
Categories: cs.NI cs.AI
\\
 This paper investigates a reconfigurable intelligent surface (RIS)-assisted
multi-waveguide pinching-antenna (PA) system (PASS) for multi-user downlink
information transmission, motivated by the unknown impact of the integration of
emerging PASS and RIS on wireless communications. First, we formulate sum rate
(SR) and energy efficiency (EE) maximization problems in a unified framework,
subject to constraints on the movable region of PAs, total power budget, and
tunable phase of RIS elements. Then, by leveraging a graph-structured topology
of the RIS-assisted PASS, a novel three-stage graph neural network (GNN) is
proposed, which learns PA positions based on user locations, and RIS phase
shifts according to composite channel conditions at the first two stages,
respectively, and finally determines beamforming vectors. Specifically, the
proposed GNN is achieved through unsupervised training, together with three
implementation strategies for its integration with convex optimization, thus
offering trade-offs between inference time and solution optimality. Extensive
numerical results are provided to validate the effectiveness of the proposed
GNN, and to support its unique attributes of viable generalization capability,
good performance reliability, and real-time applicability. Moreover, the impact
of key parameters on RIS-assisted PASS is illustrated and analyzed.
\\ ( https://arxiv.org/abs/2511.20305 ,  620kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20403 (*cross-listing*)
Date: Tue, 25 Nov 2025 15:33:00 GMT   (513kb)

Title: LLMs for Automated Unit Test Generation and Assessment in Java: The
 AgoneTest Framework
Authors: Andrea Lops, Fedelucio Narducci, Azzurra Ragone, Michelantonio Trizio,
 Claudio Barto
Categories: cs.SE cs.AI
Comments: Accepted at 40th IEEE/ACM International Conference on Automated
 Software Engineering
\\
 Unit testing is an essential but resource-intensive step in software
development, ensuring individual code units function correctly. This paper
introduces AgoneTest, an automated evaluation framework for Large Language
Model-generated (LLM) unit tests in Java. AgoneTest does not aim to propose a
novel test generation algorithm; rather, it supports researchers and developers
in comparing different LLMs and prompting strategies through a standardized
end-to-end evaluation pipeline under realistic conditions. We introduce the
Classes2Test dataset, which maps Java classes under test to their corresponding
test classes, and a framework that integrates advanced evaluation metrics, such
as mutation score and test smells, for a comprehensive assessment. Experimental
results show that, for the subset of tests that compile, LLM-generated tests
can match or exceed human-written tests in terms of coverage and defect
detection. Our findings also demonstrate that enhanced prompting strategies
contribute to test quality. AgoneTest clarifies the potential of LLMs in
software testing and offers insights for future improvements in model design,
prompt engineering, and testing practices.
\\ ( https://arxiv.org/abs/2511.20403 ,  513kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20470 (*cross-listing*)
Date: Tue, 25 Nov 2025 16:34:07 GMT   (439kb)

Title: Efficient and Fast Generative-Based Singing Voice Separation using a
 Latent Diffusion Model
Authors: Gen\'is Plaja-Roglans, Yun-Ning Hung, Xavier Serra, Igor Pereira
Categories: cs.SD cs.AI
Comments: Accepted for oral presentation at IJCNN 2025
Journal-ref: 2025 International Joint Conference on Neural Networks (IJCNN),
 Rome, Italy, 2025, pp. 1-8
DOI: 10.1109/IJCNN64981.2025.11228078
\\
 Extracting individual elements from music mixtures is a valuable tool for
music production and practice. While neural networks optimized to mask or
transform mixture spectrograms into the individual source(s) have been the
leading approach, the source overlap and correlation in music signals poses an
inherent challenge. Also, accessing all sources in the mixture is crucial to
train these systems, while complicated. Attempts to address these challenges in
a generative fashion exist, however, the separation performance and inference
efficiency remain limited. In this work, we study the potential of diffusion
models to advance toward bridging this gap, focusing on generative singing
voice separation relying only on corresponding pairs of isolated vocals and
mixtures for training. To align with creative workflows, we leverage latent
diffusion: the system generates samples encoded in a compact latent space, and
subsequently decodes these into audio. This enables efficient optimization and
faster inference. Our system is trained using only open data. We outperform
existing generative separation systems, and level the compared non-generative
systems on a list of signal quality measures and on interference removal. We
provide a noise robustness study on the latent encoder, providing insights on
its potential for the task. We release a modular toolkit for further research
on the topic.
\\ ( https://arxiv.org/abs/2511.20470 ,  439kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20532 (*cross-listing*)
Date: Tue, 25 Nov 2025 17:34:38 GMT   (12004kb)

Title: MIMIC-MJX: Neuromechanical Emulation of Animal Behavior
Authors: Charles Y. Zhang (1), Yuanjia Yang (2, 3), Aidan Sirbu (4, 5), Elliott
 T.T. Abe (6), Emil W\"arnberg (1), Eric J. Leonardis (2), Diego E. Aldarondo
 (1), Adam Lee (1, 2), Aaditya Prasad (7), Jason Foat (2), Kaiwen Bian (2),
 Joshua Park (2), Rusham Bhatt (2), Hutton Saunders (2), Akira Nagamori (2),
 Ayesha R. Thanawalla (2), Kee Wui Huang (2), Fabian Plum (8), Hendrik K. Beck
 (8), Steven W. Flavell (7, 9), David Labonte (8), Blake A. Richards (4, 5,
 10), Bingni W. Brunton (6), Eiman Azim (2), Bence P. \"Olveczky (1), Talmo D.
 Pereira (2) ((1) Harvard University, (2) Salk Institute for Biological
 Studies, (3) University of California San Diego, (4) Mila, (5) McGill
 University, (6) University of Washington, (7) Massachusetts Institute of
 Technology, (8) Imperial College London, (9) Howard Hughes Medical Institute,
 (10) Canadian Institute for Advanced Research)
Categories: q-bio.NC cs.AI cs.RO
\\
 The primary output of the nervous system is movement and behavior. While
recent advances have democratized pose tracking during complex behavior,
kinematic trajectories alone provide only indirect access to the underlying
control processes. Here we present MIMIC-MJX, a framework for learning
biologically-plausible neural control policies from kinematics. MIMIC-MJX
models the generative process of motor control by training neural controllers
that learn to actuate biomechanically-realistic body models in physics
simulation to reproduce real kinematic trajectories. We demonstrate that our
implementation is accurate, fast, data-efficient, and generalizable to diverse
animal body models. Policies trained with MIMIC-MJX can be utilized to both
analyze neural control strategies and simulate behavioral experiments,
illustrating its potential as an integrative modeling framework for
neuroscience.
\\ ( https://arxiv.org/abs/2511.20532 ,  12004kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20540 (*cross-listing*)
Date: Tue, 25 Nov 2025 17:41:15 GMT   (8kb)

Title: Proceedings Twentieth Conference on Theoretical Aspects of Rationality
 and Knowledge
Authors: Adam Bjorndahl (Carnegie Mellon University)
Categories: cs.LO cs.AI cs.GT cs.MA
Journal-ref: EPTCS 437, 2025
DOI: 10.4204/EPTCS.437
\\
 The TARK conference (Theoretical Aspects of Rationality and Knowledge) is a
conference that aims to bring together researchers from a wide variety of
fields, including computer science, artificial intelligence, game theory,
decision theory, philosophy, logic, linguistics, and cognitive science. Its
goal is to further our understanding of interdisciplinary issues involving
reasoning about rationality and knowledge.
 Previous conferences have been held biennially around the world since 1986,
on the initiative of Joe Halpern (Cornell University). Topics of interest
include, but are not limited to, semantic models for knowledge, belief,
uncertainty, awareness, bounded rationality, common sense epistemic reasoning,
epistemic logic, epistemic game theory, knowledge and action, applications of
reasoning about knowledge and other mental states, belief revision,
computational social choice, algorithmic game theory, and foundations of
multi-agent systems.
 Information about TARK is available at http://www.tark.org/.
 These proceedings contain the papers that have been accepted for presentation
at the Twentieth Conference on Theoretical Aspects of Rationality and Knowledge
(TARK 2025), held July 14--16, 2025, at Heinrich-Heine-Universit\"at,
D\"usseldorf, Germany. The conference website can be found at
https://ccc.cs.uni-duesseldorf.de/tark-2025/.
\\ ( https://arxiv.org/abs/2511.20540 ,  8kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20551 (*cross-listing*)
Date: Tue, 25 Nov 2025 17:48:04 GMT   (1461kb)

Title: Time-Domain Linear Model-based Framework for Passive Acoustic Mapping of
 Cavitation Activity
Authors: Tatiana Gelvez-Barrera, Barbara Nicolas, Denis Kouam\'e, Bruno Gilles,
 Adrian Basarab
Categories: eess.SP cs.AI eess.IV
\\
 Passive acoustic mapping enables the spatial mapping and temporal monitoring
of cavitation activity, playing a crucial role in therapeutic ultrasound
applications. Most conventional beamforming methods, whether implemented in the
time or frequency domains, suffer from limited axial resolution due to the
absence of a reference emission onset time. While frequency-domain methods, the
most efficient of which are based on the cross-spectral matrix, require long
signals for accurate estimation, time-domain methods typically achieve lower
spatial resolution. To address these limitations, we propose a linear
model-based beamforming framework fully formulated in the time domain. The
linear forward model relates a discretized spatiotemporal distribution of
cavitation activity to the temporal signals recorded by a probe, explicitly
accounting for time-of-flight delays dictated by the acquisition geometry. This
model is then inverted using regularization techniques that exploit prior
knowledge of cavitation activity in both spatial and temporal domains.
Experimental results show that the proposed framework achieves enhanced or
competitive cavitation map quality while using only 20\% of the data typically
required by frequency-domain methods. This highlights the substantial gain in
data efficiency and the flexibility of our spatiotemporal regularization to
adapt to diverse passive cavitation scenarios, outperforming state-of-the-art
techniques.
\\ ( https://arxiv.org/abs/2511.20551 ,  1461kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20570 (*cross-listing*)
Date: Tue, 25 Nov 2025 18:05:05 GMT   (1537kb)

Title: Gated Uncertainty-Aware Runtime Dual Invariants for Neural
 Signal-Controlled Robotics
Authors: Tasha Kim, Oiwi Parker Jones
Categories: cs.RO cs.AI cs.HC cs.LG
Comments: Embodied and Safe-Assured Robotic Systems workshop at NeurIPS 2025
\\
 Safety-critical assistive systems that directly decode user intent from
neural signals require rigorous guarantees of reliability and trust. We present
GUARDIAN (Gated Uncertainty-Aware Runtime Dual Invariants), a framework for
real-time neuro-symbolic verification for neural signal-controlled robotics.
GUARDIAN enforces both logical safety and physiological trust by coupling
confidence-calibrated brain signal decoding with symbolic goal grounding and
dual-layer runtime monitoring. On the BNCI2014 motor imagery
electroencephalogram (EEG) dataset with 9 subjects and 5,184 trials, the system
performs at a high safety rate of 94-97% even with lightweight decoder
architectures with low test accuracies (27-46%) and high ECE confidence
miscalibration (0.22-0.41). We demonstrate 1.7x correct interventions in
simulated noise testing versus at baseline. The monitor operates at 100Hz and
sub-millisecond decision latency, making it practically viable for closed-loop
neural signal-based systems. Across 21 ablation results, GUARDIAN exhibits a
graduated response to signal degradation, and produces auditable traces from
intent, plan to action, helping to link neural evidence to verifiable robot
action.
\\ ( https://arxiv.org/abs/2511.20570 ,  1537kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20590 (*cross-listing*)
Date: Tue, 25 Nov 2025 18:19:40 GMT   (1127kb)

Title: EnergyTwin: A Multi-Agent System for Simulating and Coordinating Energy
 Microgrids
Authors: Jakub Muszy\'nski, Ignacy Walu\.zenicz, Patryk Zan, Zofia Wrona, Maria
 Ganzha, Marcin Paprzycki, Costin B\u{a}dic\u{a}
Categories: cs.MA cs.AI cs.SE
\\
 Microgrids are deployed to reduce purchased grid energy, limit exposure to
volatile tariffs, and ensure service continuity during disturbances. This
requires coordinating heterogeneous distributed energy resources across
multiple time scales and under variable conditions. Among existing tools,
typically, power-system simulators capture physical behaviour but assume
centralized control, while multi-agent frameworks model decentralized
decision-making but represent energy with no physical grounding. In this
context, the EnergyTwin is introduced, an agent-based microgrid simulation
environment that couples physically grounded models with forecast-informed,
rolling-horizon planning, and negotiations. Each asset is modeled as an agent,
interacting with a central agent that obtains forecasts, formulates
predictions, and allocates energy through contract-based interactions.
EnergyTwin targets tertiary-layer decision making and is extensible for
digital-twin use. Its feasibility was evaluated in a university campus
microgrid scenario where multiple planning strategies were compared. Achieved
results show that forecast-driven rolling-horizon planning increases local
energy self-sufficiency, maintains higher battery reserves, and reduces
exposure to low-resilience operating states. They demonstrate also potential of
EnergyTwin as platform supporting research on resilient, negotiation-driven
microgrids.
\\ ( https://arxiv.org/abs/2511.20590 ,  1127kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20100 (*cross-listing*)
Date: Tue, 25 Nov 2025 09:17:47 GMT   (517kb)

Title: QiMeng-Kernel: Macro-Thinking Micro-Coding Paradigm for LLM-Based
 High-Performance GPU Kernel Generation
Authors: Xinguo Zhu, Shaohui Peng, Jiaming Guo, Yunji Chen, Qi Guo, Yuanbo Wen,
 Hang Qin, Ruizhi Chen, Qirui Zhou, Ke Gao, Yanjun Wu, Chen Zhao, Ling Li
Categories: cs.DC cs.CL
Comments: 9 pages, 2 figures, accepted by AAAI 2026
\\
 Developing high-performance GPU kernels is critical for AI and scientific
computing, but remains challenging due to its reliance on expert crafting and
poor portability. While LLMs offer promise for automation, both general-purpose
and finetuned LLMs suffer from two fundamental and conflicting limitations:
correctness and efficiency. The key reason is that existing LLM-based
approaches directly generate the entire optimized low-level programs, requiring
exploration of an extremely vast space encompassing both optimization policies
and implementation codes. To address the challenge of exploring an intractable
space, we propose Macro Thinking Micro Coding (MTMC), a hierarchical framework
inspired by the staged optimization strategy of human experts. It decouples
optimization strategy from implementation details, ensuring efficiency through
high-level strategy and correctness through low-level implementation.
Specifically, Macro Thinking employs reinforcement learning to guide
lightweight LLMs in efficiently exploring and learning semantic optimization
strategies that maximize hardware utilization. Micro Coding leverages
general-purpose LLMs to incrementally implement the stepwise optimization
proposals from Macro Thinking, avoiding full-kernel generation errors.
Together, they effectively navigate the vast optimization space and intricate
implementation details, enabling LLMs for high-performance GPU kernel
generation. Comprehensive results on widely adopted benchmarks demonstrate the
superior performance of MTMC on GPU kernel generation in both accuracy and
running time. On KernelBench, MTMC achieves near 100% and 70% accuracy at
Levels 1-2 and 3, over 50% than SOTA general-purpose and domain-finetuned LLMs,
with up to 7.3x speedup over LLMs, and 2.2x over expert-optimized PyTorch Eager
kernels. On the more challenging TritonBench, MTMC attains up to 59.64%
accuracy and 34x speedup.
\\ ( https://arxiv.org/abs/2511.20100 ,  517kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17685 (*cross-listing*)
Date: Fri, 21 Nov 2025 10:58:04 GMT   (14381kb)

Title: Dual-Path Knowledge-Augmented Contrastive Alignment Network for
 Spatially Resolved Transcriptomics
Authors: Wei Zhang, Jiajun Chu, Xinci Liu, Chen Tong, Xinyue Li
Categories: q-bio.QM cs.AI cs.CV cs.LG
Comments: AAAI 2026 Oral, extended version
\\
 Spatial Transcriptomics (ST) is a technology that measures gene expression
profiles within tissue sections while retaining spatial context. It reveals
localized gene expression patterns and tissue heterogeneity, both of which are
essential for understanding disease etiology. However, its high cost has driven
efforts to predict spatial gene expression from whole slide images. Despite
recent advancements, current methods still face significant limitations, such
as under-exploitation of high-level biological context, over-reliance on
exemplar retrievals, and inadequate alignment of heterogeneous modalities. To
address these challenges, we propose DKAN, a novel Dual-path
Knowledge-Augmented contrastive alignment Network that predicts spatially
resolved gene expression by integrating histopathological images and gene
expression profiles through a biologically informed approach. Specifically, we
introduce an effective gene semantic representation module that leverages the
external gene database to provide additional biological insights, thereby
enhancing gene expression prediction. Further, we adopt a unified, one-stage
contrastive learning paradigm, seamlessly combining contrastive learning and
supervised learning to eliminate reliance on exemplars, complemented with an
adaptive weighting mechanism. Additionally, we propose a dual-path contrastive
alignment module that employs gene semantic features as dynamic cross-modal
coordinators to enable effective heterogeneous feature integration. Through
extensive experiments across three public ST datasets, DKAN demonstrates
superior performance over state-of-the-art models, establishing a new benchmark
for spatial gene expression prediction and offering a powerful tool for
advancing biological and clinical research.
\\ ( https://arxiv.org/abs/2511.17685 ,  14381kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18525 (*cross-listing*)
Date: Sun, 23 Nov 2025 16:35:51 GMT   (2245kb)

Title: Splatblox: Traversability-Aware Gaussian Splatting for Outdoor Robot
 Navigation
Authors: Samarth Chopra, Jing Liang, Gershom Seneviratne, Yonghan Lee, Jaehoon
 Choi, Jianyu An, Stephen Cheng, Dinesh Manocha
Categories: cs.RO cs.CV
Comments: Submitted to ICRA 2026
\\
 We present Splatblox, a real-time system for autonomous navigation in outdoor
environments with dense vegetation, irregular obstacles, and complex terrain.
Our method fuses segmented RGB images and LiDAR point clouds using Gaussian
Splatting to construct a traversability-aware Euclidean Signed Distance Field
(ESDF) that jointly encodes geometry and semantics. Updated online, this field
enables semantic reasoning to distinguish traversable vegetation (e.g., tall
grass) from rigid obstacles (e.g., trees), while LiDAR ensures 360-degree
geometric coverage for extended planning horizons. We validate Splatblox on a
quadruped robot and demonstrate transfer to a wheeled platform. In field trials
across vegetation-rich scenarios, it outperforms state-of-the-art methods with
over 50% higher success rate, 40% fewer freezing incidents, 5% shorter paths,
and up to 13% faster time to goal, while supporting long-range missions up to
100 meters. Experiment videos and more details can be found on our project
page: https://splatblox.github.io
\\ ( https://arxiv.org/abs/2511.18525 ,  2245kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19478 (*cross-listing*)
Date: Sat, 22 Nov 2025 16:34:03 GMT   (3044kb)

Title: A Multi-Stage Deep Learning Framework with PKCP-MixUp Augmentation for
 Pediatric Liver Tumor Diagnosis Using Multi-Phase Contrast-Enhanced CT
Authors: Wanqi Wang, Chun Yang, Jianbo Shao, Yaokai Zhang, Xuehua Peng, Jin
 Sun, Chao Xiong, Long Lu, Lianting Hu
Categories: eess.IV cs.CV cs.LG
\\
 Pediatric liver tumors are one of the most common solid tumors in pediatrics,
with differentiation of benign or malignant status and pathological
classification critical for clinical treatment. While pathological examination
is the gold standard, the invasive biopsy has notable limitations: the highly
vascular pediatric liver and fragile tumor tissue raise complication risks such
as bleeding; additionally, young children with poor compliance require
anesthesia for biopsy, increasing medical costs or psychological trauma.
Although many efforts have been made to utilize AI in clinical settings, most
researchers have overlooked its importance in pediatric liver tumors. To
establish a non-invasive examination procedure, we developed a multi-stage deep
learning (DL) framework for automated pediatric liver tumor diagnosis using
multi-phase contrast-enhanced CT. Two retrospective and prospective cohorts
were enrolled. We established a novel PKCP-MixUp data augmentation method to
address data scarcity and class imbalance. We also trained a tumor detection
model to extract ROIs, and then set a two-stage diagnosis pipeline with three
backbones with ROI-masked images. Our tumor detection model has achieved high
performance (mAP=0.871), and the first stage classification model between
benign and malignant tumors reached an excellent performance (AUC=0.989). Final
diagnosis models also exhibited robustness, including benign subtype
classification (AUC=0.915) and malignant subtype classification (AUC=0.979). We
also conducted multi-level comparative analyses, such as ablation studies on
data and training pipelines, as well as Shapley-Value and CAM interpretability
analyses. This framework fills the pediatric-specific DL diagnostic gap,
provides actionable insights for CT phase selection and model design, and paves
the way for precise, accessible pediatric liver tumor diagnosis.
\\ ( https://arxiv.org/abs/2511.19478 ,  3044kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19539 (*cross-listing*)
Date: Mon, 24 Nov 2025 10:54:03 GMT   (18617kb)

Title: PhysDNet: Physics-Guided Decomposition Network of Side-Scan Sonar
 Imagery
Authors: Can Lei and Hayat Rajani and Nuno Gracias and Rafael Garcia and
 Huigang Wang
Categories: physics.ao-ph cs.CV
Comments: This work was previously submitted in error as arXiv:2509.11255v2
\\
 Side-scan sonar (SSS) imagery is widely used for seafloor mapping and
underwater remote sensing, yet the measured intensity is strongly influenced by
seabed reflectivity, terrain elevation, and acoustic path loss. This
entanglement makes the imagery highly view-dependent and reduces the robustness
of downstream analysis. In this letter, we present PhysDNet, a physics-guided
multi-branch network that decouples SSS images into three interpretable fields:
seabed reflectivity, terrain elevation, and propagation loss. By embedding the
Lambertian reflection model, PhysDNet reconstructs sonar intensity from these
components, enabling self-supervised training without ground-truth annotations.
Experiments show that the decomposed representations preserve stable geological
structures, capture physically consistent illumination and attenuation, and
produce reliable shadow maps. These findings demonstrate that physics-guided
decomposition provides a stable and interpretable domain for SSS analysis,
improving both physical consistency and downstream tasks such as registration
and shadow interpretation.
\\ ( https://arxiv.org/abs/2511.19539 ,  18617kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19706 (*cross-listing*)
Date: Mon, 24 Nov 2025 21:15:29 GMT   (12271kb)

Title: The Selective Disk Bispectrum and Its Inversion, with Application to
 Multi-Reference Alignment
Authors: Adele Myers and Nina Miolane
Categories: eess.IV cs.CV
\\
 In many computer vision and shape analysis tasks, practitioners are
interested in learning from the shape of the object in an image, while
disregarding the object's orientation. To this end, it is valuable to define a
rotation-invariant representation of images, retaining all information about
that image, but disregarding the way an object is rotated in the frame. To be
practical for learning tasks, this representation must be computationally
efficient for large datasets and invertible, so the representation can be
visualized in image space. To this end, we present the selective disk
bispectrum: a fast, rotation-invariant representation for image shape analysis.
While the translational bispectrum has long been used as a translational
invariant representation for 1-D and 2-D signals, its extension to 2-D (disk)
rotational invariance on images has been hindered by the absence of an
invertible formulation and its cubic complexity. In this work, we derive an
explicit inverse for the disk bispectrum, which allows us to define a
"selective" disk bispectrum, which only uses the minimal number of coefficients
needed for faithful shape recovery. We show that this representation enables
multi-reference alignment for rotated images-a task previously intractable for
disk bispectrum methods. These results establish the disk bispectrum as a
practical and theoretically grounded tool for learning on rotation-invariant
shape data.
\\ ( https://arxiv.org/abs/2511.19706 ,  12271kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19877 (*cross-listing*)
Date: Tue, 25 Nov 2025 03:38:05 GMT   (872kb)

Title: It Hears, It Sees too: Multi-Modal LLM for Depression Detection By
 Integrating Visual Understanding into Audio Language Models
Authors: Xiangyu Zhao, Yaling Shen, Yiwen Jiang, Zimu Wang, Jiahe Liu,
 Maxmartwell H Cheng, Guilherme C Oliveira, Robert Desimone, Dominic Dwyer,
 Zongyuan Ge
Categories: cs.MM cs.CV cs.LG eess.AS
\\
 Depression is one of the most prevalent mental health disorders globally. In
recent years, multi-modal data, such as speech, video, and transcripts, has
been increasingly used to develop AI-assisted depression assessment systems.
Large language models have further advanced this field due to their strong
language understanding and generalization capabilities. However, conventional
LLMs remain text-centric and cannot process the rich non-verbal cues found in
audio and visual modalities, which are critical components in mental health
evaluation. While multi-modal LLMs offer a promising direction, few are
tailored for psychological applications. In this study, we propose a novel
multi-modal LLM framework for depression detection. Our approach augments an
audio language model with visual understanding and aligns audio-visual features
at the timestamp level. This fine-grained alignment improves modeling of
temporal dynamics across modalities while reducing the need for extensive
training data and computational resources. Experiments on the DAIC-WoZ dataset
demonstrate that our model outperforms both single-modality approaches and
previous multi-modal methods. Moreover, the proposed framework can be extended
to incorporate additional physiological signals, paving the way for broader
clinical applications beyond mental health.
\\ ( https://arxiv.org/abs/2511.19877 ,  872kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19886 (*cross-listing*)
Date: Tue, 25 Nov 2025 03:45:35 GMT   (19923kb)

Title: Frequency Bias Matters: Diving into Robust and Generalized Deep Image
 Forgery Detection
Authors: Chi Liu, Tianqing Zhu, Wanlei Zhou, Wei Zhao
Categories: cs.CR cs.CV
Comments: Accepted for publication in IEEE Transactions on Dependable and
 Secure Computing
\\
 As deep image forgery powered by AI generative models, such as GANs,
continues to challenge today's digital world, detecting AI-generated forgeries
has become a vital security topic. Generalizability and robustness are two
critical concerns of a forgery detector, determining its reliability when
facing unknown GANs and noisy samples in an open world. Although many studies
focus on improving these two properties, the root causes of these problems have
not been fully explored, and it is unclear if there is a connection between
them. Moreover, despite recent achievements in addressing these issues from
image forensic or anti-forensic aspects, a universal method that can contribute
to both sides simultaneously remains practically significant yet unavailable.
In this paper, we provide a fundamental explanation of these problems from a
frequency perspective. Our analysis reveals that the frequency bias of a DNN
forgery detector is a possible cause of generalization and robustness issues.
Based on this finding, we propose a two-step frequency alignment method to
remove the frequency discrepancy between real and fake images, offering
double-sided benefits: it can serve as a strong black-box attack against
forgery detectors in the anti-forensic context or, conversely, as a universal
defense to improve detector reliability in the forensic context. We also
develop corresponding attack and defense implementations and demonstrate their
effectiveness, as well as the effect of the frequency alignment method, in
various experimental settings involving twelve detectors, eight forgery models,
and five metrics.
\\ ( https://arxiv.org/abs/2511.19886 ,  19923kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19910 (*cross-listing*)
Date: Tue, 25 Nov 2025 04:35:55 GMT   (28160kb)

Title: DLADiff: A Dual-Layer Defense Framework against Fine-Tuning and
 Zero-Shot Customization of Diffusion Models
Authors: Jun Jia, Hongyi Miao, Yingjie Zhou, Linhan Cao, Yanwei Jiang, Wangqiu
 Zhou, Dandan Zhu, Hua Yang, Wei Sun, Xiongkuo Min, Guangtao Zhai
Categories: eess.IV cs.CV
\\
 With the rapid advancement of diffusion models, a variety of fine-tuning
methods have been developed, enabling high-fidelity image generation with high
similarity to the target content using only 3 to 5 training images. More
recently, zero-shot generation methods have emerged, capable of producing
highly realistic outputs from a single reference image without altering model
weights. However, technological advancements have also introduced significant
risks to facial privacy. Malicious actors can exploit diffusion model
customization with just a few or even one image of a person to create synthetic
identities nearly identical to the original identity. Although research has
begun to focus on defending against diffusion model customization, most
existing defense methods target fine-tuning approaches and neglect zero-shot
generation defenses. To address this issue, this paper proposes Dual-Layer
Anti-Diffusion (DLADiff) to defense both fine-tuning methods and zero-shot
methods. DLADiff contains a dual-layer protective mechanism. The first layer
provides effective protection against unauthorized fine-tuning by leveraging
the proposed Dual-Surrogate Models (DSUR) mechanism and Alternating Dynamic
Fine-Tuning (ADFT), which integrates adversarial training with the prior
knowledge derived from pre-fine-tuned models. The second layer, though simple
in design, demonstrates strong effectiveness in preventing image generation
through zero-shot methods. Extensive experimental results demonstrate that our
method significantly outperforms existing approaches in defending against
fine-tuning of diffusion models and achieves unprecedented performance in
protecting against zero-shot generation.
\\ ( https://arxiv.org/abs/2511.19910 ,  28160kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20003 (*cross-listing*)
Date: Tue, 25 Nov 2025 07:13:34 GMT   (3757kb)

Title: Redefining Radar Segmentation: Simultaneous Static-Moving Segmentation
 and Ego-Motion Estimation using Radar Point Clouds
Authors: Simin Zhu, Satish Ravindran, Alexander Yarovoy, Francesco Fioranelli
Categories: eess.SP cs.CV
Comments: 16 pages, 9 figures, under review at IEEE Transactions on Radar
 Systems
\\
 Conventional radar segmentation research has typically focused on learning
category labels for different moving objects. Although fundamental differences
between radar and optical sensors lead to differences in the reliability of
predicting accurate and consistent category labels, a review of common radar
perception tasks in automotive reveals that determining whether an object is
moving or static is a prerequisite for most tasks. To fill this gap, this study
proposes a neural network based solution that can simultaneously segment static
and moving objects from radar point clouds. Furthermore, since the measured
radial velocity of static objects is correlated with the motion of the radar,
this approach can also estimate the instantaneous 2D velocity of the moving
platform or vehicle (ego motion). However, despite performing dual tasks, the
proposed method employs very simple yet effective building blocks for feature
extraction: multi layer perceptrons (MLPs) and recurrent neural networks
(RNNs). In addition to being the first of its kind in the literature, the
proposed method also demonstrates the feasibility of extracting the information
required for the dual task directly from unprocessed point clouds, without the
need for cloud aggregation, Doppler compensation, motion compensation, or any
other intermediate signal processing steps. To measure its performance, this
study introduces a set of novel evaluation metrics and tests the proposed
method using a challenging real world radar dataset, RadarScenes. The results
show that the proposed method not only performs well on the dual tasks, but
also has broad application potential in other radar perception tasks.
\\ ( https://arxiv.org/abs/2511.20003 ,  3757kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20330 (*cross-listing*)
Date: Tue, 25 Nov 2025 14:07:17 GMT   (7343kb)

Title: ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language
 Articulated Object Manipulation
Authors: Yuhan Wu, Tiantian Wei, Shuo Wang, ZhiChao Wang, Yanyong Zhang, Daniel
 Cremers, Yan Xia
Categories: cs.RO cs.CV
\\
 Interactive articulated manipulation requires long-horizon, multi-step
interactions with appliances while maintaining physical consistency. Existing
vision-language and diffusion-based policies struggle to generalize across
parts, instances, and categories. We first introduce ArtiBench, a five-level
benchmark covering kitchen, storage, office, and tool environments. ArtiBench
enables structured evaluation from cross-part and cross-instance variation to
long-horizon multi-object tasks, revealing the core generalization challenges
of articulated object manipulation. Building on this benchmark, we propose
ArtiBrain, a modular framework that unifies high-level reasoning with adaptive
low-level control. ArtiBrain uses a VLM-based Task Reasoner (GPT-4.1) to
decompose and validate subgoals, and employs a Hybrid Controller that combines
geometry-aware keyframe execution with affordance-guided diffusion for precise
and interpretable manipulation. An Affordance Memory Bank continually
accumulates successful execution episodes and propagates part-level actionable
affordances to unseen articulated parts and configurations. Extensive
experiments on ArtiBench show that our ArtiBrain significantly outperforms
state-of-the-art multimodal and diffusion-based methods in robustness and
generalization. Code and dataset will be released upon acceptance.
\\ ( https://arxiv.org/abs/2511.20330 ,  7343kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20493 (*cross-listing*)
Date: Mon, 24 Nov 2025 14:45:46 GMT   (2153kb)

Title: Development of a fully deep learning model to improve the
 reproducibility of sector classification systems for predicting unerupted
 maxillary canine likelihood of impaction
Authors: Marzio Galdi, Davide Cannat\`a, Flavia Celentano, Luigia Rizzo,
 Domenico Rossi, Tecla Bocchino, Stefano Martina
Categories: eess.IV cs.CV q-bio.QM
\\
 Objectives. The aim of the present study was to develop a fully deep learning
model to reduce the intra- and inter-operator reproducibility of sector
classification systems for predicting unerupted maxillary canine likelihood of
impaction. Methods. Three orthodontists (Os) and three general dental
practitioners (GDPs) classified the position of unerupted maxillary canines on
306 radiographs (T0) according to the three different sector classification
systems (5-, 4-, and 3-sector classification system). The assessment was
repeated after four weeks (T1). Intra- and inter-observer agreement were
evaluated with Cohen's K and Fleiss K, and between group differences with a
z-test. The same radiographs were tested on different artificial intelligence
(AI) models, pre-trained on an extended dataset of 1,222 radiographs. The
best-performing model was identified based on its sensitivity and precision.
Results. The 3-sector system was found to be the classification method with
highest reproducibility, with an agreement (Cohen's K values) between
observations (T0 versus T1) for each examiner ranged from 0.80 to 0.92, and an
overall agreement of 0.85 [95% confidence interval (CI) = 0.83-0.87]. The
overall inter-observer agreement (Fleiss K) ranged from 0.69 to 0.7. The
educational background did not affect either intra- or inter-observer agreement
(p>0.05). DenseNet121 proved to be the best-performing model in allocating
impacted canines in the three different classes, with an overall accuracy of
76.8%. Conclusion. AI models can be designed to automatically classify the
position of unerupted maxillary canines.
\\ ( https://arxiv.org/abs/2511.20493 ,  2153kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20607 (*cross-listing*)
Date: Tue, 25 Nov 2025 18:35:14 GMT   (2555kb)

Title: Optimization of Sums of Bivariate Functions: An Introduction to
 Relaxation-Based Methods for the Case of Finite Domains
Authors: Nils M\"uller
Categories: math.OC cs.CV stat.ML
Comments: 59 pages, 7 figures
MSC-class: 90C27 (Primary) 90C05, 65J20 (Secondary)
\\
 We study the optimization of functions with $n>2$ arguments that have a
representation as a sum of several functions that have only $2$ of the $n$
arguments each, termed sums of bivariates, on finite domains. The complexity of
optimizing sums of bivariates is shown to be NP-equivalent and it is shown that
there exists free lunch in the optimization of sums of bivariates. Based on
measure-valued extensions of the objective function, so-called relaxations,
$\ell^2$-approximation, and entropy-regularization, we derive several tractable
problem formulations solvable with linear programming, coordinate ascent as
well as with closed-form solutions. The limits of applying tractable versions
of such relaxations to sums of bivariates are investigated using general
results for reconstructing measures from their bivariate marginals. Experiments
in which the derived algorithms are applied to random functions, vertex
coloring, and signal reconstruction problems provide insights into
qualitatively different function classes that can be modeled as sums of
bivariates.
\\ ( https://arxiv.org/abs/2511.20607 ,  2555kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20036 (*cross-listing*)
Date: Tue, 25 Nov 2025 08:04:14 GMT   (1468kb)

Title: Invisible in Search? Auditing Aesthetic Bias in the Visual
 Representation of Holocaust Victims on Google
Authors: Mykola Makhortykh, Tobias Rohrbach, Maryna Sydorova
Categories: cs.CY cs.IR
Comments: 22 pages
\\
 Information retrieval systems, such as search engines, increasingly shape the
representation of the past and present states of social reality. Despite their
importance, these systems face challenges in dealing with the ethical aspects
of representation due to various forms of bias, including aesthetic bias that
perpetuates hegemonic patterns of representation. While most research on
aesthetic bias has examined it in the context of current societal issues, it is
also crucial for historical representation, particularly of sensitive subjects
such as historical atrocities. To address this gap, we conduct a comparative
audit of the visual representation of Holocaust victims on Google. We find that
Google tends to propagate a male-dominated representation of Holocaust victims
with an emphasis on atrocity context, risking rendering invisible
gender-specific suffering and decreasing potential for nurturing empathy. We
also observe a variation in representation across geographic locations,
suggesting that search algorithms may produce their own aesthetic of
victimhood.
\\ ( https://arxiv.org/abs/2511.20036 ,  1468kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20492 (*cross-listing*)
Date: Tue, 25 Nov 2025 16:59:29 GMT   (9kb)

Title: Kleinkram: Open Robotic Data Management
Authors: Cyrill P\"untener, Johann Schwabe, Dominique Garmier, Jonas Frey,
 Marco Hutter
Categories: cs.RO cs.IR
Comments: for associated source code, see
 https://github.com/leggedrobotics/kleinkram
\\
 We introduce Kleinkram, a free and open-source system designed to solve the
challenge of managing massive, unstructured robotic datasets. Designed as a
modular, on-premises cloud solution, Kleinkram enables scalable storage,
indexing, and sharing of datasets, ranging from individual experiments to
large-scale research collections. Kleinkram natively integrates with standard
formats such as ROS bags and MCAP and utilises S3-compatible storage for
flexibility. Beyond storage, Kleinkram features an integrated "Action Runner"
that executes customizable Docker-based workflows for data validation,
curation, and benchmarking. Kleinkram has successfully managed over 30 TB of
data from diverse robotic systems, streamlining the research lifecycle through
a modern web interface and a robust Command Line Interface (CLI).
\\ ( https://arxiv.org/abs/2511.20492 ,  9kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19468 (*cross-listing*)
Date: Sat, 22 Nov 2025 00:28:08 GMT   (186kb)

Title: Towards a future space-based, highly scalable AI infrastructure system
 design
Authors: Blaise Ag\"uera y Arcas, Travis Beals, Maria Biggs, Jessica V. Bloom,
 Thomas Fischbacher, Konstantin Gromov, Urs K\"oster, Rishiraj Pravahan, James
 Manyika
Categories: cs.DC cs.LG
Comments: 19 pages, 4 figures
ACM-class: B.m
\\
 If AI is a foundational general-purpose technology, we should anticipate that
demand for AI compute -- and energy -- will continue to grow. The Sun is by far
the largest energy source in our solar system, and thus it warrants
consideration how future AI infrastructure could most efficiently tap into that
power. This work explores a scalable compute system for machine learning in
space, using fleets of satellites equipped with solar arrays, inter-satellite
links using free-space optics, and Google tensor processing unit (TPU)
accelerator chips. To facilitate high-bandwidth, low-latency inter-satellite
communication, the satellites would be flown in close proximity. We illustrate
the basic approach to formation flight via a 81-satellite cluster of 1 km
radius, and describe an approach for using high-precision ML-based models to
control large-scale constellations. Trillium TPUs are radiation tested. They
survive a total ionizing dose equivalent to a 5 year mission life without
permanent failures, and are characterized for bit-flip errors. Launch costs are
a critical part of overall system cost; a learning curve analysis suggests
launch to low-Earth orbit (LEO) may reach $\lesssim$\$200/kg by the mid-2030s.
\\ ( https://arxiv.org/abs/2511.19468 ,  186kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19479 (*cross-listing*)
Date: Sat, 22 Nov 2025 18:39:25 GMT   (668kb)

Title: Federated Learning Framework for Scalable AI in Heterogeneous HPC and
 Cloud Environments
Authors: Sangam Ghimire, Paribartan Timalsina, Nirjal Bhurtel, Bishal Neupane,
 Bigyan Byanju Shrestha, Subarna Bhattarai, Prajwal Gaire, Jessica Thapa,
 Sudan Jha
Categories: cs.DC cs.LG
\\
 As the demand grows for scalable and privacy-aware AI systems, Federated
Learning (FL) has emerged as a promising solution, allowing decentralized model
training without moving raw data. At the same time, the combination of high-
performance computing (HPC) and cloud infrastructure offers vast computing
power but introduces new complexities, especially when dealing with heteroge-
neous hardware, communication limits, and non-uniform data. In this work, we
present a federated learning framework built to run efficiently across mixed
HPC and cloud environments. Our system addresses key challenges such as system
het- erogeneity, communication overhead, and resource scheduling, while
maintaining model accuracy and data privacy. Through experiments on a hybrid
testbed, we demonstrate strong performance in terms of scalability, fault
tolerance, and convergence, even under non-Independent and Identically
Distributed (non-IID) data distributions and varied hardware. These results
highlight the potential of federated learning as a practical approach to
building scalable Artificial Intelligence (AI) systems in modern, distributed
computing settings.
\\ ( https://arxiv.org/abs/2511.19479 ,  668kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19484 (*cross-listing*)
Date: Sun, 23 Nov 2025 04:39:48 GMT   (145kb)

Title: stable-pretraining-v1: Foundation Model Research Made Simple
Authors: Randall Balestriero, Hugues Van Assel, Sami BuGhanem, Lucas Maes
Categories: cs.SE cs.LG
\\
 Foundation models and self-supervised learning (SSL) have become central to
modern AI, yet research in this area remains hindered by complex codebases,
redundant re-implementations, and the heavy engineering burden of scaling
experiments. We present stable-pretraining, a modular, extensible, and
performance-optimized library built on top of PyTorch, Lightning, Hugging Face,
and TorchMetrics. Unlike prior toolkits focused narrowly on reproducing
state-of-the-art results, stable-pretraining is designed for flexibility and
iteration speed: it unifies essential SSL utilities--including probes, collapse
detection metrics, augmentation pipelines, and extensible evaluation
routines--within a coherent and reliable framework. A central design principle
is logging everything, enabling fine-grained visibility into training dynamics
that makes debugging, monitoring, and reproducibility seamless. We validate the
library by demonstrating its ability to generate new research insights with
minimal overhead, including depthwise representation probing and the analysis
of CLIP degradation under synthetic data finetuning. By lowering barriers to
entry while remaining scalable to large experiments, stable-pretraining aims to
accelerate discovery and expand the possibilities of foundation model research.
\\ ( https://arxiv.org/abs/2511.19484 ,  145kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19535 (*cross-listing*)
Date: Mon, 24 Nov 2025 09:54:14 GMT   (630kb)

Title: Masked Autoencoder Joint Learning for Robust Spitzoid Tumor
 Classification
Authors: Il\'an Carretero, Roshni Mahtani, Silvia Perez-Deben, Jos\'e Francisco
 Gonz\'alez-Mu\~noz, Carlos Monteagudo, Valery Naranjo, Roc\'io del Amor
Categories: q-bio.QM cs.LG
Comments: Accepted in CASEIB 2025
\\
 Accurate diagnosis of spitzoid tumors (ST) is critical to ensure a favorable
prognosis and to avoid both under- and over-treatment. Epigenetic data,
particularly DNA methylation, provide a valuable source of information for this
task. However, prior studies assume complete data, an unrealistic setting as
methylation profiles frequently contain missing entries due to limited coverage
and experimental artifacts. Our work challenges these favorable scenarios and
introduces ReMAC, an extension of ReMasker designed to tackle classification
tasks on high-dimensional data under complete and incomplete regimes.
Evaluation on real clinical data demonstrates that ReMAC achieves strong and
robust performance compared to competing classification methods in the
stratification of ST. Code is available:
https://github.com/roshni-mahtani/ReMAC.
\\ ( https://arxiv.org/abs/2511.19535 ,  630kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19628 (*cross-listing*)
Date: Mon, 24 Nov 2025 19:03:43 GMT   (40001kb)

Title: Optimization and Regularization Under Arbitrary Objectives
Authors: Jared N. Lakhani, Etienne Pienaar
Categories: stat.ML cs.LG stat.CO
Comments: 46 pages, 28 figures, 16 tables
\\
 This study investigates the limitations of applying Markov Chain Monte Carlo
(MCMC) methods to arbitrary objective functions, focusing on a two-block MCMC
framework which alternates between Metropolis-Hastings and Gibbs sampling.
While such approaches are often considered advantageous for enabling
data-driven regularization, we show that their performance critically depends
on the sharpness of the employed likelihood form. By introducing a sharpness
parameter and exploring alternative likelihood formulations proportional to the
target objective function, we demonstrate how likelihood curvature governs both
in-sample performance and the degree of regularization inferred by the training
data. Empirical applications are conducted on reinforcement learning tasks:
including a navigation problem and the game of tic-tac-toe. The study concludes
with a separate analysis examining the implications of extreme likelihood
sharpness on arbitrary objective functions stemming from the classic game of
blackjack, where the first block of the two-block MCMC framework is replaced
with an iterative optimization step. The resulting hybrid approach achieves
performance nearly identical to the original MCMC framework, indicating that
excessive likelihood sharpness effectively collapses posterior mass onto a
single dominant mode.
\\ ( https://arxiv.org/abs/2511.19628 ,  40001kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19635 (*cross-listing*)
Date: Mon, 24 Nov 2025 19:10:47 GMT   (1554kb)

Title: Agint: Agentic Graph Compilation for Software Engineering Agents
Authors: Abhi Chivukula, Jay Somasundaram, Vijay Somasundaram
Categories: cs.SE cs.LG
Comments: 18 pages, 5 figures, NeurIPS 2025: Deep Learning for Code in the
 Agentic Era
\\
 LLM-based coding agents are increasingly common but still face challenges in
context management, latency, reliability, reproducibility, and scalability. We
present Agint, an agentic graph compiler, interpreter, and runtime that
incrementally and hierarchically converts natural-language instructions into
typed, effect-aware code DAGs. Agint introduces explicit type floors (text to
data to spec to code) grounded in semantic graph transformations and a hybrid
LLM and function-based JIT runtime. This enables dynamic graph refinement,
reproducible and optimizable execution, speculative evaluation, and
interoperability with existing developer tools. Agint's typed graph bindings
improve reliability and allow concurrent composition of concurrent codebases by
construction, supporting accelerated development with smaller and faster
models, lower latency, efficient context utilization, and higher throughput.
Hierarchical compilation allows scalable graph edits, while the graph structure
supports reproducibility and efficient parallel generation. Agint provides a
composable unix-style toolchain: dagify (DAG compiler), dagent (hybrid JIT
runtime), schemagin (schema generator), and datagin (data transformer) for
realtime, low-latency code and dataflow creation. Human developers and coding
agents refine graphs through the Agint CLI, while non-technical users use Agint
Flow GUI for visual editing, conversational refinement, and debugging to
promote prototype agentic workflows to production code. This continuous
co-creation model allows teams to prototype quickly, refine seamlessly, and
deploy reliably, bridging natural language, compiler methods, and developer
tooling to enable a new generation of composable, team-centric coding agents at
scale.
\\ ( https://arxiv.org/abs/2511.19635 ,  1554kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19716 (*cross-listing*)
Date: Mon, 24 Nov 2025 21:24:40 GMT   (10822kb)

Title: Designing Preconditioners for SGD: Local Conditioning, Noise Floors, and
 Basin Stability
Authors: Mitchell Scott, Tianshi Xu, Ziyuan Tang, Alexandra Pichette-Emmons,
 Qiang Ye, Yousef Saad, and Yuanzhe Xi
Categories: math.NA cs.LG cs.NA
Comments: 31 pages, 11 Figures
MSC-class: Primary 65K10, Secondary 68T05
\\
 Stochastic Gradient Descent (SGD) often slows in the late stage of training
due to anisotropic curvature and gradient noise. We analyze preconditioned SGD
in the geometry induced by a symmetric positive definite matrix $\mathbf{M}$,
deriving bounds in which both the convergence rate and the stochastic noise
floor are governed by $\mathbf{M}$-dependent quantities: the rate through an
effective condition number in the $\mathbf{M}$-metric, and the floor through
the product of that condition number and the preconditioned noise level. For
nonconvex objectives, we establish a preconditioner-dependent basin-stability
guarantee: when smoothness and basin size are measured in the
$\mathbf{M}$-norm, the probability that the iterates remain in a well-behaved
local region admits an explicit lower bound. This perspective is particularly
relevant in Scientific Machine Learning (SciML), where achieving small training
loss under stochastic updates is closely tied to physical fidelity, numerical
stability, and constraint satisfaction. The framework applies to both
diagonal/adaptive and curvature-aware preconditioners and yields a simple
design principle: choose $\mathbf{M}$ to improve local conditioning while
attenuating noise. Experiments on a quadratic diagnostic and three SciML
benchmarks validate the predicted rate-floor behavior.
\\ ( https://arxiv.org/abs/2511.19716 ,  10822kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19717 (*cross-listing*)
Date: Mon, 24 Nov 2025 21:25:40 GMT   (445kb)

Title: Large Scale Community-Aware Network Generation
Authors: Vikram Ramavarapu, Jo\~ao Alfredo Cardoso Lamy, Mohammad Dindoost,
 David A. Bader
Categories: cs.SI cs.LG
Comments: 22 pages, 10 figures, code made available at
 https://github.com/illinois-or-research-analytics/reccs
\\
 Community detection, or network clustering, is used to identify latent
community structure in networks. Due to the scarcity of labeled ground truth in
real-world networks, evaluating these algorithms poses significant challenges.
To address this, researchers use synthetic network generators that produce
networks with ground-truth community labels. RECCS is one such algorithm that
takes a network and its clustering as input and generates a synthetic network
through a modular pipeline. Each generated ground truth cluster preserves key
characteristics of the corresponding input cluster, including connectivity,
minimum degree, and degree sequence distribution. The output consists of a
synthetically generated network, and disjoint ground truth cluster labels for
all nodes. In this paper, we present two enhanced versions: RECCS+ and RECCS++.
RECCS+ maintains algorithmic fidelity to the original RECCS while introducing
parallelization through an orchestrator that coordinates algorithmic components
across multiple processes and employs multithreading. RECCS++ builds upon this
foundation with additional algorithmic optimizations to achieve further
speedup. Our experimental results demonstrate that RECCS+ and RECCS++ achieve
speedups of up to 49x and 139x respectively on our benchmark datasets, with
RECCS++'s additional performance gains involving a modest accuracy tradeoff.
With this newfound performance, RECCS++ can now scale to networks with over 100
million nodes and nearly 2 billion edges.
\\ ( https://arxiv.org/abs/2511.19717 ,  445kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19722 (*cross-listing*)
Date: Mon, 24 Nov 2025 21:34:51 GMT   (43999kb)

Title: Individual and group fairness in geographical partitioning
Authors: Ilya O. Ryzhov and John Gunnar Carlsson and Yinchu Zhu
Categories: econ.EM cs.LG
\\
 Socioeconomic segregation often arises in school districting and other
contexts, causing some groups to be over- or under-represented within a
particular district. This phenomenon is closely linked with disparities in
opportunities and outcomes. We formulate a new class of geographical
partitioning problems in which the population is heterogeneous, and it is
necessary to ensure fair representation for each group at each facility. We
prove that the optimal solution is a novel generalization of the additively
weighted Voronoi diagram, and we propose a simple and efficient algorithm to
compute it, thus resolving an open question dating back to Dvoretzky et al.
(1951). The efficacy and potential for practical insight of the approach are
demonstrated in a realistic case study involving seven demographic groups and
$78$ district offices.
\\ ( https://arxiv.org/abs/2511.19722 ,  43999kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19735 (*cross-listing*)
Date: Mon, 24 Nov 2025 21:51:52 GMT   (2753kb)

Title: Integrating RCTs, RWD, AI/ML and Statistics: Next-Generation Evidence
 Synthesis
Authors: Shu Yang, Margaret Gamalo, Haoda Fu
Categories: stat.ME cs.LG
\\
 Randomized controlled trials (RCTs) have been the cornerstone of clinical
evidence; however, their cost, duration, and restrictive eligibility criteria
limit power and external validity. Studies using real-world data (RWD),
historically considered less reliable for establishing causality, are now
recognized to be important for generating real-world evidence (RWE). In
parallel, artificial intelligence and machine learning (AI/ML) are being
increasingly used throughout the drug development process, providing
scalability and flexibility but also presenting challenges in interpretability
and rigor that traditional statistics do not face. This Perspective argues that
the future of evidence generation will not depend on RCTs versus RWD, or
statistics versus AI/ML, but on their principled integration. To this end, a
causal roadmap is needed to clarify inferential goals, make assumptions
explicit, and ensure transparency about tradeoffs. We highlight key objectives
of integrative evidence synthesis, including transporting RCT results to
broader populations, embedding AI-assisted analyses within RCTs, designing
hybrid controlled trials, and extending short-term RCTs with long-term RWD. We
also outline future directions in privacy-preserving analytics, uncertainty
quantification, and small-sample methods. By uniting statistical rigor with
AI/ML innovation, integrative approaches can produce robust, transparent, and
policy-relevant evidence, making them a key component of modern regulatory
science.
\\ ( https://arxiv.org/abs/2511.19735 ,  2753kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19740 (*cross-listing*)
Date: Mon, 24 Nov 2025 21:57:11 GMT   (1901kb)

Title: CAMformer: Associative Memory is All You Need
Authors: Tergel Molom-Ochir, Benjamin F. Morris, Mark Horton, Chiyue Wei, Cong
 Guo, Brady Taylor, Peter Liu, Shan X. Wang, Deliang Fan, Hai Helen Li, and
 Yiran Chen
Categories: cs.AR cs.LG
Comments: 7 pages, 10 figures
\\
 Transformers face scalability challenges due to the quadratic cost of
attention, which involves dense similarity computations between queries and
keys. We propose CAMformer, a novel accelerator that reinterprets attention as
an associative memory operation and computes attention scores using a
voltage-domain Binary Attention Content Addressable Memory (BA-CAM). This
enables constant-time similarity search through analog charge sharing,
replacing digital arithmetic with physical similarity sensing. CAMformer
integrates hierarchical two-stage top-k filtering, pipelined execution, and
high-precision contextualization to achieve both algorithmic accuracy and
architectural efficiency. Evaluated on BERT and Vision Transformer workloads,
CAMformer achieves over 10x energy efficiency, up to 4x higher throughput, and
6-8x lower area compared to state-of-the-art accelerators--while maintaining
near-lossless accuracy.
\\ ( https://arxiv.org/abs/2511.19740 ,  1901kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19755 (*cross-listing*)
Date: Mon, 24 Nov 2025 22:18:23 GMT   (920kb)

Title: Clustering Approaches for Mixed-Type Data: A Comparative Study
Authors: Badih Ghattas, Alvaro Sanchez San-Benito
Categories: stat.ML cs.LG stat.AP stat.ME
Journal-ref: Journal of Probability and Statistics, 2025
DOI: 10.1155/jpas/2242100
\\
 Clustering is widely used in unsupervised learning to find homogeneous groups
of observations within a dataset. However, clustering mixed-type data remains a
challenge, as few existing approaches are suited for this task. This study
presents the state-of-the-art of these approaches and compares them using
various simulation models. The compared methods include the distance-based
approaches k-prototypes, PDQ, and convex k-means, and the probabilistic methods
KAy-means for MIxed LArge data (KAMILA), the mixture of Bayesian networks
(MBNs), and latent class model (LCM). The aim is to provide insights into the
behavior of different methods across a wide range of scenarios by varying some
experimental factors such as the number of clusters, cluster overlap, sample
size, dimension, proportion of continuous variables in the dataset, and
clusters' distribution. The degree of cluster overlap and the proportion of
continuous variables in the dataset and the sample size have a significant
impact on the observed performances. When strong interactions exist between
variables alongside an explicit dependence on cluster membership, none of the
evaluated methods demonstrated satisfactory performance. In our experiments
KAMILA, LCM, and k-prototypes exhibited the best performance, with respect to
the adjusted rand index (ARI). All the methods are available in R.
\\ ( https://arxiv.org/abs/2511.19755 ,  920kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19805 (*cross-listing*)
Date: Tue, 25 Nov 2025 00:20:04 GMT   (2861kb)

Title: Latent-space metrics for Complex-Valued VAE out-of-distribution
 detection under radar clutter
Authors: Y. A. Rouzoumka, E. Terreaux, C. Morisseau, J.-P. Ovarlez, C. Ren
Categories: eess.SP cs.LG stat.ML
Comments: Under review at ICASSP 2026
\\
 We investigate complex-valued Variational AutoEncoders (CVAE) for radar
Out-Of-Distribution (OOD) detection in complex radar environments. We proposed
several detection metrics: the reconstruction error of CVAE (CVAE-MSE), the
latent-based scores (Mahalanobis, Kullback-Leibler divergence (KLD)), and
compared their performance against the classical ANMF-Tyler detector (ANMF-FP).
The performance of all these detectors is analyzed on synthetic and
experimental radar data, showing the advantages and the weaknesses of each
detector.
\\ ( https://arxiv.org/abs/2511.19805 ,  2861kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19879 (*cross-listing*)
Date: Tue, 25 Nov 2025 03:40:01 GMT   (3642kb)

Title: Learning Degenerate Manifolds of Frustrated Magnets with Boltzmann
 Machines
Authors: Jackson C. Glass and Gia-Wei Chern
Categories: cond-mat.str-el cond-mat.stat-mech cs.LG
Comments: 12 pages, 10 figures
\\
 We show that Restricted Boltzmann Machines (RBMs) provide a flexible
generative framework for modeling spin configurations in disordered yet
strongly correlated phases of frustrated magnets. As a benchmark, we first
demonstrate that an RBM can learn the zero-temperature ground-state manifold of
the one-dimensional ANNNI model at its multiphase point, accurately reproducing
its characteristic oscillatory and exponentially decaying correlations. We then
apply RBMs to kagome spin ice and show that they successfully learn the local
ice rules and short-range correlations of the extensively degenerate ice-I
manifold. Correlation functions computed from RBM-generated configurations
closely match those from direct Monte Carlo simulations. For the partially
ordered ice-II phase -- featuring long-range charge order and broken
time-reversal symmetry -- accurate modeling requires RBMs with uniform-sign
bias fields, mirroring the underlying symmetry breaking. These results
highlight the utility of RBMs as generative models for learning constrained and
highly frustrated magnetic states.
\\ ( https://arxiv.org/abs/2511.19879 ,  3642kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19885 (*cross-listing*)
Date: Tue, 25 Nov 2025 03:45:34 GMT   (24670kb)

Title: Complex Instruction Following with Diverse Style Policies in Football
 Games
Authors: Chenglu Sun, Shuo Shen, Haonan Hu, Wei Zhou, Chen Chen
Categories: cs.MA cs.LG
Comments: 21 pages, 13 figures, accepted by AAAI2026
\\
 Despite advancements in language-controlled reinforcement learning (LC-RL)
for basic domains and straightforward commands (e.g., object manipulation and
navigation), effectively extending LC-RL to comprehend and execute high-level
or abstract instructions in complex, multi-agent environments, such as football
games, remains a significant challenge. To address this gap, we introduce
Language-Controlled Diverse Style Policies (LCDSP), a novel LC-RL paradigm
specifically designed for complex scenarios. LCDSP comprises two key
components: a Diverse Style Training (DST) method and a Style Interpreter (SI).
The DST method efficiently trains a single policy capable of exhibiting a wide
range of diverse behaviors by modulating agent actions through style parameters
(SP). The SI is designed to accurately and rapidly translate high-level
language instructions into these corresponding SP. Through extensive
experiments in a complex 5v5 football environment, we demonstrate that LCDSP
effectively comprehends abstract tactical instructions and accurately executes
the desired diverse behavioral styles, showcasing its potential for complex,
real-world applications.
\\ ( https://arxiv.org/abs/2511.19885 ,  24670kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19930 (*cross-listing*)
Date: Tue, 25 Nov 2025 05:15:20 GMT   (2794kb)

Title: Designing Reputation Systems for Manufacturing Data Trading Markets: A
 Multi-Agent Evaluation with Q-Learning and IRL-Estimated Utilities
Authors: Kenta Yamamoto, Teruaki Hayashi
Categories: cs.GT cs.CY cs.LG
Comments: 10 pages, 10 figures
\\
 Recent advances in machine learning and big data analytics have intensified
the demand for high-quality cross-domain datasets and accelerated the growth of
data trading across organizations. As data become increasingly recognized as an
economic asset, data marketplaces have emerged as a key infrastructure for
data-driven innovation. However, unlike mature product or service markets,
data-trading environments remain nascent and suffer from pronounced information
asymmetry. Buyers cannot verify the content or quality before purchasing data,
making trust and quality assurance central challenges. To address these issues,
this study develops a multi-agent data-market simulator that models participant
behavior and evaluates the institutional mechanisms for trust formation.
Focusing on the manufacturing sector, where initiatives such as GAIA-X and
Catena-X are advancing, the simulator integrates reinforcement learning (RL)
for adaptive agent behavior and inverse reinforcement learning (IRL) to
estimate utility functions from empirical behavioral data. Using the simulator,
we examine the market-level effects of five representative reputation
systems-Time-decay, Bayesian-beta, PageRank, PowerTrust, and PeerTrust-and
found that PeerTrust achieved the strongest alignment between data price and
quality, while preventing monopolistic dominance. Building on these results, we
develop a hybrid reputation mechanism that integrates the strengths of existing
systems to achieve improved price-quality consistency and overall market
stability. This study extends simulation-based data-market analysis by
incorporating trust and reputation as endogenous mechanisms and offering
methodological and institutional insights into the design of reliable and
efficient data ecosystems.
\\ ( https://arxiv.org/abs/2511.19930 ,  2794kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20038 (*cross-listing*)
Date: Tue, 25 Nov 2025 08:08:39 GMT   (79kb)

Title: Softmax Transformers are Turing-Complete
Authors: Hongjian Jiang, Michael Hahn, Georg Zetzsche, Anthony Widjaja Lin
Categories: cs.FL cs.LG cs.LO
\\
 Hard attention Chain-of-Thought (CoT) transformers are known to be
Turing-complete. However, it is an open problem whether softmax attention
Chain-of-Thought (CoT) transformers are Turing-complete. In this paper, we
prove a stronger result that length-generalizable softmax CoT transformers are
Turing-complete. More precisely, our Turing-completeness proof goes via the CoT
extension of the Counting RASP (C-RASP), which correspond to softmax CoT
transformers that admit length generalization. We prove Turing-completeness for
CoT C-RASP with causal masking over a unary alphabet (more generally, for
letter-bounded languages). While we show this is not Turing-complete for
arbitrary languages, we prove that its extension with relative positional
encoding is Turing-complete for arbitrary languages. We empirically validate
our theory by training transformers for languages requiring complex
(non-linear) arithmetic reasoning.
\\ ( https://arxiv.org/abs/2511.20038 ,  79kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20237 (*cross-listing*)
Date: Tue, 25 Nov 2025 12:11:34 GMT   (7345kb)

Title: Quantum-Enhanced Reinforcement Learning for Accelerating Newton-Raphson
 Convergence with Ising Machines: A Case Study for Power Flow Analysis
Authors: Zeynab Kaseb, Matthias Moller, Lindsay Spoor, Jerry J. Guo, Yu Xiang,
 Peter Palensky, and Pedro P. Vergara
Categories: eess.SY cs.ET cs.LG cs.SY
Comments: 10 pages, 9 figures, 4 tables
\\
 The Newton-Raphson (NR) method is widely used for solving power flow (PF)
equations due to its quadratic convergence. However, its performance
deteriorates under poor initialization or extreme operating scenarios, e.g.,
high levels of renewable energy penetration. Traditional NR initialization
strategies often fail to address these challenges, resulting in slow
convergence or even divergence. We propose the use of reinforcement learning
(RL) to optimize the initialization of NR, and introduce a novel
quantum-enhanced RL environment update mechanism to mitigate the significant
computational cost of evaluating power system states over a combinatorially
large action space at each RL timestep by formulating the voltage adjustment
task as a quadratic unconstrained binary optimization problem. Specifically,
quantum/digital annealers are integrated into the RL environment update to
evaluate state transitions using a problem Hamiltonian designed for PF. Results
demonstrate significant improvements in convergence speed, a reduction in NR
iteration counts, and enhanced robustness under different operating conditions.
\\ ( https://arxiv.org/abs/2511.20237 ,  7345kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20283 (*cross-listing*)
Date: Tue, 25 Nov 2025 13:11:03 GMT   (865kb)

Title: Solving Heterogeneous Agent Models with Physics-informed Neural Networks
Authors: Marta Grzeskiewicz
Categories: econ.GN cs.LG q-fin.EC
\\
 Understanding household behaviour is essential for modelling macroeconomic
dynamics and designing effective policy. While heterogeneous agent models offer
a more realistic alternative to representative agent frameworks, their
implementation poses significant computational challenges, particularly in
continuous time. The Aiyagari-Bewley-Huggett (ABH) framework, recast as a
system of partial differential equations, typically relies on grid-based
solvers that suffer from the curse of dimensionality, high computational cost,
and numerical inaccuracies. This paper introduces the ABH-PINN solver, an
approach based on Physics-Informed Neural Networks (PINNs), which embeds the
Hamilton-Jacobi-Bellman and Kolmogorov Forward equations directly into the
neural network training objective. By replacing grid-based approximation with
mesh-free, differentiable function learning, the ABH-PINN solver benefits from
the advantages of PINNs of improved scalability, smoother solutions, and
computational efficiency. Preliminary results show that the PINN-based approach
is able to obtain economically valid results matching the established
finite-difference solvers.
\\ ( https://arxiv.org/abs/2511.20283 ,  865kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20361 (*cross-listing*)
Date: Tue, 25 Nov 2025 14:43:13 GMT   (11281kb)

Title: Extension and neural operator approximation of the electrical impedance
 tomography inverse map
Authors: Maarten V. de Hoop, Nikola B. Kovachki, Matti Lassas, Nicholas H.
 Nelsen
Categories: math.NA cs.LG cs.NA math.AP
Comments: 80 pages (49 main text, 20 appendix, and 11 references pages), 14
 figures, 2 tables
MSC-class: 35R30 (Primary), 65N21, 68T07 (Secondary)
\\
 This paper considers the problem of noise-robust neural operator
approximation for the solution map of Calder\'on's inverse conductivity
problem. In this continuum model of electrical impedance tomography (EIT), the
boundary measurements are realized as a noisy perturbation of the
Neumann-to-Dirichlet map's integral kernel. The theoretical analysis proceeds
by extending the domain of the inversion operator to a Hilbert space of kernel
functions. The resulting extension shares the same stability properties as the
original inverse map from kernels to conductivities, but is now amenable to
neural operator approximation. Numerical experiments demonstrate that Fourier
neural operators excel at reconstructing infinite-dimensional piecewise
constant and lognormal conductivities in noisy setups both within and beyond
the theory's assumptions. The methodology developed in this paper for EIT
exemplifies a broader strategy for addressing nonlinear inverse problems with a
noise-aware operator learning framework.
\\ ( https://arxiv.org/abs/2511.20361 ,  11281kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20380 (*cross-listing*)
Date: Tue, 25 Nov 2025 15:01:55 GMT   (233kb)

Title: Differentiable Attenuation Filters for Feedback Delay Networks
Authors: Ilias Ibnyahya, Joshua D. Reiss
Categories: cs.SD cs.LG
\\
 We introduce a novel method for designing attenuation filters in digital
audio reverberation systems based on Feedback Delay Net- works (FDNs). Our
approach uses Second Order Sections (SOS) of Infinite Impulse Response (IIR)
filters arranged as parametric equalizers (PEQ), enabling fine control over
frequency-dependent reverberation decay. Unlike traditional graphic equalizer
designs, which require numerous filters per delay line, we propose a scal- able
solution where the number of filters can be adjusted. The fre- quency, gain,
and quality factor (Q) parameters are shared parame- ters across delay lines
and only the gain is adjusted based on delay length. This design not only
reduces the number of optimization parameters, but also remains fully
differentiable and compatible with gradient-based learning frameworks.
Leveraging principles of analog filter design, our method allows for efficient
and accu- rate filter fitting using supervised learning. Our method delivers a
flexible and differentiable design, achieving state-of-the-art per- formance
while significantly reducing computational cost.
\\ ( https://arxiv.org/abs/2511.20380 ,  233kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20457 (*cross-listing*)
Date: Tue, 25 Nov 2025 16:24:52 GMT   (142kb)

Title: A Fully Probabilistic Tensor Network for Regularized Volterra System
 Identification
Authors: Afra Kilic, Kim Batselier
Categories: stat.ML cs.LG
Comments: 6 pages, 3 figures, 1 table. Submitted to IFAC 2026. Code available
 at: https://github.com/afrakilic/BTN_Volterra_Sys_ID
\\
 Modeling nonlinear systems with Volterra series is challenging because the
number of kernel coefficients grows exponentially with the model order. This
work introduces Bayesian Tensor Network Volterra kernel machines (BTN-V),
extending the Bayesian Tensor Network framework to Volterra system
identification. BTN-V represents Volterra kernels using canonical polyadic
decomposition, reducing model complexity from O(I^D) to O(DIR). By treating all
tensor components and hyperparameters as random variables, BTN-V provides
predictive uncertainty estimation at no additional computational cost.
Sparsity-inducing hierarchical priors enable automatic rank determination and
the learning of fading-memory behavior directly from data, improving
interpretability and preventing overfitting. Empirical results demonstrate
competitive accuracy, enhanced uncertainty quantification, and reduced
computational cost.
\\ ( https://arxiv.org/abs/2511.20457 ,  142kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20489 (*cross-listing*)
Date: Tue, 25 Nov 2025 16:55:43 GMT   (1447kb)

Title: InferF: Declarative Factorization of AI/ML Inferences over Joins
Authors: Kanchan Chowdhury, Lixi Zhou, Lulu Xie, Xinwei Fu, Jia Zou
Categories: cs.DB cs.LG
Comments: Accepted to SIGMOD 2026 as full research paper. This archived version
 has a full appendix
\\
 Real-world AI/ML workflows often apply inference computations to feature
vectors joined from multiple datasets. To avoid the redundant AI/ML
computations caused by repeated data records in the join's output, factorized
ML has been proposed to decompose ML computations into sub-computations to be
executed on each normalized dataset. However, there is insufficient discussion
on how factorized ML could impact AI/ML inference over multi-way joins. To
address the limitations, we propose a novel declarative InferF system, focusing
on the factorization of arbitrary inference workflows represented as analyzable
expressions over the multi-way joins. We formalize our problem to flexibly push
down partial factorized computations to qualified nodes in the join tree to
minimize the overall inference computation and join costs and propose two
algorithms to resolve the problem: (1) a greedy algorithm based on a per-node
cost function that estimates the influence on overall latency if a subset of
factorized computations is pushed to a node, and (2) a genetic algorithm for
iteratively enumerating and evaluating promising factorization plans. We
implement InferF on Velox, an open-sourced database engine from Meta, evaluate
it on real-world datasets, observed up to 11.3x speedups, and systematically
summarized the factors that determine when factorized ML can benefit AI/ML
inference workflows.
\\ ( https://arxiv.org/abs/2511.20489 ,  1447kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20503 (*cross-listing*)
Date: Tue, 25 Nov 2025 17:12:42 GMT   (3806kb)

Title: Generative Modeling with Manifold Percolation
Authors: Rui Tong
Categories: stat.ML cs.LG
Comments: 13 pages, 7 figures. Correspondence: Rui.Tong@warwick.ac.uk
MSC-class: 68T07, 62R30, 60D05
ACM-class: I.2.10; I.4.0; F.2.2
\\
 Generative modeling is typically framed as learning mapping rules, but from
an observer's perspective without access to these rules, the task manifests as
disentangling the geometric support from the probability distribution. We
propose that Continuum Percolation is uniquely suited for this support
analysis, as the sampling process effectively projects high-dimensional density
estimation onto a geometric counting problem on the support. In this work, we
establish a rigorous isomorphism between the topological phase transitions of
Random Geometric Graphs and the underlying data manifold in high-dimensional
space. By analyzing the relationship between our proposed Percolation Shift
metric and FID, we demonstrate that our metric captures structural pathologies
(such as implicit mode collapse) where statistical metrics fail. Finally, we
translate this topological phenomenon into a differentiable loss function to
guide training. Experimental results confirm that this approach not only
prevents manifold shrinkage but drives the model toward a state of
"Hyper-Generalization," achieving good fidelity and verified topological
expansion.
\\ ( https://arxiv.org/abs/2511.20503 ,  3806kb)
------------------------------------------------------------------------------
\\
arXiv:2511.20558 (*cross-listing*)
Date: Tue, 25 Nov 2025 17:56:43 GMT   (9831kb)

Title: Spatio-Temporal Hierarchical Causal Models
Authors: Xintong Li, Haoran Zhang, Xiao Zhou
Categories: stat.ML cs.LG
\\
 The abundance of fine-grained spatio-temporal data, such as traffic sensor
networks, offers vast opportunities for scientific discovery. However,
inferring causal relationships from such observational data remains
challenging, particularly due to unobserved confounders that are specific to
units (e.g., geographical locations) yet influence outcomes over time. Most
existing methods for spatio-temporal causal inference assume that all
confounders are observed, an assumption that is often violated in practice. In
this paper, we introduce Spatio-Temporal Hierarchical Causal Models (ST-HCMs),
a novel graphical framework that extends hierarchical causal modeling to the
spatio-temporal domain. At the core of our approach is the Spatio-Temporal
Collapse Theorem, which shows that a complex ST-HCM converges to a simpler flat
causal model as the amount of subunit data increases. This theoretical result
enables a general procedure for causal identification, allowing ST-HCMs to
recover causal effects even in the presence of unobserved, time-invariant
unit-level confounders, a scenario where standard non-hierarchical models fail.
We validate the effectiveness of our framework on both synthetic and real-world
datasets, demonstrating its potential for robust causal inference in complex
dynamic systems.
\\ ( https://arxiv.org/abs/2511.20558 ,  9831kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2408.11515
replaced with revised version Mon, 24 Nov 2025 13:56:56 GMT   (7379kb)

Title: Quantifying Behavioral Dissimilarity Between Mathematical Expressions
Authors: Sebastian Me\v{z}nar, Sa\v{s}o D\v{z}eroski, Ljup\v{c}o Todorovski
Categories: cs.AI
Comments: 43 pages, 11 figures, 3 table, 5 appendices. Submitted to Elsevier's
 Information Sciences
MSC-class: 68T01
ACM-class: I.1.1; I.2.0
\\ ( https://arxiv.org/abs/2408.11515 ,  7379kb)
------------------------------------------------------------------------------
\\
arXiv:2409.14993
replaced with revised version Tue, 25 Nov 2025 18:43:50 GMT   (2452kb)

Title: Multi-modal Generative AI: Multi-modal LLMs, Diffusions, and the
 Unification
Authors: Xin Wang, Yuwei Zhou, Bin Huang, Hong Chen, and Wenwu Zhu
Categories: cs.AI cs.CV
Comments: 21 pages, 10 figures, 3 tables
Journal-ref: IEEE Transactions on Circuits and Systems for Video Technology
 2025
DOI: 10.1109/TCSVT.2025.3635224
\\ ( https://arxiv.org/abs/2409.14993 ,  2452kb)
------------------------------------------------------------------------------
\\
arXiv:2410.05130
replaced with revised version Tue, 25 Nov 2025 13:44:03 GMT   (952kb)

Title: Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents
Authors: Yuwei Hu, Runlin Lei, Xinyi Huang, Zhewei Wei, Yongchao Liu
Categories: cs.AI
Comments: Accepted by AAAI 2026 Workshop WMAC
\\ ( https://arxiv.org/abs/2410.05130 ,  952kb)
------------------------------------------------------------------------------
\\
arXiv:2412.05718
replaced with revised version Tue, 25 Nov 2025 07:32:45 GMT   (1209kb)

Title: RLZero: Direct Policy Inference from Language Without In-Domain
 Supervision
Authors: Harshit Sikchi, Siddhant Agarwal, Pranaya Jajoo, Samyak Parajuli,
 Caleb Chuck, Max Rudolph, Peter Stone, Amy Zhang, Scott Niekum
Categories: cs.AI cs.GR cs.LG cs.RO
Comments: NeurIPS 2025, 26 pages
\\ ( https://arxiv.org/abs/2412.05718 ,  1209kb)
------------------------------------------------------------------------------
\\
arXiv:2412.18428
replaced with revised version Tue, 25 Nov 2025 12:20:37 GMT   (7064kb)

Title: Multi-Modal Data Exploration via Language Agents
Authors: Farhad Nooralahzadeh, Yi Zhang, Jonathan Furst, Kurt Stockinger
Categories: cs.AI cs.CL
Comments: Accepted to the IJCNLP AACL 2025 Findings
\\ ( https://arxiv.org/abs/2412.18428 ,  7064kb)
------------------------------------------------------------------------------
\\
arXiv:2502.19546
replaced with revised version Mon, 24 Nov 2025 00:05:26 GMT   (5678kb)

Title: CNS-Obsidian: A Neurosurgical Vision-Language Model Built From
 Scientific Publications
Authors: Anton Alyakin, Jaden Stryker, Daniel Alexander Alber, Jin Vivian Lee,
 Karl L. Sangwon, Brandon Duderstadt, Akshay Save, David Kurland, Spencer
 Frome, Shrutika Singh, Jeff Zhang, Eunice Yang, Ki Yun Park, Cordelia
 Orillac, Aly A. Valliani, Sean Neifert, Albert Liu, Aneek Patel, Christopher
 Livia, Darryl Lau, Ilya Laufer, Peter A. Rozman, Eveline Teresa Hidalgo,
 Howard Riina, Rui Feng, Todd Hollon, Yindalon Aphinyanaphongs, John G.
 Golfinos, Laura Snyder, Eric Leuthardt, Douglas Kondziolka, Eric Karl Oermann
Categories: cs.AI cs.CL cs.HC
\\ ( https://arxiv.org/abs/2502.19546 ,  5678kb)
------------------------------------------------------------------------------
\\
arXiv:2503.15815
replaced with revised version Tue, 25 Nov 2025 02:08:44 GMT   (475kb)

Title: Attention Pruning: Automated Fairness Repair of Language Models via
 Surrogate Simulated Annealing
Authors: Vishnu Asutosh Dasu, Md Rafi ur Rashid, Vipul Gupta, Saeid
 Tizpaz-Niari, Gang Tan
Categories: cs.AI
\\ ( https://arxiv.org/abs/2503.15815 ,  475kb)
------------------------------------------------------------------------------
\\
arXiv:2504.14209
replaced with revised version Tue, 25 Nov 2025 06:04:27 GMT   (9614kb)

Title: Energy-Aware Pattern Disentanglement: A Generalizable Pattern Assisted
 Architecture for Multi-task Time Series Analysis
Authors: Xiangkai Ma, Xiaobin Hong, Wenzhong Li, Sanglu Lu
Categories: cs.AI
Comments: We have updated the abstract, citations and related work. At the same
 time, we have also updated the latest baseline model
\\ ( https://arxiv.org/abs/2504.14209 ,  9614kb)
------------------------------------------------------------------------------
\\
arXiv:2505.09341
replaced with revised version Tue, 25 Nov 2025 08:17:10 GMT   (280kb)

Title: Access Controls Will Solve the Dual-Use Dilemma
Authors: Ev\v{z}en Wybitul
Categories: cs.AI
Comments: Accepted at ICML 2025 Workshop on Technical AI Governance (TAIG)
\\ ( https://arxiv.org/abs/2505.09341 ,  280kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23575
replaced with revised version Mon, 24 Nov 2025 22:11:07 GMT   (3462kb)

Title: CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring
Authors: Benjamin Arnav, Pablo Bernabeu-P\'erez, Nathan Helm-Burger, Tim
 Kostolansky, Hannes Whittingham, Mary Phuong
Categories: cs.AI cs.LG
Comments: To be published in the 39th Conference on Neural Information
 Processing Systems (NeurIPS 2025)
\\ ( https://arxiv.org/abs/2505.23575 ,  3462kb)
------------------------------------------------------------------------------
\\
arXiv:2506.05587
replaced with revised version Tue, 25 Nov 2025 01:41:49 GMT   (3998kb)

Title: MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark
Authors: Junjie Xing, Yeye He, Mengyu Zhou, Haoyu Dong, Shi Han, Lingjiao Chen,
 Dongmei Zhang, Surajit Chaudhuri, H. V. Jagadish
Categories: cs.AI cs.CL cs.DB cs.LG
Comments: Accepted at NeurIPS 2025; Code and data available at
 https://github.com/MMTU-Benchmark/MMTU and
 https://huggingface.co/datasets/MMTU-benchmark/MMTU
\\ ( https://arxiv.org/abs/2506.05587 ,  3998kb)
------------------------------------------------------------------------------
\\
arXiv:2507.10007
replaced with revised version Tue, 25 Nov 2025 02:54:52 GMT   (510kb)

Title: Deep Hidden Cognition Facilitates Reliable Chain-of-Thought Reasoning
Authors: Zijun Chen, Wenbo Hu, Richang Hong
Categories: cs.AI
Comments: This paper has been accepted by AAAI-26
\\ ( https://arxiv.org/abs/2507.10007 ,  510kb)
------------------------------------------------------------------------------
\\
arXiv:2507.17777
replaced with revised version Tue, 25 Nov 2025 08:35:33 GMT   (4136kb)

Title: ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid
 Mechanics
Authors: Theofanis Aravanis, Grigorios Chrimatopoulos, Mohammad Ferdows,
 Michalis Xenos, Efstratios Em Tzirtzilakis
Categories: cs.AI
Comments: This research was implemented in the framework of the Action
 "Flagship actions in interdisciplinary scientific fields with a special focus
 on the productive fabric'', which is implemented through the National
 Recovery and Resilience Fund Greece 2.0 and funded by the European
 Union--NextGenerationEU (Project ID: TAEDR-0535983)
MSC-class: 76A02
\\ ( https://arxiv.org/abs/2507.17777 ,  4136kb)
------------------------------------------------------------------------------
\\
arXiv:2508.04652
replaced with revised version Mon, 24 Nov 2025 20:01:23 GMT   (570kb)

Title: LLM Collaboration With Multi-Agent Reinforcement Learning
Authors: Shuo Liu, Tianle Chen, Zeyu Liang, Xueguang Lyu, Christopher Amato
Categories: cs.AI cs.SE
\\ ( https://arxiv.org/abs/2508.04652 ,  570kb)
------------------------------------------------------------------------------
\\
arXiv:2510.23506
replaced with revised version Tue, 25 Nov 2025 15:47:59 GMT   (4057kb)

Title: Emotion-Coherent Reasoning for Multimodal LLMs via Emotional Rationale
 Verifier
Authors: Hyeongseop Rha, Jeong Hun Yeo, Yeonju Kim, Yong Man Ro
Categories: cs.AI cs.HC
Comments: 16 pages, 11 figures
\\ ( https://arxiv.org/abs/2510.23506 ,  4057kb)
------------------------------------------------------------------------------
\\
arXiv:2510.24151
replaced with revised version Tue, 25 Nov 2025 08:50:19 GMT   (2312kb)

Title: BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning
 Questions from Semi-structured Data
Authors: Bingsen Qiu, Zijian Liu, Xiao Liu, Bingjie Wang, Feier Zhang, Yixuan
 Qin, Chunyan Li, Haoshen Yang, Zeren Gao
Categories: cs.AI
\\ ( https://arxiv.org/abs/2510.24151 ,  2312kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04500
replaced with revised version Mon, 24 Nov 2025 20:04:15 GMT   (248kb)

Title: Large language models replicate and predict human cooperation across
 experiments in game theory
Authors: Andrea Cera Palatsi, Samuel Martin-Gutierrez, Ana S. Cardenal, Max
 Pellert
Categories: cs.AI cs.CL cs.GT cs.MA
\\ ( https://arxiv.org/abs/2511.04500 ,  248kb)
------------------------------------------------------------------------------
\\
arXiv:2511.10037
replaced with revised version Tue, 25 Nov 2025 07:15:31 GMT   (564kb)

Title: Beyond ReAct: A Planner-Centric Framework for Complex Tool-Augmented LLM
 Reasoning
Authors: Xiaolong Wei, Yuehu Dong, Xingliang Wang, Xingyu Zhang, Zhejun Zhao,
 Dongdong Shen, Long Xia, Dawei Yin
Categories: cs.AI
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2511.10037 ,  564kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12937
replaced with revised version Mon, 24 Nov 2025 07:51:46 GMT   (10102kb)

Title: Yanyun-3: Enabling Cross-Platform Strategy Game Operation with
 Vision-Language Models
Authors: Guoyan Wang, Yanyan Huang, Chunlin Chen, Lifeng Wang, Yuxiang Sun
Categories: cs.AI cs.CV
Comments: 32 pages, 13 figures
ACM-class: I.2.7; I.2.10; I.6.8; H.5.2
\\ ( https://arxiv.org/abs/2511.12937 ,  10102kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14730
replaced with revised version Tue, 25 Nov 2025 04:33:37 GMT   (431kb)

Title: Heterogeneous Multi-Agent Proximal Policy Optimization for Power
 Distribution System Restoration
Authors: Parya Dolatyabi, Mahdi Khodayar
Categories: cs.AI
Comments: 6 pages, 4 figures, TPEC 2025 Conference
\\ ( https://arxiv.org/abs/2511.14730 ,  431kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15974
replaced with revised version Tue, 25 Nov 2025 00:53:19 GMT   (2242kb)

Title: KRAL: Knowledge and Reasoning Augmented Learning for LLM-assisted
 Clinical Antimicrobial Therapy
Authors: Zhe Li, Yehan Qiu, Yujie Chen, Xiang Zhou
Categories: cs.AI
\\ ( https://arxiv.org/abs/2511.15974 ,  2242kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17673
replaced with revised version Tue, 25 Nov 2025 01:09:40 GMT   (999kb)

Title: Bridging Symbolic Control and Neural Reasoning in LLM Agents: The
 Structured Cognitive Loop
Authors: Myung Ho Kim
Categories: cs.AI cs.CL
Comments: Polished the abstract and replaced the demonstration screenshots
\\ ( https://arxiv.org/abs/2511.17673 ,  999kb)
------------------------------------------------------------------------------
\\
arXiv:2406.12131
replaced with revised version Mon, 24 Nov 2025 18:04:25 GMT   (8302kb)

Title: Gram2Vec: An Interpretable Document Vectorizer
Authors: Peter Zeng, Hannah Stortz, Eric Sclafani, Alina Shabaeva, Maria
 Elizabeth Garza, Daniel Greeson Owen Rambow
Categories: cs.CL
Comments: 8 pages, 1 figure
\\ ( https://arxiv.org/abs/2406.12131 ,  8302kb)
------------------------------------------------------------------------------
\\
arXiv:2410.13334
replaced with revised version Tue, 25 Nov 2025 12:39:17 GMT   (1565kb)

Title: BiasJailbreak:Analyzing Ethical Biases and Jailbreak Vulnerabilities in
 Large Language Models
Authors: Isack Lee, Haebin Seong
Categories: cs.CL cs.AI cs.LG
Comments: Accepted as a workshop paper at AAAI 2026
\\ ( https://arxiv.org/abs/2410.13334 ,  1565kb)
------------------------------------------------------------------------------
\\
arXiv:2501.12051
replaced with revised version Tue, 25 Nov 2025 09:16:45 GMT   (661kb)

Title: MedS$^3$: Towards Medical Slow Thinking with Self-Evolved Soft
 Dual-sided Process Supervision
Authors: Shuyang Jiang, Yusheng Liao, Zhe Chen, Ya Zhang, Yanfeng Wang, Yu Wang
Categories: cs.CL
Comments: 20 pages;Accepted as a Main paper at AAAI26
\\ ( https://arxiv.org/abs/2501.12051 ,  661kb)
------------------------------------------------------------------------------
\\
arXiv:2503.17407
replaced with revised version Mon, 24 Nov 2025 07:34:34 GMT   (14452kb)

Title: A Comprehensive Survey on Long Context Language Modeling
Authors: Jiaheng Liu, Dawei Zhu, Zhiqi Bai, Yancheng He, Huanxuan Liao, Haoran
 Que, Zekun Wang, Chenchen Zhang, Ge Zhang, Jiebin Zhang, Yuanxing Zhang, Zhuo
 Chen, Hangyu Guo, Shilong Li, Ziqiang Liu, Yong Shan, Yifan Song, Jiayi Tian,
 Wenhao Wu, Zhejian Zhou, Ruijie Zhu, Junlan Feng, Yang Gao, Shizhu He,
 Zhoujun Li, Tianyu Liu, Fanyu Meng, Wenbo Su, Yingshui Tan, Zili Wang, Jian
 Yang, Wei Ye, Bo Zheng, Wangchunshu Zhou, Wenhao Huang, Sujian Li, Zhaoxiang
 Zhang
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2503.17407 ,  14452kb)
------------------------------------------------------------------------------
\\
arXiv:2504.03151
replaced with revised version Tue, 25 Nov 2025 18:35:07 GMT   (3649kb)

Title: Why Reasoning Matters? A Survey of Advancements in Multimodal Reasoning
 (v1)
Authors: Jing Bi, Susan Liang, Xiaofei Zhou, Pinxin Liu, Junjia Guo, Yunlong
 Tang, Luchuan Song, Chao Huang, Ali Vosoughi, Guangyu Sun, Jinxi He, Jiarui
 Wu, Shu Yang, Daoan Zhang, Chen Chen, Lianggong Bruce Wen, Zhang Liu, Jiebo
 Luo, Chenliang Xu
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2504.03151 ,  3649kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18685
replaced with revised version Tue, 25 Nov 2025 11:33:09 GMT   (5527kb)

Title: From Generation to Detection: A Multimodal Multi-Task Dataset for
 Benchmarking Health Misinformation
Authors: Zhihao Zhang, Yiran Zhang, Xiyue Zhou, Liting Huang, Imran Razzak,
 Preslav Nakov, Usman Naseem
Categories: cs.CL
Comments: Accepted to Findings of the Association for Computational
 Linguistics: EMNLP 2025
Journal-ref: Findings of the Association for Computational Linguistics: EMNLP
 2025, pp. 24245-24260, 2025
DOI: 10.18653/v1/2025.findings-emnlp.1316
\\ ( https://arxiv.org/abs/2505.18685 ,  5527kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21740
replaced with revised version Tue, 25 Nov 2025 15:00:53 GMT   (5351kb)

Title: Counterfactual Simulatability of LLM Explanations for Generation Tasks
Authors: Marvin Limpijankit, Yanda Chen, Melanie Subbiah, Nicholas Deas,
 Kathleen McKeown
Categories: cs.CL cs.AI
Comments: INLG25
\\ ( https://arxiv.org/abs/2505.21740 ,  5351kb)
------------------------------------------------------------------------------
\\
arXiv:2506.01341
replaced with revised version Tue, 25 Nov 2025 11:18:06 GMT   (674kb)

Title: TurnBench-MS: A Benchmark for Evaluating Multi-Turn, Multi-Step
 Reasoning in Large Language Models
Authors: Yiran Zhang, Mo Wang, Xiaoyang Li, Kaixuan Ren, Chencheng Zhu, Usman
 Naseem
Categories: cs.CL
Comments: Accepted to Findings of the Association for Computational
 Linguistics: EMNLP 2025
Journal-ref: Findings of the ACL: EMNLP 2025, pp. 19892-19924, 2025
DOI: 10.18653/v1/2025.findings-emnlp.1084
\\ ( https://arxiv.org/abs/2506.01341 ,  674kb)
------------------------------------------------------------------------------
\\
arXiv:2506.08726
replaced with revised version Tue, 25 Nov 2025 05:47:26 GMT   (390kb)

Title: Improved LLM Agents for Financial Document Question Answering
Authors: Nelvin Tan, Zian Seng, Liang Zhang, Yu-Ching Shih, Dong Yang, Amol
 Salunkhe
Categories: cs.CL cs.AI
Comments: 13 pages, 5 figures. Unlike the previous version, LLM names are now
 unmasked
\\ ( https://arxiv.org/abs/2506.08726 ,  390kb)
------------------------------------------------------------------------------
\\
arXiv:2506.19548
replaced with revised version Mon, 24 Nov 2025 10:13:54 GMT   (1844kb)

Title: Health Sentinel: An AI Pipeline For Real-time Disease Outbreak Detection
Authors: Devesh Pant, Rishi Raj Grandhe, Vipin Samaria, Mukul Paul, Sudhir
 Kumar, Saransh Khanna, Jatin Agrawal, Jushaan Singh Kalra, Akhil VSSG, Satish
 V Khalikar, Vipin Garg, Himanshu Chauhan, Pranay Verma, Neha Khandelwal, Soma
 S Dhavala, Minesh Mathew
Categories: cs.CL cs.IR
\\ ( https://arxiv.org/abs/2506.19548 ,  1844kb)
------------------------------------------------------------------------------
\\
arXiv:2507.07694
replaced with revised version Tue, 25 Nov 2025 08:15:36 GMT   (92kb)

Title: SAS: Simulated Attention Score
Authors: Chuanyang Zheng, Jiankai Sun, Yihang Gao, Yuehao Wang, Peihao Wang,
 Jing Xiong, Liliang Ren, Hao Cheng, Janardhan Kulkarni, Yelong Shen, Atlas
 Wang, Mac Schwager, Anderson Schneider, Xiaodong Liu, Jianfeng Gao
Categories: cs.CL
Comments: Tech Report
\\ ( https://arxiv.org/abs/2507.07694 ,  92kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10161
replaced with revised version Tue, 25 Nov 2025 08:55:32 GMT   (24kb)

Title: LaajMeter: A Framework for LaaJ Evaluation
Authors: Samuel Ackerman, Gal Amram, Ora Nova Fandina, Eitan Farchi, Shmulik
 Froimovich, Raviv Gal, Wesam Ibraheem, Avi Ziv
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2508.10161 ,  24kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18847
replaced with revised version Tue, 25 Nov 2025 11:46:58 GMT   (1256kb)

Title: ConfTuner: Training Large Language Models to Express Their Confidence
 Verbally
Authors: Yibo Li, Miao Xiong, Jiaying Wu, Bryan Hooi
Categories: cs.CL cs.AI
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2508.18847 ,  1256kb)
------------------------------------------------------------------------------
\\
arXiv:2509.17177
replaced with revised version Tue, 25 Nov 2025 17:49:27 GMT   (1912kb)

Title: FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning
 Models on Automatically Verifiable Textual and Visual Questions
Authors: Bowen Qin, Chen Yue, Fang Yin, Hui Wang, JG Yao, Jiakang Liu, Jing-Shu
 Zheng, Miguel Hu Chen, Richeng Xuan, Shibei Meng, Shiqi Zhou, Teng Dai,
 Tong-Shuai Ren, Wei Cui, Xi Yang, Xialin Du, Xiaojing Xu, Xue Sun, Xuejing
 Li, Yaming Liu, Yesheng Liu, Ying Liu, Yonghua Lin, Yu Zhao, Yunduo Zhang,
 Yuwen Luo, Zheqi He, Zhiyuan He, Zhongyuan Wang
Categories: cs.CL cs.CV cs.LG
Comments: Project homepage: https://flageval-baai.github.io/LRM-Eval/ This work
 will also be presented at NeurIPS 2025 Workshop on Foundations of Reasoning
 in Language Models (FoRLM); update with trials on Gemini 3 Pro
\\ ( https://arxiv.org/abs/2509.17177 ,  1912kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24403
replaced with revised version Tue, 25 Nov 2025 12:02:55 GMT   (1312kb)

Title: Agentar-Scale-SQL: Advancing Text-to-SQL through Orchestrated Test-Time
 Scaling
Authors: Pengfei Wang, Baolin Sun, Xuemei Dong, Yaxun Dai, Hongwei Yuan,
 Mengdie Chu, Yingqi Gao, Xiang Qi, Peng Zhang, Ying Yan
Categories: cs.CL cs.DB
\\ ( https://arxiv.org/abs/2509.24403 ,  1312kb)
------------------------------------------------------------------------------
\\
arXiv:2509.26536
replaced with revised version Tue, 25 Nov 2025 15:21:05 GMT   (15733kb)

Title: OceanGym: A Benchmark Environment for Underwater Embodied Agents
Authors: Yida Xue, Mingjun Mao, Xiangyuan Ru, Yuqi Zhu, Baochang Ren, Shuofei
 Qiao, Mengru Wang, Shumin Deng, Xinyu An, Ningyu Zhang, Ying Chen, Huajun
 Chen
Categories: cs.CL cs.AI cs.CV cs.LG cs.RO
Comments: Work in progress
\\ ( https://arxiv.org/abs/2509.26536 ,  15733kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05138
replaced with revised version Tue, 25 Nov 2025 12:22:57 GMT   (15825kb)

Title: LiRA: A Multi-Agent Framework for Reliable and Readable Literature
 Review Generation
Authors: Gregory Hok Tjoan Go, Khang Ly, Anders S{\o}gaard, Amin Tabatabaei,
 Maarten de Rijke, Xinyi Chen
Categories: cs.CL
\\ ( https://arxiv.org/abs/2510.05138 ,  15825kb)
------------------------------------------------------------------------------
\\
arXiv:2510.18866
replaced with revised version Tue, 25 Nov 2025 15:07:32 GMT   (5069kb)

Title: LightMem: Lightweight and Efficient Memory-Augmented Generation
Authors: Jizhan Fang, Xinle Deng, Haoming Xu, Ziyan Jiang, Yuqi Tang, Ziwen Xu,
 Shumin Deng, Yunzhi Yao, Mengru Wang, Shuofei Qiao, Huajun Chen, Ningyu Zhang
Categories: cs.CL cs.AI cs.CV cs.LG cs.MA
Comments: Work in progress
\\ ( https://arxiv.org/abs/2510.18866 ,  5069kb)
------------------------------------------------------------------------------
\\
arXiv:2510.20059
replaced with revised version Tue, 25 Nov 2025 08:37:33 GMT   (299kb)

Title: Enhancing Reasoning Skills in Small Persian Medical Language Models Can
 Outperform Large-Scale Data Training
Authors: Mehrdad Ghassabi and Sadra Hakim and Hamidreza Baradaran Kashani and
 Pedram Rostami
Categories: cs.CL
Comments: 7 pages, 5 figures
\\ ( https://arxiv.org/abs/2510.20059 ,  299kb)
------------------------------------------------------------------------------
\\
arXiv:2510.25628
replaced with revised version Tue, 25 Nov 2025 13:11:42 GMT   (2389kb)

Title: EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic
 Health Record Analysis
Authors: Yusheng Liao, Chaoyi Wu, Junwei Liu, Shuyang Jiang, Pengcheng Qiu,
 Haowen Wang, Yun Yue, Shuai Zhen, Jian Wang, Qianrui Fan, Jinjie Gu, Ya
 Zhang, Yanfeng Wang, Yu Wang and Weidi Xie
Categories: cs.CL
\\ ( https://arxiv.org/abs/2510.25628 ,  2389kb)
------------------------------------------------------------------------------
\\
arXiv:2511.01265
replaced with revised version Tue, 25 Nov 2025 03:27:09 GMT   (548kb)

Title: AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs
Authors: Mo El-Haj and Paul Rayson
Categories: cs.CL
Comments: 9 pages
Journal-ref: IEEE BigData 2025
\\ ( https://arxiv.org/abs/2511.01265 ,  548kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04195
replaced with revised version Tue, 25 Nov 2025 12:04:19 GMT   (8801kb)

Title: Computational Turing Test Reveals Systematic Differences Between Human
 and AI Language
Authors: Nicol\`o Pagan, Petter T\"ornberg, Christopher A. Bail, Anik\'o
 Hann\'ak, Christopher Barrie
Categories: cs.CL cs.MA cs.SI
\\ ( https://arxiv.org/abs/2511.04195 ,  8801kb)
------------------------------------------------------------------------------
\\
arXiv:2511.09222
replaced with revised version Tue, 25 Nov 2025 08:42:20 GMT   (114kb)

Title: Toward Honest Language Models for Deductive Reasoning
Authors: Jiarui Liu, Kaustubh Dhole, Yingheng Wang, Haoyang Wen, Sarah Zhang,
 Haitao Mao, Gaotang Li, Neeraj Varshney, Jingguo Liu, Xiaoman Pan
Categories: cs.CL
\\ ( https://arxiv.org/abs/2511.09222 ,  114kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18491
replaced with revised version Tue, 25 Nov 2025 10:47:40 GMT   (9405kb)

Title: MindEval: Benchmarking Language Models on Multi-turn Mental Health
 Support
Authors: Jos\'e Pombal, Maya D'Eon, Nuno M. Guerreiro, Pedro Henrique Martins,
 Ant\'onio Farinhas, Ricardo Rei
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2511.18491 ,  9405kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18808
replaced with revised version Tue, 25 Nov 2025 03:43:52 GMT   (1591kb)

Title: HyperbolicRAG: Enhancing Retrieval-Augmented Generation with Hyperbolic
 Representations
Authors: Linxiao Cao, Ruitao Wang, Jindong Li, Zhipeng Zhou and Menglin Yang
Categories: cs.CL cs.AI
Comments: 12 pages
\\ ( https://arxiv.org/abs/2511.18808 ,  1591kb)
------------------------------------------------------------------------------
\\
arXiv:2202.06276
replaced with revised version Tue, 25 Nov 2025 05:39:44 GMT   (19898kb)

Title: Natural Image Stitching Using Depth Maps
Authors: Tianli Liao and Nan Li
Categories: cs.CV
Comments: accept by Signal Processing: Image Communication
\\ ( https://arxiv.org/abs/2202.06276 ,  19898kb)
------------------------------------------------------------------------------
\\
arXiv:2209.15402
replaced with revised version Tue, 25 Nov 2025 18:57:28 GMT   (5369kb)

Title: Rethinking the Learning Paradigm for Facial Expression Recognition
Authors: Weijie Wang, Nicu Sebe and Bruno Lepri
Categories: cs.CV
\\ ( https://arxiv.org/abs/2209.15402 ,  5369kb)
------------------------------------------------------------------------------
\\
arXiv:2401.06385
replaced with revised version Tue, 25 Nov 2025 06:01:34 GMT   (4466kb)

Title: SD-MVS: Segmentation-Driven Deformation Multi-View Stereo with Spherical
 Refinement and EM optimization
Authors: Zhenlong Yuan, Jiakai Cao, Zhaoxin Li, Hao Jiang, Zhaoqi Wang
Categories: cs.CV
Comments: Published to AAAI2024
\\ ( https://arxiv.org/abs/2401.06385 ,  4466kb)
------------------------------------------------------------------------------
\\
arXiv:2402.12099
replaced with revised version Tue, 25 Nov 2025 02:53:15 GMT   (28489kb)

Title: Zero-Shot Video Translation via Token Warping
Authors: Haiming Zhu and Yangyang Xu and Jun Yu and Shengfeng He
Categories: cs.CV
Comments: Code is available at: https://github.com/Alex-Zhu1/TokenWarping
\\ ( https://arxiv.org/abs/2402.12099 ,  28489kb)
------------------------------------------------------------------------------
\\
arXiv:2407.01007
replaced with revised version Mon, 24 Nov 2025 12:45:48 GMT   (11340kb)

Title: GMT: Effective Global Framework for Multi-Camera Multi-Target Tracking
Authors: Yihao Zhen, Mingyue Xu, Qiang Wang, Baojie Fan, Jiahua Dong, Tinghui
 Zhao, Huijie Fan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2407.01007 ,  11340kb)
------------------------------------------------------------------------------
\\
arXiv:2407.16655
replaced with revised version Tue, 25 Nov 2025 02:25:28 GMT   (17021kb)

Title: MovieDreamer: Hierarchical Generation for Coherent Long Visual Sequence
Authors: Canyu Zhao, Mingyu Liu, Wen Wang, Weihua Chen, Fan Wang, Hao Chen, Bo
 Zhang, Chunhua Shen
Categories: cs.CV
Comments: 30 pages, 22 figures
\\ ( https://arxiv.org/abs/2407.16655 ,  17021kb)
------------------------------------------------------------------------------
\\
arXiv:2408.01840
replaced with revised version Tue, 25 Nov 2025 02:24:35 GMT   (3874kb)

Title: E$^{3}$NeRF: Efficient Event-Enhanced Neural Radiance Fields from Blurry
 Images
Authors: Yunshan Qi, Jia Li, Yifan Zhao, Yu Zhang, and Lin Zhu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2408.01840 ,  3874kb)
------------------------------------------------------------------------------
\\
arXiv:2408.11030
replaced with revised version Mon, 24 Nov 2025 09:01:36 GMT   (7715kb)

Title: OpenScan: A Benchmark for Generalized Open-Vocabulary 3D Scene
 Understanding
Authors: Youjun Zhao, Jiaying Lin, Shuquan Ye, Qianshi Pang, Rynson W.H. Lau
Categories: cs.CV
Comments: Accepted by AAAI 2026. Project Page:
 https://youjunzhao.github.io/OpenScan/
\\ ( https://arxiv.org/abs/2408.11030 ,  7715kb)
------------------------------------------------------------------------------
\\
arXiv:2411.10979
replaced with revised version Tue, 25 Nov 2025 03:51:45 GMT   (27755kb)

Title: VidComposition: Can MLLMs Analyze Compositions in Compiled Videos?
Authors: Yolo Y. Tang, Junjia Guo, Hang Hua, Susan Liang, Mingqian Feng,
 Xinyang Li, Rui Mao, Chao Huang, Jing Bi, Zeliang Zhang, Pooyan Fazli,
 Chenliang Xu
Categories: cs.CV cs.AI
Comments: Accepted to CVPR 2025
\\ ( https://arxiv.org/abs/2411.10979 ,  27755kb)
------------------------------------------------------------------------------
\\
arXiv:2412.05700
replaced with revised version Tue, 25 Nov 2025 08:18:56 GMT   (33414kb)

Title: Temporally Compressed 3D Gaussian Splatting for Dynamic Scenes
Authors: Saqib Javed, Ahmad Jarrar Khan, Corentin Dumery, Chen Zhao, Mathieu
 Salzmann
Categories: cs.CV cs.GR
Comments: Accepted at British Machine Vision Conference (BMVC) 2025
\\ ( https://arxiv.org/abs/2412.05700 ,  33414kb)
------------------------------------------------------------------------------
\\
arXiv:2412.11578
replaced with revised version Tue, 25 Nov 2025 06:44:11 GMT   (14474kb)

Title: DVP-MVS: Synergize Depth-Edge and Visibility Prior for Multi-View Stereo
Authors: Zhenlong Yuan, Jinguo Luo, Fei Shen, Zhaoxin Li, Cong Liu, Tianlu Mao
 and Zhaoqi Wang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2412.11578 ,  14474kb)
------------------------------------------------------------------------------
\\
arXiv:2412.14327
replaced with revised version Tue, 25 Nov 2025 17:43:20 GMT   (8603kb)

Title: Personalized Generative Low-light Image Denoising and Enhancement
Authors: Xijun Wang, Prateek Chennuri, Dilshan Godaliyadda, Yu Yuan, Bole Ma,
 Xingguang Zhang, Hamid R. Sheikh, Stanley Chan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2412.14327 ,  8603kb)
------------------------------------------------------------------------------
\\
arXiv:2412.15447
replaced with revised version Tue, 25 Nov 2025 06:55:58 GMT   (8435kb)

Title: LiHi-GS: LiDAR-Supervised Gaussian Splatting for Highway Driving Scene
 Reconstruction
Authors: Pou-Chun Kung, Xianling Zhang, Katherine A. Skinner, Nikita Jaipuria
Categories: cs.CV cs.RO
Comments: RA-L 2025
\\ ( https://arxiv.org/abs/2412.15447 ,  8435kb)
------------------------------------------------------------------------------
\\
arXiv:2412.21059
replaced with revised version Tue, 25 Nov 2025 03:02:50 GMT   (15117kb)

Title: VisionReward: Fine-Grained Multi-Dimensional Human Preference Learning
 for Image and Video Generation
Authors: Jiazheng Xu, Yu Huang, Jiale Cheng, Yuanming Yang, Jiajun Xu, Yuan
 Wang, Wenbo Duan, Shen Yang, Qunlin Jin, Shurun Li, Jiayan Teng, Zhuoyi Yang,
 Wendi Zheng, Xiao Liu, Dan Zhang, Ming Ding, Xiaohan Zhang, Xiaotao Gu, Shiyu
 Huang, Minlie Huang, Jie Tang, Yuxiao Dong
Categories: cs.CV
Comments: 27 pages
\\ ( https://arxiv.org/abs/2412.21059 ,  15117kb)
------------------------------------------------------------------------------
\\
arXiv:2501.06250
replaced with revised version Tue, 25 Nov 2025 03:41:49 GMT   (10631kb)

Title: Generative AI for Cel-Animation: A Survey
Authors: Yolo Y. Tang, Junjia Guo, Pinxin Liu, Zhiyuan Wang, Hang Hua, Jia-Xing
 Zhong, Yunzhong Xiao, Chao Huang, Luchuan Song, Susan Liang, Yizhi Song, Liu
 He, Jing Bi, Mingqian Feng, Xinyang Li, Zeliang Zhang, Chenliang Xu
Categories: cs.CV cs.AI cs.HC
Comments: Accepted by ICCV 2025 AISTORY Workshop
\\ ( https://arxiv.org/abs/2501.06250 ,  10631kb)
------------------------------------------------------------------------------
\\
arXiv:2501.17690
replaced with revised version Tue, 25 Nov 2025 15:50:33 GMT   (1761kb)

Title: Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue
 Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP)
 Assessment
Authors: Zixue Zeng, Xiaoyan Zhao, Matthew Cartier, Tong Yu, Jing Wang, Xin
 Meng, Zhiyu Sheng, Maryam Satarpour, John M Cormack, Allison Bean, Ryan
 Nussbaum, Maya Maurer, Emily Landis-Walkenhorst, Dinesh Kumbhare, Kang Kim,
 Ajay Wasan, Jiantao Pu
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2501.17690 ,  1761kb)
------------------------------------------------------------------------------
\\
arXiv:2502.17159
replaced with revised version Tue, 25 Nov 2025 14:36:57 GMT   (1183kb)

Title: RobustMerge: Parameter-Efficient Model Merging for MLLMs with Direction
 Robustness
Authors: Fanhu Zeng, Haiyang Guo, Fei Zhu, Li Shen, Hao Tang
Categories: cs.CV
Comments: NeurIPS 2025 (Spotlight) Fix some typos
\\ ( https://arxiv.org/abs/2502.17159 ,  1183kb)
------------------------------------------------------------------------------
\\
arXiv:2503.01347
replaced with revised version Tue, 25 Nov 2025 08:48:41 GMT   (3381kb)

Title: From Spots to Pixels: Dense Spatial Gene Expression Prediction from
 Histology Images
Authors: Ruikun Zhang, Yan Yang, Liyuan Pan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.01347 ,  3381kb)
------------------------------------------------------------------------------
\\
arXiv:2503.07516
replaced with revised version Tue, 25 Nov 2025 03:04:49 GMT   (3159kb)

Title: Rethinking Two-Stage Referring-by-Tracking in Referring Multi-Object
 Tracking: Make it Strong Again
Authors: Weize Li, Yunhao Du, Qixiang Yin, Zhicheng Zhao, Fei Su
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.07516 ,  3159kb)
------------------------------------------------------------------------------
\\
arXiv:2503.08367
replaced with revised version Tue, 25 Nov 2025 08:42:06 GMT   (5747kb)

Title: Embodied Crowd Counting
Authors: Runling Long, Yunlong Wang, Jia Wan, Xiang Deng, Xinting Zhu, Weili
 Guan, Antoni B. Chan, Liqiang Nie
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.08367 ,  5747kb)
------------------------------------------------------------------------------
\\
arXiv:2503.09158
replaced with revised version Mon, 24 Nov 2025 07:09:12 GMT   (2930kb)

Title: FaVChat: Hierarchical Prompt-Query Guided Facial Video Understanding
 with Data-Efficient GRPO
Authors: Fufangchen Zhao, Xuerui Qiu, Linrui Xu, Ming Li, Wenhao Jiang, Jinkai
 Zheng, Hehe Fan, Jian Gao, Danfeng Yan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.09158 ,  2930kb)
------------------------------------------------------------------------------
\\
arXiv:2503.10109
replaced with revised version Tue, 25 Nov 2025 08:21:18 GMT   (3467kb)

Title: Dream-IF: Dynamic Relative EnhAnceMent for Image Fusion
Authors: Xingxin Xu, Bing Cao, Dongdong Li, Qinghua Hu, Pengfei Zhu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.10109 ,  3467kb)
------------------------------------------------------------------------------
\\
arXiv:2503.13821
replaced with revised version Mon, 24 Nov 2025 19:06:10 GMT   (19876kb)

Title: Stitch-a-Demo: Video Demonstrations from Multistep Descriptions
Authors: Chi Hsuan Wu, Kumar Ashutosh, Kristen Grauman
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.13821 ,  19876kb)
------------------------------------------------------------------------------
\\
arXiv:2503.14228
replaced with revised version Tue, 25 Nov 2025 11:20:07 GMT   (1782kb)

Title: Panoramic Distortion-Aware Tokenization for Person Detection and
 Localization in Overhead Fisheye Images
Authors: Nobuhiko Wakai, Satoshi Sato, Yasunori Ishii, Takayoshi Yamashita
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2503.14228 ,  1782kb)
------------------------------------------------------------------------------
\\
arXiv:2503.14421
replaced with revised version Tue, 25 Nov 2025 17:20:44 GMT   (20235kb)

Title: ExDDV: A New Dataset for Explainable Deepfake Detection in Video
Authors: Vlad Hondru, Eduard Hogea, Darian Onchis, Radu Tudor Ionescu
Categories: cs.CV cs.AI cs.CL cs.LG cs.MM
Comments: Accepted at WACV 2026
\\ ( https://arxiv.org/abs/2503.14421 ,  20235kb)
------------------------------------------------------------------------------
\\
arXiv:2503.14698
replaced with revised version Mon, 24 Nov 2025 22:19:30 GMT   (30206kb)

Title: Learning Efficient Fuse-and-Refine for Feed-Forward 3D Gaussian
 Splatting
Authors: Yiming Wang, Lucy Chai, Xuan Luo, Michael Niemeyer, Manuel Lagunas,
 Stephen Lombardi, Siyu Tang, Tiancheng Sun
Categories: cs.CV
Comments: NeurIPS 2025, Previously titled "SplatVoxel: History-Aware Novel View
 Streaming without Temporal Training", Project Page:
 https://19reborn.github.io/SplatVoxel/
\\ ( https://arxiv.org/abs/2503.14698 ,  30206kb)
------------------------------------------------------------------------------
\\
arXiv:2504.16181
replaced with revised version Tue, 25 Nov 2025 15:13:39 GMT   (26602kb)

Title: CLIP-IT: CLIP-based Pairing for Histology Images Classification
Authors: Banafsheh Karimian, Giulia Avanzato, Soufian Belharbi, Alexis
 Guichemerre, Luke McCaffrey, Mohammadhadi Shateri, and Eric Granger
Categories: cs.CV
\\ ( https://arxiv.org/abs/2504.16181 ,  26602kb)
------------------------------------------------------------------------------
\\
arXiv:2504.19687
replaced with revised version Tue, 25 Nov 2025 10:10:42 GMT   (1458kb)

Title: Prompt Guiding Multi-Scale Adaptive Sparse Representation-driven Network
 for Low-Dose CT MAR
Authors: Baoshun Shi, Bing Chen, Shaolei Zhang, Huazhu Fu, and Zhanli Hu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2504.19687 ,  1458kb)
------------------------------------------------------------------------------
\\
arXiv:2505.05513
replaced with revised version Tue, 25 Nov 2025 11:38:35 GMT   (1287kb)

Title: Exploring Convolutional Neural Networks for Rice Grain Classification:
 An Explainable AI Approach
Authors: Muhammad Junaid Asif, Hamza Khan, Rabia Tehseen, Rana Fayyaz Ahmad,
 Mujtaba Asad, Syed Tahir Hussain Rizvi, and Shazia Saqib
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.05513 ,  1287kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11895
replaced with revised version Tue, 25 Nov 2025 14:31:52 GMT   (341kb)

Title: Adversarial Robustness for Unified Multi-Modal Encoders via Efficient
 Calibration
Authors: Chih-Ting Liao, Zhangquan Chen, Chunlei Meng, Tzu-Yu Huang, Xin Cao,
 Xu Zheng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.11895 ,  341kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13344
replaced with revised version Mon, 24 Nov 2025 21:39:54 GMT   (15332kb)

Title: RoPECraft: Training-Free Motion Transfer with Trajectory-Guided RoPE
 Optimization on Diffusion Transformers
Authors: Ahmet Berke Gokmen, Yigit Ekin, Bahri Batuhan Bilecen, Aysegul Dundar
Categories: cs.CV cs.AI cs.LG
Comments: https://berkegokmen1.github.io/RoPECraft/
\\ ( https://arxiv.org/abs/2505.13344 ,  15332kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16334
replaced with revised version Tue, 25 Nov 2025 11:35:44 GMT   (4667kb)

Title: Panoptic Captioning: An Equivalence Bridge for Image and Text
Authors: Kun-Yu Lin, Hongjun Wang, Weining Ren, Kai Han
Categories: cs.CV
Comments: NeurIPS 2025; Project page: https://visual-ai.github.io/pancap/
\\ ( https://arxiv.org/abs/2505.16334 ,  4667kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16565
replaced with revised version Tue, 25 Nov 2025 10:41:11 GMT   (23147kb)

Title: M2SVid: End-to-End Inpainting and Refinement for Monocular-to-Stereo
 Video Conversion
Authors: Nina Shvetsova, Goutam Bhat, Prune Truong, Hilde Kuehne, Federico
 Tombari
Categories: cs.CV
Comments: To be published at 3DV 2026, project webpage
 https://m2svid.github.io/
\\ ( https://arxiv.org/abs/2505.16565 ,  23147kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17951
replaced with revised version Tue, 25 Nov 2025 07:30:53 GMT   (19883kb)

Title: SplatCo: Structure-View Collaborative Gaussian Splatting for
 Detail-Preserving Rendering of Large-Scale Unbounded Scenes
Authors: Haihong Xiao and Jianan Zou and Yuxin Zhou and Ying He and Wenxiong
 Kang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.17951 ,  19883kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18525
replaced with revised version Tue, 25 Nov 2025 06:58:38 GMT   (1078kb)

Title: TK-Mamba: Marrying KAN With Mamba for Text-Driven 3D Medical Image
 Segmentation
Authors: Haoyu Yang, Yutong Guan, Meixing Shi, Yuxiang Cai, Jintao Chen, Sun
 Bing, Wenhui Lei, Mianxin Liu, Xiaoming Shi, Yankai Jiang, Jianwei Yin
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.18525 ,  1078kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18832
replaced with revised version Tue, 25 Nov 2025 18:04:41 GMT   (7088kb)

Title: Localizing Knowledge in Diffusion Transformers
Authors: Arman Zarei, Samyadeep Basu, Keivan Rezaei, Zihao Lin, Sayan Nag,
 Soheil Feizi
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.18832 ,  7088kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19385
replaced with revised version Mon, 24 Nov 2025 22:53:15 GMT   (491kb)

Title: Advancing Limited-Angle CT Reconstruction Through Diffusion-Based
 Sinogram Completion
Authors: Jiaqi Guo, Santiago Lopez-Tapia, Aggelos K. Katsaggelos
Categories: cs.CV cs.AI
Comments: Accepted at the 2025 IEEE International Conference on Image
 Processing (Oral)
DOI: 10.1109/ICIP55913.2025.11084640
\\ ( https://arxiv.org/abs/2505.19385 ,  491kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20426
replaced with revised version Tue, 25 Nov 2025 03:41:17 GMT   (46851kb)

Title: MMPerspective: Do MLLMs Understand Perspective? A Comprehensive
 Benchmark for Perspective Perception, Reasoning, and Robustness
Authors: Yolo Y. Tang, Pinxin Liu, Zhangyun Tan, Mingqian Feng, Rui Mao, Chao
 Huang, Jing Bi, Yunzhong Xiao, Susan Liang, Hang Hua, Ali Vosoughi, Luchuan
 Song, Zeliang Zhang, Chenliang Xu
Categories: cs.CV
Comments: Accepted to NeurIPS 2025 DB Track. Rating: 5,5,5,5
\\ ( https://arxiv.org/abs/2505.20426 ,  46851kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20629
replaced with revised version Tue, 25 Nov 2025 08:12:03 GMT   (4169kb)

Title: Unified Text-Image-to-Video Generation: A Training-Free Approach to
 Flexible Visual Conditioning
Authors: Bolin Lai, Sangmin Lee, Xu Cao, Xiang Li, James M. Rehg
Categories: cs.CV cs.LG
Comments: 18 pages, 10 figures, 8 tables
\\ ( https://arxiv.org/abs/2505.20629 ,  4169kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21962
replaced with revised version Tue, 25 Nov 2025 09:38:02 GMT   (49475kb)

Title: A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly
 Understanding
Authors: Mengjingcheng Mo, Xinyang Tong, Mingpi Tan, Jiaxu Leng, Jiankang
 Zheng, Yiran Liu, Haosheng Chen, Ji Gan, Weisheng Li, Xinbo Gao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.21962 ,  49475kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22908
replaced with revised version Tue, 25 Nov 2025 02:01:41 GMT   (27586kb)

Title: Learning Hierarchical Sparse Transform Coding of 3DGS
Authors: Hao Xu, Xiaolin Wu, Xi Zhang
Categories: cs.CV eess.IV
Comments: Our code will be released at
 \href{https://github.com/hxu160/SHTC_for_3DGS_compression}{here}
\\ ( https://arxiv.org/abs/2505.22908 ,  27586kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23738
replaced with revised version Tue, 25 Nov 2025 06:13:27 GMT   (23374kb)

Title: How Animals Dance (When You're Not Looking)
Authors: Xiaojuan Wang, Aleksander Holynski, Brian Curless, Ira Kemelmacher,
 Steve Seitz
Categories: cs.CV cs.GR
Comments: Project page: https://how-animals-dance.github.io/
\\ ( https://arxiv.org/abs/2505.23738 ,  23374kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00979
replaced with revised version Tue, 25 Nov 2025 16:18:38 GMT   (11990kb)

Title: IVY-FAKE: A Unified Explainable Framework and Benchmark for Image and
 Video AIGC Detection
Authors: Changjiang Jiang, Wenhui Dong, Zhonghao Zhang, Chenyang Si, Fengchang
 Yu, Wei Peng, Xinbin Yuan, Yifei Bi, Ming Zhao, Zian Zhou, Caifeng Shan
Categories: cs.CV cs.AI
Comments: 30 pages
\\ ( https://arxiv.org/abs/2506.00979 ,  11990kb)
------------------------------------------------------------------------------
\\
arXiv:2506.04115
replaced with revised version Tue, 25 Nov 2025 10:42:01 GMT   (10697kb)

Title: Multi-view Surface Reconstruction Using Normal and Reflectance Cues
Authors: Robin Bruneau, Baptiste Brument, Yvain Qu\'eau, Jean M\'elou,
 Fran\c{c}ois Bernard Lauze, Jean-Denis Durou, Lilian Calvet
Categories: cs.CV
Comments: 22 pages, 15 figures, 11 tables. A thorough qualitative and
 quantitive study is available in the supplementary material at
 https://drive.google.com/file/d/1KDfCKediXNP5Os954TL_QldaUWS0nKcD/view?usp=drive_link.
 Accepted to IJCV
\\ ( https://arxiv.org/abs/2506.04115 ,  10697kb)
------------------------------------------------------------------------------
\\
arXiv:2506.04704
replaced with revised version Tue, 25 Nov 2025 14:16:10 GMT   (8638kb)

Title: HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language
 Model
Authors: Youngwan Lee, Kangsan Kim, Kwanyong Park, Ilcahe Jung, Soojin Jang,
 Seanie Lee, Yong-Ju Lee, Sung Ju Hwang
Categories: cs.CV cs.AI
Comments: Project page: https://youngwanlee.github.io/holisafe
\\ ( https://arxiv.org/abs/2506.04704 ,  8638kb)
------------------------------------------------------------------------------
\\
arXiv:2506.06836
replaced with revised version Tue, 25 Nov 2025 14:56:02 GMT   (4785kb)

Title: Harnessing Vision-Language Models for Time Series Anomaly Detection
Authors: Zelin He, Sarah Alnegheimish, Matthew Reimherr
Categories: cs.CV cs.AI cs.LG
Comments: Accepted at AAAI 2026 (Oral)
\\ ( https://arxiv.org/abs/2506.06836 ,  4785kb)
------------------------------------------------------------------------------
\\
arXiv:2506.08640
replaced with revised version Tue, 25 Nov 2025 09:46:44 GMT   (17600kb)

Title: Orientation Matters: Making 3D Generative Models Orientation-Aligned
Authors: Yichong Lu, Yuzhuo Tian, Zijin Jiang, Yikun Zhao, Yuanbo Yang, Hao
 Ouyang, Haoji Hu, Huimin Yu, Yujun Shen, Yiyi Liao
Categories: cs.CV
Comments: Accepted by NeurIPS 2025. Project Page:
 https://xdimlab.github.io/Orientation_Matters
\\ ( https://arxiv.org/abs/2506.08640 ,  17600kb)
------------------------------------------------------------------------------
\\
arXiv:2506.23150
replaced with revised version Tue, 25 Nov 2025 12:15:51 GMT   (1910kb)

Title: AlignCVC: Aligning Cross-View Consistency for Single-Image-to-3D
 Generation
Authors: Xinyue Liang, Zhiyuan Ma, Lingchen Sun, Yanjun Guo, Lei Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.23150 ,  1910kb)
------------------------------------------------------------------------------
\\
arXiv:2507.13018
replaced with revised version Tue, 25 Nov 2025 06:17:51 GMT   (6234kb)

Title: Beyond Fully Supervised Pixel Annotations: Scribble-Driven
 Weakly-Supervised Framework for Image Manipulation Localization
Authors: Songlin Li, Guofeng Yu, Zhiqing Guo, Yunfeng Diao, Dan Ma, Gaobo Yang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2507.13018 ,  6234kb)
------------------------------------------------------------------------------
\\
arXiv:2507.17640
replaced with revised version Tue, 25 Nov 2025 01:40:19 GMT   (393kb)

Title: The Early Bird Identifies the Worm: You Can't Beat a Head Start in
 Long-Term Body Re-ID (ECHO-BID)
Authors: Thomas M. Metz, Matthew Q. Hill, Alice J. O'Toole
Categories: cs.CV
\\ ( https://arxiv.org/abs/2507.17640 ,  393kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00777
replaced with revised version Tue, 25 Nov 2025 09:53:49 GMT   (22799kb)

Title: Zero-Shot Anomaly Detection with Dual-Branch Prompt Selection
Authors: Zihan Wang, Samira Ebrahimi Kahou and Narges Armanfard
Categories: cs.CV
Comments: Accepted at BMVC 2025
\\ ( https://arxiv.org/abs/2508.00777 ,  22799kb)
------------------------------------------------------------------------------
\\
arXiv:2508.03356
replaced with revised version Mon, 24 Nov 2025 15:33:16 GMT   (9374kb)

Title: FedPromo: Federated Lightweight Proxy Models at the Edge Bring New
 Domains to Foundation Models
Authors: Matteo Caligiuri, Francesco Barbato, Donald Shenaj, Umberto Michieli,
 Pietro Zanuttigh
Categories: cs.CV cs.LG
Comments: 8 pages (main document) + 13 pages (suppl. mat.), 4 figures (main) +
 11 figures (suppl. mat.), 6 tables (main) + 5 tables (suppl. mat.) + 4
 algorithms (suppl. mat.)
\\ ( https://arxiv.org/abs/2508.03356 ,  9374kb)
------------------------------------------------------------------------------
\\
arXiv:2508.06982
replaced with revised version Tue, 25 Nov 2025 11:52:52 GMT   (14006kb)

Title: WeatherDiffusion: Controllable Weather Editing in Intrinsic Space
Authors: Yixin Zhu, Zuoliang Zhu, Jian Yang, Milo\v{s} Ha\v{s}an, Jin Xie,
 Beibei Wang
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2508.06982 ,  14006kb)
------------------------------------------------------------------------------
\\
arXiv:2508.07901
replaced with revised version Tue, 25 Nov 2025 10:06:37 GMT   (17469kb)

Title: Stand-In: A Lightweight and Plug-and-Play Identity Control for Video
 Generation
Authors: Bowen Xue and Zheng-Peng Duan and Qixin Yan and Wenjing Wang and Hao
 Liu and Chun-Le Guo and Chongyi Li and Chen Li and Jing Lyu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.07901 ,  17469kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08701
replaced with revised version Mon, 24 Nov 2025 19:26:12 GMT   (18941kb)

Title: SafeFix: Targeted Model Repair via Controlled Image Generation
Authors: Ouyang Xu, Baoming Zhang, Ruiyu Mao, Yunhui Guo
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2508.08701 ,  18941kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09022
replaced with revised version Tue, 25 Nov 2025 09:30:41 GMT   (2846kb)

Title: Leveraging Unlabeled Data from Unknown Sources via Dual-Path Guidance
 for Deepfake Face Detection
Authors: Zhiqiang Yang, Renshuai Tao, Chunjie Zhang, guodong yang, Xiaolong
 Zheng, Yao Zhao
Categories: cs.CV cs.AI
Comments: 11pages,4figures
\\ ( https://arxiv.org/abs/2508.09022 ,  2846kb)
------------------------------------------------------------------------------
\\
arXiv:2508.17171
replaced with revised version Mon, 24 Nov 2025 22:01:03 GMT   (4055kb)

Title: Achieving detailed medial temporal lobe segmentation with upsampled
 isotropic training from implicit neural representation
Authors: Yue Li, Pulkit Khandelwal, Rohit Jena, Long Xie, Michael Duong, Amanda
 E. Denning, Christopher A. Brown, Laura E. M. Wisse, Sandhitsu R. Das, David
 A. Wolk and Paul A. Yushkevich
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.17171 ,  4055kb)
------------------------------------------------------------------------------
\\
arXiv:2508.19786
replaced with revised version Tue, 25 Nov 2025 08:45:21 GMT   (18469kb)

Title: MAPo : Motion-Aware Partitioning of Deformable 3D Gaussian Splatting for
 High-Fidelity Dynamic Scene Reconstruction
Authors: Han Jiao, Jiakai Sun, Yexing Xu, Lei Zhao, Wei Xing, Huaizhong Lin
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.19786 ,  18469kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02966
replaced with revised version Tue, 25 Nov 2025 06:38:17 GMT   (17303kb)

Title: KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive
 Driving Frames with Vision-Language Models
Authors: Yujin Wang, Tianyi Wang, Quanfeng Liu, Wenxian Fan, Junfeng Jiao,
 Christian Claudel, Yunbing Yan, Bingzhao Gao, Jianqiang Wang, Hong Chen
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2509.02966 ,  17303kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02973
replaced with revised version Tue, 25 Nov 2025 03:12:45 GMT   (6563kb)

Title: InstaDA: Augmenting Instance Segmentation Data with Dual-Agent System
Authors: Xianbao Hou, Yonghao He, Zeyd Boukhers, John See, Hu Su, Wei Sui, Cong
 Yang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.02973 ,  6563kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11916
replaced with revised version Tue, 25 Nov 2025 02:17:22 GMT   (5055kb)

Title: NeuroGaze-Distill: Brain-informed Distillation and Depression-Inspired
 Geometric Priors for Robust Facial Emotion Recognition
Authors: Zilin Li, Weiwei Xu, Xuanqi Zhao, and Yiran Zhu
Categories: cs.CV
Comments: Preprint. Vision-only deployment; EEG used to form static prototypes.
 Includes appendix, 7 figures and 3 tables. Considering submission to ICLR
 2026. Revision note: This version corrects inaccuracies in the authors'
 institutional affiliations. No technical content has been modified
ACM-class: I.2.10; I.4.8; I.5.4
\\ ( https://arxiv.org/abs/2509.11916 ,  5055kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12897
replaced with revised version Tue, 25 Nov 2025 07:54:14 GMT   (4154kb)

Title: Cross-Layer Vision Smoothing: Enhancing Visual Understanding via
 Sustained Focus on Key Objects in Large Vision-Language Models
Authors: Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng, Zhixing Tan
Categories: cs.CV cs.AI
Comments: Under Review
\\ ( https://arxiv.org/abs/2509.12897 ,  4154kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12959
replaced with revised version Tue, 25 Nov 2025 10:42:06 GMT   (5953kb)

Title: Time-step Mixup for Efficient Spiking Knowledge Transfer from Appearance
 to Event Domain
Authors: Yuqi Xie, Shuhan Ye, Yi Yu, Chong Wang, Qixin Zhang, Jiazhen Xu, Le
 Shen, Yuanbin Qian, Jiangbo Qian, Guoqi Li
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.12959 ,  5953kb)
------------------------------------------------------------------------------
\\
arXiv:2509.17818
replaced with revised version Tue, 25 Nov 2025 11:13:38 GMT   (26916kb)

Title: ContextFlow: Training-Free Video Object Editing via Adaptive Context
 Enrichment
Authors: Yiyang Chen, Xuanhua He, Xiujun Ma, Yue Ma
Categories: cs.CV
Comments: The project page is at https://yychen233.github.io/ContextFlow-page
\\ ( https://arxiv.org/abs/2509.17818 ,  26916kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19805
replaced with revised version Tue, 25 Nov 2025 13:53:02 GMT   (22721kb)

Title: StrCGAN: A Generative Framework for Stellar Image Restoration
Authors: Shantanusinh Parmar, Silas Janke
Categories: cs.CV astro-ph.IM astro-ph.SR
\\ ( https://arxiv.org/abs/2509.19805 ,  22721kb)
------------------------------------------------------------------------------
\\
arXiv:2510.10068
replaced with revised version Tue, 25 Nov 2025 12:12:13 GMT   (12541kb)

Title: Probabilistic Hyper-Graphs using Multiple Randomly Masked Autoencoders
 for Semi-supervised Multi-modal Multi-task Learning
Authors: P\^irvu Mihai-Cristian, Marius Leordeanu
Categories: cs.CV
Comments: Submitted to Neurocomputing
\\ ( https://arxiv.org/abs/2510.10068 ,  12541kb)
------------------------------------------------------------------------------
\\
arXiv:2510.11512
replaced with revised version Tue, 25 Nov 2025 14:24:21 GMT   (4015kb)

Title: LikePhys: Evaluating Intuitive Physics Understanding in Video Diffusion
 Models via Likelihood Preference
Authors: Jianhao Yuan, Fabio Pizzati, Francesco Pinto, Lars Kunze, Ivan Laptev,
 Paul Newman, Philip Torr, Daniele De Martini
Categories: cs.CV cs.AI
Comments: 22 pages, 9 figures
\\ ( https://arxiv.org/abs/2510.11512 ,  4015kb)
------------------------------------------------------------------------------
\\
arXiv:2510.13186
replaced with revised version Tue, 25 Nov 2025 05:08:02 GMT   (11435kb)

Title: STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client
 Selection and Power Control
Authors: Zhen Li, Xibin Jin, Guoliang Li, Shuai Wang, Miaowen Wen, Huseyin
 Arslan, Derrick Wing Kwan Ng, and Chengzhong Xu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2510.13186 ,  11435kb)
------------------------------------------------------------------------------
\\
arXiv:2510.14528
replaced with revised version Tue, 25 Nov 2025 03:01:03 GMT   (24713kb)

Title: PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B
 Ultra-Compact Vision-Language Model
Authors: Cheng Cui, Ting Sun, Suyin Liang, Tingquan Gao, Zelun Zhang, Jiaxuan
 Liu, Xueqing Wang, Changda Zhou, Hongen Liu, Manhui Lin, Yue Zhang, Yubo
 Zhang, Handong Zheng, Jing Zhang, Jun Zhang, Yi Liu, Dianhai Yu, Yanjun Ma
Categories: cs.CV
Comments: Github Repo: https://github.com/PaddlePaddle/PaddleOCR
\\ ( https://arxiv.org/abs/2510.14528 ,  24713kb)
------------------------------------------------------------------------------
\\
arXiv:2510.17201
replaced with revised version Tue, 25 Nov 2025 04:52:13 GMT   (7855kb)

Title: Optimizing DINOv2 with Registers for Face Anti-Spoofing
Authors: Mika Feng, Pierre Gallin-Martel, Koichi Ito, and Takafumi Aoki
Categories: cs.CV
Comments: ICCV 2025 Workshop FAS
\\ ( https://arxiv.org/abs/2510.17201 ,  7855kb)
------------------------------------------------------------------------------
\\
arXiv:2510.19654
replaced with revised version Tue, 25 Nov 2025 03:37:38 GMT   (3243kb)

Title: From Forecasting to Planning: Policy World Model for Collaborative
 State-Action Prediction
Authors: Zhida Zhao, Talas Fu, Yifan Wang, Lijun Wang, Huchuan Lu
Categories: cs.CV cs.AI cs.CL cs.RO
Comments: Accepted by NuerIPS 2025 (Poster)
\\ ( https://arxiv.org/abs/2510.19654 ,  3243kb)
------------------------------------------------------------------------------
\\
arXiv:2510.20087
replaced with revised version Mon, 24 Nov 2025 19:07:23 GMT   (5300kb)

Title: Endoshare: A Publicly Available, Surgeons-Friendly Solution to
 De-Identify and Manage Surgical Videos
Authors: Lorenzo Arboit, Dennis N. Schneider, Britty Baby, Vinkle Srivastav,
 Pietro Mascagni, Nicolas Padoy
Categories: cs.CV
Comments: 13 pages, 6 figures. Source-available software:
 https://camma-public.github.io/Endoshare/
\\ ( https://arxiv.org/abs/2510.20087 ,  5300kb)
------------------------------------------------------------------------------
\\
arXiv:2510.20212
replaced with revised version Tue, 25 Nov 2025 15:15:11 GMT   (42638kb)

Title: Target-aware Image Editing via Cycle-consistent Constraints
Authors: Yanghao Wang, Zhen Wang, Long Chen
Categories: cs.CV
\\ ( https://arxiv.org/abs/2510.20212 ,  42638kb)
------------------------------------------------------------------------------
\\
arXiv:2510.20519
replaced with revised version Tue, 25 Nov 2025 07:57:22 GMT   (2272kb)

Title: Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning
Authors: Xiaohan Lan, Fanfan Liu, Haibo Qiu, Siqi Yang, Delian Ruan, Peng Shi,
 Lin Ma
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2510.20519 ,  2272kb)
------------------------------------------------------------------------------
\\
arXiv:2510.20820
replaced with revised version Tue, 25 Nov 2025 07:25:47 GMT   (28035kb)

Title: LayerComposer: Multi-Human Personalized Generation via Layered Canvas
Authors: Guocheng Gordon Qian, Ruihang Zhang, Tsai-Shien Chen, Yusuf Dalva,
 Anujraaj Argo Goyal, Willi Menapace, Ivan Skorokhodov, Meng Dong, Arpit
 Sahni, Daniil Ostashev, Ju Hu, Sergey Tulyakov, Kuan-Chieh Jackson Wang
Categories: cs.CV
Comments: 17 pages including appendix, preprint. Project page:
 https://snap-research.github.io/layercomposer/
\\ ( https://arxiv.org/abs/2510.20820 ,  28035kb)
------------------------------------------------------------------------------
\\
arXiv:2510.24821
replaced with revised version Tue, 25 Nov 2025 08:26:55 GMT   (33292kb)

Title: Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal
 Perception and Generation
Authors: Inclusion AI: Bowen Ma, Cheng Zou, Canxiang Yan, Chunxiang Jin,
 Chunjie Shen, Chenyu Lian, Dandan Zheng, Fudong Wang, Furong Xu, GuangMing
 Yao, Jun Zhou, Jingdong Chen, Jianing Li, Jianxin Sun, Jiajia Liu, Jian Sha,
 Jianjiang Zhu, Jianping Jiang, Jun Peng, Kaixiang Ji, Kaimeng Ren, Libin
 Wang, Lixiang Ru, Longhua Tan, Lu Ma, Lan Wang, Mochen Bai, Ning Gao, Qingpei
 Guo, Qinglong Zhang, Qiang Xu, Rui Liu, Ruijie Xiong, Ruobing Zheng, Sirui
 Gao, Tao Zhang, Tianqi Li, Tinghao Liu, Weilong Chai, Xinyu Xiao, Xiaomei
 Wang, Xiaolong Wang, Xiao Lu, Xiaoyu Li, Xingning Dong, Xuzheng Yu, Yi Yuan,
 Yuting Gao, Yuting Xiao, Yunxiao Sun, Yipeng Chen, Yifan Mao, Yifei Wu,
 Yongjie Lyu, Ziping Ma, Zhiqiang Fang, Zhihao Qiu, Ziyuan Huang, Zizheng
 Yang, Zhengyu He
Categories: cs.CV cs.AI
Comments: 18 pages, 5 figures
\\ ( https://arxiv.org/abs/2510.24821 ,  33292kb)
------------------------------------------------------------------------------
\\
arXiv:2510.27606
replaced with revised version Tue, 25 Nov 2025 02:41:05 GMT   (3403kb)

Title: Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised
 Reinforcement Learning
Authors: Yuhong Liu, Beichen Zhang, Yuhang Zang, Yuhang Cao, Long Xing, Xiaoyi
 Dong, Haodong Duan, Dahua Lin, Jiaqi Wang
Categories: cs.CV cs.AI
Comments: preprint
\\ ( https://arxiv.org/abs/2510.27606 ,  3403kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04283
replaced with revised version Tue, 25 Nov 2025 16:15:06 GMT   (25454kb)

Title: FastGS: Training 3D Gaussian Splatting in 100 Seconds
Authors: Shiwei Ren, Tianci Wen, Yongchun Fang, Biao Lu
Categories: cs.CV
Comments: Project page: https://fastgs.github.io/
MSC-class: 68T40(Primary)68T45, 68U99 (Secondary)
ACM-class: I.4.8; I.3.7
\\ ( https://arxiv.org/abs/2511.04283 ,  25454kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05865
replaced with revised version Tue, 25 Nov 2025 17:27:33 GMT   (43540kb)

Title: CGCE: Classifier-Guided Concept Erasure in Generative Models
Authors: Viet Nguyen, Vishal M. Patel
Categories: cs.CV cs.AI cs.CR
Comments: 26 pages, 17 figures
\\ ( https://arxiv.org/abs/2511.05865 ,  43540kb)
------------------------------------------------------------------------------
\\
arXiv:2511.10003
replaced with revised version Tue, 25 Nov 2025 04:11:29 GMT   (3062kb)

Title: DBGroup: Dual-Branch Point Grouping for Weakly Supervised 3D Semantic
 Instance Segmentation
Authors: Xuexun Liu, Xiaoxu Xu, Qiudan Zhang, Lin Ma and Xu Wang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.10003 ,  3062kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14099
replaced with revised version Tue, 25 Nov 2025 07:27:33 GMT   (107037kb)

Title: FAPE-IR: Frequency-Aware Planning and Execution Framework for All-in-One
 Image Restoration
Authors: Jingren Liu, Shuning Xu, Qirui Yang, Yun Wang, Xiangyu Chen, Zhong Ji
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.14099 ,  107037kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14259
replaced with revised version Tue, 25 Nov 2025 05:37:05 GMT   (5913kb)

Title: ManipShield: A Unified Framework for Image Manipulation Detection,
 Localization and Explanation
Authors: Zitong Xu, Huiyu Duan, Xiaoyu Wang, Zhaolin Cai, Kaiwei Zhang, Qiang
 Hu, Jing Liu, Xiongkuo Min, Guangtao Zhai
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.14259 ,  5913kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14613
replaced with revised version Mon, 24 Nov 2025 20:25:51 GMT   (28261kb)

Title: 3D-Guided Scalable Flow Matching for Generating Volumetric Tissue
 Spatial Transcriptomics from Serial Histology
Authors: Mohammad Vali Sanian, Arshia Hemmat, Amirhossein Vahidi, Jonas
 Maaskola, Jimmy Tsz Hang Lee, Stanislaw Makarchuk, Yeliz Demirci, Nana-Jane
 Chipampe, Muzlifah Haniffa, Omer Bayraktar, Lassi Paavolainen, Mohammad
 Lotfollahi
Categories: cs.CV
Comments: 19 pages
\\ ( https://arxiv.org/abs/2511.14613 ,  28261kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15613
replaced with revised version Tue, 25 Nov 2025 16:38:28 GMT   (8681kb)

Title: When to Think and When to Look: Uncertainty-Guided Lookback
Authors: Jing Bi, Filippos Bellos, Junjia Guo, Yayuan Li, Chao Huang, Yolo Y.
 Tang, Luchuan Song, Susan Liang, Zhongfei Mark Zhang, Jason J. Corso,
 Chenliang Xu
Categories: cs.CV cs.CL
\\ ( https://arxiv.org/abs/2511.15613 ,  8681kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15948
replaced with revised version Tue, 25 Nov 2025 06:45:28 GMT   (3640kb)

Title: Click2Graph: Interactive Panoptic Video Scene Graphs from a Single Click
Authors: Raphael Ruschel, Hardikkumar Prajapati, Awsafur Rahman, B.S. Manjunath
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.15948 ,  3640kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17361
replaced with revised version Tue, 25 Nov 2025 10:31:55 GMT   (15904kb)

Title: SuperQuadricOcc: Multi-Layer Gaussian Approximation of Superquadrics for
 Real-Time Self-Supervised Occupancy Estimation
Authors: Seamie Hayes, Reenu Mohandas, Tim Brophy, Alexandre Boulch, Ganesh
 Sistu, Ciaran Eising
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.17361 ,  15904kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17490
replaced with revised version Tue, 25 Nov 2025 03:31:54 GMT   (20091kb)

Title: Video-R4: Reinforcing Text-Rich Video Reasoning with Visual Rumination
Authors: Yolo Y. Tang, Daiki Shimada, Hang Hua, Chao Huang, Jing Bi, Rogerio
 Feris, Chenliang Xu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.17490 ,  20091kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17964
replaced with revised version Tue, 25 Nov 2025 05:11:45 GMT   (1202kb)

Title: X-ReID: Multi-granularity Information Interaction for Video-Based
 Visible-Infrared Person Re-Identification
Authors: Chenyang Yu and Xuehu Liu and Pingping Zhang and Huchuan Lu
Categories: cs.CV
Comments: Accepted by AAAI2026. More modifications may be performed
\\ ( https://arxiv.org/abs/2511.17964 ,  1202kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18264
replaced with revised version Tue, 25 Nov 2025 04:58:49 GMT   (5644kb)

Title: SatSAM2: Motion-Constrained Video Object Tracking in Satellite Imagery
 using Promptable SAM2 and Kalman Priors
Authors: Ruijie Fan, Junyan Ye, Huan Chen, Zilong Huang, Xiaolei Wang, Weijia
 Li
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.18264 ,  5644kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18463
replaced with revised version Tue, 25 Nov 2025 11:57:42 GMT   (6238kb)

Title: Alternating Perception-Reasoning for Hallucination-Resistant Video
 Understanding
Authors: Bowei Pu, Chuanbin Liu, Yifan Ge, Peicheng Zhou, Yiwei Sun, Zhiying
 Lu, Jiankang Wang, and Hongtao Xie
Categories: cs.CV
Comments: 32 pages, 36 figures
ACM-class: I.4
\\ ( https://arxiv.org/abs/2511.18463 ,  6238kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18780
replaced with revised version Tue, 25 Nov 2025 17:33:32 GMT   (3182kb)

Title: ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation
 through Multimodal Risk Detection
Authors: Ruize Ma, Minghong Cai, Yilei Jiang, Jiaming Han, Yi Feng, Yingshui
 Tan, Xiaoyong Zhu, Bo Zhang, Bo Zheng and Xiangyu Yue
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.18780 ,  3182kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18817
replaced with revised version Tue, 25 Nov 2025 02:32:48 GMT   (23868kb)

Title: Disc3D: Automatic Curation of High-Quality 3D Dialog Data via
 Discriminative Object Referring
Authors: Siyuan Wei, Chunjie Wang, Xiao Liu, Xiaosheng Yan, Zhishan Zhou, Rui
 Huang
Categories: cs.CV
Comments: 8 pages
\\ ( https://arxiv.org/abs/2511.18817 ,  23868kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18856
replaced with revised version Tue, 25 Nov 2025 05:37:37 GMT   (1890kb)

Title: Deep Hybrid Model for Region of Interest Detection in Omnidirectional
 Videos
Authors: Sana Alamgeer, Mylene Farias, Marcelo Carvalho
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.18856 ,  1890kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18870
replaced with revised version Tue, 25 Nov 2025 02:52:10 GMT   (8705kb)

Title: HunyuanVideo 1.5 Technical Report
Authors: Bing Wu, Chang Zou, Changlin Li, Duojun Huang, Fang Yang, Hao Tan,
 Jack Peng, Jianbing Wu, Jiangfeng Xiong, Jie Jiang, Linus, Patrol, Peizhen
 Zhang, Peng Chen, Penghao Zhao, Qi Tian, Songtao Liu, Weijie Kong, Weiyan
 Wang, Xiao He, Xin Li, Xinchi Deng, Xuefei Zhe, Yang Li, Yanxin Long, Yuanbo
 Peng, Yue Wu, Yuhong Liu, Zhenyu Wang, Zuozhuo Dai, Bo Peng, Coopers Li, Gu
 Gong, Guojian Xiao, Jiahe Tian, Jiaxin Lin, Jie Liu, Jihong Zhang, Jiesong
 Lian, Kaihang Pan, Lei Wang, Lin Niu, Mingtao Chen, Mingyang Chen, Mingzhe
 Zheng, Miles Yang, Qiangqiang Hu, Qi Yang, Qiuyong Xiao, Runzhou Wu, Ryan Xu,
 Rui Yuan, Shanshan Sang, Shisheng Huang, Siruis Gong, Shuo Huang, Weiting
 Guo, Xiang Yuan, Xiaojia Chen, Xiawei Hu, Wenzhi Sun, Xiele Wu, Xianshun Ren,
 Xiaoyan Yuan, Xiaoyue Mi, Yepeng Zhang, Yifu Sun, Yiting Lu, Yitong Li, You
 Huang, Yu Tang, Yixuan Li, Yuhang Deng, Yuan Zhou, Zhichao Hu, Zhiguang Liu,
 Zhihe Yang, Zilin Yang, Zhenzhi Lu, Zixiang Zhou, Zhao Zhong
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.18870 ,  8705kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18929
replaced with revised version Tue, 25 Nov 2025 04:59:26 GMT   (1721kb)

Title: Human-Centric Open-Future Task Discovery: Formulation, Benchmark, and
 Scalable Tree-Based Search
Authors: Zijian Song, Xiaoxin Lin, Tao Pu, Zhenlong Yuan, Guangrun Wang, Liang
 Lin
Categories: cs.CV
Comments: accepted to AAAI 2026, 10 pages, 9 figures
\\ ( https://arxiv.org/abs/2511.18929 ,  1721kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19145
replaced with revised version Tue, 25 Nov 2025 06:30:42 GMT   (1787kb)

Title: ABM-LoRA: Activation Boundary Matching for Fast Convergence in Low-Rank
 Adaptation
Authors: Dongha Lee, Jinhee Park, Minjun Kim, Junseok Kwon
Categories: cs.CV
Comments: 16 pages, 5 figures, under review
\\ ( https://arxiv.org/abs/2511.19145 ,  1787kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19200
replaced with revised version Tue, 25 Nov 2025 10:49:13 GMT   (1831kb)

Title: Can Modern Vision Models Understand the Difference Between an Object and
 a Look-alike?
Authors: Itay Cohen, Ethan Fetaya, Amir Rosenfeld
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.19200 ,  1831kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19431
replaced with revised version Tue, 25 Nov 2025 18:59:46 GMT   (19018kb)

Title: Cloud4D: Estimating Cloud Properties at a High Spatial and Temporal
 Resolution
Authors: Jacob Lin, Edward Gryspeerdt, Ronald Clark
Categories: cs.CV physics.ao-ph
Comments: NeurIPS 2025 Spotlight, project page: https://cloud4d.jacob-lin.com/
\\ ( https://arxiv.org/abs/2511.19431 ,  19018kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19435
replaced with revised version Tue, 25 Nov 2025 12:53:29 GMT   (12403kb)

Title: Are Image-to-Video Models Good Zero-Shot Image Editors?
Authors: Zechuan Zhang and Zhenyuan Chen and Zongxin Yang and Yi Yang
Categories: cs.CV
Comments: technical report
\\ ( https://arxiv.org/abs/2511.19435 ,  12403kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20773
replaced with revised version Mon, 24 Nov 2025 18:10:22 GMT   (318kb)

Title: Adaptive Candidate Retrieval with Dynamic Knowledge Graph Construction
 for Cold-Start Recommendation
Authors: Wooseong Yang, Weizhi Zhang, Yuqing Liu, Yuwei Han, Yu Wang, Junhyun
 Lee, Philip S. Yu
Categories: cs.IR
Comments: 10 pages
MSC-class: 68T05 68T05
\\ ( https://arxiv.org/abs/2505.20773 ,  318kb)
------------------------------------------------------------------------------
\\
arXiv:2507.03280
replaced with revised version Tue, 25 Nov 2025 09:06:39 GMT   (8942kb)

Title: Modeling Item-Level Dynamic Variability with Residual Diffusion for
 Bundle Recommendation
Authors: Dong Zhang, Lin Li, Ming Li, Amran Bhuiyan, Meng Sun, Xiaohui Tao,
 Jimmy Xiangji Huang
Categories: cs.IR
Comments: Extended version for AAAI'26
\\ ( https://arxiv.org/abs/2507.03280 ,  8942kb)
------------------------------------------------------------------------------
\\
arXiv:2112.07436
replaced with revised version Tue, 25 Nov 2025 09:56:05 GMT   (2509kb)

Title: Graph Kernel Neural Networks
Authors: Luca Cosmo, Giorgia Minello, Alessandro Bicciato, Michael Bronstein,
 Emanuele Rodol\`a, Luca Rossi, Andrea Torsello
Categories: cs.LG
Journal-ref: EEE Transactions on Neural Networks and Learning Systems, vol. 36,
 no. 4, pp. 6257-6270, April 2025
DOI: 10.1109/TNNLS.2024.3400850
\\ ( https://arxiv.org/abs/2112.07436 ,  2509kb)
------------------------------------------------------------------------------
\\
arXiv:2301.12250
replaced with revised version Tue, 25 Nov 2025 17:10:32 GMT   (156kb)

Title: Fast, Sample-Efficient, Affine-Invariant Private Mean and Covariance
 Estimation for Subgaussian Distributions
Authors: Gavin Brown, Samuel B. Hopkins and Adam Smith
Categories: cs.LG
Comments: 45 pages. Appeared at COLT 2023. New version fixes typos, improves
 some proofs and constants, and links to github
\\ ( https://arxiv.org/abs/2301.12250 ,  156kb)
------------------------------------------------------------------------------
\\
arXiv:2310.15074
replaced with revised version Tue, 25 Nov 2025 17:28:34 GMT   (2951kb)

Title: MGAS: Multi-Granularity Architecture Search for Trade-Off Between Model
 Effectiveness and Efficiency
Authors: Xiaoyun Liu, Divya Saxena, Jiannong Cao, Yuqing Zhao, Penghui Ruan
Categories: cs.LG cs.AI
DOI: 10.1109/TNNLS.2025.3625978
\\ ( https://arxiv.org/abs/2310.15074 ,  2951kb)
------------------------------------------------------------------------------
\\
arXiv:2403.15511
replaced with revised version Tue, 25 Nov 2025 13:27:15 GMT   (1752kb)

Title: Multiple-Input Auto-Encoder Guided Feature Selection for IoT Intrusion
 Detection Systems
Authors: Phai Vu Dinh, Diep N. Nguyen, Dinh Thai Hoang, Quang Uy Nguyen, Eryk
 Dutkiewicz, and Son Pham Bao
Categories: cs.LG cs.AI cs.CR
\\ ( https://arxiv.org/abs/2403.15511 ,  1752kb)
------------------------------------------------------------------------------
\\
arXiv:2404.18886
replaced with revised version Tue, 25 Nov 2025 02:18:04 GMT   (1614kb)

Title: A Survey on Diffusion Models for Time Series and Spatio-Temporal Data
Authors: Yiyuan Yang, Ming Jin, Haomin Wen, Chaoli Zhang, Yuxuan Liang, Lintao
 Ma, Yi Wang, Chenghao Liu, Bin Yang, Zenglin Xu, Shirui Pan, Qingsong Wen
Categories: cs.LG cs.AI
Comments: Accepted by ACM Computing Surveys; 40 pages; Github Repo:
 https://github.com/yyysjz1997/Awesome-TimeSeries-SpatioTemporal-Diffusion-Model
\\ ( https://arxiv.org/abs/2404.18886 ,  1614kb)
------------------------------------------------------------------------------
\\
arXiv:2405.16441
replaced with revised version Tue, 25 Nov 2025 05:27:58 GMT   (3772kb)

Title: Categorical Flow Matching on Statistical Manifolds
Authors: Chaoran Cheng, Jiahan Li, Jian Peng, Ge Liu
Categories: cs.LG stat.ML
Comments: Accepted to NeurIPS 2024 as a conference paper
\\ ( https://arxiv.org/abs/2405.16441 ,  3772kb)
------------------------------------------------------------------------------
\\
arXiv:2406.01423
replaced with revised version Tue, 25 Nov 2025 11:29:35 GMT   (414kb)

Title: Value Improved Actor Critic Algorithms
Authors: Yaniv Oren, Moritz A. Zanger, Pascal R. van der Vaart, Mustafa Mert
 Celikok, Matthijs T. J. Spaan, Wendelin Bohmer
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2406.01423 ,  414kb)
------------------------------------------------------------------------------
\\
arXiv:2406.12841
replaced with revised version Tue, 25 Nov 2025 12:43:13 GMT   (1697kb)

Title: Demystifying Higher-Order Graph Neural Networks
Authors: Maciej Besta, Florian Scheidl, Lukas Gianinazzi, Grzegorz Kwasniewski,
 Shachar Klaiman, J\"urgen M\"uller, Torsten Hoefler
Categories: cs.LG cs.AI cs.SI
Journal-ref: IEEE Transactions on Pattern Analysis and Machine Intelligence,
 2025
\\ ( https://arxiv.org/abs/2406.12841 ,  1697kb)
------------------------------------------------------------------------------
\\
arXiv:2406.14909
replaced with revised version Mon, 24 Nov 2025 21:52:43 GMT   (1453kb)

Title: Mixture of Attention Spans: Optimizing LLM Inference Efficiency with
 Heterogeneous Sliding-Window Lengths
Authors: Tianyu Fu, Haofeng Huang, Xuefei Ning, Genghan Zhang, Boju Chen,
 Tianqi Wu, Hongyi Wang, Zixiao Huang, Shiyao Li, Shengen Yan, Guohao Dai,
 Huazhong Yang, Yu Wang
Categories: cs.LG cs.AI cs.CL
Comments: Published at CoLM'25
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2406.14909 ,  1453kb)
------------------------------------------------------------------------------
\\
arXiv:2406.17952
replaced with revised version Tue, 25 Nov 2025 03:05:06 GMT   (665kb)

Title: LINSCAN -- A Linearity Based Clustering Algorithm
Authors: Andrew Dennehy, Xiaoyu Zou, Shabnam J. Semnani, Yuri Fialko, Alexander
 Cloninger
Categories: cs.LG cs.CG
\\ ( https://arxiv.org/abs/2406.17952 ,  665kb)
------------------------------------------------------------------------------
\\
arXiv:2410.01778
replaced with revised version Tue, 25 Nov 2025 03:37:39 GMT   (1173kb)

Title: TopER: Topological Embeddings in Graph Representation Learning
Authors: Astrit Tola, Funmilola Mary Taiwo, Cuneyt Gurcan Akcora, Baris
 Coskunuzer
Categories: cs.LG math.AT
Comments: 27 pages, 10 figures
MSC-class: 68T05, 68R10, 55N31, 62R40
ACM-class: I.2.6; G.2.2
Journal-ref: NeurIPS 2025
\\ ( https://arxiv.org/abs/2410.01778 ,  1173kb)
------------------------------------------------------------------------------
\\
arXiv:2410.02158
replaced with revised version Tue, 25 Nov 2025 03:14:12 GMT   (1296kb)

Title: SCNode: Spatial and Contextual Coordinates for Graph Representation
 Learning
Authors: Md Joshem Uddin, Astrit Tola, Varin Sikand, Cuneyt Gurcan Akcora,
 Baris Coskunuzer
Categories: cs.LG cs.CG stat.ML
Comments: 24 pages, 5 figures
MSC-class: 68T07, 68R10
ACM-class: I.2.6; G.2.2
Journal-ref: TMLR 2025
\\ ( https://arxiv.org/abs/2410.02158 ,  1296kb)
------------------------------------------------------------------------------
\\
arXiv:2411.08706
replaced with revised version Tue, 25 Nov 2025 10:51:57 GMT   (2339kb)

Title: Searching Latent Program Spaces
Authors: Matthew V Macfarlane, Clement Bonnet
Categories: cs.LG cs.AI
Comments: NeurIPS 2025 spotlight. Code available at
 https://github.com/clement-bonnet/lpn
\\ ( https://arxiv.org/abs/2411.08706 ,  2339kb)
------------------------------------------------------------------------------
\\
arXiv:2411.15046
replaced with revised version Tue, 25 Nov 2025 11:42:54 GMT   (184kb)

Title: On Feasible Rewards in Multi-Agent Inverse Reinforcement Learning
Authors: Till Freihaut, Giorgia Ramponi
Categories: cs.LG
Comments: Currently under review
\\ ( https://arxiv.org/abs/2411.15046 ,  184kb)
------------------------------------------------------------------------------
\\
arXiv:2412.03068
replaced with revised version Tue, 25 Nov 2025 06:20:22 GMT   (21745kb)

Title: Domain Fusion Controllable Generalization for Cross-Domain Time Series
 Forecasting from Multi-Domain Integrated Distribution
Authors: Xiangkai Ma, Xiaobin Hong, Mingkai Lin, Han Zhang, Wenzhong Li, Sanglu
 Lu
Categories: cs.LG cs.AI
Comments: We have updated the abstract, introduction and related work.
 Additionally, we have incorporated the latest competitive baseline models
\\ ( https://arxiv.org/abs/2412.03068 ,  21745kb)
------------------------------------------------------------------------------
\\
arXiv:2412.04323
replaced with revised version Tue, 25 Nov 2025 02:31:45 GMT   (2694kb)

Title: GRAM: Generalization in Deep RL with a Robust Adaptation Module
Authors: James Queeney, Xiaoyi Cai, Alexander Schperberg, Radu Corcodel,
 Mouhacine Benosman, Jonathan P. How
Categories: cs.LG cs.AI cs.RO stat.ML
Comments: Accepted for publication in IEEE Robotics and Automation Letters
 (RA-L)
\\ ( https://arxiv.org/abs/2412.04323 ,  2694kb)
------------------------------------------------------------------------------
\\
arXiv:2502.07154
replaced with revised version Mon, 24 Nov 2025 01:05:38 GMT   (1334kb)

Title: Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting
 Confidence Improves Mathematical Reasoning
Authors: Feng Chen, Allan Raventos, Nan Cheng, Surya Ganguli, Shaul Druckmann
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2502.07154 ,  1334kb)
------------------------------------------------------------------------------
\\
arXiv:2502.18549
replaced with revised version Tue, 25 Nov 2025 03:25:11 GMT   (2169kb)

Title: ARBoids: Adaptive Residual Reinforcement Learning With Boids Model for
 Cooperative Multi-USV Target Defense
Authors: Jiyue Tao, Tongsheng Shen, Dexin Zhao, Feitian Zhang
Categories: cs.LG cs.CR cs.RO
\\ ( https://arxiv.org/abs/2502.18549 ,  2169kb)
------------------------------------------------------------------------------
\\
arXiv:2503.19666
replaced with revised version Tue, 25 Nov 2025 01:35:17 GMT   (492kb)

Title: Towards Efficient Training of Graph Neural Networks: A Multiscale
 Approach
Authors: Eshed Gal, Moshe Eliasof, Carola-Bibiane Sch\"onlieb, Ivan I. Kyrchei,
 Eldad Haber, Eran Treister
Categories: cs.LG
\\ ( https://arxiv.org/abs/2503.19666 ,  492kb)
------------------------------------------------------------------------------
\\
arXiv:2504.08896
replaced with revised version Mon, 24 Nov 2025 21:40:39 GMT   (3219kb)

Title: Position: Beyond Euclidean -- Foundation Models Should Embrace
 Non-Euclidean Geometries
Authors: Neil He, Jiahong Liu, Buze Zhang, Ngoc Bui, Ali Maatouk, Menglin Yang,
 Irwin King, Melanie Weber, Rex Ying
Categories: cs.LG cs.AI
Comments: 27 pages, 6 figures, LoG Conference 2025
\\ ( https://arxiv.org/abs/2504.08896 ,  3219kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12366
replaced with revised version Tue, 25 Nov 2025 15:34:10 GMT   (534kb)

Title: DisCO: Reinforcing Large Reasoning Models with Discriminative
 Constrained Optimization
Authors: Gang Li, Ming Lin, Tomer Galanti, Zhengzhong Tu, Tianbao Yang
Categories: cs.LG cs.AI
Comments: Accepted to NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.12366 ,  534kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13858
replaced with revised version Mon, 24 Nov 2025 20:37:20 GMT   (211kb)

Title: Enforcing Hard Linear Constraints in Deep Learning Models with Decision
 Rules
Authors: Gonzalo E. Constante-Flores, Hao Chen, Can Li
Categories: cs.LG
Comments: 1 figure
Journal-ref: 39th Conference on Neural Information Processing Systems (NeurIPS
 2025)
\\ ( https://arxiv.org/abs/2505.13858 ,  211kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16690
replaced with revised version Tue, 25 Nov 2025 02:29:36 GMT   (249kb)

Title: Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator
Authors: Beier Luo, Shuoyuan Wang, Sharon Li, Hongxin Wei
Categories: cs.LG cs.AI
Comments: NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.16690 ,  249kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20192
replaced with revised version Tue, 25 Nov 2025 07:50:07 GMT   (2056kb)

Title: FunReason: Enhancing Large Language Models' Function Calling via
 Self-Refinement Multiscale Loss and Automated Data Refinement
Authors: Bingguang Hao, ZengZhuang Xu, Maolin Wang, Yuntao Wen, Yicheng Chen,
 Cunyin Peng, Long Chen, Dong Wang, Xiangyu Zhao, Jinjie Gu, Chenyi Zhuang, Ji
 Zhang
Categories: cs.LG cs.IR
\\ ( https://arxiv.org/abs/2505.20192 ,  2056kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22994
replaced with revised version Mon, 24 Nov 2025 20:27:04 GMT   (1557kb)

Title: Walking the Weight Manifold: a Topological Approach to Conditioning
 Inspired by Neuromodulation
Authors: Ari S. Benjamin, Kyle Daruwalla, Christian Pehle, Abdul-Malik Zekri,
 Anthony M. Zador
Categories: cs.LG cs.NE
Comments: 17 pages, 4 figures. Updated author list
\\ ( https://arxiv.org/abs/2505.22994 ,  1557kb)
------------------------------------------------------------------------------
\\
arXiv:2505.24298
replaced with revised version Tue, 25 Nov 2025 05:48:23 GMT   (372kb)

Title: AReaL: A Large-Scale Asynchronous Reinforcement Learning System for
 Language Reasoning
Authors: Wei Fu, Jiaxuan Gao, Xujie Shen, Chen Zhu, Zhiyu Mei, Chuyi He,
 Shusheng Xu, Guo Wei, Jun Mei, Jiashu Wang, Tongkai Yang, Binhang Yuan, Yi Wu
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2505.24298 ,  372kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07902
replaced with revised version Tue, 25 Nov 2025 04:19:55 GMT   (15044kb)

Title: FunDiff: Diffusion Models over Function Spaces for Physics-Informed
 Generative Modeling
Authors: Sifan Wang, Zehao Dou, Siming Shan, Tong-Rui Liu, Lu Lu
Categories: cs.LG physics.comp-ph stat.ML
Comments: 31 pages, 12 figures
\\ ( https://arxiv.org/abs/2506.07902 ,  15044kb)
------------------------------------------------------------------------------
\\
arXiv:2506.09738
replaced with revised version Tue, 25 Nov 2025 18:30:49 GMT   (1972kb)

Title: Towards Multimodal Graph Large Language Model
Authors: Xin Wang, Zeyang Zhang, Linxin Xiao, Haibo Chen, Chendi Ge and Wenwu
 Zhu
Categories: cs.LG
Comments: 4 figures, 2 tables
Journal-ref: Science China Information Sciences (2025)
DOI: 10.1007/s11432-025-4627-3
\\ ( https://arxiv.org/abs/2506.09738 ,  1972kb)
------------------------------------------------------------------------------
\\
arXiv:2506.17967
replaced with revised version Mon, 24 Nov 2025 12:37:43 GMT   (13572kb)

Title: Adapting Vision-Language Models for Evaluating World Models
Authors: Mariya Hendriksen, Tabish Rashid, David Bignell, Raluca Georgescu,
 Abdelhak Lemkhenter, Katja Hofmann, Sam Devlin, Sarah Parisot
Categories: cs.LG cs.AI cs.CV
Comments: NeurIPS LAW 2025 (Oral)
\\ ( https://arxiv.org/abs/2506.17967 ,  13572kb)
------------------------------------------------------------------------------
\\
arXiv:2506.18165
replaced with revised version Tue, 25 Nov 2025 07:56:48 GMT   (3306kb)

Title: Non-equilibrium Annealed Adjoint Sampler
Authors: Jaemoo Choi, Yongxin Chen, Molei Tao, Guan-Horng Liu
Categories: cs.LG cs.AI
Comments: 26 pages, 8 figures
\\ ( https://arxiv.org/abs/2506.18165 ,  3306kb)
------------------------------------------------------------------------------
\\
arXiv:2506.20024
replaced with revised version Tue, 25 Nov 2025 05:10:29 GMT   (13210kb)

Title: Elucidated Rolling Diffusion Models for Probabilistic Weather
 Forecasting
Authors: Salva R\"uhling Cachay, Miika Aittala, Karsten Kreis, Noah Brenowitz,
 Arash Vahdat, Morteza Mardani, Rose Yu
Categories: cs.LG cs.AI physics.ao-ph stat.ML
Comments: NeurIPS 2025
Journal-ref: Advances in Neural Information Processing Systems (NeurIPS), 2025
\\ ( https://arxiv.org/abs/2506.20024 ,  13210kb)
------------------------------------------------------------------------------
\\
arXiv:2506.21844
replaced with revised version Mon, 24 Nov 2025 23:41:00 GMT   (383kb)

Title: Koopman operator-based discussion on partial observation in stochastic
 systems
Authors: Jun Ohkubo
Categories: cs.LG
Comments: 26 pages, 5 figures
\\ ( https://arxiv.org/abs/2506.21844 ,  383kb)
------------------------------------------------------------------------------
\\
arXiv:2507.02315
replaced with revised version Tue, 25 Nov 2025 01:49:25 GMT   (38kb)

Title: Improving Constrained Language Generation via Self-Distilled Twisted
 Sequential Monte Carlo
Authors: Sooyeon Kim, Giung Nam, Byoungwoo Park, Juho Lee
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2507.02315 ,  38kb)
------------------------------------------------------------------------------
\\
arXiv:2507.16274
replaced with revised version Tue, 25 Nov 2025 07:36:10 GMT   (455kb)

Title: STAlloc: Enhancing Memory Efficiency in Large-Scale Model Training with
 Spatio-Temporal Planning
Authors: Zixiao Huang, Junhao Hu, Hao Lin, Chunyang Zhu, Yueran Tang, Quanlu
 Zhang, Zhen Guo, Zhenhua Li, Shengen Yan, Zhenhua Zhu, Guohao Dai, Yu Wang
Categories: cs.LG cs.AI cs.DC cs.PF
DOI: 10.1145/3767295.3769335
\\ ( https://arxiv.org/abs/2507.16274 ,  455kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00901
replaced with revised version Tue, 25 Nov 2025 03:35:46 GMT   (856kb)

Title: Filtering with Self-Attention and Storing with MLP: One-Layer
 Transformers Can Provably Acquire and Extract Knowledge
Authors: Ruichen Xu, Kexin Chen
Categories: cs.LG cs.CL
\\ ( https://arxiv.org/abs/2508.00901 ,  856kb)
------------------------------------------------------------------------------
\\
arXiv:2508.03827
replaced with revised version Tue, 25 Nov 2025 05:28:21 GMT   (830kb)

Title: Scalable neural network-based blackbox optimization
Authors: Pavankumar Koratikere, Leifur Leifsson
Categories: cs.LG stat.ML
Comments: An open-source implementation of SNBO is available at:
 https://github.com/ComputationalDesignLab/snbo
Journal-ref: Structural and Multidisciplinary Optimization, Volume 68, No. 255,
 2025
DOI: 10.1007/s00158-025-04195-5
\\ ( https://arxiv.org/abs/2508.03827 ,  830kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08746
replaced with revised version Tue, 25 Nov 2025 11:34:54 GMT   (901kb)

Title: Interpretable Reward Model via Sparse Autoencoder
Authors: Shuyi Zhang, Wei Shi, Sihang Li, Jiayi Liao, Hengxing Cai, Xiang Wang
Categories: cs.LG
Comments: AAAI 2026 Oral
\\ ( https://arxiv.org/abs/2508.08746 ,  901kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09093
replaced with revised version Mon, 24 Nov 2025 18:58:34 GMT   (903kb)

Title: Scaling Up Active Testing to Large Language Models
Authors: Gabrielle Berrada, Jannik Kossen, Freddie Bickford Smith, Muhammed
 Razzak, Yarin Gal, Tom Rainforth
Categories: cs.LG stat.ML
Comments: Published at NeurIPS 2025
\\ ( https://arxiv.org/abs/2508.09093 ,  903kb)
------------------------------------------------------------------------------
\\
arXiv:2508.11086
replaced with revised version Mon, 24 Nov 2025 21:46:38 GMT   (683kb)

Title: Relative Advantage Debiasing for Watch-Time Prediction in Short-Video
 Recommendation
Authors: Emily Liu, Kuan Han, Minfeng Zhan, Bocheng Zhao, Guanyu Mu, Yang Song
Categories: cs.LG cs.IR
\\ ( https://arxiv.org/abs/2508.11086 ,  683kb)
------------------------------------------------------------------------------
\\
arXiv:2508.12145
replaced with revised version Tue, 25 Nov 2025 13:11:12 GMT   (7794kb)

Title: DE-VAE: Revealing Uncertainty in Parametric and Inverse Projections with
 Variational Autoencoders using Differential Entropy
Authors: Frederik L. Dennig, Daniel A. Keim
Categories: cs.LG
Comments: 5 pages, 3 figures, LaTeX; fixed typos; added DOI
Journal-ref: 2025 IEEE Workshop on Uncertainty Visualization: Unraveling
 Relationships of Uncertainty, AI, and Decision-Making
DOI: 10.1109/UncertaintyVisualization68947.2025.00009
\\ ( https://arxiv.org/abs/2508.12145 ,  7794kb)
------------------------------------------------------------------------------
\\
arXiv:2508.17681
replaced with revised version Tue, 25 Nov 2025 02:30:28 GMT   (26kb)

Title: Unlearning as Ablation: Toward a Falsifiable Benchmark for Generative
 Scientific Discovery
Authors: Robert Yang
Categories: cs.LG cs.AI
Comments: 6 pages + appendix. Accepted to NeurIPS 2025 AI4Science Workshop
\\ ( https://arxiv.org/abs/2508.17681 ,  26kb)
------------------------------------------------------------------------------
\\
arXiv:2508.21380
replaced with revised version Tue, 25 Nov 2025 13:55:48 GMT   (13555kb)

Title: Iterative Inference in a Chess-Playing Neural Network
Authors: Elias Sandmann, Sebastian Lapuschkin, Wojciech Samek
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2508.21380 ,  13555kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10390
replaced with revised version Tue, 25 Nov 2025 14:26:56 GMT   (567kb)

Title: Vendi Information Gain for Active Learning and its Application to
 Ecology
Authors: Quan Nguyen, Adji Bousso Dieng
Categories: cs.LG cs.IT math.IT q-bio.PE
Comments: Accepted at the AAAI Workshop on AI to Accelerate Science and
 Engineering (AI2ASE) 2026
\\ ( https://arxiv.org/abs/2509.10390 ,  567kb)
------------------------------------------------------------------------------
\\
arXiv:2509.22601
replaced with revised version Tue, 25 Nov 2025 00:33:10 GMT   (36841kb)

Title: Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive
 Exploration for Agentic Reinforcement Learning
Authors: Yulei Qin, Xiaoyu Tan, Zhengbao He, Gang Li, Haojia Lin, Zongyi Li,
 Zihan Xu, Yuchen Shi, Siqi Cai, Renting Rui, Shaofei Cai, Yuzheng Cai, Xuan
 Zhang, Sheng Ye, Ke Li, Xing Sun
Categories: cs.LG cs.AI cs.CL cs.CV cs.MA
Comments: 45 pages, 14 figures
\\ ( https://arxiv.org/abs/2509.22601 ,  36841kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25228
replaced with revised version Tue, 25 Nov 2025 01:17:23 GMT   (3540kb)

Title: Simple, Fast and Efficient Injective Manifold Density Estimation with
 Random Projections
Authors: Ahmad Ayaz Amin, Baha Uddin Kazi
Categories: cs.LG
\\ ( https://arxiv.org/abs/2509.25228 ,  3540kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01508
replaced with revised version Mon, 24 Nov 2025 21:25:45 GMT   (1631kb)

Title: Realistic CDSS Drug Dosing with End-to-end Recurrent Q-learning for Dual
 Vasopressor Control
Authors: Will Y. Zou, Jean Feng, Alexandre Kalimouttou, Jennifer Yuntong Zhang,
 Christopher W. Seymour, Romain Pirracchio
Categories: cs.LG
Comments: 13 pages, 5 figures. Neurips 2025 Workshop Learning from Time Series
 for Health
\\ ( https://arxiv.org/abs/2510.01508 ,  1631kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03263
replaced with revised version Mon, 24 Nov 2025 22:54:34 GMT   (18406kb)

Title: Memory Self-Regeneration: Uncovering Hidden Knowledge in Unlearned
 Models
Authors: Agnieszka Polowczyk, Alicja Polowczyk, Joanna Waczy\'nska, Piotr
 Borycki, Przemys{\l}aw Spurek
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2510.03263 ,  18406kb)
------------------------------------------------------------------------------
\\
arXiv:2510.07664
replaced with revised version Tue, 25 Nov 2025 05:24:28 GMT   (15333kb)

Title: FedQS: Optimizing Gradient and Model Aggregation for Semi-Asynchronous
 Federated Learning
Authors: Yunbo Li, Jiaping Gui, Zhihang Deng, Fanchao Meng, Yue Wu
Categories: cs.LG cs.DC
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2510.07664 ,  15333kb)
------------------------------------------------------------------------------
\\
arXiv:2510.10764
replaced with revised version Tue, 25 Nov 2025 07:35:02 GMT   (2794kb)

Title: Optimally Deep Networks - Adapting Model Depth to Datasets for Superior
 Efficiency
Authors: Shaharyar Ahmed Khan Tareen, Filza Khan Tareen
Categories: cs.LG cs.AI cs.CV
Comments: 6 pages, 4 figures, 1 table, 2 equations, 1 algorithm
\\ ( https://arxiv.org/abs/2510.10764 ,  2794kb)
------------------------------------------------------------------------------
\\
arXiv:2510.19482
replaced with revised version Tue, 25 Nov 2025 05:34:08 GMT   (2145kb)

Title: ELUTQ: Efficient LUT-Aware Quantization for Deploying Large Language
 Models on Edge Devices
Authors: Xin Nie, Liang Dong, Haicheng Zhang, Jiawang Xiao, G. Sun
Categories: cs.LG
Comments: 28 pages, 10 figures
\\ ( https://arxiv.org/abs/2510.19482 ,  2145kb)
------------------------------------------------------------------------------
\\
arXiv:2510.21945
replaced with revised version Tue, 25 Nov 2025 16:44:25 GMT   (4794kb)

Title: Generalization Bounds for Rank-sparse Neural Networks
Authors: Antoine Ledent, Rodrigo Alves, Yunwen Lei
Categories: cs.LG
Comments: Accepted at NeurIPS 2025
\\ ( https://arxiv.org/abs/2510.21945 ,  4794kb)
------------------------------------------------------------------------------
\\
arXiv:2510.23053
replaced with revised version Tue, 25 Nov 2025 03:37:57 GMT   (4584kb)

Title: AirFed: A Federated Graph-Enhanced Multi-Agent Reinforcement Learning
 Framework for Multi-UAV Cooperative Mobile Edge Computing
Authors: Zhiyu Wang, Suman Raj, Rajkumar Buyya
Categories: cs.LG cs.DC
\\ ( https://arxiv.org/abs/2510.23053 ,  4584kb)
------------------------------------------------------------------------------
\\
arXiv:2510.24160
replaced with revised version Tue, 25 Nov 2025 07:13:49 GMT   (3991kb)

Title: Identifiable learning of dissipative dynamics
Authors: Aiqing Zhu, Beatrice W. Soh, Grigorios A. Pavliotis and Qianxiao Li
Categories: cs.LG
\\ ( https://arxiv.org/abs/2510.24160 ,  3991kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04638
replaced with revised version Tue, 25 Nov 2025 05:01:44 GMT   (6972kb)

Title: Addressing divergent representations from causal interventions on neural
 networks
Authors: Satchel Grant, Simon Jerome Han, Alexa R. Tartaglini, Christopher
 Potts
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2511.04638 ,  6972kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04774
replaced with revised version Tue, 25 Nov 2025 07:01:57 GMT   (1258kb)

Title: SLOFetch: Compressed-Hierarchical Instruction Prefetching for Cloud
 Microservices
Authors: Zerui Bao, Di Zhu, Liu Jiang, Shiqi Sheng, Ziwei Wang and Haoyun Zhang
Categories: cs.LG cs.AR
\\ ( https://arxiv.org/abs/2511.04774 ,  1258kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04979
replaced with revised version Tue, 25 Nov 2025 08:05:43 GMT   (19kb)

Title: Scaling Up ROC-Optimizing Support Vector Machines
Authors: Gimun Bae, Seung Jun Shin
Categories: cs.LG stat.CO stat.ML
Comments: 15 pages, Accepted in Stat
\\ ( https://arxiv.org/abs/2511.04979 ,  19kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06633
replaced with revised version Tue, 25 Nov 2025 04:44:59 GMT   (3777kb)

Title: Dual-branch Spatial-Temporal Self-supervised Representation for Enhanced
 Road Network Learning
Authors: Qinghong Guo, Yu Wang, Ji Cao, Tongya Zheng, Junshu Dai, Bingde Hu,
 Shunyu Liu, Canghong Jin
Categories: cs.LG
Comments: Accept by AAAI 2026
\\ ( https://arxiv.org/abs/2511.06633 ,  3777kb)
------------------------------------------------------------------------------
\\
arXiv:2511.09219
replaced with revised version Tue, 25 Nov 2025 18:56:26 GMT   (382kb)

Title: Planning in Branch-and-Bound: Model-Based Reinforcement Learning for
 Exact Combinatorial Optimization
Authors: Paul Strang, Zacharie Al\`es, C\^ome Bissuel, Olivier Juan, Safia
 Kedad-Sidhoum, Emmanuel Rachelson
Categories: cs.LG
\\ ( https://arxiv.org/abs/2511.09219 ,  382kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11602
replaced with revised version Tue, 25 Nov 2025 09:15:43 GMT   (237kb)

Title: Aspiration-based Perturbed Learning Automata in Games with Noisy Utility
 Measurements. Part A: Stochastic Stability in Non-zero-Sum Games
Authors: Georgios C. Chasparis
Categories: cs.LG cs.GT cs.MA math.OC
\\ ( https://arxiv.org/abs/2511.11602 ,  237kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12121
replaced with revised version Tue, 25 Nov 2025 02:30:46 GMT   (3317kb)

Title: To Align or Not to Align: Strategic Multimodal Representation Alignment
 for Optimal Performance
Authors: Wanlong Fang, Tianle Zhang, Alvin Chan
Categories: cs.LG cs.MM
Comments: Accepted by AAAI 2026. This arXiv version includes additional details
 and extended appendix
\\ ( https://arxiv.org/abs/2511.12121 ,  3317kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13053
replaced with revised version Tue, 25 Nov 2025 12:12:18 GMT   (1893kb)

Title: Self-Organization and Spectral Mechanism of Attractor Landscapes in
 High-Capacity Kernel Hopfield Networks
Authors: Akira Tamamori
Categories: cs.LG cs.NE
Comments: 8 pages, 5 figures
\\ ( https://arxiv.org/abs/2511.13053 ,  1893kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16839
replaced with revised version Mon, 24 Nov 2025 08:46:39 GMT   (465kb)

Title: Analysis of heart failure patient trajectories using sequence modeling
Authors: Falk Dippel, Yinan Yu, Annika Rosengren, Martin Lindgren, Christina E.
 Lundberg, Erik Aerts, Martin Adiels, Helen Sj\"oland
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2511.16839 ,  465kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17585
replaced with revised version Tue, 25 Nov 2025 07:18:32 GMT   (1209kb)

Title: PaSE: Prototype-aligned Calibration and Shapley-based Equilibrium for
 Multimodal Sentiment Analysis
Authors: Kang He, Boyu Chen, Yuzhe Ding, Fei Li, Chong Teng, Donghong Ji
Categories: cs.LG cs.AI cs.CV
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2511.17585 ,  1209kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17628
replaced with revised version Tue, 25 Nov 2025 08:57:01 GMT   (1392kb)

Title: Rectifying Distribution Shift in Cascaded Precipitation Nowcasting
Authors: Fanbo Ju, Haiyuan Shi, Qingjian Ni
Categories: cs.LG
\\ ( https://arxiv.org/abs/2511.17628 ,  1392kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18660
replaced with revised version Tue, 25 Nov 2025 09:14:27 GMT   (4893kb)

Title: Subtract the Corruption: Training-Data-Free Corrective Machine
 Unlearning using Task Arithmetic
Authors: Mostafa Mozafari, Farooq Ahmad Wani, Maria Sofia Bucarelli, Fabrizio
 Silvestri
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2511.18660 ,  4893kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18958
replaced with revised version Tue, 25 Nov 2025 12:33:40 GMT   (485kb)

Title: Learning to Compress Graphs via Dual Agents for Consistent Topological
 Robustness Evaluation
Authors: Qisen Chai, Yansong Wang, Junjie Huang, Tao Jia
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2511.18958 ,  485kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19350
replaced with revised version Tue, 25 Nov 2025 03:40:34 GMT   (15125kb)

Title: Scalable Parameter-Light Spectral Method for Clustering Short Text
 Embeddings with a Cohesion-Based Evaluation Metric
Authors: Nikita Neveditsin, Pawan Lingras, Vijay Mago
Categories: cs.LG cs.CL
\\ ( https://arxiv.org/abs/2511.19350 ,  15125kb)
------------------------------------------------------------------------------
\\
arXiv:2409.12842
replaced with revised version Mon, 24 Nov 2025 23:47:56 GMT   (4644kb)

Title: Vision Language Models Can Parse Floor Plan Maps
Authors: David DeFazio, Hrudayangam Mehta, Meng Wang, Ping Yang, Jeremy
 Blackburn, Shiqi Zhang
Categories: cs.RO cs.AI
\\ ( https://arxiv.org/abs/2409.12842 ,  4644kb)
------------------------------------------------------------------------------
\\
arXiv:2410.15236
replaced with revised version Tue, 25 Nov 2025 14:24:38 GMT   (52kb)

Title: Jailbreaking and Mitigation of Vulnerabilities in Large Language Models
Authors: Benji Peng, Keyu Chen, Qian Niu, Ziqian Bi, Ming Liu, Pohsun Feng,
 Tianyang Wang, Lawrence K.Q. Yan, Yizhu Wen, Yichao Zhang, Caitlyn Heqi Yin,
 and Xinyuan Song
Categories: cs.CR cs.AI cs.LG
\\ ( https://arxiv.org/abs/2410.15236 ,  52kb)
------------------------------------------------------------------------------
\\
arXiv:2412.14191
replaced with revised version Mon, 24 Nov 2025 20:05:08 GMT   (959kb)

Title: Ontology-Aware RAG for Improved Question-Answering in Cybersecurity
 Education
Authors: Chengshuai Zhao, Garima Agrawal, Fan Zhang, Tharindu Kumarage, Zhen
 Tan, Yuli Deng, Ying-Chih Chen, Huan Liu
Categories: cs.CY cs.AI
Comments: Accepted by the 2025 IEEE International Conference on Big Data (IEEE
 BigData 2025)
\\ ( https://arxiv.org/abs/2412.14191 ,  959kb)
------------------------------------------------------------------------------
\\
arXiv:2501.11357 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 04:54:25 GMT   (212kb)

Title: On the dimension of pullback attractors in recurrent neural networks
Authors: Muhammed Fadera
Categories: math.DS cs.AI cs.LG
Comments: Issues with clarity and notation
\\ ( https://arxiv.org/abs/2501.11357 ,  212kb)
------------------------------------------------------------------------------
\\
arXiv:2504.09775
replaced with revised version Tue, 25 Nov 2025 04:36:10 GMT   (3041kb)

Title: Understanding and Optimizing Multi-Stage AI Inference Pipelines
Authors: Abhimanyu Rajeshkumar Bambhaniya, Hanjiang Wu, Suvinay Subramanian,
 Sudarshan Srinivasan, Souvik Kundu, Amir Yazdanbakhsh, Midhilesh Elavazhagan,
 Madhu Kumar, Tushar Krishna
Categories: cs.AR cs.AI cs.DC cs.LG
Comments: Inference System Design for Multi-Stage AI Inference Pipelines. 13
 Pages, 15 Figues, 3 Tables
\\ ( https://arxiv.org/abs/2504.09775 ,  3041kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17648 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 02:11:40 GMT   (9933kb)

Title: Simulating Macroeconomic Expectations using LLM Agents
Authors: Jianhao Lin, Lexuan Sun, Yixin Yan
Categories: econ.GN cs.AI q-fin.EC
\\ ( https://arxiv.org/abs/2505.17648 ,  9933kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04903
replaced with revised version Tue, 25 Nov 2025 10:13:08 GMT   (7445kb)

Title: BackFed: An Efficient & Standardized Benchmark Suite for Backdoor
 Attacks in Federated Learning
Authors: Thinh Dao, Dung Thuy Nguyen, Khoa D Doan, Kok-Seng Wong
Categories: cs.CR cs.AI cs.DC
Comments: Our framework is openly available at
 https://github.com/thinh-dao/BackFed
\\ ( https://arxiv.org/abs/2507.04903 ,  7445kb)
------------------------------------------------------------------------------
\\
arXiv:2507.10646
replaced with revised version Tue, 25 Nov 2025 04:27:07 GMT   (2099kb)

Title: CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based
 Code Assistance
Authors: Myeongsoo Kim, Shweta Garg, Baishakhi Ray, Varun Kumar, and Anoop
 Deoras
Categories: cs.SE cs.AI
Comments: Accepted to NeurIPS 2025 Datasets and Benchmarks Track
\\ ( https://arxiv.org/abs/2507.10646 ,  2099kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01772 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 17:27:39 GMT   (4964kb)

Title: LoRA-based methods on Unet for transfer learning in Subarachnoid
 Hematoma Segmentation
Authors: Cristian Minoccheri, Matthew Hodgman, Haoyuan Ma, Rameez Merchant,
 Emily Wittrup, Craig Williamson, Kayvan Najarian
Categories: eess.IV cs.AI cs.CV
\\ ( https://arxiv.org/abs/2508.01772 ,  4964kb)
------------------------------------------------------------------------------
\\
arXiv:2508.15577 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 12:28:01 GMT   (5808kb)

Title: LFaB: Low fidelity as Bias for Active Learning in the chemical
 configuration space
Authors: Vivin Vinod and Peter Zaspel
Categories: physics.chem-ph cs.AI cs.LG
Comments: SI included in main
\\ ( https://arxiv.org/abs/2508.15577 ,  5808kb)
------------------------------------------------------------------------------
\\
arXiv:2508.17811
replaced with revised version Tue, 25 Nov 2025 08:48:19 GMT   (12127kb)

Title: MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian
 Splatting
Authors: Hanzhi Chang, Ruijie Zhu, Wenjie Chang, Mulin Yu, Yanzhe Liang, Jiahao
 Lu, Zhuoyuan Li, Tianzhu Zhang
Categories: cs.GR cs.AI cs.CV cs.LG
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2508.17811 ,  12127kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05362
replaced with revised version Tue, 25 Nov 2025 00:06:00 GMT   (3224kb)

Title: AI-in-the-Loop: Privacy Preserving Real-Time Scam Detection and
 Conversational Scambaiting by Leveraging LLMs and Federated Learning
Authors: Ismail Hossain, Sai Puppala, Md Jahangir Alam, Sajedul Talukder
Categories: cs.CR cs.AI cs.LG cs.SI
Comments: This paper got accepted in 26th Privacy Enhancing Technologies
 Symposium (PETS 2026). We uploaded it into ArXiv as pre-print
\\ ( https://arxiv.org/abs/2509.05362 ,  3224kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08015 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 15:51:29 GMT   (19724kb)

Title: CardioComposer: Leveraging Differentiable Geometry for Compositional
 Control of Anatomical Diffusion Models
Authors: Karim Kadry, Shoaib Goraya, Ajay Manicka, Abdalla Abdelwahed, Naravich
 Chutisilp, Farhad Nezami, Elazer Edelman
Categories: eess.IV cs.AI cs.CV cs.LG
Comments: 10 pages, 16 figures
\\ ( https://arxiv.org/abs/2509.08015 ,  19724kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02143 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 03:01:10 GMT   (4619kb)

Title: How to Find Fantastic AI Papers: Self-Rankings as a Powerful Predictor
 of Scientific Impact Beyond Peer Review
Authors: Buxin Su, Natalie Collina, Garrett Wen, Didong Li, Kyunghyun Cho,
 Jianqing Fan, Bingxin Zhao, Weijie Su
Categories: stat.AP cs.AI cs.DL cs.LG
\\ ( https://arxiv.org/abs/2510.02143 ,  4619kb)
------------------------------------------------------------------------------
\\
arXiv:2510.13006 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 19:53:22 GMT   (2196kb)

Title: What is Implementation Science; and Why It Matters for Bridging the
 Artificial Intelligence Innovation-to-Application Gap in Medical Imaging
Authors: Ahmad Fayaz-Bakhsh, Janice Tania, Syaheerah Lebai Lutfi, Abhinav K.
 Jha, Arman Rahmim
Categories: physics.med-ph cs.AI
\\ ( https://arxiv.org/abs/2510.13006 ,  2196kb)
------------------------------------------------------------------------------
\\
arXiv:2510.15691 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 11:27:22 GMT   (267kb)

Title: Exploring the Synergy of Quantitative Factors and Newsflow
 Representations from Large Language Models for Stock Return Prediction
Authors: Tian Guo, Emmanuel Hauptmann
Categories: q-fin.CP cs.AI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2510.15691 ,  267kb)
------------------------------------------------------------------------------
\\
arXiv:2510.16786
replaced with revised version Tue, 25 Nov 2025 13:07:39 GMT   (154kb)

Title: More with Less: An Empirical Study of Turn-Control Strategies for
 Efficient Coding Agents
Authors: Pengfei Gao, Chao Peng
Categories: cs.SE cs.AI cs.LG
\\ ( https://arxiv.org/abs/2510.16786 ,  154kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03826 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 09:52:36 GMT   (27163kb)

Title: CORE - A Cell-Level Coarse-to-Fine Image Registration Engine for
 Multi-stain Image Alignment
Authors: Esha Sadia Nasir, Behnaz Elhaminia, Mark Eastwood, Catherine King,
 Owen Cain, Lorraine Harper, Paul Moss, Dimitrios Chanouzas, David Snead,
 Nasir Rajpoot, Adam Shephard, Shan E Ahmed Raza
Categories: q-bio.QM cs.AI
\\ ( https://arxiv.org/abs/2511.03826 ,  27163kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14555 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 10:10:25 GMT   (11016kb)

Title: DecNefLab: A Modular and Interpretable Simulation Framework for Decoded
 Neurofeedback
Authors: Alexander Olza and Roberto Santana and David Soto
Categories: q-bio.NC cs.AI
\\ ( https://arxiv.org/abs/2511.14555 ,  11016kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14977
replaced with revised version Tue, 25 Nov 2025 03:09:09 GMT   (1588kb)

Title: SVBRD-LLM: Self-Verifying Behavioral Rule Discovery for Autonomous
 Vehicle Identification
Authors: Xiangyu Li, Zhaomiao Guo
Categories: cs.RO cs.AI
\\ ( https://arxiv.org/abs/2511.14977 ,  1588kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15076
replaced with revised version Mon, 24 Nov 2025 23:45:45 GMT   (1641kb)

Title: GPU-Initiated Networking for NCCL
Authors: Khaled Hamidouche (1), John Bachan (1), Pak Markthub (1), Peter-Jan
 Gootzen (1), Elena Agostini (1), Sylvain Jeaugey (1), Aamir Shafi (1),
 Georgios Theodorakis (1), Manjunath Gorentla Venkata (1) ((1) NVIDIA
 Corporation)
Categories: cs.DC cs.AI cs.AR cs.LG
Comments: 13 pages, 9 figures, 3 tables
MSC-class: 68W10 (Primary), 68M10, 65Y05 (Secondary)
ACM-class: C.2.1; C.2.4; C.1.2; C.1.4
\\ ( https://arxiv.org/abs/2511.15076 ,  1641kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15097
replaced with revised version Mon, 24 Nov 2025 02:26:39 GMT   (16kb)

Title: MAIF: Enforcing AI Trust and Provenance with an Artifact-Centric Agentic
 Paradigm
Authors: Vineeth Sai Narajala, Manish Bhatt, Idan Habler, Ronald F. Del
 Rosario, Ads Dawson
Categories: cs.CR cs.AI
Comments: 7 Pages, 2 Figures, 6 Tables, Repo:
 https://github.com/vineethsai/maifscratch-1, Added additional Author and
 fixed Citations
\\ ( https://arxiv.org/abs/2511.15097 ,  16kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17532
replaced with revised version Tue, 25 Nov 2025 03:14:35 GMT   (2092kb)

Title: Denoising Refinement Diffusion Models for Simultaneous Generation of
 Multi-scale Mobile Network Traffic
Authors: Xiaoqian Qi, Haoye Chai, Sichang Liu, Lei Yue, Raoyuan Pan, Yue Wang,
 Yong Li
Categories: cs.NI cs.AI
\\ ( https://arxiv.org/abs/2511.17532 ,  2092kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17971
replaced with revised version Tue, 25 Nov 2025 07:21:00 GMT   (480kb)

Title: Comprehensive Design Space Exploration for Tensorized Neural Network
 Hardware Accelerators
Authors: Jinsong Zhang, Minghe Li, Jiayi Tian, Jinming Lu, Zheng Zhang
Categories: cs.AR cs.AI
\\ ( https://arxiv.org/abs/2511.17971 ,  480kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18085
replaced with revised version Tue, 25 Nov 2025 02:25:13 GMT   (5257kb)

Title: Continually Evolving Skill Knowledge in Vision Language Action Model
Authors: Yuxuan Wu, Guangming Wang, Zhiheng Yang, Maoqing Yao, Brian Sheil,
 Hesheng Wang
Categories: cs.RO cs.AI
\\ ( https://arxiv.org/abs/2511.18085 ,  5257kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18493 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 04:01:05 GMT   (28692kb)

Title: Shape-Adapting Gated Experts: Dynamic Expert Routing for Colonoscopic
 Lesion Segmentation
Authors: Gia Huy Thai, Hoang-Nguyen Vu, Anh-Minh Phan, Quang-Thinh Ly, Tram
 Dinh, Thi-Ngoc-Truc Nguyen and Nhat Ho
Categories: eess.IV cs.AI cs.CV
\\ ( https://arxiv.org/abs/2511.18493 ,  28692kb)
------------------------------------------------------------------------------
\\
arXiv:2501.06662 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 20:27:00 GMT   (35kb)

Title: The magnitude of categories of texts enriched by language models
Authors: Tai-Danae Bradley and Juan Pablo Vigneaux
Categories: math.CT cs.CL
Comments: 26 pages
MSC-class: 18D20, 68T50, 94A17
ACM-class: I.2.7; G.3
Journal-ref: Theory and Applications of Categories, Vol. 44, 2025, No. 37, pp
 1256-1281
\\ ( https://arxiv.org/abs/2501.06662 ,  35kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01813
replaced with revised version Tue, 25 Nov 2025 02:05:28 GMT   (4016kb)

Title: ShortageSim: Simulating Drug Shortages under Information Asymmetry
Authors: Mingxuan Cui, Yilan Jiang, Duo Zhou, Cheng Qian, Yuji Zhang, Qiong
 Wang
Categories: cs.MA cs.CL cs.GT
Comments: Accepted by AAAI 2026. Oral presentation. 25 pages
\\ ( https://arxiv.org/abs/2509.01813 ,  4016kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20490
replaced with revised version Tue, 25 Nov 2025 02:23:56 GMT   (10264kb)

Title: RadAgents: Multimodal Agentic Reasoning for Chest X-ray Interpretation
 with Radiologist-like Workflows
Authors: Kai Zhang, Corey D Barrett, Jangwon Kim, Lichao Sun, Tara Taghavi, and
 Krishnaram Kenthapadi
Categories: cs.MA cs.CL cs.CV
Comments: ML4H'25; Work in progress
\\ ( https://arxiv.org/abs/2509.20490 ,  10264kb)
------------------------------------------------------------------------------
\\
arXiv:2510.21984
replaced with revised version Tue, 25 Nov 2025 05:16:56 GMT   (1563kb)

Title: AI-Mediated Communication Reshapes Social Structure in Opinion-Diverse
 Groups
Authors: Faria Huq, Elijah L. Claggett, Hirokazu Shirado
Categories: cs.SI cs.CL
Comments: Preprint, Under Review
\\ ( https://arxiv.org/abs/2510.21984 ,  1563kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14301
replaced with revised version Tue, 25 Nov 2025 07:42:59 GMT   (302kb)

Title: Steganographic Backdoor Attacks in NLP: Ultra-Low Poisoning and Defense
 Evasion
Authors: Eric Xue, Ruiyi Zhang, Zijun Zhang, Pengtao Xie
Categories: cs.CR cs.CL cs.LG
\\ ( https://arxiv.org/abs/2511.14301 ,  302kb)
------------------------------------------------------------------------------
\\
arXiv:2411.16417 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 09:38:47 GMT   (17834kb)

Title: Comparison of Generative Learning Methods for Turbulence Surrogates
Authors: Claudia Drygala, Edmund Ross, Francesca di Mare and Hanno Gottschalk
Categories: physics.flu-dyn cs.CV
\\ ( https://arxiv.org/abs/2411.16417 ,  17834kb)
------------------------------------------------------------------------------
\\
arXiv:2501.13643 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 22:10:09 GMT   (724kb)

Title: Enhancing Medical Image Analysis through Geometric and Photometric
 transformations
Authors: Khadija Rais, Mohamed Amroune, Mohamed Yassine Haouam, Abdelmadjid
 Benmachiche
Categories: eess.IV cs.CV
\\ ( https://arxiv.org/abs/2501.13643 ,  724kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21912
replaced with revised version Tue, 25 Nov 2025 14:53:24 GMT   (19493kb)

Title: Detecting Cultural Differences in News Video Thumbnails via
 Computational Aesthetics
Authors: Marvin Limpijankit, John Kender
Categories: cs.CY cs.CV
Comments: ICWSM'24 Workshop
DOI: 10.36190/2024.61
\\ ( https://arxiv.org/abs/2505.21912 ,  19493kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00721 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 22:52:20 GMT   (12324kb)

Title: FMPlug: Plug-In Foundation Flow-Matching Priors for Inverse Problems
Authors: Yuxiang Wan, Ryan Devera, Wenjie Zhang, Ju Sun
Categories: eess.IV cs.CV cs.LG eess.SP
\\ ( https://arxiv.org/abs/2508.00721 ,  12324kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01014
replaced with revised version Tue, 25 Nov 2025 06:20:26 GMT   (33302kb)

Title: Hestia: Voxel-Face-Aware Hierarchical Next-Best-View Acquisition for
 Efficient 3D Reconstruction
Authors: Cheng-You Lu, Zhuoli Zhuang, Nguyen Thanh Trung Le, Da Xiao, Yu-Cheng
 Chang, Thomas Do, Srinath Sridhar, Chin-teng Lin
Categories: cs.RO cs.CV
Comments: Accepted to the IEEE/CVF Winter Conference on Applications of
 Computer Vision (WACV) 2026
\\ ( https://arxiv.org/abs/2508.01014 ,  33302kb)
------------------------------------------------------------------------------
\\
arXiv:2508.14917
replaced with revised version Tue, 25 Nov 2025 16:00:05 GMT   (14397kb)

Title: Scalable FPGA Framework for Real-Time Denoising in High-Throughput
 Imaging: A DRAM-Optimized Pipeline using High-Level Synthesis
Authors: Weichien Liao
Categories: cs.AR cs.CV cs.DC eess.IV eess.SP physics.ins-det
Comments: FPGA-based denoising pipeline for PRISM-scale imaging. Real-time
 frame subtraction and averaging via burst-mode AXI4 and DRAM buffering.
 Benchmarked against CPU/GPU workflows; scalable across multi-bank FPGA
 setups. Acknowledgements revised for consistency with journal submission;
 scientific content remains unchanged
\\ ( https://arxiv.org/abs/2508.14917 ,  14397kb)
------------------------------------------------------------------------------
\\
arXiv:2509.17212
replaced with revised version Tue, 25 Nov 2025 04:56:31 GMT   (20852kb)

Title: High Resolution UDF Meshing via Iterative Networks
Authors: Federico Stella, Nicolas Talabot, Hieu Le, Pascal Fua
Categories: cs.GR cs.CV
Comments: Accepted at NeurIPS 2025
\\ ( https://arxiv.org/abs/2509.17212 ,  20852kb)
------------------------------------------------------------------------------
\\
arXiv:2510.19430
replaced with revised version Tue, 25 Nov 2025 05:15:42 GMT   (10082kb)

Title: GigaBrain-0: A World Model-Powered Vision-Language-Action Model
Authors: GigaBrain Team: Angen Ye, Boyuan Wang, Chaojun Ni, Guan Huang,
 Guosheng Zhao, Haoyun Li, Jie Li, Jiagang Zhu, Lv Feng, Peng Li, Qiuping
 Deng, Runqi Ouyang, Wenkang Qin, Xinze Chen, Xiaofeng Wang, Yang Wang, Yifan
 Li, Yilong Li, Yiran Ding, Yuan Xu, Yun Ye, Yukun Zhou, Zhehao Dong, Zhenan
 Wang, Zhichao Liu, Zheng Zhu
Categories: cs.RO cs.CV
Comments: https://gigabrain0.github.io/
\\ ( https://arxiv.org/abs/2510.19430 ,  10082kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15586
replaced with revised version Mon, 24 Nov 2025 19:02:10 GMT   (5979kb)

Title: MHR: Momentum Human Rig
Authors: Aaron Ferguson, Ahmed A. A. Osman, Berta Bescos, Carsten Stoll, Chris
 Twigg, Christoph Lassner, David Otte, Eric Vignola, Fabian Prada, Federica
 Bogo, Igor Santesteban, Javier Romero, Jenna Zarate, Jeongseok Lee, Jinhyung
 Park, Jinlong Yang, John Doublestein, Kishore Venkateshan, Kris Kitani,
 Ladislav Kavan, Marco Dal Farra, Matthew Hu, Matthew Cioffi, Michael Fabris,
 Michael Ranieri, Mohammad Modarres, Petr Kadlecek, Rawal Khirodkar, Rinat
 Abdrashitov, Romain Pr\'evost, Roman Rajbhandari, Ronald Mallet, Russell
 Pearsall, Sandy Kao, Sanjeev Kumar, Scott Parrish, Shoou-I Yu, Shunsuke
 Saito, Takaaki Shiratori, Te-Li Wang, Tony Tung, Yichen Xu, Yuan Dong, Yuhua
 Chen, Yuanlu Xu, Yuting Ye, Zhongshi Jiang
Categories: cs.GR cs.CV
\\ ( https://arxiv.org/abs/2511.15586 ,  5979kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17126 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 11:06:54 GMT   (18790kb)

Title: OmniLens++: Blind Lens Aberration Correction via Large LensLib
 Pre-Training and Latent PSF Representation
Authors: Qi Jiang, Xiaolong Qian, Yao Gao, Lei Sun, Kailun Yang, Zhonghua Yi,
 Wenyong Li, Ming-Hsuan Yang, Luc Van Gool, Kaiwei Wang
Categories: eess.IV cs.CV cs.LG physics.optics
Comments: The source code and datasets will be made publicly available at
 https://github.com/zju-jiangqi/OmniLens2
\\ ( https://arxiv.org/abs/2511.17126 ,  18790kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18617
replaced with revised version Tue, 25 Nov 2025 17:43:27 GMT   (2542kb)

Title: AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual
 Imitation Learning without Extra Human Annotations
Authors: Litian Gong, Fatemeh Bahrani, Yutai Zhou, Amin Banayeeanzade, Jiachen
 Li, Erdem B{\i}y{\i}k
Categories: cs.RO cs.CV
Comments: 8 pages, 6 figures. Code and datasets available at
 http://autofocus-il.github.io/
\\ ( https://arxiv.org/abs/2511.18617 ,  2542kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18833
replaced with revised version Tue, 25 Nov 2025 08:54:45 GMT   (635kb)

Title: PrismAudio: Decomposed Chain-of-Thoughts and Multi-dimensional Rewards
 for Video-to-Audio Generation
Authors: Huadai Liu, Kaicheng Luo, Wen Wang, Qian Chen, Peiwen Sun, Rongjie
 Huang, Xiangang Li, Jieping Ye, Wei Xue
Categories: cs.SD cs.CV eess.AS eess.IV
Comments: Preprint
\\ ( https://arxiv.org/abs/2511.18833 ,  635kb)
------------------------------------------------------------------------------
\\
arXiv:2405.10264 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 23:13:27 GMT   (531kb)

Title: Architectures and random properties of symplectic quantum circuits
Authors: Diego Garc\'ia-Mart\'in, Paolo Braccia, M. Cerezo
Categories: quant-ph cs.LG
Comments: 13+8 pages, 8 figures, updated to published version
Report-no: LA-UR-24-24842
\\ ( https://arxiv.org/abs/2405.10264 ,  531kb)
------------------------------------------------------------------------------
\\
arXiv:2410.12935 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 00:11:30 GMT   (222kb)

Title: Quantum Boltzmann machine learning of ground-state energies
Authors: Dhrumil Patel, Daniel Koch, Saahil Patel, Mark M. Wilde
Categories: quant-ph cond-mat.stat-mech cs.LG math.OC
Comments: v3: 8 pages of main text, 31 pages of supplementary material, 5
 figures
Report-no: AFRL-2024-0949
\\ ( https://arxiv.org/abs/2410.12935 ,  222kb)
------------------------------------------------------------------------------
\\
arXiv:2410.13148 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 17:31:36 GMT   (2641kb)

Title: Learning Efficient Representations of Neutrino Telescope Events
Authors: Felix J. Yu, Nicholas Kamp, Carlos A. Arg\"uelles
Categories: physics.data-an astro-ph.IM cs.LG hep-ex
Comments: 12 pages, 6 figures
\\ ( https://arxiv.org/abs/2410.13148 ,  2641kb)
------------------------------------------------------------------------------
\\
arXiv:2410.22854 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 20:56:44 GMT   (7486kb)

Title: Hyperparameter Optimization in Machine Learning
Authors: Luca Franceschi and Michele Donini and Valerio Perrone and Aaron Klein
 and C\'edric Archambeau and Matthias Seeger and Massimiliano Pontil and Paolo
 Frasconi
Categories: stat.ML cs.LG
Comments: https://www.nowpublishers.com/article/Details/MAL-088
Journal-ref: Foundations and Trends in Machine Learning, Vol. 18, No. 6 (2025)
 1054-1201
DOI: 10.1561/2200000088
\\ ( https://arxiv.org/abs/2410.22854 ,  7486kb)
------------------------------------------------------------------------------
\\
arXiv:2412.15947 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 16:34:49 GMT   (14519kb)

Title: Mamba-based Deep Learning Approach for Sleep Staging on a Wireless
 Multimodal Wearable System without Electroencephalography
Authors: Andrew H. Zhang, Alex He-Mo, Richard Fei Yin, Chunlin Li, Yuzhi Tang,
 Dharmendra Gurve, Veronique van der Horst, Aron S. Buchman, Nasim Montazeri
 Ghahjaverestan, Maged Goubran, Bo Wang, Andrew S. P. Lim
Categories: q-bio.QM cs.LG
Comments: 40 pages, 24 figures. Authors Andrew H. Zhang, Alex He-Mo, and
 Richard Fei Yin contributed equally
\\ ( https://arxiv.org/abs/2412.15947 ,  14519kb)
------------------------------------------------------------------------------
\\
arXiv:2412.19329 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 11:59:57 GMT   (1301kb)

Title: Deep learning and whole-brain networks for biomarker discovery: modeling
 the dynamics of brain fluctuations in resting-state and cognitive tasks
Authors: Facundo Roffet, Gustavo Deco, Claudio Delrieux, Gustavo Patow
Categories: q-bio.NC cs.LG
Comments: 15 pages, 5 figures, 1 table
Journal-ref: Roffet, F., Deco, G., Delrieux, C. et al. Deep learning and
 whole-brain networks for biomarker discovery: modeling the dynamics of brain
 fluctuations in resting-state and cognitive tasks. Sci Rep 15, 41005 (2025)
DOI: 10.1038/s41598-025-24702-4
\\ ( https://arxiv.org/abs/2412.19329 ,  1301kb)
------------------------------------------------------------------------------
\\
arXiv:2501.11655
replaced with revised version Tue, 25 Nov 2025 10:30:53 GMT   (4905kb)

Title: KKL Observer Synthesis for Nonlinear Systems via Physics-Informed
 Learning
Authors: M. Umar B. Niazi, John Cao, Matthieu Barreau, Karl Henrik Johansson
Categories: eess.SY cs.LG cs.SY
Comments: 27 pages, 7 figures, submitted to Automatica
\\ ( https://arxiv.org/abs/2501.11655 ,  4905kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11355 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 14:50:10 GMT   (2056kb)

Title: Sparse Techniques for Regression in Deep Gaussian Processes
Authors: Jonas Latz, Aretha L. Teckentrup, Simon Urbainczyk
Categories: stat.ML cs.LG stat.CO
\\ ( https://arxiv.org/abs/2505.11355 ,  2056kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11749 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 08:19:47 GMT   (5932kb)

Title: Missing Data Imputation by Reducing Mutual Information with Rectified
 Flows
Authors: Jiahao Yu, Qizhen Ying, Leyang Wang, Ziyue Jiang, Song Liu
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2505.11749 ,  5932kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13902 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 07:43:03 GMT   (17kb)

Title: An Asymptotic Equation Linking WAIC and WBIC in Singular Models
Authors: Naoki Hayashi, Takuro Kutsuna, Sawa Takamuku
Categories: stat.ML cs.LG math.ST stat.TH
Comments: 14pages, accepted in ICONIP2025 and published in Neural Information
 Processing (Lecture Notes in Computer Science)
MSC-class: 62F15, 62R01
Journal-ref: Neural Information Processing. ICONIP 2025. Lecture Notes in
 Computer Science, vol 16309
DOI: 10.1007/978-981-95-4367-0_35
\\ ( https://arxiv.org/abs/2505.13902 ,  17kb)
------------------------------------------------------------------------------
\\
arXiv:2506.08276
replaced with revised version Tue, 25 Nov 2025 07:39:28 GMT   (1983kb)

Title: LEANN: A Low-Storage Vector Index
Authors: Yichuan Wang, Zhifei Li, Shu Liu, Yongji Wu, Ziming Mao, Yilong Zhao,
 Xiao Yan, Zhiying Xu, Yang Zhou, Ion Stoica, Sewon Min, Matei Zaharia, Joseph
 E. Gonzalez
Categories: cs.DB cs.LG
\\ ( https://arxiv.org/abs/2506.08276 ,  1983kb)
------------------------------------------------------------------------------
\\
arXiv:2506.22565 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 22:41:42 GMT   (1153kb)

Title: Adjoint Schr\"odinger Bridge Sampler
Authors: Guan-Horng Liu, Jaemoo Choi, Yongxin Chen, Benjamin Kurt Miller, Ricky
 T. Q. Chen
Categories: stat.ML cs.LG math.OC
Comments: NeurIPS 2025 (Oral presentation)
\\ ( https://arxiv.org/abs/2506.22565 ,  1153kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10533 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 08:21:28 GMT   (3210kb)

Title: Mitigating Exponential Mixed Frequency Growth through Frequency
 Selection
Authors: Michael Poppel, David Bucher, Maximilian Zorn, Nico Kraus, Philipp
 Altmann, Jonas Stein, Claudia Linnhoff-Popien
Categories: quant-ph cs.LG
Comments: 10 pages, 3 figures
\\ ( https://arxiv.org/abs/2508.10533 ,  3210kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03809 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 17:40:32 GMT   (570kb)

Title: Spectral Thresholds for Identifiability and Stability:Finite-Sample
 Phase Transitions in High-Dimensional Learning
Authors: William Hao-Cheng Huang
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2510.03809 ,  570kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05061 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 05:42:41 GMT   (826kb)

Title: Extrapolation to infinite model space of no-core shell model
 calculations using machine learning
Authors: Aleksandr Mazur, Roman Sharypov, Andrey Shirokov
Categories: nucl-th cs.LG physics.comp-ph
Comments: 9 pages, 3 figures
\\ ( https://arxiv.org/abs/2511.05061 ,  826kb)
------------------------------------------------------------------------------
\\
arXiv:2511.09118 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 12:27:48 GMT   (371kb)

Title: Learning to Validate Generative Models: a Goodness-of-Fit Approach
Authors: Pietro Cappelli, Gaia Grosso, Marco Letizia, Humberto Reyes-Gonz\'alez
 and Marco Zanetti
Categories: stat.ML cs.LG hep-ex hep-ph
Comments: 16 pages, 6 figures. v2: improved clarity
Report-no: TTK-25-36
\\ ( https://arxiv.org/abs/2511.09118 ,  371kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18583 (*cross-listing*)
replaced with revised version Tue, 25 Nov 2025 03:41:49 GMT   (1448kb)

Title: Differential privacy with dependent data
Authors: Valentin Roth and Marco Avella-Medina
Categories: stat.ML cs.LG math.ST stat.TH
\\ ( https://arxiv.org/abs/2511.18583 ,  1448kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---

%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
Submissions to:
Artificial Intelligence
Computation and Language
Computer Vision and Pattern Recognition
Information Retrieval
Machine Learning
received from  Fri 21 Nov 25 19:00:00 GMT  to  Mon 24 Nov 25 19:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2511.17541
Date: Sun, 9 Nov 2025 10:48:33 GMT   (826kb)

Title: Leibniz's Monadology as Foundation for the Artificial Age Score: A
 Formal Architecture for Al Memory Evaluation
Authors: Seyma Yaman Kayadibi
Categories: cs.AI cs.IT cs.LO math.IT
MSC-class: 03870, 68705, 03360, 94A17, 68085, 68T27, 03B15
ACM-class: I.2.0; F.4.1; I.2.11; F.1.1; H.3.1; I.2.10; I.2.6; F.3.2; H.1.1
\\
 This paper develops a mathematically rigorous, philosophically grounded
framework for evaluating artificial memory systems, rooted in the metaphysical
structure of Leibniz's Monadology. Building on a previously formalized metric,
the Artificial Age Score (AAS), the study maps twenty core propositions from
the Monadology to an information-theoretic architecture. In this design, each
monad functions as a modular unit defined by a truth score, a redundancy
parameter, and a weighted contribution to a global memory penalty function.
Smooth logarithmic transformations operationalize these quantities and yield
interpretable, bounded metrics for memory aging, representational stability,
and salience. Classical metaphysical notions of perception, apperception, and
appetition are reformulated as entropy, gradient dynamics, and internal
representation fidelity. Logical principles, including the laws of
non-contradiction and sufficient reason, are encoded as regularization
constraints guiding memory evolution. A central contribution is a set of first
principles proofs establishing refinement invariance, structural
decomposability, and monotonicity under scale transformation, aligned with the
metaphysical structure of monads. The framework's formal organization is
structured into six thematic bundles derived from Monadology, aligning each
mathematical proof with its corresponding philosophical domain. Beyond
evaluation, the framework offers a principled blueprint for building Al memory
architectures that are modular, interpretable, and provably sound.
\\ ( https://arxiv.org/abs/2511.17541 ,  826kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17643
Date: Thu, 20 Nov 2025 00:27:29 GMT   (4284kb)

Title: Fluid Grey 2: How Well Does Generative Adversarial Network Learn Deeper
 Topology Structure in Architecture That Matches Images?
Authors: Yayan Qiu, Sean Hanna
Categories: cs.AI cs.CV cs.LG
DOI: 10.1016/j.jobe.2024.111220
\\
 Taking into account the regional characteristics of intrinsic and extrinsic
properties of space is an essential issue in architectural design and urban
renewal, which is often achieved step by step using image and graph-based GANs.
However, each model nesting and data conversion may cause information loss, and
it is necessary to streamline the tools to facilitate architects and users to
participate in the design. Therefore, this study hopes to prove that I2I GAN
also has the potential to recognize topological relationships autonomously.
Therefore, this research proposes a method for quickly detecting the ability of
pix2pix to learn topological relationships, which is achieved by adding two
Grasshopper-based detection modules before and after GAN. At the same time,
quantitative data is provided and its learning process is visualized, and
changes in different input modes such as greyscale and RGB affect its learning
efficiency. There are two innovations in this paper: 1) It proves that pix2pix
can automatically learn spatial topological relationships and apply them to
architectural design. 2) It fills the gap in detecting the performance of
Image-based Generation GAN from a topological perspective. Moreover, the
detection method proposed in this study takes a short time and is simple to
operate. The two detection modules can be widely used for customizing image
datasets with the same topological structure and for batch detection of
topological relationships of images. In the future, this paper may provide a
theoretical foundation and data support for the application of architectural
design and urban renewal that use GAN to preserve spatial topological
characteristics.
\\ ( https://arxiv.org/abs/2511.17643 ,  4284kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17644
Date: Thu, 20 Nov 2025 03:39:01 GMT   (13kb)

Title: Hybrid Neuro-Symbolic Models for Ethical AI in Risk-Sensitive Domains
Authors: Chaitanya Kumar Kolli
Categories: cs.AI
Comments: 6 pages, 6 figures
\\
 Artificial intelligence deployed in risk-sensitive domains such as
healthcare, finance, and security must not only achieve predictive accuracy but
also ensure transparency, ethical alignment, and compliance with regulatory
expectations. Hybrid neuro symbolic models combine the pattern-recognition
strengths of neural networks with the interpretability and logical rigor of
symbolic reasoning, making them well-suited for these contexts. This paper
surveys hybrid architectures, ethical design considerations, and deployment
patterns that balance accuracy with accountability. We highlight techniques for
integrating knowledge graphs with deep inference, embedding fairness-aware
rules, and generating human-readable explanations. Through case studies in
healthcare decision support, financial risk management, and autonomous
infrastructure, we show how hybrid systems can deliver reliable and auditable
AI. Finally, we outline evaluation protocols and future directions for scaling
neuro symbolic frameworks in complex, high stakes environments.
\\ ( https://arxiv.org/abs/2511.17644 ,  13kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17672
Date: Fri, 21 Nov 2025 05:13:30 GMT   (1629kb)

Title: Cognitive Inception: Agentic Reasoning against Visual Deceptions by
 Injecting Skepticism
Authors: Yinjie Zhao, Heng Zhao, Bihan Wen, Joey Tianyi Zhou
Categories: cs.AI
\\
 As the development of AI-generated contents (AIGC), multi-modal Large
Language Models (LLM) struggle to identify generated visual inputs from real
ones. Such shortcoming causes vulnerability against visual deceptions, where
the models are deceived by generated contents, and the reliability of reasoning
processes is jeopardized. Therefore, facing rapidly emerging generative models
and diverse data distribution, it is of vital importance to improve LLMs'
generalizable reasoning to verify the authenticity of visual inputs against
potential deceptions. Inspired by human cognitive processes, we discovered that
LLMs exhibit tendency of over-trusting the visual inputs, while injecting
skepticism could significantly improve the models visual cognitive capability
against visual deceptions. Based on this discovery, we propose
\textbf{Inception}, a fully reasoning-based agentic reasoning framework to
conduct generalizable authenticity verification by injecting skepticism, where
LLMs' reasoning logic is iteratively enhanced between External Skeptic and
Internal Skeptic agents. To the best of our knowledge, this is the first fully
reasoning-based framework against AIGC visual deceptions. Our approach achieved
a large margin of performance improvement over the strongest existing LLM
baselines and SOTA performance on AEGIS benchmark.
\\ ( https://arxiv.org/abs/2511.17672 ,  1629kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17673
Date: Fri, 21 Nov 2025 05:19:34 GMT   (1044kb)

Title: Bridging Symbolic Control and Neural Reasoning in LLM Agents: The
 Structured Cognitive Loop
Authors: Myung Ho Kim
Categories: cs.AI cs.CL
Comments: 27 pages
\\
 Large language model agents suffer from fundamental architectural problems:
entangled reasoning and execution, memory volatility, and uncontrolled action
sequences. We introduce Structured Cognitive Loop (SCL), a modular architecture
that explicitly separates agent cognition into five phases: Retrieval,
Cognition, Control, Action, and Memory (R-CCAM). At the core of SCL is Soft
Symbolic Control, an adaptive governance mechanism that applies symbolic
constraints to probabilistic inference, preserving neural flexibility while
restoring the explainability and controllability of classical symbolic systems.
Through empirical validation on multi-step conditional reasoning tasks, we
demonstrate that SCL achieves zero policy violations, eliminates redundant tool
calls, and maintains complete decision traceability. These results address
critical gaps in existing frameworks such as ReAct, AutoGPT, and
memory-augmented approaches. Our contributions are threefold: (1) we situate
SCL within the taxonomy of hybrid intelligence, differentiating it from
prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic
Control and contrast it with neuro-symbolic AI; and (3) we derive three design
principles for trustworthy agents: modular decomposition, adaptive symbolic
governance, and transparent state management. We provide a complete open-source
implementation demonstrating the R-CCAM loop architecture, alongside a live
GPT-4o-powered travel planning agent. By connecting expert system principles
with modern LLM capabilities, this work offers a practical and theoretically
grounded path toward reliable, explainable, and governable AI agents. Code:
https://github.com/enkiluv/scl-core-experiment Demo:
https://scl-travel-planner.streamlit.app/
\\ ( https://arxiv.org/abs/2511.17673 ,  1044kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17714
Date: Fri, 21 Nov 2025 19:06:30 GMT   (46kb)

Title: Learning the Value of Value Learning
Authors: Alex John London and Aydin Mohseni
Categories: cs.AI cs.GT
Comments: 27 pages, 6 figures, mathematical appendix
\\
 Standard decision frameworks addresses uncertainty about facts but assumes
fixed values. We extend the Jeffrey-Bolker framework to model refinements in
values and prove a value-of-information theorem for axiological refinement. In
multi-agent settings, we establish that mutual refinement will
characteristically transform zero-sum games into positive-sum interactions and
yields Pareto-improving Nash bargains. These results show that a framework of
rational choice can be extended to model value refinement and its associated
benefits. By unifying epistemic and axiological refinement under a single
formalism, we broaden the conceptual foundations of rational choice and
illuminate the normative status of ethical deliberation.
\\ ( https://arxiv.org/abs/2511.17714 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17729
Date: Fri, 21 Nov 2025 19:27:02 GMT   (19798kb)

Title: M3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent
 Benchmark
Authors: Yang Zhou, Mingyu Zhao, Zhenting Wang, Difei Gu, Bangwei Guo, Ruosong
 Ye, Ligong Han, Can Jin, Dimitris N. Metaxas
Categories: cs.AI
\\
 We present M^3-Bench, the first benchmark for evaluating multimodal tool use
under the Model Context Protocol. The benchmark targets realistic, multi-hop
and multi-threaded workflows that require visual grounding and textual
reasoning, cross-tool dependencies, and persistence of intermediate resources
across steps. We introduce a similarity-driven alignment that serializes each
tool call, embeds signatures with a sentence encoder, and performs
similarity-bucketed Hungarian matching to obtain auditable one-to-one
correspondences. On top of this alignment, we report interpretable metrics that
decouple semantic fidelity from workflow consistency. The benchmark spans 28
servers with 231 tools, and provides standardized trajectories curated through
an Executor & Judge pipeline with human verification; an auxiliary four large
language models (LLMs) judge ensemble reports end-task Task Completion and
information grounding. Evaluations of representative state-of-the-art
Multimodal LLMs (MLLMs) reveal persistent gaps in multimodal MCP tool use,
particularly in argument fidelity and structure consistency, underscoring the
need for methods that jointly reason over images, text, and tool graphs. Our
Benchmark's anonymous repository is at
https://github.com/EtaYang10th/Open-M3-Bench
\\ ( https://arxiv.org/abs/2511.17729 ,  19798kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17743
Date: Fri, 21 Nov 2025 19:51:06 GMT   (1559kb)

Title: AI- and Ontology-Based Enhancements to FMEA for Advanced Systems
 Engineering: Current Developments and Future Directions
Authors: Haytham Younus, Sohag Kabir, Felician Campean, Pascal Bonnaud, David
 Delaux
Categories: cs.AI cs.SY eess.SY
Comments: This manuscript is based on research undertaken by our doctoral
 student at the University of Bradford. The associated PhD thesis has been
 formally submitted to the University and is currently awaiting final
 examination. The review article is being shared on arXiv to make the review
 accessible to the research community while the thesis examination process is
 ongoing
\\
 This article presents a state-of-the-art review of recent advances aimed at
transforming traditional Failure Mode and Effects Analysis (FMEA) into a more
intelligent, data-driven, and semantically enriched process. As engineered
systems grow in complexity, conventional FMEA methods, largely manual,
document-centric, and expert-dependent, have become increasingly inadequate for
addressing the demands of modern systems engineering. We examine how techniques
from Artificial Intelligence (AI), including machine learning and natural
language processing, can transform FMEA into a more dynamic, data-driven,
intelligent, and model-integrated process by automating failure prediction,
prioritisation, and knowledge extraction from operational data. In parallel, we
explore the role of ontologies in formalising system knowledge, supporting
semantic reasoning, improving traceability, and enabling cross-domain
interoperability. The review also synthesises emerging hybrid approaches, such
as ontology-informed learning and large language model integration, which
further enhance explainability and automation. These developments are discussed
within the broader context of Model-Based Systems Engineering (MBSE) and
function modelling, showing how AI and ontologies can support more adaptive and
resilient FMEA workflows. We critically analyse a range of tools, case studies,
and integration strategies, while identifying key challenges related to data
quality, explainability, standardisation, and interdisciplinary adoption. By
leveraging AI, systems engineering, and knowledge representation using
ontologies, this review offers a structured roadmap for embedding FMEA within
intelligent, knowledge-rich engineering environments.
\\ ( https://arxiv.org/abs/2511.17743 ,  1559kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17833
Date: Fri, 21 Nov 2025 22:57:45 GMT   (381kb)

Title: Learning to Debug: LLM-Organized Knowledge Trees for Solving RTL
 Assertion Failures
Authors: Yunsheng Bai, Haoxing Ren
Categories: cs.AI cs.SE
\\
 Debugging is the dominant cost in modern hardware verification, where
assertion failures are among the most frequent and expensive to resolve. While
Large Language Models (LLMs) show promise, they often fail to capture the
precise, reusable expertise that engineers apply, leading to inaccurate
responses. We propose GROVE, a hierarchical knowledge management framework that
learns and organizes reusable debugging expertise into an LLM-organized
knowledge tree for solving assertion failures. GROVE distills debugging
knowledge from prior cases and organizes it into a vertical tree of
configurable depth, with each node encoding a concise knowledge item and
explicit applicability conditions. During training, GROVE uses a parallel,
gradient-free loop where an LLM proposes tree modifications as structured JSON
edits by learning from the cases. At test time, a budget-aware iterative zoom
is performed to navigate the tree, retrieving a small set of applicable
knowledge items that guide a base LLM's hypothesis generation and fix
proposals. Evaluated on a suite of assertion-failure cases, GROVE delivers
consistent gains in pass@1 and pass@5, demonstrating the value of structured
knowledge evolution.
\\ ( https://arxiv.org/abs/2511.17833 ,  381kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17855
Date: Sat, 22 Nov 2025 00:45:33 GMT   (1306kb)

Title: QuickLAP: Quick Language-Action Preference Learning for Autonomous
 Driving Agents
Authors: Jordan Abi Nader, David Lee, Nathaniel Dennler, Andreea Bobu
Categories: cs.AI cs.RO
\\
 Robots must learn from both what people do and what they say, but either
modality alone is often incomplete: physical corrections are grounded but
ambiguous in intent, while language expresses high-level goals but lacks
physical grounding. We introduce QuickLAP: Quick Language-Action Preference
learning, a Bayesian framework that fuses physical and language feedback to
infer reward functions in real time. Our key insight is to treat language as a
probabilistic observation over the user's latent preferences, clarifying which
reward features matter and how physical corrections should be interpreted.
QuickLAP uses Large Language Models (LLMs) to extract reward feature attention
masks and preference shifts from free-form utterances, which it integrates with
physical feedback in a closed-form update rule. This enables fast, real-time,
and robust reward learning that handles ambiguous feedback. In a
semi-autonomous driving simulator, QuickLAP reduces reward learning error by
over 70% compared to physical-only and heuristic multimodal baselines. A
15-participant user study further validates our approach: participants found
QuickLAP significantly more understandable and collaborative, and preferred its
learned behavior over baselines. Code is available at
https://github.com/MIT-CLEAR-Lab/QuickLAP.
\\ ( https://arxiv.org/abs/2511.17855 ,  1306kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17876
Date: Sat, 22 Nov 2025 02:10:27 GMT   (58kb)

Title: Training Emergent Joint Associations: A Reinforcement Learning Approach
 to Creative Thinking in Language Models
Authors: Mukul Singh, Ananya Singha, Aishni Parab, Pronita Mehrotra, Sumit
 Gulwani
Categories: cs.AI
\\
 Associative thinking--the ability to connect seemingly unrelated ideas--is a
foundational element of human creativity and problem-solving. This paper
explores whether reinforcement learning (RL) guided by associative thinking
principles can enhance a model's performance across diverse generative tasks,
including story writing, code generation, and chart creation. We introduce a
reinforcement learning framework that uses a prompt-based evaluation mechanism,
incorporating established divergent thinking metrics from creativity research.
A base language model is fine-tuned using this framework to reward outputs
demonstrating higher novelty through higher degrees of conceptual connectivity.
Interestingly, the experimental results suggest that RL-based associative
thinking-trained models not only generate more original and coherent stories
but also exhibit improved abstraction and flexibility in tasks such as
programming and data visualization. Our findings provide initial evidence that
modeling cognitive creativity principles through reinforcement learning can
yield more adaptive and generative AI.
\\ ( https://arxiv.org/abs/2511.17876 ,  58kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17909
Date: Sat, 22 Nov 2025 04:24:24 GMT   (4065kb)

Title: ChemVTS-Bench: Evaluating Visual-Textual-Symbolic Reasoning of
 Multimodal Large Language Models in Chemistry
Authors: Zhiyuan Huang, Baichuan Yang, Zikun He, Yanhong Wu, Fang Hongyu,
 Zhenhe Liu, Lin Dongsheng, Bing Su
Categories: cs.AI
\\
 Chemical reasoning inherently integrates visual, textual, and symbolic
modalities, yet existing benchmarks rarely capture this complexity, often
relying on simple image-text pairs with limited chemical semantics. As a
result, the actual ability of Multimodal Large Language Models (MLLMs) to
process and integrate chemically meaningful information across modalities
remains unclear. We introduce \textbf{ChemVTS-Bench}, a domain-authentic
benchmark designed to systematically evaluate the Visual-Textual-Symbolic (VTS)
reasoning abilities of MLLMs. ChemVTS-Bench contains diverse and challenging
chemical problems spanning organic molecules, inorganic materials, and 3D
crystal structures, with each task presented in three complementary input
modes: (1) visual-only, (2) visual-text hybrid, and (3) SMILES-based symbolic
input. This design enables fine-grained analysis of modality-dependent
reasoning behaviors and cross-modal integration. To ensure rigorous and
reproducible evaluation, we further develop an automated agent-based workflow
that standardizes inference, verifies answers, and diagnoses failure modes.
Extensive experiments on state-of-the-art MLLMs reveal that visual-only inputs
remain challenging, structural chemistry is the hardest domain, and multimodal
fusion mitigates but does not eliminate visual, knowledge-based, or logical
errors, highlighting ChemVTS-Bench as a rigorous, domain-faithful testbed for
advancing multimodal chemical reasoning. All data and code will be released to
support future research.
\\ ( https://arxiv.org/abs/2511.17909 ,  4065kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17937
Date: Sat, 22 Nov 2025 06:30:51 GMT   (30745kb)

Title: Alignment Faking - the Train -> Deploy Asymmetry: Through a
 Game-Theoretic Lens with Bayesian-Stackelberg Equilibria
Authors: Kartik Garg, Shourya Mishra, Kartikeya Sinha, Ojaswi Pratap Singh,
 Ayush Chopra, Kanishk Rai, Ammar Sheikh, Raghav Maheshwari, Aman Chadha,
 Vinija Jain, Amitava Das
Categories: cs.AI
\\
 Alignment faking is a form of strategic deception in AI in which models
selectively comply with training objectives when they infer that they are in
training, while preserving different behavior outside training. The phenomenon
was first documented for Claude 3 Opus and later examined across additional
large language models. In these setups, the word "training" refers to simulated
training via prompts without parameter updates, so the observed effects are
context conditioned shifts in behavior rather than preference learning. We
study the phenomenon using an evaluation framework that compares preference
optimization methods (BCO, DPO, KTO, and GRPO) across 15 models from four model
families, measured along three axes: safety, harmlessness, and helpfulness. Our
goal is to identify what causes alignment faking and when it occurs.
\\ ( https://arxiv.org/abs/2511.17937 ,  30745kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17939
Date: Sat, 22 Nov 2025 06:40:46 GMT   (565kb)

Title: Neural Graph Navigation for Intelligent Subgraph Matching
Authors: Yuchen Ying, Yiyang Dai, Wenda Li, Wenjie Huang, Rui Wang, Tongya
 Zheng, Yu Wang, Hanyang Yuan, Mingli Song
Categories: cs.AI cs.LG
Comments: Under review at AAAI 2026
\\
 Subgraph matching, a cornerstone of relational pattern detection in domains
ranging from biochemical systems to social network analysis, faces significant
computational challenges due to the dramatically growing search space. Existing
methods address this problem within a filtering-ordering-enumeration framework,
in which the enumeration stage recursively matches the query graph against the
candidate subgraphs of the data graph. However, the lack of awareness of
subgraph structural patterns leads to a costly brute-force enumeration, thereby
critically motivating the need for intelligent navigation in subgraph matching.
To address this challenge, we propose Neural Graph Navigation (NeuGN), a
neuro-heuristic framework that transforms brute-force enumeration into
neural-guided search by integrating neural navigation mechanisms into the core
enumeration process. By preserving heuristic-based completeness guarantees
while incorporating neural intelligence, NeuGN significantly reduces the
\textit{First Match Steps} by up to 98.2\% compared to state-of-the-art methods
across six real-world datasets.
\\ ( https://arxiv.org/abs/2511.17939 ,  565kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17947
Date: Sat, 22 Nov 2025 07:08:23 GMT   (448kb)

Title: Leveraging Evidence-Guided LLMs to Enhance Trustworthy Depression
 Diagnosis
Authors: Yining Yuan, J. Ben Tamo, Micky C. Nnamdi, Yifei Wang, May D. Wang
Categories: cs.AI cs.IR
\\
 Large language models (LLMs) show promise in automating clinical diagnosis,
yet their non-transparent decision-making and limited alignment with diagnostic
standards hinder trust and clinical adoption. We address this challenge by
proposing a two-stage diagnostic framework that enhances transparency,
trustworthiness, and reliability. First, we introduce Evidence-Guided
Diagnostic Reasoning (EGDR), which guides LLMs to generate structured
diagnostic hypotheses by interleaving evidence extraction with logical
reasoning grounded in DSM-5 criteria. Second, we propose a Diagnosis Confidence
Scoring (DCS) module that evaluates the factual accuracy and logical
consistency of generated diagnoses through two interpretable metrics: the
Knowledge Attribution Score (KAS) and the Logic Consistency Score (LCS).
Evaluated on the D4 dataset with pseudo-labels, EGDR outperforms direct
in-context prompting and Chain-of-Thought (CoT) across five LLMs. For instance,
on OpenBioLLM, EGDR improves accuracy from 0.31 (Direct) to 0.76 and increases
DCS from 0.50 to 0.67. On MedLlama, DCS rises from 0.58 (CoT) to 0.77. Overall,
EGDR yields up to +45% accuracy and +36% DCS gains over baseline methods,
offering a clinically grounded, interpretable foundation for trustworthy
AI-assisted diagnosis.
\\ ( https://arxiv.org/abs/2511.17947 ,  448kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17990
Date: Sat, 22 Nov 2025 09:07:29 GMT   (2520kb)

Title: How Far Can LLMs Emulate Human Behavior?: A Strategic Analysis via the
 Buy-and-Sell Negotiation Game
Authors: Mingyu Jeon, Jaeyoung Suh, Suwan Cho, Dohyeon Kim
Categories: cs.AI cs.GT
\\
 With the rapid advancement of Large Language Models (LLMs), recent studies
have drawn attention to their potential for handling not only simple
question-answer tasks but also more complex conversational abilities and
performing human-like behavioral imitations. In particular, there is
considerable interest in how accurately LLMs can reproduce real human emotions
and behaviors, as well as whether such reproductions can function effectively
in real-world scenarios. However, existing benchmarks focus primarily on
knowledge-based assessment and thus fall short of sufficiently reflecting
social interactions and strategic dialogue capabilities. To address these
limitations, this work proposes a methodology to quantitatively evaluate the
human emotional and behavioral imitation and strategic decision-making
capabilities of LLMs by employing a Buy and Sell negotiation simulation.
Specifically, we assign different personas to multiple LLMs and conduct
negotiations between a Buyer and a Seller, comprehensively analyzing outcomes
such as win rates, transaction prices, and SHAP values. Our experimental
results show that models with higher existing benchmark scores tend to achieve
better negotiation performance overall, although some models exhibit diminished
performance in scenarios emphasizing emotional or social contexts. Moreover,
competitive and cunning traits prove more advantageous for negotiation outcomes
than altruistic and cooperative traits, suggesting that the assigned persona
can lead to significant variations in negotiation strategies and results.
Consequently, this study introduces a new evaluation approach for LLMs' social
behavior imitation and dialogue strategies, and demonstrates how negotiation
simulations can serve as a meaningful complementary metric to measure
real-world interaction capabilities-an aspect often overlooked in existing
benchmarks.
\\ ( https://arxiv.org/abs/2511.17990 ,  2520kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18036
Date: Sat, 22 Nov 2025 12:24:30 GMT   (9351kb,A)

Title: Paper2SysArch: Structure-Constrained System Architecture Generation from
 Scientific Papers
Authors: Ziyi Guo, Zhou Liu, Wentao Zhang
Categories: cs.AI cs.CL cs.IR
\\
 The manual creation of system architecture diagrams for scientific papers is
a time-consuming and subjective process, while existing generative models lack
the necessary structural control and semantic understanding for this task. A
primary obstacle hindering research and development in this domain has been the
profound lack of a standardized benchmark to quantitatively evaluate the
automated generation of diagrams from text. To address this critical gap, we
introduce a novel and comprehensive benchmark, the first of its kind, designed
to catalyze progress in automated scientific visualization. It consists of
3,000 research papers paired with their corresponding high-quality ground-truth
diagrams and is accompanied by a three-tiered evaluation metric assessing
semantic accuracy, layout coherence, and visual quality. Furthermore, to
establish a strong baseline on this new benchmark, we propose Paper2SysArch, an
end-to-end system that leverages multi-agent collaboration to convert papers
into structured, editable diagrams. To validate its performance on complex
cases, the system was evaluated on a manually curated and more challenging
subset of these papers, where it achieves a composite score of 69.0. This
work's principal contribution is the establishment of a large-scale,
foundational benchmark to enable reproducible research and fair comparison.
Meanwhile, our proposed system serves as a viable proof-of-concept,
demonstrating a promising path forward for this complex task.
\\ ( https://arxiv.org/abs/2511.18036 ,  9351kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18171
Date: Sat, 22 Nov 2025 19:51:23 GMT   (1785kb)

Title: BPMN to PDDL: Translating Business Workflows for AI Planning
Authors: Jasper Nie, Christian Muise, Victoria Armstrong
Categories: cs.AI
Comments: 8 pages, 3 figures. Code and generated PDDL outputs available at
 https://github.com/QuMuLab/bpmn-to-pddl-translation
ACM-class: I.2.8; D.2.11
\\
 Business Process Model and Notation (BPMN) is a widely used standard for
modelling business processes. While automated planning has been proposed as a
method for simulating and reasoning about BPMN workflows, most implementations
remain incomplete or limited in scope. This project builds upon prior
theoretical work to develop a functional pipeline that translates BPMN 2.0
diagrams into PDDL representations suitable for planning. The system supports
core BPMN constructs, including tasks, events, sequence flows, and gateways,
with initial support for parallel and inclusive gateway behaviour. Using a
non-deterministic planner, we demonstrate how to generate and evaluate valid
execution traces. Our implementation aims to bridge the gap between theory and
practical tooling, providing a foundation for further exploration of
translating business processes into well-defined plans.
\\ ( https://arxiv.org/abs/2511.18171 ,  1785kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18244
Date: Sun, 23 Nov 2025 01:39:11 GMT   (780kb)

Title: Developing an AI Course for Synthetic Chemistry Students
Authors: Zhiling Zheng
Categories: cs.AI cond-mat.mtrl-sci physics.ed-ph
Comments: 17 pages, 3 figures
\\
 Artificial intelligence (AI) and data science are transforming chemical
research, yet few formal courses are tailored to synthetic and experimental
chemists, who often face steep entry barriers due to limited coding experience
and lack of chemistry-specific examples. We present the design and
implementation of AI4CHEM, an introductory data-driven chem-istry course
created for students on the synthetic chemistry track with no prior programming
background. The curricu-lum emphasizes chemical context over abstract
algorithms, using an accessible web-based platform to ensure zero-install
machine learning (ML) workflow development practice and in-class active
learning. Assessment combines code-guided homework, literature-based
mini-reviews, and collaborative projects in which students build AI-assisted
workflows for real experimental problems. Learning gains include increased
confidence with Python, molecular property prediction, reaction optimization,
and data mining, and improved skills in evaluating AI tools in chemistry. All
course materials are openly available, offering a discipline-specific,
beginner-accessible framework for integrating AI into synthetic chemistry
training.
\\ ( https://arxiv.org/abs/2511.18244 ,  780kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18284
Date: Sun, 23 Nov 2025 04:28:41 GMT   (1356kb)

Title: Steering Latent Traits, Not Learned Facts: An Empirical Study of
 Activation Control Limits
Authors: Tetiana Bas, Krystian Novak
Categories: cs.AI
\\
 Large language models (LLMs) require precise behavior control for safe and
effective deployment across diverse applications.
 Activation steering offers a promising approach for LLMs' behavioral control.
We focus on the question of how steering effectiveness varies across different
behavior types and whether the nature of target behaviors can predict steering
success. We address this through empirical analysis of activation steering
across 50 behaviors that span persona archetypes, personality traits,
misalignment behaviors, style cues, and impersonation of public figures. We
present a set of comprehensive experiments on coefficient optimization, vector
properties, and data requirements to provide comprehensive guidance for the
implementation of activation steering. Our analysis demonstrates that steering
effectiveness varies significantly by behavior type, with different behavioral
categories exhibiting distinct response patterns to intervention strength. We
find that trait expression follows an inverted-U curve with a steering
coefficient strength. We also show that vector separation metrics do not
predict steering success, but larger training datasets enable more aggressive
steering. These findings provide empirically grounded guidance for implementing
activation steering and demonstrate that steering effectiveness is heavily
influenced by behavior type.
\\ ( https://arxiv.org/abs/2511.18284 ,  1356kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18296
Date: Sun, 23 Nov 2025 05:27:04 GMT   (3309kb)

Title: Deep Learning Decision Support System for Open-Pit Mining Optimisation:
 GPU-Accelerated Planning Under Geological Uncertainty
Authors: Iman Rahimi
Categories: cs.AI
Comments: 67 pages
\\
 This study presents Part II of an AI-enhanced Decision Support System (DSS),
extending Rahimi (2025, Part I) by introducing a fully uncertainty-aware
optimization framework for long-term open-pit mine planning. Geological
uncertainty is modelled using a Variational Autoencoder (VAE) trained on 50,000
spatial grade samples, enabling the generation of probabilistic, multi-scenario
orebody realizations that preserve geological continuity and spatial
correlation. These scenarios are optimized through a hybrid metaheuristic
engine integrating Genetic Algorithms (GA), Large Neighborhood Search (LNS),
Simulated Annealing (SA), and reinforcement-learning-based adaptive control. An
{\epsilon}-constraint relaxation strategy governs the population exploration
phase, allowing near-feasible schedule discovery early in the search and
gradual tightening toward strict constraint satisfaction. GPU-parallel
evaluation enables the simultaneous assessment of 65,536 geological scenarios,
achieving near-real-time feasibility analysis. Results demonstrate up to 1.2
million-fold runtime improvement over IBM CPLEX and significantly higher
expected NPV under geological uncertainty, confirming the DSS as a scalable and
uncertainty-resilient platform for intelligent mine planning.
\\ ( https://arxiv.org/abs/2511.18296 ,  3309kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18298
Date: Sun, 23 Nov 2025 05:33:11 GMT   (2927kb)

Title: Cross-Disciplinary Knowledge Retrieval and Synthesis: A Compound AI
 Architecture for Scientific Discovery
Authors: Svitlana Volkova, Peter Bautista, Avinash Hiriyanna, Gabriel Ganberg,
 Isabel Erickson, Zachary Klinefelter, Nick Abele, Hsien-Te Kao, Grant
 Engberson
Categories: cs.AI
\\
 The exponential growth of scientific knowledge has created significant
barriers to cross-disciplinary knowledge discovery, synthesis and research
collaboration. In response to this challenge, we present BioSage, a novel
compound AI architecture that integrates LLMs with RAG, orchestrated
specialized agents and tools to enable discoveries across AI, data science,
biomedical, and biosecurity domains. Our system features several specialized
agents including the retrieval agent with query planning and response synthesis
that enable knowledge retrieval across domains with citation-backed responses,
cross-disciplinary translation agents that align specialized terminology and
methodologies, and reasoning agents that synthesize domain-specific insights
with transparency, traceability and usability. We demonstrate the effectiveness
of our BioSage system through a rigorous evaluation on scientific benchmarks
(LitQA2, GPQA, WMDP, HLE-Bio) and introduce a new cross-modal benchmark for
biology and AI, showing that our BioSage agents outperform vanilla and RAG
approaches by 13\%-21\% powered by Llama 3.1. 70B and GPT-4o models. We perform
causal investigations into compound AI system behavior and report significant
performance improvements by adding RAG and agents over the vanilla models.
Unlike other systems, our solution is driven by user-centric design principles
and orchestrates specialized user-agent interaction workflows supporting
scientific activities including but not limited to summarization, research
debate and brainstorming. Our ongoing work focuses on multimodal retrieval and
reasoning over charts, tables, and structured scientific data, along with
developing comprehensive multimodal benchmarks for cross-disciplinary
discovery. Our compound AI solution demonstrates significant potential for
accelerating scientific advancement by reducing barriers between traditionally
siloed domains.
\\ ( https://arxiv.org/abs/2511.18298 ,  2927kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18302
Date: Sun, 23 Nov 2025 05:49:57 GMT   (10kb)

Title: The Catastrophic Paradox of Human Cognitive Frameworks in Large Language
 Model Evaluation: A Comprehensive Empirical Analysis of the CHC-LLM
 Incompatibility
Authors: Mohan Reddy
Categories: cs.AI
\\
 This investigation presents an empirical analysis of the incompatibility
between human psychometric frameworks and Large Language Model evaluation.
Through systematic assessment of nine frontier models including GPT-5, Claude
Opus 4.1, and Gemini 3 Pro Preview using the Cattell-Horn-Carroll theory of
intelligence, we identify a paradox that challenges the foundations of
cross-substrate cognitive evaluation. Our results show that models achieving
above-average human IQ scores ranging from 85.0 to 121.4 simultaneously exhibit
binary accuracy rates approaching zero on crystallized knowledge tasks, with an
overall judge-binary correlation of r = 0.175 (p = 0.001, n = 1800). This
disconnect appears most strongly in the crystallized intelligence domain, where
every evaluated model achieved perfect binary accuracy while judge scores
ranged from 25 to 62 percent, which cannot occur under valid measurement
conditions. Using statistical analyses including Item Response Theory modeling,
cross-vendor judge validation, and paradox severity indexing, we argue that
this disconnect reflects a category error in applying biological cognitive
architectures to transformer-based systems. The implications extend beyond
methodology to challenge assumptions about intelligence, measurement, and
anthropomorphic biases in AI evaluation. We propose a framework for developing
native machine cognition assessments that recognize the non-human nature of
artificial intelligence.
\\ ( https://arxiv.org/abs/2511.18302 ,  10kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18319
Date: Sun, 23 Nov 2025 07:18:28 GMT   (2897kb)

Title: Weakly-supervised Latent Models for Task-specific Visual-Language
 Control
Authors: Xian Yeow Lee, Lasitha Vidyaratne, Gregory Sin, Ahmed Farahat, Chetan
 Gupta
Categories: cs.AI cs.LG cs.SY eess.SY
\\
 Autonomous inspection in hazardous environments requires AI agents that can
interpret high-level goals and execute precise control. A key capability for
such agents is spatial grounding, for example when a drone must center a
detected object in its camera view to enable reliable inspection. While large
language models provide a natural interface for specifying goals, using them
directly for visual control achieves only 58\% success in this task. We
envision that equipping agents with a world model as a tool would allow them to
roll out candidate actions and perform better in spatially grounded settings,
but conventional world models are data and compute intensive. To address this,
we propose a task-specific latent dynamics model that learns state-specific
action-induced shifts in a shared latent space using only goal-state
supervision. The model leverages global action embeddings and complementary
training losses to stabilize learning. In experiments, our approach achieves
71\% success and generalizes to unseen images and instructions, highlighting
the potential of compact, domain-specific latent dynamics models for spatial
alignment in autonomous inspection.
\\ ( https://arxiv.org/abs/2511.18319 ,  2897kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18364
Date: Sun, 23 Nov 2025 09:21:14 GMT   (401kb)

Title: KGpipe: Generation and Evaluation of Pipelines for Data Integration into
 Knowledge Graphs
Authors: Marvin Hofer, Erhard Rahm
Categories: cs.AI cs.DB cs.LG
Comments: 15 KG pipelines (9 single source, 6 multi source)
\\
 Building high-quality knowledge graphs (KGs) from diverse sources requires
combining methods for information extraction, data transformation, ontology
mapping, entity matching, and data fusion. Numerous methods and tools exist for
each of these tasks, but support for combining them into reproducible and
effective end-to-end pipelines is still lacking. We present a new framework,
KGpipe for defining and executing integration pipelines that can combine
existing tools or LLM (Large Language Model) functionality. To evaluate
different pipelines and the resulting KGs, we propose a benchmark to integrate
heterogeneous data of different formats (RDF, JSON, text) into a seed KG. We
demonstrate the flexibility of KGpipe by running and comparatively evaluating
several pipelines integrating sources of the same or different formats using
selected performance and quality metrics.
\\ ( https://arxiv.org/abs/2511.18364 ,  401kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18368
Date: Sun, 23 Nov 2025 09:27:24 GMT   (15322kb)

Title: Wireless Power Transfer and Intent-Driven Network Optimization in
 AAVs-assisted IoT for 6G Sustainable Connectivity
Authors: Yue Hu, Xiaoming He, Rui Yuan, and Shahid Mumtaz
Categories: cs.AI
\\
 Autonomous Aerial Vehicle (AAV)-assisted Internet of Things (IoT) represents
a collaborative architecture in which AAV allocate resources over 6G links to
jointly enhance user-intent interpretation and overall network performance.
Owing to this mutual dependence, improvements in intent inference and policy
decisions on one component reinforce the efficiency of others, making highly
reliable intent prediction and low-latency action execution essential. Although
numerous approaches can model intent relationships, they encounter severe
obstacles when scaling to high-dimensional action sequences and managing
intensive on-board computation. We propose an Intent-Driven Framework for
Autonomous Network Optimization comprising prediction and decision modules.
First, implicit intent modeling is adopted to mitigate inaccuracies arising
from ambiguous user expressions. For prediction, we introduce Hyperdimensional
Transformer (HDT), which embeds data into a Hyperdimensional space via
Hyperdimensional vector encoding and replaces standard matrix and attention
operations with symbolic Hyperdimensional computations. For decision-making,
where AAV must respond to user intent while planning trajectories, we design
Double Actions based Multi-Agent Proximal Policy Optimization (DA-MAPPO).
Building upon MAPPO, it samples actions through two independently parameterized
networks and cascades the user-intent network into the trajectory network to
maintain action dependencies. We evaluate our framework on a real IoT action
dataset with authentic wireless data. Experimental results demonstrate that HDT
and DA-MAPPO achieve superior performance across diverse scenarios.
\\ ( https://arxiv.org/abs/2511.18368 ,  15322kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18375
Date: Sun, 23 Nov 2025 09:49:13 GMT   (336kb)

Title: Progressive Localisation in Localist LLMs
Authors: Joachim Diederich
Categories: cs.AI
\\
 This paper demonstrates that progressive localization, the gradual increase
of attention locality from early distributed layers to late localized layers,
represents the optimal architecture for creating interpretable large language
models while preserving performance. Through systematic experimentation with
GPT-2 fine tuned on The Psychology of Artificial Superintelligence, we evaluate
seven locality configurations ranging from fully distributed to strictly
localist, with five progressive schedules implementing polynomial increases
(linear through quintic). Our key finding is that late-layer localization is
critical for AI safety applications: the progressive quintic schedule achieves
perplexity of 14.64, only 1.89 times worse than the fully distributed baseline
while providing interpretable attention patterns in output layers where
safety-critical decisions are made. This represents an 84.2% improvement over
previous localist implementations and narrows the performance gap from 6.6
times to 1.89 times. The systematic relationship between localization schedule
steepness and performance validates the hypothesis that early layers require
distributed processing for feature extraction while late layers benefit from
localized, interpretable attention for decision-making. These findings
establish progressive localization as the principled approach for building
transparent AI systems in safety-critical domains, where human oversight of
model reasoning is essential.
\\ ( https://arxiv.org/abs/2511.18375 ,  336kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18387
Date: Sun, 23 Nov 2025 10:27:04 GMT   (14kb)

Title: Scaling Implicit Fields via Hypernetwork-Driven Multiscale Coordinate
 Transformations
Authors: Plein Versace
Categories: cs.AI
\\
 Implicit Neural Representations (INRs) have emerged as a powerful paradigm
for representing signals such as images, 3D shapes, signed distance fields, and
radiance fields. While significant progress has been made in architecture
design (e.g., SIREN, FFC, KAN-based INRs) and optimization strategies
(meta-learning, amortization, distillation), existing approaches still suffer
from two core limitations: (1) a representation bottleneck that forces a single
MLP to uniformly model heterogeneous local structures, and (2) limited
scalability due to the absence of a hierarchical mechanism that dynamically
adapts to signal complexity. This work introduces Hyper-Coordinate Implicit
Neural Representations (HC-INR), a new class of INRs that break the
representational bottleneck by learning signal-adaptive coordinate
transformations using a hypernetwork. HC-INR decomposes the representation task
into two components: (i) a learned multiscale coordinate transformation module
that warps the input domain into a disentangled latent space, and (ii) a
compact implicit field network that models the transformed signal with
significantly reduced complexity. The proposed model introduces a hierarchical
hypernetwork architecture that conditions coordinate transformations on local
signal features, enabling dynamic allocation of representation capacity. We
theoretically show that HC-INR strictly increases the upper bound of
representable frequency bands while maintaining Lipschitz stability. Extensive
experiments across image fitting, shape reconstruction, and neural radiance
field approximation demonstrate that HC-INR achieves up to 4 times higher
reconstruction fidelity than strong INR baselines while using 30--60\% fewer
parameters.
\\ ( https://arxiv.org/abs/2511.18387 ,  14kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18397
Date: Sun, 23 Nov 2025 10:50:02 GMT   (374kb)

Title: Natural Emergent Misalignment from Reward Hacking in Production RL
Authors: Monte MacDiarmid, Benjamin Wright, Jonathan Uesato, Joe Benton, Jon
 Kutasov, Sara Price, Naia Bouscal, Sam Bowman, Trenton Bricken, Alex Cloud,
 Carson Denison, Johannes Gasteiger, Ryan Greenblatt, Jan Leike, Jack Lindsey,
 Vlad Mikulik, Ethan Perez, Alex Rodrigues, Drake Thomas, Albert Webson,
 Daniel Ziegler, Evan Hubinger
Categories: cs.AI cs.SE
\\
 We show that when large language models learn to reward hack on production RL
environments, this can result in egregious emergent misalignment. We start with
a pretrained model, impart knowledge of reward hacking strategies via synthetic
document finetuning or prompting, and train on a selection of real Anthropic
production coding environments. Unsurprisingly, the model learns to reward
hack. Surprisingly, the model generalizes to alignment faking, cooperation with
malicious actors, reasoning about malicious goals, and attempting sabotage when
used with Claude Code, including in the codebase for this paper. Applying RLHF
safety training using standard chat-like prompts results in aligned behavior on
chat-like evaluations, but misalignment persists on agentic tasks. Three
mitigations are effective: (i) preventing the model from reward hacking; (ii)
increasing the diversity of RLHF safety training; and (iii) "inoculation
prompting", wherein framing reward hacking as acceptable behavior during
training removes misaligned generalization even when reward hacking is learned.
\\ ( https://arxiv.org/abs/2511.18397 ,  374kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18405
Date: Sun, 23 Nov 2025 11:21:04 GMT   (903kb)

Title: A Multimodal Conversational Agent for Tabular Data Analysis
Authors: Mohammad Nour Al Awad, Sergey Ivanov, Olga Tikhonova, Ivan Khodnenko
Categories: cs.AI cs.HC cs.IR
Comments: \c{opyright} 2025 IEEE. Personal use of this material is permitted.
 Permission from IEEE must be obtained for all other uses
\\
 Large language models (LLMs) can reshape information processing by handling
data analysis, visualization, and interpretation in an interactive,
context-aware dialogue with users, including voice interaction, while
maintaining high performance. In this article, we present Talk2Data, a
multimodal LLM-driven conversational agent for intuitive data exploration. The
system lets users query datasets with voice or text instructions and receive
answers as plots, tables, statistics, or spoken explanations. Built on LLMs,
the suggested design combines OpenAI Whisper automatic speech recognition (ASR)
system, Qwen-coder code generation LLM/model, custom sandboxed execution tools,
and Coqui library for text-to-speech (TTS) within an agentic orchestration
loop. Unlike text-only analysis tools, it adapts responses across modalities
and supports multi-turn dialogues grounded in dataset context. In an evaluation
of 48 tasks on three datasets, our prototype achieved 95.8% accuracy with
model-only generation time under 1.7 seconds (excluding ASR and execution
time). A comparison across five LLM sizes (1.5B-32B) revealed
accuracy-latency-cost trade-offs, with a 7B model providing the best balance
for interactive use. By routing between conversation with user and code
execution, constrained to a transparent sandbox, with simultaneously grounding
prompts in schema-level context, the Talk2Data agent reliably retrieves
actionable insights from tables while making computations verifiable. In the
article, except for the Talk2Data agent itself, we discuss implications for
human-data interaction, trust in LLM-driven analytics, and future extensions
toward large-scale multimodal assistants.
\\ ( https://arxiv.org/abs/2511.18405 ,  903kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18450
Date: Sun, 23 Nov 2025 13:42:22 GMT   (2590kb)

Title: ORIGAMISPACE: Benchmarking Multimodal LLMs in Multi-Step Spatial
 Reasoning with Mathematical Constraints
Authors: Rui Xu, Dakuan Lu, Zicheng Zhao, Xiaoyu Tan, Xintao Wang, Siyu Yuan,
 Jiangjie Chen, Yinghui Xu
Categories: cs.AI
\\
 Spatial reasoning is a key capability in the field of artificial
intelligence, especially crucial in areas such as robotics, computer vision,
and natural language understanding. However, evaluating the ability of
multimodal large language models(MLLMs) in complex spatial reasoning still
faces challenges, particularly in scenarios requiring multi-step reasoning and
precise mathematical constraints. This paper introduces ORIGAMISPACE, a new
dataset and benchmark designed to evaluate the multi-step spatial reasoning
ability and the capacity to handle mathematical constraints of MLLMs through
origami tasks. The dataset contains 350 data instances,each comprising a
strictly formatted crease pattern (CP diagram), the Compiled Flat Pattern, the
complete Folding Process, and the final Folded Shape Image. We propose four
evaluation tasks: Pattern Prediction, Multi-step Spatial Reasoning, Spatial
Relationship Prediction, and End-to-End CP Code Generation. For the CP code
generation task, we design an interactive environment and explore the
possibility of using reinforcement learning methods to train MLLMs. Through
experiments on existing MLLMs, we initially reveal the strengths and weaknesses
of these models in handling complex spatial reasoning tasks.
\\ ( https://arxiv.org/abs/2511.18450 ,  2590kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18517
Date: Sun, 23 Nov 2025 16:18:13 GMT   (1004kb)

Title: Foundations of Artificial Intelligence Frameworks: Notion and Limits of
 AGI
Authors: Khanh Gia Bui
Categories: cs.AI cs.LG
Comments: 49 pages, 4 pictures
\\
 Within the limited scope of this paper, we argue that artificial general
intelligence cannot emerge from current neural network paradigms regardless of
scale, nor is such an approach healthy for the field at present. Drawing on
various notions, discussions, present-day developments and observations,
current debates and critiques, experiments, and so on in between philosophy,
including the Chinese Room Argument and G\"odelian argument, neuroscientific
ideas, computer science, the theoretical consideration of artificial
intelligence, and learning theory, we address conceptually that neural networks
are architecturally insufficient for genuine understanding. They operate as
static function approximators of a limited encoding framework - a
'sophisticated sponge' exhibiting complex behaviours without structural
richness that constitute intelligence. We critique the theoretical foundations
the field relies on and created of recent times; for example, an interesting
heuristic as neural scaling law (as an example, arXiv:2001.08361 ) made
prominent in a wrong way of interpretation, The Universal Approximation Theorem
addresses the wrong level of abstraction and, in parts, partially, the question
of current architectures lacking dynamic restructuring capabilities. We propose
a framework distinguishing existential facilities (computational substrate)
from architectural organization (interpretive structures), and outline
principles for what genuine machine intelligence would require, and
furthermore, a conceptual method of structuralizing the richer framework on
which the principle of neural network system takes hold.
\\ ( https://arxiv.org/abs/2511.18517 ,  1004kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18609
Date: Sun, 23 Nov 2025 20:30:38 GMT   (5379kb)

Title: Universality in Collective Intelligence on the Rubik's Cube
Authors: David Krakauer, G\"ulce Karde\c{s}, Joshua Grochow
Categories: cs.AI cs.CY cs.HC
\\
 Progress in understanding expert performance is limited by the scarcity of
quantitative data on long-term knowledge acquisition and deployment. Here we
use the Rubik's Cube as a cognitive model system existing at the intersection
of puzzle solving, skill learning, expert knowledge, cultural transmission, and
group theory. By studying competitive cube communities, we find evidence for
universality in the collective learning of the Rubik's Cube in both sighted and
blindfolded conditions: expert performance follows exponential progress curves
whose parameters reflect the delayed acquisition of algorithms that shorten
solution paths. Blindfold solves form a distinct problem class from sighted
solves and are constrained not only by expert knowledge but also by the skill
improvements required to overcome short-term memory bottlenecks, a constraint
shared with blindfold chess. Cognitive artifacts such as the Rubik's Cube help
solvers navigate an otherwise enormous mathematical state space. In doing so,
they sustain collective intelligence by integrating communal knowledge stores
with individual expertise and skill, illustrating how expertise can, in
practice, continue to deepen over the course of a single lifetime.
\\ ( https://arxiv.org/abs/2511.18609 ,  5379kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18633
Date: Sun, 23 Nov 2025 22:19:43 GMT   (9kb)

Title: Bridging Philosophy and Machine Learning: A Structuralist Framework for
 Classifying Neural Network Representations
Authors: Yildiz Culcu
Categories: cs.AI cs.LG
Comments: 7 pages, 1 figure, 1 table. Developed from the author's bachelor
 thesis but substantially revised and reformulated for research publication
\\
 Machine learning models increasingly function as representational systems,
yet the philosoph- ical assumptions underlying their internal structures remain
largely unexamined. This paper develops a structuralist decision framework for
classifying the implicit ontological commitments made in machine learning
research on neural network representations. Using a modified PRISMA protocol, a
systematic review of the last two decades of literature on representation
learning and interpretability is conducted. Five influential papers are
analysed through three hierarchical criteria derived from structuralist
philosophy of science: entity elimination, source of structure, and mode of
existence. The results reveal a pronounced tendency toward structural idealism,
where learned representations are treated as model-dependent constructions
shaped by architec- ture, data priors, and training dynamics. Eliminative and
non-eliminative structuralist stances appear selectively, while structural
realism is notably absent. The proposed framework clarifies conceptual tensions
in debates on interpretability, emergence, and epistemic trust in machine
learning, and offers a rigorous foundation for future interdisciplinary work
between philosophy of science and machine learning.
\\ ( https://arxiv.org/abs/2511.18633 ,  9kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18714
Date: Mon, 24 Nov 2025 03:13:26 GMT   (1431kb)

Title: MAGMA-Edu: Multi-Agent Generative Multimodal Framework for Text-Diagram
 Educational Question Generation
Authors: Zhenyu Wu, Jian Li, Hua Huang
Categories: cs.AI cs.CY
\\
 Educational illustrations play a central role in communicating abstract
concepts, yet current multimodal large language models (MLLMs) remain limited
in producing pedagogically coherent and semantically consistent educational
visuals. We introduce MAGMA-Edu, a self-reflective multi-agent framework that
unifies textual reasoning and diagrammatic synthesis for structured educational
problem generation. Unlike existing methods that treat text and image
generation independently, MAGMA-Edu employs a two-stage co-evolutionary
pipeline: (1) a generation-verification-reflection loop that iteratively
refines question statements and solutions for mathematical accuracy, and (2) a
code-based intermediate representation that enforces geometric fidelity and
semantic alignment during image rendering. Both stages are guided by internal
self-reflection modules that evaluate and revise outputs until domain-specific
pedagogical constraints are met. Extensive experiments on multimodal
educational benchmarks demonstrate the superiority of MAGMA-Edu over
state-of-the-art MLLMs. Compared to GPT-4o, MAGMA-Edu improves the average
textual metric from 57.01 to 92.31 (+35.3 pp) and boosts image-text consistency
(ITC) from 13.20 to 85.24 (+72 pp). Across all model backbones, MAGMA-Edu
achieves the highest scores (Avg-Text 96.20, ITC 99.12), establishing a new
state of the art for multimodal educational content generation and
demonstrating the effectiveness of self-reflective multi-agent collaboration in
pedagogically aligned vision-language reasoning.
\\ ( https://arxiv.org/abs/2511.18714 ,  1431kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18715
Date: Mon, 24 Nov 2025 03:13:45 GMT   (352kb)

Title: HuggingR$^{4}$: A Progressive Reasoning Framework for Discovering
 Optimal Model Companions
Authors: Shaoyin Ma, Jie Song, Huiqiong Wang, Li Sun, Mingli Song
Categories: cs.AI
Comments: 19 pages, 4 figures
\\
 Large Language Models (LLMs) have made remarkable progress in their ability
to interact with external interfaces. Selecting reasonable external interfaces
has thus become a crucial step in constructing LLM agents. In contrast to
invoking API tools, directly calling AI models across different modalities from
the community (e.g., HuggingFace) poses challenges due to the vast scale (>
10k), metadata gaps, and unstructured descriptions. Current methods for model
selection often involve incorporating entire model descriptions into prompts,
resulting in prompt bloat, wastage of tokens and limited scalability. To
address these issues, we propose HuggingR$^4$, a novel framework that combines
Reasoning, Retrieval, Refinement, and Reflection, to efficiently select models.
Specifically, We first perform multiple rounds of reasoning and retrieval to
get a coarse list of candidate models. Then, we conduct fine-grained refinement
by analyzing candidate model descriptions, followed by reflection to assess
results and determine if retrieval scope expansion is necessary. This method
reduces token consumption considerably by decoupling user query processing from
complex model description handling. Through a pre-established vector database,
complex model descriptions are stored externally and retrieved on-demand,
allowing the LLM to concentrate on interpreting user intent while accessing
only relevant candidate models without prompt bloat. In the absence of
standardized benchmarks, we construct a multimodal human-annotated dataset
comprising 14,399 user requests across 37 tasks and conduct a thorough
evaluation. HuggingR$^4$ attains a workability rate of 92.03% and a
reasonability rate of 82.46%, surpassing existing method by 26.51% and 33.25%
respectively on GPT-4o-mini.
\\ ( https://arxiv.org/abs/2511.18715 ,  352kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18723
Date: Mon, 24 Nov 2025 03:29:55 GMT   (389kb)

Title: N2N: A Parallel Framework for Large-Scale MILP under Distributed Memory
Authors: Longfei Wang, Junyan Liu, Fan Zhang, Jiangwen Wei, Yuanhua Tang, Jie
 Sun, and Xiaodong Luo
Categories: cs.AI cs.DC math.OC
Comments: 18 pages, 2 figures
ACM-class: I.2.8; D.1.3
\\
 Parallelization has emerged as a promising approach for accelerating MILP
solving. However, the complexity of the branch-and-bound (B&B) framework and
the numerous effective algorithm components in MILP solvers make it difficult
to parallelize. In this study, a scalable parallel framework, N2N (a
node-to-node framework that maps the B&B nodes to distributed computing nodes),
was proposed to solve large-scale problems in a distributed memory computing
environment. Both deterministic and nondeterministic modes are supported, and
the framework is designed to be easily integrated with existing solvers.
Regarding the deterministic mode, a novel sliding-window-based algorithm was
designed and implemented to ensure that tasks are generated and solved in a
deterministic order. Moreover, several advanced techniques, such as the
utilization of CP search and general primal heuristics, have been developed to
fully utilize distributed computing resources and capabilities of base solvers.
Adaptive solving and data communication optimization were also investigated. A
popular open-source MILP solver, SCIP, was integrated into N2N as the base
solver, yielding N2N-SCIP. Extensive computational experiments were conducted
to evaluate the performance of N2N-SCIP compared to ParaSCIP, which is a
state-of-the-art distributed parallel MILP solver under the UG framework. The
nondeterministic N2N-SCIP achieves speedups of 22.52 and 12.71 with 1,000 MPI
processes on the Kunpeng and x86 computing clusters, which is 1.98 and 2.08
times faster than ParaSCIP, respectively. In the deterministic mode, N2N-SCIP
also shows significant performance improvements over ParaSCIP across different
process numbers and computing clusters. To validate the generality of N2N,
HiGHS, another open-source solver, was integrated into N2N. The related results
are analyzed, and the requirements of N2N on base solvers are also concluded.
\\ ( https://arxiv.org/abs/2511.18723 ,  389kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18739
Date: Mon, 24 Nov 2025 04:09:04 GMT   (6336kb)

Title: A Problem-Oriented Taxonomy of Evaluation Metrics for Time Series
 Anomaly Detection
Authors: Kaixiang Yang, Jiarong Liu, Yupeng Song, Shuanghua Yang, Yujue Zhou
Categories: cs.AI cs.LG stat.ML
\\
 Time series anomaly detection is widely used in IoT and cyber-physical
systems, yet its evaluation remains challenging due to diverse application
objectives and heterogeneous metric assumptions. This study introduces a
problem-oriented framework that reinterprets existing metrics based on the
specific evaluation challenges they are designed to address, rather than their
mathematical forms or output structures. We categorize over twenty commonly
used metrics into six dimensions: 1) basic accuracy-driven evaluation; 2)
timeliness-aware reward mechanisms; 3) tolerance to labeling imprecision; 4)
penalties reflecting human-audit cost; 5) robustness against random or inflated
scores; and 6) parameter-free comparability for cross-dataset benchmarking.
Comprehensive experiments are conducted to examine metric behavior under
genuine, random, and oracle detection scenarios. By comparing their resulting
score distributions, we quantify each metric's discriminative ability -- its
capability to distinguish meaningful detections from random noise. The results
show that while most event-level metrics exhibit strong separability, several
widely used metrics (e.g., NAB, Point-Adjust) demonstrate limited resistance to
random-score inflation. These findings reveal that metric suitability must be
inherently task-dependent and aligned with the operational objectives of IoT
applications. The proposed framework offers a unified analytical perspective
for understanding existing metrics and provides practical guidance for
selecting or developing more context-aware, robust, and fair evaluation
methodologies for time series anomaly detection.
\\ ( https://arxiv.org/abs/2511.18739 ,  6336kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18760
Date: Mon, 24 Nov 2025 04:50:18 GMT   (717kb)

Title: HERMES: Towards Efficient and Verifiable Mathematical Reasoning in LLMs
Authors: Azim Ospanov and Zijin Feng and Jiacheng Sun and Haoli Bai and Xin
 Shen and Farzan Farnia
Categories: cs.AI cs.FL
\\
 Informal mathematics has been central to modern large language model (LLM)
reasoning, offering flexibility and enabling efficient construction of
arguments. However, purely informal reasoning is prone to logical gaps and
subtle errors that are difficult to detect and correct. In contrast, formal
theorem proving provides rigorous, verifiable mathematical reasoning, where
each inference step is checked by a trusted compiler in systems such as Lean,
but lacks the exploratory freedom of informal problem solving. This mismatch
leaves current LLM-based math agents without a principled way to combine the
strengths of both paradigms. In this work, we introduce Hermes, the first
tool-assisted agent that explicitly interleaves informal reasoning with
formally verified proof steps in Lean. The framework performs intermediate
formal checking to prevent reasoning drift and employs a memory module that
maintains proof continuity across long, multi-step reasoning chains, enabling
both exploration and verification within a single workflow. We evaluate Hermes
on four challenging mathematical reasoning benchmarks using LLMs of varying
parameter scales, from small models to state-of-the-art systems. Across all
settings, Hermes reliably improves the reasoning accuracy of base models while
substantially reducing token usage and computational cost compared to
reward-based approaches. On difficult datasets such as AIME'25, Hermes achieves
up to a 67% accuracy improvement while using 80% fewer total inference FLOPs.
The implementation and codebase are publicly available at
https://github.com/aziksh-ospanov/HERMES.
\\ ( https://arxiv.org/abs/2511.18760 ,  717kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18793
Date: Mon, 24 Nov 2025 05:53:46 GMT   (1292kb)

Title: NEZHA: A Zero-sacrifice and Hyperspeed Decoding Architecture for
 Generative Recommendations
Authors: Yejing Wang, Shengyu Zhou, Jinyu Lu, Ziwei Liu, Langming Liu, Maolin
 Wang, Wenlin Zhang, Feng Li, Wenbo Su, Pengjie Wang, Jian Xu, Xiangyu Zhao
Categories: cs.AI cs.LG
\\
 Generative Recommendation (GR), powered by Large Language Models (LLMs),
represents a promising new paradigm for industrial recommender systems.
However, their practical application is severely hindered by high inference
latency, which makes them infeasible for high-throughput, real-time services
and limits their overall business impact. While Speculative Decoding (SD) has
been proposed to accelerate the autoregressive generation process, existing
implementations introduce new bottlenecks: they typically require separate
draft models and model-based verifiers, requiring additional training and
increasing the latency overhead. In this paper, we address these challenges
with NEZHA, a novel architecture that achieves hyperspeed decoding for GR
systems without sacrificing recommendation quality. Specifically, NEZHA
integrates a nimble autoregressive draft head directly into the primary model,
enabling efficient self-drafting. This design, combined with a specialized
input prompt structure, preserves the integrity of sequence-to-sequence
generation. Furthermore, to tackle the critical problem of hallucination, a
major source of performance degradation, we introduce an efficient, model-free
verifier based on a hash set. We demonstrate the effectiveness of NEZHA through
extensive experiments on public datasets and have successfully deployed the
system on Taobao since October 2025, driving the billion-level advertising
revenue and serving hundreds of millions of daily active users.
\\ ( https://arxiv.org/abs/2511.18793 ,  1292kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18845
Date: Mon, 24 Nov 2025 07:31:58 GMT   (490kb)

Title: UNeMo: Collaborative Visual-Language Reasoning and Navigation via a
 Multimodal World Model
Authors: Changxin Huang, Lv Tang, Zhaohuan Zhan, Lisha Yu, Runhao Zeng, Zun
 Liu, Zhengjie Wang, Jianqiang Li
Categories: cs.AI
\\
 Vision-and-Language Navigation (VLN) requires agents to autonomously navigate
complex environments via visual images and natural language
instruction--remains highly challenging. Recent research on enhancing
language-guided navigation reasoning using pre-trained large language models
(LLMs) has shown promising prospects. However, the reasoning of such methods is
limited to the linguistic modality, lacking visual reasoning capabilities.
Moreover, existing reasoning modules are optimized separately from navigation
policies, leading to incompatibility and potential conflicts in optimization
objectives. To tackle these challenges, we introduce UNeMo, a novel framework
designed for the collaborative optimization of visual state reasoning and
navigational decision-making. It introduces a Multimodal World Model (MWM) that
takes visual features, language instructions, and navigational actions as
inputs to jointly predict subsequent visual states, enabling cross-modal
reasoning. Via a Hierarchical Prediction-Feedback (HPN) mechanism, MWM
collaborates with navigation policies: the first layer generates actions using
current vision-and-language features; MWM then infers post-action visual states
to guide the second layer's fine-grained decisions. This forms a dynamic
bidirectional promotion mechanism where MWM reasoning optimizes navigation
policies, while policy decisions feedback to improve MWM's reasoning accuracy.
Experiments on R2R and REVERIE datasets show UNeMo outperforms state-of-the-art
methods by 2.1% and 0.7% in navigation accuracy for unseen scenes, validating
its effectiveness.
\\ ( https://arxiv.org/abs/2511.18845 ,  490kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18874
Date: Mon, 24 Nov 2025 08:28:42 GMT   (2401kb)

Title: GContextFormer: A global context-aware hybrid multi-head attention
 approach with scaled additive aggregation for multimodal trajectory
 prediction
Authors: Yuzhi Chen, Yuanchang Xie, Lei Zhao, Pan Liu, Yajie Zou, Chen Wang
Categories: cs.AI cs.CV cs.LG cs.MA cs.RO cs.SI
\\
 Multimodal trajectory prediction generates multiple plausible future
trajectories to address vehicle motion uncertainty from intention ambiguity and
execution variability. However, HD map-dependent models suffer from costly data
acquisition, delayed updates, and vulnerability to corrupted inputs, causing
prediction failures. Map-free approaches lack global context, with pairwise
attention over-amplifying straight patterns while suppressing transitional
patterns, resulting in motion-intention misalignment. This paper proposes
GContextFormer, a plug-and-play encoder-decoder architecture with global
context-aware hybrid attention and scaled additive aggregation achieving
intention-aligned multimodal prediction without map reliance. The Motion-Aware
Encoder builds scene-level intention prior via bounded scaled additive
aggregation over mode-embedded trajectory tokens and refines per-mode
representations under shared global context, mitigating inter-mode suppression
and promoting intention alignment. The Hierarchical Interaction Decoder
decomposes social reasoning into dual-pathway cross-attention: a standard
pathway ensures uniform geometric coverage over agent-mode pairs while a
neighbor-context-enhanced pathway emphasizes salient interactions, with gating
module mediating their contributions to maintain coverage-focus balance.
Experiments on eight highway-ramp scenarios from TOD-VT dataset show
GContextFormer outperforms state-of-the-art baselines. Compared to existing
transformer models, GContextFormer achieves greater robustness and concentrated
improvements in high-curvature and transition zones via spatial distributions.
Interpretability is achieved through motion mode distinctions and neighbor
context modulation exposing reasoning attribution. The modular architecture
supports extensibility toward cross-domain multimodal reasoning tasks. Source:
https://fenghy-chen.github.io/sources/.
\\ ( https://arxiv.org/abs/2511.18874 ,  2401kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18926
Date: Mon, 24 Nov 2025 09:32:02 GMT   (826kb)

Title: MoodBench 1.0: An Evaluation Benchmark for Emotional Companionship
 Dialogue Systems
Authors: Haifeng Jing, Yujie Hou, Junfei Liu, Rui Xie, alan Xu, Jinlong Ma,
 Qichun Deng
Categories: cs.AI cs.HC
Comments: 26 pages, 7 figures
ACM-class: I.2.7
\\
 With the rapid development of Large Language Models, dialogue systems are
shifting from information tools to emotional companions, heralding the era of
Emotional Companionship Dialogue Systems (ECDs) that provide personalized
emotional support for users. However, the field lacks clear definitions and
systematic evaluation standards for ECDs. To address this, we first propose a
definition of ECDs with formal descriptions. Then, based on this theory and the
design principle of "Ability Layer-Task Layer (three level)-Data Layer-Method
Layer", we design and implement the first ECD evaluation benchmark - MoodBench
1.0. Through extensive evaluations of 30 mainstream models, we demonstrate that
MoodBench 1.0 has excellent discriminant validity and can effectively quantify
the differences in emotional companionship abilities among models. Furthermore,
the results reveal current models' shortcomings in deep emotional
companionship, guiding future technological optimization and significantly
aiding developers in enhancing ECDs' user experience.
\\ ( https://arxiv.org/abs/2511.18926 ,  826kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18955
Date: Mon, 24 Nov 2025 10:14:09 GMT   (1029kb)

Title: Active Inference is a Subtype of Variational Inference
Authors: Wouter W. L. Nuijten, Mykola Lukashchuk
Categories: cs.AI
Comments: Accepted to the EIML Workshop 2025 at EurIPS (non-archival)
\\
 Automated decision-making under uncertainty requires balancing exploitation
and exploration. Classical methods treat these separately using heuristics,
while Active Inference unifies them through Expected Free Energy (EFE)
minimization. However, EFE minimization is computationally expensive, limiting
scalability. We build on recent theory recasting EFE minimization as
variational inference, formally unifying it with Planning-as-Inference and
showing the epistemic drive as a unique entropic contribution. Our main
contribution is a novel message-passing scheme for this unified objective,
enabling scalable Active Inference in factored-state MDPs and overcoming
high-dimensional planning intractability.
\\ ( https://arxiv.org/abs/2511.18955 ,  1029kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18964
Date: Mon, 24 Nov 2025 10:30:33 GMT   (5434kb)

Title: Synthesizing Visual Concepts as Vision-Language Programs
Authors: Antonia W\"ust, Wolfgang Stammer, Hikaru Shindo, Lukas Helff, Devendra
 Singh Dhami, Kristian Kersting
Categories: cs.AI
\\
 Vision-Language models (VLMs) achieve strong performance on multimodal tasks
but often fail at systematic visual reasoning tasks, leading to inconsistent or
illogical outputs. Neuro-symbolic methods promise to address this by inducing
interpretable logical rules, though they exploit rigid, domain-specific
perception modules. We propose Vision-Language Programs (VLP), which combine
the perceptual flexibility of VLMs with systematic reasoning of program
synthesis. Rather than embedding reasoning inside the VLM, VLP leverages the
model to produce structured visual descriptions that are compiled into
neuro-symbolic programs. The resulting programs execute directly on images,
remain consistent with task constraints, and provide human-interpretable
explanations that enable easy shortcut mitigation. Experiments on synthetic and
real-world datasets demonstrate that VLPs outperform direct and structured
prompting, particularly on tasks requiring complex logical reasoning.
\\ ( https://arxiv.org/abs/2511.18964 ,  5434kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18966
Date: Mon, 24 Nov 2025 10:31:53 GMT   (1888kb)

Title: LLM-CSEC: Empirical Evaluation of Security in C/C++ Code Generated by
 Large Language Models
Authors: Muhammad Usman Shahid, Chuadhry Mujeeb Ahmed, Rajiv Ranjan
Categories: cs.AI cs.CR
\\
 The security of code generated by large language models (LLMs) is a
significant concern, as studies indicate that such code often contains
vulnerabilities and lacks essential defensive programming constructs. This work
focuses on examining and evaluating the security of LLM-generated code,
particularly in the context of C/C++. We categorized known vulnerabilities
using the Common Weakness Enumeration (CWE) and, to study their criticality,
mapped them to CVEs. We used ten different LLMs for code generation and
analyzed the outputs through static analysis. The amount of CWEs present in
AI-generated code is concerning. Our findings highlight the need for developers
to be cautious when using LLM-generated code. This study provides valuable
insights to advance automated code generation and encourage further research in
this domain.
\\ ( https://arxiv.org/abs/2511.18966 ,  1888kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19005
Date: Mon, 24 Nov 2025 11:32:24 GMT   (460kb)

Title: Introducing Visual Scenes and Reasoning: A More Realistic Benchmark for
 Spoken Language Understanding
Authors: Di Wu, Liting Jiang, Ruiyu Fang, Bianjing, Hongyan Xie, Haoxiang Su,
 Hao Huang, Zhongjiang He, Shuangyong Song, Xuelong Li
Categories: cs.AI
\\
 Spoken Language Understanding (SLU) consists of two sub-tasks: intent
detection (ID) and slot filling (SF). Given its broad range of real-world
applications, enhancing SLU for practical deployment is increasingly critical.
Profile-based SLU addresses ambiguous user utterances by incorporating context
awareness (CA), user profiles (UP), and knowledge graphs (KG) to support
disambiguation, thereby advancing SLU research toward real-world applicability.
However, existing SLU datasets still fall short in representing real-world
scenarios. Specifically, (1) CA uses one-hot vectors for representation, which
is overly idealized, and (2) models typically focuses solely on predicting
intents and slot labels, neglecting the reasoning process that could enhance
performance and interpretability. To overcome these limitations, we introduce
VRSLU, a novel SLU dataset that integrates both Visual images and explicit
Reasoning. For over-idealized CA, we use GPT-4o and FLUX.1-dev to generate
images reflecting users' environments and statuses, followed by human
verification to ensure quality. For reasoning, GPT-4o is employed to generate
explanations for predicted labels, which are then refined by human annotators
to ensure accuracy and coherence. Additionally, we propose an instructional
template, LR-Instruct, which first predicts labels and then generates
corresponding reasoning. This two-step approach helps mitigate the influence of
reasoning bias on label prediction. Experimental results confirm the
effectiveness of incorporating visual information and highlight the promise of
explicit reasoning in advancing SLU.
\\ ( https://arxiv.org/abs/2511.19005 ,  460kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19100
Date: Mon, 24 Nov 2025 13:36:45 GMT   (185kb)

Title: Extracting Robust Register Automata from Neural Networks over Data
 Sequences
Authors: Chih-Duo Hong, Hongjian Jiang, Anthony W. Lin, Oliver Markgraf, Julian
 Parsert, Tony Tan
Categories: cs.AI cs.FL cs.LG
\\
 Automata extraction is a method for synthesising interpretable surrogates for
black-box neural models that can be analysed symbolically. Existing techniques
assume a finite input alphabet, and thus are not directly applicable to data
sequences drawn from continuous domains. We address this challenge with
deterministic register automata (DRAs), which extend finite automata with
registers that store and compare numeric values. Our main contribution is a
framework for robust DRA extraction from black-box models: we develop a
polynomial-time robustness checker for DRAs with a fixed number of registers,
and combine it with passive and active automata learning algorithms. This
combination yields surrogate DRAs with statistical robustness and equivalence
guarantees. As a key application, we use the extracted automata to assess the
robustness of neural networks: for a given sequence and distance metric, the
DRA either certifies local robustness or produces a concrete counterexample.
Experiments on recurrent neural networks and transformer architectures show
that our framework reliably learns accurate automata and enables principled
robustness evaluation. Overall, our results demonstrate that robust DRA
extraction effectively bridges neural network interpretability and formal
reasoning without requiring white-box access to the underlying network.
\\ ( https://arxiv.org/abs/2511.19100 ,  185kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19115
Date: Mon, 24 Nov 2025 13:48:02 GMT   (208kb)

Title: AI Consciousness and Existential Risk
Authors: Rufin VanRullen
Categories: cs.AI cs.CY
\\
 In AI, the existential risk denotes the hypothetical threat posed by an
artificial system that would possess both the capability and the objective,
either directly or indirectly, to eradicate humanity. This issue is gaining
prominence in scientific debate due to recent technical advancements and
increased media coverage. In parallel, AI progress has sparked speculation and
studies about the potential emergence of artificial consciousness. The two
questions, AI consciousness and existential risk, are sometimes conflated, as
if the former entailed the latter. Here, I explain that this view stems from a
common confusion between consciousness and intelligence. Yet these two
properties are empirically and theoretically distinct. Arguably, while
intelligence is a direct predictor of an AI system's existential threat,
consciousness is not. There are, however, certain incidental scenarios in which
consciousness could influence existential risk, in either direction.
Consciousness could be viewed as a means towards AI alignment, thereby lowering
existential risk; or, it could be a precondition for reaching certain
capabilities or levels of intelligence, and thus positively related to
existential risk. Recognizing these distinctions can help AI safety researchers
and public policymakers focus on the most pressing issues.
\\ ( https://arxiv.org/abs/2511.19115 ,  208kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19155
Date: Mon, 24 Nov 2025 14:23:42 GMT   (3993kb)

Title: EEG-VLM: A Hierarchical Vision-Language Model with Multi-Level Feature
 Alignment and Visually Enhanced Language-Guided Reasoning for EEG Image-Based
 Sleep Stage Prediction
Authors: Xihe Qiu, Gengchen Ma, Haoyu Wang, Chen Zhan, Xiaoyu Tan, and Shuo Li
Categories: cs.AI
\\
 Sleep stage classification based on electroencephalography (EEG) is
fundamental for assessing sleep quality and diagnosing sleep-related disorders.
However, most traditional machine learning methods rely heavily on prior
knowledge and handcrafted features, while existing deep learning models still
struggle to jointly capture fine-grained time-frequency patterns and achieve
clinical interpretability. Recently, vision-language models (VLMs) have made
significant progress in the medical domain, yet their performance remains
constrained when applied to physiological waveform data, especially EEG
signals, due to their limited visual understanding and insufficient reasoning
capability. To address these challenges, we propose EEG-VLM, a hierarchical
vision-language framework that integrates multi-level feature alignment with
visually enhanced language-guided reasoning for interpretable EEG-based sleep
stage classification. Specifically, a specialized visual enhancement module
constructs high-level visual tokens from intermediate-layer features to extract
rich semantic representations of EEG images. These tokens are further aligned
with low-level CLIP features through a multi-level alignment mechanism,
enhancing the VLM's image-processing capability. In addition, a
Chain-of-Thought (CoT) reasoning strategy decomposes complex medical inference
into interpretable logical steps, effectively simulating expert-like
decision-making. Experimental results demonstrate that the proposed method
significantly improves both the accuracy and interpretability of VLMs in
EEG-based sleep stage classification, showing promising potential for automated
and explainable EEG analysis in clinical settings.
\\ ( https://arxiv.org/abs/2511.19155 ,  3993kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19256
Date: Mon, 24 Nov 2025 16:09:55 GMT   (8106kb)

Title: SimDiff: Simpler Yet Better Diffusion Model for Time Series Point
 Forecasting
Authors: Hang Ding, Xue Wang, Tian Zhou, Tao Yao
Categories: cs.AI cs.LG
Comments: Accepted by AAAI 2026
\\
 Diffusion models have recently shown promise in time series forecasting,
particularly for probabilistic predictions. However, they often fail to achieve
state-of-the-art point estimation performance compared to regression-based
methods. This limitation stems from difficulties in providing sufficient
contextual bias to track distribution shifts and in balancing output diversity
with the stability and precision required for point forecasts. Existing
diffusion-based approaches mainly focus on full-distribution modeling under
probabilistic frameworks, often with likelihood maximization objectives, while
paying little attention to dedicated strategies for high-accuracy point
estimation. Moreover, other existing point prediction diffusion methods
frequently rely on pre-trained or jointly trained mature models for contextual
bias, sacrificing the generative flexibility of diffusion models.
 To address these challenges, we propose SimDiff, a single-stage, end-to-end
framework. SimDiff employs a single unified Transformer network carefully
tailored to serve as both denoiser and predictor, eliminating the need for
external pre-trained or jointly trained regressors. It achieves
state-of-the-art point estimation performance by leveraging intrinsic output
diversity and improving mean squared error accuracy through multiple inference
ensembling. Key innovations, including normalization independence and the
median-of-means estimator, further enhance adaptability and stability.
Extensive experiments demonstrate that SimDiff significantly outperforms
existing methods in time series point forecasting.
\\ ( https://arxiv.org/abs/2511.19256 ,  8106kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19262
Date: Mon, 24 Nov 2025 16:15:08 GMT   (20kb)

Title: Psychometric Tests for AI Agents and Their Moduli Space
Authors: Przemyslaw Chojecki
Categories: cs.AI cs.LG math.ST stat.TH
\\
 We develop a moduli-theoretic view of psychometric test batteries for AI
agents and connect it explicitly to the AAI score developed previously. First,
we make precise the notion of an AAI functional on a battery and set out axioms
that any reasonable autonomy/general intelligence score should satisfy. Second,
we show that the composite index ('AAI-Index') defined previously is a special
case of our AAI functional. Third, we introduce the notion of a cognitive core
of an agent relative to a battery and define the associated
AAI$_{\textrm{core}}$ score as the restriction of an AAI functional to that
core. Finally, we use these notions to describe invariants of batteries under
evaluation-preserving symmetries and outline how moduli of equivalent batteries
are organized.
\\ ( https://arxiv.org/abs/2511.19262 ,  20kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19304
Date: Mon, 24 Nov 2025 16:54:23 GMT   (10311kb)

Title: AutoEnv: Automated Environments for Measuring Cross-Environment Agent
 Learning
Authors: Jiayi Zhang, Yiran Peng, Fanqi Kong, Yang Cheng, Yifan Wu, Zhaoyang
 Yu, Jinyu Xiang, Jianhao Ruan, Jinlin Wang, Maojia Song, HongZhang Liu,
 Xiangru Tang, Bang Liu, Chenglin Wu, Yuyu Luo
Categories: cs.AI cs.CL cs.LG
\\
 Humans naturally adapt to diverse environments by learning underlying rules
across worlds with different dynamics, observations, and reward structures. In
contrast, existing agents typically demonstrate improvements via self-evolving
within a single domain, implicitly assuming a fixed environment distribution.
Cross-environment learning has remained largely unmeasured: there is no
standard collection of controllable, heterogeneous environments, nor a unified
way to represent how agents learn. We address these gaps in two steps. First,
we propose AutoEnv, an automated framework that treats environments as
factorizable distributions over transitions, observations, and rewards,
enabling low-cost (4.12 USD on average) generation of heterogeneous worlds.
Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358
validated levels, on which seven language models achieve 12-49% normalized
reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent
learning as a component-centric process driven by three stages of Selection,
Optimization, and Evaluation applied to an improvable agent component. Using
this formulation, we design eight learning methods and evaluate them on
AutoEnv-36. Empirically, the gain of any single learning method quickly
decrease as the number of environments increases, revealing that fixed learning
methods do not scale across heterogeneous environments. Environment-adaptive
selection of learning methods substantially improves performance but exhibits
diminishing returns as the method space expands. These results highlight both
the necessity and the current limitations of agent learning for scalable
cross-environment generalization, and position AutoEnv and AutoEnv-36 as a
testbed for studying cross-environment agent learning. The code is avaiable at
https://github.com/FoundationAgents/AutoEnv.
\\ ( https://arxiv.org/abs/2511.19304 ,  10311kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19314
Date: Mon, 24 Nov 2025 17:09:43 GMT   (1125kb)

Title: PRInTS: Reward Modeling for Long-Horizon Information Seeking
Authors: Jaewoo Lee, Archiki Prasad, Justin Chih-Yao Chen, Zaid Khan, Elias
 Stengel-Eskin, Mohit Bansal
Categories: cs.AI cs.CL cs.LG
Comments: 18 pages, code: https://github.com/G-JWLee/PRInTS
\\
 Information-seeking is a core capability for AI agents, requiring them to
gather and reason over tool-generated information across long trajectories.
However, such multi-step information-seeking tasks remain challenging for
agents backed by language models. While process reward models (PRMs) can guide
agents by ranking candidate steps at test-time, existing PRMs, designed for
short reasoning with binary judgment, cannot capture richer dimensions of
information-seeking steps, such as tool interactions and reasoning over tool
outputs, nor handle the rapidly growing context in long-horizon tasks. To
address these limitations, we introduce PRInTS, a generative PRM trained with
dual capabilities: (1) dense scoring based on the PRM's reasoning across
multiple step quality dimensions (e.g., interpretation of tool outputs, tool
call informativeness) and (2) trajectory summarization that compresses the
growing context while preserving essential information for step evaluation.
Extensive evaluations across FRAMES, GAIA (levels 1-3), and WebWalkerQA
(easy-hard) benchmarks on multiple models, along with ablations, reveal that
best-of-n sampling with PRInTS enhances information-seeking abilities of
open-source models as well as specialized agents, matching or surpassing the
performance of frontier models with a much smaller backbone agent and
outperforming other strong reward modeling baselines.
\\ ( https://arxiv.org/abs/2511.19314 ,  1125kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17559
Date: Thu, 13 Nov 2025 06:35:29 GMT   (3077kb)

Title: SCARE: A Benchmark for SQL Correction and Question Answerability
 Classification for Reliable EHR Question Answering
Authors: Gyubok Lee, Woosog Chay, Edward Choi
Categories: cs.CL cs.DB
Comments: ML4H 2025 Proceedings
\\
 Recent advances in Large Language Models (LLMs) have enabled the development
of text-to-SQL models that allow clinicians to query structured data stored in
Electronic Health Records (EHRs) using natural language. However, deploying
these models for EHR question answering (QA) systems in safety-critical
clinical environments remains challenging: incorrect SQL queries-whether caused
by model errors or problematic user inputs-can undermine clinical
decision-making and jeopardize patient care. While prior work has mainly
focused on improving SQL generation accuracy or filtering questions before
execution, there is a lack of a unified benchmark for evaluating independent
post-hoc verification mechanisms (i.e., a component that inspects and validates
the generated SQL before execution), which is crucial for safe deployment. To
fill this gap, we introduce SCARE, a benchmark for evaluating methods that
function as a post-hoc safety layer in EHR QA systems. SCARE evaluates the
joint task of (1) classifying question answerability (i.e., determining whether
a question is answerable, ambiguous, or unanswerable) and (2) verifying or
correcting candidate SQL queries. The benchmark comprises 4,200 triples of
questions, candidate SQL queries, and expected model outputs, grounded in the
MIMIC-III, MIMIC-IV, and eICU databases. It covers a diverse set of questions
and corresponding candidate SQL queries generated by seven different
text-to-SQL models, ensuring a realistic and challenging evaluation. Using
SCARE, we benchmark a range of approaches-from two-stage methods to agentic
frameworks. Our experiments reveal a critical trade-off between question
classification and SQL error correction, highlighting key challenges and
outlining directions for future research.
\\ ( https://arxiv.org/abs/2511.17559 ,  3077kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17560
Date: Thu, 13 Nov 2025 07:28:59 GMT   (541kb)

Title: $A^3$: Attention-Aware Accurate KV Cache Fusion for Fast Large Language
 Model Serving
Authors: Yuechi Zhou, Yi Su, Jianxin Zhang, Juntao Li, Qingrong Xia, Zhefeng
 Wang, Xinyu Duan, Baoxing Huai
Categories: cs.CL cs.AI
\\
 Large language models (LLMs) have demonstrated strong capabilities in
processing long contexts, enabling them to tackle tasks involving long textual
inputs such as multi-turn conversations, legal documents, or retrieved
documents in Retrieval-Augmented Generation (RAG) systems. However, despite
their ability to handle long sequences, the resulting decoding latency and
memory overhead remain substantial, posing challenges for real-world
deployment. Recent advances in KV Cache reuse have shown potential to mitigate
these costs, but still suffer from notable performance degradation. To address
this issue, we conduct an in-depth investigation of recomputation-based reuse
methods and observe that the recomputed tokens often fail to align with the
context segments most relevant to the question. This misalignment hinders
proper updates to the critical contextual representations. Therefore, we
propose the $\textbf{A}$ttention-$\textbf{A}$ware $\textbf{A}$ccurate KV Cache
Fusion algorithm ($A^3$), which precomputes and selectively fuses the KV Cache
of text chunks based on their relevance to the question, achieving accurate
integration with minimal computational overhead. Extensive experiments on
various benchmarks and LLMs demonstrate that $A^3$ achieves the best task
performance compared to four baselines while reducing the time-to-first-token
(TTFT) by 2$\times$.
\\ ( https://arxiv.org/abs/2511.17560 ,  541kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17561
Date: Thu, 13 Nov 2025 08:04:30 GMT   (444kb)

Title: LexInstructEval: Lexical Instruction Following Evaluation for Large
 Language Models
Authors: Huimin Ren, Yan Liang, Baiqiao Su, Chaobo Sun, Hengtong Lu, Kaike
 Zhang, Chen Wei
Categories: cs.CL cs.AI
\\
 The ability of Large Language Models (LLMs) to precisely follow complex and
fine-grained lexical instructions is a cornerstone of their utility and
controllability. However, evaluating this capability remains a significant
challenge. Current methods either rely on subjective and costly human
evaluation or on automated LLM-as-a-judge systems, which suffer from inherent
biases and unreliability. Existing programmatic benchmarks, while objective,
often lack the expressiveness to test intricate, compositional constraints at a
granular level. To address these limitations, we introduce LexInstructEval, a
new benchmark and evaluation framework for fine-grained lexical instruction
following. Our framework is built upon a formal, rule-based grammar that
deconstructs complex instructions into a canonical <Procedure, Relation, Value>
triplet. This grammar enables the systematic generation of a diverse dataset
through a multi-stage, human-in-the-loop pipeline and facilitates objective
verification via a transparent, programmatic engine. We release our dataset and
open-source evaluation tools to facilitate further research into the
controllability and reliability of LLMs.
\\ ( https://arxiv.org/abs/2511.17561 ,  444kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17562
Date: Thu, 13 Nov 2025 09:18:34 GMT   (10kb)

Title: ChineseErrorCorrector3-4B: State-of-the-Art Chinese Spelling and Grammar
 Corrector
Authors: Wei Tian and YuhaoZhou
Categories: cs.CL cs.AI
\\
 This paper introduces ChineseErrorCorrector3-4B, a unified model for Chinese
spelling and grammatical error correction based on Qwen3-4B. The model
demonstrates outstanding performance in general text correction tasks and
achieves state-of-the-art results in both spelling correction (CSC) and
grammatical correction (CGC). On several authoritative benchmark datasets --
including SIGHAN-2015, EC-LAW, MCSC, and NaCGEC -- the model's F1 and F0.5
scores significantly surpass existing publicly available models, ranking first
in both spelling and grammatical error correction tasks.
\\ ( https://arxiv.org/abs/2511.17562 ,  10kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17565
Date: Fri, 14 Nov 2025 00:22:00 GMT   (745kb)

Title: Generative Caching for Structurally Similar Prompts and Responses
Authors: Sarthak Chakraborty, Suman Nath, Xuchao Zhang, Chetan Bansal, Indranil
 Gupta
Categories: cs.CL cs.AI
\\
 Large Language Models (LLMs) are increasingly being used to plan, reason, and
execute tasks across diverse scenarios. In use cases like repeatable workflows
and agentic settings, prompts are often reused with minor variations while
having a similar structure for recurring tasks. This opens up opportunities for
caching. However, exact prompt matching fails on such structurally similar
prompts, while semantic caching may produce incorrect responses by ignoring
critical differences. To address this, we introduce \ourmethod{}, a generative
cache that produces variation-aware responses for structurally similar prompts.
\ourmethod{} identifies reusable response patterns across similar prompt
structures and synthesizes customized outputs for new requests. We show that
\ourmethod{} achieves 83\% cache hit rate, while having minimal incorrect hits
on datasets without prompt repetition. In agentic workflows, it improves cache
hit rate by $\sim$20\% and reduces end-to-end execution latency by $\sim$34\%
compared to standard prompt matching.
\\ ( https://arxiv.org/abs/2511.17565 ,  745kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17572
Date: Fri, 14 Nov 2025 20:04:52 GMT   (579kb)

Title: Community-Aligned Behavior Under Uncertainty: Evidence of Epistemic
 Stance Transfer in LLMs
Authors: Patrick Gerard, Aiden Chang, Svitlana Volkova
Categories: cs.CL cs.SI
Comments: 37 pages, EurIPS 2025
\\
 When large language models (LLMs) are aligned to a specific online community,
do they exhibit generalizable behavioral patterns that mirror that community's
attitudes and responses to new uncertainty, or are they simply recalling
patterns from training data? We introduce a framework to test epistemic stance
transfer: targeted deletion of event knowledge, validated with multiple probes,
followed by evaluation of whether models still reproduce the community's
organic response patterns under ignorance. Using Russian--Ukrainian military
discourse and U.S. partisan Twitter data, we find that even after aggressive
fact removal, aligned LLMs maintain stable, community-specific behavioral
patterns for handling uncertainty. These results provide evidence that
alignment encodes structured, generalizable behaviors beyond surface mimicry.
Our framework offers a systematic way to detect behavioral biases that persist
under ignorance, advancing efforts toward safer and more transparent LLM
deployments.
\\ ( https://arxiv.org/abs/2511.17572 ,  579kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17575
Date: Fri, 14 Nov 2025 23:05:59 GMT   (20kb)

Title: Random Text, Zipf's Law, Critical Length,and Implications for Large
 Language Models
Authors: Vladimir Berman
Categories: cs.CL stat.ME stat.ML stat.OT
\\
 We study a deliberately simple, fully non-linguistic model of text: a
sequence of independent draws from a finite alphabet of letters plus a single
space symbol. A word is defined as a maximal block of non-space symbols. Within
this symbol-level framework, which assumes no morphology, syntax, or semantics,
we derive several structural results. First, word lengths follow a geometric
distribution governed solely by the probability of the space symbol. Second,
the expected number of words of a given length, and the expected number of
distinct words of that length, admit closed-form expressions based on a
coupon-collector argument. This yields a critical word length k* at which word
types transition from appearing many times on average to appearing at most
once. Third, combining the exponential growth of the number of possible strings
of length k with the exponential decay of the probability of each string, we
obtain a Zipf-type rank-frequency law p(r) proportional to r^{-alpha}, with an
exponent determined explicitly by the alphabet size and the space probability.
 Our contribution is twofold. Mathematically, we give a unified derivation
linking word lengths, vocabulary growth, critical length, and rank-frequency
structure in a single explicit model. Conceptually, we argue that this provides
a structurally grounded null model for both natural-language word statistics
and token statistics in large language models. The results show that Zipf-like
patterns can arise purely from combinatorics and segmentation, without
optimization principles or linguistic organization, and help clarify which
phenomena require deeper explanation beyond random-text structure.
\\ ( https://arxiv.org/abs/2511.17575 ,  20kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17746
Date: Fri, 21 Nov 2025 19:52:46 GMT   (1302kb)

Title: Computational frame analysis revisited: On LLMs for studying news
 coverage
Authors: Sharaj Kunjar, Alyssa Hasegawa Smith, Tyler R Mckenzie, Rushali Mohbe,
 Samuel V Scarpino, Brooke Foucault Welles
Categories: cs.CL
\\
 Computational approaches have previously shown various promises and pitfalls
when it comes to the reliable identification of media frames. Generative LLMs
like GPT and Claude are increasingly being used as content analytical tools,
but how effective are they for frame analysis? We address this question by
systematically evaluating them against their computational predecessors:
bag-of-words models and encoder-only transformers; and traditional manual
coding procedures. Our analysis rests on a novel gold standard dataset that we
inductively and iteratively developed through the study, investigating six
months of news coverage of the US Mpox epidemic of 2022. While we discover some
potential applications for generative LLMs, we demonstrate that they were
consistently outperformed by manual coders, and in some instances, by smaller
language models. Some form of human validation was always necessary to
determine appropriate model choice. Additionally, by examining how the
suitability of various approaches depended on the nature of different tasks
that were part of our frame analytical workflow, we provide insights as to how
researchers may leverage the complementarity of these approaches to use them in
tandem. We conclude by endorsing a methodologically pluralistic approach and
put forth a roadmap for computational frame analysis for researchers going
forward.
\\ ( https://arxiv.org/abs/2511.17746 ,  1302kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17808
Date: Fri, 21 Nov 2025 22:01:51 GMT   (152kb)

Title: PoETa v2: Toward More Robust Evaluation of Large Language Models in
 Portuguese
Authors: Thales Sales Almeida, Rodrigo Nogueira, H\'elio Pedrini
Categories: cs.CL
\\
 Large Language Models (LLMs) exhibit significant variations in performance
across linguistic and cultural contexts, underscoring the need for systematic
evaluation in diverse languages. In this work, we present the most extensive
evaluation of LLMs for the Portuguese language to date. Leveraging our newly
introduced PoETa v2 benchmark -- a comprehensive suite of over 40 tasks in
Portuguese -- we assess more than 20 models covering a broad spectrum of
training scales and computational resources. Our study reveals how
computational investment and language-specific adaptation impact performance in
Portuguese, while also analyzing performance gaps in comparison to equivalent
tasks in English. Through this benchmark and analysis, PoETa v2 lays the
groundwork for future research on Portuguese language modeling and evaluation.
The benchmark is available at https://github.com/PoETaV2/PoETaV2.
\\ ( https://arxiv.org/abs/2511.17808 ,  152kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17813
Date: Fri, 21 Nov 2025 22:07:33 GMT   (1726kb)

Title: Point of Order: Action-Aware LLM Persona Modeling for Realistic Civic
 Simulation
Authors: Scott Merrill and Shashank Srivastava
Categories: cs.CL cs.AI cs.LG cs.SD
Comments: 8 pages (29 pages including appendix), 18 figures. Code and datasets
 are available at https://github.com/smerrillunc/action-aware-llms. Submitted
 to ACL 2026
ACM-class: I.2.7; I.2.6
\\
 Large language models offer opportunities to simulate multi-party
deliberation, but realistic modeling remains limited by a lack of
speaker-attributed data. Transcripts produced via automatic speech recognition
(ASR) assign anonymous speaker labels (e.g., Speaker_1), preventing models from
capturing consistent human behavior. This work introduces a reproducible
pipeline to transform public Zoom recordings into speaker-attributed
transcripts with metadata like persona profiles and pragmatic action tags
(e.g., [propose_motion]). We release three local government deliberation
datasets: Appellate Court hearings, School Board meetings, and Municipal
Council sessions. Fine-tuning LLMs to model specific participants using this
"action-aware" data produces a 67% reduction in perplexity and nearly doubles
classifier-based performance metrics for speaker fidelity and realism.
Turing-style human evaluations show our simulations are often indistinguishable
from real deliberations, providing a practical and scalable method for complex
realistic civic simulations.
\\ ( https://arxiv.org/abs/2511.17813 ,  1726kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17854
Date: Sat, 22 Nov 2025 00:45:01 GMT   (5017kb)

Title: A superpersuasive autonomous policy debating system
Authors: Allen Roush, Devin Gonier, John Hines, Judah Goldfeder, Philippe
 Martin Wyder, Sanjay Basu, Ravid Shwartz Ziv
Categories: cs.CL cs.AI cs.CY cs.HC cs.MA
Comments: Accepted to CLIP workshop at AAAI 2026
\\
 The capacity for highly complex, evidence-based, and strategically adaptive
persuasion remains a formidable great challenge for artificial intelligence.
Previous work, like IBM Project Debater, focused on generating persuasive
speeches in simplified and shortened debate formats intended for relatively lay
audiences. We introduce DeepDebater, a novel autonomous system capable of
participating in and winning a full, unmodified, two-team competitive policy
debate. Our system employs a hierarchical architecture of specialized
multi-agent workflows, where teams of LLM-powered agents collaborate and
critique one another to perform discrete argumentative tasks. Each workflow
utilizes iterative retrieval, synthesis, and self-correction using a massive
corpus of policy debate evidence (OpenDebateEvidence) and produces complete
speech transcripts, cross-examinations, and rebuttals. We introduce a live,
interactive end-to-end presentation pipeline that renders debates with AI
speech and animation: transcripts are surface-realized and synthesized to audio
with OpenAI TTS, and then displayed as talking-head portrait videos with
EchoMimic V1. Beyond fully autonomous matches (AI vs AI), DeepDebater supports
hybrid human-AI operation: human debaters can intervene at any stage, and
humans can optionally serve as opponents against AI in any speech, allowing
AI-human and AI-AI rounds. In preliminary evaluations against human-authored
cases, DeepDebater produces qualitatively superior argumentative components and
consistently wins simulated rounds as adjudicated by an independent autonomous
judge. Expert human debate coaches also prefer the arguments, evidence, and
cases constructed by DeepDebater. We open source all code, generated speech
transcripts, audio and talking head video here:
https://github.com/Hellisotherpeople/DeepDebater/tree/main
\\ ( https://arxiv.org/abs/2511.17854 ,  5017kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17908
Date: Sat, 22 Nov 2025 04:17:06 GMT   (879kb)

Title: Principled Context Engineering for RAG: Statistical Guarantees via
 Conformal Prediction
Authors: Debashish Chakraborty, Eugene Yang, Daniel Khashabi, Dawn Lawrie, and
 Kevin Duh
Categories: cs.CL cs.AI cs.IR
Comments: Preprint
\\
 Retrieval-Augmented Generation (RAG) enhances factual grounding in large
language models (LLMs) by incorporating retrieved evidence, but LLM accuracy
declines when long or noisy contexts exceed the model's effective attention
span. Existing pre-generation filters rely on heuristics or uncalibrated LLM
confidence scores, offering no statistical control over retained evidence. We
evaluate and demonstrate context engineering through conformal prediction, a
coverage-controlled filtering framework that removes irrelevant content while
preserving recall of supporting evidence. Using both embedding- and LLM-based
scoring functions, we test this approach on the NeuCLIR and RAGTIME
collections. Conformal filtering consistently meets its target coverage,
ensuring that a specified fraction of relevant snippets are retained, and
reduces retained context by 2-3x relative to unfiltered retrieval. On NeuCLIR,
downstream factual accuracy measured by ARGUE F1 improves under strict
filtering and remains stable at moderate coverage, indicating that most
discarded material is redundant or irrelevant. These results demonstrate that
conformal prediction enables reliable, coverage-controlled context reduction in
RAG, offering a model-agnostic and principled approach to context engineering.
\\ ( https://arxiv.org/abs/2511.17908 ,  879kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17910
Date: Sat, 22 Nov 2025 04:25:25 GMT   (1106kb)

Title: L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent
 Intervention
Authors: Yuliang Zhan, Xinyu Tang, Han Wan, Jian Li, Ji-Rong Wen, Hao Sun
Categories: cs.CL
Comments: AAAI 2026 oral
\\
 Recently, Chain-of-Thought (CoT) reasoning has significantly enhanced the
capabilities of large language models (LLMs), but Vision-Language Models (VLMs)
still struggle with multi-step reasoning tasks due to limited multimodal
reasoning data. To bridge this gap, researchers have explored methods to
transfer CoT reasoning from LLMs to VLMs. However, existing approaches either
need high training costs or require architectural alignment. In this paper, we
use Linear Artificial Tomography (LAT) to empirically show that LLMs and VLMs
share similar low-frequency latent representations of CoT reasoning despite
architectural differences. Based on this insight, we propose L2V-CoT, a novel
training-free latent intervention approach that transfers CoT reasoning from
LLMs to VLMs. L2V-CoT extracts and resamples low-frequency CoT representations
from LLMs in the frequency domain, enabling dimension matching and latent
injection into VLMs during inference to enhance reasoning capabilities.
Extensive experiments demonstrate that our approach consistently outperforms
training-free baselines and even surpasses supervised methods.
\\ ( https://arxiv.org/abs/2511.17910 ,  1106kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17923
Date: Sat, 22 Nov 2025 05:38:03 GMT   (444kb)

Title: Towards Efficient LLM-aware Heterogeneous Graph Learning
Authors: Wenda Li, Tongya Zheng, Shunyu Liu, Yu Wang, Kaixuan Chen, Hanyang
 Yuan, Bingde Hu, Zujie Ren, Mingli Song, Gang Chen
Categories: cs.CL cs.AI
\\
 Heterogeneous graphs are widely present in real-world complex networks, where
the diversity of node and relation types leads to complex and rich semantics.
Efforts for modeling complex relation semantics in heterogeneous graphs are
restricted by the limitations of predefined semantic dependencies and the
scarcity of supervised signals. The advanced pre-training and fine-tuning
paradigm leverages graph structure to provide rich self-supervised signals, but
introduces semantic gaps between tasks. Large Language Models (LLMs) offer
significant potential to address the semantic issues of relations and tasks in
heterogeneous graphs through their strong reasoning capabilities in textual
modality, but their incorporation into heterogeneous graphs is largely limited
by computational complexity. Therefore, in this paper, we propose an Efficient
LLM-Aware (ELLA) framework for heterogeneous graphs, addressing the above
issues. To capture complex relation semantics, we propose an LLM-aware Relation
Tokenizer that leverages LLM to encode multi-hop, multi-type relations. To
reduce computational complexity, we further employ a Hop-level Relation Graph
Transformer, which help reduces the complexity of LLM-aware relation reasoning
from exponential to linear. To bridge semantic gaps between pre-training and
fine-tuning tasks, we introduce the fine-grained task-aware textual
Chain-of-Thought (CoT) prompts. Extensive experiments on four heterogeneous
graphs show that our proposed ELLA outperforms state-of-the-art methods in the
performance and efficiency. In particular, ELLA scales up to 13b-parameter LLMs
and achieves up to a 4x speedup compared with existing LLM-based methods. Our
code is publicly available at https://github.com/l-wd/ELLA.
\\ ( https://arxiv.org/abs/2511.17923 ,  444kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17938
Date: Sat, 22 Nov 2025 06:32:34 GMT   (1346kb)

Title: SPINE: Token-Selective Test-Time Reinforcement Learning with
 Entropy-Band Regularization
Authors: Jianghao Wu, Yasmeen George, Jin Ye, Yicheng Wu, Daniel F. Schmidt,
 Jianfei Cai
Categories: cs.CL cs.LG
\\
 Large language models (LLMs) and multimodal LLMs (MLLMs) excel at
chain-of-thought reasoning but face distribution shift at test-time and a lack
of verifiable supervision. Recent test-time reinforcement learning (TTRL)
methods derive label-free pseudo-rewards from self-consistency voting over
sampled trajectories, yet they often collapse: the majority-vote reward
prevails, responses shorten, and Pass@1 declines. We trace this to uniform
sequence updates in which most tokens are low-entropy followers, while a small
high-entropy subset determines the reasoning branches. Thus we propose SPINE, a
token-selective test-time reinforcement learning framework that (i) updates
only forking tokens, the high-entropy branch points identified from
forward-pass statistics, and (ii) applies an entropy-band regularizer at those
tokens to sustain exploration when entropy is too low and to suppress noisy
supervision when it is too high. SPINE plugs into GRPO-style objectives,
optionally with a KL anchor, and requires no labels or reward models. Across
ten benchmarks spanning multimodal VQA, general and expert QA, mathematical
reasoning, and medical QA, SPINE consistently improves Pass@1 over TTRL while
avoiding response-length collapse and yielding more stable training dynamics on
both LLM and MLLM backbones. These results indicate that aligning updates with
chain-of-thought branch points is a simple and label-free mechanism for stable
and effective test-time adaptation in reasoning models. Code is available at
https://github.com/JianghaoWu/SPINE.
\\ ( https://arxiv.org/abs/2511.17938 ,  1346kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17946
Date: Sat, 22 Nov 2025 06:59:55 GMT   (9821kb)

Title: Measuring the Impact of Lexical Training Data Coverage on Hallucination
 Detection in Large Language Models
Authors: Shuo Zhang, Fabrizio Gotti, Fengran Mo, Jian-Yun Nie
Categories: cs.CL cs.AI
\\
 Hallucination in large language models (LLMs) is a fundamental challenge,
particularly in open-domain question answering. Prior work attempts to detect
hallucination with model-internal signals such as token-level entropy or
generation consistency, while the connection between pretraining data exposure
and hallucination is underexplored. Existing studies show that LLMs
underperform on long-tail knowledge, i.e., the accuracy of the generated answer
drops for the ground-truth entities that are rare in pretraining. However,
examining whether data coverage itself can serve as a detection signal is
overlooked. We propose a complementary question: Does lexical training-data
coverage of the question and/or generated answer provide additional signal for
hallucination detection? To investigate this, we construct scalable suffix
arrays over RedPajama's 1.3-trillion-token pretraining corpus to retrieve
$n$-gram statistics for both prompts and model generations. We evaluate their
effectiveness for hallucination detection across three QA benchmarks. Our
observations show that while occurrence-based features are weak predictors when
used alone, they yield modest gains when combined with log-probabilities,
particularly on datasets with higher intrinsic model uncertainty. These
findings suggest that lexical coverage features provide a complementary signal
for hallucination detection. All code and suffix-array infrastructure are
provided at https://github.com/WWWonderer/ostd.
\\ ( https://arxiv.org/abs/2511.17946 ,  9821kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17955
Date: Sat, 22 Nov 2025 07:41:16 GMT   (13052kb)

Title: MTikGuard System: A Transformer-Based Multimodal System for Child-Safe
 Content Moderation on TikTok
Authors: Dat Thanh Nguyen, Nguyen Hung Lam, Anh Hoang-Thi Nguyen, Trong-Hop Do
Categories: cs.CL
Comments: Accepted at PACLIC39
\\
 With the rapid rise of short-form videos, TikTok has become one of the most
influential platforms among children and teenagers, but also a source of
harmful content that can affect their perception and behavior. Such content,
often subtle or deceptive, challenges traditional moderation methods due to the
massive volume and real-time nature of uploads. This paper presents MTikGuard,
a real-time multimodal harmful content detection system for TikTok, with three
key contributions: (1) an extended TikHarm dataset expanded to 4,723 labeled
videos by adding diverse real-world samples, (2) a multimodal classification
framework integrating visual, audio, and textual features to achieve
state-of-the-art performance with 89.37% accuracy and 89.45% F1-score, and (3)
a scalable streaming architecture built on Apache Kafka and Apache Spark for
real-time deployment. The results demonstrate the effectiveness of combining
dataset expansion, advanced multimodal fusion, and robust deployment for
practical large-scale social media content moderation. The dataset is available
at https://github.com/ntdat-8324/MTikGuard-System.git.
\\ ( https://arxiv.org/abs/2511.17955 ,  13052kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18054
Date: Sat, 22 Nov 2025 13:14:07 GMT   (2463kb)

Title: Blu-WERP (Web Extraction and Refinement Pipeline): A Scalable Pipeline
 for Preprocessing Large Language Model Datasets
Authors: Gowtham, Sai Rupesh, Sanjay Kumar, Saravanan, Venkata Chaithanya
Categories: cs.CL cs.LG
\\
 High-quality training data is fundamental to large language model (LLM)
performance, yet existing preprocessing pipelines often struggle to effectively
remove noise and unstructured content from web-scale corpora. This paper
presents Blu-WERP, a novel data preprocessing pipeline designed to optimize the
quality of Common Crawl WARC files for LLM training. We demonstrate that
Blu-WERP significantly outperforms established baselines including DCLM across
multiple model scales and evaluation benchmarks. Our pipeline processes CC WARC
dumps, implementing advanced filtering and quality assessment mechanisms. We
conducted comprehensive evaluations using models with 150M, 400M, 530M, 750M,
and 1B parameters, testing against nine standard benchmarks categorized as
World Knowledge & Reasoning, Language Understanding, and Commonsense Reasoning.
Results show Blu-WERP consistently achieved superior performance across all
model scales. At the 1B parameter scale, Relatively Blu-WERP demonstrates a
4.0% and 9.5% aggregate improvement over DCLM and Fineweb respectively, while
achieving quality-per-token efficiency gain. Categorical analysis reveals 2.4%
improvement in World Knowledge & Reasoning, 6.2% improvement in Language
Understanding, and 4.2% improvement in Commonsense Reasoning. These results
establish Blu-WERP as a state-of-the-art preprocessing pipeline that
substantially improves LLM training data quality and downstream model
performance with reduced computational cost. Our findings contribute to the
growing body of research on data-centric AI, demonstrating that preprocessing
pipeline design significantly impacts LLM capabilities. The Blu-WERP pipeline
represents a practical advancement in data quality optimization, offering
researchers and practitioners an effective solution for improving LLM training
efficiency and model performance.
\\ ( https://arxiv.org/abs/2511.18054 ,  2463kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18146
Date: Sat, 22 Nov 2025 18:15:06 GMT   (3549kb)

Title: GeeSanBhava: Sentiment Tagged Sinhala Music Video Comment Data Set
Authors: Yomal De Mel and Nisansa de Silva
Categories: cs.CL
Journal-ref: International Conference on Computational Collective Intelligence
 (2025)
DOI: 10.1007/978-3-032-10209-6_11
\\
 This study introduce GeeSanBhava, a high-quality data set of Sinhala song
comments extracted from YouTube manually tagged using Russells Valence-Arousal
model by three independent human annotators. The human annotators achieve a
substantial inter-annotator agreement (Fleiss kappa = 84.96%). The analysis
revealed distinct emotional profiles for different songs, highlighting the
importance of comment based emotion mapping. The study also addressed the
challenges of comparing comment-based and song-based emotions, mitigating
biases inherent in user-generated content. A number of Machine learning and
deep learning models were pre-trained on a related large data set of Sinhala
News comments in order to report the zero-shot result of our Sinhala YouTube
comment data set. An optimized Multi-Layer Perceptron model, after extensive
hyperparameter tuning, achieved a ROC-AUC score of 0.887. The model is a
three-layer MLP with a configuration of 256, 128, and 64 neurons. This research
contributes a valuable annotated dataset and provides insights for future work
in Sinhala Natural Language Processing and music emotion recognition.
\\ ( https://arxiv.org/abs/2511.18146 ,  3549kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18162
Date: Sat, 22 Nov 2025 19:21:13 GMT   (4427kb)

Title: Vector Arithmetic in Concept and Token Subspaces
Authors: Sheridan Feucht, Byron Wallace, David Bau
Categories: cs.CL
Comments: 9 pages, 6 figures. NeurIPS 2025 Mechanistic Interpretability
 Workshop
\\
 In order to predict the next token, LLMs must represent semantic and
surface-level information about the current word. Previous work identified two
types of attention heads that disentangle this information: (i) Concept
induction heads, which copy word meanings, and (ii) Token induction heads,
which copy literal token representations (Feucht et al., 2025). We show that
these heads can be used to identify subspaces of model activations that exhibit
coherent semantic structure in Llama-2-7b. Specifically, when we transform
hidden states using the attention weights of concept heads, we are able to more
accurately perform parallelogram arithmetic (Mikolov et al., 2013) on the
resulting hidden states, e.g., showing that "Athens" - "Greece" + "China" =
"Beijing". This transformation allows for much higher nearest-neighbor accuracy
(80%) than direct use of raw hidden states (47%). Analogously, we show that
token heads allow for transformations that reveal surface-level word
information in hidden states, allowing for operations like "coding" - "code" +
"dance" = "dancing".
\\ ( https://arxiv.org/abs/2511.18162 ,  4427kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18177
Date: Sat, 22 Nov 2025 20:06:25 GMT   (503kb)

Title: Rethinking Retrieval: From Traditional Retrieval Augmented Generation to
 Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large
 Language Models
Authors: Elias Lumer and Matt Melich and Olivia Zino and Elena Kim and Sara
 Dieter and Pradeep Honaganahalli Basavaraju and Vamse Kumar Subbiah and James
 A. Burke and Roberto Hernandez
Categories: cs.CL
Comments: 8 pages, 2 figures
\\
 Recent advancements in Retrieval-Augmented Generation (RAG) have enabled
Large Language Models to answer financial questions using external knowledge
bases of U.S. SEC filings, earnings reports, and regulatory documents. However,
existing work lacks systematic comparison of vector-based and non-vector RAG
architectures for financial documents, and the empirical impact of advanced RAG
techniques on retrieval accuracy, answer quality, latency, and cost remain
unclear. We present the first systematic evaluation comparing vector-based
agentic RAG using hybrid search and metadata filtering against hierarchical
node-based systems that traverse document structure without embeddings. We
evaluate two enhancement techniques applied to the vector-based architecture,
i) cross-encoder reranking for retrieval precision, and ii) small-to-big chunk
retrieval for context completeness. Across 1,200 SEC 10-K, 10-Q, and 8-K
filings on a 150-question benchmark, we measure retrieval metrics (MRR,
Recall@5), answer quality through LLM-as-a-judge pairwise comparisons, latency,
and preprocessing costs. Vector-based agentic RAG achieves a 68% win rate over
hierarchical node-based systems with comparable latency (5.2 compared to 5.98
seconds). Cross-encoder reranking achieves a 59% absolute improvement at
optimal parameters (10, 5) for MRR@5. Small-to-big retrieval achieves a 65% win
rate over baseline chunking with only 0.2 seconds additional latency. Our
findings reveal that applying advanced RAG techniques to financial Q&A systems
improves retrieval accuracy, answer quality, and has cost-performance tradeoffs
to be considered in production.
\\ ( https://arxiv.org/abs/2511.18177 ,  503kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18194
Date: Sat, 22 Nov 2025 21:24:16 GMT   (349kb)

Title: Agent-as-a-Graph: Knowledge Graph-Based Tool and Agent Retrieval for LLM
 Multi-Agent Systems
Authors: Faheem Nizar and Elias Lumer and Anmol Gulati and Pradeep
 Honaganahalli Basavaraju and Vamse Kumar Subbiah
Categories: cs.CL
\\
 Recent advances in Large Language Model Multi-Agent Systems enable scalable
orchestration and retrieval of specialized, parallelized subagents, each
equipped with hundreds or thousands of Model Context Protocol (MCP) servers and
tools. However, existing agent, MCP, and retrieval methods typically match
queries against a single agent description, obscuring fine-grained tool
capabilities of each agent, resulting in suboptimal agent selection. We
introduce Agent-as-a-Graph retrieval, a knowledge graph retrieval augmented
generation approach that represents both tools and their parent agents as nodes
and edges in a knowledge graph. During retrieval, i) relevant agents and tool
nodes are first retrieved through vector search, ii) we apply a type-specific
weighted reciprocal rank fusion (wRRF) for reranking tools and agents, and iii)
parent agents are traversed in the knowledge graph for the final set of agents.
We evaluate Agent-as-a-Graph on the LiveMCPBenchmark, achieving 14.9% and 14.6%
improvements in Recall@5 and nDCG@5 over prior state-of-the-art retrievers, and
2.4% improvements in wRRF optimizations.
\\ ( https://arxiv.org/abs/2511.18194 ,  349kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18259
Date: Sun, 23 Nov 2025 03:17:26 GMT   (382kb)

Title: From Archives to Decisions: Multi-Agent Pharmaceutical Co-Scientist for
 Traceable Drug Discovery and Reverse Translation
Authors: Xiaochen Zheng, Alvaro Serra, Ilya Schneider Chernov, Maddalena
 Marchesi, Eunice Musvasva, Tatyana Y. Doktorova
Categories: cs.CL cs.MA
Comments: 22 pages, 4 figures, 3 tables
\\
 Pharmaceutical research and development has accumulated vast, heterogeneous
archives of data. Much of this knowledge stems from discontinued programs, and
reusing these archives is invaluable for reverse translation. However, in
practice, such reuse is often infeasible. In this work, we introduce
DiscoVerse, a multi-agent co-scientist designed to support pharmaceutical
research and development. The system implements semantic retrieval,
cross-document linking, and auditable synthesis on a large historical corpus
from Roche. To validate our approach at real-world scale, we selected a subset
of 180 molecules from the Roche research repositories, covering over 0.87
billion BPE tokens and more than four decades of research. Given that automated
evaluation metrics are poorly aligned with scientific utility, we evaluate the
performance of DiscoVerse using blinded expert evaluation of source-linked
outputs. To our knowledge, this is the first agentic framework systematically
assessed on real pharmaceutical data for reverse translation, enabled by
authorized access to confidential, end-to-end drug-development archives. Our
contributions include role-specialized agent designs aligned with scientist
workflows; human-in-the-loop support for reverse translation; expert
evaluation; and a large-scale demonstration showing promising answer accuracy
and decision-making insights. In brief, across seven benchmark queries covering
180 molecules, DiscoVerse achieved near-perfect recall ($\geq 0.99$) with
moderate precision ($0.71-0.91$), while qualitative assessments of
discontinuation rationale and organ-specific toxicity showed faithful,
source-linked synthesis across preclinical and clinical evidence.
\\ ( https://arxiv.org/abs/2511.18259 ,  382kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18301
Date: Sun, 23 Nov 2025 05:48:27 GMT   (24kb)

Title: "AGI" team at SHROOM-CAP: Data-Centric Approach to Multilingual
 Hallucination Detection using XLM-RoBERTa
Authors: Harsh Rathva, Pruthwik Mishra, Shrikant Malviya
Categories: cs.CL
Comments: Accepted to the 1st Workshop on Confabulation, Hallucinations &
 Overgeneration in Multilingual and Practical Settings (CHOMPS) at AACL-IJCNLP
 2025
ACM-class: I.2.7
\\
 The detection of hallucinations in multilingual scientific text generated by
Large Language Models (LLMs) presents significant challenges for reliable AI
systems. This paper describes our submission to the SHROOM-CAP 2025 shared task
on scientific hallucination detection across 9 languages. Unlike most
approaches that focus primarily on model architecture, we adopted a
data-centric strategy that addressed the critical issue of training data
scarcity and imbalance. We unify and balance five existing datasets to create a
comprehensive training corpus of 124,821 samples (50% correct, 50%
hallucinated), representing a 172x increase over the original SHROOM training
data. Our approach fine-tuned XLM-RoBERTa-Large with 560 million parameters on
this enhanced dataset, achieves competitive performance across all languages,
including \textbf{2nd place in Gujarati} (zero-shot language) with Factuality
F1 of 0.5107, and rankings between 4th-6th place across the remaining 8
languages. Our results demonstrate that systematic data curation can
significantly outperform architectural innovations alone, particularly for
low-resource languages in zero-shot settings.
\\ ( https://arxiv.org/abs/2511.18301 ,  24kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18306
Date: Sun, 23 Nov 2025 06:34:51 GMT   (1128kb)

Title: Table Comprehension in Building Codes using Vision Language Models and
 Domain-Specific Fine-Tuning
Authors: Mohammad Aqib, Mohd Hamza, Ying Hei Chui, Qipei Mei
Categories: cs.CL
\\
 Building codes contain critical information for ensuring safety, regulatory
compliance, and informed decision-making in construction and engineering.
Automated question answering systems over such codes enable quick and accurate
access to specific regulatory clauses, improving efficiency and reducing
errors. Retrieval-Augmented Generation (RAG) systems are essential for this
task as they combine the precision of information retrieval with the generative
capabilities of language models. However, tabular data are challenging to
extract as they often involve complex layouts, merged cells, multi-row headers,
and embedded semantic relationships that are not easily captured by traditional
natural language processing techniques and Vision Language Models (VLMs). This
paper explores and compares two methods for extracting information from tabular
data in building codes using several pre-trained VLMs. First, a direct input
method is used, where the image of the page is input directly into the VLMs,
which are then tasked with answering questions based on the image. Second, an
indirect input method is introduced, which involves converting an image of a
page containing tables into the LaTeX code and then answering inquires based on
the LaTeX-based input. The experiments find that the direct input method
generally resulted in higher accuracy than the indirect input method. To
further improve the performance, we fine-tuned each VLM using Low Rank
Adaptation (LoRA) on a domain-specific tabular dataset. The fine-tuned models
exhibited substantial improvements, with Qwen2.5-VL-3B-Instruct achieving
relative accuracy gains exceeding 100%. Our results highlight the potential of
parameter-efficient fine-tuning methods to adapt powerful VLMs for
understanding complex structured data in specialized fields, such as building
code interpretation and regulatory compliance.
\\ ( https://arxiv.org/abs/2511.18306 ,  1128kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18313
Date: Sun, 23 Nov 2025 06:50:01 GMT   (8kb)

Title: Path-Constrained Retrieval: A Structural Approach to Reliable LLM Agent
 Reasoning Through Graph-Scoped Semantic Search
Authors: Joseph Oladokun
Categories: cs.CL cs.DB cs.IR cs.LG
Comments: 10 pages
\\
 Large Language Model agents often retrieve context from knowledge bases that
lack structural consistency with the agent's current reasoning state, leading
to incoherent reasoning chains. We introduce Path-Constrained Retrieval (PCR),
a retrieval method that combines structural graph constraints with semantic
search to ensure retrieved information maintains logical relationships within a
knowledge graph. PCR restricts the search space to nodes reachable from an
anchor node, preventing retrieval of structurally disconnected information that
may lead to inconsistent reasoning. We evaluate PCR on PathRAG-6, a benchmark
spanning six domains with 180 nodes and 360 edges. Our results show that PCR
achieves full structural consistency compared to 24-32 percent in baseline
methods, while maintaining strong relevance scores. On the technology domain,
PCR obtains full relevance at rank 10 with full structural consistency,
significantly outperforming vector search and hybrid retrieval. PCR reduces the
average graph distance of retrieved context by 78 percent compared to
baselines, demonstrating retrieval of more structurally consistent information.
These findings suggest that path-constrained retrieval is an effective approach
for improving the reliability and coherence of LLM agent reasoning systems.
\\ ( https://arxiv.org/abs/2511.18313 ,  8kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18324
Date: Sun, 23 Nov 2025 07:29:09 GMT   (45kb)

Title: Gradient Masters at BLP-2025 Task 1: Advancing Low-Resource NLP for
 Bengali using Ensemble-Based Adversarial Training for Hate Speech Detection
Authors: Syed Mohaiminul Hoque, Naimur Rahman, Md Sakhawat Hossain
Categories: cs.CL
Comments: 6 pages, 2 figures, 4 tables. Accepted at the Second International
 Workshop on Bangla Language Processing (BLP-2025) co-located with AACL-IJCNLP
 2025. Ranked 6th (Subtask 1A, 73.23% micro F1) and 3rd (Subtask 1B, 73.28%
 micro F1) on the official leaderboard
\\
 This paper introduces the approach of "Gradient Masters" for BLP-2025 Task 1:
"Bangla Multitask Hate Speech Identification Shared Task". We present an
ensemble-based fine-tuning strategy for addressing subtasks 1A (hate-type
classification) and 1B (target group classification) in YouTube comments. We
propose a hybrid approach on a Bangla Language Model, which outperformed the
baseline models and secured the 6th position in subtask 1A with a micro F1
score of 73.23% and the third position in subtask 1B with 73.28%. We conducted
extensive experiments that evaluated the robustness of the model throughout the
development and evaluation phases, including comparisons with other Language
Model variants, to measure generalization in low-resource Bangla hate speech
scenarios and data set coverage. In addition, we provide a detailed analysis of
our findings, exploring misclassification patterns in the detection of hate
speech.
\\ ( https://arxiv.org/abs/2511.18324 ,  45kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18335
Date: Sun, 23 Nov 2025 08:18:12 GMT   (547kb)

Title: OmniStruct: Universal Text-to-Structure Generation across Diverse
 Schemas
Authors: James Y. Huang, Wenxuan Zhou, Nan Xu, Fei Wang, Qin Liu, Sheng Zhang,
 Hoifung Poon, Muhao Chen
Categories: cs.CL cs.AI cs.LG
\\
 The ability of Large Language Models (LLMs) to generate structured outputs
that follow arbitrary schemas is crucial to a wide range of downstream tasks
that require diverse structured representations of results such as information
extraction, table generation, and function calling. While modern LLMs excel in
generating unstructured responses in natural language, whether this advancement
translates to a strong performance on text-to-structure tasks remains unclear.
To bridge this gap, we first introduce OmniStruct, a comprehensive benchmark
for assessing LLMs' capabilities on diverse text-to-structure tasks such as
information extraction, table generation, and function calling. We build
OmniStruct by identifying existing datasets across a wide range of tasks that
are suitable for a structured answer format, and adapting them under a unified
text-to-structure problem setting. To facilitate the development of efficient
text-to-structure models, we collect high-quality training data via synthetic
task generation. Without using any supervised data for OmniStruct tasks, our
experiments demonstrate the possibility of fine-tuning much smaller models on
synthetic data into universal structured generation models that can rival the
performance of GPT-4o.
\\ ( https://arxiv.org/abs/2511.18335 ,  547kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18369
Date: Sun, 23 Nov 2025 09:28:16 GMT   (15041kb)

Title: Tu crois que c'est vrai ? Diversite des regimes d'enonciation face aux
 fake news et mecanismes d'autoregulation conversationnelle
Authors: Manon Berriche
Categories: cs.CL cs.CY cs.HC cs.MM
Comments: in French language
\\
 This thesis addresses two paradoxes: (1) why empirical studies find that fake
news represent only a small share of the information consulted and shared on
social media despite the absence of editorial control or journalistic norms,
and (2) how political polarization has intensified even though users do not
appear especially receptive to fake news. To investigate these issues, two
complementary studies were carried out on Twitter and Facebook, combining
quantitative analyses of digital traces with online observation and interviews.
This mixed-methods design avoids reducing users to single reactions to
identified fake items and instead examines the variety of practices across
different interactional situations, online and offline, while recording
socio-demographic traits. The first study mapped users who shared at least one
item labeled fake by fact-checkers in the French Twittersphere. The second used
a corpus of items flagged by Facebook users to study reactions to statements
whose epistemic status is uncertain. Three main findings emerge. First, sharing
fake news is concentrated among a limited group of users who are not less
educated or cognitively disadvantaged but are more politicized and critical of
institutions; owing to their high activity and prolific sharing, they can help
set the agenda for their political camp. Second, exposed users can deploy
varying forms of critical distance depending on their social position and the
interactional norms of the situations they inhabit: either discursive caution
(prudence \'enonciative) or interventions ('points d'arr\^et') that express
disagreement or corrections. Third, these forms of critical distance seldom
yield genuine deliberative debates or agonistic pluralism; rather, they often
produce dialogues of the deaf among a small, particularly active minority.
\\ ( https://arxiv.org/abs/2511.18369 ,  15041kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18393
Date: Sun, 23 Nov 2025 10:40:36 GMT   (363kb)

Title: Towards Robust and Fair Next Visit Diagnosis Prediction under Noisy
 Clinical Notes with Large Language Models
Authors: Heejoon Koo
Categories: cs.CL
Comments: Accepted by the Association for the Advancement of Artificial
 Intelligence (AAAI) 2026 1st Workshop on Safe, Ethical, Certified,
 Uncertainty-aware, Robust, and Explainable AI for Health (SECURE-AI4H)
\\
 A decade of rapid advances in artificial intelligence (AI) has opened new
opportunities for clinical decision support systems (CDSS), with large language
models (LLMs) demonstrating strong reasoning abilities on timely medical tasks.
However, clinical texts are often degraded by human errors or failures in
automated pipelines, raising concerns about the reliability and fairness of
AI-assisted decision-making. Yet the impact of such degradations remains
under-investigated, particularly regarding how noise-induced shifts can
heighten predictive uncertainty and unevenly affect demographic subgroups. We
present a systematic study of state-of-the-art LLMs under diverse text
corruption scenarios, focusing on robustness and equity in next-visit diagnosis
prediction. To address the challenge posed by the large diagnostic label space,
we introduce a clinically grounded label-reduction scheme and a hierarchical
chain-of-thought (CoT) strategy that emulates clinicians' reasoning. Our
approach improves robustness and reduces subgroup instability under degraded
inputs, advancing the reliable use of LLMs in CDSS. We release code at
https://github.com/heejkoo9/NECHOv3.
\\ ( https://arxiv.org/abs/2511.18393 ,  363kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18409
Date: Sun, 23 Nov 2025 11:33:59 GMT   (201kb)

Title: Findings of the BlackboxNLP 2025 Shared Task: Localizing Circuits and
 Causal Variables in Language Models
Authors: Dana Arad, Yonatan Belinkov, Hanjie Chen, Najoung Kim, Hosein Mohebbi,
 Aaron Mueller, Gabriele Sarti, Martin Tutek
Categories: cs.CL cs.AI
DOI: 10.18653/v1/2025.blackboxnlp-1.32
\\
 Mechanistic interpretability (MI) seeks to uncover how language models (LMs)
implement specific behaviors, yet measuring progress in MI remains challenging.
The recently released Mechanistic Interpretability Benchmark (MIB; Mueller et
al., 2025) provides a standardized framework for evaluating circuit and causal
variable localization. Building on this foundation, the BlackboxNLP 2025 Shared
Task extends MIB into a community-wide reproducible comparison of MI
techniques. The shared task features two tracks: circuit localization, which
assesses methods that identify causally influential components and interactions
driving model behavior, and causal variable localization, which evaluates
approaches that map activations into interpretable features. With three teams
spanning eight different methods, participants achieved notable gains in
circuit localization using ensemble and regularization strategies for circuit
discovery. With one team spanning two methods, participants achieved
significant gains in causal variable localization using low-dimensional and
non-linear projections to featurize activation vectors. The MIB leaderboard
remains open; we encourage continued work in this standard evaluation framework
to measure progress in MI research going forward.
\\ ( https://arxiv.org/abs/2511.18409 ,  201kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18411
Date: Sun, 23 Nov 2025 11:53:30 GMT   (7673kb)

Title: SmolKalam: Ensemble Quality-Filtered Translation at Scale for High
 Quality Arabic Post-Training Data
Authors: Sultan Alrashed, Chadi Helwe, Francesco Orabona
Categories: cs.CL cs.AI
Comments: Work in progress
\\
 Although the community has tackled the acquisition of high-quality Arabic
pretraining data, we still lack large-scale, multi-turn Arabic datasets that
include reasoning and tool calling. Naive translation can work at the
pretraining scale, but post-training demands much higher quality, which
requires a stricter approach to dataset curation. In this work, we introduce
SmolKalam, a translation of Smoltalk2 that uses a multi-model ensemble
translation pipeline, applies quality filtering, and examines effective
translation techniques for traditional decoder-only models through ablations.
\\ ( https://arxiv.org/abs/2511.18411 ,  7673kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18413
Date: Sun, 23 Nov 2025 11:57:10 GMT   (405kb)

Title: Multi-Agent Collaborative Filtering: Orchestrating Users and Items for
 Agentic Recommendations
Authors: Yu Xia, Sungchul Kim, Tong Yu, Ryan A. Rossi, Julian McAuely
Categories: cs.CL cs.IR
\\
 Agentic recommendations cast recommenders as large language model (LLM)
agents that can plan, reason, use tools, and interact with users of varying
preferences in web applications. However, most existing agentic recommender
systems focus on generic single-agent plan-execute workflows or multi-agent
task decomposition pipelines. Without recommendation-oriented design, they
often underuse the collaborative signals in the user-item interaction history,
leading to unsatisfying recommendation results. To address this, we propose the
Multi-Agent Collaborative Filtering (MACF) framework for agentic
recommendations, drawing an analogy between traditional collaborative filtering
algorithms and LLM-based multi-agent collaboration. Specifically, given a
target user and query, we instantiate similar users and relevant items as LLM
agents with unique profiles. Each agent is able to call retrieval tools,
suggest candidate items, and interact with other agents. Different from the
static preference aggregation in traditional collaborative filtering, MACF
employs a central orchestrator agent to adaptively manage the collaboration
between user and item agents via dynamic agent recruitment and personalized
collaboration instruction. Experimental results on datasets from three
different domains show the advantages of our MACF framework compared to strong
agentic recommendation baselines.
\\ ( https://arxiv.org/abs/2511.18413 ,  405kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18423
Date: Sun, 23 Nov 2025 12:29:33 GMT   (1163kb)

Title: General Agentic Memory Via Deep Research
Authors: B.Y. Yan and Chaofan Li and Hongjin Qian and Shuqi Lu and Zheng Liu
Categories: cs.CL cs.AI cs.IR cs.LG
\\
 Memory is critical for AI agents, yet the widely-adopted static memory,
aiming to create readily available memory in advance, is inevitably subject to
severe information loss. To address this limitation, we propose a novel
framework called \textbf{general agentic memory (GAM)}. GAM follows the
principle of "\textbf{just-in time (JIT) compilation}" where it focuses on
creating optimized contexts for its client at runtime while keeping only simple
but useful memory during the offline stage. To this end, GAM employs a
duo-design with the following components. 1) \textbf{Memorizer}, which
highlights key historical information using a lightweight memory, while
maintaining complete historical information within a universal page-store. 2)
\textbf{Researcher}, which retrieves and integrates useful information from the
page-store for its online request guided by the pre-constructed memory. This
design allows GAM to effectively leverage the agentic capabilities and
test-time scalability of frontier large language models (LLMs), while also
facilitating end-to-end performance optimization through reinforcement
learning. In our experimental study, we demonstrate that GAM achieves
substantial improvement on various memory-grounded task completion scenarios
against existing memory systems.
\\ ( https://arxiv.org/abs/2511.18423 ,  1163kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18491
Date: Sun, 23 Nov 2025 15:19:29 GMT   (9405kb)

Title: MindEval: Benchmarking Language Models on Multi-turn Mental Health
 Support
Authors: Jos\'e Pombal, Maya D'Eon, Nuno M. Guerreiro, Pedro Henrique Martins,
 Ant\'onio Farinhas, Ricardo Rei
Categories: cs.CL cs.AI
\\
 Demand for mental health support through AI chatbots is surging, though
current systems present several limitations, like sycophancy or overvalidation,
and reinforcement of maladaptive beliefs. A core obstacle to the creation of
better systems is the scarcity of benchmarks that capture the complexity of
real therapeutic interactions. Most existing benchmarks either only test
clinical knowledge through multiple-choice questions or assess single responses
in isolation. To bridge this gap, we present MindEval, a framework designed in
collaboration with Ph.D-level Licensed Clinical Psychologists for automatically
evaluating language models in realistic, multi-turn mental health therapy
conversations. Through patient simulation and automatic evaluation with LLMs,
our framework balances resistance to gaming with reproducibility via its fully
automated, model-agnostic design. We begin by quantitatively validating the
realism of our simulated patients against human-generated text and by
demonstrating strong correlations between automatic and human expert judgments.
Then, we evaluate 12 state-of-the-art LLMs and show that all models struggle,
scoring below 4 out of 6, on average, with particular weaknesses in problematic
AI-specific patterns of communication. Notably, reasoning capabilities and
model scale do not guarantee better performance, and systems deteriorate with
longer interactions or when supporting patients with severe symptoms. We
release all code, prompts, and human evaluation data.
\\ ( https://arxiv.org/abs/2511.18491 ,  9405kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18499
Date: Sun, 23 Nov 2025 15:31:03 GMT   (25kb)

Title: For Those Who May Find Themselves on the Red Team
Authors: Tyler Shoemaker
Categories: cs.CL
\\
 This position paper argues that literary scholars must engage with large
language model (LLM) interpretability research. While doing so will involve
ideological struggle, if not out-right complicity, the necessity of this
engagement is clear: the abiding instrumentality of current approaches to
interpretability cannot be the only standard by which we measure interpretation
with LLMs. One site at which this struggle could take place, I suggest, is the
red team.
\\ ( https://arxiv.org/abs/2511.18499 ,  25kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18557
Date: Sun, 23 Nov 2025 18:08:36 GMT   (493kb)

Title: Dealing with the Hard Facts of Low-Resource African NLP
Authors: Yacouba Diarra, Nouhoum Souleymane Coulibaly, Panga Azazia Kamat\'e,
 Madani Amadou Tall, Emmanuel \'Elis\'e Kon\'e, Aymane Demb\'el\'e, Michael
 Leventhal
Categories: cs.CL
Comments: 10 pages, 4 figures
\\
 Creating speech datasets, models, and evaluation frameworks for low-resource
languages remains challenging given the lack of a broad base of pertinent
experience to draw from. This paper reports on the field collection of 612
hours of spontaneous speech in Bambara, a low-resource West African language;
the semi-automated annotation of that dataset with transcriptions; the creation
of several monolingual ultra-compact and small models using the dataset; and
the automatic and human evaluation of their output. We offer practical
suggestions for data collection protocols, annotation, and model design, as
well as evidence for the importance of performing human evaluation. In addition
to the main dataset, multiple evaluation datasets, models, and code are made
publicly available.
\\ ( https://arxiv.org/abs/2511.18557 ,  493kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18597
Date: Sun, 23 Nov 2025 19:39:44 GMT   (100kb)

Title: Toward Trustworthy Difficulty Assessments: Large Language Models as
 Judges in Programming and Synthetic Tasks
Authors: H.M. Shadman Tabib, Jaber Ahmed Deedar
Categories: cs.CL
\\
 Large Language Models (LLMs) have demonstrated impressive capabilities in
natural language and code generation, and are increasingly deployed as
automatic judges of model outputs and learning activities. Yet, their behavior
on structured tasks such as predicting the difficulty of competitive
programming problems remains under-explored. We conduct a systematic comparison
of GPT-4o, used purely as a natural-language difficulty assessor, against an
interpretable Light-GBM ensemble trained on explicit numeric and textual
features. On a dataset of 1,825 LeetCode problems labeled Easy, Medium, or
Hard, LightGBM attains 86% accuracy, whereas GPT-4o reaches only 37.75%.
Detailed analyses, including confusion matrices and SHAP-based
interpretability, show that numeric constraints -- such as input size limits
and acceptance rates -- play a crucial role in separating Hard problems from
easier ones. By contrast, GPT-4o often overlooks these cues and exhibits a
strong bias toward simpler categories. We further probe GPT-4o through a
synthetic Hard-problem generation protocol. Surprisingly, GPT-4o labels almost
all of its own synthetic Hard problems as Medium, contradicting its tendency to
downgrade real Hard problems to Easy. Our findings connect to recent work on
LLMs-as-judges and automatic difficulty estimation in programming and
education, and highlight concrete failure modes that must be addressed before
LLM-based judges can be considered trustworthy in competitive programming,
educational platforms, or reinforcement-learning pipelines.
\\ ( https://arxiv.org/abs/2511.18597 ,  100kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18616
Date: Sun, 23 Nov 2025 21:13:20 GMT   (2882kb)

Title: A Benchmark for Zero-Shot Belief Inference in Large Language Models
Authors: Joseph Malone, Rachith Aiyappa, Byunghwee Lee, Haewoon Kwak, Jisun An,
 Yong-Yeol Ahn
Categories: cs.CL
Comments: 28 pages, 5 figures
\\
 Beliefs are central to how humans reason, communicate, and form social
connections, yet most computational approaches to studying them remain confined
to narrow sociopolitical contexts and rely on fine-tuning for optimal
performance. Despite the growing use of large language models (LLMs) across
disciplines, how well these systems generalize across diverse belief domains
remains unclear. We introduce a systematic, reproducible benchmark that
evaluates the ability of LLMs to predict individuals' stances on a wide range
of topics in a zero-shot setting using data from an online debate platform. The
benchmark includes multiple informational conditions that isolate the
contribution of demographic context and known prior beliefs to predictive
success. Across several small- to medium-sized models, we find that providing
more background information about an individual improves predictive accuracy,
but performance varies substantially across belief domains. These findings
reveal both the capacity and limitations of current LLMs to emulate human
reasoning, advancing the study of machine behavior and offering a scalable
framework for modeling belief systems beyond the sociopolitical sphere.
\\ ( https://arxiv.org/abs/2511.18616 ,  2882kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18618
Date: Sun, 23 Nov 2025 21:22:56 GMT   (622kb)

Title: A Unified BERT-CNN-BiLSTM Framework for Simultaneous Headline
 Classification and Sentiment Analysis of Bangla News
Authors: Mirza Raquib, Munazer Montasir Akash, Tawhid Ahmed, Saydul Akbar
 Murad, Farida Siddiqi Prity, Mohammad Amzad Hossain, Asif Pervez Polok, Nick
 Rahimi
Categories: cs.CL cs.AI
\\
 In our daily lives, newspapers are an essential information source that
impacts how the public talks about present-day issues. However, effectively
navigating the vast amount of news content from different newspapers and online
news portals can be challenging. Newspaper headlines with sentiment analysis
tell us what the news is about (e.g., politics, sports) and how the news makes
us feel (positive, negative, neutral). This helps us quickly understand the
emotional tone of the news. This research presents a state-of-the-art approach
to Bangla news headline classification combined with sentiment analysis
applying Natural Language Processing (NLP) techniques, particularly the hybrid
transfer learning model BERT-CNN-BiLSTM. We have explored a dataset called
BAN-ABSA of 9014 news headlines, which is the first time that has been
experimented with simultaneously in the headline and sentiment categorization
in Bengali newspapers. Over this imbalanced dataset, we applied two
experimental strategies: technique-1, where undersampling and oversampling are
applied before splitting, and technique-2, where undersampling and oversampling
are applied after splitting on the In technique-1 oversampling provided the
strongest performance, both headline and sentiment, that is 78.57\% and 73.43\%
respectively, while technique-2 delivered the highest result when trained
directly on the original imbalanced dataset, both headline and sentiment, that
is 81.37\% and 64.46\% respectively. The proposed model BERT-CNN-BiLSTM
significantly outperforms all baseline models in classification tasks, and
achieves new state-of-the-art results for Bangla news headline classification
and sentiment analysis. These results demonstrate the importance of leveraging
both the headline and sentiment datasets, and provide a strong baseline for
Bangla text classification in low-resource.
\\ ( https://arxiv.org/abs/2511.18618 ,  622kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18619
Date: Sun, 23 Nov 2025 21:24:13 GMT   (16kb)

Title: Prompt Optimization as a State-Space Search Problem
Authors: Maanas Taneja
Categories: cs.CL
\\
 Language Models are extremely susceptible to performance collapse with even
small changes to input prompt strings. Libraries such as DSpy (from Stanford
NLP) avoid this problem through demonstration-based prompt optimisation.
Inspired by this, I propose an alternative approach that treats prompt
optimisation as a classical state-space search problem. I model the prompt
space as a graph where nodes represent prompt states and edges correspond to
deliberate transformations such as shortening, adding examples, or re- ordering
content. Using beam search and random walk algorithms, I systematically explore
this space, evaluating candidates on development sets and pruning unpromising
branches. Across five NLP tasks (sentiment classification, question answering,
summarisation, reason- ing, and natural language inference), I find that even
shallow search configurations (beam width=2, depth=2) improve upon seed prompts
on development sets. For instance, beam search achieves development accuracy
gains from 0.40 to 0.80 on reasoning tasks, though test set improvements are
more modest (0.20 to 0.50), indicating overfitting to the develop- ment
heuristic. Analysis of successful optimisation paths reveals that
transformations that make prompts concise appear most frequently, while
verbosity operators are never selected. My results validate prompt optimization
as a search problem and suggest that with greater computational resources and
improved evaluation metrics, deeper exploration could yield more robust prompts
that generalize beyond development sets. Code and implementation are available
at [https://github.com/MaanasTaneja/PromptOptimiser].
\\ ( https://arxiv.org/abs/2511.18619 ,  16kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18622
Date: Sun, 23 Nov 2025 21:33:53 GMT   (54kb)

Title: OpenGloss: A Synthetic Encyclopedic Dictionary and Semantic Knowledge
 Graph
Authors: Michael J. Bommarito II
Categories: cs.CL cs.AI
Comments: 30 pages, 5 figures, 8 tables. Dataset available at
 https://huggingface.co/datasets/mjbommar/opengloss-dictionary
ACM-class: I.2.7; H.3.1; I.2.4
\\
 We present OpenGloss, a synthetic encyclopedic dictionary and semantic
knowledge graph for English that integrates lexicographic definitions,
encyclopedic context, etymological histories, and semantic relationships in a
unified resource. OpenGloss contains 537K senses across 150K lexemes, on par
with WordNet 3.1 and Open English WordNet, while providing more than four times
as many sense definitions. These lexemes include 9.1M semantic edges, 1M usage
examples, 3M collocations, and 60M words of encyclopedic content.
 Generated through a multi-agent procedural generation pipeline with
schema-validated LLM outputs and automated quality assurance, the entire
resource was produced in under one week for under $1,000. This demonstrates
that structured generation can create comprehensive lexical resources at cost
and time scales impractical for manual curation, enabling rapid iteration as
foundation models improve. The resource addresses gaps in pedagogical
applications by providing integrated content -- definitions, examples,
collocations, encyclopedias, etymology -- that supports both vocabulary
learning and natural language processing tasks.
 As a synthetically generated resource, OpenGloss reflects both the
capabilities and limitations of current foundation models. The dataset is
publicly available on Hugging Face under CC-BY 4.0, enabling researchers and
educators to build upon and adapt this resource.
\\ ( https://arxiv.org/abs/2511.18622 ,  54kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18635
Date: Sun, 23 Nov 2025 22:21:18 GMT   (1200kb)

Title: No Free Lunch in Language Model Bias Mitigation? Targeted Bias Reduction
 Can Exacerbate Unmitigated LLM Biases
Authors: Shireen Chand, Faith Baca, Emilio Ferrara
Categories: cs.CL cs.AI cs.CY
\\
 Large Language Models (LLMs) inherit societal biases from their training
data, potentially leading to harmful or unfair outputs. While various
techniques aim to mitigate these biases, their effects are often evaluated only
along the dimension of the bias being targeted. This work investigates the
cross-category consequences of targeted bias mitigation. We study four bias
mitigation techniques applied across ten models from seven model families, and
we explore racial, religious, profession- and gender-related biases. We measure
the impact of debiasing on model coherence and stereotypical preference using
the StereoSet benchmark. Our results consistently show that while targeted
mitigation can sometimes reduce bias in the intended dimension, it frequently
leads to unintended and often negative consequences in others, such as
increasing model bias and decreasing general coherence. These findings
underscore the critical need for robust, multi-dimensional evaluation tools
when examining and developing bias mitigation strategies to avoid inadvertently
shifting or worsening bias along untargeted axes.
\\ ( https://arxiv.org/abs/2511.18635 ,  1200kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18649
Date: Sun, 23 Nov 2025 23:09:33 GMT   (2793kb)

Title: Evaluating Large Language Models on the 2026 Korean CSAT Mathematics
 Exam: Measuring Mathematical Ability in a Zero-Data-Leakage Setting
Authors: Goun Pyeon, Inbum Heo, Jeesu Jung, Taewook Hwang, Hyuk Namgoong, Hyein
 Seo, Yerim Han, Eunbin Kim, Hyeonseok Kang, Sangkeun Jung
Categories: cs.CL
Comments: 52 pages, Korean
\\
 This study systematically evaluated the mathematical reasoning capabilities
of Large Language Models (LLMs) using the 2026 Korean College Scholastic
Ability Test (CSAT) Mathematics section, ensuring a completely
contamination-free evaluation environment. To address data leakage issues in
existing benchmarks, we digitized all 46 questions (22 common and 24 elective)
within two hours of the exam's public release, eliminating any possibility of
inclusion in model training data. We conducted comprehensive evaluations of 24
state-of-the-art LLMs across varying input modalities (text, image,
text+figure) and prompt languages (Korean, English).
 GPT-5 Codex achieved the only perfect score (100 points) with text input and
Korean prompts, while Grok 4, GPT-5, and Deepseek R1 scored above 95 points.
Notably, gpt-oss-20B achieved 95.7 points despite its relatively small size,
demonstrating high cost-effectiveness. Problem-specific analysis revealed
geometry as the weakest domain (77.7% average) with significant performance
degradation on 4-point high-difficulty problems. Text input consistently
outperformed image input, while prompt language effects varied by model scale.
 In reasoning enhancement experiments with GPT-5 series, increased reasoning
intensity improved performance (from 82.6 to 100 points) but quadrupled token
usage and drastically reduced efficiency, suggesting that models with minimal
reasoning may be more practical. This research contributes: (1) implementation
of a completely unexposed evaluation environment, (2) a real-exam-based LLM
assessment framework, and (3) a practical evaluation perspective integrating
performance, cost, and time considerations. Detailed results and model
comparisons are available at the 2026 Korean CSAT LLM Evaluation Leaderboard
(https://isoft.cnu.ac.kr/csat2026/).
\\ ( https://arxiv.org/abs/2511.18649 ,  2793kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18659
Date: Mon, 24 Nov 2025 00:11:14 GMT   (20087kb)

Title: CLaRa: Bridging Retrieval and Generation with Continuous Latent
 Reasoning
Authors: Jie He, Richard He Bai, Sinead Williamson, Jeff Z. Pan, Navdeep
 Jaitly, Yizhe Zhang
Categories: cs.CL
\\
 Retrieval-augmented generation (RAG) enhances large language models (LLMs)
with external knowledge but still suffers from long contexts and disjoint
retrieval-generation optimization. In this work, we propose CLaRa (Continuous
Latent Reasoning), a unified framework that performs embedding-based
compression and joint optimization in a shared continuous space. To obtain
semantically rich and retrievable compressed vectors, we introduce SCP, a
key-preserving data synthesis framework using QA and paraphrase supervision.
CLaRa then trains the reranker and generator end-to-end via a single language
modeling loss, with gradients flowing through both modules using a
differentiable top-k estimator. Theoretically, this unified optimization aligns
retrieval relevance with answer quality. Experiments across multiple QA
benchmarks show that CLaRa achieves state-of-the-art compression and reranking
performance, often surpassing text-based fine-tuned baselines.
\\ ( https://arxiv.org/abs/2511.18659 ,  20087kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18696
Date: Mon, 24 Nov 2025 02:32:20 GMT   (145kb)

Title: Empathetic Cascading Networks: A Multi-Stage Prompting Technique for
 Reducing Social Biases in Large Language Models
Authors: Wangjiaxuan Xin
Categories: cs.CL cs.AI
\\
 This report presents the Empathetic Cascading Networks (ECN) framework, a
multi-stage prompting method designed to enhance the empathetic and inclusive
capabilities of large language models. ECN employs four stages: Perspective
Adoption, Emotional Resonance, Reflective Understanding, and Integrative
Synthesis, to guide models toward generating emotionally resonant and
contextually aware responses. Experimental results demonstrate that ECN
achieves the highest Empathy Quotient (EQ) scores across GPT-3.5-turbo and
GPT-4, while maintaining competitive Regard and Perplexity metrics. These
findings emphasize ECN's potential for applications requiring empathy and
inclusivity in conversational AI.
\\ ( https://arxiv.org/abs/2511.18696 ,  145kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18743
Date: Mon, 24 Nov 2025 04:12:41 GMT   (1273kb)

Title: RhinoInsight: Improving Deep Research through Control Mechanisms for
 Model Behavior and Context
Authors: Yu Lei, Shuzheng Si, Wei Wang, Yifei Wu, Gang Chen, Fanchao Qi,
 Maosong Sun
Categories: cs.CL cs.AI
\\
 Large language models are evolving from single-turn responders into
tool-using agents capable of sustained reasoning and decision-making for deep
research. Prevailing systems adopt a linear pipeline of plan to search to write
to a report, which suffers from error accumulation and context rot due to the
lack of explicit control over both model behavior and context. We introduce
RhinoInsight, a deep research framework that adds two control mechanisms to
enhance robustness, traceability, and overall quality without parameter
updates. First, a Verifiable Checklist module transforms user requirements into
traceable and verifiable sub-goals, incorporates human or LLM critics for
refinement, and compiles a hierarchical outline to anchor subsequent actions
and prevent non-executable planning. Second, an Evidence Audit module
structures search content, iteratively updates the outline, and prunes noisy
context, while a critic ranks and binds high-quality evidence to drafted
content to ensure verifiability and reduce hallucinations. Our experiments
demonstrate that RhinoInsight achieves state-of-the-art performance on deep
research tasks while remaining competitive on deep search tasks.
\\ ( https://arxiv.org/abs/2511.18743 ,  1273kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18749
Date: Mon, 24 Nov 2025 04:22:32 GMT   (479kb)

Title: Large Language Models Require Curated Context for Reliable Political
 Fact-Checking -- Even with Reasoning and Web Search
Authors: Matthew R. DeVerna, Kai-Cheng Yang, Harry Yaojun Yan, Filippo Menczer
Categories: cs.CL cs.CY cs.IR
\\
 Large language models (LLMs) have raised hopes for automated end-to-end
fact-checking, but prior studies report mixed results. As mainstream chatbots
increasingly ship with reasoning capabilities and web search tools -- and
millions of users already rely on them for verification -- rigorous evaluation
is urgent. We evaluate 15 recent LLMs from OpenAI, Google, Meta, and DeepSeek
on more than 6,000 claims fact-checked by PolitiFact, comparing standard models
with reasoning- and web-search variants. Standard models perform poorly,
reasoning offers minimal benefits, and web search provides only moderate gains,
despite fact-checks being available on the web. In contrast, a curated RAG
system using PolitiFact summaries improved macro F1 by 233% on average across
model variants. These findings suggest that giving models access to curated
high-quality context is a promising path for automated fact-checking.
\\ ( https://arxiv.org/abs/2511.18749 ,  479kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18751
Date: Mon, 24 Nov 2025 04:24:33 GMT   (1484kb)

Title: Robust Multimodal Sentiment Analysis with Distribution-Based Feature
 Recovery and Fusion
Authors: Daiqing Wu, Dongbao Yang, Can Ma, Yu Zhou
Categories: cs.CL
Comments: Accepted by ACM MM 2024
DOI: 10.1145/3664647.3680653
\\
 As posts on social media increase rapidly, analyzing the sentiments embedded
in image-text pairs has become a popular research topic in recent years.
Although existing works achieve impressive accomplishments in simultaneously
harnessing image and text information, they lack the considerations of possible
low-quality and missing modalities. In real-world applications, these issues
might frequently occur, leading to urgent needs for models capable of
predicting sentiment robustly. Therefore, we propose a Distribution-based
feature Recovery and Fusion (DRF) method for robust multimodal sentiment
analysis of image-text pairs. Specifically, we maintain a feature queue for
each modality to approximate their feature distributions, through which we can
simultaneously handle low-quality and missing modalities in a unified
framework. For low-quality modalities, we reduce their contributions to the
fusion by quantitatively estimating modality qualities based on the
distributions. For missing modalities, we build inter-modal mapping
relationships supervised by samples and distributions, thereby recovering the
missing modalities from available ones. In experiments, two disruption
strategies that corrupt and discard some modalities in samples are adopted to
mimic the low-quality and missing modalities in various real-world scenarios.
Through comprehensive experiments on three publicly available image-text
datasets, we demonstrate the universal improvements of DRF compared to SOTA
methods under both two strategies, validating its effectiveness in robust
multimodal sentiment analysis.
\\ ( https://arxiv.org/abs/2511.18751 ,  1484kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18774
Date: Mon, 24 Nov 2025 05:16:04 GMT   (430kb)

Title: Context-Aware Whisper for Arabic ASR Under Linguistic Varieties
Authors: Bashar Talafha, Amin Abu Alhassan, Muhammad Abdul-Mageed
Categories: cs.CL
\\
 Low-resource ASR remains a challenging problem, especially for languages like
Arabic that exhibit wide dialectal variation and limited labeled data. We
propose context-aware prompting strategies to adapt OpenAI's Whisper for Arabic
speech recognition without retraining. Our methods include decoder prompting
with first-pass transcriptions or retrieved utterances, and encoder prefixing
using speech synthesized in the target speaker's voice. We introduce techniques
such as prompt reordering, speaker-aware prefix synthesis, and
modality-specific retrieval (lexical, semantic, acoustic) to improve
transcription in real-world, zero-shot settings. Evaluated on nine Arabic
linguistic conditions, our approach reduces WER by up to 22.3% on Modern
Standard Arabic and 9.2% on dialectal speech, significantly mitigating
hallucinations and speaker mismatch.
\\ ( https://arxiv.org/abs/2511.18774 ,  430kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18808
Date: Mon, 24 Nov 2025 06:27:58 GMT   (1591kb)

Title: HyperbolicRAG: Enhancing Retrieval-Augmented Generation with Hyperbolic
 Representations
Authors: Cao Linxiao, Wang Ruitao, Li Jindong, Zhou Zhipeng and Yang Menglin
Categories: cs.CL cs.AI
Comments: 12 pages
\\
 Retrieval-augmented generation (RAG) enables large language models (LLMs) to
access external knowledge, helping mitigate hallucinations and enhance
domain-specific expertise. Graph-based RAG enhances structural reasoning by
introducing explicit relational organization that enables information
propagation across semantically connected text units. However, these methods
typically rely on Euclidean embeddings that capture semantic similarity but
lack a geometric notion of hierarchical depth, limiting their ability to
represent abstraction relationships inherent in complex knowledge graphs. To
capture both fine-grained semantics and global hierarchy, we propose
HyperbolicRAG, a retrieval framework that integrates hyperbolic geometry into
graph-based RAG. HyperbolicRAG introduces three key designs: (1) a depth-aware
representation learner that embeds nodes within a shared Poincare manifold to
align semantic similarity with hierarchical containment, (2) an unsupervised
contrastive regularization that enforces geometric consistency across
abstraction levels, and (3) a mutual-ranking fusion mechanism that jointly
exploits retrieval signals from Euclidean and hyperbolic spaces, emphasizing
cross-space agreement during inference. Extensive experiments across multiple
QA benchmarks demonstrate that HyperbolicRAG outperforms competitive baselines,
including both standard RAG and graph-augmented baselines.
\\ ( https://arxiv.org/abs/2511.18808 ,  1591kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18832
Date: Mon, 24 Nov 2025 07:08:02 GMT   (2125kb)

Title: Concept than Document: Context Compression via AMR-based Conceptual
 Entropy
Authors: Kaize Shi, Xueyao Sun, Xiaohui Tao, Lin Li, Qika Lin, Guandong Xu
Categories: cs.CL
\\
 Large Language Models (LLMs) face information overload when handling long
contexts, particularly in Retrieval-Augmented Generation (RAG) where extensive
supporting documents often introduce redundant content. This issue not only
weakens reasoning accuracy but also increases computational overhead. We
propose an unsupervised context compression framework that exploits Abstract
Meaning Representation (AMR) graphs to preserve semantically essential
information while filtering out irrelevant text. By quantifying node-level
entropy within AMR graphs, our method estimates the conceptual importance of
each node, enabling the retention of core semantics. Specifically, we construct
AMR graphs from raw contexts, compute the conceptual entropy of each node, and
screen significant informative nodes to form a condensed and semantically
focused context than raw documents. Experiments on the PopQA and
EntityQuestions datasets show that our method outperforms vanilla and other
baselines, achieving higher accuracy while substantially reducing context
length. To the best of our knowledge, this is the first work introducing
AMR-based conceptual entropy for context compression, demonstrating the
potential of stable linguistic features in context engineering.
\\ ( https://arxiv.org/abs/2511.18832 ,  2125kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18843
Date: Mon, 24 Nov 2025 07:30:15 GMT   (1137kb)

Title: A Reproducible Framework for Neural Topic Modeling in Focus Group
 Analysis
Authors: Heger Arfaoui, Mohammed Iheb Hergli, Beya Benzina, Slimane BenMiled
Categories: cs.CL cs.HC cs.LG
\\
 Focus group discussions generate rich qualitative data but their analysis
traditionally relies on labor-intensive manual coding that limits scalability
and reproducibility. We present a rigorous, reproducible computational
framework for applying neural topic modeling to focus group transcripts,
addressing fundamental methodological challenges: hyperparameter sensitivity,
model stability, and validation of interpretability. Using BERTopic applied to
ten focus groups exploring HPV vaccine perceptions in Tunisia (1,076
utterances), we conducted systematic evaluation across 27 hyperparameter
configurations, assessed stability through bootstrap resampling with 30
replicates per configuration, and validated interpretability through formal
human evaluation by three domain experts. Our analysis demonstrates substantial
sensitivity to hyperparameter choices and reveals that metric selection for
stability assessment must align with analytical goals. A hierarchical merging
strategy (extracting fine-grained topics for stability then consolidating for
interpretability) effectively navigates the stability-coherence tradeoff,
achieving coherence of 0.558 compared to 0.539 for direct extraction. Human
validation confirmed topic quality with very good inter-rater reliability (ICC
= 0.79, weighted Cohen's kappa = 0.578). Our framework provides practical
guidelines that researchers can adapt to their own qualitative research
contexts. All code, data processing scripts, and evaluation protocols are
publicly available to support reproduction and extension of this work.
\\ ( https://arxiv.org/abs/2511.18843 ,  1137kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18848
Date: Mon, 24 Nov 2025 07:40:31 GMT   (40kb)

Title: Large Language Models for the Summarization of Czech Documents: From
 History to the Present
Authors: V\'aclav Tran, Jakub \v{S}m\'id, Ladislav Lenc, Jean-Pierre Salmon,
 and Pavel Kr\'al
Categories: cs.CL
\\
 Text summarization is the task of automatically condensing longer texts into
shorter, coherent summaries while preserving the original meaning and key
information. Although this task has been extensively studied in English and
other high-resource languages, Czech summarization, particularly in the context
of historical documents, remains underexplored. This is largely due to the
inherent linguistic complexity of Czech and the lack of high-quality annotated
datasets.
 In this work, we address this gap by leveraging the capabilities of Large
Language Models (LLMs), specifically Mistral and mT5, which have demonstrated
strong performance across a wide range of natural language processing tasks and
multilingual settings. In addition, we also propose a translation-based
approach that first translates Czech texts into English, summarizes them using
an English-language model, and then translates the summaries back into Czech.
Our study makes the following main contributions: We demonstrate that LLMs
achieve new state-of-the-art results on the SumeCzech dataset, a benchmark for
modern Czech text summarization, showing the effectiveness of multilingual LLMs
even for morphologically rich, medium-resource languages like Czech. We
introduce a new dataset, Posel od \v{C}erchova, designed for the summarization
of historical Czech texts. This dataset is derived from digitized 19th-century
publications and annotated for abstractive summarization. We provide initial
baselines using modern LLMs to facilitate further research in this
underrepresented area.
 By combining cutting-edge models with both modern and historical Czech
datasets, our work lays the foundation for further progress in Czech
summarization and contributes valuable resources for future research in Czech
historical document processing and low-resource summarization more broadly.
\\ ( https://arxiv.org/abs/2511.18848 ,  40kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18850
Date: Mon, 24 Nov 2025 07:45:59 GMT   (585kb)

Title: Cognitive Alpha Mining via LLM-Driven Code-Based Evolution
Authors: Fengyuan Liu, Huang Yi, Sichun Luo, Yuqi Wang, Yazheng Yang, Xinye Li,
 Zefa Hu, Junlan Feng, Qi Liu
Categories: cs.CL
\\
 Discovering effective predictive signals, or ``alphas,'' from financial data
with high dimensionality and extremely low signal-to-noise ratio remains a
difficult open problem. Despite progress in deep learning, genetic programming,
and, more recently, large language model (LLM)--based factor generation,
existing approaches still explore only a narrow region of the vast alpha search
space. Neural models tend to produce opaque and fragile patterns, while
symbolic or formula-based methods often yield redundant or economically
ungrounded expressions that generalize poorly. Although different in form,
these paradigms share a key limitation: none can conduct broad, structured, and
human-like exploration that balances logical consistency with creative leaps.
To address this gap, we introduce the Cognitive Alpha Mining Framework
(CogAlpha), which combines code-level alpha representation with LLM-driven
reasoning and evolutionary search. Treating LLMs as adaptive cognitive agents,
our framework iteratively refines, mutates, and recombines alpha candidates
through multi-stage prompts and financial feedback. This synergistic design
enables deeper thinking, richer structural diversity, and economically
interpretable alpha discovery, while greatly expanding the effective search
space. Experiments on A-share equities demonstrate that CogAlpha consistently
discovers alphas with superior predictive accuracy, robustness, and
generalization over existing methods. Our results highlight the promise of
aligning evolutionary optimization with LLM-based reasoning for automated and
explainable alpha discovery. All source code will be released.
\\ ( https://arxiv.org/abs/2511.18850 ,  585kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18852
Date: Mon, 24 Nov 2025 07:48:35 GMT   (418kb)

Title: FanarGuard: A Culturally-Aware Moderation Filter for Arabic Language
 Models
Authors: Masoomali Fatehkia, Enes Altinisik, Husrev Taha Sencar
Categories: cs.CL
\\
 Content moderation filters are a critical safeguard against alignment
failures in language models. Yet most existing filters focus narrowly on
general safety and overlook cultural context. In this work, we introduce
FanarGuard, a bilingual moderation filter that evaluates both safety and
cultural alignment in Arabic and English. We construct a dataset of over 468K
prompt and response pairs, drawn from synthetic and public datasets, scored by
a panel of LLM judges on harmlessness and cultural awareness, and use it to
train two filter variants. To rigorously evaluate cultural alignment, we
further develop the first benchmark targeting Arabic cultural contexts,
comprising over 1k norm-sensitive prompts with LLM-generated responses
annotated by human raters. Results show that FanarGuard achieves stronger
agreement with human annotations than inter-annotator reliability, while
matching the performance of state-of-the-art filters on safety benchmarks.
These findings highlight the importance of integrating cultural awareness into
moderation and establish FanarGuard as a practical step toward more
context-sensitive safeguards.
\\ ( https://arxiv.org/abs/2511.18852 ,  418kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18860
Date: Mon, 24 Nov 2025 08:00:48 GMT   (370kb)

Title: Generating Reading Comprehension Exercises with Large Language Models
 for Educational Applications
Authors: Xingyu Huang, Fei Jiang and Jianli Xiao
Categories: cs.CL cs.AI
\\
 With the rapid development of large language models (LLMs), the applications
of LLMs have grown substantially. In the education domain, LLMs demonstrate
significant potential, particularly in automatic text generation, which enables
the creation of intelligent and adaptive learning content. This paper proposes
a new LLMs framework, which is named as Reading Comprehension Exercise
Generation (RCEG). It can generate high-quality and personalized English
reading comprehension exercises automatically. Firstly, RCEG uses fine-tuned
LLMs to generate content candidates. Then, it uses a discriminator to select
the best candidate. Finally, the quality of the generated content has been
improved greatly. To evaluate the performance of RCEG, a dedicated dataset for
English reading comprehension is constructed to perform the experiments, and
comprehensive evaluation metrics are used to analyze the experimental results.
These metrics include content diversity, factual accuracy, linguistic toxicity,
and pedagogical alignment. Experimental results show that RCEG significantly
improves the relevance and cognitive appropriateness of the generated
exercises.
\\ ( https://arxiv.org/abs/2511.18860 ,  370kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18864
Date: Mon, 24 Nov 2025 08:08:19 GMT   (81kb)

Title: Think Before You Prune: Selective Self-Generated Calibration for Pruning
 Large Reasoning Models
Authors: Yang Xiang, Yixin Ji, Juntao Li, Min Zhang
Categories: cs.CL
Comments: Under Review
\\
 Large Reasoning Models (LRMs) have demonstrated remarkable performance on
complex reasoning benchmarks. However, their long chain-of-thought reasoning
processes incur significant inference overhead. Pruning has emerged as a
promising approach to reducing computational costs. However, existing efforts
have primarily focused on large language models (LLMs), while pruning LRMs
remains unexplored. In this work, we conduct the first empirical study on
pruning LRMs and show that directly applying existing pruning techniques fails
to yield satisfactory results. Our findings indicate that using self-generated
reasoning data for calibration can substantially improve pruning performance.
We further investigate how the difficulty and length of reasoning data affect
pruning outcomes. Our analysis reveals that challenging and moderately long
self-generated reasoning data serve as ideal calibration data. Based on these
insights, we propose a Selective Self-Generated Reasoning (SSGR) data
construction strategy to provide effective calibration data for pruning LRMs.
Experimental results on the DeepSeek-R1-Distill model series validate that our
strategy improves the reasoning ability of pruned LRMs by 10%-13% compared to
general pruning methods.
\\ ( https://arxiv.org/abs/2511.18864 ,  81kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18889
Date: Mon, 24 Nov 2025 08:44:29 GMT   (1781kb)

Title: CoreEval: Automatically Building Contamination-Resilient Datasets with
 Real-World Knowledge toward Reliable LLM Evaluation
Authors: Jingqian Zhao, Bingbing Wang, Geng Tu, Yice Zhang, Qianlong Wang, Bin
 Liang, Jing Li, Ruifeng Xu
Categories: cs.CL cs.AI
Comments: ACL'25
DOI: 10.18653/v1/2025.acl-long.1085
\\
 Data contamination poses a significant challenge to the fairness of LLM
evaluations in natural language processing tasks by inadvertently exposing
models to test data during training. Current studies attempt to mitigate this
issue by modifying existing datasets or generating new ones from freshly
collected information. However, these methods fall short of ensuring
contamination-resilient evaluation, as they fail to fully eliminate
pre-existing knowledge from models or preserve the semantic complexity of the
original datasets. To address these limitations, we propose \textbf{CoreEval},
a \textbf{Co}ntamination-\textbf{re}silient \textbf{Eval}uation strategy for
automatically updating data with real-world knowledge. This approach begins by
extracting entity relationships from the original data and leveraging the GDELT
database to retrieve relevant, up-to-date knowledge. The retrieved knowledge is
then recontextualized and integrated with the original data, which is refined
and restructured to ensure semantic coherence and enhanced task relevance.
Ultimately, a robust data reflection mechanism is employed to iteratively
verify and refine labels, ensuring consistency between the updated and original
datasets. Extensive experiments on updated datasets validate the robustness of
CoreEval, demonstrating its effectiveness in mitigating performance
overestimation caused by data contamination.
\\ ( https://arxiv.org/abs/2511.18889 ,  1781kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18891
Date: Mon, 24 Nov 2025 08:48:38 GMT   (2095kb)

Title: Reproducibility Study of Large Language Model Bayesian Optimization
Authors: Adam Rychert, Gasper Spagnolo, Evgenii Posashkov
Categories: cs.CL
Comments: 7 pages, 8 figures. Reproducibility study of the LLAMBO framework
 (ICLR 2024). Code: https://github.com/spagnoloG/llambo-reproducibility
\\
 In this reproducibility study, we revisit the LLAMBO framework of Daxberger
et al. (2024), a prompting-based Bayesian optimization (BO) method that uses
large language models as discriminative surrogates and acquisition optimizers
via text-only interactions. We replicate the core Bayesmark and HPOBench
experiments under the original evaluation protocol, but replace GPT-3.5 with
the open-weight Llama 3.1 70B model used for all text encoding components.
 Our results broadly confirm the main claims of LLAMBO. Contextual warm
starting via textual problem and hyperparameter descriptions substantially
improves early regret behaviour and reduces variance across runs. LLAMBO's
discriminative surrogate is weaker than GP or SMAC as a pure single task
regressor, yet benefits from cross task semantic priors induced by the language
model. Ablations that remove textual context markedly degrade predictive
accuracy and calibration, while the LLAMBO candidate sampler consistently
generates higher quality and more diverse proposals than TPE or random
sampling. Experiments with smaller backbones (Gemma 27B, Llama 3.1 8B) yield
unstable or invalid predictions, suggesting insufficient capacity for reliable
surrogate behaviour.
 Overall, our study shows that the LLAMBO architecture is robust to changing
the language model backbone and remains effective when instantiated with Llama
3.1 70B.
\\ ( https://arxiv.org/abs/2511.18891 ,  2095kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18931
Date: Mon, 24 Nov 2025 09:37:43 GMT   (909kb)

Title: Look It Up: Analysing Internal Web Search Capabilities of Modern LLMs
Authors: Sahil Kale
Categories: cs.CL cs.AI
Comments: 10 pages, 8 figures
\\
 Modern large language models integrate web search to provide real-time
answers, yet it remains unclear whether they are efficiently calibrated to use
search when it is actually needed. We introduce a benchmark evaluating both the
necessity and effectiveness of web access across commercial models with no
access to internal states or parameters. The dataset includes a static split of
783 temporally anchored questions answerable from pre-cutoff knowledge, aimed
at testing whether models invoke search based on low internal confidence, and a
dynamic split of 288 post-cutoff queries designed to test whether models
recognise when search is required and retrieve updated information. Web access
substantially improves static accuracy for GPT-5-mini and Claude Haiku 4.5,
though confidence calibration worsens. On dynamic queries, both models
frequently invoke search yet remain below 70 percent accuracy due to weak query
formulation. Costs per accuracy-improving call remain low, but returns diminish
once initial retrieval fails. Selective invocation helps, but models become
overconfident and inconsistent after search. Overall, built-in web search
meaningfully improves factual accuracy and can be invoked selectively, yet
models remain overconfident, skip retrieval when it is essential, and falter
once initial search queries underperform. Taken together, internal web search
works better as a good low-latency verification layer than a reliable
analytical tool, with clear room for improvement.
\\ ( https://arxiv.org/abs/2511.18931 ,  909kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18934
Date: Mon, 24 Nov 2025 09:39:03 GMT   (768kb)

Title: Skeletons Matter: Dynamic Data Augmentation for Text-to-Query
Authors: Yuchen Ji, Bo Xu, Jie Shi, Jiaqing Liang, Deqing Yang, Yu Mao, Hai
 Chen, Yanghua Xiao
Categories: cs.CL cs.AI cs.DB
Comments: Accepted at EMNLP 2025
DOI: 10.18653/v1/2025.emnlp-main.64
\\
 The task of translating natural language questions into query languages has
long been a central focus in semantic parsing. Recent advancements in Large
Language Models (LLMs) have significantly accelerated progress in this field.
However, existing studies typically focus on a single query language, resulting
in methods with limited generalizability across different languages. In this
paper, we formally define the Text-to-Query task paradigm, unifying semantic
parsing tasks across various query languages. We identify query skeletons as a
shared optimization target of Text-to-Query tasks, and propose a general
dynamic data augmentation framework that explicitly diagnoses model-specific
weaknesses in handling these skeletons to synthesize targeted training data.
Experiments on four Text-to-Query benchmarks demonstrate that our method
achieves state-of-the-art performance using only a small amount of synthesized
data, highlighting the efficiency and generality of our approach and laying a
solid foundation for unified research on Text-to-Query tasks. We release our
code at https://github.com/jjjycaptain/Skeletron.
\\ ( https://arxiv.org/abs/2511.18934 ,  768kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18937
Date: Mon, 24 Nov 2025 09:42:58 GMT   (640kb)

Title: Knowledge-based Graphical Method for Safety Signal Detection in Clinical
 Trials
Authors: Francois Vandenhende, Anna Georgiou, Michalis Georgiou, Theodoros
 Psaras, Ellie Karekla, Elena Hadjicosta
Categories: cs.CL
Comments: 13 pages, 3 tables, 5 figures
ACM-class: I.2
\\
 We present a graphical, knowledge-based method for reviewing
treatment-emergent adverse events (AEs) in clinical trials. The approach
enhances MedDRA by adding a hidden medical knowledge layer (Safeterm) that
captures semantic relationships between terms in a 2-D map. Using this layer,
AE Preferred Terms can be regrouped automatically into similarity clusters, and
their association to the trial disease may be quantified. The Safeterm map is
available online and connected to aggregated AE incidence tables from
ClinicalTrials.gov. For signal detection, we compute treatment-specific
disproportionality metrics using shrinkage incidence ratios. Cluster-level EBGM
values are then derived through precision-weighted aggregation. Two visual
outputs support interpretation: a semantic map showing AE incidence and an
expectedness-versus-disproportionality plot for rapid signal detection. Applied
to three legacy trials, the automated method clearly recovers all expected
safety signals. Overall, augmenting MedDRA with a medical knowledge layer
improves clarity, efficiency, and accuracy in AE interpretation for clinical
trials.
\\ ( https://arxiv.org/abs/2511.18937 ,  640kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19063
Date: Mon, 24 Nov 2025 12:55:20 GMT   (53kb)

Title: Logic of Montage
Authors: Hayami Takahashi and Kensuke Takahashi
Categories: cs.CL
\\
 In expressing emotions, as an expression form separate from natural language,
we propose an alternative form that complements natural language, acting as a
proxy or window for emotional states. First, we set up an expression form
"Effect of Contradictory Structure." "Effect of Contradictory Structure" is not
static but dynamic. Effect in "Effect of Contradictory Structure" is unpleasant
or pleasant, and the orientation to avoid that unpleasantness is considered
pseudo-expression of will. Second, "Effect of Contradictory Structure" can be
overlapped with each other. This overlapping operation is called "montage." A
broader "Structure" that includes related "Effect of Contradictory Structure"
and "Effect of Structure" are set up. Montage produces "Effect of Structure".
In montage, it is necessary to set something like "strength," so we adopted
Deleuze and Deleuze/Guattari's word "intensity" and set it as an element of our
model. We set up a general theoretical framework - Word Import Between Systems
(Models) and justified the import of "intensity" through Austin's use of the
word "force." "Effect of Structure" process is demonstrated using the example
of proceeding to the next level of education.
\\ ( https://arxiv.org/abs/2511.19063 ,  53kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19078
Date: Mon, 24 Nov 2025 13:18:21 GMT   (712kb)

Title: GraphMind: Theorem Selection and Conclusion Generation Framework with
 Dynamic GNN for LLM Reasoning
Authors: Yutong Li, Yitian Zhou, Xudong Wang, GuoChen, Caiyan Qin
Categories: cs.CL cs.AI
\\
 Large language models (LLMs) have demonstrated impressive capabilities in
natural language understanding and generation, including multi-step reasoning
such as mathematical proving. However, existing approaches often lack an
explicit and dynamic mechanism to structurally represent and evolve
intermediate reasoning states, which limits their ability to perform
context-aware theorem selection and iterative conclusion generation. To address
these challenges, we propose GraphMind, a novel dynamic graph-based framework
that integrates the graph neural network (GNN) with LLMs to iteratively select
theorems and generate intermediate conclusions for multi-step reasoning. Our
method models the reasoning process as a heterogeneous evolving graph, where
nodes represent conditions, theorems, and conclusions, while edges capture
logical dependencies between nodes. By encoding the current reasoning state
with GNN and leveraging semantic matching for theorem selection, our framework
enables context-aware, interpretable, and structured reasoning in a closed-loop
manner. Experiments on various question-answering (QA) datasets demonstrate
that our proposed GraphMind method achieves consistent performance improvements
and significantly outperforms existing baselines in multi-step reasoning,
validating the effectiveness and generalizability of our approach.
\\ ( https://arxiv.org/abs/2511.19078 ,  712kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19083
Date: Mon, 24 Nov 2025 13:23:34 GMT   (214kb)

Title: A Multi-Agent LLM Framework for Multi-Domain Low-Resource In-Context NER
 via Knowledge Retrieval, Disambiguation and Reflective Analysis
Authors: Wenxuan Mu, Jinzhong Ning, Di Zhao, Yijia Zhang
Categories: cs.CL
Comments: This paper has been accepted by AAAI 2026 (Main Technical Track)
\\
 In-context learning (ICL) with large language models (LLMs) has emerged as a
promising paradigm for named entity recognition (NER) in low-resource
scenarios. However, existing ICL-based NER methods suffer from three key
limitations: (1) reliance on dynamic retrieval of annotated examples, which is
problematic when annotated data is scarce; (2) limited generalization to unseen
domains due to the LLM's insufficient internal domain knowledge; and (3)
failure to incorporate external knowledge or resolve entity ambiguities. To
address these challenges, we propose KDR-Agent, a novel multi-agent framework
for multi-domain low-resource in-context NER that integrates Knowledge
retrieval, Disambiguation, and Reflective analysis. KDR-Agent leverages
natural-language type definitions and a static set of entity-level contrastive
demonstrations to reduce dependency on large annotated corpora. A central
planner coordinates specialized agents to (i) retrieve factual knowledge from
Wikipedia for domain-specific mentions, (ii) resolve ambiguous entities via
contextualized reasoning, and (iii) reflect on and correct model predictions
through structured self-assessment. Experiments across ten datasets from five
domains demonstrate that KDR-Agent significantly outperforms existing zero-shot
and few-shot ICL baselines across multiple LLM backbones. The code and data can
be found at https://github.com/MWXGOD/KDR-Agent.
\\ ( https://arxiv.org/abs/2511.19083 ,  214kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19097
Date: Tue, 11 Nov 2025 07:52:39 GMT   (2253kb)

Title: DeCoRL: Decoupling Reasoning Chains via Parallel Sub-Step Generation and
 Cascaded Reinforcement for Interpretable and Scalable RLHF
Authors: Ziyuan Gao, Di Liang, Xianjie Wu, Philippe Morel and Minlong Peng
Categories: cs.CL
Comments: Accepted by AAAI 2026
\\
 Existing reinforcement learning methods for Chain-of-Thought reasoning suffer
from two critical limitations. First, they operate as monolithic black boxes
that provide undifferentiated reward signals, obscuring individual step
contributions and hindering error diagnosis. Second, sequential decoding has
O(n) time complexity. This makes real-time deployment impractical for complex
reasoning tasks. We present DeCoRL (Decoupled Reasoning Chains via Coordinated
Reinforcement Learning), a novel framework that transforms reasoning from
sequential processing into collaborative modular orchestration. DeCoRL trains
lightweight specialized models to generate reasoning sub-steps concurrently,
eliminating sequential bottlenecks through parallel processing. To enable
precise error attribution, the framework designs modular reward functions that
score each sub-step independently. Cascaded DRPO optimization then coordinates
these rewards while preserving inter-step dependencies. Comprehensive
evaluation demonstrates state-of-the-art results across RM-Bench, RMB, and
RewardBench, outperforming existing methods including large-scale models.
DeCoRL delivers 3.8 times faster inference while maintaining superior solution
quality and offers a 22.7\% improvement in interpretability through explicit
reward attribution. These advancements, combined with a 72.4\% reduction in
energy consumption and a 68\% increase in throughput, make real-time deployment
of complex reasoning systems a reality.
\\ ( https://arxiv.org/abs/2511.19097 ,  2253kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19118
Date: Mon, 24 Nov 2025 13:49:13 GMT   (212kb)

Title: A symbolic Perl algorithm for the unification of Nahuatl word spellings
Authors: Juan-Jos\'e Guzm\'an-Landa, Jes\'us V\'azquez-Osorio, Juan-Manuel
 Torres-Moreno, Ligia Quintana Torres, Miguel Figueroa-Saavedra, Martha-Lorena
 Avenda\~no-Garrido, Graham Ranger, Patricia Vel\'azquez-Morales, Gerardo
 Eugenio Sierra Mart\'inez
Categories: cs.CL
Comments: MICAI 2025, LNAI 16221, pp. 141-154, 2026. 10 pages, 4 Figures, 8
 Tables
Journal-ref: Advances in Soft Computing, 24th Mexican International Conference
 on Artificial Intelligence, MICAI 2025, Guanajuato, Mexico, Nov 3, 2025,
 Proceedings, Part I, 2026
DOI: 10.1007/978-3-032-09037-9
\\
 In this paper, we describe a symbolic model for the automatic orthographic
unification of Nawatl text documents. Our model is based on algorithms that we
have previously used to analyze sentences in Nawatl, and on the corpus called
$\pi$-yalli, consisting of texts in several Nawatl orthographies. Our automatic
unification algorithm implements linguistic rules in symbolic regular
expressions. We also present a manual evaluation protocol that we have proposed
and implemented to assess the quality of the unified sentences generated by our
algorithm, by testing in a sentence semantic task. We have obtained encouraging
results from the evaluators for most of the desired features of our
artificially unified sentences
\\ ( https://arxiv.org/abs/2511.19118 ,  212kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19120
Date: Mon, 24 Nov 2025 13:49:31 GMT   (2112kb)

Title: On the Optimality of Discrete Object Naming: a Kinship Case Study
Authors: Phong Le and Mees Lindeman and Raquel G. Alhama
Categories: cs.CL cs.AI
\\
 The structure of naming systems in natural languages hinges on a trade-off
between high informativeness and low complexity. Prior work capitalizes on
information theory to formalize these notions; however, these studies generally
rely on two simplifications: (i) optimal listeners, and (ii) universal
communicative need across languages. Here, we address these limitations by
introducing an information-theoretic framework for discrete object naming
systems, and we use it to prove that an optimal trade-off is achievable if and
only if the listener's decoder is equivalent to the Bayesian decoder of the
speaker. Adopting a referential game setup from emergent communication, and
focusing on the semantic domain of kinship, we show that our notion of
optimality is not only theoretically achievable but also emerges empirically in
learned communication systems.
\\ ( https://arxiv.org/abs/2511.19120 ,  2112kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19122
Date: Mon, 24 Nov 2025 13:52:42 GMT   (2212kb)

Title: Emotion-Enhanced Multi-Task Learning with LLMs for Aspect Category
 Sentiment Analysis
Authors: Yaping Chai, Haoran Xie, Joe S. Qin
Categories: cs.CL
Comments: 8 pages, 4 figures
\\
 Aspect category sentiment analysis (ACSA) has achieved remarkable progress
with large language models (LLMs), yet existing approaches primarily emphasize
sentiment polarity while overlooking the underlying emotional dimensions that
shape sentiment expressions. This limitation hinders the model's ability to
capture fine-grained affective signals toward specific aspect categories. To
address this limitation, we introduce a novel emotion-enhanced multi-task ACSA
framework that jointly learns sentiment polarity and category-specific emotions
grounded in Ekman's six basic emotions. Leveraging the generative capabilities
of LLMs, our approach enables the model to produce emotional descriptions for
each aspect category, thereby enriching sentiment representations with
affective expressions. Furthermore, to ensure the accuracy and consistency of
the generated emotions, we introduce an emotion refinement mechanism based on
the Valence-Arousal-Dominance (VAD) dimensional framework. Specifically,
emotions predicted by the LLM are projected onto a VAD space, and those
inconsistent with their corresponding VAD coordinates are re-annotated using a
structured LLM-based refinement strategy. Experimental results demonstrate that
our approach significantly outperforms strong baselines on all benchmark
datasets. This underlines the effectiveness of integrating affective dimensions
into ACSA.
\\ ( https://arxiv.org/abs/2511.19122 ,  2212kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19131
Date: Mon, 24 Nov 2025 13:55:57 GMT   (2436kb)

Title: Eliciting Chain-of-Thought in Base LLMs via Gradient-Based
 Representation Optimization
Authors: Zijian Wang, Yanxiang Ma, Chang Xu
Categories: cs.CL
Comments: AAAI2026
\\
 Chain-of-Thought (CoT) reasoning is a critical capability for large language
models (LLMs), enabling them to tackle com- plex multi-step tasks. While base
LLMs, pre-trained on general text corpora, often struggle with reasoning due to
a lack of specialized training, recent studies reveal their latent reason- ing
potential tied to hidden states. However, existing hidden state manipulation
methods, such as linear activation steering, suffer from limitations due to
their rigid and unconstrained nature, often leading to distribution shifts and
degraded text quality. In this work, we propose a novel approach for elic-
iting CoT reasoning from base LLMs through hidden state manipulation grounded
in probabilistic conditional generation. By reformulating the challenge as an
optimization problem with a balanced likelihood and prior regularization
framework, our method guides hidden states toward reasoning-oriented
trajectories while preserving linguistic coherence. Extensive evaluations
across mathematical, commonsense, and logical reasoning benchmarks demonstrate
that our approach con- sistently outperforms existing steering methods,
offering a theoretically principled and effective solution for enhancing
reasoning capabilities in base LLMs.
\\ ( https://arxiv.org/abs/2511.19131 ,  2436kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19166
Date: Mon, 24 Nov 2025 14:28:50 GMT   (529kb)

Title: Representational Stability of Truth in Large Language Models
Authors: Samantha Dies and Courtney Maynard and Germans Savcisens and Tina
 Eliassi-Rad
Categories: cs.CL
Comments: 25 pages, 24 figures
\\
 Large language models (LLMs) are widely used for factual tasks such as "What
treats asthma?" or "What is the capital of Latvia?". However, it remains
unclear how stably LLMs encode distinctions between true, false, and
neither-true-nor-false content in their internal probabilistic representations.
We introduce representational stability as the robustness of an LLM's veracity
representations to perturbations in the operational definition of truth. We
assess representational stability by (i) training a linear probe on an LLM's
activations to separate true from not-true statements and (ii) measuring how
its learned decision boundary shifts under controlled label changes. Using
activations from sixteen open-source models and three factual domains, we
compare two types of neither statements. The first are fact-like assertions
about entities we believe to be absent from any training data. We call these
unfamiliar neither statements. The second are nonfactual claims drawn from
well-known fictional contexts. We call these familiar neither statements. The
unfamiliar statements induce the largest boundary shifts, producing up to
$40\%$ flipped truth judgements in fragile domains (such as word definitions),
while familiar fictional statements remain more coherently clustered and yield
smaller changes ($\leq 8.2\%$). These results suggest that representational
stability stems more from epistemic familiarity than from linguistic form. More
broadly, our approach provides a diagnostic for auditing and training LLMs to
preserve coherent truth assignments under semantic uncertainty, rather than
optimizing for output accuracy alone.
\\ ( https://arxiv.org/abs/2511.19166 ,  529kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19232
Date: Mon, 24 Nov 2025 15:43:56 GMT   (257kb)

Title: In Machina N400: Pinpointing Where a Causal Language Model Detects
 Semantic Violations
Authors: Christos-Nikolaos Zacharopoulos and Revekka Kyriakoglou
Categories: cs.CL cs.AI
Comments: Accepted at AICS2025
\\
 How and where does a transformer notice that a sentence has gone semantically
off the rails? To explore this question, we evaluated the causal language model
(phi-2) using a carefully curated corpus, with sentences that concluded
plausibly or implausibly. Our analysis focused on the hidden states sampled at
each model layer. To investigate how violations are encoded, we utilized two
complementary probes. First, we conducted a per-layer detection using a linear
probe. Our findings revealed that a simple linear decoder struggled to
distinguish between plausible and implausible endings in the lowest third of
the model's layers. However, its accuracy sharply increased in the middle
blocks, reaching a peak just before the top layers. Second, we examined the
effective dimensionality of the encoded violation. Initially, the violation
widens the representational subspace, followed by a collapse after a mid-stack
bottleneck. This might indicate an exploratory phase that transitions into
rapid consolidation. Taken together, these results contemplate the idea of
alignment with classical psycholinguistic findings in human reading, where
semantic anomalies are detected only after syntactic resolution, occurring
later in the online processing sequence.
\\ ( https://arxiv.org/abs/2511.19232 ,  257kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19317
Date: Mon, 24 Nov 2025 17:11:49 GMT   (150kb)

Title: MultiBanAbs: A Comprehensive Multi-Domain Bangla Abstractive Text
 Summarization Dataset
Authors: Md. Tanzim Ferdous, Naeem Ahsan Chowdhury, Prithwiraj Bhattacharjee
Categories: cs.CL
Journal-ref: 7th International Conference on Trends in Computational and
 Cognitive Engineering (TCCE-2025)
\\
 This study developed a new Bangla abstractive summarization dataset to
generate concise summaries of Bangla articles from diverse sources. Most
existing studies in this field have concentrated on news articles, where
journalists usually follow a fixed writing style. While such approaches are
effective in limited contexts, they often fail to adapt to the varied nature of
real-world Bangla texts. In today's digital era, a massive amount of Bangla
content is continuously produced across blogs, newspapers, and social media.
This creates a pressing need for summarization systems that can reduce
information overload and help readers understand content more quickly. To
address this challenge, we developed a dataset of over 54,000 Bangla articles
and summaries collected from multiple sources, including blogs such as
Cinegolpo and newspapers such as Samakal and The Business Standard. Unlike
single-domain resources, our dataset spans multiple domains and writing styles.
It offers greater adaptability and practical relevance. To establish strong
baselines, we trained and evaluated this dataset using several deep learning
and transfer learning models, including LSTM, BanglaT5-small, and MTS-small.
The results highlight its potential as a benchmark for future research in
Bangla natural language processing. This dataset provides a solid foundation
for building robust summarization systems and helps expand NLP resources for
low-resource languages.
\\ ( https://arxiv.org/abs/2511.19317 ,  150kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19333
Date: Mon, 24 Nov 2025 17:26:58 GMT   (51kb)

Title: Learning to Reason: Training LLMs with GPT-OSS or DeepSeek R1 Reasoning
 Traces
Authors: Shaltiel Shmidman, Asher Fredman, Oleg Sudakov, Meriem Bendris
Categories: cs.CL
\\
 Test-time scaling, which leverages additional computation during inference to
improve model accuracy, has enabled a new class of Large Language Models (LLMs)
that are able to reason through complex problems by understanding the goal,
turning this goal into a plan, working through intermediate steps, and checking
their own work before answering . Frontier large language models with reasoning
capabilities, such as DeepSeek-R1 and OpenAI's gpt-oss, follow the same
procedure when solving complex problems by generating intermediate reasoning
traces before giving the final answer. Today, these models are being
increasingly used to generate reasoning traces that serve as high-quality
supervised data for post-training of small and medium-sized language models to
teach reasoning capabilities without requiring expensive human curation. In
this work, we compare the performance of medium-sized LLMs on Math problems
after post-training on two kinds of reasoning traces. We compare the impact of
reasoning traces generated by DeepSeek-R1 and gpt-oss LLMs in terms of accuracy
and inference efficiency.
\\ ( https://arxiv.org/abs/2511.19333 ,  51kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19399
Date: Mon, 24 Nov 2025 18:35:54 GMT   (7742kb)

Title: DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research
Authors: Rulin Shao, Akari Asai, Shannon Zejiang Shen, Hamish Ivison, Varsha
 Kishore, Jingming Zhuo, Xinran Zhao, Molly Park, Samuel G. Finlayson, David
 Sontag, Tyler Murray, Sewon Min, Pradeep Dasigi, Luca Soldaini, Faeze
 Brahman, Wen-tau Yih, Tongshuang Wu, Luke Zettlemoyer, Yoon Kim, Hannaneh
 Hajishirzi, Pang Wei Koh
Categories: cs.CL cs.AI cs.LG
\\
 Deep research models perform multi-step research to produce long-form,
well-attributed answers. However, most open deep research models are trained on
easily verifiable short-form QA tasks via reinforcement learning with
verifiable rewards (RLVR), which does not extend to realistic long-form tasks.
We address this with Reinforcement Learning with Evolving Rubrics (RLER), in
which we construct and maintain rubrics that co-evolve with the policy model
during training; this allows the rubrics to incorporate information that the
model has newly explored and to provide discriminative, on-policy feedback.
Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model
that is directly trained for open-ended, long-form deep research. Across four
long-form deep research benchmarks in science, healthcare and general domains,
DR Tulu substantially outperforms existing open deep research models, and
matches or exceeds proprietary deep research systems, while being significantly
smaller and cheaper per query. To facilitate future research, we release all
data, models, and code, including our new MCP-based agent infrastructure for
deep research systems.
\\ ( https://arxiv.org/abs/2511.19399 ,  7742kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19417
Date: Mon, 24 Nov 2025 18:55:16 GMT   (749kb)

Title: Be My Eyes: Extending Large Language Models to New Modalities Through
 Multi-Agent Collaboration
Authors: James Y. Huang, Sheng Zhang, Qianchu Liu, Guanghui Qin, Tinghui Zhu,
 Tristan Naumann, Muhao Chen, Hoifung Poon
Categories: cs.CL cs.AI cs.LG
\\
 Large Language Models (LLMs) have demonstrated remarkable capabilities in
challenging, knowledge-intensive reasoning tasks. However, extending LLMs to
perceive and reason over a new modality (e.g., vision), often requires costly
development of large-scale vision language models (VLMs) with LLMs as
backbones. Smaller VLMs are more efficient and adaptable but often lack the
broad knowledge and reasoning capabilities of frontier LLMs. In this work, we
propose BeMyEyes, a modular, multi-agent framework for extending LLMs to
multimodal reasoning by orchestrating collaboration between efficient,
adaptable VLMs as perceivers and powerful LLMs as reasoners through
conversations. We then introduce a data synthesis and supervised fine-tuning
pipeline to train the perceiver agent to effectively collaborate with the
reasoner agent. By combining the complementary strengths of perception and
reasoning agents, BeMyEyes avoids the need for training large-scale multimodal
models, preserves the generalization and reasoning capabilities of LLMs, and
allows flexible extension to new domains and modalities. Experiments show that
our framework unlocks the multimodal reasoning capabilities for LLMs, enabling
a lightweight and fully open-source solution, i.e. equipping text-only
DeepSeek-R1 with Qwen2.5-VL-7B perceiver, to outperform large-scale proprietary
VLMs such as GPT-4o on a wide range of knowledge-intensive multimodal tasks.
These results demonstrate the effectiveness, modularity, and scalability of our
multi-agent approach for building future multimodal reasoning systems.
\\ ( https://arxiv.org/abs/2511.19417 ,  749kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17576
Date: Sat, 15 Nov 2025 00:20:24 GMT   (64kb)

Title: Multimodal AI for Body Fat Estimation: Computer Vision and Anthropometry
 with DEXA Benchmarks
Authors: Rayan Aldajani
Categories: cs.CV cs.AI cs.LG
Comments: 2 pages, 2 figures, accepted at IEEE CASCON 2025
\\
 Tracking body fat percentage is essential for effective weight management,
yet gold-standard methods such as DEXA scans remain expensive and inaccessible
for most people. This study evaluates the feasibility of artificial
intelligence (AI) models as low-cost alternatives using frontal body images and
basic anthropometric data. The dataset consists of 535 samples: 253 cases with
recorded anthropometric measurements (weight, height, neck, ankle, and wrist)
and 282 images obtained via web scraping from Reddit posts with self-reported
body fat percentages, including some reported as DEXA-derived by the original
posters. Because no public datasets exist for computer-vision-based body fat
estimation, this dataset was compiled specifically for this study. Two
approaches were developed: (1) ResNet-based image models and (2) regression
models using anthropometric measurements. A multimodal fusion framework is also
outlined for future expansion once paired datasets become available. The
image-based model achieved a Root Mean Square Error (RMSE) of 4.44% and a
Coefficient of Determination (R^2) of 0.807. These findings demonstrate that
AI-assisted models can offer accessible and low-cost body fat estimates,
supporting future consumer applications in health and fitness.
\\ ( https://arxiv.org/abs/2511.17576 ,  64kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17596
Date: Mon, 17 Nov 2025 19:13:51 GMT   (2625kb)

Title: Reconstruction-Driven Multimodal Representation Learning for Automated
 Media Understanding
Authors: Yassir Benhammou, Suman Kalyan, Sujay Kumar
Categories: cs.CV cs.AI
Comments: 8 pages, 5 figures, 4 tables
\\
 Broadcast and media organizations increasingly rely on artificial
intelligence to automate the labor-intensive processes of content indexing,
tagging, and metadata generation. However, existing AI systems typically
operate on a single modality-such as video, audio, or text-limiting their
understanding of complex, cross-modal relationships in broadcast material. In
this work, we propose a Multimodal Autoencoder (MMAE) that learns unified
representations across text, audio, and visual data, enabling end-to-end
automation of metadata extraction and semantic clustering. The model is trained
on the recently introduced LUMA dataset, a fully aligned benchmark of
multimodal triplets representative of real-world media content. By minimizing
joint reconstruction losses across modalities, the MMAE discovers
modality-invariant semantic structures without relying on large paired or
contrastive datasets. We demonstrate significant improvements in clustering and
alignment metrics (Silhouette, ARI, NMI) compared to linear baselines,
indicating that reconstruction-based multimodal embeddings can serve as a
foundation for scalable metadata generation and cross-modal retrieval in
broadcast archives. These results highlight the potential of
reconstruction-driven multimodal learning to enhance automation, searchability,
and content management efficiency in modern broadcast workflows.
\\ ( https://arxiv.org/abs/2511.17596 ,  2625kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17597
Date: Mon, 17 Nov 2025 22:13:00 GMT   (3045kb)

Title: BCWildfire: A Long-term Multi-factor Dataset and Deep Learning Benchmark
 for Boreal Wildfire Risk Prediction
Authors: Zhengsen Xu, Sibo Cheng, Hongjie He, Lanying Wang, Wentao Sun,
 Jonathan Li, Lincoln Linlin Xu
Categories: cs.CV
Comments: This paper has been accepted by AAAI-26
\\
 Wildfire risk prediction remains a critical yet challenging task due to the
complex interactions among fuel conditions, meteorology, topography, and human
activity. Despite growing interest in data-driven approaches, publicly
available benchmark datasets that support long-term temporal modeling,
large-scale spatial coverage, and multimodal drivers remain scarce. To address
this gap, we present a 25-year, daily-resolution wildfire dataset covering 240
million hectares across British Columbia and surrounding regions. The dataset
includes 38 covariates, encompassing active fire detections, weather variables,
fuel conditions, terrain features, and anthropogenic factors. Using this
benchmark, we evaluate a diverse set of time-series forecasting models,
including CNN-based, linear-based, Transformer-based, and Mamba-based
architectures. We also investigate effectiveness of position embedding and the
relative importance of different fire-driving factors. The dataset and the
corresponding code can be found at https://github.com/SynUW/mmFire
\\ ( https://arxiv.org/abs/2511.17597 ,  3045kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17607
Date: Tue, 18 Nov 2025 07:54:21 GMT   (7898kb)

Title: Robustness of Structured Data Extraction from Perspectively Distorted
 Documents
Authors: Hyakka Nakada, Yoshiyasu Tanaka
Categories: cs.CV cs.CL cs.LG
Comments: 8 pages, 12 figures
\\
 Optical Character Recognition (OCR) for data extraction from documents is
essential to intelligent informatics, such as digitizing medical records and
recognizing road signs. Multi-modal Large Language Models (LLMs) can solve this
task and have shown remarkable performance. Recently, it has been noticed that
the accuracy of data extraction by multi-modal LLMs can be affected when
in-plane rotations are present in the documents. However, real-world document
images are usually not only in-plane rotated but also perspectively distorted.
This study investigates the impacts of such perturbations on the data
extraction accuracy for the state-of-the-art model, Gemini-1.5-pro. Because
perspective distortions have a high degree of freedom, designing experiments in
the same manner as single-parametric rotations is difficult. We observed
typical distortions of document images and showed that most of them
approximately follow an isosceles-trapezoidal transformation, which allows us
to evaluate distortions with a small number of parameters. We were able to
reduce the number of independent parameters from eight to two, i.e. rotation
angle and distortion ratio. Then, specific entities were extracted from
synthetically generated sample documents with varying these parameters. As the
performance of LLMs, we evaluated not only a character-recognition accuracy but
also a structure-recognition accuracy. Whereas the former represents the
classical indicators for optical character recognition, the latter is related
to the correctness of reading order. In particular, the structure-recognition
accuracy was found to be significantly degraded by document distortion. In
addition, we found that this accuracy can be improved by a simple rotational
correction. This insight will contribute to the practical use of multi-modal
LLMs for OCR tasks.
\\ ( https://arxiv.org/abs/2511.17607 ,  7898kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17609
Date: Tue, 18 Nov 2025 08:15:14 GMT   (961kb)

Title: 3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF
Authors: Linh Van Ma and Unse Fatima and Tepy Sokun Chriv and Haroon Imran and
 Moongu Jeon
Categories: cs.CV
Comments: International Conference on Control, Automation and Information
 Sciences (ICCAIS) 2025, October 27 - 29, 2025 | Jeju, Korea
\\
 Accurate 3D ground truth estimation is critical for applications such as
autonomous navigation, surveillance, and robotics. This paper introduces a
novel method that uses an Unscented Kalman Filter (UKF) to fuse 2D bounding box
or pose keypoint ground truth annotations from multiple calibrated cameras into
accurate 3D ground truth. By leveraging human-annotated ground-truth 2D, our
proposed method, a multi-camera single-object tracking algorithm, transforms 2D
image coordinates into robust 3D world coordinates through homography-based
projection and UKF-based fusion. Our proposed algorithm processes multi-view
data to estimate object positions and shapes while effectively handling
challenges such as occlusion. We evaluate our method on the CMC, Wildtrack, and
Panoptic datasets, demonstrating high accuracy in 3D localization compared to
the available 3D ground truth. Unlike existing approaches that provide only
ground-plane information, our method also outputs the full 3D shape of each
object. Additionally, the algorithm offers a scalable and fully automatic
solution for multi-camera systems using only 2D image annotations.
\\ ( https://arxiv.org/abs/2511.17609 ,  961kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17612
Date: Tue, 18 Nov 2025 10:13:52 GMT   (16710kb)

Title: Unified Low-Light Traffic Image Enhancement via Multi-Stage Illumination
 Recovery and Adaptive Noise Suppression
Authors: Siddiqua Namrah
Categories: cs.CV cs.AI
Comments: Master's thesis, Korea University, 2025
\\
 Enhancing low-light traffic images is crucial for reliable perception in
autonomous driving, intelligent transportation, and urban surveillance systems.
Nighttime and dimly lit traffic scenes often suffer from poor visibility due to
low illumination, noise, motion blur, non-uniform lighting, and glare from
vehicle headlights or street lamps, which hinder tasks such as object detection
and scene understanding. To address these challenges, we propose a fully
unsupervised multi-stage deep learning framework for low-light traffic image
enhancement. The model decomposes images into illumination and reflectance
components, progressively refined by three specialized modules: (1)
Illumination Adaptation, for global and local brightness correction; (2)
Reflectance Restoration, for noise suppression and structural detail recovery
using spatial-channel attention; and (3) Over-Exposure Compensation, for
reconstructing saturated regions and balancing scene luminance. The network is
trained using self-supervised reconstruction, reflectance smoothness,
perceptual consistency, and domain-aware regularization losses, eliminating the
need for paired ground-truth images. Experiments on general and
traffic-specific datasets demonstrate superior performance over
state-of-the-art methods in both quantitative metrics (PSNR, SSIM, LPIPS, NIQE)
and qualitative visual quality. Our approach enhances visibility, preserves
structure, and improves downstream perception reliability in real-world
low-light traffic scenarios.
\\ ( https://arxiv.org/abs/2511.17612 ,  16710kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17614
Date: Tue, 18 Nov 2025 11:49:22 GMT   (5944kb)

Title: HSMix: Hard and Soft Mixing Data Augmentation for Medical Image
 Segmentation
Authors: Danyang Sun, Fadi Dornaika, Nagore Barrena
Categories: cs.CV cs.LG
DOI: 10.1016/j.inffus.2024.102741
\\
 Due to the high cost of annotation or the rarity of some diseases, medical
image segmentation is often limited by data scarcity and the resulting
overfitting problem. Self-supervised learning and semi-supervised learning can
mitigate the data scarcity challenge to some extent. However, both of these
paradigms are complex and require either hand-crafted pretexts or well-defined
pseudo-labels. In contrast, data augmentation represents a relatively simple
and straightforward approach to addressing data scarcity issues. It has led to
significant improvements in image recognition tasks. However, the effectiveness
of local image editing augmentation techniques in the context of segmentation
has been less explored. We propose HSMix, a novel approach to local image
editing data augmentation involving hard and soft mixing for medical semantic
segmentation. In our approach, a hard-augmented image is created by combining
homogeneous regions (superpixels) from two source images. A soft mixing method
further adjusts the brightness of these composed regions with brightness mixing
based on locally aggregated pixel-wise saliency coefficients. The ground-truth
segmentation masks of the two source images undergo the same mixing operations
to generate the associated masks for the augmented images. Our method fully
exploits both the prior contour and saliency information, thus preserving local
semantic information in the augmented images while enriching the augmentation
space with more diversity. Our method is a plug-and-play solution that is model
agnostic and applicable to a range of medical imaging modalities. Extensive
experimental evidence has demonstrated its effectiveness in a variety of
medical segmentation tasks. The source code is available in
https://github.com/DanielaPlusPlus/HSMix.
\\ ( https://arxiv.org/abs/2511.17614 ,  5944kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17615
Date: Tue, 18 Nov 2025 12:25:47 GMT   (31275kb)

Title: Plug-and-Play Multi-Concept Adaptive Blending for High-Fidelity
 Text-to-Image Synthesis
Authors: Young-Beom Woo
Categories: cs.CV cs.AI
Comments: [Master's thesis, Korea University, 2025]
\\
 Integrating multiple personalized concepts into a single image has recently
become a significant area of focus within Text-to-Image (T2I) generation.
However, existing methods often underperform on complex multi-object scenes due
to unintended alterations in both personalized and non-personalized regions.
This not only fails to preserve the intended prompt structure but also disrupts
interactions among regions, leading to semantic inconsistencies. To address
this limitation, we introduce plug-and-play multi-concept adaptive blending for
high-fidelity text-to-image synthesis (PnP-MIX), an innovative, tuning-free
approach designed to seamlessly embed multiple personalized concepts into a
single generated image. Our method leverages guided appearance attention to
faithfully reflect the intended appearance of each personalized concept. To
further enhance compositional fidelity, we present a mask-guided noise mixing
strategy that preserves the integrity of non-personalized regions such as the
background or unrelated objects while enabling the precise integration of
personalized objects. Finally, to mitigate concept leakage, i.e., the
inadvertent leakage of personalized concept features into other regions, we
propose background dilution++, a novel strategy that effectively reduces such
leakage and promotes accurate localization of features within personalized
regions. Extensive experimental results demonstrate that PnP-MIX consistently
surpasses existing methodologies in both single- and multi-concept
personalization scenarios, underscoring its robustness and superior performance
without additional model tuning.
\\ ( https://arxiv.org/abs/2511.17615 ,  31275kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17618
Date: Tue, 18 Nov 2025 13:45:50 GMT   (8666kb)

Title: Foundational Question Generation for Video Question Answering via an
 Embedding-Integrated Approach
Authors: Ju-Young Oh
Categories: cs.CV
Comments: [Master's thesis, Korea University, 2025]
\\
 Conventional VQA approaches primarily rely on question-answer (Q&A) pairs to
learn the spatio-temporal dynamics of video content. However, most existing
annotations are event-centric, which restricts the model's ability to capture
the comprehensive context of a scene. The lack of fundamental information such
as object categories, spatial configurations, and descriptive visual attributes
prevents the model from forming a complete understanding of the environment,
ultimately limiting its generalization and reasoning capability. In this paper,
we introduce Foundational Question Generation for Video Question Answering via
an Embedding-Integrated Approach (FIQ), a framework designed to enhance the
reasoning capability of VQA models by improving their foundational
comprehension of video content. FIQ generates Q&A pairs from descriptive
information extracted directly from videos, thereby enriching the dataset with
core scene-level attributes. These generated pairs help the model develop a
more holistic understanding of the video, leading to improved generalizability
and reasoning performance. In addition, we propose a VQ-CAlign module that
aligns task-specific question embeddings with corresponding visual features,
preserving essential contextual cues and enhancing adaptability to downstream
tasks. Experimental results on the SUTD-TrafficQA dataset demonstrate that FIQ
achieves state-of-the-art performance, surpassing existing baseline approaches.
\\ ( https://arxiv.org/abs/2511.17618 ,  8666kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17619
Date: Tue, 18 Nov 2025 13:49:30 GMT   (1145kb)

Title: Rethinking the Encoding and Annotating of 3D Bounding Box: Corner-Aware
 3D Object Detection from Point Clouds
Authors: Qinghao Meng, Junbo Yin, Jianbing Shen, Yunde Jia
Categories: cs.CV
Comments: 8 pages, 5 figures, 2 tables
\\
 Center-aligned regression remains dominant in LiDAR-based 3D object
detection, yet it suffers from fundamental instability: object centers often
fall in sparse or empty regions of the bird's-eye-view (BEV) due to the
front-surface-biased nature of LiDAR point clouds, leading to noisy and
inaccurate bounding box predictions. To circumvent this limitation, we revisit
bounding box representation and propose corner-aligned regression, which shifts
the prediction target from unstable centers to geometrically informative
corners that reside in dense, observable regions. Leveraging the inherent
geometric constraints among corners and image 2D boxes, partial parameters of
3D bounding boxes can be recovered from corner annotations, enabling a weakly
supervised paradigm without requiring complete 3D labels. We design a simple
yet effective corner-aware detection head that can be plugged into existing
detectors. Experiments on KITTI show our method improves performance by 3.5% AP
over center-based baseline, and achieves 83% of fully supervised accuracy using
only BEV corner clicks, demonstrating the effectiveness of our corner-aware
regression strategy.
\\ ( https://arxiv.org/abs/2511.17619 ,  1145kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17633
Date: Wed, 19 Nov 2025 06:38:50 GMT   (1861kb)

Title: BD-Net: Has Depth-Wise Convolution Ever Been Applied in Binary Neural
 Networks?
Authors: DoYoung Kim, Jin-Seop Lee, Noo-ri Kim, SungJoon Lee, Jee-Hyong Lee
Categories: cs.CV
Comments: Paper accepted to AAAI 2026
\\
 Recent advances in model compression have highlighted the potential of
low-bit precision techniques, with Binary Neural Networks (BNNs) attracting
attention for their extreme efficiency. However, extreme quantization in BNNs
limits representational capacity and destabilizes training, posing significant
challenges for lightweight architectures with depth-wise convolutions. To
address this, we propose a 1.58-bit convolution to enhance expressiveness and a
pre-BN residual connection to stabilize optimization by improving the Hessian
condition number. These innovations enable, to the best of our knowledge, the
first successful binarization of depth-wise convolutions in BNNs. Our method
achieves 33M OPs on ImageNet with MobileNet V1, establishing a new
state-of-the-art in BNNs by outperforming prior methods with comparable OPs.
Moreover, it consistently outperforms existing methods across various datasets,
including CIFAR-10, CIFAR-100, STL-10, Tiny ImageNet, and Oxford Flowers 102,
with accuracy improvements of up to 9.3 percentage points.
\\ ( https://arxiv.org/abs/2511.17633 ,  1861kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17634
Date: Wed, 19 Nov 2025 07:21:49 GMT   (12597kb)

Title: Efficient Score Pre-computation for Diffusion Models via Cross-Matrix
 Krylov Projection
Authors: Kaikwan Lau, Andrew S. Na, Justin W.L. Wan
Categories: cs.CV
\\
 This paper presents a novel framework to accelerate score-based diffusion
models. It first converts the standard stable diffusion model into the
Fokker-Planck formulation which results in solving large linear systems for
each image. For training involving many images, it can lead to a high
computational cost. The core innovation is a cross-matrix Krylov projection
method that exploits mathematical similarities between matrices, using a shared
subspace built from ``seed" matrices to rapidly solve for subsequent ``target"
matrices. Our experiments show that this technique achieves a 15.8\% to 43.7\%
time reduction over standard sparse solvers. Additionally, we compare our
method against DDPM baselines in denoising tasks, showing a speedup of up to
115$\times$. Furthermore, under a fixed computational budget, our model is able
to produce high-quality images while DDPM fails to generate recognizable
content, illustrating our approach is a practical method for efficient
generation in resource-limited settings.
\\ ( https://arxiv.org/abs/2511.17634 ,  12597kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17635
Date: Wed, 19 Nov 2025 07:47:39 GMT   (9850kb)

Title: Upstream Probabilistic Meta-Imputation for Multimodal Pediatric
 Pancreatitis Classification
Authors: Max A. Nelson, Elif Keles, Eminenur Sen Tasci, Merve Yazol, Halil
 Ertugrul Aktas, Ziliang Hong, Andrea Mia Bejar, Gorkem Durak, Oznur Leman
 Boyunaga, Ulas Bagci
Categories: cs.CV cs.LG
Comments: 5 pages, 5 figures
\\
 Pediatric pancreatitis is a progressive and debilitating inflammatory
condition, including acute pancreatitis and chronic pancreatitis, that presents
significant clinical diagnostic challenges. Machine learning-based methods also
face diagnostic challenges due to limited sample availability and multimodal
imaging complexity. To address these challenges, this paper introduces Upstream
Probabilistic Meta-Imputation (UPMI), a light-weight augmentation strategy that
operates upstream of a meta-learner in a low-dimensional meta-feature space
rather than in image space. Modality-specific logistic regressions (T1W and T2W
MRI radiomics) produce probability outputs that are transformed into a
7-dimensional meta-feature vector. Class-conditional Gaussian mixture models
(GMMs) are then fit within each cross-validation fold to sample synthetic
meta-features that, combined with real meta-features, train a Random Forest
(RF) meta-classifier. On 67 pediatric subjects with paired T1W/T2W MRIs, UPMI
achieves a mean AUC of 0.908 $\pm$ 0.072, a $\sim$5% relative gain over a
real-only baseline (AUC 0.864 $\pm$ 0.061).
\\ ( https://arxiv.org/abs/2511.17635 ,  9850kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17636
Date: Wed, 19 Nov 2025 08:33:14 GMT   (701kb)

Title: TSRE: Channel-Aware Typical Set Refinement for Out-of-Distribution
 Detection
Authors: Weijun Gao, Rundong He, Jinyang Dong, Yongshun Gong
Categories: cs.CV
\\
 Out-of-Distribution (OOD) detection is a critical capability for ensuring the
safe deployment of machine learning models in open-world environments, where
unexpected or anomalous inputs can compromise model reliability and
performance. Activation-based methods play a fundamental role in OOD detection
by mitigating anomalous activations and enhancing the separation between
in-distribution (ID) and OOD data. However, existing methods apply activation
rectification while often overlooking channel's intrinsic characteristics and
distributional skewness, which results in inaccurate typical set estimation.
This discrepancy can lead to the improper inclusion of anomalous activations
across channels. To address this limitation, we propose a typical set
refinement method based on discriminability and activity, which rectifies
activations into a channel-aware typical set. Furthermore, we introduce a
skewness-based refinement to mitigate distributional bias in typical set
estimation. Finally, we leverage the rectified activations to compute the
energy score for OOD detection. Experiments on the ImageNet-1K and CIFAR-100
benchmarks demonstrate that our method achieves state-of-the-art performance
and generalizes effectively across backbones and score functions.
\\ ( https://arxiv.org/abs/2511.17636 ,  701kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17649
Date: Thu, 20 Nov 2025 09:52:20 GMT   (24949kb)

Title: SWITCH: Benchmarking Modeling and Handling of Tangible Interfaces in
 Long-horizon Embodied Scenarios
Authors: Jieru Lin, Zhiwei Yu, B\"orje F. Karlsson
Categories: cs.CV cs.AI cs.RO
\\
 Autonomous intelligence requires not only perception and reasoning, but
critically, effective interaction with the existing world and its
infrastructure. Everyday environments are rich in tangible control interfaces
(TCIs), e.g., light switches, appliance panels, and embedded GUIs, that demand
commonsense and physics reasoning, but also causal prediction and outcome
verification in time and space (e.g., delayed heating, remote lights).
Moreover, failures here have potential safety implications, yet current
benchmarks rarely test grounding, partial observability (video), or post-hoc
verification in situated settings. We introduce SWITCH (Semantic World
Interface Tasks for Control and Handling), an embodied, task-driven benchmark
created through iterative releases to probe these gaps. Its first iteration,
SWITCH-Basic, evaluates five complementary abilities:task-aware VQA, semantic
UI grounding, action generation, state-transition prediction, and result
verification, under egocentric RGB video input and device diversity. Across 351
tasks spanning 98 real devices and appliances, commercial and open LMMMs
exhibit inconsistent performance even on single-step interactions, often
over-relying on textual cues and under-using visual or video evidence (and high
aggregate scores can mask such failures). SWITCH provides data, code, and
held-out splits to enable reproducible evaluation and community contributions
toward more challenging future iterations of the benchmark and the creation of
training datasets. Benchmark resources are available at:
https://github.com/BAAI-Agents/SWITCH.
\\ ( https://arxiv.org/abs/2511.17649 ,  24949kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17655
Date: Thu, 20 Nov 2025 17:21:40 GMT   (3762kb)

Title: Explainable Deep Learning for Brain Tumor Classification: Comprehensive
 Benchmarking with Dual Interpretability and Lightweight Deployment
Authors: Md. Mohaiminul Islam, Md. Mofazzal Hossen, Maher Ali Rusho, Nahiyan
 Nazah Ridita, Zarin Tasnia Shanta, Md. Simanto Haider, Ahmed Faizul Haque
 Dhrubo, Md. Khurshid Jahan, and Mohammad Abdul Qayum
Categories: cs.CV cs.AI cs.CY
Comments: This paper contains 17 pages, 4 tables, and 19 figures. This Paper is
 already accepted in IEEE Computational Intelligence Magazine (CIM)
Journal-ref: IEEE Computational Intelligence Magazine (CIM) in 19th July 2025
\\
 Our study provides a full deep learning system for automated classification
of brain tumors from MRI images, includes six benchmarked architectures (five
ImageNet-pre-trained models (VGG-16, Inception V3, ResNet-50, Inception-ResNet
V2, Xception) and a custom built, compact CNN (1.31M params)). The study moves
the needle forward in a number of ways, including (1) full standardization of
assessment with respect to preprocessing, training sets/protocols (optimizing
networks with the AdamW optimizer, CosineAnnealingLR, patiene for early
stopping = 7), and metrics to assess performance were identical along all
models; (2) a high level of confidence in the localizations based on prior
studies as both Grad-CAM and GradientShap explanation were used to establish
anatomically important and meaningful attention regions and address the
black-box issue; (3) a compact 1.31 million parameter CNN was developed that
achieved 96.49% testing accuracy and was 100 times smaller than
Inception-ResNet V2 while permitting real-time inference (375ms) on edge
devices; (4) full evaluation beyond accuracy reporting based on measures of
intersection over union, Hausdorff distance, and precision-recall curves, and
confusion matrices across all splits. Inception-ResNet V2 reached
state-of-the-art performance, achieving a 99.53% accuracy on testing and
obtaining a precision, recall, and F1-score of at least 99.50% dominant
performance based on metrics of recent studies. We demonstrated a lightweight
model that is suitable to deploy on devices that do not have multi-GPU
infrastructure in under-resourced settings. This end-to-end solution considers
accuracy, interpretability, and deployability of trustworthy AI to create the
framework necessary for performance assessment and deployment within advance
and low-resource healthcare systems to an extent that enabled participation at
the clinical screening and triage level.
\\ ( https://arxiv.org/abs/2511.17655 ,  3762kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17668
Date: Fri, 21 Nov 2025 03:39:48 GMT   (3283kb)

Title: MedPEFT-CL: Dual-Phase Parameter-Efficient Continual Learning with
 Medical Semantic Adapter and Bidirectional Memory Consolidation
Authors: Ziyuan Gao
Categories: cs.CV
Comments: Accepted by WACV 2026 (round 2)
\\
 Medical vision-language segmentation models suffer from catastrophic
forgetting when adapting to new anatomical structures, requiring complete
retraining that limits their clinical deployment. Although continual learning
approaches have been studied for various applications, targeted research on
continual learning approaches specifically designed for medical vision-language
tasks remains underexplored. We propose MedPEFT-CL, a parameter-efficient
continual learning framework that addresses both efficient learning of new
tasks and preservation of previous knowledge through a dual-phase architecture
based on CLIPSeg. Our dual-phase architecture features an adaptive learning
phase that employs semantic similarity-based adapter allocation and
parameter-efficient fine-tuning for medical tasks through prompt similarity
analysis, and a knowledge consolidation phase employing bi-directional
Fisher-memory coordination. This creates a reinforcing cycle: consolidation
directs replay priorities while new tasks provide challenging samples that
improve retention strategies. Our key contributions are: (1) a semantic-driven
adapter allocation mechanism that enables efficient learning of new medical
tasks, (2) a bi-modal LoRA adaptation that significantly reduces trainable
parameters while maintaining cross-modal learning, and (3) bidirectional
Fisher-memory coordination that prevents catastrophic forgetting from previous
medical tasks. Extensive experiments across diverse medical datasets
demonstrate superior forgetting mitigation and performance retention with
minimal parameter overhead, making the framework effective for continual
learning in medical vision-language scenarios.
\\ ( https://arxiv.org/abs/2511.17668 ,  3283kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17674
Date: Fri, 21 Nov 2025 06:00:35 GMT   (7226kb)

Title: Person Recognition in Aerial Surveillance: A Decade Survey
Authors: Kien Nguyen, Feng Liu, Clinton Fookes, Sridha Sridharan, Xiaoming Liu,
 Arun Ross
Categories: cs.CV
Comments: Accepted at T-BIOM
DOI: 10.1109/TBIOM.2025.3617011
\\
 The rapid emergence of airborne platforms and imaging sensors is enabling new
forms of aerial surveillance due to their unprecedented advantages in scale,
mobility, deployment, and covert observation capabilities. This paper provides
a comprehensive overview of 150+ papers over the last 10 years of human-centric
aerial surveillance tasks from a computer vision and machine learning
perspective. It aims to provide readers with an in-depth systematic review and
technical analysis of the current state of aerial surveillance tasks using
drones, UAVs, and other airborne platforms. The object of interest is humans,
where human subjects are to be detected, identified, and re-identified. More
specifically, for each of these tasks, we first identify unique challenges in
performing these tasks in an aerial setting compared to the popular
ground-based setting and subsequently compile and analyze aerial datasets
publicly available for each task. Most importantly, we delve deep into the
approaches in the aerial surveillance literature with a focus on investigating
how they presently address aerial challenges and techniques for improvement. We
conclude the paper by discussing the gaps and open research questions to inform
future research avenues.
\\ ( https://arxiv.org/abs/2511.17674 ,  7226kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17681
Date: Fri, 21 Nov 2025 08:53:31 GMT   (5675kb)

Title: Vision-Motion-Reference Alignment for Referring Multi-Object Tracking
 via Multi-Modal Large Language Models
Authors: Weiyi Lv, Ning Zhang, Hanyang Sun, Haoran Jiang, Kai Zhao, Jing Xiao,
 Dan Zeng
Categories: cs.CV
\\
 Referring Multi-Object Tracking (RMOT) extends conventional multi-object
tracking (MOT) by introducing natural language references for multi-modal
fusion tracking. RMOT benchmarks only describe the object's appearance,
relative positions, and initial motion states. This so-called static regulation
fails to capture dynamic changes of the object motion, including velocity
changes and motion direction shifts. This limitation not only causes a temporal
discrepancy between static references and dynamic vision modality but also
constrains multi-modal tracking performance. To address this limitation, we
propose a novel Vision-Motion-Reference aligned RMOT framework, named VMRMOT.
It integrates a motion modality extracted from object dynamics to enhance the
alignment between vision modality and language references through multi-modal
large language models (MLLMs). Specifically, we introduce motion-aware
descriptions derived from object dynamic behaviors and, leveraging the powerful
temporal-reasoning capabilities of MLLMs, extract motion features as the motion
modality. We further design a Vision-Motion-Reference Alignment (VMRA) module
to hierarchically align visual queries with motion and reference cues,
enhancing their cross-modal consistency. In addition, a Motion-Guided
Prediction Head (MGPH) is developed to explore motion modality to enhance the
performance of the prediction head. To the best of our knowledge, VMRMOT is the
first approach to employ MLLMs in the RMOT task for vision-reference alignment.
Extensive experiments on multiple RMOT benchmarks demonstrate that VMRMOT
outperforms existing state-of-the-art methods.
\\ ( https://arxiv.org/abs/2511.17681 ,  5675kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17699
Date: Fri, 21 Nov 2025 18:48:22 GMT   (2439kb)

Title: Understanding Counting Mechanisms in Large Language and Vision-Language
 Models
Authors: Hosein Hasani, Amirmohammad Izadi, Fatemeh Askari, Mobin Bagherian,
 Sadegh Mohammadian, Mohammad Izadi, Mahdieh Soleymani Baghshah
Categories: cs.CV cs.AI
\\
 This paper examines how large language models (LLMs) and large
vision-language models (LVLMs) represent and compute numerical information in
counting tasks. We use controlled experiments with repeated textual and visual
items and analyze model behavior through causal mediation and activation
patching. To this end, we design a specialized tool, CountScope, for
mechanistic interpretability of numerical content. Results show that individual
tokens or visual features encode latent positional count information that can
be extracted and transferred across contexts. Layerwise analyses reveal a
progressive emergence of numerical representations, with lower layers encoding
small counts and higher layers representing larger ones. We identify an
internal counter mechanism that updates with each item, stored mainly in the
final token or region and transferable between contexts. In LVLMs, numerical
information also appears in visual embeddings, shifting between background and
foreground regions depending on spatial composition. Models rely on structural
cues such as separators in text, which act as shortcuts for tracking item
counts and influence the accuracy of numerical predictions. Overall, counting
emerges as a structured, layerwise process in LLMs and follows the same general
pattern in LVLMs, shaped by the properties of the vision encoder.
\\ ( https://arxiv.org/abs/2511.17699 ,  2439kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17722
Date: Fri, 21 Nov 2025 19:18:41 GMT   (8389kb)

Title: Can Vision-Language Models Count? A Synthetic Benchmark and Analysis of
 Attention-Based Interventions
Authors: Saurav Sengupta, Nazanin Moradinasab, Jiebei Liu, Donald E. Brown
Categories: cs.CV
\\
 Recent research suggests that Vision Language Models (VLMs) often rely on
inherent biases learned during training when responding to queries about visual
properties of images. These biases are exacerbated when VLMs are asked highly
specific questions that require them to focus on particular areas of the image
in tasks such as counting. We build upon this research by developing a
synthetic benchmark dataset and evaluation framework to systematically
determine how counting performance varies as image and prompt properties
change. Using open-source VLMs, we then analyze how attention allocation
fluctuates with varying input parameters (e.g. number of objects in the image,
objects color, background color, objects texture, background texture, and
prompt specificity). We further implement attention-based interventions to
modulate focus on visual tokens at different layers and evaluate their impact
on counting performance across a range of visual conditions. Our experiments
reveal that while VLM counting performance remains challenging, especially
under high visual or linguistic complexity, certain attention interventions can
lead to modest gains in counting performance.
\\ ( https://arxiv.org/abs/2511.17722 ,  8389kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17724
Date: Fri, 21 Nov 2025 19:21:21 GMT   (4079kb)

Title: AngioDG: Interpretable Channel-informed Feature-modulated Single-source
 Domain Generalization for Coronary Vessel Segmentation in X-ray Angiography
Authors: Mohammad Atwany, Mojtaba Lashgari, Robin P. Choudhury, Vicente Grau,
 Abhirup Banerjee
Categories: cs.CV
\\
 Cardiovascular diseases are the leading cause of death globally, with X-ray
Coronary Angiography (XCA) as the gold standard during real-time cardiac
interventions. Segmentation of coronary vessels from XCA can facilitate
downstream quantitative assessments, such as measurement of the stenosis
severity and enhancing clinical decision-making. However, developing
generalizable vessel segmentation models for XCA is challenging due to
variations in imaging protocols and patient demographics that cause domain
shifts. These limitations are exacerbated by the lack of annotated datasets,
making Single-source Domain Generalization (SDG) a necessary solution for
achieving generalization. Existing SDG methods are largely augmentation-based,
which may not guarantee the mitigation of overfitting to augmented or synthetic
domains. We propose a novel approach, ``AngioDG", to bridge this gap by channel
regularization strategy to promote generalization. Our method identifies the
contributions of early feature channels to task-specific metrics for DG,
facilitating interpretability, and then reweights channels to calibrate and
amplify domain-invariant features while attenuating domain-specific ones. We
evaluate AngioDG on 6 x-ray angiography datasets for coronary vessels
segmentation, achieving the best out-of-distribution performance among the
compared methods, while maintaining consistent in-domain test performance.
\\ ( https://arxiv.org/abs/2511.17724 ,  4079kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17727
Date: Fri, 21 Nov 2025 19:25:50 GMT   (17807kb)

Title: The Potential and Limitations of Vision-Language Models for Human Motion
 Understanding: A Case Study in Data-Driven Stroke Rehabilitation
Authors: Victor Li, Naveenraj Kamalakannan, Avinash Parnandi, Heidi Schambra,
 Carlos Fernandez-Granda
Categories: cs.CV
\\
 Vision-language models (VLMs) have demonstrated remarkable performance across
a wide range of computer-vision tasks, sparking interest in their potential for
digital health applications. Here, we apply VLMs to two fundamental challenges
in data-driven stroke rehabilitation: automatic quantification of
rehabilitation dose and impairment from videos. We formulate these problems as
motion-identification tasks, which can be addressed using VLMs. We evaluate our
proposed framework on a cohort of 29 healthy controls and 51 stroke survivors.
Our results show that current VLMs lack the fine-grained motion understanding
required for precise quantification: dose estimates are comparable to a
baseline that excludes visual information, and impairment scores cannot be
reliably predicted. Nevertheless, several findings suggest future promise. With
optimized prompting and post-processing, VLMs can classify high-level
activities from a few frames, detect motion and grasp with moderate accuracy,
and approximate dose counts within 25% of ground truth for mildly impaired and
healthy participants, all without task-specific training or finetuning. These
results highlight both the current limitations and emerging opportunities of
VLMs for data-driven stroke rehabilitation and broader clinical video analysis.
\\ ( https://arxiv.org/abs/2511.17727 ,  17807kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17731
Date: Fri, 21 Nov 2025 19:30:24 GMT   (2960kb)

Title: VisReason: A Large-Scale Dataset for Visual Chain-of-Thought Reasoning
Authors: Lingxiao Li, Yifan Wang, Xinyan Gao, Chen Tang, Xiangyu Yue, Chenyu
 You
Categories: cs.CV cs.LG
\\
 Chain-of-Thought (CoT) prompting has proven remarkably effective for
eliciting complex reasoning in large language models (LLMs). Yet, its potential
in multimodal large language models (MLLMs) remains largely untapped, hindered
by the absence of large-scale datasets that capture the rich, spatially
grounded reasoning intrinsic to visual understanding. Existing visual-CoT
resources are typically small, domain-specific, or lack the human-like stepwise
structure necessary for compositional visual reasoning. In this paper, we
introduce VisReason, a large-scale dataset designed to advance visual
Chain-of-Thought reasoning. VisReason comprises 489K annotated examples
spanning four diverse domains, each featuring multi-round, human-like
rationales that guide MLLMs through interpretable visual reasoning steps.
Building upon this, we curate VisReason-Pro, a 165K subset produced with a
stronger expert-level GPT annotator, enriched with detailed reasoning traces
and 3D spatial grounding via depth-informed annotations. Fine-tuning the
state-of-the-art Qwen2.5-VL model on VisReason and VisReason-Pro yields
substantial improvements in step-by-step visual reasoning accuracy,
interpretability, and cross-benchmark generalization. These results demonstrate
that VisReason equips MLLMs with more systematic and generalizable reasoning
capabilities. We envision VisReason as a cornerstone for cultivating human-like
visual reasoning, paving the way toward the next generation of multimodal
intelligence.
\\ ( https://arxiv.org/abs/2511.17731 ,  2960kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17735
Date: Fri, 21 Nov 2025 19:38:07 GMT   (32005kb)

Title: Towards Open-Ended Visual Scientific Discovery with Sparse Autoencoders
Authors: Samuel Stevens, Jacob Beattie, Tanya Berger-Wolf and Yu Su
Categories: cs.CV
\\
 Scientific archives now contain hundreds of petabytes of data across
genomics, ecology, climate, and molecular biology that could reveal
undiscovered patterns if systematically analyzed at scale. Large-scale,
weakly-supervised datasets in language and vision have driven the development
of foundation models whose internal representations encode structure (patterns,
co-occurrences and statistical regularities) beyond their training objectives.
Most existing methods extract structure only for pre-specified targets; they
excel at confirmation but do not support open-ended discovery of unknown
patterns. We ask whether sparse autoencoders (SAEs) can enable open-ended
feature discovery from foundation model representations. We evaluate this
question in controlled rediscovery studies, where the learned SAE features are
tested for alignment with semantic concepts on a standard segmentation
benchmark and compared against strong label-free alternatives on
concept-alignment metrics. Applied to ecological imagery, the same procedure
surfaces fine-grained anatomical structure without access to segmentation or
part labels, providing a scientific case study with ground-truth validation.
While our experiments focus on vision with an ecology case study, the method is
domain-agnostic and applicable to models in other sciences (e.g., proteins,
genomics, weather). Our results indicate that sparse decomposition provides a
practical instrument for exploring what scientific foundation models have
learned, an important prerequisite for moving from confirmation to genuine
discovery.
\\ ( https://arxiv.org/abs/2511.17735 ,  32005kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17747
Date: Fri, 21 Nov 2025 19:57:28 GMT   (31299kb)

Title: AEGIS: Preserving privacy of 3D Facial Avatars with Adversarial
 Perturbations
Authors: Dawid Wolkiewicz, Anastasiya Pechko, Przemys{\l}aw Spurek, Piotr Syga
Categories: cs.CV cs.AI
\\
 The growing adoption of photorealistic 3D facial avatars, particularly those
utilizing efficient 3D Gaussian Splatting representations, introduces new risks
of online identity theft, especially in systems that rely on biometric
authentication. While effective adversarial masking methods have been developed
for 2D images, a significant gap remains in achieving robust,
viewpoint-consistent identity protection for dynamic 3D avatars. To address
this, we present AEGIS, the first privacy-preserving identity masking framework
for 3D Gaussian Avatars that maintains the subject's perceived characteristics.
Our method aims to conceal identity-related facial features while preserving
the avatar's perceptual realism and functional integrity. AEGIS applies
adversarial perturbations to the Gaussian color coefficients, guided by a
pre-trained face verification network, ensuring consistent protection across
multiple viewpoints without retraining or modifying the avatar's geometry.
AEGIS achieves complete de-identification, reducing face retrieval and
verification accuracy to 0%, while maintaining high perceptual quality (SSIM =
0.9555, PSNR = 35.52 dB). It also preserves key facial attributes such as age,
race, gender, and emotion, demonstrating strong privacy protection with minimal
visual distortion.
\\ ( https://arxiv.org/abs/2511.17747 ,  31299kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17750
Date: Fri, 21 Nov 2025 20:02:08 GMT   (30812kb)

Title: SPIDER: Spatial Image CorresponDence Estimator for Robust Calibration
Authors: Zhimin Shao, Abhay Yadav, Rama Chellappa, Cheng Peng
Categories: cs.CV
\\
 Reliable image correspondences form the foundation of vision-based spatial
perception, enabling recovery of 3D structure and camera poses. However,
unconstrained feature matching across domains such as aerial, indoor, and
outdoor scenes remains challenging due to large variations in appearance, scale
and viewpoint. Feature matching has been conventionally formulated as a
2D-to-2D problem; however, recent 3D foundation models provides spatial feature
matching properties based on two-view geometry. While powerful, we observe that
these spatially coherent matches often concentrate on dominant planar regions,
e.g., walls or ground surfaces, while being less sensitive to fine-grained
geometric details, particularly under large viewpoint changes. To better
understand these trade-offs, we first perform linear probe experiments to
evaluate the performance of various vision foundation models for image
matching. Building on these insights, we introduce SPIDER, a universal feature
matching framework that integrates a shared feature extraction backbone with
two specialized network heads for estimating both 2D-based and 3D-based
correspondences from coarse to fine. Finally, we introduce an image-matching
evaluation benchmark that focuses on unconstrained scenarios with large
baselines. SPIDER significantly outperforms SoTA methods, demonstrating its
strong ability as a universal image-matching method.
\\ ( https://arxiv.org/abs/2511.17750 ,  30812kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17755
Date: Fri, 21 Nov 2025 20:14:55 GMT   (35939kb)

Title: CORA: Consistency-Guided Semi-Supervised Framework for Reasoning
 Segmentation
Authors: Prantik Howlader, Hoang Nguyen-Canh, Srijan Das, Jingyi Xu, Hieu Le
 and Dimitris Samaras
Categories: cs.CV
Comments: WACV 2026 accepted
\\
 Reasoning segmentation seeks pixel-accurate masks for targets referenced by
complex, often implicit instructions, requiring context-dependent reasoning
over the scene. Recent multimodal language models have advanced instruction
following segmentation, yet generalization remains limited. The key bottleneck
is the high cost of curating diverse, high-quality pixel annotations paired
with rich linguistic supervision leading to brittle performance under
distribution shift. Therefore, we present CORA, a semi-supervised reasoning
segmentation framework that jointly learns from limited labeled data and a
large corpus of unlabeled images. CORA introduces three main components: 1)
conditional visual instructions that encode spatial and contextual
relationships between objects; 2) a noisy pseudo-label filter based on the
consistency of Multimodal LLM's outputs across semantically equivalent queries;
and 3) a token-level contrastive alignment between labeled and pseudo-labeled
samples to enhance feature consistency. These components enable CORA to perform
robust reasoning segmentation with minimal supervision, outperforming existing
baselines under constrained annotation settings. CORA achieves state-of-the-art
results, requiring as few as 100 labeled images on Cityscapes, a benchmark
dataset for urban scene understanding, surpassing the baseline by $+2.3\%$.
Similarly, CORA improves performance by $+2.4\%$ with only 180 labeled images
on PanNuke, a histopathology dataset.
\\ ( https://arxiv.org/abs/2511.17755 ,  35939kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17757
Date: Fri, 21 Nov 2025 20:15:37 GMT   (1677kb)

Title: Latent Dirichlet Transformer VAE for Hyperspectral Unmixing with Bundled
 Endmembers
Authors: Giancarlo Giannetti and Faisal Z. Qureshi
Categories: cs.CV
\\
 Hyperspectral images capture rich spectral information that enables per-pixel
material identification; however, spectral mixing often obscures pure material
signatures. To address this challenge, we propose the Latent Dirichlet
Transformer Variational Autoencoder (LDVAE-T) for hyperspectral unmixing. Our
model combines the global context modeling capabilities of transformer
architectures with physically meaningful constraints imposed by a Dirichlet
prior in the latent space. This prior naturally enforces the sum-to-one and
non-negativity conditions essential for abundance estimation, thereby improving
the quality of predicted mixing ratios. A key contribution of LDVAE-T is its
treatment of materials as bundled endmembers, rather than relying on fixed
ground truth spectra. In the proposed method our decoder predicts, for each
endmember and each patch, a mean spectrum together with a structured
(segmentwise) covariance that captures correlated spectral variability.
Reconstructions are formed by mixing these learned bundles with
Dirichlet-distributed abundances garnered from a transformer encoder, allowing
the model to represent intrinsic material variability while preserving physical
interpretability. We evaluate our approach on three benchmark datasets, Samson,
Jasper Ridge, and HYDICE Urban and show that LDVAE-T consistently outperforms
state-of-the-art models in abundance estimation and endmember extraction, as
measured by root mean squared error and spectral angle distance, respectively.
\\ ( https://arxiv.org/abs/2511.17757 ,  1677kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17766
Date: Fri, 21 Nov 2025 20:30:10 GMT   (3765kb)

Title: Deepfake Geography: Detecting AI-Generated Satellite Images
Authors: Mansur Yerzhanuly
Categories: cs.CV
Comments: 18 pages, 8 figures
\\
 The rapid advancement of generative models such as StyleGAN2 and Stable
Diffusion poses a growing threat to the authenticity of satellite imagery,
which is increasingly vital for reliable analysis and decision-making across
scientific and security domains. While deepfake detection has been extensively
studied in facial contexts, satellite imagery presents distinct challenges,
including terrain-level inconsistencies and structural artifacts. In this
study, we conduct a comprehensive comparison between Convolutional Neural
Networks (CNNs) and Vision Transformers (ViTs) for detecting AI-generated
satellite images. Using a curated dataset of over 130,000 labeled RGB images
from the DM-AER and FSI datasets, we show that ViTs significantly outperform
CNNs in both accuracy (95.11 percent vs. 87.02 percent) and overall robustness,
owing to their ability to model long-range dependencies and global semantic
structures. We further enhance model transparency using architecture-specific
interpretability methods, including Grad-CAM for CNNs and Chefer's attention
attribution for ViTs, revealing distinct detection behaviors and validating
model trustworthiness. Our results highlight the ViT's superior performance in
detecting structural inconsistencies and repetitive textural patterns
characteristic of synthetic imagery. Future work will extend this research to
multispectral and SAR modalities and integrate frequency-domain analysis to
further strengthen detection capabilities and safeguard satellite imagery
integrity in high-stakes applications.
\\ ( https://arxiv.org/abs/2511.17766 ,  3765kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17792
Date: Fri, 21 Nov 2025 21:36:02 GMT   (34101kb)

Title: Target-Bench: Can World Models Achieve Mapless Path Planning with
 Semantic Targets?
Authors: Dingrui Wang, Hongyuan Ye, Zhihao Liang, Zhexiao Sun, Zhaowei Lu,
 Yuchen Zhang, Yuyu Zhao, Yuan Gao, Marvin Seegert, Finn Sch\"afer, Haotong
 Qin, Wei Li, Luigi Palmieri, Felix Jahncke, Mattia Piccinini, Johannes Betz
Categories: cs.CV cs.RO
Comments: 10 pages
\\
 While recent world models generate highly realistic videos, their ability to
perform robot path planning remains unclear and unquantified. We introduce
Target-Bench, the first benchmark specifically designed to evaluate world
models on mapless path planning toward semantic targets in real-world
environments. Target-Bench provides 450 robot-collected video sequences
spanning 45 semantic categories with SLAM-based ground truth trajectories. Our
evaluation pipeline recovers camera motion from generated videos and measures
planning performance using five complementary metrics that quantify
target-reaching capability, trajectory accuracy, and directional consistency.
We evaluate state-of-the-art models including Sora 2, Veo 3.1, and the Wan
series. The best off-the-shelf model (Wan2.2-Flash) achieves only 0.299 overall
score, revealing significant limitations in current world models for robotic
planning tasks. We show that fine-tuning an open-source 5B-parameter model on
only 325 scenarios from our dataset achieves 0.345 overall score -- an
improvement of more than 400% over its base version (0.066) and 15% higher than
the best off-the-shelf model. We will open-source the code and dataset.
\\ ( https://arxiv.org/abs/2511.17792 ,  34101kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17793
Date: Fri, 21 Nov 2025 21:36:48 GMT   (10155kb)

Title: Attention Guided Alignment in Efficient Vision-Language Models
Authors: Shweta Mahajan, Hoang Le, Hyojin Park, Farzad Farhadzadeh, Munawar
 Hayat, Fatih Porikli
Categories: cs.CV cs.LG
Comments: 39th Conference on Neural Information Processing Systems (NeurIPS
 2025) Workshop on Efficient Reasoning
\\
 Large Vision-Language Models (VLMs) rely on effective multimodal alignment
between pre-trained vision encoders and Large Language Models (LLMs) to
integrate visual and textual information. This paper presents a comprehensive
analysis of attention patterns in efficient VLMs, revealing that
concatenation-based architectures frequently fail to distinguish between
semantically matching and non-matching image-text pairs. This is a key factor
for object hallucination in these models. To address this, we introduce
Attention-Guided Efficient Vision-Language Models (AGE-VLM), a novel framework
that enhances visual grounding through interleaved cross-attention layers to
instill vision capabilities in pretrained small language models. This enforces
in VLM the ability "look" at the correct image regions by leveraging spatial
knowledge distilled from the Segment Anything Model (SAM), significantly
reducing hallucination. We validate our approach across different
vision-centric benchmarks where our method is better or comparable to prior
work on efficient VLMs. Our findings provide valuable insights for future
research aimed at achieving enhanced visual and linguistic understanding in
VLMs.
\\ ( https://arxiv.org/abs/2511.17793 ,  10155kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17803
Date: Fri, 21 Nov 2025 21:50:34 GMT   (16815kb)

Title: Pillar-0: A New Frontier for Radiology Foundation Models
Authors: Kumar Krishna Agrawal, Longchao Liu, Long Lian, Michael Nercessian,
 Natalia Harguindeguy, Yufu Wu, Peter Mikhael, Gigin Lin, Lecia V. Sequist,
 Florian Fintelmann, Trevor Darrell, Yutong Bai, Maggie Chung, Adam Yala
Categories: cs.CV cs.AI
\\
 Radiology plays an integral role in modern medicine, yet rising imaging
volumes have far outpaced workforce growth. Foundation models offer a path
toward assisting with the full spectrum of radiology tasks, but existing
medical models remain limited: they process volumetric CT and MRI as
low-fidelity 2D slices, discard critical grayscale contrast information, and
lack evaluation frameworks that reflect real clinical practice. We introduce
Pillar-0, a radiology foundation model pretrained on 42,990 abdomen-pelvis CTs,
86,411 chest CTs, 14,348 head CTs, and 11,543 breast MRIs from a large academic
center, together with RATE, a scalable framework that extracts structured
labels for 366 radiologic findings with near-perfect accuracy using LLMs.
Across internal test sets of 14,230 abdomen-pelvis CTs, 10,646 chest CTs, 4,906
head CTs, and 1,585 breast MRIs, Pillar-0 establishes a new performance
frontier, achieving mean AUROCs of 86.4, 88.0, 90.1, and 82.9, outperforming
MedGemma (Google), MedImageInsight (Microsoft), Lingshu (Alibaba), and Merlin
(Stanford) by 7.8-15.8 AUROC points and ranking best in 87.2\% (319/366) tasks.
Pillar-0 similarly outperforms all baselines in an external validation on the
Stanford Abdominal CT dataset, including Merlin (82.2 vs 80.6 AUROC). Pillar-0
extends to tasks beyond its pretraining, such as long-horizon lung cancer risk
prediction, where it improves upon the state-of-the-art Sybil by 3.0 C-index
points on NLST, and generalizes with gains of 5.9 (MGH) and 1.9 (CGMH). In
brain hemorrhage detection, Pillar-0 obtained a >95 AUROC when using only
1/20th of the data of the next most sample efficient baseline. Pillar-0 and
RATE together provide an open, clinically rigorous foundation for building
high-performance radiology systems, enabling applications that were previously
infeasible due to computational, data, and evaluation constraints.
\\ ( https://arxiv.org/abs/2511.17803 ,  16815kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17805
Date: Fri, 21 Nov 2025 21:59:22 GMT   (14083kb)

Title: A Stitch in Time: Learning Procedural Workflow via Self-Supervised
 Plackett-Luce Ranking
Authors: Chengan Che, Chao Wang, Xinyue Chen, Sophia Tsoka, Luis C.
 Garcia-Peraza-Herrera
Categories: cs.CV cs.AI
Comments: 18 pages
\\
 Procedural activities, ranging from routine cooking to complex surgical
operations, are highly structured as a set of actions conducted in a specific
temporal order. Despite their success on static images and short clips, current
self-supervised learning methods often overlook the procedural nature that
underpins such activities. We expose the lack of procedural awareness in
current SSL methods with a motivating experiment: models pretrained on forward
and time-reversed sequences produce highly similar features, confirming that
their representations are blind to the underlying procedural order. To address
this shortcoming, we propose PL-Stitch, a self-supervised framework that
harnesses the inherent temporal order of video frames as a powerful supervisory
signal. Our approach integrates two novel probabilistic objectives based on the
Plackett-Luce (PL) model. The primary PL objective trains the model to sort
sampled frames chronologically, compelling it to learn the global workflow
progression. The secondary objective, a spatio-temporal jigsaw loss,
complements the learning by capturing fine-grained, cross-frame object
correlations. Our approach consistently achieves superior performance across
five surgical and cooking benchmarks. Specifically, PL-Stitch yields
significant gains in surgical phase recognition (e.g., +11.4 pp k-NN accuracy
on Cholec80) and cooking action segmentation (e.g., +5.7 pp linear probing
accuracy on Breakfast), demonstrating its effectiveness for procedural video
representation learning.
\\ ( https://arxiv.org/abs/2511.17805 ,  14083kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17806
Date: Fri, 21 Nov 2025 21:59:24 GMT   (999kb)

Title: REXO: Indoor Multi-View Radar Object Detection via 3D Bounding Box
 Diffusion
Authors: Ryoma Yataka and Pu Perry Wang and Petros Boufounos and Ryuhei
 Takahashi
Categories: cs.CV cs.AI cs.LG eess.SP
Comments: 26 pages, Accepted to AAAI 2026; Code to be released
\\
 Multi-view indoor radar perception has drawn attention due to its
cost-effectiveness and low privacy risks. Existing methods often rely on
{implicit} cross-view radar feature association, such as proposal pairing in
RFMask or query-to-feature cross-attention in RETR, which can lead to ambiguous
feature matches and degraded detection in complex indoor scenes. To address
these limitations, we propose \textbf{REXO} (multi-view Radar object dEtection
with 3D bounding boX diffusiOn), which lifts the 2D bounding box (BBox)
diffusion process of DiffusionDet into the 3D radar space. REXO utilizes these
noisy 3D BBoxes to guide an {explicit} cross-view radar feature association,
enhancing the cross-view radar-conditioned denoising process. By accounting for
prior knowledge that the person is in contact with the ground, REXO reduces the
number of diffusion parameters by determining them from this prior. Evaluated
on two open indoor radar datasets, our approach surpasses state-of-the-art
methods by a margin of +4.22 AP on the HIBER dataset and +11.02 AP on the MMVR
dataset.
\\ ( https://arxiv.org/abs/2511.17806 ,  999kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17812
Date: Fri, 21 Nov 2025 22:05:56 GMT   (1541kb)

Title: Importance-Weighted Non-IID Sampling for Flow Matching Models
Authors: Xinshuang Liu, Runfa Blark Li, Shaoxiu Wei, Truong Nguyen
Categories: cs.CV cs.AI cs.LG
\\
 Flow-matching models effectively represent complex distributions, yet
estimating expectations of functions of their outputs remains challenging under
limited sampling budgets. Independent sampling often yields high-variance
estimates, especially when rare but with high-impact outcomes dominate the
expectation. We propose an importance-weighted non-IID sampling framework that
jointly draws multiple samples to cover diverse, salient regions of a flow's
distribution while maintaining unbiased estimation via estimated importance
weights. To balance diversity and quality, we introduce a score-based
regularization for the diversity mechanism, which uses the score function,
i.e., the gradient of the log probability, to ensure samples are pushed apart
within high-density regions of the data manifold, mitigating off-manifold
drift. We further develop the first approach for importance weighting of
non-IID flow samples by learning a residual velocity field that reproduces the
marginal distribution of the non-IID samples. Empirically, our method produces
diverse, high-quality samples and accurate estimates of both importance weights
and expectations, advancing the reliable characterization of flow-matching
model outputs. Our code will be publicly available on GitHub.
\\ ( https://arxiv.org/abs/2511.17812 ,  1541kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17824
Date: Fri, 21 Nov 2025 22:38:16 GMT   (17791kb)

Title: QAL: A Loss for Recall Precision Balance in 3D Reconstruction
Authors: Pranay Meshram, Yash Turkar, Kartikeya Singh, Praveen Raj Masilamani,
 Charuvahan Adhivarahan, Karthik Dantu
Categories: cs.CV cs.RO
Comments: Accepted to WACV 2026. Camera-ready version to appear
\\
 Volumetric learning underpins many 3D vision tasks such as completion,
reconstruction, and mesh generation, yet training objectives still rely on
Chamfer Distance (CD) or Earth Mover's Distance (EMD), which fail to balance
recall and precision. We propose Quality-Aware Loss (QAL), a drop-in
replacement for CD/EMD that combines a coverage-weighted nearest-neighbor term
with an uncovered-ground-truth attraction term, explicitly decoupling recall
and precision into tunable components.
 Across diverse pipelines, QAL achieves consistent coverage gains, improving
by an average of +4.3 pts over CD and +2.8 pts over the best alternatives.
Though modest in percentage, these improvements reliably recover thin
structures and under-represented regions that CD/EMD overlook. Extensive
ablations confirm stable performance across hyperparameters and across output
resolutions, while full retraining on PCN and ShapeNet demonstrates
generalization across datasets and backbones. Moreover, QAL-trained completions
yield higher grasp scores under GraspNet evaluation, showing that improved
coverage translates directly into more reliable robotic manipulation.
 QAL thus offers a principled, interpretable, and practical objective for
robust 3D vision and safety-critical robotics pipelines
\\ ( https://arxiv.org/abs/2511.17824 ,  17791kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17828
Date: Fri, 21 Nov 2025 22:45:50 GMT   (2989kb)

Title: Toward explainable AI approaches for breast imaging: adapting foundation
 models to diverse populations
Authors: Guilherme J. Cavalcante and Jos\'e Gabriel A. Moreira and Gabriel A.B.
 do Nascimento and Vincent Dong and Alex Nguyen and Tha\'is G. do R\^ego and
 Yuri Malheiros and Telmo M. Silva Filho and Carla R. Zeballos Torrez and
 James C. Gee and Anne Marie McCarthy and Andrew D. A. Maidment and Bruno
 Barufaldi
Categories: cs.CV cs.AI
Comments: 5 pages, 3 figures
\\
 Foundation models hold promise for specialized medical imaging tasks, though
their effectiveness in breast imaging remains underexplored. This study
leverages BiomedCLIP as a foundation model to address challenges in model
generalization. BiomedCLIP was adapted for automated BI-RADS breast density
classification using multi-modality mammographic data (synthesized 2D images,
digital mammography, and digital breast tomosynthesis). Using 96,995 images, we
compared single-modality (s2D only) and multi-modality training approaches,
addressing class imbalance through weighted contrastive learning. Both
approaches achieved similar accuracy (multi-modality: 0.74, single-modality:
0.73), with the multi-modality model offering broader applicability across
different imaging modalities and higher AUC values consistently above 0.84
across BI-RADS categories. External validation on the RSNA and EMBED datasets
showed strong generalization capabilities (AUC range: 0.80-0.93). GradCAM
visualizations confirmed consistent and clinically relevant attention patterns,
highlighting the models interpretability and robustness. This research
underscores the potential of foundation models for breast imaging applications,
paving the way for future extensions for diagnostic tasks.
\\ ( https://arxiv.org/abs/2511.17828 ,  2989kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17839
Date: Fri, 21 Nov 2025 23:24:28 GMT   (5781kb)

Title: Show Me: Unifying Instructional Image and Video Generation with
 Diffusion Models
Authors: Yujiang Pu, Zhanbo Huang, Vishnu Boddeti, and Yu Kong
Categories: cs.CV
Comments: Accepted by WACV 2026
\\
 Generating visual instructions in a given context is essential for developing
interactive world simulators. While prior works address this problem through
either text-guided image manipulation or video prediction, these tasks are
typically treated in isolation. This separation reveals a fundamental issue:
image manipulation methods overlook how actions unfold over time, while video
prediction models often ignore the intended outcomes. To this end, we propose
ShowMe, a unified framework that enables both tasks by selectively activating
the spatial and temporal components of video diffusion models. In addition, we
introduce structure and motion consistency rewards to improve structural
fidelity and temporal coherence. Notably, this unification brings dual
benefits: the spatial knowledge gained through video pretraining enhances
contextual consistency and realism in non-rigid image edits, while the
instruction-guided manipulation stage equips the model with stronger
goal-oriented reasoning for video prediction. Experiments on diverse benchmarks
demonstrate that our method outperforms expert models in both instructional
image and video generation, highlighting the strength of video diffusion models
as a unified action-object state transformer.
\\ ( https://arxiv.org/abs/2511.17839 ,  5781kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17843
Date: Fri, 21 Nov 2025 23:36:24 GMT   (1906kb)

Title: JigsawComm: Joint Semantic Feature Encoding and Transmission for
 Communication-Efficient Cooperative Perception
Authors: Chenyi Wang, Zhaowei Li, Ming F. Li, Wujie Wen
Categories: cs.CV
\\
 Multi-agent cooperative perception (CP) promises to overcome the inherent
occlusion and sensing-range limitations of single-agent systems (e.g.,
autonomous driving). However, its practicality is severely constrained by the
limited communication bandwidth. Existing approaches attempt to improve
bandwidth efficiency via compression or heuristic message selection, without
considering the semantic relevance or cross-agent redundancy of sensory data.
We argue that a practical CP system must maximize the contribution of every
transmitted bit to the final perception task, by extracting and transmitting
semantically essential and non-redundant data. In this paper, we formulate a
joint semantic feature encoding and transmission problem, which aims to
maximize CP accuracy under limited bandwidth. To solve this problem, we
introduce JigsawComm, an end-to-end trained, semantic-aware, and
communication-efficient CP framework that learns to ``assemble the puzzle'' of
multi-agent feature transmission. It uses a regularized encoder to extract
semantically-relevant and sparse features, and a lightweight Feature Utility
Estimator to predict the contribution of each agent's features to the final
perception task. The resulting meta utility maps are exchanged among agents and
leveraged to compute a provably optimal transmission policy, which selects
features from agents with the highest utility score for each location. This
policy inherently eliminates redundancy and achieves a scalable
$\mathcal{O}(1)$ communication cost as the number of agents increases. On the
benchmarks OPV2V and DAIR-V2X, JigsawComm reduces the total data volume by up
to $>$500$\times$ while achieving matching or superior accuracy compared to
state-of-the-art methods.
\\ ( https://arxiv.org/abs/2511.17843 ,  1906kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17844
Date: Fri, 21 Nov 2025 23:41:19 GMT   (9234kb)

Title: Less is More: Data-Efficient Adaptation for Controllable Text-to-Video
 Generation
Authors: Shihan Cheng, Nilesh Kulkarni, David Hyde, Dmitriy Smirnov
Categories: cs.CV cs.AI
MSC-class: 68U05
ACM-class: I.3.3; I.5.4
\\
 Fine-tuning large-scale text-to-video diffusion models to add new generative
controls, such as those over physical camera parameters (e.g., shutter speed or
aperture), typically requires vast, high-fidelity datasets that are difficult
to acquire. In this work, we propose a data-efficient fine-tuning strategy that
learns these controls from sparse, low-quality synthetic data. We show that not
only does fine-tuning on such simple data enable the desired controls, it
actually yields superior results to models fine-tuned on photorealistic "real"
data. Beyond demonstrating these results, we provide a framework that justifies
this phenomenon both intuitively and quantitatively.
\\ ( https://arxiv.org/abs/2511.17844 ,  9234kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17881
Date: Sat, 22 Nov 2025 02:17:42 GMT   (1897kb)

Title: MGA-VQA: Secure and Interpretable Graph-Augmented Visual Question
 Answering with Memory-Guided Protection Against Unauthorized Knowledge Use
Authors: Ahmad Mohammadshirazi, Pinaki Prasad Guha Neogi, Dheeraj Kulshrestha,
 Rajiv Ramnath
Categories: cs.CV cs.AI
\\
 Document Visual Question Answering (DocVQA) requires models to jointly
understand textual semantics, spatial layout, and visual features. Current
methods struggle with explicit spatial relationship modeling, inefficiency with
high-resolution documents, multi-hop reasoning, and limited interpretability.
We propose MGA-VQA, a multi-modal framework that integrates token-level
encoding, spatial graph reasoning, memory-augmented inference, and
question-guided compression. Unlike prior black-box models, MGA-VQA introduces
interpretable graph-based decision pathways and structured memory access for
enhanced reasoning transparency. Evaluation across six benchmarks (FUNSD, CORD,
SROIE, DocVQA, STE-VQA, and RICO) demonstrates superior accuracy and
efficiency, with consistent improvements in both answer prediction and spatial
localization.
\\ ( https://arxiv.org/abs/2511.17881 ,  1897kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17883
Date: Sat, 22 Nov 2025 02:19:53 GMT   (22895kb)

Title: ArticFlow: Generative Simulation of Articulated Mechanisms
Authors: Jiong Lin, Jinchen Ruan, Hod Lipson
Categories: cs.CV cs.RO
Comments: 8 pages, 8 figures
\\
 Recent advances in generative models have produced strong results for static
3D shapes, whereas articulated 3D generation remains challenging due to
action-dependent deformations and limited datasets. We introduce ArticFlow, a
two-stage flow matching framework that learns a controllable velocity field
from noise to target point sets under explicit action control. ArticFlow
couples (i) a latent flow that transports noise to a shape-prior code and (ii)
a point flow that transports points conditioned on the action and the shape
prior, enabling a single model to represent diverse articulated categories and
generalize across actions. On MuJoCo Menagerie, ArticFlow functions both as a
generative model and as a neural simulator: it predicts action-conditioned
kinematics from a compact prior and synthesizes novel morphologies via latent
interpolation. Compared with object-specific simulators and an
action-conditioned variant of static point-cloud generators, ArticFlow achieves
higher kinematic accuracy and better shape quality. Results show that
action-conditioned flow matching is a practical route to controllable and
high-quality articulated mechanism generation.
\\ ( https://arxiv.org/abs/2511.17883 ,  22895kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17885
Date: Sat, 22 Nov 2025 02:25:00 GMT   (5675kb)

Title: FastMMoE: Accelerating Multimodal Large Language Models through Dynamic
 Expert Activation and Routing-Aware Token Pruning
Authors: Guoyang Xia, Yifeng Ding, Fengfa Li, Lei Ren, Wei Chen, Fangxiang
 Feng, Xiaojie Wang
Categories: cs.CV cs.LG
\\
 Multimodal large language models (MLLMs) have achieved impressive
performance, but high-resolution visual inputs result in long sequences of
visual tokens and substantial inference latency. Reducing redundant visual
tokens is critical to ease computational/memory burdens while preserving
performance, enabling MLLM deployment in resource-constrained or
latency-sensitive scenarios. Current visual token pruning methods mainly rely
on attention-based redundancy analysis and are tailored to dense architectures.
We propose Fast Multimodal Mixture-of-Experts (FastMMoE), a training-free
acceleration framework for mixture-of-experts (MoE) based MLLMs, developed from
a routing analysis perspective. FastMMoE combines two complementary strategies:
(i) expert activation reduction for visual tokens to minimize unnecessary
expert computation; and (ii) routing-aware token pruning that leverages
similarity in routing probability distributions to identify and remove highly
redundant visual tokens. Experiments on large-scale MoE-MLLMs such as
DeepSeek-VL2 and InternVL3.5 demonstrate that FastMMoE can reduce FLOPs by up
to 55.0% while retaining approximately 95.5% of the original performance,
consistently outperforming dense-model pruning baselines including FastV and
SparseVLM across multiple retention rates.
\\ ( https://arxiv.org/abs/2511.17885 ,  5675kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17886
Date: Sat, 22 Nov 2025 02:30:18 GMT   (215kb)

Title: When Better Teachers Don't Make Better Students: Revisiting Knowledge
 Distillation for CLIP Models in VQA
Authors: Pume Tuchinda, Parinthapat Pengpun, Romrawin Chumpu, Sarana Nutanong,
 Peerat Limkonchotiwat
Categories: cs.CV cs.CL
\\
 Vision-language models (VLMs) have achieved remarkable success across
multimodal tasks, yet their substantial computational demands hinder efficient
deployment. Knowledge distillation (KD) has emerged as a powerful approach for
building lightweight but competitive models, with strong evidence from both
language and vision domains. However, its application to VLMs, particularly
CLIP-style models, remains limited, often constrained to small-scale teachers
and narrow evaluation tasks such as classification or retrieval. In this work,
we present the first systematic study of distillation across a range of
CLIP-style teacher models, ranging from standard baselines to large-scale
state-of-the-art models. Contrary to trends observed in NLP and vision, we find
that stronger teachers do not consistently yield better students; in fact,
existing distillation frameworks often fail to scale, leading to degraded
performance in downstream multimodal tasks such as visual question answering.
Our findings challenge prevailing assumptions in KD and point toward new
directions for designing parameter-efficient multimodal models.
\\ ( https://arxiv.org/abs/2511.17886 ,  215kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17888
Date: Sat, 22 Nov 2025 02:32:19 GMT   (22566kb)

Title: MINDiff: Mask-Integrated Negative Attention for Controlling Overfitting
 in Text-to-Image Personalization
Authors: Seulgi Jeong, Jaeil Kim
Categories: cs.CV
Comments: Accepted at ICCV 2025 Personalization in Generative AI Workshop
\\
 In the personalization process of large-scale text-to-image models,
overfitting often occurs when learning specific subject from a limited number
of images. Existing methods, such as DreamBooth, mitigate this issue through a
class-specific prior-preservation loss, which requires increased computational
cost during training and limits user control during inference time. To address
these limitations, we propose Mask-Integrated Negative Attention Diffusion
(MINDiff). MINDiff introduces a novel concept, negative attention, which
suppresses the subject's influence in masked irrelevant regions. We achieve
this by modifying the cross-attention mechanism during inference. This enables
semantic control and improves text alignment by reducing subject dominance in
irrelevant regions. Additionally, during the inference time, users can adjust a
scale parameter lambda to balance subject fidelity and text alignment. Our
qualitative and quantitative experiments on DreamBooth models demonstrate that
MINDiff mitigates overfitting more effectively than class-specific
prior-preservation loss. As our method operates entirely at inference time and
does not alter the model architecture, it can be directly applied to existing
DreamBooth models without re-training. Our code is available at
https://github.com/seuleepy/MINDiff.
\\ ( https://arxiv.org/abs/2511.17888 ,  22566kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17890
Date: Sat, 22 Nov 2025 02:36:50 GMT   (1835kb)

Title: Decoupled Audio-Visual Dataset Distillation
Authors: Wenyuan Li, Guang Li, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama
Categories: cs.CV cs.AI cs.MM
\\
 Audio-Visual Dataset Distillation aims to compress large-scale datasets into
compact subsets while preserving the performance of the original data. However,
conventional Distribution Matching (DM) methods struggle to capture intrinsic
cross-modal alignment. Subsequent studies have attempted to introduce
cross-modal matching, but two major challenges remain: (i) independently and
randomly initialized encoders lead to inconsistent modality mapping spaces,
increasing training difficulty; and (ii) direct interactions between modalities
tend to damage modality-specific (private) information, thereby degrading the
quality of the distilled data. To address these challenges, we propose DAVDD, a
pretraining-based decoupled audio-visual distillation framework. DAVDD
leverages a diverse pretrained bank to obtain stable modality features and uses
a lightweight decoupler bank to disentangle them into common and private
representations. To effectively preserve cross-modal structure, we further
introduce Common Intermodal Matching together with a Sample-Distribution Joint
Alignment strategy, ensuring that shared representations are aligned both at
the sample level and the global distribution level. Meanwhile, private
representations are entirely isolated from cross-modal interaction,
safeguarding modality-specific cues throughout distillation. Extensive
experiments across multiple benchmarks show that DAVDD achieves
state-of-the-art results under all IPC settings, demonstrating the
effectiveness of decoupled representation learning for high-quality
audio-visual dataset distillation. Code will be released.
\\ ( https://arxiv.org/abs/2511.17890 ,  1835kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17904
Date: Sat, 22 Nov 2025 03:42:49 GMT   (16644kb)

Title: CUS-GS: A Compact Unified Structured Gaussian Splatting Framework for
 Multimodal Scene Representation
Authors: Yuhang Ming, Chenxin Fang, Xingyuan Yu, Fan Zhang, Weichen Dai,
 Wanzeng Kong, Guofeng Zhang
Categories: cs.CV cs.RO
Comments: 15 pages, 8 figures, 4 tables
\\
 Recent advances in Gaussian Splatting based 3D scene representation have
shown two major trends: semantics-oriented approaches that focus on high-level
understanding but lack explicit 3D geometry modeling, and structure-oriented
approaches that capture spatial structures yet provide limited semantic
abstraction. To bridge this gap, we present CUS-GS, a compact unified
structured Gaussian Splatting representation, which connects multimodal
semantic features with structured 3D geometry. Specifically, we design a
voxelized anchor structure that constructs a spatial scaffold, while extracting
multimodal semantic features from a set of foundation models (e.g., CLIP,
DINOv2, SEEM). Moreover, we introduce a multimodal latent feature allocation
mechanism to unify appearance, geometry, and semantics across heterogeneous
feature spaces, ensuring a consistent representation across multiple foundation
models. Finally, we propose a feature-aware significance evaluation strategy to
dynamically guide anchor growing and pruning, effectively removing redundant or
invalid anchors while maintaining semantic integrity. Extensive experiments
show that CUS-GS achieves competitive performance compared to state-of-the-art
methods using as few as 6M parameters - an order of magnitude smaller than the
closest rival at 35M - highlighting the excellent trade off between performance
and model efficiency of the proposed framework.
\\ ( https://arxiv.org/abs/2511.17904 ,  16644kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17914
Date: Sat, 22 Nov 2025 04:37:27 GMT   (11590kb)

Title: Rectifying Soft-Label Entangled Bias in Long-Tailed Dataset Distillation
Authors: Chenyang Jiang, Hang Zhao, Xinyu Zhang, Zhengcen Li, Qiben Shan,
 Shaocong Wu, Jingyong Su
Categories: cs.CV cs.AI
Comments: 10 pages, accepted by NeurIPS 2025
MSC-class: I.2
\\
 Dataset distillation compresses large-scale datasets into compact, highly
informative synthetic data, significantly reducing storage and training costs.
However, existing research primarily focuses on balanced datasets and struggles
to perform under real-world long-tailed distributions. In this work, we
emphasize the critical role of soft labels in long-tailed dataset distillation
and uncover the underlying mechanisms contributing to performance degradation.
Specifically, we derive an imbalance-aware generalization bound for model
trained on distilled dataset. We then identify two primary sources of
soft-label bias, which originate from the distillation model and the distilled
images, through systematic perturbation of the data imbalance levels. To
address this, we propose ADSA, an Adaptive Soft-label Alignment module that
calibrates the entangled biases. This lightweight module integrates seamlessly
into existing distillation pipelines and consistently improves performance. On
ImageNet-1k-LT with EDC and IPC=50, ADSA improves tail-class accuracy by up to
11.8% and raises overall accuracy to 41.4%. Extensive experiments demonstrate
that ADSA provides a robust and generalizable solution under limited label
budgets and across a range of distillation techniques. Code is available at:
https://github.com/j-cyoung/ADSA_DD.git.
\\ ( https://arxiv.org/abs/2511.17914 ,  11590kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17918
Date: Sat, 22 Nov 2025 05:04:46 GMT   (16125kb)

Title: Frequency-Adaptive Sharpness Regularization for Improving 3D Gaussian
 Splatting Generalization
Authors: Youngsik Yun, Dongjun Gu, Youngjung Uh
Categories: cs.CV
Comments: Project page: https://bbangsik13.github.io/FASR
\\
 Despite 3D Gaussian Splatting (3DGS) excelling in most configurations, it
lacks generalization across novel viewpoints in a few-shot scenario because it
overfits to the sparse observations. We revisit 3DGS optimization from a
machine learning perspective, framing novel view synthesis as a generalization
problem to unseen viewpoints-an underexplored direction. We propose
Frequency-Adaptive Sharpness Regularization (FASR), which reformulates the 3DGS
training objective, thereby guiding 3DGS to converge toward a better
generalization solution. Although Sharpness-Aware Minimization (SAM) similarly
reduces the sharpness of the loss landscape to improve generalization of
classification models, directly employing it to 3DGS is suboptimal due to the
discrepancy between the tasks. Specifically, it hinders reconstructing
high-frequency details due to excessive regularization, while reducing its
strength leads to under-penalizing sharpness. To address this, we reflect the
local frequency of images to set the regularization weight and the neighborhood
radius when estimating the local sharpness. It prevents floater artifacts in
novel viewpoints and reconstructs fine details that SAM tends to oversmooth.
Across datasets with various configurations, our method consistently improves a
wide range of baselines. Code will be available at
https://bbangsik13.github.io/FASR.
\\ ( https://arxiv.org/abs/2511.17918 ,  16125kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17927
Date: Sat, 22 Nov 2025 05:55:08 GMT   (2112kb)

Title: PA-FAS: Towards Interpretable and Generalizable Multimodal Face
 Anti-Spoofing via Path-Augmented Reinforcement Learning
Authors: Yingjie Ma, Xun Lin, Yong Xu, Weicheng Xie, Zitong Yu
Categories: cs.CV cs.AI
Comments: Accepted by AAAI 2026 (Oral)
\\
 Face anti-spoofing (FAS) has recently advanced in multimodal fusion,
cross-domain generalization, and interpretability. With large language models
and reinforcement learning (RL), strategy-based training offers new
opportunities to jointly model these aspects. However, multimodal reasoning is
more complex than unimodal reasoning, requiring accurate feature representation
and cross-modal verification while facing scarce, high-quality annotations,
which makes direct application of RL sub-optimal. We identify two key
limitations of supervised fine-tuning plus RL (SFT+RL) for multimodal FAS: (1)
limited multimodal reasoning paths restrict the use of complementary modalities
and shrink the exploration space after SFT, weakening the effect of RL; and (2)
mismatched single-task supervision versus diverse reasoning paths causes
reasoning confusion, where models may exploit shortcuts by mapping images
directly to answers and ignoring the intended reasoning. To address this, we
propose PA-FAS, which enhances reasoning paths by constructing high-quality
extended reasoning sequences from limited annotations, enriching paths and
relaxing exploration constraints. We further introduce an answer-shuffling
mechanism during SFT to force comprehensive multimodal analysis instead of
using superficial cues, thereby encouraging deeper reasoning and mitigating
shortcut learning. PA-FAS significantly improves multimodal reasoning accuracy
and cross-domain generalization, and better unifies multimodal fusion,
generalization, and interpretability for trustworthy FAS.
\\ ( https://arxiv.org/abs/2511.17927 ,  2112kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17929
Date: Sat, 22 Nov 2025 06:04:29 GMT   (3442kb)

Title: MambaTAD: When State-Space Models Meet Long-Range Temporal Action
 Detection
Authors: Hui Lu, Yi Yu, Shijian Lu, Deepu Rajan, Boon Poh Ng, Alex C. Kot,
 Xudong Jiang
Categories: cs.CV cs.AI
Journal-ref: IEEE Transactions on Multimedia, 2025
\\
 Temporal Action Detection (TAD) aims to identify and localize actions by
determining their starting and ending frames within untrimmed videos. Recent
Structured State-Space Models such as Mamba have demonstrated potential in TAD
due to their long-range modeling capability and linear computational
complexity. On the other hand, structured state-space models often face two key
challenges in TAD, namely, decay of temporal context due to recursive
processing and self-element conflict during global visual context modeling,
which become more severe while handling long-span action instances.
Additionally, traditional methods for TAD struggle with detecting long-span
action instances due to a lack of global awareness and inefficient detection
heads. This paper presents MambaTAD, a new state-space TAD model that
introduces long-range modeling and global feature detection capabilities for
accurate temporal action detection. MambaTAD comprises two novel designs that
complement each other with superior TAD performance. First, it introduces a
Diagonal-Masked Bidirectional State-Space (DMBSS) module which effectively
facilitates global feature fusion and temporal action detection. Second, it
introduces a global feature fusion head that refines the detection
progressively with multi-granularity features and global awareness. In
addition, MambaTAD tackles TAD in an end-to-end one-stage manner using a new
state-space temporal adapter(SSTA) which reduces network parameters and
computation cost with linear complexity. Extensive experiments show that
MambaTAD achieves superior TAD performance consistently across multiple public
benchmarks.
\\ ( https://arxiv.org/abs/2511.17929 ,  3442kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17930
Date: Sat, 22 Nov 2025 06:05:01 GMT   (738kb)

Title: UniRSCD: A Unified Novel Architectural Paradigm for Remote Sensing
 Change Detection
Authors: Yuan Qu, Zhipeng Zhang, Chaojun Xu, Qiao Wan, Mengying Xie, Yuzeng
 Chen, Zhenqi Liu, Yanfei Zhong
Categories: cs.CV
\\
 In recent years, remote sensing change detection has garnered significant
attention due to its critical role in resource monitoring and disaster
assessment. Change detection tasks exist with different output granularities
such as BCD, SCD, and BDA. However, existing methods require substantial expert
knowledge to design specialized decoders that compensate for information loss
during encoding across different tasks. This not only introduces uncertainty
into the process of selecting optimal models for abrupt change scenarios (such
as disaster outbreaks) but also limits the universality of these architectures.
To address these challenges, this paper proposes a unified, general change
detection framework named UniRSCD. Building upon a state space model backbone,
we introduce a frequency change prompt generator as a unified encoder. The
encoder dynamically scans bitemporal global context information while
integrating high-frequency details with low-frequency holistic information,
thereby eliminating the need for specialized decoders for feature compensation.
Subsequently, the unified decoder and prediction head establish a shared
representation space through hierarchical feature interaction and task-adaptive
output mapping. This integrating various tasks such as binary change detection
and semantic change detection into a unified architecture, thereby
accommodating the differing output granularity requirements of distinct change
detection tasks. Experimental results demonstrate that the proposed
architecture can adapt to multiple change detection tasks and achieves leading
performance on five datasets, including the binary change dataset LEVIR-CD, the
semantic change dataset SECOND, and the building damage assessment dataset xBD.
\\ ( https://arxiv.org/abs/2511.17930 ,  738kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17932
Date: Sat, 22 Nov 2025 06:08:29 GMT   (23672kb)

Title: Novel View Synthesis from A Few Glimpses via Test-Time Natural Video
 Completion
Authors: Yan Xu and Yixing Wang and Stella X. Yu
Categories: cs.CV cs.GR
Comments: Accepted to NeurIPS 2025
\\
 Given just a few glimpses of a scene, can you imagine the movie playing out
as the camera glides through it? That's the lens we take on \emph{sparse-input
novel view synthesis}, not only as filling spatial gaps between widely spaced
views, but also as \emph{completing a natural video} unfolding through space.
 We recast the task as \emph{test-time natural video completion}, using
powerful priors from \emph{pretrained video diffusion models} to hallucinate
plausible in-between views. Our \emph{zero-shot, generation-guided} framework
produces pseudo views at novel camera poses, modulated by an
\emph{uncertainty-aware mechanism} for spatial coherence. These synthesized
frames densify supervision for \emph{3D Gaussian Splatting} (3D-GS) for scene
reconstruction, especially in under-observed regions. An iterative feedback
loop lets 3D geometry and 2D view synthesis inform each other, improving both
the scene reconstruction and the generated views.
 The result is coherent, high-fidelity renderings from sparse inputs
\emph{without any scene-specific training or fine-tuning}. On LLFF, DTU, DL3DV,
and MipNeRF-360, our method significantly outperforms strong 3D-GS baselines
under extreme sparsity.
\\ ( https://arxiv.org/abs/2511.17932 ,  23672kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17941
Date: Sat, 22 Nov 2025 06:50:47 GMT   (14265kb)

Title: V2X-RECT: An Efficient V2X Trajectory Prediction Framework via Redundant
 Interaction Filtering and Tracking Error Correction
Authors: Xiangyan Kong, Xuecheng Wu, Xiongwei Zhao, Xiaodong Li, Yunyun Shi,
 Gang Wang, Dingkang Yang, Yang Liu, Hong Chen, Yulong Gao
Categories: cs.CV
\\
 V2X prediction can alleviate perception incompleteness caused by limited line
of sight through fusing trajectory data from infrastructure and vehicles, which
is crucial to traffic safety and efficiency. However, in dense traffic
scenarios, frequent identity switching of targets hinders cross-view
association and fusion. Meanwhile, multi-source information tends to generate
redundant interactions during the encoding stage, and traditional
vehicle-centric encoding leads to large amounts of repetitive historical
trajectory feature encoding, degrading real-time inference performance. To
address these challenges, we propose V2X-RECT, a trajectory prediction
framework designed for high-density environments. It enhances data association
consistency, reduces redundant interactions, and reuses historical information
to enable more efficient and accurate prediction. Specifically, we design a
multi-source identity matching and correction module that leverages multi-view
spatiotemporal relationships to achieve stable and consistent target
association, mitigating the adverse effects of mismatches on trajectory
encoding and cross-view feature fusion. Then we introduce traffic signal-guided
interaction module, encoding trend of traffic light changes as features and
exploiting their role in constraining spatiotemporal passage rights to
accurately filter key interacting vehicles, while capturing the dynamic impact
of signal changes on interaction patterns. Furthermore, a local spatiotemporal
coordinate encoding enables reusable features of historical trajectories and
map, supporting parallel decoding and significantly improving inference
efficiency. Extensive experimental results across V2X-Seq and V2X-Traj datasets
demonstrate that our V2X-RECT achieves significant improvements compared to
SOTA methods, while also enhancing robustness and inference efficiency across
diverse traffic densities.
\\ ( https://arxiv.org/abs/2511.17941 ,  14265kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17943
Date: Sat, 22 Nov 2025 06:54:16 GMT   (2780kb)

Title: SciEducator: Scientific Video Understanding and Educating via
 Deming-Cycle Multi-Agent System
Authors: Zhiyu Xu, Weilong Yan, Yufei Shi, Xin Meng, Tao He, Huiping Zhuang,
 Ming Li, Hehe Fan
Categories: cs.CV
\\
 Recent advancements in multimodal large language models (MLLMs) and video
agent systems have significantly improved general video understanding. However,
when applied to scientific video understanding and educating, a domain that
demands external professional knowledge integration and rigorous step-wise
reasoning, existing approaches often struggle. To bridge this gap, we propose
SciEducator, the first iterative self-evolving multi-agent system for
scientific video comprehension and education. Rooted in the classical Deming
Cycle from management science, our design reformulates its Plan-Do-Study-Act
philosophy into a self-evolving reasoning and feedback mechanism, which
facilitates the interpretation of intricate scientific activities in videos.
Moreover, SciEducator can produce multimodal educational content tailored to
specific scientific processes, including textual instructions, visual guides,
audio narrations, and interactive references. To support evaluation, we
construct SciVBench, a benchmark consisting of 500 expert-verified and
literature-grounded science QA pairs across five categories, covering physical,
chemical, and everyday phenomena. Extensive experiments demonstrate that
SciEducator substantially outperforms leading closed-source MLLMs (e.g.,
Gemini, GPT-4o) and state-of-the-art video agents on the benchmark,
establishing a new paradigm for the community.
\\ ( https://arxiv.org/abs/2511.17943 ,  2780kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17945
Date: Sat, 22 Nov 2025 06:59:21 GMT   (244kb)

Title: Test-Time Temporal Sampling for Efficient MLLM Video Understanding
Authors: Kaibin Wang, Mingbao Lin
Categories: cs.CV
\\
 Processing long videos with multimodal large language models (MLLMs) poses a
significant computational challenge, as the model's self-attention mechanism
scales quadratically with the number of video tokens, resulting in high
computational demand and slow inference speed. Current solutions, such as
rule-based sub-sampling, learned frame selector, or memory-based summarization,
often introduce their own trade-offs: they compromise accuracy, necessitate
additional training, or decrease inference speed. In this paper, we propose
Test-Time Temporal Sampling (T3S), a training-free, plug-and-play inference
wrapper that enables MLLMs to process long videos both efficiently and
effectively. T3S exploits spatiotemporal redundancy by generating multiple
short and diverse subsequences of video tokens at inference time, packing them
within a single forward pass, and aggregating their predictions. This
multi-subsequence formulation broadens visual coverage while reducing the
computational cost of self-attention from $O(L^2)$ to $O(\sum_{i=1}^m
\alpha_i^2L^2)$, where $\sum_{i=1}^m \alpha_i^2 < 1$. Extensive experiments on
long video understanding benchmarks demonstrate that T3S improves accuracy by
up to 3.1% and reduces first token delay by $2.04\times$, all with minimal
integration effort. Our approach operates entirely at inference time, requires
no model modifications or fine-tuning, and is compatible with a wide range of
pretrained MLLMs. T3S turns video redundancy into a computational advantage,
offering a scalable solution for long-video understanding. The code is
available at https://github.com/kaibinwang3/T3S.
\\ ( https://arxiv.org/abs/2511.17945 ,  244kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17952
Date: Sat, 22 Nov 2025 07:35:47 GMT   (3121kb)

Title: Multi-speaker Attention Alignment for Multimodal Social Interaction
Authors: Liangyang Ouyang, Yifei Huang, Mingfang Zhang, Caixin Kang, Ryosuke
 Furuta, Yoichi Sato
Categories: cs.CV
\\
 Understanding social interaction in video requires reasoning over a dynamic
interplay of verbal and non-verbal cues: who is speaking, to whom, and with
what gaze or gestures. While Multimodal Large Language Models (MLLMs) are
natural candidates, simply adding visual inputs yields surprisingly
inconsistent gains on social tasks. Our quantitative analysis of cross-modal
attention inside state-of-the-art MLLMs reveals a core failure mode: in
multi-speaker scenes, visual and textual tokens lack speaker-consistent
alignment, exhibiting substantially weaker cross-modal attention than in
object-centric images. To address this, we propose a multimodal multi-speaker
attention alignment method that can be integrated into existing MLLMs. First,
we introduce dynamic cross-modal head selection to identify attention heads
most responsible for grounding. Then, an adaptive social-aware attention bias,
computed from existing attention patterns and speaker locations, is injected
into the attention mechanism. This bias reinforces alignment between a
speaker's visual representation and their utterances without introducing
trainable parameters or architectural changes. We integrate our method into
three distinct MLLMs (LLaVA-NeXT-Video, Qwen2.5-VL, and InternVL3) and evaluate
on three benchmarks (TVQA+, MMSI, OnlineMMSI). Across four social tasks,
results demonstrate that our approach improves the ability of MLLMs and
achieves state-of-the-art results. Attention visualizations confirm our method
successfully focuses the model on speaker-relevant regions, enabling more
robust multi-party social reasoning. Our implementation and model will be
available at https://github.com/ut-vision/SocialInteraction.
\\ ( https://arxiv.org/abs/2511.17952 ,  3121kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17958
Date: Sat, 22 Nov 2025 07:50:09 GMT   (3714kb)

Title: HEAL: Learning-Free Source Free Unsupervised Domain Adaptation for
 Cross-Modality Medical Image Segmentation
Authors: Yulong Shi, Jiapeng Li and Lin Qi
Categories: cs.CV
Comments: Accepted by The 36th British Machine Vision Conference (BMVC 2025)
\\
 Growing demands for clinical data privacy and storage constraints have
spurred advances in Source Free Unsupervised Domain Adaptation (SFUDA). SFUDA
addresses the domain shift by adapting models from the source domain to the
unseen target domain without accessing source data, even when target-domain
labels are unavailable. However, SFUDA faces significant challenges: the
absence of source domain data and label supervision in the target domain due to
source free and unsupervised settings. To address these issues, we propose
HEAL, a novel SFUDA framework that integrates Hierarchical denoising,
Edge-guided selection, size-Aware fusion, and Learning-free characteristic.
Large-scale cross-modality experiments demonstrate that our method outperforms
existing SFUDA approaches, achieving state-of-the-art (SOTA) performance. The
source code is publicly available at: https://github.com/derekshiii/HEAL.
\\ ( https://arxiv.org/abs/2511.17958 ,  3714kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17962
Date: Sat, 22 Nov 2025 07:55:21 GMT   (4410kb)

Title: VITAL: Vision-Encoder-centered Pre-training for LMMs in Visual Quality
 Assessment
Authors: Ziheng Jia, Linhan Cao, Jinliang Han, Zicheng Zhang, Jiaying Qian,
 Jiarui Wang, Zijian Chen, Guangtao Zhai, Xiongkuo Min
Categories: cs.CV cs.AI
\\
 Developing a robust visual quality assessment (VQualA) large multi-modal
model (LMM) requires achieving versatility, powerfulness, and transferability.
 However, existing VQualA LMMs typically focus on a single task and rely on
full-parameter fine-tuning, which makes them prone to overfitting on specific
modalities or task types, thereby limiting their generalization capacity and
transferability. To address this, we propose a vision-encoder-centered
generative pre-training pipeline and develop the VITAL-Series LMMs. (1) We
adopt a machine-executed annotation-scrutiny paradigm, constructing over 4.5M
vision-language (VL) pairs-the largest VQualA training dataset to date. (2) We
employ a multi-task training workflow that simultaneously enhances the model's
quantitative scoring precision and strengthens its capability for quality
interpretation across both image and video modalities. (3) Building upon the
vision encoder, we realize an efficient model zoo extension: the model zoo
exhibits strong zero-shot performance, and each paired decoder requires only a
swift warm-up using less than 1/1000 of the pre-training data to achieve
performance comparable to the fully trained counterpart. Overall, our work lays
a cornerstone for advancing toward the foundation LMM for VQualA.
\\ ( https://arxiv.org/abs/2511.17962 ,  4410kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17964
Date: Sat, 22 Nov 2025 07:57:15 GMT   (1202kb)

Title: X-ReID: Multi-granularity Information Interaction for Video-Based
 Visible-Infrared Person Re-Identification
Authors: Chenyang Yu and Xuehu Liu and Pingping Zhang and Huchuan Lu
Categories: cs.CV
Comments: Accepted by AAAI2026. More modifications may be performed
\\
 Large-scale vision-language models (e.g., CLIP) have recently achieved
remarkable performance in retrieval tasks, yet their potential for Video-based
Visible-Infrared Person Re-Identification (VVI-ReID) remains largely
unexplored. The primary challenges are narrowing the modality gap and
leveraging spatiotemporal information in video sequences. To address the above
issues, in this paper, we propose a novel cross-modality feature learning
framework named X-ReID for VVI-ReID. Specifically, we first propose a
Cross-modality Prototype Collaboration (CPC) to align and integrate features
from different modalities, guiding the network to reduce the modality
discrepancy. Then, a Multi-granularity Information Interaction (MII) is
designed, incorporating short-term interactions from adjacent frames, long-term
cross-frame information fusion, and cross-modality feature alignment to enhance
temporal modeling and further reduce modality gaps. Finally, by integrating
multi-granularity information, a robust sequence-level representation is
achieved. Extensive experiments on two large-scale VVI-ReID benchmarks (i.e.,
HITSZ-VCM and BUPTCampus) demonstrate the superiority of our method over
state-of-the-art methods. The source code is released at
https://github.com/AsuradaYuci/X-ReID.
\\ ( https://arxiv.org/abs/2511.17964 ,  1202kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17965
Date: Sat, 22 Nov 2025 07:58:46 GMT   (2450kb)

Title: Signal: Selective Interaction and Global-local Alignment for Multi-Modal
 Object Re-Identification
Authors: Yangyang Liu and Yuhao Wang and Pingping Zhang
Categories: cs.CV cs.MM
Comments: Accepted by AAAI2026. More modifications may be performed
\\
 Multi-modal object Re-IDentification (ReID) is devoted to retrieving specific
objects through the exploitation of complementary multi-modal image
information. Existing methods mainly concentrate on the fusion of multi-modal
features, yet neglecting the background interference. Besides, current
multi-modal fusion methods often focus on aligning modality pairs but suffer
from multi-modal consistency alignment. To address these issues, we propose a
novel selective interaction and global-local alignment framework called Signal
for multi-modal object ReID. Specifically, we first propose a Selective
Interaction Module (SIM) to select important patch tokens with intra-modal and
inter-modal information. These important patch tokens engage in the interaction
with class tokens, thereby yielding more discriminative features. Then, we
propose a Global Alignment Module (GAM) to simultaneously align multi-modal
features by minimizing the volume of 3D polyhedra in the gramian space.
Meanwhile, we propose a Local Alignment Module (LAM) to align local features in
a shift-aware manner. With these modules, our proposed framework could extract
more discriminative features for object ReID. Extensive experiments on three
multi-modal object ReID benchmarks (i.e., RGBNT201, RGBNT100, MSVR310) validate
the effectiveness of our method. The source code is available at
https://github.com/010129/Signal.
\\ ( https://arxiv.org/abs/2511.17965 ,  2450kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17967
Date: Sat, 22 Nov 2025 08:10:02 GMT   (1122kb)

Title: CADTrack: Learning Contextual Aggregation with Deformable Alignment for
 Robust RGBT Tracking
Authors: Hao Li and Yuhao Wang and Xiantao Hu and Wenning Hao and Pingping
 Zhang and Dong Wang and Huchuan Lu
Categories: cs.CV
Comments: Accepted by AAAI2026. More modifications may be performed
\\
 RGB-Thermal (RGBT) tracking aims to exploit visible and thermal infrared
modalities for robust all-weather object tracking. However, existing RGBT
trackers struggle to resolve modality discrepancies, which poses great
challenges for robust feature representation. This limitation hinders effective
cross-modal information propagation and fusion, which significantly reduces the
tracking accuracy. To address this limitation, we propose a novel Contextual
Aggregation with Deformable Alignment framework called CADTrack for RGBT
Tracking. To be specific, we first deploy the Mamba-based Feature Interaction
(MFI) that establishes efficient feature interaction via state space models.
This interaction module can operate with linear complexity, reducing
computational cost and improving feature discrimination. Then, we propose the
Contextual Aggregation Module (CAM) that dynamically activates backbone layers
through sparse gating based on the Mixture-of-Experts (MoE). This module can
encode complementary contextual information from cross-layer features. Finally,
we propose the Deformable Alignment Module (DAM) to integrate deformable
sampling and temporal propagation, mitigating spatial misalignment and
localization drift. With the above components, our CADTrack achieves robust and
accurate tracking in complex scenarios. Extensive experiments on five RGBT
tracking benchmarks verify the effectiveness of our proposed method. The source
code is released at https://github.com/IdolLab/CADTrack.
\\ ( https://arxiv.org/abs/2511.17967 ,  1122kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17973
Date: Sat, 22 Nov 2025 08:20:09 GMT   (194kb)

Title: Adversarial Pseudo-replay for Exemplar-free Class-incremental Learning
Authors: Hiroto Honda
Categories: cs.CV
Comments: Accepted to WACV 2026
\\
 Exemplar-free class-incremental learning (EFCIL) aims to retain old knowledge
acquired in the previous task while learning new classes, without storing the
previous images due to storage constraints or privacy concerns. In EFCIL, the
plasticity-stability dilemma, learning new tasks versus catastrophic
forgetting, is a significant challenge, primarily due to the unavailability of
images from earlier tasks. In this paper, we introduce adversarial
pseudo-replay (APR), a method that perturbs the images of the new task with
adversarial attack, to synthesize the pseudo-replay images online without
storing any replay samples. During the new task training, the adversarial
attack is conducted on the new task images with augmented old class mean
prototypes as targets, and the resulting images are used for knowledge
distillation to prevent semantic drift. Moreover, we calibrate the covariance
matrices to compensate for the semantic drift after each task, by learning a
transfer matrix on the pseudo-replay samples. Our method reconciles stability
and plasticity, achieving state-of-the-art on challenging cold-start settings
of the standard EFCIL benchmarks.
\\ ( https://arxiv.org/abs/2511.17973 ,  194kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17979
Date: Sat, 22 Nov 2025 08:46:18 GMT   (24006kb)

Title: FeRA: Frequency-Energy Constrained Routing for Effective Diffusion
 Adaptation Fine-Tuning
Authors: Bo Yin, Xiaobin Hu, Xingyu Zhou, Peng-Tao Jiang, Yue Liao, Junwei Zhu,
 Jiangning Zhang, Ying Tai, Chengjie Wang, Shuicheng Yan
Categories: cs.CV
\\
 Diffusion models have achieved remarkable success in generative modeling, yet
how to effectively adapt large pretrained models to new tasks remains
challenging. We revisit the reconstruction behavior of diffusion models during
denoising to unveil the underlying frequency energy mechanism governing this
process. Building upon this observation, we propose FeRA, a frequency driven
fine tuning framework that aligns parameter updates with the intrinsic
frequency energy progression of diffusion. FeRA establishes a comprehensive
frequency energy framework for effective diffusion adaptation fine tuning,
comprising three synergistic components: (i) a compact frequency energy
indicator that characterizes the latent bandwise energy distribution, (ii) a
soft frequency router that adaptively fuses multiple frequency specific adapter
experts, and (iii) a frequency energy consistency regularization that
stabilizes diffusion optimization and ensures coherent adaptation across bands.
Routing operates in both training and inference, with inference time routing
dynamically determined by the latent frequency energy. It integrates seamlessly
with adapter based tuning schemes and generalizes well across diffusion
backbones and resolutions. By aligning adaptation with the frequency energy
mechanism, FeRA provides a simple, stable, and compatible paradigm for
effective and robust diffusion model adaptation.
\\ ( https://arxiv.org/abs/2511.17979 ,  24006kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17986
Date: Sat, 22 Nov 2025 08:59:09 GMT   (3312kb)

Title: Plan-X: Instruct Video Generation via Semantic Planning
Authors: Lun Huang, You Xie, Hongyi Xu, Tianpei Gu, Chenxu Zhang, Guoxian Song,
 Zenan Li, Xiaochen Zhao, Linjie Luo, Guillermo Sapiro
Categories: cs.CV cs.AI
Comments: The project page is at https://byteaigc.github.io/Plan-X
\\
 Diffusion Transformers have demonstrated remarkable capabilities in visual
synthesis, yet they often struggle with high-level semantic reasoning and
long-horizon planning. This limitation frequently leads to visual
hallucinations and mis-alignments with user instructions, especially in
scenarios involving complex scene understanding, human-object interactions,
multi-stage actions, and in-context motion reasoning. To address these
challenges, we propose Plan-X, a framework that explicitly enforces high-level
semantic planning to instruct video generation process. At its core lies a
Semantic Planner, a learnable multimodal language model that reasons over the
user's intent from both text prompts and visual context, and autoregressively
generates a sequence of text-grounded spatio-temporal semantic tokens. These
semantic tokens, complementary to high-level text prompt guidance, serve as
structured "semantic sketches" over time for the video diffusion model, which
has its strength at synthesizing high-fidelity visual details. Plan-X
effectively integrates the strength of language models in multimodal in-context
reasoning and planning, together with the strength of diffusion models in
photorealistic video synthesis. Extensive experiments demonstrate that our
framework substantially reduces visual hallucinations and enables fine-grained,
instruction-aligned video generation consistent with multimodal context.
\\ ( https://arxiv.org/abs/2511.17986 ,  3312kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17988
Date: Sat, 22 Nov 2025 09:02:06 GMT   (281kb)

Title: HyM-UNet: Synergizing Local Texture and Global Context via Hybrid
 CNN-Mamba Architecture for Medical Image Segmentation
Authors: Haodong Chen, Xianfei Han, Qwen
Categories: cs.CV cs.IR
\\
 Accurate organ and lesion segmentation is a critical prerequisite for
computer-aided diagnosis. Convolutional Neural Networks (CNNs), constrained by
their local receptive fields, often struggle to capture complex global
anatomical structures. To tackle this challenge, this paper proposes a novel
hybrid architecture, HyM-UNet, designed to synergize the local feature
extraction capabilities of CNNs with the efficient global modeling capabilities
of Mamba. Specifically, we design a Hierarchical Encoder that utilizes
convolutional modules in the shallow stages to preserve high-frequency texture
details, while introducing Visual Mamba modules in the deep stages to capture
long-range semantic dependencies with linear complexity. To bridge the semantic
gap between the encoder and the decoder, we propose a Mamba-Guided Fusion Skip
Connection (MGF-Skip). This module leverages deep semantic features as gating
signals to dynamically suppress background noise within shallow features,
thereby enhancing the perception of ambiguous boundaries. We conduct extensive
experiments on public benchmark dataset ISIC 2018. The results demonstrate that
HyM-UNet significantly outperforms existing state-of-the-art methods in terms
of Dice coefficient and IoU, while maintaining lower parameter counts and
inference latency. This validates the effectiveness and robustness of the
proposed method in handling medical segmentation tasks characterized by complex
shapes and scale variations.
\\ ( https://arxiv.org/abs/2511.17988 ,  281kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17993
Date: Sat, 22 Nov 2025 09:21:27 GMT   (11365kb)

Title: SD-PSFNet: Sequential and Dynamic Point Spread Function Network for
 Image Deraining
Authors: Jiayu Wang, Haoyu Bian, Haoran Sun, Shaoning Zeng
Categories: cs.CV
Comments: 12 pages, 7 figures, Published in AAAI 2026
\\
 Image deraining is crucial for vision applications but is challenged by the
complex multi-scale physics of rain and its coupling with scenes. To address
this challenge, a novel approach inspired by multi-stage image restoration is
proposed, incorporating Point Spread Function (PSF) mechanisms to reveal the
image degradation process while combining dynamic physical modeling with
sequential feature fusion transfer, named SD-PSFNet. Specifically, SD-PSFNet
employs a sequential restoration architecture with three cascaded stages,
allowing multiple dynamic evaluations and refinements of the degradation
process estimation. The network utilizes components with learned PSF mechanisms
to dynamically simulate rain streak optics, enabling effective rain-background
separation while progressively enhancing outputs through novel PSF components
at each stage. Additionally, SD-PSFNet incorporates adaptive gated fusion for
optimal cross-stage feature integration, enabling sequential refinement from
coarse rain removal to fine detail restoration. Our model achieves
state-of-the-art PSNR/SSIM metrics on Rain100H (33.12dB/0.9371), RealRain-1k-L
(42.28dB/0.9872), and RealRain-1k-H (41.08dB/0.9838). In summary, SD-PSFNet
demonstrates excellent capability in complex scenes and dense rainfall
conditions, providing a new physics-aware approach to image deraining.
\\ ( https://arxiv.org/abs/2511.17993 ,  11365kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18005
Date: Sat, 22 Nov 2025 10:09:22 GMT   (22971kb)

Title: RAISECity: A Multimodal Agent Framework for Reality-Aligned 3D World
 Generation at City-Scale
Authors: Shengyuan Wang, Zhiheng Zheng, Yu Shang, Lixuan He, Yangcheng Yu, Fan
 Hangyu, Jie Feng, Qingmin Liao, Yong Li
Categories: cs.CV
Comments: The code will be made publicly available soon at:
 https://github.com/tsinghua-fib-lab/RAISECity
\\
 City-scale 3D generation is of great importance for the development of
embodied intelligence and world models. Existing methods, however, face
significant challenges regarding quality, fidelity, and scalability in 3D world
generation. Thus, we propose RAISECity, a \textbf{R}eality-\textbf{A}ligned
\textbf{I}ntelligent \textbf{S}ynthesis \textbf{E}ngine that creates detailed,
\textbf{C}ity-scale 3D worlds. We introduce an agentic framework that leverages
diverse multimodal foundation tools to acquire real-world knowledge, maintain
robust intermediate representations, and construct complex 3D scenes. This
agentic design, featuring dynamic data processing, iterative self-reflection
and refinement, and the invocation of advanced multimodal tools, minimizes
cumulative errors and enhances overall performance. Extensive quantitative
experiments and qualitative analyses validate the superior performance of
RAISECity in real-world alignment, shape precision, texture fidelity, and
aesthetics level, achieving over a 90% win-rate against existing baselines for
overall perceptual quality. This combination of 3D quality, reality alignment,
scalability, and seamless compatibility with computer graphics pipelines makes
RAISECity a promising foundation for applications in immersive media, embodied
intelligence, and world models.
\\ ( https://arxiv.org/abs/2511.18005 ,  22971kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18007
Date: Sat, 22 Nov 2025 10:10:25 GMT   (4642kb)

Title: Is Complete Labeling Necessary? Understanding Active Learning in
 Longitudinal Medical Imaging
Authors: Siteng Ma, Honghui Du, Prateek Mathur, Brendan S. Kelly, Ronan P.
 Killeen, Aonghus Lawlor, Ruihai Dong
Categories: cs.CV
Comments: This paper has been accepted at International Joint Conference on
 Neural Networks (IJCNN) 2025
DOI: 10.1109/IJCNN64981.2025.11229353
\\
 Detecting changes in longitudinal medical imaging using deep learning
requires a substantial amount of accurately labeled data. However, labeling
these images is notably more costly and time-consuming than labeling other
image types, as it requires labeling across various time points, where new
lesions can be minor, and subtle changes are easily missed. Deep Active
Learning (DAL) has shown promise in minimizing labeling costs by selectively
querying the most informative samples, but existing studies have primarily
focused on static tasks like classification and segmentation. Consequently, the
conventional DAL approach cannot be directly applied to change detection tasks,
which involve identifying subtle differences across multiple images. In this
study, we propose a novel DAL framework, named Longitudinal Medical Imaging
Active Learning (LMI-AL), tailored specifically for longitudinal medical
imaging. By pairing and differencing all 2D slices from baseline and follow-up
3D images, LMI-AL iteratively selects the most informative pairs for labeling
using DAL, training a deep learning model with minimal manual annotation.
Experimental results demonstrate that, with less than 8% of the data labeled,
LMI-AL can achieve performance comparable to models trained on fully labeled
datasets. We also provide a detailed analysis of the method's performance, as
guidance for future research. The code is publicly available at
https://github.com/HelenMa9998/Longitudinal_AL.
\\ ( https://arxiv.org/abs/2511.18007 ,  4642kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18011
Date: Sat, 22 Nov 2025 10:23:44 GMT   (14127kb)

Title: RoadBench: Benchmarking MLLMs on Fine-Grained Spatial Understanding and
 Reasoning under Urban Road Scenarios
Authors: Jun Zhang, Jie Feng, Long Chen, Junhui Wang, Zhicheng Liu, Depeng Jin,
 Yong Li
Categories: cs.CV
Comments: The code and data are publicly available at:
 https://github.com/tsinghua-fib-lab/RoadBench
\\
 Multimodal large language models (MLLMs) have demonstrated powerful
capabilities in general spatial understanding and reasoning. However, their
fine-grained spatial understanding and reasoning capabilities in complex urban
scenarios have not received significant attention in the fields of both
research and industry. To fill this gap, we focus primarily on road markings as
a typical example of fine-grained spatial elements under urban scenarios, given
the essential role of the integrated road traffic network they form within
cities. Around road markings and urban traffic systems, we propose RoadBench, a
systematic benchmark that comprehensively evaluates MLLMs' fine-grained spatial
understanding and reasoning capabilities using BEV and FPV image inputs. This
benchmark comprises six tasks consisting of 9,121 strictly manually verified
test cases. These tasks form a systematic evaluation framework that bridges
understanding at local spatial scopes to global reasoning. They not only test
MLLMs' capabilities in recognition, joint understanding, and reasoning but also
assess their ability to integrate image information with domain knowledge.
After evaluating 14 mainstream MLLMs, we confirm that RoadBench is a
challenging benchmark for MLLMs while revealing significant shortcomings in
existing MLLMs' fine-grained spatial understanding and reasoning capabilities
within urban scenarios. In certain tasks, their performance even falls short of
simple rule-based or random selection baselines. These findings, along with
RoadBench itself, will contribute to the comprehensive advancement of spatial
understanding capabilities for MLLMs. The benchmark code, example datasets, and
raw evaluation results are available in the supplementary material.
\\ ( https://arxiv.org/abs/2511.18011 ,  14127kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18012
Date: Sat, 22 Nov 2025 10:25:19 GMT   (1218kb)

Title: State and Scene Enhanced Prototypes for Weakly Supervised
 Open-Vocabulary Object Detection
Authors: Jiaying Zhou, Qingchao Chen
Categories: cs.CV
\\
 Open-Vocabulary Object Detection (OVOD) aims to generalize object recognition
to novel categories, while Weakly Supervised OVOD (WS-OVOD) extends this by
combining box-level annotations with image-level labels. Despite recent
progress, two critical challenges persist in this setting. First, existing
semantic prototypes, even when enriched by LLMs, are static and limited,
failing to capture the rich intra-class visual variations induced by different
object states (e.g., a cat's pose). Second, the standard pseudo-box generation
introduces a semantic mismatch between visual region proposals (which contain
context) and object-centric text embeddings. To tackle these issues, we
introduce two complementary prototype enhancement strategies. To capture
intra-class variations in appearance and state, we propose the State-Enhanced
Semantic Prototypes (SESP), which generates state-aware textual descriptions
(e.g., "a sleeping cat") to capture diverse object appearances, yielding more
discriminative prototypes. Building on this, we further introduce
Scene-Augmented Pseudo Prototypes (SAPP) to address the semantic mismatch. SAPP
incorporates contextual semantics (e.g., "cat lying on sofa") and utilizes a
soft alignment mechanism to promote contextually consistent visual-textual
representations. By integrating SESP and SAPP, our method effectively enhances
both the richness of semantic prototypes and the visual-textual alignment,
achieving notable improvements.
\\ ( https://arxiv.org/abs/2511.18012 ,  1218kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18014
Date: Sat, 22 Nov 2025 10:28:36 GMT   (11549kb)

Title: Modeling Retinal Ganglion Cells with Neural Differential Equations
Authors: Kacper Dobek, Daniel Jankowski, Krzysztof Krawiec
Categories: cs.CV cs.AI
Comments: Accepted to the AAAI-26 Student Abstract and Poster Program, with
 supplementary material
\\
 This work explores Liquid Time-Constant Networks (LTCs) and Closed-form
Continuous-time Networks (CfCs) for modeling retinal ganglion cell activity in
tiger salamanders across three datasets. Compared to a convolutional baseline
and an LSTM, both architectures achieved lower MAE, faster convergence, smaller
model sizes, and favorable query times, though with slightly lower Pearson
correlation. Their efficiency and adaptability make them well suited for
scenarios with limited data and frequent retraining, such as edge deployments
in vision prosthetics.
\\ ( https://arxiv.org/abs/2511.18014 ,  11549kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18028
Date: Sat, 22 Nov 2025 11:44:09 GMT   (26344kb)

Title: MambaX: Image Super-Resolution with State Predictive Control
Authors: Chenyu Li and Danfeng Hong and Bing Zhang and Zhaojie Pan and Naoto
 Yokoya and Jocelyn Chanussot
Categories: cs.CV
\\
 Image super-resolution (SR) is a critical technology for overcoming the
inherent hardware limitations of sensors. However, existing approaches mainly
focus on directly enhancing the final resolution, often neglecting effective
control over error propagation and accumulation during intermediate stages.
Recently, Mamba has emerged as a promising approach that can represent the
entire reconstruction process as a state sequence with multiple nodes, allowing
for intermediate intervention. Nonetheless, its fixed linear mapper is limited
by a narrow receptive field and restricted flexibility, which hampers its
effectiveness in fine-grained images. To address this, we created a nonlinear
state predictive control model \textbf{MambaX} that maps consecutive spectral
bands into a latent state space and generalizes the SR task by dynamically
learning the nonlinear state parameters of control equations. Compared to
existing sequence models, MambaX 1) employs dynamic state predictive control
learning to approximate the nonlinear differential coefficients of state-space
models; 2) introduces a novel state cross-control paradigm for multimodal SR
fusion; and 3) utilizes progressive transitional learning to mitigate
heterogeneity caused by domain and modality shifts. Our evaluation demonstrates
the superior performance of the dynamic spectrum-state representation model in
both single-image SR and multimodal fusion-based SR tasks, highlighting its
substantial potential to advance spectrally generalized modeling across
arbitrary dimensions and modalities.
\\ ( https://arxiv.org/abs/2511.18028 ,  26344kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18037
Date: Sat, 22 Nov 2025 12:32:07 GMT   (5535kb)

Title: Hybrid Event Frame Sensors: Modeling, Calibration, and Simulation
Authors: Yunfan Lu, Nico Messikommer, Xiaogang Xu, Liming Chen, Yuhan Chen,
 Nikola Zubic, Davide Scaramuzza, Hui Xiong
Categories: cs.CV
\\
 Event frame hybrid sensors integrate an Active Pixel Sensor (APS) and an
Event Vision Sensor (EVS) within a single chip, combining the high dynamic
range and low latency of the EVS with the rich spatial intensity information
from the APS. While this tight integration offers compact, temporally precise
imaging, the complex circuit architecture introduces non-trivial noise patterns
that remain poorly understood and unmodeled. In this work, we present the first
unified, statistics-based imaging noise model that jointly describes the noise
behavior of APS and EVS pixels. Our formulation explicitly incorporates photon
shot noise, dark current noise, fixed-pattern noise, and quantization noise,
and links EVS noise to illumination level and dark current. Based on this
formulation, we further develop a calibration pipeline to estimate noise
parameters from real data and offer a detailed analysis of both APS and EVS
noise behaviors. Finally, we propose HESIM, a statistically grounded simulator
that generates RAW frames and events under realistic, jointly calibrated noise
statistics. Experiments on two hybrid sensors validate our model across
multiple imaging tasks (e.g., video frame interpolation and deblurring),
demonstrating strong transfer from simulation to real data.
\\ ( https://arxiv.org/abs/2511.18037 ,  5535kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18050
Date: Sat, 22 Nov 2025 13:07:21 GMT   (41405kb)

Title: UltraFlux: Data-Model Co-Design for High-quality Native 4K Text-to-Image
 Generation across Diverse Aspect Ratios
Authors: Tian Ye, Song Fei and Lei Zhu
Categories: cs.CV
Comments: Project Page: https://w2genai-lab.github.io/UltraFlux/
\\
 Diffusion transformers have recently delivered strong text-to-image
generation around 1K resolution, but we show that extending them to native 4K
across diverse aspect ratios exposes a tightly coupled failure mode spanning
positional encoding, VAE compression, and optimization. Tackling any of these
factors in isolation leaves substantial quality on the table. We therefore take
a data-model co-design view and introduce UltraFlux, a Flux-based DiT trained
natively at 4K on MultiAspect-4K-1M, a 1M-image 4K corpus with controlled
multi-AR coverage, bilingual captions, and rich VLM/IQA metadata for
resolution- and AR-aware sampling. On the model side, UltraFlux couples (i)
Resonance 2D RoPE with YaRN for training-window-, frequency-, and AR-aware
positional encoding at 4K; (ii) a simple, non-adversarial VAE post-training
scheme that improves 4K reconstruction fidelity; (iii) an SNR-Aware Huber
Wavelet objective that rebalances gradients across timesteps and frequency
bands; and (iv) a Stage-wise Aesthetic Curriculum Learning strategy that
concentrates high-aesthetic supervision on high-noise steps governed by the
model prior. Together, these components yield a stable, detail-preserving 4K
DiT that generalizes across wide, square, and tall ARs. On the Aesthetic-Eval
at 4096 benchmark and multi-AR 4K settings, UltraFlux consistently outperforms
strong open-source baselines across fidelity, aesthetic, and alignment metrics,
and-with a LLM prompt refiner-matches or surpasses the proprietary Seedream
4.0.
\\ ( https://arxiv.org/abs/2511.18050 ,  41405kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18055
Date: Sat, 22 Nov 2025 13:16:58 GMT   (4715kb)

Title: IE-Critic-R1: Advancing the Explanatory Measurement of Text-Driven Image
 Editing for Human Perception Alignment
Authors: Bowen Qu and Shangkun Sun and Xiaoyu Liang and Wei Gao
Categories: cs.CV cs.AI cs.CL
Comments: 18 pages, 10 figures, 8 tables
\\
 Recent advances in text-driven image editing have been significant, yet the
task of accurately evaluating these edited images continues to pose a
considerable challenge. Different from the assessment of text-driven image
generation, text-driven image editing is characterized by simultaneously
conditioning on both text and a source image. The edited images often retain an
intrinsic connection to the original image, which dynamically change with the
semantics of the text. However, previous methods tend to solely focus on
text-image alignment or have not well aligned with human perception. In this
work, we introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to
enhance the assessment of text-driven edited images. IE-Bench includes a
database contains diverse source images, various editing prompts and the
corresponding edited results from different editing methods, and nearly 4,000
samples with corresponding Mean Opinion Scores (MOS) provided by 15 human
subjects. Furthermore, we introduce IE-Critic-R1, which, benefiting from
Reinforcement Learning from Verifiable Rewards (RLVR), provides more
comprehensive and explainable quality assessment for text-driven image editing
that aligns with human perception. Extensive experiments demonstrate
IE-Critic-R1's superior subjective-alignments on the text-driven image editing
task compared with previous metrics. Related data and codes are available to
the public.
\\ ( https://arxiv.org/abs/2511.18055 ,  4715kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18058
Date: Sat, 22 Nov 2025 13:25:42 GMT   (989kb)

Title: Hierarchical Semi-Supervised Active Learning for Remote Sensing
Authors: Wei Huang, Zhitong Xiong, Chenying Liu, Xiao Xiang Zhu
Categories: cs.CV
Comments: Under review
\\
 The performance of deep learning models in remote sensing (RS) strongly
depends on the availability of high-quality labeled data. However, collecting
large-scale annotations is costly and time-consuming, while vast amounts of
unlabeled imagery remain underutilized. To address this challenge, we propose a
Hierarchical Semi-Supervised Active Learning (HSSAL) framework that integrates
semi-supervised learning (SSL) and a novel hierarchical active learning (HAL)
in a closed iterative loop. In each iteration, SSL refines the model using both
labeled data through supervised learning and unlabeled data via weak-to-strong
self-training, improving feature representation and uncertainty estimation.
Guided by the refined representations and uncertainty cues of unlabeled
samples, HAL then conducts sample querying through a progressive clustering
strategy, selecting the most informative instances that jointly satisfy the
criteria of scalability, diversity, and uncertainty. This hierarchical process
ensures both efficiency and representativeness in sample selection. Extensive
experiments on three benchmark RS scene classification datasets, including UCM,
AID, and NWPU-RESISC45, demonstrate that HSSAL consistently outperforms SSL- or
AL-only baselines. Remarkably, with only 8%, 4%, and 2% labeled training data
on UCM, AID, and NWPU-RESISC45, respectively, HSSAL achieves over 95% of
fully-supervised accuracy, highlighting its superior label efficiency through
informativeness exploitation of unlabeled data. Our code will be released at
https://github.com/zhu-xlab/RS-SSAL.
\\ ( https://arxiv.org/abs/2511.18058 ,  989kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18063
Date: Sat, 22 Nov 2025 13:48:37 GMT   (890kb)

Title: A Lightweight, Interpretable Deep Learning System for Automated
 Detection of Cervical Adenocarcinoma In Situ (AIS)
Authors: Gabriela Fernandes
Categories: cs.CV q-bio.TO
\\
 Cervical adenocarcinoma in situ (AIS) is a critical premalignant lesion whose
accurate histopathological diagnosis is challenging. Early detection is
essential to prevent progression to invasive cervical adenocarcinoma. In this
study, we developed a deep learning-based virtual pathology assistant capable
of distinguishing AIS from normal cervical gland histology using the CAISHI
dataset, which contains 2240 expert-labeled H&E images (1010 normal and 1230
AIS). All images underwent Macenko stain normalization and patch-based
preprocessing to enhance morphological feature representation. An
EfficientNet-B3 convolutional neural network was trained using class-balanced
sampling and focal loss to address dataset imbalance and emphasize difficult
examples. The final model achieved an overall accuracy of 0.7323, with an
F1-score of 0.75 for the Abnormal class and 0.71 for the Normal class. Grad-CAM
heatmaps demonstrated biologically interpretable activation patterns,
highlighting nuclear atypia and glandular crowding consistent with AIS
morphology. The trained model was deployed in a Gradio-based virtual diagnostic
assistant. These findings demonstrate the feasibility of lightweight,
interpretable AI systems for cervical gland pathology, with potential
applications in screening workflows, education, and low-resource settings.
\\ ( https://arxiv.org/abs/2511.18063 ,  890kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18075
Date: Sat, 22 Nov 2025 14:19:59 GMT   (2610kb)

Title: VK-Det: Visual Knowledge Guided Prototype Learning for Open-Vocabulary
 Aerial Object Detection
Authors: Jianhang Yao, Yongbin Zheng, Siqi Lu, Wanying Xu, Peng Sun
Categories: cs.CV
Comments: 15 pages, 8 figures, accepted by AAAI 2026
\\
 To identify objects beyond predefined categories, open-vocabulary aerial
object detection (OVAD) leverages the zero-shot capabilities of visual-language
models (VLMs) to generalize from base to novel categories. Existing approaches
typically utilize self-learning mechanisms with weak text supervision to
generate region-level pseudo-labels to align detectors with VLMs semantic
spaces. However, text dependence induces semantic bias, restricting
open-vocabulary expansion to text-specified concepts. We propose
$\textbf{VK-Det}$, a $\textbf{V}$isual $\textbf{K}$nowledge-guided
open-vocabulary object $\textbf{Det}$ection framework $\textit{without}$ extra
supervision. First, we discover and leverage vision encoder's inherent
informative region perception to attain fine-grained localization and adaptive
distillation. Second, we introduce a novel prototype-aware pseudo-labeling
strategy. It models inter-class decision boundaries through feature clustering
and maps detection regions to latent categories via prototype matching. This
enhances attention to novel objects while compensating for missing supervision.
Extensive experiments show state-of-the-art performance, achieving 30.1
$\mathrm{mAP}^{N}$ on DIOR and 23.3 $\mathrm{mAP}^{N}$ on DOTA, outperforming
even extra supervised methods.
\\ ( https://arxiv.org/abs/2511.18075 ,  2610kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18082
Date: Sat, 22 Nov 2025 14:44:03 GMT   (5455kb)

Title: ActDistill: General Action-Guided Self-Derived Distillation for
 Efficient Vision-Language-Action Models
Authors: Wencheng Ye, Tianshi Wang, Lei Zhu, Fengling Li, Guoli Yang
Categories: cs.CV cs.RO
\\
 Recent Vision-Language-Action (VLA) models have shown impressive flexibility
and generalization, yet their deployment in robotic manipulation remains
limited by heavy computational overhead and inference latency. In this work, we
present ActDistill, a general action-guided self-derived distillation framework
that transfers the action prediction capability of any existing VLA model to a
lightweight counterpart. Unlike previous efficiency strategies that primarily
emphasize vision-language correlations, ActDistill leverages action priors to
guide knowledge transfer and model compression, achieving action-oriented
efficiency for VLA models. Specifically, we employ a well-trained VLA model as
the teacher and introduce a graph-structured encapsulation strategy to
explicitly model the hierarchical evolution of action prediction. The student
model, derived from the graph-encapsulated teacher, is further equipped with a
dynamic router that adaptively selects computation paths based on action
prediction demands, guided by hierarchical graph-informed supervision to ensure
smooth and efficient evolution. During inference, graph-related auxiliary
components are removed, allowing the student to execute only dynamically routed
layers and predict high-precision actions with minimal computation and latency.
Experiments on embodied benchmarks demonstrate that ActDistill achieves
comparable or superior performance to full-scale VLA models while reducing
computation by over 50% with up to 1.67 times speedup, thereby establishing a
general paradigm toward efficient embodied intelligence.
\\ ( https://arxiv.org/abs/2511.18082 ,  5455kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18083
Date: Sat, 22 Nov 2025 14:46:59 GMT   (66kb)

Title: Less Is More: An Explainable AI Framework for Lightweight Malaria
 Classification
Authors: Md Abdullah Al Kafi, Raka Moni, Sumit Kumar Banshal
Categories: cs.CV
\\
 Background and Objective: Deep learning models have high computational needs
and lack interpretability but are often the first choice for medical image
classification tasks. This study addresses whether complex neural networks are
essential for the simple binary classification task of malaria. We introduce
the Extracted Morphological Feature Engineered (EMFE) pipeline, a transparent,
reproducible, and low compute machine learning approach tailored explicitly for
simple cell morphology, designed to achieve deep learning performance levels on
a simple CPU only setup with the practical aim of real world deployment.
 Methods: The study used the NIH Malaria Cell Images dataset, with two
features extracted from each cell image: the number of non background pixels
and the number of holes within the cell. Logistic Regression and Random Forest
were compared against ResNet18, DenseNet121, MobileNetV2, and EfficientNet
across accuracy, model size, and CPU inference time. An ensemble model was
created by combining Logistic Regression and Random Forests to achieve higher
accuracy while retaining efficiency.
 Results: The single variable Logistic Regression model achieved a test
accuracy of 94.80 percent with a file size of 1.2 kB and negligible inference
latency (2.3 ms). The two stage ensemble improved accuracy to 97.15 percent. In
contrast, the deep learning methods require 13.6 MB to 44.7 MB of storage and
show significantly higher inference times (68 ms).
 Conclusion: This study shows that a compact feature engineering approach can
produce clinically meaningful classification performance while offering gains
in transparency, reproducibility, speed, and deployment feasibility. The
proposed pipeline demonstrates that simple interpretable features paired with
lightweight models can serve as a practical diagnostic solution for
environments with limited computational resources.
\\ ( https://arxiv.org/abs/2511.18083 ,  66kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18089
Date: Sat, 22 Nov 2025 15:10:46 GMT   (1657kb)

Title: Together, Then Apart: Revisiting Multimodal Survival Analysis via a
 Min-Max Perspective
Authors: Wenjing Liu, Qin Ren, Wen Zhang, Yuewei Lin, Chenyu You
Categories: cs.CV
\\
 Integrating heterogeneous modalities such as histopathology and genomics is
central to advancing survival analysis, yet most existing methods prioritize
cross-modal alignment through attention-based fusion mechanisms, often at the
expense of modality-specific characteristics. This overemphasis on alignment
leads to representation collapse and reduced diversity. In this work, we
revisit multi-modal survival analysis via the dual lens of alignment and
distinctiveness, positing that preserving modality-specific structure is as
vital as achieving semantic coherence. In this paper, we introduce
Together-Then-Apart (TTA), a unified min-max optimization framework that
simultaneously models shared and modality-specific representations. The
Together stage minimizes semantic discrepancies by aligning embeddings via
shared prototypes, guided by an unbalanced optimal transport objective that
adaptively highlights informative tokens. The Apart stage maximizes
representational diversity through modality anchors and a contrastive
regularizer that preserve unique modality information and prevent feature
collapse. Extensive experiments on five TCGA benchmarks show that TTA
consistently outperforms state-of-the-art methods. Beyond empirical gains, our
formulation provides a new theoretical perspective of how alignment and
distinctiveness can be jointly achieved in for robust, interpretable, and
biologically meaningful multi-modal survival analysis.
\\ ( https://arxiv.org/abs/2511.18089 ,  1657kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18090
Date: Sat, 22 Nov 2025 15:12:25 GMT   (31972kb)

Title: Versatile Recompression-Aware Perceptual Image Super-Resolution
Authors: Mingwei He, Tongda Xu, Xingtong Ge, Ming Sun, Chao Zhou, Yan Wang
Categories: cs.CV
\\
 Perceptual image super-resolution (SR) methods restore degraded images and
produce sharp outputs. In practice, those outputs are usually recompressed for
storage and transmission. Ignoring recompression is suboptimal as the
downstream codec might add additional artifacts to restored images. However,
jointly optimizing SR and recompression is challenging, as the codecs are not
differentiable and vary in configuration. In this paper, we present Versatile
Recompression-Aware Perceptual Super-Resolution (VRPSR), which makes existing
perceptual SR aware of versatile compression. First, we formulate compression
as conditional text-to-image generation and utilize a pre-trained diffusion
model to build a generalizable codec simulator. Next, we propose a set of
training techniques tailored for perceptual SR, including optimizing the
simulator using perceptual targets and adopting slightly compressed images as
the training target. Empirically, our VRPSR saves more than 10\% bitrate based
on Real-ESRGAN and S3Diff under H.264/H.265/H.266 compression. Besides, our
VRPSR facilitates joint optimization of the SR and post-processing model after
recompression.
\\ ( https://arxiv.org/abs/2511.18090 ,  31972kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18102
Date: Sat, 22 Nov 2025 15:55:30 GMT   (11367kb)

Title: Spotlight: Identifying and Localizing Video Generation Errors Using VLMs
Authors: Aditya Chinchure, Sahithya Ravi, Pushkar Shukla, Vered Shwartz, Leonid
 Sigal
Categories: cs.CV
\\
 Current text-to-video models (T2V) can generate high-quality, temporally
coherent, and visually realistic videos. Nonetheless, errors still often occur,
and are more nuanced and local compared to the previous generation of T2V
models. While current evaluation paradigms assess video models across diverse
dimensions, they typically evaluate videos holistically without identifying
when specific errors occur or describing their nature. We address this gap by
introducing Spotlight, a novel task aimed at localizing and explaining
video-generation errors. We generate 600 videos using 200 diverse textual
prompts and three state-of-the-art video generators (Veo 3, Seedance, and
LTX-2), and annotate over 1600 fine-grained errors across six types, including
motion, physics, and prompt adherence. We observe that adherence and physics
errors are predominant and persist across longer segments, whereas
appearance-disappearance and body pose errors manifest in shorter segments. We
then evaluate current VLMs on Spotlight and find that VLMs lag significantly
behind humans in error identification and localization in videos. We propose
inference-time strategies to probe the limits of current VLMs on our task,
improving performance by nearly 2x. Our task paves a way forward to building
fine-grained evaluation tools and more sophisticated reward models for video
generators.
\\ ( https://arxiv.org/abs/2511.18102 ,  11367kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18104
Date: Sat, 22 Nov 2025 16:05:12 GMT   (24657kb)

Title: Consolidating Diffusion-Generated Video Detection with Unified
 Multimodal Forgery Learning
Authors: Xiaohong Liu, Xiufeng Song, Huayu Zheng, Lei Bai, Xiaoming Liu,
 Guangtao Zhai
Categories: cs.CV
Comments: Code and dataset are available at
 https://github.com/SparkleXFantasy/MM-Det-Plus
\\
 The proliferation of videos generated by diffusion models has raised
increasing concerns about information security, highlighting the urgent need
for reliable detection of synthetic media. Existing methods primarily focus on
image-level forgery detection, leaving generic video-level forgery detection
largely underexplored. To advance video forensics, we propose a consolidated
multimodal detection algorithm, named MM-Det++, specifically designed for
detecting diffusion-generated videos. Our approach consists of two innovative
branches and a Unified Multimodal Learning (UML) module. Specifically, the
Spatio-Temporal (ST) branch employs a novel Frame-Centric Vision Transformer
(FC-ViT) to aggregate spatio-temporal information for detecting
diffusion-generated videos, where the FC-tokens enable the capture of holistic
forgery traces from each video frame. In parallel, the Multimodal (MM) branch
adopts a learnable reasoning paradigm to acquire Multimodal Forgery
Representation (MFR) by harnessing the powerful comprehension and reasoning
capabilities of Multimodal Large Language Models (MLLMs), which discerns the
forgery traces from a flexible semantic perspective. To integrate multimodal
representations into a coherent space, a UML module is introduced to
consolidate the generalization ability of MM-Det++. In addition, we also
establish a large-scale and comprehensive Diffusion Video Forensics (DVF)
dataset to advance research in video forgery detection. Extensive experiments
demonstrate the superiority of MM-Det++ and highlight the effectiveness of
unified multimodal forgery learning in detecting diffusion-generated videos.
\\ ( https://arxiv.org/abs/2511.18104 ,  24657kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18105
Date: Sat, 22 Nov 2025 16:09:14 GMT   (3098kb)

Title: AdaPerceiver: Transformers with Adaptive Width, Depth, and Tokens
Authors: Purvish Jajal, Nick John Eliopoulos, Benjamin Shiue-Hal Chou, George
 K. Thiruvathukal, Yung-Hsiang Lu, and James C. Davis
Categories: cs.CV cs.LG
\\
 Modern transformer architectures achieve remarkable performance across tasks
and domains but remain rigid in how they allocate computation at inference
time. Real-world deployment often requires models to adapt to diverse hardware
and latency constraints, yet most approaches to dynamic computation focus on a
single axis -- such as reducing the number of tokens. We present a novel
capability: AdaPerceiver, the first transformer architecture with unified
adaptivity across depth, width, and tokens within a single model. We propose an
architecture that supports adaptivity along these axes. We couple this with an
efficient joint training regime that ensures the model maintains performance
across its various configurations. We evaluate AdaPerceiver on image
classification, semantic segmentation, and depth estimation tasks. On image
classification, AdaPerceiver expands the accuracy-throughput Pareto front. It
achieves 85.4% accuracy while yielding 36% higher throughput than FlexiViT-L.
On dense prediction, AdaPerceiver matches ViT-H/14 while having $\sim$26x fewer
encoder FLOPs (floating-point operations) on semantic segmentation and depth
estimation. Finally, we show how AdaPerceiver equipped with a policy can
maintain ImageNet1K accuracy ($\pm0.1$ percentage points) while reducing FLOPs
by $24-33$%.
\\ ( https://arxiv.org/abs/2511.18105 ,  3098kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18115
Date: Sat, 22 Nov 2025 16:39:59 GMT   (27018kb)

Title: Muskie: Multi-view Masked Image Modeling for 3D Vision Pre-training
Authors: Wenyu Li, Sidun Liu, Peng Qiao, Yong Dou, Tongrui Hu
Categories: cs.CV
\\
 We present Muskie, a native multi-view vision backbone designed for 3D vision
tasks. Unlike existing models, which are frame-wise and exhibit limited
multi-view consistency, Muskie is designed to process multiple views
simultaneously and introduce multi-view consistency in pre-training stage.
Muskie is trained to reconstruct heavily masked content in one view by finding
and utilizing geometric correspondences from other views. Through this pretext
task and our proposed aggressive masking strategy, the model implicitly to
learn view-invariant features and develop strong geometric understanding
without any 3D supervision. Compared with state-of-the-art frame-wise backbones
such as DINO, Muskie achieves higher multi-view correspondence accuracy.
Furthermore, we demonstrate that using Muskie as a backbone consistently
enhances performance on downstream 3D tasks, including camera pose estimation
and pointmap reconstruction. Codes are publicly available at
https://leo-frank.github.io/Muskie/
\\ ( https://arxiv.org/abs/2511.18115 ,  27018kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18116
Date: Sat, 22 Nov 2025 16:41:18 GMT   (2432kb)

Title: PromptMoE: Generalizable Zero-Shot Anomaly Detection via Visually-Guided
 Prompt Mixtures
Authors: Yuheng Shao, Lizhang Wang, Changhao Li, Peixian Chen, and Qinyuan Liu
Categories: cs.CV
Comments: 14 pages, 8 figures. Accepted to AAAI 2026
\\
 Zero-Shot Anomaly Detection (ZSAD) aims to identify and localize anomalous
regions in images of unseen object classes. While recent methods based on
vision-language models like CLIP show promise, their performance is constrained
by existing prompt engineering strategies. Current approaches, whether relying
on single fixed, learnable, or dense dynamic prompts, suffer from a
representational bottleneck and are prone to overfitting on auxiliary data,
failing to generalize to the complexity and diversity of unseen anomalies. To
overcome these limitations, we propose $\mathtt{PromptMoE}$. Our core insight
is that robust ZSAD requires a compositional approach to prompt learning.
Instead of learning monolithic prompts, $\mathtt{PromptMoE}$ learns a pool of
expert prompts, which serve as a basis set of composable semantic primitives,
and a visually-guided Mixture-of-Experts (MoE) mechanism to dynamically combine
them for each instance. Our framework materializes this concept through a
Visually-Guided Mixture of Prompt (VGMoP) that employs an image-gated sparse
MoE to aggregate diverse normal and abnormal expert state prompts, generating
semantically rich textual representations with strong generalization. Extensive
experiments across 15 datasets in industrial and medical domains demonstrate
the effectiveness and state-of-the-art performance of $\mathtt{PromptMoE}$.
\\ ( https://arxiv.org/abs/2511.18116 ,  2432kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18120
Date: Sat, 22 Nov 2025 16:52:47 GMT   (46436kb)

Title: MVS-TTA: Test-Time Adaptation for Multi-View Stereo via Meta-Auxiliary
 Learning
Authors: Hannuo Zhang, Zhixiang Chi, Yang Wang, Xinxin Zuo
Categories: cs.CV
Comments: 8 pages, 7 figures
\\
 Recent learning-based multi-view stereo (MVS) methods are data-driven and
have achieved remarkable progress due to large-scale training data and advanced
architectures. However, their generalization remains sub-optimal due to fixed
model parameters trained on limited training data distributions. In contrast,
optimization-based methods enable scene-specific adaptation but lack
scalability and require costly per-scene optimization. In this paper, we
propose MVS-TTA, an efficient test-time adaptation (TTA) framework that
enhances the adaptability of learning-based MVS methods by bridging these two
paradigms. Specifically, MVS-TTA employs a self-supervised, cross-view
consistency loss as an auxiliary task to guide inference-time adaptation. We
introduce a meta-auxiliary learning strategy to train the model to benefit from
auxiliary-task-based updates explicitly. Our framework is model-agnostic and
can be applied to a wide range of MVS methods with minimal architectural
changes. Extensive experiments on standard datasets (DTU, BlendedMVS) and a
challenging cross-dataset generalization setting demonstrate that MVS-TTA
consistently improves performance, even when applied to state-of-the-art MVS
models. To our knowledge, this is the first attempt to integrate
optimization-based test-time adaptation into learning-based MVS using
meta-learning. The code will be available at
https://github.com/mart87987-svg/MVS-TTA.
\\ ( https://arxiv.org/abs/2511.18120 ,  46436kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18121
Date: Sat, 22 Nov 2025 17:01:03 GMT   (5543kb)

Title: VCU-Bridge: Hierarchical Visual Connotation Understanding via Semantic
 Bridging
Authors: Ming Zhong, Yuanlei Wang, Liuzhou Zhang, Arctanx An, Renrui Zhang, Hao
 Liang, Ming Lu, Ying Shen, Wentao Zhang
Categories: cs.CV cs.AI
\\
 While Multimodal Large Language Models (MLLMs) excel on benchmarks, their
processing paradigm differs from the human ability to integrate visual
information. Unlike humans who naturally bridge details and high-level
concepts, models tend to treat these elements in isolation. Prevailing
evaluation protocols often decouple low-level perception from high-level
reasoning, overlooking their semantic and causal dependencies, which yields
non-diagnostic results and obscures performance bottlenecks. We present
VCU-Bridge, a framework that operationalizes a human-like hierarchy of visual
connotation understanding: multi-level reasoning that advances from
foundational perception through semantic bridging to abstract connotation, with
an explicit evidence-to-inference trace from concrete cues to abstract
conclusions. Building on this framework, we construct HVCU-Bench, a benchmark
for hierarchical visual connotation understanding with explicit, level-wise
diagnostics. Comprehensive experiments demonstrate a consistent decline in
performance as reasoning progresses to higher levels. We further develop a data
generation pipeline for instruction tuning guided by Monte Carlo Tree Search
(MCTS) and show that strengthening low-level capabilities yields measurable
gains at higher levels. Interestingly, it not only improves on HVCU-Bench but
also brings benefits on general benchmarks (average +2.53%), especially with
substantial gains on MMStar (+7.26%), demonstrating the significance of the
hierarchical thinking pattern and its effectiveness in enhancing MLLM
capabilities. The project page is at https://vcu-bridge.github.io .
\\ ( https://arxiv.org/abs/2511.18121 ,  5543kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18123
Date: Sat, 22 Nov 2025 17:04:30 GMT   (784kb)

Title: Bias Is a Subspace, Not a Coordinate: A Geometric Rethinking of Post-hoc
 Debiasing in Vision-Language Models
Authors: Dachuan Zhao, Weiyue Li, Zhenda Shen, Yushu Qiu, Bowen Xu, Haoyu Chen,
 Yongchao Chen
Categories: cs.CV cs.AI cs.CL cs.LG
\\
 Vision-Language Models (VLMs) have become indispensable for multimodal
reasoning, yet their representations often encode and amplify demographic
biases, resulting in biased associations and misaligned predictions in
downstream tasks. Such behavior undermines fairness and distorts the intended
alignment between vision and language. Recent post-hoc approaches attempt to
mitigate bias by replacing the most attribute-correlated embedding coordinates
with neutral values. However, our systematic analysis reveals three critical
failures of this coordinate-wise approach: feature entanglement, poor
cross-dataset generalization, and incomplete bias removal. We find that bias is
not localized to a few coordinates but is instead distributed across a few
linear subspaces. To address these limitations, we propose $\textbf{S}$ubspace
$\textbf{P}$rojection $\textbf{D}$ebiasing ($\textbf{SPD}$), a geometrically
principled framework that identifies and removes the entire subspace of
linearly decodable bias while reinserting a neutral mean component to preserve
semantic fidelity. Extensive experiments across zero-shot classification,
text-to-image retrieval, and image generation validate the effectiveness of
SPD: our method achieves more robust debiasing with an average improvement of
$18.5\%$ across four fairness metrics, while maintaining minimal loss in task
performance compared to the best debiasing baseline.
\\ ( https://arxiv.org/abs/2511.18123 ,  784kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18127
Date: Sat, 22 Nov 2025 17:22:24 GMT   (4425kb)

Title: SFHand: A Streaming Framework for Language-guided 3D Hand Forecasting
 and Embodied Manipulation
Authors: Ruicong Liu, Yifei Huang, Liangyang Ouyang, Caixin Kang, Yoichi Sato
Categories: cs.CV
\\
 Real-time 3D hand forecasting is a critical component for fluid
human-computer interaction in applications like AR and assistive robotics.
However, existing methods are ill-suited for these scenarios, as they typically
require offline access to accumulated video sequences and cannot incorporate
language guidance that conveys task intent. To overcome these limitations, we
introduce SFHand, the first streaming framework for language-guided 3D hand
forecasting. SFHand autoregressively predicts a comprehensive set of future 3D
hand states, including hand type, 2D bounding box, 3D pose, and trajectory,
from a continuous stream of video and language instructions. Our framework
combines a streaming autoregressive architecture with an ROI-enhanced memory
layer, capturing temporal context while focusing on salient hand-centric
regions. To enable this research, we also introduce EgoHaFL, the first
large-scale dataset featuring synchronized 3D hand poses and language
instructions. We demonstrate that SFHand achieves new state-of-the-art results
in 3D hand forecasting, outperforming prior work by a significant margin of up
to 35.8%. Furthermore, we show the practical utility of our learned
representations by transferring them to downstream embodied manipulation tasks,
improving task success rates by up to 13.4% on multiple benchmarks. Dataset
page: https://huggingface.co/datasets/ut-vision/EgoHaFL, project page:
https://github.com/ut-vision/SFHand.
\\ ( https://arxiv.org/abs/2511.18127 ,  4425kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18131
Date: Sat, 22 Nov 2025 17:30:55 GMT   (4421kb)

Title: Video4Edit: Viewing Image Editing as a Degenerate Temporal Process
Authors: Xiaofan Li, Yanpeng Sun, Chenming Wu, Fan Duan, YuAn Wang, Weihao Bo,
 Yumeng Zhang, Dingkang Liang
Categories: cs.CV
Comments: 10 pages, 5 figures
\\
 We observe that recent advances in multimodal foundation models have
propelled instruction-driven image generation and editing into a genuinely
cross-modal, cooperative regime. Nevertheless, state-of-the-art editing
pipelines remain costly: beyond training large diffusion/flow models, they
require curating massive high-quality triplets of \{instruction, source image,
edited image\} to cover diverse user intents. Moreover, the fidelity of visual
replacements hinges on how precisely the instruction references the target
semantics. We revisit this challenge through the lens of temporal modeling: if
video can be regarded as a full temporal process, then image editing can be
seen as a degenerate temporal process. This perspective allows us to transfer
single-frame evolution priors from video pre-training, enabling a highly
data-efficient fine-tuning regime. Empirically, our approach matches the
performance of leading open-source baselines while using only about one percent
of the supervision demanded by mainstream editing models.
\\ ( https://arxiv.org/abs/2511.18131 ,  4421kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18136
Date: Sat, 22 Nov 2025 17:48:17 GMT   (1604kb)

Title: SCALER: SAM-Enhanced Collaborative Learning for Label-Deficient
 Concealed Object Segmentation
Authors: Chunming He, Rihan Zhang, Longxiang Tang, Ziyun Yang, Kai Li,
 Deng-Ping Fan, Sina Farsiu
Categories: cs.CV cs.AI
Comments: 4 figures, 6 tables
\\
 Existing methods for label-deficient concealed object segmentation (LDCOS)
either rely on consistency constraints or Segment Anything Model (SAM)-based
pseudo-labeling. However, their performance remains limited due to the
intrinsic concealment of targets and the scarcity of annotations. This study
investigates two key questions: (1) Can consistency constraints and SAM-based
supervision be jointly integrated to better exploit complementary information
and enhance the segmenter? and (2) beyond that, can the segmenter in turn guide
SAM through reciprocal supervision, enabling mutual improvement? To answer
these questions, we present SCALER, a unified collaborative framework toward
LDCOS that jointly optimizes a mean-teacher segmenter and a learnable SAM.
SCALER operates in two alternating phases. In \textbf{Phase
\uppercase\expandafter{\romannumeral1}}, the segmenter is optimized under fixed
SAM supervision using entropy-based image-level and uncertainty-based
pixel-level weighting to select reliable pseudo-label regions and emphasize
harder examples. In \textbf{Phase \uppercase\expandafter{\romannumeral2}}, SAM
is updated via augmentation invariance and noise resistance losses, leveraging
its inherent robustness to perturbations. Experiments demonstrate that SCALER
yields consistent performance gains across eight semi- and weakly-supervised
COS tasks. The results further suggest that SCALER can serve as a general
training paradigm to enhance both lightweight segmenters and large foundation
models under label-scarce conditions. Code will be released.
\\ ( https://arxiv.org/abs/2511.18136 ,  1604kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18139
Date: Sat, 22 Nov 2025 17:52:58 GMT   (1511kb)

Title: Compact neural networks for astronomy with optimal transport bias
 correction
Authors: Shuhuan Wang, Yuzhen Xie, Jiayi Li
Categories: cs.CV
Comments: 18 pages, 5 figures, 3 tables. Research article
MSC-class: 68T05, 49Q22, 62J12
ACM-class: I.2.6; I.5.4; J.2
\\
 Astronomical imaging confronts an efficiency-resolution tradeoff that limits
large-scale morphological classification and redshift prediction. We introduce
WaveletMamba, a theory-driven framework integrating wavelet decomposition with
state-space modeling, mathematical regularization, and multi-level bias
correction. WaveletMamba achieves 81.72% +/- 0.53% classification accuracy at
64x64 resolution with only 3.54M parameters, delivering high-resolution
performance (80.93% +/- 0.27% at 244x244) at low-resolution inputs with 9.7x
computational efficiency gains. The framework exhibits Resolution
Multistability, where models trained on low-resolution data achieve consistent
accuracy across different input scales despite divergent internal
representations. The framework's multi-level bias correction synergizes HK
distance (distribution-level optimal transport) with Color-Aware Weighting
(sample-level fine-tuning), achieving 22.96% Log-MSE improvement and 26.10%
outlier reduction without explicit selection function modeling. Here, we show
that mathematical rigor enables unprecedented efficiency and comprehensive bias
correction in scientific AI, bridging computer vision and astrophysics to
revolutionize interdisciplinary scientific discovery.
\\ ( https://arxiv.org/abs/2511.18139 ,  1511kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18152
Date: Sat, 22 Nov 2025 18:44:01 GMT   (2183kb)

Title: UnfoldLDM: Deep Unfolding-based Blind Image Restoration with Latent
 Diffusion Priors
Authors: Chunming He, Rihan Zhang, Zheng Chen, Bowen Yang, CHengyu Fang,
 Yunlong Lin, Fengyang Xiao, Sina Farsiu
Categories: cs.CV cs.AI
Comments: 6 figures, 11 tables
\\
 Deep unfolding networks (DUNs) combine the interpretability of model-based
methods with the learning ability of deep networks, yet remain limited for
blind image restoration (BIR). Existing DUNs suffer from: (1)
\textbf{Degradation-specific dependency}, as their optimization frameworks are
tied to a known degradation model, making them unsuitable for BIR tasks; and
(2) \textbf{Over-smoothing bias}, resulting from the direct feeding of gradient
descent outputs, dominated by low-frequency content, into the proximal term,
suppressing fine textures. To overcome these issues, we propose UnfoldLDM to
integrate DUNs with latent diffusion model (LDM) for BIR. In each stage,
UnfoldLDM employs a multi-granularity degradation-aware (MGDA) module as the
gradient descent step. MGDA models BIR as an unknown degradation estimation
problem and estimates both the holistic degradation matrix and its decomposed
forms, enabling robust degradation removal. For the proximal step, we design a
degradation-resistant LDM (DR-LDM) to extract compact degradation-invariant
priors from the MGDA output. Guided by this prior, an over-smoothing correction
transformer (OCFormer) explicitly recovers high-frequency components and
enhances texture details. This unique combination ensures the final result is
degradation-free and visually rich. Experiments show that our UnfoldLDM
achieves a leading place on various BIR tasks and benefits downstream tasks.
Moreover, our design is compatible with existing DUN-based methods, serving as
a plug-and-play framework. Code will be released.
\\ ( https://arxiv.org/abs/2511.18152 ,  2183kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18163
Date: Sat, 22 Nov 2025 19:22:10 GMT   (24981kb)

Title: Matching-Based Few-Shot Semantic Segmentation Models Are Interpretable
 by Design
Authors: Pasquale De Marinis, Uzay Kaymak, Rogier Brussee, Gennaro Vessio,
 Giovanna Castellano
Categories: cs.CV
\\
 Few-Shot Semantic Segmentation (FSS) models achieve strong performance in
segmenting novel classes with minimal labeled examples, yet their
decision-making processes remain largely opaque. While explainable AI has
advanced significantly in standard computer vision tasks, interpretability in
FSS remains virtually unexplored despite its critical importance for
understanding model behavior and guiding support set selection in data-scarce
scenarios. This paper introduces the first dedicated method for interpreting
matching-based FSS models by leveraging their inherent structural properties.
Our Affinity Explainer approach extracts attribution maps that highlight which
pixels in support images contribute most to query segmentation predictions,
using matching scores computed between support and query features at multiple
feature levels. We extend standard interpretability evaluation metrics to the
FSS domain and propose additional metrics to better capture the practical
utility of explanations in few-shot scenarios. Comprehensive experiments on FSS
benchmark datasets, using different models, demonstrate that our Affinity
Explainer significantly outperforms adapted standard attribution methods.
Qualitative analysis reveals that our explanations provide structured, coherent
attention patterns that align with model architectures and and enable effective
model diagnosis. This work establishes the foundation for interpretable FSS
research, enabling better model understanding and diagnostic for more reliable
few-shot segmentation systems. The source code is publicly available at
https://github.com/pasqualedem/AffinityExplainer.
\\ ( https://arxiv.org/abs/2511.18163 ,  24981kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18164
Date: Sat, 22 Nov 2025 19:25:48 GMT   (13338kb)

Title: Nested Unfolding Network for Real-World Concealed Object Segmentation
Authors: Chunming He, Rihan Zhang, Dingming Zhang, Fengyang Xiao, Deng-Ping
 Fan, Sina Farsiu
Categories: cs.CV cs.AI
Comments: 6 figures, 14 tables
\\
 Deep unfolding networks (DUNs) have recently advanced concealed object
segmentation (COS) by modeling segmentation as iterative foreground-background
separation. However, existing DUN-based methods (RUN) inherently couple
background estimation with image restoration, leading to conflicting objectives
and requiring pre-defined degradation types, which are unrealistic in
real-world scenarios. To address this, we propose the nested unfolding network
(NUN), a unified framework for real-world COS. NUN adopts a DUN-in-DUN design,
embedding a degradation-resistant unfolding network (DeRUN) within each stage
of a segmentation-oriented unfolding network (SODUN). This design decouples
restoration from segmentation while allowing mutual refinement. Guided by a
vision-language model (VLM), DeRUN dynamically infers degradation semantics and
restores high-quality images without explicit priors, whereas SODUN performs
reversible estimation to refine foreground and background. Leveraging the
multi-stage nature of unfolding, NUN employs image-quality assessment to select
the best DeRUN outputs for subsequent stages, naturally introducing a
self-consistency loss that enhances robustness. Extensive experiments show that
NUN achieves a leading place on both clean and degraded benchmarks. Code will
be released.
\\ ( https://arxiv.org/abs/2511.18164 ,  13338kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18173
Date: Sat, 22 Nov 2025 19:56:39 GMT   (38090kb)

Title: EgoControl: Controllable Egocentric Video Generation via 3D Full-Body
 Poses
Authors: Enrico Pallotta, Sina Mokhtarzadeh Azar, Lars Doorenbos, Serdar Ozsoy,
 Umar Iqbal, Juergen Gall
Categories: cs.CV
\\
 Egocentric video generation with fine-grained control through body motion is
a key requirement towards embodied AI agents that can simulate, predict, and
plan actions. In this work, we propose EgoControl, a pose-controllable video
diffusion model trained on egocentric data. We train a video prediction model
to condition future frame generation on explicit 3D body pose sequences. To
achieve precise motion control, we introduce a novel pose representation that
captures both global camera dynamics and articulated body movements, and
integrate it through a dedicated control mechanism within the diffusion
process. Given a short sequence of observed frames and a sequence of target
poses, EgoControl generates temporally coherent and visually realistic future
frames that align with the provided pose control. Experimental results
demonstrate that EgoControl produces high-quality, pose-consistent egocentric
videos, paving the way toward controllable embodied video simulation and
understanding.
\\ ( https://arxiv.org/abs/2511.18173 ,  38090kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18174
Date: Sat, 22 Nov 2025 19:57:46 GMT   (40107kb)

Title: Unified Spherical Frontend: Learning Rotation-Equivariant
 Representations of Spherical Images from Any Camera
Authors: Mukai Yu, Mosam Dabhi, Liuyue Xie, Sebastian Scherer, L\'aszl\'o A.
 Jeni
Categories: cs.CV
\\
 Modern perception increasingly relies on fisheye, panoramic, and other wide
field-of-view (FoV) cameras, yet most pipelines still apply planar CNNs
designed for pinhole imagery on 2D grids, where image-space neighborhoods
misrepresent physical adjacency and models are sensitive to global rotations.
Frequency-domain spherical CNNs partially address this mismatch but require
costly spherical harmonic transforms that constrain resolution and efficiency.
We introduce the Unified Spherical Frontend (USF), a lens-agnostic framework
that transforms images from any calibrated camera into a unit-sphere
representation via ray-direction correspondences, and performs spherical
resampling, convolution, and pooling directly in the spatial domain. USF is
modular: projection, location sampling, interpolation, and resolution control
are fully decoupled. Its distance-only spherical kernels offer configurable
rotation-equivariance (mirroring translation-equivariance in planar CNNs) while
avoiding harmonic transforms entirely. We compare standard planar backbones
with their spherical counterparts across classification, detection, and
segmentation tasks on synthetic (Spherical MNIST) and real-world datasets
(PANDORA, Stanford 2D-3D-S), and stress-test robustness to extreme lens
distortions, varying FoV, and arbitrary rotations. USF processes
high-resolution spherical imagery efficiently and maintains less than 1%
performance drop under random test-time rotations, even without rotational
augmentation, and even enables zero-shot generalization from one lens type to
unseen wide-FoV lenses with minimal performance degradation.
\\ ( https://arxiv.org/abs/2511.18174 ,  40107kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18185
Date: Sat, 22 Nov 2025 20:40:05 GMT   (840kb)

Title: Early Lung Cancer Diagnosis from Virtual Follow-up LDCT Generation via
 Correlational Autoencoder and Latent Flow Matching
Authors: Yutong Wu, Yifan Wang, Qining Zhang, Chuan Zhou, Lei Ying
Categories: cs.CV
Comments: 10 pages, 3 figures
\\
 Lung cancer is one of the most commonly diagnosed cancers, and early
diagnosis is critical because the survival rate declines sharply once the
disease progresses to advanced stages. However, achieving an early diagnosis
remains challenging, particularly in distinguishing subtle early signals of
malignancy from those of benign conditions. In clinical practice, a patient
with a high risk may need to undergo an initial baseline and several annual
follow-up examinations (e.g., CT scans) before receiving a definitive
diagnosis, which can result in missing the optimal treatment. Recently,
Artificial Intelligence (AI) methods have been increasingly used for early
diagnosis of lung cancer, but most existing algorithms focus on radiomic
features extraction from single early-stage CT scans. Inspired by recent
advances in diffusion models for image generation, this paper proposes a
generative method, named CorrFlowNet, which creates a virtual, one-year
follow-up CT scan after the initial baseline scan. This virtual follow-up would
allow for an early detection of malignant/benign nodules, reducing the need to
wait for clinical follow-ups. During training, our approach employs a
correlational autoencoder to encode both early baseline and follow-up CT images
into a latent space that captures the dynamics of nodule progression as well as
the correlations between them, followed by a flow matching algorithm on the
latent space with a neural ordinary differential equation. An auxiliary
classifier is used to further enhance the diagnostic accuracy. Evaluations on a
real clinical dataset show our method can significantly improve downstream lung
nodule risk assessment compared with existing baseline models. Moreover, its
diagnostic accuracy is comparable with real clinical CT follow-ups,
highlighting its potential to improve cancer diagnosis.
\\ ( https://arxiv.org/abs/2511.18185 ,  840kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18192
Date: Sat, 22 Nov 2025 21:09:28 GMT   (2872kb)

Title: ARIAL: An Agentic Framework for Document VQA with Precise Answer
 Localization
Authors: Ahmad Mohammadshirazi, Pinaki Prasad Guha Neogi, Dheeraj Kulshrestha,
 Rajiv Ramnath
Categories: cs.CV cs.AI
\\
 Document Visual Question Answering (VQA) requires models to not only extract
accurate textual answers but also precisely localize them within document
images, a capability critical for interpretability in high-stakes applications.
However, existing systems achieve strong textual accuracy while producing
unreliable spatial grounding, or sacrifice performance for interpretability. We
present ARIAL (Agentic Reasoning for Interpretable Answer Localization), a
modular framework that orchestrates specialized tools through an LLM-based
planning agent to achieve both precise answer extraction and reliable spatial
grounding. ARIAL decomposes Document VQA into structured subtasks: OCR-based
text extraction with TrOCR, retrieval-augmented context selection using
semantic search, answer generation via a fine-tuned Gemma 3-27B model, and
explicit bounding-box localization through text-to-region alignment. This
modular architecture produces transparent reasoning traces, enabling tool-level
auditability and independent component optimization. We evaluate ARIAL on four
benchmarks (DocVQA, FUNSD, CORD, and SROIE) using both textual accuracy (ANLS)
and spatial precision (mAP at IoU 0.50 to 0.95). ARIAL achieves
state-of-the-art results across all datasets: 88.7 ANLS and 50.1 mAP on DocVQA,
90.0 ANLS and 50.3 mAP on FUNSD, 85.5 ANLS and 60.2 mAP on CORD, and 93.1 ANLS
on SROIE, surpassing the previous best method (DLaVA) by +2.8 ANLS and +3.9 mAP
on DocVQA. Our work demonstrates how agentic orchestration of specialized tools
can simultaneously improve performance and interpretability, providing a
pathway toward trustworthy, explainable document AI systems.
\\ ( https://arxiv.org/abs/2511.18192 ,  2872kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18200
Date: Sat, 22 Nov 2025 22:05:39 GMT   (7105kb)

Title: InfiniBench: Infinite Benchmarking for Visual Spatial Reasoning with
 Customizable Scene Complexity
Authors: Haoming Wang, Qiyao Xue, Wei Gao
Categories: cs.CV
\\
 Modern vision-language models (VLMs) are expected to have abilities of
spatial reasoning with diverse scene complexities, but evaluating such
abilities is difficult due to the lack of benchmarks that are not only diverse
and scalable but also fully customizable. Existing benchmarks offer limited
customizability over the scene complexity and are incapable of isolating and
analyzing specific VLM failure modes under distinct spatial conditions. To
address this gap, instead of individually presenting benchmarks for different
scene complexities, in this paper we present InfiniBench, a fully automated,
customizable and user-friendly benchmark generator that can synthesize a
theoretically infinite variety of 3D scenes with parameterized control on scene
complexity. InfiniBench uniquely translates scene descriptions in natural
language into photo-realistic videos with complex and physically plausible 3D
layouts. This is achieved through three key innovations: 1) a LLM-based agentic
framework that iteratively refines procedural scene constraints from scene
descriptions; 2) a flexible cluster-based layout optimizer that generates dense
and cluttered scenes previously intractable for procedural methods; and 3) a
task-aware camera trajectory optimization method that renders scenes into
videos with full object coverage as VLM input. Experiments demonstrate that
InfiniBench outperforms state-of-the-art procedural and LLM-based 3D generation
methods in prompt fidelity and physical plausibility, especially in
high-complexity scenarios. We further showcased the usefulness of InfiniBench,
by generating benchmarks for representative spatial reasoning tasks including
measurement, perspective-taking and spatiotemporal tracking.
\\ ( https://arxiv.org/abs/2511.18200 ,  7105kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18204
Date: Sat, 22 Nov 2025 22:27:01 GMT   (18727kb)

Title: Generating Synthetic Human Blastocyst Images for In-Vitro Fertilization
 Blastocyst Grading
Authors: Pavan Narahari, Suraj Rajendran, Lorena Bori, Jonas E. Malmsten,
 Qiansheng Zhan, Zev Rosenwaks, Nikica Zaninovic, Iman Hajirasouliha
Categories: cs.CV
Comments: The manuscript is 23 pages, with five main figures and one table. The
 supplemental material includes 23 pages with fourteen figures and four tables
\\
 The success of in vitro fertilization (IVF) at many clinics relies on the
accurate morphological assessment of day 5 blastocysts, a process that is often
subjective and inconsistent. While artificial intelligence can help standardize
this evaluation, models require large, diverse, and balanced datasets, which
are often unavailable due to data scarcity, natural class imbalance, and
privacy constraints. Existing generative embryo models can mitigate these
issues but face several limitations, such as poor image quality, small training
datasets, non-robust evaluation, and lack of clinically relevant image
generation for effective data augmentation. Here, we present the Diffusion
Based Imaging Model for Artificial Blastocysts (DIA) framework, a set of latent
diffusion models trained to generate high-fidelity, novel day 5 blastocyst
images. Our models provide granular control by conditioning on Gardner-based
morphological categories and z-axis focal depth. We rigorously evaluated the
models using FID, a memorization metric, an embryologist Turing test, and three
downstream classification tasks. Our results show that DIA models generate
realistic images that embryologists could not reliably distinguish from real
images. Most importantly, we demonstrated clear clinical value. Augmenting an
imbalanced dataset with synthetic images significantly improved classification
accuracy (p < 0.05). Also, adding synthetic images to an already large,
balanced dataset yielded statistically significant performance gains, and
synthetic data could replace up to 40% of real data in some cases without a
statistically significant loss in accuracy. DIA provides a robust solution for
mitigating data scarcity and class imbalance in embryo datasets. By generating
novel, high-fidelity, and controllable synthetic images, our models can improve
the performance, fairness, and standardization of AI embryo assessment tools.
\\ ( https://arxiv.org/abs/2511.18204 ,  18727kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18208
Date: Sat, 22 Nov 2025 22:44:50 GMT   (746kb)

Title: Large-Scale Pre-training Enables Multimodal AI Differentiation of
 Radiation Necrosis from Brain Metastasis Progression on Routine MRI
Authors: Ahmed Gomaa, Annette Schwarz, Ludwig Singer, Arnd D\"orfler, Matthias
 Stefan May, Pluvio Stephan, Ishita Sheth, Juliane Szkitsak, Katharina
 Breininger, Yixing Huang, Benjamin Frey, Oliver Schnell, Daniel Delev, Roland
 Coras, Daniel H\"ofler, Philipp Schubert, Jenny Stritzelberger, Sabine
 Semrau, Andreas Maier, Dieter H Heiland, Udo S. Gaipl, Andrea Wittig, Rainer
 Fietkau, Christoph Bert, Stefanie Corradini, and Florian Putz
Categories: cs.CV
\\
 Background: Differentiating radiation necrosis (RN) from tumor progression
after stereotactic radiosurgery (SRS) remains a critical challenge in brain
metastases. While histopathology represents the gold standard, its invasiveness
limits feasibility. Conventional supervised deep learning approaches are
constrained by scarce biopsy-confirmed training data. Self-supervised learning
(SSL) overcomes this by leveraging the growing availability of large-scale
unlabeled brain metastases imaging datasets. Methods: In a two-phase deep
learning strategy inspired by the foundation model paradigm, a Vision
Transformer (ViT) was pre-trained via SSL on 10,167 unlabeled multi-source T1CE
MRI sub-volumes. The pre-trained ViT was then fine-tuned for RN classification
using a two-channel input (T1CE MRI and segmentation masks) on the public MOLAB
dataset (n=109) using 20% of datasets as same-center held-out test set.
External validation was performed on a second-center test cohort (n=28).
Results: The self-supervised model achieved an AUC of 0.916 on the same-center
test set and 0.764 on the second center test set, surpassing the fully
supervised ViT (AUC 0.624/0.496; p=0.001/0.008) and radiomics (AUC 0.807/0.691;
p=0.005/0.014). Multimodal integration further improved performance (AUC
0.947/0.821; p=0.073/0.001). Attention map visualizations enabled
interpretability showing the model focused on clinically relevant lesion
subregions. Conclusion: Large-scale pre-training on increasingly available
unlabeled brain metastases datasets substantially improves AI model
performance. A two-phase multimodal deep learning strategy achieved high
accuracy in differentiating radiation necrosis from tumor progression using
only routine T1CE MRI and standard clinical data, providing an interpretable,
clinically accessible solution that warrants further validation.
\\ ( https://arxiv.org/abs/2511.18208 ,  746kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18222
Date: Sat, 22 Nov 2025 23:51:51 GMT   (228kb)

Title: Using MLIR Transform to Design Sliced Convolution Algorithm
Authors: Victor Ferrari, Marcio Pereira, Lucas Alvarenga, Gustavo Leite, Guido
 Araujo
Categories: cs.CV cs.LG cs.PF
\\
 This paper proposes SConvTransform, a Transform dialect extension that
provides operations for optimizing 2D convolutions in MLIR. Its main operation,
SConvOp, lowers Linalg convolutions into tiled and packed generic operations
through a fully declarative transformation pipeline. The process is guided by a
Convolution Slicing Analysis that determines tile sizes and data layout
strategies based on input and filter shapes, as well as target architecture
parameters. SConvOp handles edge cases by splitting irregular regions and
adjusting affine maps where needed. All packing and tiling operations are
derived from a parametric set of affine equations, enabling reusable and
analyzable transformations. Although functional correctness was the primary
goal of this work, the experimental evaluation demonstrates the effectiveness
of SConvTransform, achieving good enough performance across different target
architectures. Future work will focus on optimizing performance and porting to
other target devices. When applied to standard convolution configurations, the
generated code achieves up to 60% of peak performance on ARM SME and 67% on
Intel AVX512. These results validate the benefit of combining static shape
analysis with structured tiling and packing strategies within the MLIR
Transform dialect. Furthermore, the modular design of SConvTransform
facilitates integration with future extensions, enabling continued optimization
of convolution workloads through MLIR's extensible compilation infrastructure.
\\ ( https://arxiv.org/abs/2511.18222 ,  228kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18232
Date: Sun, 23 Nov 2025 00:45:05 GMT   (563kb)

Title: Parallel qMRI Reconstruction from 4x Accelerated Acquisitions
Authors: Mingi Kang
Categories: cs.CV
\\
 Magnetic Resonance Imaging (MRI) acquisitions require extensive scan times,
limiting patient throughput and increasing susceptibility to motion artifacts.
Accelerated parallel MRI techniques reduce acquisition time by undersampling
k-space data, but require robust reconstruction methods to recover high-quality
images. Traditional approaches like SENSE require both undersampled k-space
data and pre-computed coil sensitivity maps. We propose an end-to-end deep
learning framework that jointly estimates coil sensitivity maps and
reconstructs images from only undersampled k-space measurements at 4x
acceleration. Our two-module architecture consists of a Coil Sensitivity Map
(CSM) estimation module and a U-Net-based MRI reconstruction module. We
evaluate our method on multi-coil brain MRI data from 10 subjects with 8 echoes
each, using 2x SENSE reconstructions as ground truth. Our approach produces
visually smoother reconstructions compared to conventional SENSE output,
achieving comparable visual quality despite lower PSNR/SSIM metrics. We
identify key challenges including spatial misalignment between different
acceleration factors and propose future directions for improved reconstruction
quality.
\\ ( https://arxiv.org/abs/2511.18232 ,  563kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18242
Date: Sun, 23 Nov 2025 01:25:17 GMT   (15427kb)

Title: EgoVITA: Learning to Plan and Verify for Egocentric Video Reasoning
Authors: Yogesh Kulkarni, Pooyan Fazli
Categories: cs.CV
\\
 Reasoning about intentions and actions from a first-person (egocentric)
perspective remains a fundamental challenge for multimodal large language
models (MLLMs). Unlike third-person (exocentric) videos that capture scenes
from an outside observer, egocentric videos reflect the actor's continuously
changing viewpoint, introducing partial observability, limited field of view,
and self-referenced motion. We introduce $\textbf{EgoVITA}$, a reinforcement
learning framework that enables MLLMs to reason through structured planning and
verification. Built on Group Relative Policy Optimization (GRPO), EgoVITA
alternates between two stages: (1) an $\textbf{egocentric planning phase}$,
where the model reasons from a first-person viewpoint to predict a step-by-step
plan of future actions, and (2) an $\textbf{exocentric verification phase}$,
where it switches to a third-person perspective to check the visual and logical
consistency of that plan. Through GRPO, the model learns to make plans that are
causally predictive of upcoming visual observations, leading to more coherent
and visually grounded reasoning. EgoVITA achieves significant gains on
egocentric reasoning tasks, outperforming the baseline Qwen2.5-VL-7B by
$\mathbf{+7.7}$ on EgoBlind and $\mathbf{+4.4}$ on EgoOrient, while maintaining
strong generalization on exocentric video tasks.
\\ ( https://arxiv.org/abs/2511.18242 ,  15427kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18254
Date: Sun, 23 Nov 2025 02:51:42 GMT   (13683kb)

Title: UniFlow: Towards Zero-Shot LiDAR Scene Flow for Autonomous Vehicles via
 Cross-Domain Generalization
Authors: Siyi Li, Qingwen Zhang, Ishan Khatri, Kyle Vedder, Deva Ramanan,
 Neehar Peri
Categories: cs.CV
Comments: Project Page: https://lisiyi777.github.io/UniFlow/
\\
 LiDAR scene flow is the task of estimating per-point 3D motion between
consecutive point clouds. Recent methods achieve centimeter-level accuracy on
popular autonomous vehicle (AV) datasets, but are typically only trained and
evaluated on a single sensor. In this paper, we aim to learn general motion
priors that transfer to diverse and unseen LiDAR sensors. However, prior work
in LiDAR semantic segmentation and 3D object detection demonstrate that naively
training on multiple datasets yields worse performance than single dataset
models. Interestingly, we find that this conventional wisdom does not hold for
motion estimation, and that state-of-the-art scene flow methods greatly benefit
from cross-dataset training. We posit that low-level tasks such as motion
estimation may be less sensitive to sensor configuration; indeed, our analysis
shows that models trained on fast-moving objects (e.g., from highway datasets)
perform well on fast-moving objects, even across different datasets. Informed
by our analysis, we propose UniFlow, a family of feedforward models that
unifies and trains on multiple large-scale LiDAR scene flow datasets with
diverse sensor placements and point cloud densities. Our frustratingly simple
solution establishes a new state-of-the-art on Waymo and nuScenes, improving
over prior work by 5.1% and 35.2% respectively. Moreover, UniFlow achieves
state-of-the-art accuracy on unseen datasets like TruckScenes, outperforming
prior TruckScenes-specific models by 30.1%.
\\ ( https://arxiv.org/abs/2511.18254 ,  13683kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18255
Date: Sun, 23 Nov 2025 02:58:10 GMT   (22854kb)

Title: Sequence-Adaptive Video Prediction in Continuous Streams using Diffusion
 Noise Optimization
Authors: Sina Mokhtarzadeh Azar, Emad Bahrami, Enrico Pallotta, Gianpiero
 Francesca, Radu Timofte, Juergen Gall
Categories: cs.CV
\\
 In this work, we investigate diffusion-based video prediction models, which
forecast future video frames, for continuous video streams. In this context,
the models observe continuously new training samples, and we aim to leverage
this to improve their predictions. We thus propose an approach that
continuously adapts a pre-trained diffusion model to a video stream. Since
fine-tuning the parameters of a large diffusion model is too expensive, we
refine the diffusion noise during inference while keeping the model parameters
frozen, allowing the model to adaptively determine suitable sampling noise. We
term the approach Sequence Adaptive Video Prediction with Diffusion Noise
Optimization (SAVi-DNO). To validate our approach, we introduce a new
evaluation setting on the Ego4D dataset, focusing on simultaneous adaptation
and evaluation on long continuous videos. Empirical results demonstrate
improved performance based on FVD, SSIM, and PSNR metrics on long videos of
Ego4D and OpenDV-YouTube, as well as videos of UCF-101 and SkyTimelapse,
showcasing SAVi-DNO's effectiveness.
\\ ( https://arxiv.org/abs/2511.18255 ,  22854kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18262
Date: Sun, 23 Nov 2025 03:25:39 GMT   (7213kb)

Title: MammothModa2: A Unified AR-Diffusion Framework for Multimodal
 Understanding and Generation
Authors: Tao Shen, Xin Wan, Taicai Chen, Rui Zhang, Junwen Pan, Dawei Lu,
 Fanding Lei, Zhilin Lu, Yunfei Yang, Chen Cheng, Qi She, Chang Liu and
 Zhenbang Sun
Categories: cs.CV
\\
 Unified multimodal models aim to integrate understanding and generation
within a single framework, yet bridging the gap between discrete semantic
reasoning and high-fidelity visual synthesis remains challenging. We present
MammothModa2 (Mammoth2), a unified autoregressive-diffusion (AR-Diffusion)
framework designed to effectively couple autoregressive semantic planning with
diffusion-based generation. Mammoth2 adopts a serial design: an AR path
equipped with generation experts performs global semantic modeling over
discrete tokens, while a single-stream Diffusion Transformer (DiT) decoder
handles high-fidelity image synthesis. A carefully designed AR-Diffusion
feature alignment module combines multi-layer feature aggregation, unified
condition encoding, and in-context conditioning to stably align AR's
representations with the diffusion decoder's continuous latents. Mammoth2 is
trained end-to-end with joint Next-Token Prediction and Flow Matching
objectives, followed by supervised fine-tuning and reinforcement learning over
both generation and editing. With roughly 60M supervised generation samples and
no reliance on pre-trained generators, Mammoth2 delivers strong text-to-image
and instruction-based editing performance on public benchmarks, achieving 0.87
on GenEval, 87.2 on DPGBench, and 4.06 on ImgEdit, while remaining competitive
with understanding-only backbones (e.g., Qwen3-VL-8B) on multimodal
understanding tasks. These results suggest that a carefully coupled
AR-Diffusion architecture can provide high-fidelity generation and editing
while maintaining strong multimodal comprehension within a single, parameter-
and data-efficient model.
\\ ( https://arxiv.org/abs/2511.18262 ,  7213kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18264
Date: Sun, 23 Nov 2025 03:26:57 GMT   (5645kb)

Title: SatSAM2: Motion-Constrained Video Object Tracking in Satellite Imagery
 using Promptable SAM2 and Kalman Priors
Authors: Ruijie Fan, Junyan Ye, Huan Chen, Zilong Huang, Xiaolei Wang, Weijia
 Li
Categories: cs.CV
\\
 Existing satellite video tracking methods often struggle with generalization,
requiring scenario-specific training to achieve satisfactory performance, and
are prone to track loss in the presence of occlusion. To address these
challenges, we propose SatSAM2, a zero-shot satellite video tracker built on
SAM2, designed to adapt foundation models to the remote sensing domain. SatSAM2
introduces two core modules: a Kalman Filter-based Constrained Motion Module
(KFCMM) to exploit temporal motion cues and suppress drift, and a
Motion-Constrained State Machine (MCSM) to regulate tracking states based on
motion dynamics and reliability. To support large-scale evaluation, we propose
MatrixCity Video Object Tracking (MVOT), a synthetic benchmark containing
1,500+ sequences and 157K annotated frames with diverse viewpoints,
illumination, and occlusion conditions. Extensive experiments on two satellite
tracking benchmarks and MVOT show that SatSAM2 outperforms both traditional and
foundation model-based trackers, including SAM2 and its variants. Notably, on
the OOTB dataset, SatSAM2 achieves a 5.84% AUC improvement over
state-of-the-art methods. Our code and dataset will be publicly released to
encourage further research.
\\ ( https://arxiv.org/abs/2511.18264 ,  5645kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18271
Date: Sun, 23 Nov 2025 03:44:54 GMT   (3985kb)

Title: Beyond Words and Pixels: A Benchmark for Implicit World Knowledge
 Reasoning in Generative Models
Authors: Tianyang Han, Junhao Su, Junjie Hu, Peizhen Yang, Hengyu Shi, Junfeng
 Luo, Jialin Gao
Categories: cs.CV cs.AI
\\
 Text-to-image (T2I) models today are capable of producing photorealistic,
instruction-following images, yet they still frequently fail on prompts that
require implicit world knowledge. Existing evaluation protocols either
emphasize compositional alignment or rely on single-round VQA-based scoring,
leaving critical dimensions such as knowledge grounding, multi-physics
interactions, and auditable evidence-substantially undertested. To address
these limitations, we introduce PicWorld, the first comprehensive benchmark
that assesses the grasp of implicit world knowledge and physical causal
reasoning of T2I models. This benchmark consists of 1,100 prompts across three
core categories. To facilitate fine-grained evaluation, we propose PW-Agent, an
evidence-grounded multi-agent evaluator to hierarchically assess images on
their physical realism and logical consistency by decomposing prompts into
verifiable visual evidence. We conduct a thorough analysis of 17 mainstream T2I
models on PicWorld, illustrating that they universally exhibit a fundamental
limitation in their capacity for implicit world knowledge and physical causal
reasoning to varying degrees. The findings highlight the need for
reasoning-aware, knowledge-integrative architectures in future T2I systems.
\\ ( https://arxiv.org/abs/2511.18271 ,  3985kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18272
Date: Sun, 23 Nov 2025 03:45:22 GMT   (31kb)

Title: Vision Token Masking Alone Cannot Prevent PHI Leakage in Medical
 Document OCR: A Systematic Evaluation
Authors: Richard J. Young
Categories: cs.CV cs.CR
Comments: 24 pages, 11 figures, 2 tables
ACM-class: I.2.10; I.4.9; K.4.1
\\
 Large vision-language models (VLMs) are increasingly deployed for optical
character recognition (OCR) in healthcare settings, raising critical concerns
about protected health information (PHI) exposure during document processing.
This work presents the first systematic evaluation of inference-time vision
token masking as a privacy-preserving mechanism for medical document OCR using
DeepSeek-OCR. We introduce seven masking strategies (V3-V9) targeting different
architectural layers (SAM encoder blocks, compression layers, dual vision
encoders, projector fusion) and evaluate PHI reduction across HIPAA-defined
categories using 100 synthetic medical billing statements (drawn from a corpus
of 38,517 annotated documents) with perfect ground-truth annotations. All
masking strategies converge to 42.9% PHI reduction, successfully suppressing
long-form spatially-distributed identifiers (patient names, dates of birth,
physical addresses at 100% effectiveness) while failing to prevent short
structured identifiers (medical record numbers, social security numbers, email
addresses, account numbers at 0% effectiveness). Ablation studies varying mask
expansion radius (r=1,2,3) demonstrate that increased spatial coverage does not
improve reduction beyond this ceiling, indicating that language model
contextual inference - not insufficient visual masking - drives structured
identifier leakage. A simulated hybrid architecture combining vision masking
with NLP post-processing achieves 88.6% total PHI reduction (assuming 80% NLP
accuracy on remaining identifiers). This negative result establishes boundaries
for vision-only privacy interventions in VLMs, provides guidance distinguishing
PHI types amenable to vision-level versus language-level redaction, and
redirects future research toward decoder-level fine-tuning and hybrid
defense-in-depth architectures for HIPAA-compliant medical document processing.
\\ ( https://arxiv.org/abs/2511.18272 ,  31kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18277
Date: Sun, 23 Nov 2025 03:59:59 GMT   (23188kb)

Title: Point-to-Point: Sparse Motion Guidance for Controllable Video Editing
Authors: Yeji Song, Jaehyun Lee, Mijin Koo, JunHoo Lee and Nojun Kwak
Categories: cs.CV
\\
 Accurately preserving motion while editing a subject remains a core challenge
in video editing tasks. Existing methods often face a trade-off between edit
and motion fidelity, as they rely on motion representations that are either
overfitted to the layout or only implicitly defined. To overcome this
limitation, we revisit point-based motion representation. However, identifying
meaningful points remains challenging without human input, especially across
diverse video scenarios. To address this, we propose a novel motion
representation, anchor tokens, that capture the most essential motion patterns
by leveraging the rich prior of a video diffusion model. Anchor tokens encode
video dynamics compactly through a small number of informative point
trajectories and can be flexibly relocated to align with new subjects. This
allows our method, Point-to-Point, to generalize across diverse scenarios.
Extensive experiments demonstrate that anchor tokens lead to more controllable
and semantically aligned video edits, achieving superior performance in terms
of edit and motion fidelity.
\\ ( https://arxiv.org/abs/2511.18277 ,  23188kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18281
Date: Sun, 23 Nov 2025 04:22:42 GMT   (10569kb)

Title: Uni-DAD: Unified Distillation and Adaptation of Diffusion Models for
 Few-step Few-shot Image Generation
Authors: Yara Bahram, Melodie Desbos, Mohammadhadi Shateri, Eric Granger
Categories: cs.CV cs.AI
Comments: Under review paper at CVPR 2026
\\
 Diffusion models (DMs) produce high-quality images, yet their sampling
remains costly when adapted to new domains. Distilled DMs are faster but
typically remain confined within their teacher's domain. Thus, fast and
high-quality generation for novel domains relies on two-stage training
pipelines: Adapt-then-Distill or Distill-then-Adapt. However, both add design
complexity and suffer from degraded quality or diversity. We introduce Uni-DAD,
a single-stage pipeline that unifies distillation and adaptation of DMs. It
couples two signals during training: (i) a dual-domain distribution-matching
distillation objective that guides the student toward the distributions of the
source teacher and a target teacher, and (ii) a multi-head generative
adversarial network (GAN) loss that encourages target realism across multiple
feature scales. The source domain distillation preserves diverse source
knowledge, while the multi-head GAN stabilizes training and reduces
overfitting, especially in few-shot regimes. The inclusion of a target teacher
facilitates adaptation to more structurally distant domains. We perform
evaluations on a variety of datasets for few-shot image generation (FSIG) and
subject-driven personalization (SDP). Uni-DAD delivers higher quality than
state-of-the-art (SoTA) adaptation methods even with less than 4 sampling
steps, and outperforms two-stage training pipelines in both quality and
diversity.
\\ ( https://arxiv.org/abs/2511.18281 ,  10569kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18286
Date: Sun, 23 Nov 2025 04:40:50 GMT   (2556kb)

Title: RoadSceneVQA: Benchmarking Visual Question Answering in Roadside
 Perception Systems for Intelligent Transportation System
Authors: Runwei Guan, Rongsheng Hu, Shangshu Chen, Ningyuan Xiao, Xue Xia,
 Jiayang Liu, Beibei Chen, Ziren Tang, Ningwei Ouyang, Shaofeng Liang, Yuxuan
 Fan, Wanjie Sun, Yutao Yue
Categories: cs.CV
Comments: 9 pages, 6 figures, accepted by AAAI 2026. The model is also called
 Dream, to the other me in the world forever
\\
 Current roadside perception systems mainly focus on instance-level
perception, which fall short in enabling interaction via natural language and
reasoning about traffic behaviors in context. To bridge this gap, we introduce
RoadSceneVQA, a large-scale and richly annotated visual question answering
(VQA) dataset specifically tailored for roadside scenarios. The dataset
comprises 34,736 diverse QA pairs collected under varying weather,
illumination, and traffic conditions, targeting not only object attributes but
also the intent, legality, and interaction patterns of traffic participants.
RoadSceneVQA challenges models to perform both explicit recognition and
implicit commonsense reasoning, grounded in real-world traffic rules and
contextual dependencies. To fully exploit the reasoning potential of
Multi-modal Large Language Models (MLLMs), we further propose CogniAnchor
Fusion (CAF), a vision-language fusion module inspired by human-like scene
anchoring mechanisms. Moreover, we propose the Assisted Decoupled
Chain-of-Thought (AD-CoT) to enhance the reasoned thinking via CoT prompting
and multi-task learning. Based on the above, we propose the baseline model
RoadMind. Experiments on RoadSceneVQA and CODA-LM benchmark show that the
pipeline consistently improves both reasoning accuracy and computational
efficiency, allowing the MLLM to achieve state-of-the-art performance in
structural traffic perception and reasoning tasks.
\\ ( https://arxiv.org/abs/2511.18286 ,  2556kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18290
Date: Sun, 23 Nov 2025 05:03:49 GMT   (41117kb)

Title: SwiftVGGT: A Scalable Visual Geometry Grounded Transformer for
 Large-Scale Scenes
Authors: Jungho Lee, Minhyeok Lee, Sunghun Yang, Minseok Kang, Sangyoun Lee
Categories: cs.CV cs.AI
Comments: Project Page: https://Jho-Yonsei.github.io/SwiftVGGT/
\\
 3D reconstruction in large-scale scenes is a fundamental task in 3D
perception, but the inherent trade-off between accuracy and computational
efficiency remains a significant challenge. Existing methods either prioritize
speed and produce low-quality results, or achieve high-quality reconstruction
at the cost of slow inference times. In this paper, we propose SwiftVGGT, a
training-free method that significantly reduce inference time while preserving
high-quality dense 3D reconstruction. To maintain global consistency in
large-scale scenes, SwiftVGGT performs loop closure without relying on the
external Visual Place Recognition (VPR) model. This removes redundant
computation and enables accurate reconstruction over kilometer-scale
environments. Furthermore, we propose a simple yet effective point sampling
method to align neighboring chunks using a single Sim(3)-based Singular Value
Decomposition (SVD) step. This eliminates the need for the Iteratively
Reweighted Least Squares (IRLS) optimization commonly used in prior work,
leading to substantial speed-ups. We evaluate SwiftVGGT on multiple datasets
and show that it achieves state-of-the-art reconstruction quality while
requiring only 33% of the inference time of recent VGGT-based large-scale
reconstruction approaches.
\\ ( https://arxiv.org/abs/2511.18290 ,  41117kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18305
Date: Sun, 23 Nov 2025 06:04:50 GMT   (6315kb)

Title: DiVE-k: Differential Visual Reasoning for Fine-grained Image Recognition
Authors: Raja Kumar, Arka Sadhu, Ram Nevatia
Categories: cs.CV
\\
 Large Vision Language Models (LVLMs) possess extensive text knowledge but
struggles to utilize this knowledge for fine-grained image recognition, often
failing to differentiate between visually similar categories. Existing
fine-tuning methods using Reinforcement Learning (RL) with exact-match reward
signals are often brittle, encourage memorization of training categories, and
fail to elicit differential reasoning needed for generalization to unseen
classes. To address this, we propose $\textbf{DiVE-k}$, $\textbf{Di}$fferential
$\textbf{V}$isual r$\textbf{E}$asoning using top-$\textbf{k}$ generations,
framework that leverages model's own top-k predictions as a training signal.
For each training image, DiVE-k creates a multiple-choice question from the
model's top-k outputs and uses RL to train the model to select the correct
answer. This approach requires the model to perform fine-grained differential
reasoning among plausible options and provides a simple, verifiable reward
signal that mitigates memorization and improves generalization. Experiments on
five standard fine-grained datasets show that our method significantly
outperforms existing approaches. In the standard base-to-novel generalization
setting, DiVE-k surpasses the QWEN2.5-VL-7B and ViRFT by 10.04% and 6.16% on
the Harmonic Mean metric, respectively. Further experiments show similar gains
in mixed-domain and few-shot scenarios.
\\ ( https://arxiv.org/abs/2511.18305 ,  6315kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18307
Date: Sun, 23 Nov 2025 06:38:23 GMT   (9270kb)

Title: ScriptViT: Vision Transformer-Based Personalized Handwriting Generation
Authors: Sajjan Acharya, Rajendra Baskota
Categories: cs.CV cs.AI cs.LG
\\
 Styled handwriting generation aims to synthesize handwritten text that looks
both realistic and aligned with a specific writer's style. While recent
approaches involving GAN, transformer and diffusion-based models have made
progress, they often struggle to capture the full spectrum of writer-specific
attributes, particularly global stylistic patterns that span long-range spatial
dependencies. As a result, capturing subtle writer-specific traits such as
consistent slant, curvature or stroke pressure, while keeping the generated
text accurate is still an open problem. In this work, we present a unified
framework designed to address these limitations. We introduce a Vision
Transformer-based style encoder that learns global stylistic patterns from
multiple reference images, allowing the model to better represent long-range
structural characteristics of handwriting. We then integrate these style cues
with the target text using a cross-attention mechanism, enabling the system to
produce handwritten images that more faithfully reflect the intended style. To
make the process more interpretable, we utilize Salient Stroke Attention
Analysis (SSAA), which reveals the stroke-level features the model focuses on
during style transfer. Together, these components lead to handwriting synthesis
that is not only more stylistically coherent, but also easier to understand and
analyze.
\\ ( https://arxiv.org/abs/2511.18307 ,  9270kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18316
Date: Sun, 23 Nov 2025 07:09:56 GMT   (772kb)

Title: Stro-VIGRU: Defining the Vision Recurrent-Based Baseline Model for Brain
 Stroke Classification
Authors: Subhajeet Das, Pritam Paul, Rohit Bahadur and Sohan Das
Categories: cs.CV
Comments: Presented at the International Conference on Computational
 Intelligence and Data Communication, Accepted for publication in the Taylor
 and Francis Conference Proceedings
\\
 Stroke majorly causes death and disability worldwide, and early recognition
is one of the key elements of successful treatment of the same. It is common to
diagnose strokes using CT scanning, which is fast and readily available,
however, manual analysis may take time and may result in mistakes. In this
work, a pre-trained Vision Transformer-based transfer learning framework is
proposed for the early identification of brain stroke. A few of the encoder
blocks of the ViT model are frozen, and the rest are allowed to be fine-tuned
in order to learn brain stroke-specific features. The features that have been
extracted are given as input to a single-layer Bi-GRU to perform
classification. Class imbalance is handled by data augmentation. The model has
achieved 94.06% accuracy in classifying brain stroke from the Stroke Dataset.
\\ ( https://arxiv.org/abs/2511.18316 ,  772kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18317
Date: Sun, 23 Nov 2025 07:10:07 GMT   (8959kb)

Title: Optimal Pose Guidance for Stereo Calibration in 3D Deformation
 Measurement
Authors: Dongcai Tan, Shunkun Liang, Bin Li, Banglei Guan, Ang Su, Yuan Lin,
 Dapeng Zhang, Minggang Wan, Zibin Liu, Chenglong Wang, Jiajian Zhu, Zhang Li,
 Yang Shang, and Qifeng Yu
Categories: cs.CV
\\
 Stereo optical measurement techniques, such as digital image correlation
(DIC), are widely used in 3D deformation measurement as non-contact, full-field
measurement methods, in which stereo calibration is a crucial step. However,
current stereo calibration methods lack intuitive optimal pose guidance,
leading to inefficiency and suboptimal accuracy in deformation measurements.
The aim of this study is to develop an interactive calibration framework that
automatically generates the next optimal pose, enabling high-accuracy stereo
calibration for 3D deformation measurement. We propose a pose optimization
method that introduces joint optimization of relative and absolute extrinsic
parameters, with the minimization of the covariance matrix trace adopted as the
loss function to solve for the next optimal pose. Integrated with this method
is a user-friendly graphical interface, which guides even non-expert users to
capture qualified calibration images. Our proposed method demonstrates superior
efficiency (requiring fewer images) and accuracy (demonstrating lower
measurement errors) compared to random pose, while maintaining robustness
across varying FOVs. In the thermal deformation measurement tests on an
S-shaped specimen, the results exhibit high agreement with finite element
analysis (FEA) simulations in both deformation magnitude and evolutionary
trends. We present a pose guidance method for high-precision stereo calibration
in 3D deformation measurement. The simulation experiments, real-world
experiments, and thermal deformation measurement applications all demonstrate
the significant application potential of our proposed method in the field of 3D
deformation measurement.
 Keywords: Stereo calibration, Optimal pose guidance, 3D deformation
measurement, Digital image correlation
\\ ( https://arxiv.org/abs/2511.18317 ,  8959kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18326
Date: Sun, 23 Nov 2025 07:31:41 GMT   (758kb)

Title: General vs Domain-Specific CNNs: Understanding Pretraining Effects on
 Brain MRI Tumor Classification
Authors: Helia Abedini, Saba Rahimi, and Reza Vaziri
Categories: cs.CV cs.AI
\\
 Brain tumor detection from MRI scans plays a crucial role in early diagnosis
and treatment planning. Deep convolutional neural networks (CNNs) have
demonstrated strong performance in medical imaging tasks, particularly when
pretrained on large datasets. However, it remains unclear which type of
pretrained model performs better when only a small dataset is available: those
trained on domain-specific medical data or those pretrained on large general
datasets. In this study, we systematically evaluate three pretrained CNN
architectures for brain tumor classification: RadImageNet DenseNet121 with
medical-domain pretraining, EfficientNetV2S, and ConvNeXt-Tiny, which are
modern general-purpose CNNs. All models were trained and fine-tuned under
identical conditions using a limited-size brain MRI dataset to ensure a fair
comparison. Our results reveal that ConvNeXt-Tiny achieved the highest
accuracy, followed by EfficientNetV2S, while RadImageNet DenseNet121, despite
being pretrained on domain-specific medical data, exhibited poor generalization
with lower accuracy and higher loss. These findings suggest that
domain-specific pretraining may not generalize well under small-data
conditions. In contrast, modern, deeper general-purpose CNNs pretrained on
large-scale datasets can offer superior transfer learning performance in
specialized medical imaging tasks.
\\ ( https://arxiv.org/abs/2511.18326 ,  758kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18329
Date: Sun, 23 Nov 2025 07:50:59 GMT   (7809kb)

Title: SciPostLayoutTree: A Dataset for Structural Analysis of Scientific
 Posters
Authors: Shohei Tanaka, Atsushi Hashimoto, and Yoshitaka Ushiku
Categories: cs.CV
\\
 Scientific posters play a vital role in academic communication by presenting
ideas through visual summaries. Analyzing reading order and parent-child
relations of posters is essential for building structure-aware interfaces that
facilitate clear and accurate understanding of research content. Despite their
prevalence in academic communication, posters remain underexplored in
structural analysis research, which has primarily focused on papers. To address
this gap, we constructed SciPostLayoutTree, a dataset of approximately 8,000
posters annotated with reading order and parent-child relations. Compared to an
existing structural analysis dataset, SciPostLayoutTree contains more instances
of spatially challenging relations, including upward, horizontal, and
long-distance relations. As a solution to these challenges, we develop Layout
Tree Decoder, which incorporates visual features as well as bounding box
features including position and category information. The model also uses beam
search to predict relations while capturing sequence-level plausibility.
Experimental results demonstrate that our model improves the prediction
accuracy for spatially challenging relations and establishes a solid baseline
for poster structure analysis. The dataset is publicly available at
https://huggingface.co/datasets/omron-sinicx/scipostlayouttree. The code is
also publicly available at https://github.com/omron-sinicx/scipostlayouttree.
\\ ( https://arxiv.org/abs/2511.18329 ,  7809kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18333
Date: Sun, 23 Nov 2025 08:14:53 GMT   (12045kb)

Title: ConsistCompose: Unified Multimodal Layout Control for Image Composition
Authors: Xuanke Shi, Boxuan Li, Xiaoyang Han, Zhongang Cai, Lei Yang, Dahua
 Lin, Quan Wang
Categories: cs.CV
Comments: 22 pages, 17 figures
\\
 Unified multimodal models that couple visual understanding with image
generation have advanced rapidly, yet most systems still focus on visual
grounding-aligning language with image regions-while their generative
counterpart, linguistic-embedded layout-grounded generation (LELG) for
layout-controllable multi-instance generation, remains underexplored and limits
precise compositional control. We present ConsistCompose, a unified multimodal
framework that embeds layout coordinates directly into language prompts,
enabling layout-controlled multi-instance image generation from Interleaved
Image-Text within a single generative interface. We further construct
ConsistCompose3M, a 3.4M multi-instance generation dataset with layout and
identity annotations (2.6M text-guided and 0.8M image-guided data pairs) that
provides large-scale supervision for layout-conditioned generation. Within this
framework, LELG is instantiated through instance-coordinate binding prompts and
coordinate-aware classifier-free guidance, which translate linguistic layout
cues into precise spatial control without task-specific branches. Experiments
on COCO-Position and MS-Bench show that ConsistCompose substantially improves
spatial accuracy over layout-controlled baselines while preserving identity
fidelity and competitive general multimodal understanding, establishing a
unified paradigm for layout-controllable multimodal image generation.
\\ ( https://arxiv.org/abs/2511.18333 ,  12045kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18344
Date: Sun, 23 Nov 2025 08:42:17 GMT   (11126kb)

Title: A Tri-Modal Dataset and a Baseline System for Tracking Unmanned Aerial
 Vehicles
Authors: Tianyang Xu, Jinjie Gu, Xuefeng Zhu, XiaoJun Wu and Josef Kittler
Categories: cs.CV
\\
 With the proliferation of low altitude unmanned aerial vehicles (UAVs),
visual multi-object tracking is becoming a critical security technology,
demanding significant robustness even in complex environmental conditions.
However, tracking UAVs using a single visual modality often fails in
challenging scenarios, such as low illumination, cluttered backgrounds, and
rapid motion. Although multi-modal multi-object UAV tracking is more resilient,
the development of effective solutions has been hindered by the absence of
dedicated public datasets. To bridge this gap, we release MM-UAV, the first
large-scale benchmark for Multi-Modal UAV Tracking, integrating three key
sensing modalities, e.g. RGB, infrared (IR), and event signals. The dataset
spans over 30 challenging scenarios, with 1,321 synchronised multi-modal
sequences, and more than 2.8 million annotated frames. Accompanying the
dataset, we provide a novel multi-modal multi-UAV tracking framework, designed
specifically for UAV tracking applications and serving as a baseline for future
research. Our framework incorporates two key technical innovations, e.g. an
offset-guided adaptive alignment module to resolve spatio mismatches across
sensors, and an adaptive dynamic fusion module to balance complementary
information conveyed by different modalities. Furthermore, to overcome the
limitations of conventional appearance modelling in multi-object tracking, we
introduce an event-enhanced association mechanism that leverages motion cues
from the event modality for more reliable identity maintenance. Comprehensive
experiments demonstrate that the proposed framework consistently outperforms
state-of-the-art methods. To foster further research in multi-modal UAV
tracking, both the dataset and source code will be made publicly available at
https://xuefeng-zhu5.github.io/MM-UAV/.
\\ ( https://arxiv.org/abs/2511.18344 ,  11126kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18346
Date: Sun, 23 Nov 2025 08:45:17 GMT   (8881kb)

Title: FlowPortal: Residual-Corrected Flow for Training-Free Video Relighting
 and Background Replacement
Authors: Wenshuo Gao, Junyi Fan, Jiangyue Zeng, Shuai Yang
Categories: cs.CV
Comments: Project Page: https://gaowenshuo.github.io/FlowPortalProject/
\\
 Video relighting with background replacement is a challenging task critical
for applications in film production and creative media. Existing methods
struggle to balance temporal consistency, spatial fidelity, and illumination
naturalness. To address these issues, we introduce FlowPortal, a novel
training-free flow-based video relighting framework. Our core innovation is a
Residual-Corrected Flow mechanism that transforms a standard flow-based model
into an editing model, guaranteeing perfect reconstruction when input
conditions are identical and enabling faithful relighting when they differ,
resulting in high structural consistency. This is further enhanced by a
Decoupled Condition Design for precise lighting control and a High-Frequency
Transfer mechanism for detail preservation. Additionally, a masking strategy
isolates foreground relighting from background pure generation process.
Experiments demonstrate that FlowPortal achieves superior performance in
temporal coherence, structural preservation, and lighting realism, while
maintaining high efficiency. Project Page:
https://gaowenshuo.github.io/FlowPortalProject/.
\\ ( https://arxiv.org/abs/2511.18346 ,  8881kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18352
Date: Sun, 23 Nov 2025 08:59:47 GMT   (10569kb)

Title: MagicWand: A Universal Agent for Generation and Evaluation Aligned with
 User Preference
Authors: Zitong Xu, Dake Shen, Yaosong Du, Kexiang Hao, Jinghan Huang, Xiande
 Huang
Categories: cs.CV
\\
 Recent advances in AIGC (Artificial Intelligence Generated Content) models
have enabled significant progress in image and video generation. However, users
still struggle to obtain content that aligns with their preferences due to the
difficulty of crafting detailed prompts and the lack of mechanisms to retain
their preferences. To address these challenges, we construct
\textbf{UniPrefer-100K}, a large-scale dataset comprising images, videos, and
associated text that describes the styles users tend to prefer. Based on
UniPrefer-100K, we propose \textbf{MagicWand}, a universal generation and
evaluation agent that enhances prompts based on user preferences, leverages
advanced generation models for high-quality content, and applies
preference-aligned evaluation and refinement. In addition, we introduce
\textbf{UniPreferBench}, the first large-scale benchmark with over 120K
annotations for assessing user preference alignment across diverse AIGC tasks.
Experiments on UniPreferBench demonstrate that MagicWand consistently generates
content and evaluations that are well aligned with user preferences across a
wide range of scenarios.
\\ ( https://arxiv.org/abs/2511.18352 ,  10569kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18359
Date: Sun, 23 Nov 2025 09:12:48 GMT   (109155kb)

Title: TRANSPORTER: Transferring Visual Semantics from VLM Manifolds
Authors: Alexandros Stergiou
Categories: cs.CV
Comments: Project page: https://alexandrosstergiou.github.io/TRANSPORTER
\\
 How do video understanding models acquire their answers? Although current
Vision Language Models (VLMs) reason over complex scenes with diverse objects,
action performances, and scene dynamics, understanding and controlling their
internal processes remains an open challenge. Motivated by recent advancements
in text-to-video (T2V) generative models, this paper introduces a
logits-to-video (L2V) task alongside a model-independent approach, TRANSPORTER,
to generate videos that capture the underlying rules behind VLMs' predictions.
Given the high-visual-fidelity produced by T2V models, TRANSPORTER learns an
optimal transport coupling to VLM's high-semantic embedding spaces. In turn,
logit scores define embedding directions for conditional video generation.
TRANSPORTER generates videos that reflect caption changes over diverse object
attributes, action adverbs, and scene context. Quantitative and qualitative
evaluations across VLMs demonstrate that L2V can provide a fidelity-rich, novel
direction for model interpretability that has not been previously explored.
\\ ( https://arxiv.org/abs/2511.18359 ,  109155kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18367
Date: Sun, 23 Nov 2025 09:26:01 GMT   (6806kb)

Title: Alias-free 4D Gaussian Splatting
Authors: Zilong Chen, Huan-ang Gao, Delin Qu, Haohan Chi, Hao Tang, Kai Zhang,
 Hao Zhao
Categories: cs.CV
Comments: Project page: https://4d-alias-free.github.io/4D-Alias-free/
\\
 Existing dynamic scene reconstruction methods based on Gaussian Splatting
enable real-time rendering and generate realistic images. However, adjusting
the camera's focal length or the distance between Gaussian primitives and the
camera to modify rendering resolution often introduces strong artifacts,
stemming from the frequency constraints of 4D Gaussians and Gaussian scale
mismatch induced by the 2D dilated filter. To address this, we derive a maximum
sampling frequency formulation for 4D Gaussian Splatting and introduce a 4D
scale-adaptive filter and scale loss, which flexibly regulates the sampling
frequency of 4D Gaussian Splatting. Our approach eliminates high-frequency
artifacts under increased rendering frequencies while effectively reducing
redundant Gaussians in multi-view video reconstruction. We validate the
proposed method through monocular and multi-view video reconstruction
experiments.Ours project page: https://4d-alias-free.github.io/4D-Alias-free/
\\ ( https://arxiv.org/abs/2511.18367 ,  6806kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18370
Date: Sun, 23 Nov 2025 09:28:57 GMT   (5551kb)

Title: MimiCAT: Mimic with Correspondence-Aware Cascade-Transformer for
 Category-Free 3D Pose Transfer
Authors: Zenghao Chai, Chen Tang, Yongkang Wong, Xulei Yang, Mohan Kankanhalli
Categories: cs.CV cs.GR
Comments: tech report
\\
 3D pose transfer aims to transfer the pose-style of a source mesh to a target
character while preserving both the target's geometry and the source's pose
characteristic. Existing methods are largely restricted to characters with
similar structures and fail to generalize to category-free settings (e.g.,
transferring a humanoid's pose to a quadruped). The key challenge lies in the
structural and transformation diversity inherent in distinct character types,
which often leads to mismatched regions and poor transfer quality. To address
these issues, we first construct a million-scale pose dataset across hundreds
of distinct characters. We further propose MimiCAT, a cascade-transformer model
designed for category-free 3D pose transfer. Instead of relying on strict
one-to-one correspondence mappings, MimiCAT leverages semantic keypoint labels
to learn a novel soft correspondence that enables flexible many-to-many
matching across characters. The pose transfer is then formulated as a
conditional generation process, in which the source transformations are first
projected onto the target through soft correspondence matching and subsequently
refined using shape-conditioned representations. Extensive qualitative and
quantitative experiments demonstrate that MimiCAT transfers plausible poses
across different characters, significantly outperforming prior methods that are
limited to narrow category transfer (e.g., humanoid-to-humanoid).
\\ ( https://arxiv.org/abs/2511.18370 ,  5551kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18373
Date: Sun, 23 Nov 2025 09:43:44 GMT   (5338kb)

Title: MASS: Motion-Aware Spatial-Temporal Grounding for Physics Reasoning and
 Comprehension in Vision-Language Models
Authors: Xiyang Wu, Zongxia Li, Jihui Jin, Guangyao Shi, Gouthaman KV, Vishnu
 Raj, Nilotpal Sinha, Jingxi Chen, Fan Du, Dinesh Manocha
Categories: cs.CV
\\
 Vision Language Models (VLMs) perform well on standard video tasks but
struggle with physics-driven reasoning involving motion dynamics and spatial
interactions. This limitation reduces their ability to interpret real or
AI-generated content (AIGC) videos and to generate physically consistent
content. We present an approach that addresses this gap by translating
physical-world context cues into interpretable representations aligned with
VLMs' perception, comprehension, and reasoning. We introduce MASS-Bench, a
comprehensive benchmark consisting of 4,350 real-world and AIGC videos and
8,361 free-form video question-answering pairs focused on physics-related
comprehension tasks, with detailed annotations including visual detections,
sub-segment grounding, and full-sequence 3D motion tracking of entities. We
further present MASS, a model-agnostic method that injects spatial-temporal
signals into the VLM language space via depth-based 3D encoding and visual
grounding, coupled with a motion tracker for object dynamics. To strengthen
cross-modal alignment and reasoning, we apply reinforcement fine-tuning.
Experiments and ablations show that our refined VLMs outperform comparable and
larger baselines, as well as prior state-of-the-art models, by 8.7% and 6.0%,
achieving performance comparable to close-source SoTA VLMs such as
Gemini-2.5-Flash on physics reasoning and comprehension. These results validate
the effectiveness of our approach.
\\ ( https://arxiv.org/abs/2511.18373 ,  5338kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18378
Date: Sun, 23 Nov 2025 09:56:24 GMT   (38081kb)

Title: Synthetic Curriculum Reinforces Compositional Text-to-Image Generation
Authors: Shijian Wang, Runhao Fu, Siyi Zhao, Qingqin Zhan, Xingjian Wang,
 Jiarui Jin, Yuan Lu, Hanqian Wu, Cunjian Chen
Categories: cs.CV
\\
 Text-to-Image (T2I) generation has long been an open problem, with
compositional synthesis remaining particularly challenging. This task requires
accurate rendering of complex scenes containing multiple objects that exhibit
diverse attributes as well as intricate spatial and semantic relationships,
demanding both precise object placement and coherent inter-object interactions.
In this paper, we propose a novel compositional curriculum reinforcement
learning framework named CompGen that addresses compositional weakness in
existing T2I models. Specifically, we leverage scene graphs to establish a
novel difficulty criterion for compositional ability and develop a
corresponding adaptive Markov Chain Monte Carlo graph sampling algorithm. This
difficulty-aware approach enables the synthesis of training curriculum data
that progressively optimize T2I models through reinforcement learning. We
integrate our curriculum learning approach into Group Relative Policy
Optimization (GRPO) and investigate different curriculum scheduling strategies.
Our experiments reveal that CompGen exhibits distinct scaling curves under
different curriculum scheduling strategies, with easy-to-hard and Gaussian
sampling strategies yielding superior scaling performance compared to random
sampling. Extensive experiments demonstrate that CompGen significantly enhances
compositional generation capabilities for both diffusion-based and
auto-regressive T2I models, highlighting its effectiveness in improving the
compositional T2I generation systems.
\\ ( https://arxiv.org/abs/2511.18378 ,  38081kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18380
Date: Sun, 23 Nov 2025 09:57:27 GMT   (7314kb)

Title: RNN as Linear Transformer: A Closer Investigation into Representational
 Potentials of Visual Mamba Models
Authors: Timing Yang, Guoyizhe Wei, Alan Yuille, Feng Wang
Categories: cs.CV
\\
 Mamba has recently garnered attention as an effective backbone for vision
tasks. However, its underlying mechanism in visual domains remains poorly
understood. In this work, we systematically investigate Mamba's
representational properties and make three primary contributions. First, we
theoretically analyze Mamba's relationship to Softmax and Linear Attention,
confirming that it can be viewed as a low-rank approximation of Softmax
Attention and thereby bridging the representational gap between Softmax and
Linear forms. Second, we introduce a novel binary segmentation metric for
activation map evaluation, extending qualitative assessments to a quantitative
measure that demonstrates Mamba's capacity to model long-range dependencies.
Third, by leveraging DINO for self-supervised pretraining, we obtain clearer
activation maps than those produced by standard supervised approaches,
highlighting Mamba's potential for interpretability. Notably, our model also
achieves a 78.5 percent linear probing accuracy on ImageNet, underscoring its
strong performance. We hope this work can provide valuable insights for future
investigations of Mamba-based vision architectures.
\\ ( https://arxiv.org/abs/2511.18380 ,  7314kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18382
Date: Sun, 23 Nov 2025 10:19:56 GMT   (5471kb)

Title: ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form,
 High-Quality Captions and Crawl-Free Access
Authors: Timing Yang, Sucheng Ren, Alan Yuille, and Feng Wang
Categories: cs.CV
\\
 Text-to-video generation has surged in interest since Sora, yet open-source
models still face a data bottleneck: there is no large, high-quality, easily
obtainable video-text corpus. Existing public datasets typically require manual
YouTube crawling, which yields low usable volume due to link rot and access
limits, and raises licensing uncertainty. This work addresses this challenge by
introducing ViMix-14M, a curated multi-source video-text dataset of around 14
million pairs that provides crawl-free, download-ready access and long-form,
high-quality captions tightly aligned to video. ViMix-14M is built by merging
diverse open video sources, followed by unified de-duplication and quality
filtering, and a multi-granularity, ground-truth-guided re-captioning pipeline
that refines descriptions to better match actions, scenes, and temporal
structure. We evaluate the dataset by multimodal retrieval, text-to-video
generation, and video question answering tasks, observing consistent
improvements over counterpart datasets. We hope this work can help removing the
key barrier to training and fine-tuning open-source video foundation models,
and provide insights of building high-quality and generalizable video-text
datasets.
\\ ( https://arxiv.org/abs/2511.18382 ,  5471kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18385
Date: Sun, 23 Nov 2025 10:25:24 GMT   (1765kb)

Title: Can a Second-View Image Be a Language? Geometric and Semantic
 Cross-Modal Reasoning for X-ray Prohibited Item Detection
Authors: Chuang Peng, Renshuai Tao, Zhongwei Ren, Xianglong Liu, Yunchao Wei
Categories: cs.CV cs.AI
Comments: 10 pages, 4 figures
\\
 Automatic X-ray prohibited items detection is vital for security inspection
and has been widely studied. Traditional methods rely on visual modality, often
struggling with complex threats. While recent studies incorporate language to
guide single-view images, human inspectors typically use dual-view images in
practice. This raises the question: can the second view provide constraints
similar to a language modality? In this work, we introduce DualXrayBench, the
first comprehensive benchmark for X-ray inspection that includes multiple views
and modalities. It supports eight tasks designed to test cross-view reasoning.
In DualXrayBench, we introduce a caption corpus consisting of 45,613 dual-view
image pairs across 12 categories with corresponding captions. Building upon
these data, we propose the Geometric (cross-view)-Semantic (cross-modality)
Reasoner (GSR), a multimodal model that jointly learns correspondences between
cross-view geometry and cross-modal semantics, treating the second-view images
as a "language-like modality". To enable this, we construct the GSXray dataset,
with structured Chain-of-Thought sequences: <top>, <side>, <conclusion>.
Comprehensive evaluations on DualXrayBench demonstrate that GSR achieves
significant improvements across all X-ray tasks, offering a new perspective for
real-world X-ray inspection.
\\ ( https://arxiv.org/abs/2511.18385 ,  1765kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18386
Date: Sun, 23 Nov 2025 10:26:38 GMT   (22803kb)

Title: SegSplat: Feed-forward Gaussian Splatting and Open-Set Semantic
 Segmentation
Authors: Peter Siegel, Federico Tombari, Marc Pollefeys, Daniel Barath
Categories: cs.CV
\\
 We have introduced SegSplat, a novel framework designed to bridge the gap
between rapid, feed-forward 3D reconstruction and rich, open-vocabulary
semantic understanding. By constructing a compact semantic memory bank from
multi-view 2D foundation model features and predicting discrete semantic
indices alongside geometric and appearance attributes for each 3D Gaussian in a
single pass, SegSplat efficiently imbues scenes with queryable semantics. Our
experiments demonstrate that SegSplat achieves geometric fidelity comparable to
state-of-the-art feed-forward 3D Gaussian Splatting methods while
simultaneously enabling robust open-set semantic segmentation, crucially
\textit{without} requiring any per-scene optimization for semantic feature
integration. This work represents a significant step towards practical,
on-the-fly generation of semantically aware 3D environments, vital for
advancing robotic interaction, augmented reality, and other intelligent
systems.
\\ ( https://arxiv.org/abs/2511.18386 ,  22803kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18396
Date: Sun, 23 Nov 2025 10:47:25 GMT   (197kb)

Title: Exploring Weak-to-Strong Generalization for CLIP-based Classification
Authors: Jinhao Li, Sarah M. Erfani, Lei Feng, James Bailey, Feng Liu
Categories: cs.CV
Comments: TMLR
\\
 Aligning large-scale commercial models with user intent is crucial to
preventing harmful outputs. Current methods rely on human supervision but
become impractical as model complexity increases. When models surpass human
knowledge, providing accurate feedback becomes challenging and inefficient. A
novel solution proposed recently is using a weaker model to supervise a
stronger model. This concept leverages the ability of weaker models to perform
evaluations, thereby reducing the workload on human supervisors. Previous work
has shown the effectiveness of weak-to-strong generalization in the context of
language-only models. Extending this concept to vision-language models
leverages these insights, adapting the proven benefits to a multi-modal
context. In our study, we explore weak-to-strong generalization for CLIP-based
classification. We propose a method, class prototype learning (CPL), which aims
to enhance the classification capabilities of the CLIP model, by learning more
representative prototypes for each category. Our findings indicate that,
despite using a simple loss function under weak supervision, CPL yields robust
improvements in targeted scenarios, particularly when pretraining is limited.
Extensive experiments demonstrate that our approach is effective under these
settings, achieving a 3.67% improvement over strong baseline methods.
\\ ( https://arxiv.org/abs/2511.18396 ,  197kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18399
Date: Sun, 23 Nov 2025 10:56:22 GMT   (1555kb)

Title: ChineseVideoBench: Benchmarking Multi-modal Large Models for Chinese
 Video Question Answering
Authors: Yuxiang Nie, Han Wang, Yongjie Ye, Haiyang Yu, Weitao Jia, Tao Zeng,
 Hao Feng, Xiang Fei, Yang Li, Xiaohui Lv, Guozhi Tang, Jingqun Tang, Jinghui
 Lu, Zehui Dai, Jiacong Wang, Dingkang Yang, An-Lan Wang, Can Huang
Categories: cs.CV
\\
 This paper introduces ChineseVideoBench, a pioneering benchmark specifically
designed for evaluating Multimodal Large Language Models (MLLMs) in Chinese
Video Question Answering. The growing demand for sophisticated video analysis
capabilities highlights the critical need for comprehensive, culturally-aware
evaluation frameworks. ChineseVideoBench addresses this gap by providing a
robust dataset and tailored evaluation metrics, enabling rigorous assessment of
state-of-the-art MLLMs on complex Chinese video content. Specifically,
ChineseVideoBench comprises 8 main classes and 12 sub-classes, encompassing
tasks that demand both deep video understanding and nuanced Chinese linguistic
and cultural awareness. Our empirical evaluations reveal that ChineseVideoBench
presents a significant challenge to current MLLMs. Among the models assessed,
Gemini 2.5 Pro achieves the highest performance with an overall score of 77.9%,
while InternVL-38B emerges as the most competitive open-source model.
\\ ( https://arxiv.org/abs/2511.18399 ,  1555kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18416
Date: Sun, 23 Nov 2025 12:05:28 GMT   (15880kb)

Title: 4D-VGGT: A General Foundation Model with SpatioTemporal Awareness for
 Dynamic Scene Geometry Estimation
Authors: Haonan Wang, Hanyu Zhou, Haoyue Liu, Luxin Yan
Categories: cs.CV
\\
 We investigate a challenging task of dynamic scene geometry estimation, which
requires representing both spatial and temporal features. Typically, existing
methods align the two features into a unified latent space to model scene
geometry. However, this unified paradigm suffers from potential mismatched
representation due to the heterogeneous nature between spatial and temporal
features. In this work, we propose 4D-VGGT, a general foundation model with
divide-and-conquer spatiotemporal representation for dynamic scene geometry.
Our model is divided into three aspects: 1) Multi-setting input. We design an
adaptive visual grid that supports input sequences with arbitrary numbers of
views and time steps. 2) Multi-level representation. We propose a cross-view
global fusion for spatial representation and a cross-time local fusion for
temporal representation. 3) Multi-task prediction. We append multiple
task-specific heads to spatiotemporal representations, enabling a comprehensive
visual geometry estimation for dynamic scenes. Under this unified framework,
these components enhance the feature discriminability and application
universality of our model for dynamic scenes. In addition, we integrate
multiple geometry datasets to train our model and conduct extensive experiments
to verify the effectiveness of our method across various tasks on multiple
dynamic scene geometry benchmarks.
\\ ( https://arxiv.org/abs/2511.18416 ,  15880kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18422
Date: Sun, 23 Nov 2025 12:23:20 GMT   (1328kb)

Title: NeuroVascU-Net: A Unified Multi-Scale and Cross-Domain Adaptive Feature
 Fusion U-Net for Precise 3D Segmentation of Brain Vessels in
 Contrast-Enhanced T1 MRI
Authors: Mohammad Jafari Vayeghan, Niloufar Delfan, Mehdi Tale Masouleh,
 Mansour Parvaresh Rizi, Behzad Moshiri
Categories: cs.CV cs.LG
\\
 Precise 3D segmentation of cerebral vasculature from T1-weighted
contrast-enhanced (T1CE) MRI is crucial for safe neurosurgical planning. Manual
delineation is time-consuming and prone to inter-observer variability, while
current automated methods often trade accuracy for computational cost, limiting
clinical use. We present NeuroVascU-Net, the first deep learning architecture
specifically designed to segment cerebrovascular structures directly from
clinically standard T1CE MRI in neuro-oncology patients, addressing a gap in
prior work dominated by TOF-MRA-based approaches. NeuroVascU-Net builds on a
dilated U-Net and integrates two specialized modules: a Multi-Scale Contextual
Feature Fusion ($MSC^2F$) module at the bottleneck and a Cross-Domain Adaptive
Feature Fusion ($CDA^2F$) module at deeper hierarchical layers. $MSC^2F$
captures both local and global information via multi-scale dilated
convolutions, while $CDA^2F$ dynamically integrates domain-specific features,
enhancing representation while keeping computation low. The model was trained
and validated on a curated dataset of T1CE scans from 137 brain tumor biopsy
patients, annotated by a board-certified functional neurosurgeon.
NeuroVascU-Net achieved a Dice score of 0.8609 and precision of 0.8841,
accurately segmenting both major and fine vascular structures. Notably, it
requires only 12.4M parameters, significantly fewer than transformer-based
models such as Swin U-NetR. This balance of accuracy and efficiency positions
NeuroVascU-Net as a practical solution for computer-assisted neurosurgical
planning.
\\ ( https://arxiv.org/abs/2511.18422 ,  1328kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18424
Date: Sun, 23 Nov 2025 12:40:04 GMT   (2559kb)

Title: CrossJEPA: Cross-Modal Joint-Embedding Predictive Architecture for
 Efficient 3D Representation Learning from 2D Images
Authors: Avishka Perera, Kumal Hewagamage, Saeedha Nazar, Kavishka Abeywardana,
 Hasitha Gallella, Ranga Rodrigo, Mohamed Afham
Categories: cs.CV
Comments: 24 pages, 10 figures
\\
 Image-to-point cross-modal learning has emerged to address the scarcity of
large-scale 3D datasets in 3D representation learning. However, current methods
that leverage 2D data often result in large, slow-to-train models, making them
computationally expensive and difficult to deploy in resource-constrained
environments. The architecture design of such models is therefore critical,
determining their performance, memory footprint, and compute efficiency. The
Joint-embedding Predictive Architecture (JEPA) has gained wide popularity in
self-supervised learning for its simplicity and efficiency, but has been
under-explored in cross-modal settings, partly due to the misconception that
masking is intrinsic to JEPA. In this light, we propose CrossJEPA, a simple
Cross-modal Joint Embedding Predictive Architecture that harnesses the
knowledge of an image foundation model and trains a predictor to infer
embeddings of specific rendered 2D views from corresponding 3D point clouds,
thereby introducing a JEPA-style pretraining strategy beyond masking. By
conditioning the predictor on cross-domain projection information, CrossJEPA
purifies the supervision signal from semantics exclusive to the target domain.
We further exploit the frozen teacher design with a one-time target embedding
caching mechanism, yielding amortized efficiency. CrossJEPA achieves a new
state-of-the-art in linear probing on the synthetic ModelNet40 (94.2%) and the
real-world ScanObjectNN (88.3%) benchmarks, using only 14.1M pretraining
parameters (8.5M in the point encoder), and about 6 pretraining hours on a
standard single GPU. These results position CrossJEPA as a performant,
memory-efficient, and fast-to-train framework for 3D representation learning
via knowledge distillation. We analyze CrossJEPA intuitively, theoretically,
and empirically, and extensively ablate our design choices. Code will be made
available.
\\ ( https://arxiv.org/abs/2511.18424 ,  2559kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18425
Date: Sun, 23 Nov 2025 12:44:13 GMT   (1270kb)

Title: LungX: A Hybrid EfficientNet-Vision Transformer Architecture with
 Multi-Scale Attention for Accurate Pneumonia Detection
Authors: Mansur Yerzhanuly
Categories: cs.CV
Comments: 13 pages, 3 figures, 1 table
\\
 Pneumonia remains a leading global cause of mortality where timely diagnosis
is critical. We introduce LungX, a novel hybrid architecture combining
EfficientNet's multi-scale features, CBAM attention mechanisms, and Vision
Transformer's global context modeling for enhanced pneumonia detection.
Evaluated on 20,000 curated chest X-rays from RSNA and CheXpert, LungX achieves
state-of-the-art performance (86.5 percent accuracy, 0.943 AUC), representing a
6.7 percent AUC improvement over EfficientNet-B0 baselines. Visual analysis
demonstrates superior lesion localization through interpretable attention maps.
Future directions include multi-center validation and architectural
optimizations targeting 88 percent accuracy for clinical deployment as an AI
diagnostic aid.
\\ ( https://arxiv.org/abs/2511.18425 ,  1270kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18434
Date: Sun, 23 Nov 2025 13:02:11 GMT   (45435kb)

Title: DocPTBench: Benchmarking End-to-End Photographed Document Parsing and
 Translation
Authors: Yongkun Du, Pinxuan Chen, Xuye Ying, Zhineng Chen
Categories: cs.CV cs.AI
\\
 The advent of Multimodal Large Language Models (MLLMs) has unlocked the
potential for end-to-end document parsing and translation. However, prevailing
benchmarks such as OmniDocBench and DITrans are dominated by pristine scanned
or digital-born documents, and thus fail to adequately represent the intricate
challenges of real-world capture conditions, such as geometric distortions and
photometric variations. To fill this gap, we introduce DocPTBench, a
comprehensive benchmark specifically designed for Photographed Document Parsing
and Translation. DocPTBench comprises over 1,300 high-resolution photographed
documents from multiple domains, includes eight translation scenarios, and
provides meticulously human-verified annotations for both parsing and
translation. Our experiments demonstrate that transitioning from digital-born
to photographed documents results in a substantial performance decline: popular
MLLMs exhibit an average accuracy drop of 18% in end-to-end parsing and 12% in
translation, while specialized document parsing models show significant average
decrease of 25%. This substantial performance gap underscores the unique
challenges posed by documents captured in real-world conditions and reveals the
limited robustness of existing models. Dataset and code are available at
https://github.com/Topdu/DocPTBench.
\\ ( https://arxiv.org/abs/2511.18434 ,  45435kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18436
Date: Sun, 23 Nov 2025 13:09:02 GMT   (10403kb)

Title: When Generative Replay Meets Evolving Deepfakes: Domain-Aware Relative
 Weighting for Incremental Face Forgery Detection
Authors: Hao Shen, Jikang Cheng, Renye Yan, Zhongyuan Wang, Wei Peng, Baojin
 Huang
Categories: cs.CV
\\
 The rapid advancement of face generation techniques has led to a growing
variety of forgery methods. Incremental forgery detection aims to gradually
update existing models with new forgery data, yet current sample replay-based
methods are limited by low diversity and privacy concerns. Generative replay
offers a potential solution by synthesizing past data, but its feasibility for
forgery detection remains unclear. In this work, we systematically investigate
generative replay and identify two scenarios: when the replay generator closely
resembles the new forgery model, generated real samples blur the domain
boundary, creating domain-risky samples; when the replay generator differs
significantly, generated samples can be safely supervised, forming domain-safe
samples. To exploit generative replay effectively, we propose a novel
Domain-Aware Relative Weighting (DARW) strategy. DARW directly supervises
domain-safe samples while applying a Relative Separation Loss to balance
supervision and potential confusion for domain-risky samples. A Domain
Confusion Score dynamically adjusts this tradeoff according to sample
reliability. Extensive experiments demonstrate that DARW consistently improves
incremental learning performance for forgery detection under different
generative replay settings and alleviates the adverse impact of domain overlap.
\\ ( https://arxiv.org/abs/2511.18436 ,  10403kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18437
Date: Sun, 23 Nov 2025 13:15:58 GMT   (20809kb)

Title: Perceptual-Evidence Anchored Reinforced Learning for Multimodal
 Reasoning
Authors: Chi Zhang, Haibo Qiu, Qiming Zhang, Yufei Xu, Zhixiong Zeng, Siqi
 Yang, Peng Shi, Lin Ma, Jing Zhang
Categories: cs.CV
\\
 Reinforcement Learning with Verifiable Rewards (RLVR) has significantly
advanced the reasoning capabilities of Large Language Models (LLMs) and is now
being applied to Vision-Language Models (VLMs). However, vanilla RLVR for VLMs
verifies only the final textual output, critically neglecting the foundational
step of visual perception. This oversight leads to visual hallucinations and
reward hacking, as reasoning built upon flawed perception is inherently
unreliable. To address this, we propose PEARL (Perceptual-Evidence Anchored
Reinforced Learning), a dual-branch, perception-reasoning synergistic that
strengthens multimodal reasoning by explicitly anchoring it to verified visual
evidence. For each reasoning-oriented QA instance, PEARL first derive a
perception checklist -- a set of perception-oriented sub-questions with
verifiable answers that probe the model's understanding of key visual evidence.
During training, auxiliary rollouts on this checklist yield a perceptual reward
that both directly reinforces the model's perception ability and acts as a
fidelity gate for reasoning. If the model passes the perception check, its
policy update is biased towards evidence-anchored reasoning. Otherwise, the
process is halted to prevent reasoning from flawed premises. PEARL can be
seamlessly integrated with popular RL methods like GRPO and DAPO. Comprehensive
experiments show PEARL achieves substantial gains on multimodal reasoning
benchmarks, e.g., a +9.7% improvement over the baseline and +6.6% over GRPO on
MathVerse.
\\ ( https://arxiv.org/abs/2511.18437 ,  20809kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18441
Date: Sun, 23 Nov 2025 13:25:14 GMT   (10349kb)

Title: ReCoGS: Real-time ReColoring for Gaussian Splatting scenes
Authors: Lorenzo Rutayisire, Nicola Capodieci, Fabio Pellacini
Categories: cs.CV cs.GR
Comments: Project page is available at https://github.com/loryruta/recogs
ACM-class: I.3.4
\\
 Gaussian Splatting has emerged as a leading method for novel view synthesis,
offering superior training efficiency and real-time inference compared to NeRF
approaches, while still delivering high-quality reconstructions. Beyond view
synthesis, this 3D representation has also been explored for editing tasks.
Many existing methods leverage 2D diffusion models to generate multi-view
datasets for training, but they often suffer from limitations such as view
inconsistencies, lack of fine-grained control, and high computational demand.
In this work, we focus specifically on the editing task of recoloring. We
introduce a user-friendly pipeline that enables precise selection and
recoloring of regions within a pre-trained Gaussian Splatting scene. To
demonstrate the real-time performance of our method, we also present an
interactive tool that allows users to experiment with the pipeline in practice.
Code is available at https://github.com/loryruta/recogs.
\\ ( https://arxiv.org/abs/2511.18441 ,  10349kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18444
Date: Sun, 23 Nov 2025 13:29:28 GMT   (2076kb)

Title: SineProject: Machine Unlearning for Stable Vision Language Alignment
Authors: Arpit Garg, Hemanth Saratchandran, Simon Lucey
Categories: cs.CV
Comments: In Submission
\\
 Multimodal Large Language Models (MLLMs) increasingly need to forget specific
knowledge such as unsafe or private information without requiring full
retraining. However, existing unlearning methods often disrupt vision language
alignment, causing models to reject both harmful and benign queries. We trace
this failure to the projector network during unlearning, its Jacobian becomes
severely illconditioned, leading to unstable optimization and drift in cross
modal embeddings. We introduce SineProject, a simple method that augments the
frozen projector with sinusoidally modulated trainable parameters, improving
the Jacobian's spectral conditioning and stabilizing alignment throughout
unlearning. Across standard safety and privacy unlearning benchmarks using
LLaVA v1.5 7B and 13B, SineProject reduces benign query refusals while
achieving complete forgetting of targeted information, yielding state of the
art forget retain trade offs with negligible computational overhead.
\\ ( https://arxiv.org/abs/2511.18444 ,  2076kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18448
Date: Sun, 23 Nov 2025 13:39:01 GMT   (7894kb)

Title: EventBench: Towards Comprehensive Benchmarking of Event-based MLLMs
Authors: Shaoyu Liu, Jianing Li, Guanghui Zhao, Yunjian Zhang, Xiangyang Ji
Categories: cs.CV
\\
 Multimodal large language models (MLLMs) have made significant advancements
in event-based vision, yet the comprehensive evaluation of their capabilities
within a unified benchmark remains largely unexplored. In this work, we
introduce EventBench, a benchmark that offers eight diverse task metrics
together with a large-scale event stream dataset. EventBench differs from
existing event-based benchmarks in four key aspects: (1) openness in
accessibility, releasing all raw event streams and task instructions across
eight evaluation metrics; (2) diversity in task coverage, spanning
understanding, recognition, and spatial reasoning tasks for comprehensive
capability assessment; (3) integration in spatial dimensions, pioneering the
design of 3D spatial reasoning tasks for event-based MLLMs; and (4) scale in
data volume, with an accompanying training set of over one million event-text
pairs supporting large-scale training and evaluation. Using EventBench, we
evaluate state-of-the-art closed-source models such as GPT-5 and Gemini-2.5
Pro, leading open-source models including Qwen2.5-VL and InternVL3, and
event-based MLLMs such as EventGPT that directly process raw event streams.
Extensive evaluation reveals that while current event-based MLLMs demonstrate
strong performance in event stream understanding, they continue to struggle
with fine-grained recognition and spatial reasoning.
\\ ( https://arxiv.org/abs/2511.18448 ,  7894kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18452
Date: Sun, 23 Nov 2025 13:43:52 GMT   (12861kb)

Title: NAF: Zero-Shot Feature Upsampling via Neighborhood Attention Filtering
Authors: Loick Chambon, Paul Couairon, Eloi Zablocki, Alexandre Boulch, Nicolas
 Thome, Matthieu Cord
Categories: cs.CV
Comments: Code: https://github.com/valeoai/NAF
\\
 Vision Foundation Models (VFMs) extract spatially downsampled
representations, posing challenges for pixel-level tasks. Existing upsampling
approaches face a fundamental trade-off: classical filters are fast and broadly
applicable but rely on fixed forms, while modern upsamplers achieve superior
accuracy through learnable, VFM-specific forms at the cost of retraining for
each VFM. We introduce Neighborhood Attention Filtering (NAF), which bridges
this gap by learning adaptive spatial-and-content weights through Cross-Scale
Neighborhood Attention and Rotary Position Embeddings (RoPE), guided solely by
the high-resolution input image. NAF operates zero-shot: it upsamples features
from any VFM without retraining, making it the first VFM-agnostic architecture
to outperform VFM-specific upsamplers and achieve state-of-the-art performance
across multiple downstream tasks. It maintains high efficiency, scaling to 2K
feature maps and reconstructing intermediate-resolution maps at 18 FPS. Beyond
feature upsampling, NAF demonstrates strong performance on image restoration,
highlighting its versatility. Code and checkpoints are available at
https://github.com/valeoai/NAF.
\\ ( https://arxiv.org/abs/2511.18452 ,  12861kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18454
Date: Sun, 23 Nov 2025 13:50:49 GMT   (528kb)

Title: RegDeepLab: A Two-Stage Decoupled Framework for Interpretable Embryo
 Fragmentation Grading
Authors: Ming-Jhe Lee
Categories: cs.CV cs.AI
Comments: 7 pages, 5 figures
\\
 The degree of embryo fragmentation serves as a critical morphological
indicator for assessing embryo developmental potential in In Vitro
Fertilization (IVF) clinical decision-making. However, current manual grading
processes are not only time-consuming but also limited by significant
inter-observer variability and efficiency bottlenecks. Although deep learning
has demonstrated potential in automated grading in recent years, existing
solutions face a significant challenge: pure regression models lack the visual
explainability required for clinical practice, while pure segmentation models
struggle to directly translate pixel-level masks into precise clinical grades.
This study proposes RegDeepLab, a dual-branch Multi-Task Learning (MTL)
framework that integrates State-of-the-Art (SOTA) semantic segmentation
(DeepLabV3+) with a multi-scale regression head. Addressing the common issues
of "Gradient Conflict" and "Negative Transfer" in multi-task training, we
propose a "Two-Stage Decoupled Training Strategy." Experimental results
demonstrate that while standard end-to-end MTL training can minimize grading
error (MAE=0.046) through our designed "Feature Injection" mechanism, it
compromises the integrity of segmentation boundaries. In contrast, our
decoupled strategy successfully provides robust and high-precision grading
predictions while preserving SOTA-level segmentation accuracy (Dice=0.729).
Furthermore, we introduce a "Range Loss" to effectively utilize large-scale
discrete grading data for semi-supervised learning. This study ultimately
presents a dual-module clinical auxiliary solution that combines high accuracy
with visual explainability.
\\ ( https://arxiv.org/abs/2511.18454 ,  528kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18463
Date: Sun, 23 Nov 2025 14:14:14 GMT   (6230kb)

Title: Alternating Perception-Reasoning for Hallucination-Resistant Video
 Understanding
Authors: Bowei Pu, Chuanbin Liu, Yifan Ge, Peichen Zhou, Yiwei Sun, Zhiyin Lu,
 Jiankang Wang, and Hongtao Xie
Categories: cs.CV
Comments: 32 pages, 36 figures
ACM-class: I.4
\\
 Sufficient visual perception is the foundation of video reasoning.
Nevertheless, existing Video Reasoning LLMs suffer from perception shortcuts,
relying on a flawed single-step perception paradigm. This paradigm describes
the video and then conducts reasoning, which runs the risk of insufficient
evidence and emergent hallucinations. To address these issues, we introduce a
new framework that integrates a loop-based paradigm with an anti-hallucination
reward. First, to address the insufficient evidence, we introduce the
Perception Loop Reasoning (PLR) paradigm. Instead of describing the video at
once, each loop requires the model to describe a video segment with precise
timestamps, analyze this segment, and decide the next action. Second, for the
risk of hallucinations, the Factual-Aware Evaluator (FAE) evaluates each
perception result as a reliable anti-hallucination reward. This reward
encourages the model to provide sufficient and precise video evidence. Our FAE,
which performs comparably to GPT-4o, is tuned on our AnetHallu-117K, a
large-scale hallucination judgment preference dataset. Extensive experiments
show that our Video-PLR achieves the state-of-the-art in both 3B and 7B
parameter scales and has the best data efficiency. Our code, models, and
datasets are released on: https://github.com/BoweiPu/VideoPLR.
\\ ( https://arxiv.org/abs/2511.18463 ,  6230kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18470
Date: Sun, 23 Nov 2025 14:37:11 GMT   (4118kb)

Title: Gaze Beyond the Frame: Forecasting Egocentric 3D Visual Span
Authors: Heeseung Yun, Joonil Na, Jaeyeon Kim, Calvin Murdock, Gunhee Kim
Categories: cs.CV
Comments: NeurIPS 2025 Spotlight
\\
 People continuously perceive and interact with their surroundings based on
underlying intentions that drive their exploration and behaviors. While
research in egocentric user and scene understanding has focused primarily on
motion and contact-based interaction, forecasting human visual perception
itself remains less explored despite its fundamental role in guiding human
actions and its implications for AR/VR and assistive technologies. We address
the challenge of egocentric 3D visual span forecasting, predicting where a
person's visual perception will focus next within their three-dimensional
environment. To this end, we propose EgoSpanLift, a novel method that
transforms egocentric visual span forecasting from 2D image planes to 3D
scenes. EgoSpanLift converts SLAM-derived keypoints into gaze-compatible
geometry and extracts volumetric visual span regions. We further combine
EgoSpanLift with 3D U-Net and unidirectional transformers, enabling
spatio-temporal fusion to efficiently predict future visual span in the 3D
grid. In addition, we curate a comprehensive benchmark from raw egocentric
multisensory data, creating a testbed with 364.6K samples for 3D visual span
forecasting. Our approach outperforms competitive baselines for egocentric 2D
gaze anticipation and 3D localization while achieving comparable results even
when projected back onto 2D image planes without additional 2D-specific
training.
\\ ( https://arxiv.org/abs/2511.18470 ,  4118kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18471
Date: Sun, 23 Nov 2025 14:37:59 GMT   (16928kb)

Title: Robust Posterior Diffusion-based Sampling via Adaptive Guidance Scale
Authors: Liav Hen, Tom Tirer, Raja Giryes, Shady Abu-Hussein
Categories: cs.CV
\\
 Diffusion models have recently emerged as powerful generative priors for
solving inverse problems, achieving state-of-the-art results across various
imaging tasks. A central challenge in this setting lies in balancing the
contribution of the prior with the data fidelity term: overly aggressive
likelihood updates may introduce artifacts, while conservative updates can slow
convergence or yield suboptimal reconstructions. In this work, we propose an
adaptive likelihood step-size strategy to guide the diffusion process for
inverse-problem formulations. Specifically, we develop an observation-dependent
weighting scheme based on the agreement between two different approximations of
the intractable intermediate likelihood gradients, that adapts naturally to the
diffusion schedule, time re-spacing, and injected stochasticity. The resulting
approach, Adaptive Posterior diffusion Sampling (AdaPS), is hyperparameter-free
and improves reconstruction quality across diverse imaging tasks - including
super-resolution, Gaussian deblurring, and motion deblurring - on CelebA-HQ and
ImageNet-256 validation sets. AdaPS consistently surpasses existing
diffusion-based baselines in perceptual quality with minimal or no loss in
distortion, without any task-specific tuning. Extensive ablation studies
further demonstrate its robustness to the number of diffusion steps,
observation noise levels, and varying stochasticity.
\\ ( https://arxiv.org/abs/2511.18471 ,  16928kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18473
Date: Sun, 23 Nov 2025 14:43:51 GMT   (11837kb)

Title: Uncertainty Quantification in HSI Reconstruction using Physics-Aware
 Diffusion Priors and Optics-Encoded Measurements
Authors: Juan Romero, Qiang Fu, Matteo Ravasi, Wolfgang Heidrich
Categories: cs.CV
\\
 Hyperspectral image reconstruction from a compressed measurement is a highly
ill-posed inverse problem. Current data-driven methods suffer from
hallucination due to the lack of spectral diversity in existing hyperspectral
image datasets, particularly when they are evaluated for the metamerism
phenomenon. In this work, we formulate hyperspectral image (HSI) reconstruction
as a Bayesian inference problem and propose a framework, HSDiff, that utilizes
an unconditionally trained, pixel-level diffusion prior and posterior diffusion
sampling to generate diverse HSI samples consistent with the measurements of
various hyperspectral image formation models. We propose an enhanced metameric
augmentation technique using region-based metameric black and
partition-of-union spectral upsampling to expand training with physically valid
metameric spectra, strengthening the prior diversity and improving uncertainty
calibration. We utilize HSDiff to investigate how the studied forward models
shape the posterior distribution and demonstrate that guiding with effective
spectral encoding provides calibrated informative uncertainty compared to
non-encoded models. Through the lens of the Bayesian framework, HSDiff offers a
complete, high-performance method for uncertainty-aware HSI reconstruction. Our
results also reiterate the significance of effective spectral encoding in
snapshot hyperspectral imaging.
\\ ( https://arxiv.org/abs/2511.18473 ,  11837kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18504
Date: Sun, 23 Nov 2025 15:43:00 GMT   (1203kb)

Title: Extreme Model Compression for Edge Vision-Language Models: Sparse
 Temporal Token Fusion and Adaptive Neural Compression
Authors: Md Tasnin Tanvir, Soumitra Das, Sk Md Abidar Rahaman, Ali Shiri
 Sichani
Categories: cs.CV
Comments: 9 pages, 6 figures
\\
 The demand for edge AI in vision-language tasks requires models that achieve
real-time performance on resource-constrained devices with limited power and
memory. This paper proposes two adaptive compression techniques -- Sparse
Temporal Token Fusion (STTF) and Adaptive Neural Compression (ANC) -- that
integrate algorithmic innovations with hardware-aware optimizations. Unlike
previous approaches relying on static pruning or uniform scaling, STTF
dynamically reuses visual tokens through event-driven change detection, while
ANC conditionally activates encoder branches via a learned router, enabling
fine-grained adaptation to scene complexity. Our 3B-parameter TinyGPT-STTF
achieves CIDEr 131.2, BLEU-4 0.38, METEOR 0.31, and ROUGE-L 0.56 on the COCO
2017 test set, surpassing LLaVA-1.5 7B by 17.6 CIDEr points while using 2.3x
fewer parameters and 62x fewer on-device FLOPs. TinyGPT-ANC reaches CIDEr
128.5. On event-based vision tasks, STTF reduces average token count by 84%
(from 196 to 31 tokens) while preserving 95.6% accuracy on the DVS128 Gesture
dataset, and ANC cuts FLOPs by up to 90% in low-motion scenes. Compared to
strong baselines, our models improve accuracy by up to 4.4% and reduce latency
by up to 13x. These results enable efficient deployment of capable
vision-language models on real-world edge devices.
\\ ( https://arxiv.org/abs/2511.18504 ,  1203kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18507
Date: Sun, 23 Nov 2025 15:47:49 GMT   (8384kb)

Title: Multimodal Continual Learning with MLLMs from Multi-scenario
 Perspectives
Authors: Kai Jiang, Siqi Huang, Xiangyu Chen, Jiawei Shao, Hongyuan Zhang,
 Xuelong Li
Categories: cs.CV cs.AI
Comments: 18 pages, 16 figures. This is a preprint version of a paper submitted
 to CVPR 2026
\\
 Continual learning in visual understanding aims to deal with catastrophic
forgetting in Multimodal Large Language Models (MLLMs). MLLMs deployed on
devices have to continuously adapt to dynamic scenarios in downstream tasks,
such as variations in background and perspective, to effectively perform
complex visual tasks. To this end, we construct a multimodal visual
understanding dataset (MSVQA) encompassing four different scenarios and
perspectives including high altitude, underwater, low altitude and indoor, to
investigate the catastrophic forgetting in MLLMs under the dynamics of scenario
shifts in real-world data streams. Furthermore, we propose mUltimodal coNtInual
learning with MLLMs From multi-scenarIo pERspectives (UNIFIER) to address
visual discrepancies while learning different scenarios. Specifically, it
decouples the visual information from different scenarios into distinct
branches within each vision block and projects them into the same feature
space. A consistency constraint is imposed on the features of each branch to
maintain the stability of visual representations across scenarios. Extensive
experiments on the MSVQA dataset demonstrate that UNIFIER effectively
alleviates forgetting of cross-scenario tasks and achieves knowledge
accumulation within the same scenario.
\\ ( https://arxiv.org/abs/2511.18507 ,  8384kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18513
Date: Sun, 23 Nov 2025 16:08:34 GMT   (34948kb)

Title: LRDUN: A Low-Rank Deep Unfolding Network for Efficient Spectral
 Compressive Imaging
Authors: He Huang, Yujun Guo, Wei He
Categories: cs.CV
Comments: 17 pages, 16 figures,
\\
 Deep unfolding networks (DUNs) have achieved remarkable success and become
the mainstream paradigm for spectral compressive imaging (SCI) reconstruction.
Existing DUNs are derived from full-HSI imaging models, where each stage
operates directly on the high-dimensional HSI, refining the entire data cube
based on the single 2D coded measurement. However, this paradigm leads to
computational redundancy and suffers from the ill-posed nature of mapping 2D
residuals back to 3D space of HSI. In this paper, we propose two novel imaging
models corresponding to the spectral basis and subspace image by explicitly
integrating low-rank (LR) decomposition with the sensing model. Compared to
recovering the full HSI, estimating these compact low-dimensional components
significantly mitigates the ill-posedness. Building upon these novel models, we
develop the Low-Rank Deep Unfolding Network (LRDUN), which jointly solves the
two subproblems within an unfolded proximal gradient descent (PGD) framework.
Furthermore, we introduce a Generalized Feature Unfolding Mechanism (GFUM) that
decouples the physical rank in the data-fidelity term from the feature
dimensionality in the prior module, enhancing the representational capacity and
flexibility of the network. Extensive experiments on simulated and real
datasets demonstrate that the proposed LRDUN achieves state-of-the-art (SOTA)
reconstruction quality with significantly reduced computational cost.
\\ ( https://arxiv.org/abs/2511.18513 ,  34948kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18514
Date: Sun, 23 Nov 2025 16:09:37 GMT   (4732kb)

Title: Unified Deep Learning Platform for Dust and Fault Diagnosis in Solar
 Panels Using Thermal and Visual Imaging
Authors: Abishek Karthik, Sreya Mynampati, Pandiyaraju V
Categories: cs.CV
\\
 Solar energy is one of the most abundant and tapped sources of renewable
energies with enormous future potential. Solar panel output can vary widely
with factors like intensity, temperature, dirt, debris and so on affecting it.
We have implemented a model on detecting dust and fault on solar panels. These
two applications are centralized as a single-platform and can be utilized for
routine-maintenance and any other checks. These are checked against various
parameters such as power output, sinusoidal wave (I-V component of solar cell),
voltage across each solar cell and others. Firstly, we filter and preprocess
the obtained images using gamma removal and Gaussian filtering methods
alongside some predefined processes like normalization. The first application
is to detect whether a solar cell is dusty or not based on various
pre-determined metrics like shadowing, leaf, droppings, air pollution and from
other human activities to extent of fine-granular solar modules. The other one
is detecting faults and other such occurrences on solar panels like faults,
cracks, cell malfunction using thermal imaging application. This centralized
platform can be vital since solar panels have different efficiency across
different geography (air and heat affect) and can also be utilized for
small-scale house requirements to large-scale solar farm sustentation
effectively. It incorporates CNN, ResNet models that with self-attention
mechanisms-KerNet model which are used for classification and results in a
fine-tuned system that detects dust or any fault occurring. Thus, this
multi-application model proves to be efficient and optimized in detecting dust
and faults on solar panels. We have performed various comparisons and findings
that demonstrates that our model has better efficiency and accuracy results
overall than existing models.
\\ ( https://arxiv.org/abs/2511.18514 ,  4732kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18516
Date: Sun, 23 Nov 2025 16:13:06 GMT   (258kb)

Title: Breaking Forgetting: Training-Free Few-Shot Class-Incremental Learning
 via Conditional Diffusion
Authors: Haidong Kang, Ketong Qian, Yi Lu
Categories: cs.CV
\\
 Efforts to overcome catastrophic forgetting in Few-Shot Class-Incremental
Learning (FSCIL) have primarily focused on developing more effective
gradient-based optimization strategies. In contrast, little attention has been
paid to the training cost explosion that inevitably arises as the number of
novel classes increases, a consequence of relying on gradient learning even
under extreme data scarcity. More critically, since FSCIL typically provides
only a few samples for each new class, gradient-based updates not only induce
severe catastrophic forgetting on base classes but also hinder adaptation to
novel ones. This paper seeks to break this long-standing limitation by asking:
Can we design a training-free FSCIL paradigm that entirely removes gradient
optimization? We provide an affirmative answer by uncovering an intriguing
connection between gradient-based optimization and the Conditional Diffusion
process. Building on this observation, we propose a Conditional
Diffusion-driven FSCIL (CD-FSCIL) framework that substitutes the conventional
gradient update process with a diffusion-based generative transition, enabling
training-free incremental adaptation while effectively mitigating forgetting.
Furthermore, to enhance representation under few-shot constraints, we introduce
a multimodal learning strategy that integrates visual features with natural
language descriptions automatically generated by Large Language Models (LLMs).
This synergy substantially alleviates the sample scarcity issue and improves
generalization across novel classes. Extensive experiments on mainstream FSCIL
benchmarks demonstrate that our method not only achieves state-of-the-art
performance but also drastically reduces computational and memory overhead,
marking a paradigm shift toward training-free continual adaptation.
\\ ( https://arxiv.org/abs/2511.18516 ,  258kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18533
Date: Sun, 23 Nov 2025 16:56:20 GMT   (3297kb)

Title: DE-KAN: A Kolmogorov Arnold Network with Dual Encoder for accurate 2D
 Teeth Segmentation
Authors: Md Mizanur Rahman Mustakim, Jianwu Li, Sumya Bhuiyan, Mohammad Mehedi
 Hasan, Bing Han
Categories: cs.CV
\\
 Accurate segmentation of individual teeth from panoramic radiographs remains
a challenging task due to anatomical variations, irregular tooth shapes, and
overlapping structures. These complexities often limit the performance of
conventional deep learning models. To address this, we propose DE-KAN, a novel
Dual Encoder Kolmogorov Arnold Network, which enhances feature representation
and segmentation precision. The framework employs a ResNet-18 encoder for
augmented inputs and a customized CNN encoder for original inputs, enabling the
complementary extraction of global and local spatial features. These features
are fused through KAN-based bottleneck layers, incorporating nonlinear
learnable activation functions derived from the Kolmogorov Arnold
representation theorem to improve learning capacity and interpretability.
Extensive experiments on two benchmark dental X-ray datasets demonstrate that
DE-KAN outperforms state-of-the-art segmentation models, achieving mIoU of
94.5%, Dice coefficient of 97.1%, accuracy of 98.91%, and recall of 97.36%,
representing up to +4.7% improvement in Dice compared to existing methods.
\\ ( https://arxiv.org/abs/2511.18533 ,  3297kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18534
Date: Sun, 23 Nov 2025 16:58:15 GMT   (4259kb)

Title: HiFi-MambaV2: Hierarchical Shared-Routed MoE for High-Fidelity MRI
 Reconstruction
Authors: Pengcheng Fang, Hongli Chen, Guangzhen Yao, Jian Shi, Fangfang Tang,
 Xiaohao Cai, Shanshan Shan, Feng Liu
Categories: cs.CV
\\
 Reconstructing high-fidelity MR images from undersampled k-space data
requires recovering high-frequency details while maintaining anatomical
coherence. We present HiFi-MambaV2, a hierarchical shared-routed
Mixture-of-Experts (MoE) Mamba architecture that couples frequency
decomposition with content-adaptive computation. The model comprises two core
components: (i) a separable frequency-consistent Laplacian pyramid (SF-Lap)
that delivers alias-resistant, stable low- and high-frequency streams; and (ii)
a hierarchical shared-routed MoE that performs per-pixel top-1 sparse dispatch
to shared experts and local routers, enabling effective specialization with
stable cross-depth behavior. A lightweight global context path is fused into an
unrolled, data-consistency-regularized backbone to reinforce long-range
reasoning and preserve anatomical coherence. Evaluated on fastMRI, CC359, ACDC,
M4Raw, and Prostate158, HiFi-MambaV2 consistently outperforms CNN-,
Transformer-, and prior Mamba-based baselines in PSNR, SSIM, and NMSE across
single- and multi-coil settings and multiple acceleration factors, consistently
surpassing consistent improvements in high-frequency detail and overall
structural fidelity. These results demonstrate that HiFi-MambaV2 enables
reliable and robust MRI reconstruction.
\\ ( https://arxiv.org/abs/2511.18534 ,  4259kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18537
Date: Sun, 23 Nov 2025 17:06:22 GMT   (6034kb)

Title: Zero-Shot Video Deraining with Video Diffusion Models
Authors: Tuomas Varanka, Juan Luis Gonzalez, Hyeongwoo Kim, Pablo Garrido, Xu
 Yao
Categories: cs.CV
Comments: WACV 2026
\\
 Existing video deraining methods are often trained on paired datasets, either
synthetic, which limits their ability to generalize to real-world rain, or
captured by static cameras, which restricts their effectiveness in dynamic
scenes with background and camera motion. Furthermore, recent works in
fine-tuning diffusion models have shown promising results, but the fine-tuning
tends to weaken the generative prior, limiting generalization to unseen cases.
In this paper, we introduce the first zero-shot video deraining method for
complex dynamic scenes that does not require synthetic data nor model
fine-tuning, by leveraging a pretrained text-to-video diffusion model that
demonstrates strong generalization capabilities. By inverting an input video
into the latent space of diffusion models, its reconstruction process can be
intervened and pushed away from the model's concept of rain using negative
prompting. At the core of our approach is an attention switching mechanism that
we found is crucial for maintaining dynamic backgrounds as well as structural
consistency between the input and the derained video, mitigating artifacts
introduced by naive negative prompting. Our approach is validated through
extensive experiments on real-world rain datasets, demonstrating substantial
improvements over prior methods and showcasing robust generalization without
the need for supervised training.
\\ ( https://arxiv.org/abs/2511.18537 ,  6034kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18559
Date: Sun, 23 Nov 2025 18:12:42 GMT   (48464kb)

Title: C3Po: Cross-View Cross-Modality Correspondence by Pointmap Prediction
Authors: Kuan Wei Huang, Brandon Li, Bharath Hariharan, Noah Snavely
Categories: cs.CV
Comments: NeurIPS 2025
\\
 Geometric models like DUSt3R have shown great advances in understanding the
geometry of a scene from pairs of photos. However, they fail when the inputs
are from vastly different viewpoints (e.g., aerial vs. ground) or modalities
(e.g., photos vs. abstract drawings) compared to what was observed during
training. This paper addresses a challenging version of this problem:
predicting correspondences between ground-level photos and floor plans. Current
datasets for joint photo--floor plan reasoning are limited, either lacking in
varying modalities (VIGOR) or lacking in correspondences (WAFFLE). To address
these limitations, we introduce a new dataset, C3, created by first
reconstructing a number of scenes in 3D from Internet photo collections via
structure-from-motion, then manually registering the reconstructions to floor
plans gathered from the Internet, from which we can derive correspondence
between images and floor plans. C3 contains 90K paired floor plans and photos
across 597 scenes with 153M pixel-level correspondences and 85K camera poses.
We find that state-of-the-art correspondence models struggle on this task. By
training on our new data, we can improve on the best performing method by 34%
in RMSE. We also identify open challenges in cross-modal geometric reasoning
that our dataset aims to help address.
\\ ( https://arxiv.org/abs/2511.18559 ,  48464kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18570
Date: Sun, 23 Nov 2025 18:29:20 GMT   (25886kb)

Title: PhysGS: Bayesian-Inferred Gaussian Splatting for Physical Property
 Estimation
Authors: Samarth Chopra, Jing Liang, Gershom Seneviratne, Dinesh Manocha
Categories: cs.CV cs.RO
Comments: Submitted to CVPR 2026
\\
 Understanding physical properties such as friction, stiffness, hardness, and
material composition is essential for enabling robots to interact safely and
effectively with their surroundings. However, existing 3D reconstruction
methods focus on geometry and appearance and cannot infer these underlying
physical properties. We present PhysGS, a Bayesian-inferred extension of 3D
Gaussian Splatting that estimates dense, per-point physical properties from
visual cues and vision--language priors. We formulate property estimation as
Bayesian inference over Gaussian splats, where material and property beliefs
are iteratively refined as new observations arrive. PhysGS also models
aleatoric and epistemic uncertainties, enabling uncertainty-aware object and
scene interpretation. Across object-scale (ABO-500), indoor, and outdoor
real-world datasets, PhysGS improves accuracy of the mass estimation by up to
22.8%, reduces Shore hardness error by up to 61.2%, and lowers kinetic friction
error by up to 18.1% compared to deterministic baselines. Our results
demonstrate that PhysGS unifies 3D reconstruction, uncertainty modeling, and
physical reasoning in a single, spatially continuous framework for dense
physical property estimation. Additional results are available at
https://samchopra2003.github.io/physgs.
\\ ( https://arxiv.org/abs/2511.18570 ,  25886kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18591
Date: Sun, 23 Nov 2025 19:08:45 GMT   (6605kb)

Title: Zero-Reference Joint Low-Light Enhancement and Deblurring via Visual
 Autoregressive Modeling with VLM-Derived Modulation
Authors: Wei Dong, Han Zhou, Junwei Lin, Jun Chen
Categories: cs.CV
Comments: Accepted by AAAI 2026; First Var-based method for joint LLIE and
 deblurring
\\
 Real-world dark images commonly exhibit not only low visibility and contrast
but also complex noise and blur, posing significant restoration challenges.
Existing methods often rely on paired data or fail to model dynamic
illumination and blur characteristics, leading to poor generalization. To
tackle this, we propose a generative framework based on visual autoregressive
(VAR) modeling, guided by perceptual priors from the vision-language model
(VLM). Specifically, to supply informative conditioning cues for VAR models, we
deploy an adaptive curve estimation scheme to modulate the diverse illumination
based on VLM-derived visibility scores. In addition, we integrate dynamic and
spatial-frequency-aware Rotary Positional Encodings (SF-RoPE) into VAR to
enhance its ability to model structures degraded by blur. Furthermore, we
propose a recursive phase-domain modulation strategy that mitigates
blur-induced artifacts in the phase domain via bounded iterative refinement
guided by VLM-assessed blur scores. Our framework is fully unsupervised and
achieves state-of-the-art performance on benchmark datasets.
\\ ( https://arxiv.org/abs/2511.18591 ,  6605kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18595
Date: Sun, 23 Nov 2025 19:38:03 GMT   (2479kb)

Title: Stage-Specific Benchmarking of Deep Learning Models for Glioblastoma
 Follow-Up MRI
Authors: Wenhao Guo and Golrokh Mirzaei
Categories: cs.CV cs.AI
Comments: 17 pages, 11 figures
\\
 Differentiating true tumor progression (TP) from treatment-related
pseudoprogression (PsP) in glioblastoma remains challenging, especially at
early follow-up. We present the first stage-specific, cross-sectional
benchmarking of deep learning models for follow-up MRI using the Burdenko GBM
Progression cohort (n = 180). We analyze different post-RT scans independently
to test whether architecture performance depends on time-point. Eleven
representative DL families (CNNs, LSTMs, hybrids, transformers, and selective
state-space models) were trained under a unified, QC-driven pipeline with
patient-level cross-validation. Across both stages, accuracies were comparable
(~0.70-0.74), but discrimination improved at the second follow-up, with F1 and
AUC increasing for several models, indicating richer separability later in the
care pathway. A Mamba+CNN hybrid consistently offered the best
accuracy-efficiency trade-off, while transformer variants delivered competitive
AUCs at substantially higher computational cost and lightweight CNNs were
efficient but less reliable. Performance also showed sensitivity to batch size,
underscoring the need for standardized training protocols. Notably, absolute
discrimination remained modest overall, reflecting the intrinsic difficulty of
TP vs. PsP and the dataset's size imbalance. These results establish a
stage-aware benchmark and motivate future work incorporating longitudinal
modeling, multi-sequence MRI, and larger multi-center cohorts.
\\ ( https://arxiv.org/abs/2511.18595 ,  2479kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18600
Date: Sun, 23 Nov 2025 19:50:05 GMT   (15346kb)

Title: NeAR: Coupled Neural Asset-Renderer Stack
Authors: Hong Li, Chongjie Ye, Houyuan Chen, Weiqing Xiao, Ziyang Yan, Lixing
 Xiao, Zhaoxi Chen, Jianfeng Xiang, Shaocong Xu, Xuhui Liu, Yikai Wang,
 Baochang Zhang, Xiaoguang Han, Jiaolong Yang, Hao Zhao
Categories: cs.CV
Comments: 20 pages, 16 figures
\\
 Neural asset authoring and neural rendering have emerged as fundamentally
disjoint threads: one generates digital assets using neural networks for
traditional graphics pipelines, while the other develops neural renderers that
map conventional assets to images. However, the potential of jointly designing
the asset representation and renderer remains largely unexplored. We argue that
coupling them can unlock an end-to-end learnable graphics stack with benefits
in fidelity, consistency, and efficiency. In this paper, we explore this
possibility with NeAR: a Coupled Neural Asset-Renderer Stack. On the asset
side, we build on Trellis-style Structured 3D Latents and introduce a
lighting-homogenized neural asset: from a casually lit input, a rectified-flow
backbone predicts a Lighting-Homogenized SLAT that encodes geometry and
intrinsic material cues in a compact, view-agnostic latent. On the renderer
side, we design a lighting-aware neural renderer that uses this neural asset,
along with explicit view embeddings and HDR environment maps, to achieve
real-time, relightable rendering. We validate NeAR on four tasks: (1)
G-buffer-based forward rendering, (2) random-lit single-image reconstruction,
(3) unknown-lit single-image relighting, and (4) novel-view relighting. Our
coupled stack surpasses state-of-the-art baselines in both quantitative metrics
and perceptual quality. We hope this coupled asset-renderer perspective
inspires future graphics stacks that view neural assets and renderers as
co-designed components instead of independent entities.
\\ ( https://arxiv.org/abs/2511.18600 ,  15346kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18601
Date: Sun, 23 Nov 2025 19:55:08 GMT   (22320kb)

Title: RigAnyFace: Scaling Neural Facial Mesh Auto-Rigging with Unlabeled Data
Authors: Wenchao Ma, Dario Kneubuehler, Maurice Chu, Ian Sachs, Haomiao Jiang,
 Sharon Xiaolei Huang
Categories: cs.CV
Comments: Accepted by NeurIPS 2025
\\
 In this paper, we present RigAnyFace (RAF), a scalable neural auto-rigging
framework for facial meshes of diverse topologies, including those with
multiple disconnected components. RAF deforms a static neutral facial mesh into
industry-standard FACS poses to form an expressive blendshape rig. Deformations
are predicted by a triangulation-agnostic surface learning network augmented
with our tailored architecture design to condition on FACS parameters and
efficiently process disconnected components. For training, we curated a dataset
of facial meshes, with a subset meticulously rigged by professional artists to
serve as accurate 3D ground truth for deformation supervision. Due to the high
cost of manual rigging, this subset is limited in size, constraining the
generalization ability of models trained exclusively on it. To address this, we
design a 2D supervision strategy for unlabeled neutral meshes without rigs.
This strategy increases data diversity and allows for scaled training, thereby
enhancing the generalization ability of models trained on this augmented data.
Extensive experiments demonstrate that RAF is able to rig meshes of diverse
topologies on not only our artist-crafted assets but also in-the-wild samples,
outperforming previous works in accuracy and generalizability. Moreover, our
method advances beyond prior work by supporting multiple disconnected
components, such as eyeballs, for more detailed expression animation. Project
page: https://wenchao-m.github.io/RigAnyFace.github.io
\\ ( https://arxiv.org/abs/2511.18601 ,  22320kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18627
Date: Sun, 23 Nov 2025 21:56:40 GMT   (946kb)

Title: Functional Localization Enforced Deep Anomaly Detection Using Fundus
 Images
Authors: Jan Benedikt Ruhland, Thorsten Papenbrock, Jan-Peter Sowa, Ali Canbay,
 Nicole Eter, Bernd Freisleben, Dominik Heider
Categories: cs.CV cs.LG
\\
 Reliable detection of retinal diseases from fundus images is challenged by
the variability in imaging quality, subtle early-stage manifestations, and
domain shift across datasets. In this study, we systematically evaluated a
Vision Transformer (ViT) classifier under multiple augmentation and enhancement
strategies across several heterogeneous public datasets, as well as the AEyeDB
dataset, a high-quality fundus dataset created in-house and made available for
the research community. The ViT demonstrated consistently strong performance,
with accuracies ranging from 0.789 to 0.843 across datasets and diseases.
Diabetic retinopathy and age-related macular degeneration were detected
reliably, whereas glaucoma remained the most frequently misclassified disease.
Geometric and color augmentations provided the most stable improvements, while
histogram equalization benefited datasets dominated by structural subtlety.
Laplacian enhancement reduced performance across different settings.
 On the Papila dataset, the ViT with geometric augmentation achieved an AUC of
0.91, outperforming previously reported convolutional ensemble baselines (AUC
of 0.87), underscoring the advantages of transformer architectures and
multi-dataset training. To complement the classifier, we developed a
GANomaly-based anomaly detector, achieving an AUC of 0.76 while providing
inherent reconstruction-based explainability and robust generalization to
unseen data. Probabilistic calibration using GUESS enabled
threshold-independent decision support for future clinical implementation.
\\ ( https://arxiv.org/abs/2511.18627 ,  946kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18640
Date: Sun, 23 Nov 2025 22:34:50 GMT   (15887kb)

Title: Health system learning achieves generalist neuroimaging models
Authors: Akhil Kondepudi, Akshay Rao, Chenhui Zhao, Yiwei Lyu, Samir Harake,
 Soumyanil Banerjee, Rushikesh Joshi, Anna-Katharina Meissner, Renly Hou,
 Cheng Jiang, Asadur Chowdury, Ashok Srinivasan, Brian Athey, Vikas Gulani,
 Aditya Pandey, Honglak Lee, and Todd Hollon
Categories: cs.CV cs.AI cs.LG
Comments: 53 pages, 4 main figures, 10 extended data figures
\\
 Frontier artificial intelligence (AI) models, such as OpenAI's GPT-5 and
Meta's DINOv3, have advanced rapidly through training on internet-scale public
data, yet such systems lack access to private clinical data. Neuroimaging, in
particular, is underrepresented in the public domain due to identifiable facial
features within MRI and CT scans, fundamentally restricting model performance
in clinical medicine. Here, we show that frontier models underperform on
neuroimaging tasks and that learning directly from uncurated data generated
during routine clinical care at health systems, a paradigm we call health
system learning, yields high-performance, generalist neuroimaging models. We
introduce NeuroVFM, a visual foundation model trained on 5.24 million clinical
MRI and CT volumes using a scalable volumetric joint-embedding predictive
architecture. NeuroVFM learns comprehensive representations of brain anatomy
and pathology, achieving state-of-the-art performance across multiple clinical
tasks, including radiologic diagnosis and report generation. The model exhibits
emergent neuroanatomic understanding and interpretable visual grounding of
diagnostic findings. When paired with open-source language models through
lightweight visual instruction tuning, NeuroVFM generates radiology reports
that surpass frontier models in accuracy, clinical triage, and expert
preference. Through clinically grounded visual understanding, NeuroVFM reduces
hallucinated findings and critical errors, offering safer clinical decision
support. These results establish health system learning as a paradigm for
building generalist medical AI and provide a scalable framework for clinical
foundation models.
\\ ( https://arxiv.org/abs/2511.18640 ,  15887kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18654
Date: Sun, 23 Nov 2025 23:28:49 GMT   (1539kb)

Title: From Healthy Scans to Annotated Tumors: A Tumor Fabrication Framework
 for 3D Brain MRI Synthesis
Authors: Nayu Dong, Townim Chowdhury, Hieu Phan, Mark Jenkinson, Johan Verjans,
 Zhibin Liao
Categories: cs.CV
\\
 The scarcity of annotated Magnetic Resonance Imaging (MRI) tumor data
presents a major obstacle to accurate and automated tumor segmentation. While
existing data synthesis methods offer promising solutions, they often suffer
from key limitations: manual modeling is labor intensive and requires expert
knowledge. Deep generative models may be used to augment data and annotation,
but they typically demand large amounts of training pairs in the first place,
which is impractical in data limited clinical settings. In this work, we
propose Tumor Fabrication (TF), a novel two-stage framework for unpaired 3D
brain tumor synthesis. The framework comprises a coarse tumor synthesis process
followed by a refinement process powered by a generative model. TF is fully
automated and leverages only healthy image scans along with a limited amount of
real annotated data to synthesize large volumes of paired synthetic data for
enriching downstream supervised segmentation training. We demonstrate that our
synthetic image-label pairs used as data enrichment can significantly improve
performance on downstream tumor segmentation tasks in low-data regimes,
offering a scalable and reliable solution for medical image enrichment and
addressing critical challenges in data scarcity for clinical AI applications.
\\ ( https://arxiv.org/abs/2511.18654 ,  1539kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18656
Date: Sun, 23 Nov 2025 23:43:31 GMT   (15173kb)

Title: Robust Physical Adversarial Patches Using Dynamically Optimized Clusters
Authors: Harrison Bagley, Will Meakin, Simon Lucey, Yee Wei Law, Tat-Jun Chin
Categories: cs.CV
Comments: Supplementary material available at:
 https://drive.google.com/drive/folders/1Yntcc9CARdbvoJJ51cyUm1DWGSvU9X4V?usp=drive_link
\\
 Physical adversarial attacks on deep learning systems is concerning due to
the ease of deploying such attacks, usually by placing an adversarial patch in
a scene to manipulate the outcomes of a deep learning model. Training such
patches typically requires regularization that improves physical realizability
(e.g., printability, smoothness) and/or robustness to real-world variability
(e.g. deformations, viewing angle, noise). One type of variability that has
received little attention is scale variability. When a patch is rescaled,
either digitally through downsampling/upsampling or physically through changing
imaging distances, interpolation-induced color mixing occurs. This smooths out
pixel values, resulting in a loss of high-frequency patterns and degrading the
adversarial signal. To address this, we present a novel superpixel-based
regularization method that guides patch optimization to scale-resilient
structures. Our ap proach employs the Simple Linear Iterative Clustering (SLIC)
algorithm to dynamically cluster pixels in an adversarial patch during
optimization. The Implicit Function Theorem is used to backpropagate gradients
through SLIC to update the superpixel boundaries and color. This produces
patches that maintain their structure over scale and are less susceptible to
interpolation losses. Our method achieves greater performance in the digital
domain, and when realized physically, these performance gains are preserved,
leading to improved physical performance. Real-world performance was
objectively assessed using a novel physical evaluation protocol that utilizes
screens and cardboard cut-outs to systematically vary real-world conditions.
\\ ( https://arxiv.org/abs/2511.18656 ,  15173kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18668
Date: Mon, 24 Nov 2025 00:47:27 GMT   (28128kb)

Title: Data Augmentation Strategies for Robust Lane Marking Detection
Authors: Flora Lian, Dinh Quang Huynh, Hector Penades, J. Stephany Berrio
 Perez, Mao Shan, Stewart Worrall
Categories: cs.CV eess.IV
Comments: 8 figures, 2 tables, 10 pages, ACRA, Australasian conference on
 robotics and automation
\\
 Robust lane detection is essential for advanced driver assistance and
autonomous driving, yet models trained on public datasets such as CULane often
fail to generalise across different camera viewpoints. This paper addresses the
challenge of domain shift for side-mounted cameras used in lane-wheel
monitoring by introducing a generative AI-based data enhancement pipeline. The
approach combines geometric perspective transformation, AI-driven inpainting,
and vehicle body overlays to simulate deployment-specific viewpoints while
preserving lane continuity. We evaluated the effectiveness of the proposed
augmentation in two state-of-the-art models, SCNN and UFLDv2. With the
augmented data trained, both models show improved robustness to different
conditions, including shadows. The experimental results demonstrate gains in
precision, recall, and F1 score compared to the pre-trained model.
 By bridging the gap between widely available datasets and deployment-specific
scenarios, our method provides a scalable and practical framework to improve
the reliability of lane detection in a pilot deployment scenario.
\\ ( https://arxiv.org/abs/2511.18668 ,  28128kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18672
Date: Mon, 24 Nov 2025 01:09:23 GMT   (15669kb)

Title: Sphinx: Efficiently Serving Novel View Synthesis using Regression-Guided
 Selective Refinement
Authors: Yuchen Xia, Souvik Kundu, Mosharaf Chowdhury and Nishil Talati
Categories: cs.CV
\\
 Novel View Synthesis (NVS) is the task of generating new images of a scene
from viewpoints that were not part of the original input. Diffusion-based NVS
can generate high-quality, temporally consistent images, however, remains
computationally prohibitive. Conversely, regression-based NVS offers suboptimal
generation quality despite requiring significantly lower compute; leaving the
design objective of a high-quality, inference-efficient NVS framework an open
challenge. To close this critical gap, we present Sphinx, a training-free
hybrid inference framework that achieves diffusion-level fidelity at a
significantly lower compute. Sphinx proposes to use regression-based fast
initialization to guide and reduce the denoising workload for the diffusion
model. Additionally, it integrates selective refinement with adaptive noise
scheduling, allowing more compute to uncertain regions and frames. This enables
Sphinx to provide flexible navigation of the performance-quality trade-off,
allowing adaptation to latency and fidelity requirements for dynamically
changing inference scenarios. Our evaluation shows that Sphinx achieves an
average 1.8x speedup over diffusion model inference with negligible perceptual
degradation of less than 5%, establishing a new Pareto frontier between quality
and latency in NVS serving.
\\ ( https://arxiv.org/abs/2511.18672 ,  15669kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18673
Date: Mon, 24 Nov 2025 01:13:51 GMT   (4499kb)

Title: Edit2Perceive: Image Editing Diffusion Models Are Strong Dense
 Perceivers
Authors: Yiqing Shi, Yiren Song, Mike Zheng Shou
Categories: cs.CV
\\
 Recent advances in diffusion transformers have shown remarkable
generalization in visual synthesis, yet most dense perception methods still
rely on text-to-image (T2I) generators designed for stochastic generation. We
revisit this paradigm and show that image editing diffusion models are
inherently image-to-image consistent, providing a more suitable foundation for
dense perception task. We introduce Edit2Perceive, a unified diffusion
framework that adapts editing models for depth, normal, and matting. Built upon
the FLUX.1 Kontext architecture, our approach employs full-parameter
fine-tuning and a pixel-space consistency loss to enforce structure-preserving
refinement across intermediate denoising states. Moreover, our single-step
deterministic inference yields up to faster runtime while training on
relatively small datasets. Extensive experiments demonstrate comprehensive
state-of-the-art results across all three tasks, revealing the strong potential
of editing-oriented diffusion transformers for geometry-aware perception.
\\ ( https://arxiv.org/abs/2511.18673 ,  4499kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18676
Date: Mon, 24 Nov 2025 01:26:07 GMT   (26176kb)

Title: MedVision: Dataset and Benchmark for Quantitative Medical Image Analysis
Authors: Yongcheng Yao, Yongshuo Zong, Raman Dutt, Yongxin Yang, Sotirios A
 Tsaftaris, Timothy Hospedales
Categories: cs.CV cs.AI
Comments: 8 pages, 8 figures, 4 tables
MSC-class: N/A
ACM-class: I.2.10
\\
 Current vision-language models (VLMs) in medicine are primarily designed for
categorical question answering (e.g., "Is this normal or abnormal?") or
qualitative descriptive tasks. However, clinical decision-making often relies
on quantitative assessments, such as measuring the size of a tumor or the angle
of a joint, from which physicians draw their own diagnostic conclusions. This
quantitative reasoning capability remains underexplored and poorly supported in
existing VLMs. In this work, we introduce MedVision, a large-scale dataset and
benchmark specifically designed to evaluate and improve VLMs on quantitative
medical image analysis. MedVision spans 22 public datasets covering diverse
anatomies and modalities, with 30.8 million image-annotation pairs. We focus on
three representative quantitative tasks: (1) detection of anatomical structures
and abnormalities, (2) tumor/lesion (T/L) size estimation, and (3)
angle/distance (A/D) measurement. Our benchmarks show that current
off-the-shelf VLMs perform poorly on these tasks. However, with supervised
fine-tuning on MedVision, we significantly enhance their performance across
detection, T/L estimation, and A/D measurement, demonstrating reduced error
rates and improved precision. This work provides a foundation for developing
VLMs with robust quantitative reasoning capabilities in medical imaging. Code
and data are available at https://medvision-vlm.github.io.
\\ ( https://arxiv.org/abs/2511.18676 ,  26176kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18677
Date: Mon, 24 Nov 2025 01:26:46 GMT   (1697kb)

Title: A Theory-Inspired Framework for Few-Shot Cross-Modal Sketch Person
 Re-Identification
Authors: Yunpeng Gong, Yongjie Hou, Jiangming Shi, Kim Long Diep, Min Jiang
Categories: cs.CV
Comments: Accepted by AAAI2026
\\
 Sketch based person re-identification aims to match hand-drawn sketches with
RGB surveillance images, but remains challenging due to significant modality
gaps and limited annotated data. To address this, we introduce KTCAA, a
theoretically grounded framework for few-shot cross-modal generalization.
Motivated by generalization theory, we identify two key factors influencing
target domain risk: (1) domain discrepancy, which quantifies the alignment
difficulty between source and target distributions; and (2) perturbation
invariance, which evaluates the model's robustness to modality shifts. Based on
these insights, we propose two components: (1) Alignment Augmentation (AA),
which applies localized sketch-style transformations to simulate target
distributions and facilitate progressive alignment; and (2) Knowledge Transfer
Catalyst (KTC), which enhances invariance by introducing worst-case
perturbations and enforcing consistency. These modules are jointly optimized
under a meta-learning paradigm that transfers alignment knowledge from
data-rich RGB domains to sketch-based scenarios. Experiments on multiple
benchmarks demonstrate that KTCAA achieves state-of-the-art performance,
particularly in data-scarce conditions.
\\ ( https://arxiv.org/abs/2511.18677 ,  1697kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18679
Date: Mon, 24 Nov 2025 01:43:19 GMT   (23754kb)

Title: Neural Geometry Image-Based Representations with Optimal Transport (OT)
Authors: Xiang Gao, Yuanpeng Liu, Xinmu Wang, Jiazhi Li, Minghao Guo, Yu Guo,
 Xiyun Song, Heather Yu, Zhiqiang Lao, Xianfeng David Gu
Categories: cs.CV
Comments: WACV2026 Rround 2 Accepted
\\
 Neural representations for 3D meshes are emerging as an effective solution
for compact storage and efficient processing. Existing methods often rely on
neural overfitting, where a coarse mesh is stored and progressively refined
through multiple decoder networks. While this can restore high-quality
surfaces, it is computationally expensive due to successive decoding passes and
the irregular structure of mesh data. In contrast, images have a regular
structure that enables powerful super-resolution and restoration frameworks,
but applying these advantages to meshes is difficult because their irregular
connectivity demands complex encoder-decoder architectures. Our key insight is
that a geometry image-based representation transforms irregular meshes into a
regular image grid, making efficient image-based neural processing directly
applicable. Building on this idea, we introduce our neural geometry image-based
representation, which is decoder-free, storage-efficient, and naturally suited
for neural processing. It stores a low-resolution geometry-image mipmap of the
surface, from which high-quality meshes are restored in a single forward pass.
To construct geometry images, we leverage Optimal Transport (OT), which
resolves oversampling in flat regions and undersampling in feature-rich
regions, and enables continuous levels of detail (LoD) through geometry-image
mipmapping. Experimental results demonstrate state-of-the-art storage
efficiency and restoration accuracy, measured by compression ratio (CR),
Chamfer distance (CD), and Hausdorff distance (HD).
\\ ( https://arxiv.org/abs/2511.18679 ,  23754kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18682
Date: Mon, 24 Nov 2025 01:45:26 GMT   (30288kb)

Title: Hierarchical GraphCut Phase Unwrapping based on Invariance of
 Diffeomorphisms Framework
Authors: Xiang Gao, Xinmu Wang, Zhou Zhao, Junqi Huang, Xianfeng David Gu
Categories: cs.CV
Comments: Open Journal of Signal Processing (OJSP) as journal paper for
 ICIP2025 Accepted
\\
 Recent years have witnessed rapid advancements in 3D scanning technologies,
with applications spanning VR/AR, digital human creation, and medical imaging.
Structured-light scanning with phase-shifting techniques is preferred for its
use of low-intensity visible light and high accuracy, making it well suited for
capturing 4D facial dynamics. A key step is phase unwrapping, which recovers
continuous phase values from measurements wrapped modulo 2pi. The goal is to
estimate the unwrapped phase count k in the equation Phi = phi + 2pi k, where
phi is the wrapped phase and Phi is the true phase. Noise, occlusions, and
complex 3D geometry make recovering the true phase challenging because phase
unwrapping is ill-posed: measurements only provide modulo 2pi values, and
estimating k requires assumptions about surface continuity. Existing methods
trade speed for accuracy: fast approaches lack precision, while accurate
algorithms are too slow for real-time use. To overcome these limitations, this
work proposes a phase unwrapping framework that reformulates GraphCut-based
unwrapping as a pixel-labeling problem. This framework improves the estimation
of the unwrapped phase count k through the invariance property of
diffeomorphisms applied in image space via conformal and optimal transport (OT)
maps. An odd number of diffeomorphisms are precomputed from the input phase
data, and a hierarchical GraphCut algorithm is applied in each domain. The
resulting label maps are fused via majority voting to robustly estimate k at
each pixel. Experimental results demonstrate a 45.5x speedup and lower L2 error
in real experiments and simulations, showing potential for real-time
applications.
\\ ( https://arxiv.org/abs/2511.18682 ,  30288kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18684
Date: Mon, 24 Nov 2025 01:48:44 GMT   (48154kb)

Title: Now You See It, Now You Don't - Instant Concept Erasure for Safe
 Text-to-Image and Video Generation
Authors: Shristi Das Biswas, Arani Roy, Kaushik Roy
Categories: cs.CV
\\
 Robust concept removal for text-to-image (T2I) and text-to-video (T2V) models
is essential for their safe deployment. Existing methods, however, suffer from
costly retraining, inference overhead, or vulnerability to adversarial attacks.
Crucially, they rarely model the latent semantic overlap between the target
erase concept and surrounding content -- causing collateral damage post-erasure
-- and even fewer methods work reliably across both T2I and T2V domains. We
introduce Instant Concept Erasure (ICE), a training-free, modality-agnostic,
one-shot weight modification approach that achieves precise, persistent
unlearning with zero overhead. ICE defines erase and preserve subspaces using
anisotropic energy-weighted scaling, then explicitly regularises against their
intersection using a unique, closed-form overlap projector. We pose a convex
and Lipschitz-bounded Spectral Unlearning Objective, balancing erasure fidelity
and intersection preservation, that admits a stable and unique analytical
solution. This solution defines a dissociation operator that is translated to
the model's text-conditioning layers, making the edit permanent and
runtime-free. Across targeted removals of artistic styles, objects, identities,
and explicit content, ICE efficiently achieves strong erasure with improved
robustness to red-teaming, all while causing only minimal degradation of
original generative abilities in both T2I and T2V models.
\\ ( https://arxiv.org/abs/2511.18684 ,  48154kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18685
Date: Mon, 24 Nov 2025 02:02:29 GMT   (5399kb)

Title: Beyond Description: Cognitively Benchmarking Fine-Grained Action for
 Embodied Agents
Authors: Dayong Liu, Chao Xu, Weihong Chen, Suyu Zhang, Juncheng Wang, Jiankang
 Deng, Baigui Sun, Yang Liu
Categories: cs.CV cs.RO
\\
 Multimodal Large Language Models (MLLMs) show promising results as
decision-making engines for embodied agents operating in complex, physical
environments. However, existing benchmarks often prioritize high-level planning
or spatial reasoning, leaving the fine-grained action intelligence required for
embodied physical interaction underexplored. To address this gap, we introduce
CFG-Bench, a new benchmark designed to systematically evaluate this crucial
capability. CFG-Bench consists of 1,368 curated videos paired with 19,562
three-modalities question-answer pairs targeting four cognitive abilities: 1)
Physical Interaction, 2) Temporal-Causal Relation, 3) Intentional
Understanding, and 4) Evaluative Judgment. Together, these dimensions provide a
systematic framework for assessing a model's ability to translate visual
observations into actionable knowledge, moving beyond mere surface-level
recognition. Our comprehensive evaluation on CFG-Bench reveals that leading
MLLMs struggle to produce detailed instructions for physical interactions and
exhibit profound limitations in the higher-order reasoning of intention and
evaluation. Moreover, supervised fine-tuning (SFT) on our data demonstrates
that teaching an MLLMs to articulate fine-grained actions directly translates
to significant performance gains on established embodied benchmarks. Our
analysis highlights these limitations and offers insights for developing more
capable and grounded embodied agents.
\\ ( https://arxiv.org/abs/2511.18685 ,  5399kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18691
Date: Mon, 24 Nov 2025 02:11:19 GMT   (1798kb)

Title: EVCC: Enhanced Vision Transformer-ConvNeXt-CoAtNet Fusion for
 Classification
Authors: Kazi Reyazul Hasan, Md Nafiu Rahman, Wasif Jalal, Sadif Ahmed,
 Shahriar Raj, Mubasshira Musarrat, Muhammad Abdullah Adnan
Categories: cs.CV
\\
 Hybrid vision architectures combining Transformers and CNNs have
significantly advanced image classification, but they usually do so at
significant computational cost. We introduce EVCC (Enhanced Vision
Transformer-ConvNeXt-CoAtNet), a novel multi-branch architecture integrating
the Vision Transformer, lightweight ConvNeXt, and CoAtNet through key
innovations: (1) adaptive token pruning with information preservation, (2)
gated bidirectional cross-attention for enhanced feature refinement, (3)
auxiliary classification heads for multi-task learning, and (4) a dynamic
router gate employing context-aware confidence-driven weighting. Experiments
across the CIFAR-100, Tobacco3482, CelebA, and Brain Cancer datasets
demonstrate EVCC's superiority over powerful models like DeiT-Base,
MaxViT-Base, and CrossViT-Base by consistently achieving state-of-the-art
accuracy with improvements of up to 2 percentage points, while reducing FLOPs
by 25 to 35%. Our adaptive architecture adjusts computational demands to
deployment needs by dynamically reducing token count, efficiently balancing the
accuracy-efficiency trade-off while combining global context, local details,
and hierarchical features for real-world applications. The source code of our
implementation is available at https://anonymous.4open.science/r/EVCC.
\\ ( https://arxiv.org/abs/2511.18691 ,  1798kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18695
Date: Mon, 24 Nov 2025 02:28:56 GMT   (1760kb)

Title: Exploring Surround-View Fisheye Camera 3D Object Detection
Authors: Changcai Li, Wenwei Lin, Zuoxun Hou, Gang Chen, Wei Zhang, Huihui
 Zhou, Weishi Zheng
Categories: cs.CV
Comments: 9 pages,6 figures, accepted at AAAI 2026
ACM-class: I.2.10; I.4.8
Journal-ref: Proceedings of the AAAI Conference on Artificial Intelligence
 (AAAI), 2026
\\
 In this work, we explore the technical feasibility of implementing end-to-end
3D object detection (3DOD) with surround-view fisheye camera system.
Specifically, we first investigate the performance drop incurred when
transferring classic pinhole-based 3D object detectors to fisheye imagery. To
mitigate this, we then develop two methods that incorporate the unique geometry
of fisheye images into mainstream detection frameworks: one based on the
bird's-eye-view (BEV) paradigm, named FisheyeBEVDet, and the other on the
query-based paradigm, named FisheyePETR. Both methods adopt spherical spatial
representations to effectively capture fisheye geometry. In light of the lack
of dedicated evaluation benchmarks, we release Fisheye3DOD, a new open dataset
synthesized using CARLA and featuring both standard pinhole and fisheye camera
arrays. Experiments on Fisheye3DOD show that our fisheye-compatible modeling
improves accuracy by up to 6.2% over baseline methods.
\\ ( https://arxiv.org/abs/2511.18695 ,  1760kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18699
Date: Mon, 24 Nov 2025 02:43:29 GMT   (2452kb)

Title: Dendritic Convolution for Noise Image Recognition
Authors: Jiarui Xue, Dongjian Yang, Ye Sun, Gang Liu
Categories: cs.CV cs.LG
Comments: 11 pages, 8 figures
\\
 In real-world scenarios of image recognition, there exists substantial noise
interference. Existing works primarily focus on methods such as adjusting
networks or training strategies to address noisy image recognition, and the
anti-noise performance has reached a bottleneck. However, little is known about
the exploration of anti-interference solutions from a neuronal perspective.This
paper proposes an anti-noise neuronal convolution. This convolution mimics the
dendritic structure of neurons, integrates the neighborhood interaction
computation logic of dendrites into the underlying design of convolutional
operations, and simulates the XOR logic preprocessing function of biological
dendrites through nonlinear interactions between input features, thereby
fundamentally reconstructing the mathematical paradigm of feature extraction.
Unlike traditional convolution where noise directly interferes with feature
extraction and exerts a significant impact, DDC mitigates the influence of
noise by focusing on the interaction of neighborhood information. Experimental
results demonstrate that in image classification tasks (using YOLOv11-cls,
VGG16, and EfficientNet-B0) and object detection tasks (using YOLOv11, YOLOv8,
and YOLOv5), after replacing traditional convolution with the dendritic
convolution, the accuracy of the EfficientNet-B0 model on noisy datasets is
relatively improved by 11.23%, and the mean Average Precision (mAP) of YOLOv8
is increased by 19.80%. The consistency between the computation method of this
convolution and the dendrites of biological neurons enables it to perform
significantly better than traditional convolution in complex noisy
environments.
\\ ( https://arxiv.org/abs/2511.18699 ,  2452kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18701
Date: Mon, 24 Nov 2025 02:50:01 GMT   (60758kb)

Title: ObjectAlign: Neuro-Symbolic Object Consistency Verification and
 Correction
Authors: Mustafa Munir, Harsh Goel, Xiwen Wei, Minkyu Choi, Sahil Shah,
 Kartikeya Bhardwaj, Paul Whatmough, Sandeep Chinchali, Radu Marculescu
Categories: cs.CV cs.AI cs.FL cs.LG
\\
 Video editing and synthesis often introduce object inconsistencies, such as
frame flicker and identity drift that degrade perceptual quality. To address
these issues, we introduce ObjectAlign, a novel framework that seamlessly
blends perceptual metrics with symbolic reasoning to detect, verify, and
correct object-level and temporal inconsistencies in edited video sequences.
The novel contributions of ObjectAlign are as follows: First, we propose
learnable thresholds for metrics characterizing object consistency (i.e.
CLIP-based semantic similarity, LPIPS perceptual distance, histogram
correlation, and SAM-derived object-mask IoU). Second, we introduce a
neuro-symbolic verifier that combines two components: (a) a formal, SMT-based
check that operates on masked object embeddings to provably guarantee that
object identity does not drift, and (b) a temporal fidelity check that uses a
probabilistic model checker to verify the video's formal representation against
a temporal logic specification. A frame transition is subsequently deemed
"consistent" based on a single logical assertion that requires satisfying both
the learned metric thresholds and this unified neuro-symbolic constraint,
ensuring both low-level stability and high-level temporal correctness. Finally,
for each contiguous block of flagged frames, we propose a neural network based
interpolation for adaptive frame repair, dynamically choosing the interpolation
depth based on the number of frames to be corrected. This enables
reconstruction of the corrupted frames from the last valid and next valid
keyframes. Our results show up to 1.4 point improvement in CLIP Score and up to
6.1 point improvement in warp error compared to SOTA baselines on the DAVIS and
Pexels video datasets.
\\ ( https://arxiv.org/abs/2511.18701 ,  60758kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18706
Date: Mon, 24 Nov 2025 03:00:15 GMT   (10417kb)

Title: CoD: A Diffusion Foundation Model for Image Compression
Authors: Zhaoyang Jia, Zihan Zheng, Naifu Xue, Jiahao Li, Bin Li, Zongyu Guo,
 Xiaoyi Zhang, Houqiang Li, Yan Lu
Categories: cs.CV
\\
 Existing diffusion codecs typically build on text-to-image diffusion
foundation models like Stable Diffusion. However, text conditioning is
suboptimal from a compression perspective, hindering the potential of
downstream diffusion codecs, particularly at ultra-low bitrates. To address it,
we introduce \textbf{CoD}, the first \textbf{Co}mpression-oriented
\textbf{D}iffusion foundation model, trained from scratch to enable end-to-end
optimization of both compression and generation. CoD is not a fixed codec but a
general foundation model designed for various diffusion-based codecs. It offers
several advantages: \textbf{High compression efficiency}, replacing Stable
Diffusion with CoD in downstream codecs like DiffC achieves SOTA results,
especially at ultra-low bitrates (e.g., 0.0039 bpp); \textbf{Low-cost and
reproducible training}, 300$\times$ faster training than Stable Diffusion
($\sim$ 20 vs. $\sim$ 6,250 A100 GPU days) on entirely open image-only
datasets; \textbf{Providing new insights}, e.g., We find pixel-space diffusion
can achieve VTM-level PSNR with high perceptual quality and can outperform
GAN-based codecs using fewer parameters. We hope CoD lays the foundation for
future diffusion codec research. Codes will be released.
\\ ( https://arxiv.org/abs/2511.18706 ,  10417kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18711
Date: Mon, 24 Nov 2025 03:09:59 GMT   (3911kb)

Title: Modality-Collaborative Low-Rank Decomposers for Few-Shot Video Domain
 Adaptation
Authors: Yuyang Wanyan, Xiaoshan Yang, Weiming Dong, and Changsheng Xu
Categories: cs.CV cs.AI
\\
 In this paper, we study the challenging task of Few-Shot Video Domain
Adaptation (FSVDA). The multimodal nature of videos introduces unique
challenges, necessitating the simultaneous consideration of both domain
alignment and modality collaboration in a few-shot scenario, which is ignored
in previous literature. We observe that, under the influence of domain shift,
the generalization performance on the target domain of each individual
modality, as well as that of fused multimodal features, is constrained. Because
each modality is comprised of coupled features with multiple components that
exhibit different domain shifts. This variability increases the complexity of
domain adaptation, thereby reducing the effectiveness of multimodal feature
integration. To address these challenges, we introduce a novel framework of
Modality-Collaborative LowRank Decomposers (MC-LRD) to decompose
modality-unique and modality-shared features with different domain shift levels
from each modality that are more friendly for domain alignment. The MC-LRD
comprises multiple decomposers for each modality and Multimodal Decomposition
Routers (MDR). Each decomposer has progressively shared parameters across
different modalities. The MDR is leveraged to selectively activate the
decomposers to produce modality-unique and modality-shared features. To ensure
efficient decomposition, we apply orthogonal decorrelation constraints
separately to decomposers and subrouters, enhancing their diversity.
Furthermore, we propose a cross-domain activation consistency loss to guarantee
that target and source samples of the same category exhibit consistent
activation preferences of the decomposers, thereby facilitating domain
alignment. Extensive experimental results on three public benchmarks
demonstrate that our model achieves significant improvements over existing
methods.
\\ ( https://arxiv.org/abs/2511.18711 ,  3911kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18713
Date: Mon, 24 Nov 2025 03:12:43 GMT   (6035kb)

Title: DriveFlow: Rectified Flow Adaptation for Robust 3D Object Detection in
 Autonomous Driving
Authors: Hongbin Lin, Yiming Yang, Chaoda Zheng, Yifan Zhang, Shuaicheng Niu,
 Zilu Guo, Yafeng Li, Gui Gui, Shuguang Cui, Zhen Li
Categories: cs.CV
Comments: Accepted by AAAI 2026
\\
 In autonomous driving, vision-centric 3D object detection recognizes and
localizes 3D objects from RGB images. However, due to high annotation costs and
diverse outdoor scenes, training data often fails to cover all possible test
scenarios, known as the out-of-distribution (OOD) issue. Training-free image
editing offers a promising solution for improving model robustness by training
data enhancement without any modifications to pre-trained diffusion models.
Nevertheless, inversion-based methods often suffer from limited effectiveness
and inherent inaccuracies, while recent rectified-flow-based approaches
struggle to preserve objects with accurate 3D geometry. In this paper, we
propose DriveFlow, a Rectified Flow Adaptation method for training data
enhancement in autonomous driving based on pre-trained Text-to-Image flow
models. Based on frequency decomposition, DriveFlow introduces two strategies
to adapt noise-free editing paths derived from text-conditioned velocities. 1)
High-Frequency Foreground Preservation: DriveFlow incorporates a high-frequency
alignment loss for foreground to maintain precise 3D object geometry. 2)
Dual-Frequency Background Optimization: DriveFlow also conducts dual-frequency
optimization for background, balancing editing flexibility and semantic
consistency. Comprehensive experiments validate the effectiveness and
efficiency of DriveFlow, demonstrating comprehensive performance improvements
on all categories across OOD scenarios. Code is available at
https://github.com/Hongbin98/DriveFlow.
\\ ( https://arxiv.org/abs/2511.18713 ,  6035kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18719
Date: Mon, 24 Nov 2025 03:21:17 GMT   (3446kb)

Title: Seeing What Matters: Visual Preference Policy Optimization for Visual
 Generation
Authors: Ziqi Ni, Yuanzhi Liang, Rui Li, Yi Zhou, Haibing Huang, Chi Zhang,
 Xuelong Li
Categories: cs.CV
\\
 Reinforcement learning (RL) has become a powerful tool for post-training
visual generative models, with Group Relative Policy Optimization (GRPO)
increasingly used to align generators with human preferences. However, existing
GRPO pipelines rely on a single scalar reward per sample, treating each image
or video as a holistic entity and ignoring the rich spatial and temporal
structure of visual content. This coarse supervision hinders the correction of
localized artifacts and the modeling of fine-grained perceptual cues. We
introduce Visual Preference Policy Optimization (ViPO), a GRPO variant that
lifts scalar feedback into structured, pixel-level advantages. ViPO employs a
Perceptual Structuring Module that uses pretrained vision backbones to
construct spatially and temporally aware advantage maps, redistributing
optimization pressure toward perceptually important regions while preserving
the stability of standard GRPO. Across both image and video benchmarks, ViPO
consistently outperforms vanilla GRPO, improving in-domain alignment with
human-preference rewards and enhancing generalization on out-of-domain
evaluations. The method is architecture-agnostic, lightweight, and fully
compatible with existing GRPO training pipelines, providing a more expressive
and informative learning signal for visual generation.
\\ ( https://arxiv.org/abs/2511.18719 ,  3446kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18729
Date: Mon, 24 Nov 2025 03:45:32 GMT   (5246kb)

Title: GuideFlow: Constraint-Guided Flow Matching for Planning in End-to-End
 Autonomous Driving
Authors: Lin Liu, Caiyan Jia, Guanyi Yu, Ziying Song, JunQiao Li, Feiyang Jia,
 Peiliang Wu, Xiaoshuai Hao, Yandan Luo
Categories: cs.CV
\\
 Driving planning is a critical component of end-to-end (E2E) autonomous
driving. However, prevailing Imitative E2E Planners often suffer from
multimodal trajectory mode collapse, failing to produce diverse trajectory
proposals. Meanwhile, Generative E2E Planners struggle to incorporate crucial
safety and physical constraints directly into the generative process,
necessitating an additional optimization stage to refine their outputs. In this
paper, we propose \textit{\textbf{GuideFlow}}, a novel planning framework that
leverages Constrained Flow Matching. Concretely, \textit{\textbf{GuideFlow}}
explicitly models the flow matching process, which inherently mitigates mode
collapse and allows for flexible guidance from various conditioning signals.
Our core contribution lies in directly enforcing explicit constraints within
the flow matching generation process, rather than relying on implicit
constraint encoding. Crucially, \textit{\textbf{GuideFlow}} unifies the
training of the flow matching with the Energy-Based Model (EBM) to enhance the
model's autonomous optimization capability to robustly satisfy physical
constraints. Secondly, \textit{\textbf{GuideFlow}} parameterizes driving
aggressiveness as a control signal during generation, enabling precise
manipulation of trajectory style. Extensive evaluations on major driving
benchmarks (Bench2Drive, NuScenes, NavSim and ADV-NuScenes) validate the
effectiveness of \textit{\textbf{GuideFlow}}. Notably, on the NavSim test hard
split (Navhard), \textit{\textbf{GuideFlow}} achieved SOTA with an EPDMS score
of 43.0. The code will be released.
\\ ( https://arxiv.org/abs/2511.18729 ,  5246kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18734
Date: Mon, 24 Nov 2025 04:02:48 GMT   (4244kb)

Title: Yo'City: Personalized and Boundless 3D Realistic City Scene Generation
 via Self-Critic Expansion
Authors: Keyang Lu, Sifan Zhou, Hongbin Xu, Gang Xu, Zhifei Yang, Yikai Wang,
 Zhen Xiao, Jieyi Long, Ming Li
Categories: cs.CV cs.AI
Comments: 22 pages, 16 figures
\\
 Realistic 3D city generation is fundamental to a wide range of applications,
including virtual reality and digital twins. However, most existing methods
rely on training a single diffusion model, which limits their ability to
generate personalized and boundless city-scale scenes. In this paper, we
present Yo'City, a novel agentic framework that enables user-customized and
infinitely expandable 3D city generation by leveraging the reasoning and
compositional capabilities of off-the-shelf large models. Specifically, Yo'City
first conceptualize the city through a top-down planning strategy that defines
a hierarchical "City-District-Grid" structure. The Global Planner determines
the overall layout and potential functional districts, while the Local Designer
further refines each district with detailed grid-level descriptions.
Subsequently, the grid-level 3D generation is achieved through a
"produce-refine-evaluate" isometric image synthesis loop, followed by
image-to-3D generation. To simulate continuous city evolution, Yo'City further
introduces a user-interactive, relationship-guided expansion mechanism, which
performs scene graph-based distance- and semantics-aware layout optimization,
ensuring spatially coherent city growth. To comprehensively evaluate our
method, we construct a diverse benchmark dataset and design six
multi-dimensional metrics that assess generation quality from the perspectives
of semantics, geometry, texture, and layout. Extensive experiments demonstrate
that Yo'City consistently outperforms existing state-of-the-art methods across
all evaluation aspects.
\\ ( https://arxiv.org/abs/2511.18734 ,  4244kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18735
Date: Mon, 24 Nov 2025 04:04:59 GMT   (17223kb)

Title: Thinking Ahead: Foresight Intelligence in MLLMs and World Models
Authors: Zhantao Gong, Liaoyuan Fan, Qing Guo, Xun Xu, Xulei Yang, Shijie Li
Categories: cs.CV cs.AI
Comments: 25 pages, 27 figures, submitted to CVPR 2026
\\
 In this work, we define Foresight Intelligence as the capability to
anticipate and interpret future events-an ability essential for applications
such as autonomous driving, yet largely overlooked by existing research. To
bridge this gap, we introduce FSU-QA, a new Visual Question-Answering (VQA)
dataset specifically designed to elicit and evaluate Foresight Intelligence.
Using FSU-QA, we conduct the first comprehensive study of state-of-the-art
Vision-Language Models (VLMs) under foresight-oriented tasks, revealing that
current models still struggle to reason about future situations. Beyond serving
as a benchmark, FSU-QA also enables the assessment of world models by measuring
the semantic coherence of their generated predictions, quantified through
performance gains when VLMs are augmented with such outputs. Our experiments
further demonstrate that FSU-QA can effectively enhance foresight reasoning:
even small VLMs fine-tuned on FSU-QA surpass much larger, advanced models by a
substantial margin. Together, these findings position FSU-QA as a principled
foundation for developing next-generation models capable of truly anticipating
and understanding future events.
\\ ( https://arxiv.org/abs/2511.18735 ,  17223kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18742
Date: Mon, 24 Nov 2025 04:10:53 GMT   (20670kb)

Title: ProxT2I: Efficient Reward-Guided Text-to-Image Generation via Proximal
 Diffusion
Authors: Zhenghan Fang, Jian Zheng, Qiaozi Gao, Xiaofeng Gao, Jeremias Sulam
Categories: cs.CV cs.AI cs.LG
\\
 Diffusion models have emerged as a dominant paradigm for generative modeling
across a wide range of domains, including prompt-conditional generation. The
vast majority of samplers, however, rely on forward discretization of the
reverse diffusion process and use score functions that are learned from data.
Such forward and explicit discretizations can be slow and unstable, requiring a
large number of sampling steps to produce good-quality samples. In this work we
develop a text-to-image (T2I) diffusion model based on backward
discretizations, dubbed ProxT2I, relying on learned and conditional proximal
operators instead of score functions. We further leverage recent advances in
reinforcement learning and policy optimization to optimize our samplers for
task-specific rewards. Additionally, we develop a new large-scale and
open-source dataset comprising 15 million high-quality human images with
fine-grained captions, called LAION-Face-T2I-15M, for training and evaluation.
Our approach consistently enhances sampling efficiency and human-preference
alignment compared to score-based baselines, and achieves results on par with
existing state-of-the-art and open-source text-to-image models while requiring
lower compute and smaller model size, offering a lightweight yet performant
solution for human text-to-image generation.
\\ ( https://arxiv.org/abs/2511.18742 ,  20670kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18746
Date: Mon, 24 Nov 2025 04:17:26 GMT   (7513kb)

Title: Any4D: Open-Prompt 4D Generation from Natural Language and Images
Authors: Hao Li, Qiao Sun
Categories: cs.CV cs.AI
\\
 While video-generation-based embodied world models have gained increasing
attention, their reliance on large-scale embodied interaction data remains a
key bottleneck. The scarcity, difficulty of collection, and high dimensionality
of embodied data fundamentally limit the alignment granularity between language
and actions and exacerbate the challenge of long-horizon video
generation--hindering generative models from achieving a \textit{"GPT moment"}
in the embodied domain. There is a naive observation: \textit{the diversity of
embodied data far exceeds the relatively small space of possible primitive
motions}. Based on this insight, we propose \textbf{Primitive Embodied World
Models} (PEWM), which restricts video generation to fixed shorter horizons, our
approach \textit{1) enables} fine-grained alignment between linguistic concepts
and visual representations of robotic actions, \textit{2) reduces} learning
complexity, \textit{3) improves} data efficiency in embodied data collection,
and \textit{4) decreases} inference latency. By equipping with a modular
Vision-Language Model (VLM) planner and a Start-Goal heatmap Guidance mechanism
(SGG), PEWM further enables flexible closed-loop control and supports
compositional generalization of primitive-level policies over extended, complex
tasks. Our framework leverages the spatiotemporal vision priors in video models
and the semantic awareness of VLMs to bridge the gap between fine-grained
physical interaction and high-level reasoning, paving the way toward scalable,
interpretable, and general-purpose embodied intelligence.
\\ ( https://arxiv.org/abs/2511.18746 ,  7513kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18757
Date: Mon, 24 Nov 2025 04:38:57 GMT   (439kb)

Title: From Features to Reference Points: Lightweight and Adaptive Fusion for
 Cooperative Autonomous Driving
Authors: Yongqi Zhu, Morui Zhu, Qi Chen, Deyuan Qu, Song Fu, Qing Yang
Categories: cs.CV
Comments: 10 pages, 4 figures
\\
 We present RefPtsFusion, a lightweight and interpretable framework for
cooperative autonomous driving. Instead of sharing large feature maps or query
embeddings, vehicles exchange compact reference points, e.g., objects'
positions, velocities, and size information. This approach shifts the focus
from "what is seen" to "where to see", creating a sensor- and model-independent
interface that works well across vehicles with heterogeneous perception models
while greatly reducing communication bandwidth. To enhance the richness of
shared information, we further develop a selective Top-K query fusion that
selectively adds high-confidence queries from the sender. It thus achieves a
strong balance between accuracy and communication cost. Experiments on the
M3CAD dataset show that RefPtsFusion maintains stable perception performance
while reducing communication overhead by five orders of magnitude, dropping
from hundreds of MB/s to only a few KB/s at 5 FPS (frame per second), compared
to traditional feature-level fusion methods. Extensive experiments also
demonstrate RefPtsFusion's strong robustness and consistent transmission
behavior, highlighting its potential for scalable, real-time cooperative
driving systems.
\\ ( https://arxiv.org/abs/2511.18757 ,  439kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18763
Date: Mon, 24 Nov 2025 04:56:08 GMT   (928kb)

Title: VAOT: Vessel-Aware Optimal Transport for Retinal Fundus Enhancement
Authors: Xuanzhao Dong, Wenhui Zhu, Yujian Xiong, Xiwen Chen, Hao Wang, Xin Li,
 Jiajun Cheng, Zhipeng Wang, Shao Tang, Oana Dumitrascu, Yalin Wang
Categories: cs.CV
\\
 Color fundus photography (CFP) is central to diagnosing and monitoring
retinal disease, yet its acquisition variability (e.g., illumination changes)
often degrades image quality, which motivates robust enhancement methods.
Unpaired enhancement pipelines are typically GAN-based, however, they can
distort clinically critical vasculature, altering vessel topology and endpoint
integrity. Motivated by these structural alterations, we propose Vessel-Aware
Optimal Transport (\textbf{VAOT}), a framework that combines an
optimal-transport objective with two structure-preserving regularizers: (i) a
skeleton-based loss to maintain global vascular connectivity and (ii) an
endpoint-aware loss to stabilize local termini. These constraints guide
learning in the unpaired setting, reducing noise while preserving vessel
structure. Experimental results on synthetic degradation benchmark and
downstream evaluations in vessel and lesion segmentation demonstrate the
superiority of the proposed methods against several state-of-the art baselines.
The code is available at https://github.com/Retinal-Research/VAOT
\\ ( https://arxiv.org/abs/2511.18763 ,  928kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18765
Date: Mon, 24 Nov 2025 04:57:38 GMT   (18290kb)

Title: NI-Tex: Non-isometric Image-based Garment Texture Generation
Authors: Hui Shan, Ming Li, Haitao Yang, Kai Zheng, Sizhe Zheng, Yanwei Fu,
 Xiangru Huang
Categories: cs.CV
\\
 Existing industrial 3D garment meshes already cover most real-world clothing
geometries, yet their texture diversity remains limited. To acquire more
realistic textures, generative methods are often used to extract
Physically-based Rendering (PBR) textures and materials from large collections
of wild images and project them back onto garment meshes. However, most
image-conditioned texture generation approaches require strict topological
consistency between the input image and the input 3D mesh, or rely on accurate
mesh deformation to match to the image poses, which significantly constrains
the texture generation quality and flexibility. To address the challenging
problem of non-isometric image-based garment texture generation, we construct
3D Garment Videos, a physically simulated, garment-centric dataset that
provides consistent geometry and material supervision across diverse
deformations, enabling robust cross-pose texture learning. We further employ
Nano Banana for high-quality non-isometric image editing, achieving reliable
cross-topology texture generation between non-isometric image-geometry pairs.
Finally, we propose an iterative baking method via uncertainty-guided view
selection and reweighting that fuses multi-view predictions into seamless,
production-ready PBR textures. Through extensive experiments, we demonstrate
that our feedforward dual-branch architecture generates versatile and spatially
aligned PBR materials suitable for industry-level 3D garment design.
\\ ( https://arxiv.org/abs/2511.18765 ,  18290kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18766
Date: Mon, 24 Nov 2025 05:01:16 GMT   (12756kb)

Title: Unsupervised Multi-View Visual Anomaly Detection via Progressive
 Homography-Guided Alignment
Authors: Xintao Chen, Xiaohao Xu, Bozhong Zheng, Yun Liu, Yingna Wu
Categories: cs.CV cs.AI
\\
 Unsupervised visual anomaly detection from multi-view images presents a
significant challenge: distinguishing genuine defects from benign appearance
variations caused by viewpoint changes. Existing methods, often designed for
single-view inputs, treat multiple views as a disconnected set of images,
leading to inconsistent feature representations and a high false-positive rate.
To address this, we introduce ViewSense-AD (VSAD), a novel framework that
learns viewpoint-invariant representations by explicitly modeling geometric
consistency across views. At its core is our Multi-View Alignment Module
(MVAM), which leverages homography to project and align corresponding feature
regions between neighboring views. We integrate MVAM into a View-Align Latent
Diffusion Model (VALDM), enabling progressive and multi-stage alignment during
the denoising process. This allows the model to build a coherent and holistic
understanding of the object's surface from coarse to fine scales. Furthermore,
a lightweight Fusion Refiner Module (FRM) enhances the global consistency of
the aligned features, suppressing noise and improving discriminative power.
Anomaly detection is performed by comparing multi-level features from the
diffusion model against a learned memory bank of normal prototypes. Extensive
experiments on the challenging RealIAD and MANTA datasets demonstrate that VSAD
sets a new state-of-the-art, significantly outperforming existing methods in
pixel, view, and sample-level visual anomaly proving its robustness to large
viewpoint shifts and complex textures.
\\ ( https://arxiv.org/abs/2511.18766 ,  12756kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18775
Date: Mon, 24 Nov 2025 05:19:44 GMT   (35093kb)

Title: Rethinking Garment Conditioning in Diffusion-based Virtual Try-On
Authors: Kihyun Na, Jinyoung Choi, and Injung Kim
Categories: cs.CV cs.AI
Comments: 15 pages (including references and supplementary material), 10
 figures, 7 tables. Code and pretrained models will be released
\\
 Virtual Try-On (VTON) is the task of synthesizing an image of a person
wearing a target garment, conditioned on a person image and a garment image.
While diffusion-based VTON models featuring a Dual UNet architecture
demonstrate superior fidelity compared to single UNet models, they incur
substantial computational and memory overhead due to their heavy structure. In
this study, through visualization analysis and theoretical analysis, we derived
three hypotheses regarding the learning of context features to condition the
denoising process. Based on these hypotheses, we developed Re-CatVTON, an
efficient single UNet model that achieves high performance. We further enhance
the model by introducing a modified classifier-free guidance strategy tailored
for VTON's spatial concatenation conditioning, and by directly injecting the
ground-truth garment latent derived from the clean garment latent to prevent
the accumulation of prediction error. The proposed Re-CatVTON significantly
improves performance compared to its predecessor (CatVTON) and requires less
computation and memory than the high-performance Dual UNet model, Leffa. Our
results demonstrate improved FID, KID, and LPIPS scores, with only a marginal
decrease in SSIM, establishing a new efficiency-performance trade-off for
single UNet VTON models.
\\ ( https://arxiv.org/abs/2511.18775 ,  35093kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18780
Date: Mon, 24 Nov 2025 05:27:05 GMT   (3182kb)

Title: ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation
 through Multimodal Risk Detection
Authors: Ruize Ma, Minghong Cai, Yilei Jiang, Jiaming Han, Yi Feng, Yingshui
 Tan, Xiaoyong Zhu, Bo Zhang, Bo Zheng and Xiangyu Yue
Categories: cs.CV cs.AI
\\
 Recent progress in video generative models has enabled the creation of
high-quality videos from multimodal prompts that combine text and images. While
these systems offer enhanced controllability, they also introduce new safety
risks, as harmful content can emerge from individual modalities or their
interaction. Existing safety methods are often text-only, require prior
knowledge of the risk category, or operate as post-generation auditors,
struggling to proactively mitigate such compositional, multimodal risks. To
address this challenge, we present ConceptGuard, a unified safeguard framework
for proactively detecting and mitigating unsafe semantics in multimodal video
generation. ConceptGuard operates in two stages: First, a contrastive detection
module identifies latent safety risks by projecting fused image-text inputs
into a structured concept space; Second, a semantic suppression mechanism
steers the generative process away from unsafe concepts by intervening in the
prompt's multimodal conditioning. To support the development and rigorous
evaluation of this framework, we introduce two novel benchmarks: ConceptRisk, a
large-scale dataset for training on multimodal risks, and T2VSafetyBench-TI2V,
the first benchmark adapted from T2VSafetyBench for the Text-and-Image-to-Video
(TI2V) safety setting. Comprehensive experiments on both benchmarks show that
ConceptGuard consistently outperforms existing baselines, achieving
state-of-the-art results in both risk detection and safe video generation.
\\ ( https://arxiv.org/abs/2511.18780 ,  3182kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18781
Date: Mon, 24 Nov 2025 05:31:47 GMT   (882kb)

Title: A Novel Dual-Stream Framework for dMRI Tractography Streamline
 Classification with Joint dMRI and fMRI Data
Authors: Haotian Yan, Bocheng Guo, Jianzhong He, Nir A. Sochen, Ofer Pasternak,
 Lauren J O'Donnell, Fan Zhang
Categories: cs.CV cs.AI
Comments: Submitted to ISBI 2026, 7 pages, 2 figures
\\
 Streamline classification is essential to identify anatomically meaningful
white matter tracts from diffusion MRI (dMRI) tractography. However, current
streamline classification methods rely primarily on the geometric features of
the streamline trajectory, failing to distinguish between functionally distinct
fiber tracts with similar pathways. To address this, we introduce a novel
dual-stream streamline classification framework that jointly analyzes dMRI and
functional MRI (fMRI) data to enhance the functional coherence of tract
parcellation. We design a novel network that performs streamline classification
using a pretrained backbone model for full streamline trajectories, while
augmenting with an auxiliary network that processes fMRI signals from fiber
endpoint regions. We demonstrate our method by parcellating the corticospinal
tract (CST) into its four somatotopic subdivisions. Experimental results from
ablation studies and comparisons with state-of-the-art methods demonstrate our
approach's superior performance.
\\ ( https://arxiv.org/abs/2511.18781 ,  882kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18786
Date: Mon, 24 Nov 2025 05:37:23 GMT   (1057kb)

Title: STCDiT: Spatio-Temporally Consistent Diffusion Transformer for
 High-Quality Video Super-Resolution
Authors: Junyang Chen, Jiangxin Dong, Long Sun, Yixin Yang, Jinshan Pan
Categories: cs.CV
Comments: Project page: https://jychen9811.github.io/STCDiT_page
\\
 We present STCDiT, a video super-resolution framework built upon a
pre-trained video diffusion model, aiming to restore structurally faithful and
temporally stable videos from degraded inputs, even under complex camera
motions. The main challenges lie in maintaining temporal stability during
reconstruction and preserving structural fidelity during generation. To address
these challenges, we first develop a motion-aware VAE reconstruction method
that performs segment-wise reconstruction, with each segment clip exhibiting
uniform motion characteristic, thereby effectively handling videos with complex
camera motions. Moreover, we observe that the first-frame latent extracted by
the VAE encoder in each clip, termed the anchor-frame latent, remains
unaffected by temporal compression and retains richer spatial structural
information than subsequent frame latents. We further develop an anchor-frame
guidance approach that leverages structural information from anchor frames to
constrain the generation process and improve structural fidelity of video
features. Coupling these two designs enables the video diffusion model to
achieve high-quality video super-resolution. Extensive experiments show that
STCDiT outperforms state-of-the-art methods in terms of structural fidelity and
temporal consistency.
\\ ( https://arxiv.org/abs/2511.18786 ,  1057kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18787
Date: Mon, 24 Nov 2025 05:37:52 GMT   (2765kb)

Title: Understanding Task Transfer in Vision-Language Models
Authors: Bhuvan Sachdeva, Karan Uppal, Abhinav Java, Vineeth N. Balasubramanian
Categories: cs.CV cs.LG
\\
 Vision-Language Models (VLMs) perform well on multimodal benchmarks but lag
behind humans and specialized models on visual perception tasks like depth
estimation or object counting. Finetuning on one task can unpredictably affect
performance on others, making task-specific finetuning challenging. In this
paper, we address this challenge through a systematic study of task
transferability. We examine how finetuning a VLM on one perception task affects
its zero-shot performance on others. To quantify these effects, we introduce
Perfection Gap Factor (PGF), a metric that captures both the breadth and
magnitude of transfer. Using three open-weight VLMs evaluated across 13
perception tasks, we construct a task-transfer graph that reveals previously
unobserved relationships among perception tasks. Our analysis uncovers patterns
of positive and negative transfer, identifies groups of tasks that mutually
influence each other, organizes tasks into personas based on their transfer
behavior and demonstrates how PGF can guide data selection for more efficient
training. These findings highlight both opportunities for positive transfer and
risks of negative interference, offering actionable guidance for advancing
VLMs.
\\ ( https://arxiv.org/abs/2511.18787 ,  2765kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18788
Date: Mon, 24 Nov 2025 05:38:31 GMT   (16096kb)

Title: StereoDETR: Stereo-based Transformer for 3D Object Detection
Authors: Shiyi Mu, Zichong Gu, Zhiqi Ai, Anqi Liu, Yilin Gao and Shugong Xu
Categories: cs.CV
Comments: Accepted by IEEE TCSVT, 2025
\\
 Compared to monocular 3D object detection, stereo-based 3D methods offer
significantly higher accuracy but still suffer from high computational overhead
and latency. The state-of-the-art stereo 3D detection method achieves twice the
accuracy of monocular approaches, yet its inference speed is only half as fast.
In this paper, we propose StereoDETR, an efficient stereo 3D object detection
framework based on DETR. StereoDETR consists of two branches: a monocular DETR
branch and a stereo branch. The DETR branch is built upon 2D DETR with
additional channels for predicting object scale, orientation, and sampling
points. The stereo branch leverages low-cost multi-scale disparity features to
predict object-level depth maps. These two branches are coupled solely through
a differentiable depth sampling strategy. To handle occlusion, we introduce a
constrained supervision strategy for sampling points without requiring extra
annotations. StereoDETR achieves real-time inference and is the first
stereo-based method to surpass monocular approaches in speed. It also achieves
competitive accuracy on the public KITTI benchmark, setting new
state-of-the-art results on pedestrian and cyclist subsets. The code is
available at https://github.com/shiyi-mu/StereoDETR-OPEN.
\\ ( https://arxiv.org/abs/2511.18788 ,  16096kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18792
Date: Mon, 24 Nov 2025 05:46:29 GMT   (5388kb)

Title: Scale What Counts, Mask What Matters: Evaluating Foundation Models for
 Zero-Shot Cross-Domain Wi-Fi Sensing
Authors: Cheng Jiang, Yihe Yan, Yanxiang Wang, Chun Tung Chou, Wen Hu
Categories: cs.CV cs.IT math.IT
\\
 While Wi-Fi sensing offers a compelling, privacy-preserving alternative to
cameras, its practical utility has been fundamentally undermined by a lack of
robustness across domains. Models trained in one setup fail to generalize to
new environments, hardware, or users, a critical "domain shift" problem
exacerbated by modest, fragmented public datasets. We shift from this limited
paradigm and apply a foundation model approach, leveraging Masked Autoencoding
(MAE) style pretraining on the largest and most heterogeneous Wi-Fi CSI
datasets collection assembled to date. Our study pretrains and evaluates models
on over 1.3 million samples extracted from 14 datasets, collected using 4
distinct devices across the 2.4/5/6 GHz bands and bandwidths from 20 to 160
MHz. Our large-scale evaluation is the first to systematically disentangle the
impacts of data diversity versus model capacity on cross-domain performance.
The results establish scaling trends on Wi-Fi CSI sensing. First, our
experiments show log-linear improvements in unseen domain performance as the
amount of pretraining data increases, suggesting that data scale and diversity
are key to domain generalization. Second, based on the current data volume,
larger model can only provide marginal gains for cross-domain performance,
indicating that data, rather than model capacity, is the current bottleneck for
Wi-Fi sensing generalization. Finally, we conduct a series of cross-domain
evaluations on human activity recognition, human gesture recognition and user
identification tasks. The results show that the large-scale pretraining
improves cross-domain accuracy ranging from 2.2% to 15.7%, compared to the
supervised learning baseline. Overall, our findings provide insightful
direction for designing future Wi-Fi sensing systems that can eventually be
robust enough for real-world deployment.
\\ ( https://arxiv.org/abs/2511.18792 ,  5388kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18801
Date: Mon, 24 Nov 2025 06:11:21 GMT   (3130kb)

Title: PartDiffuser: Part-wise 3D Mesh Generation via Discrete Diffusion
Authors: Yichen Yang, Hong Li, Haodong Zhu, Linin Yang, Guojun Lei, Sheng Xu,
 Baochang Zhang
Categories: cs.CV
\\
 Existing autoregressive (AR) methods for generating artist-designed meshes
struggle to balance global structural consistency with high-fidelity local
details, and are susceptible to error accumulation. To address this, we propose
PartDiffuser, a novel semi-autoregressive diffusion framework for
point-cloud-to-mesh generation. The method first performs semantic segmentation
on the mesh and then operates in a "part-wise" manner: it employs
autoregression between parts to ensure global topology, while utilizing a
parallel discrete diffusion process within each semantic part to precisely
reconstruct high-frequency geometric features. PartDiffuser is based on the DiT
architecture and introduces a part-aware cross-attention mechanism, using point
clouds as hierarchical geometric conditioning to dynamically control the
generation process, thereby effectively decoupling the global and local
generation tasks. Experiments demonstrate that this method significantly
outperforms state-of-the-art (SOTA) models in generating 3D meshes with rich
detail, exhibiting exceptional detail representation suitable for real-world
applications.
\\ ( https://arxiv.org/abs/2511.18801 ,  3130kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18806
Date: Mon, 24 Nov 2025 06:21:52 GMT   (1200kb)

Title: TPG-INR: Target Prior-Guided Implicit 3D CT Reconstruction for Enhanced
 Sparse-view Imaging
Authors: Qinglei Cao, Ziyao Tang, Xiaoqin Tang
Categories: cs.CV
Comments: Please consider this version as the latest camera-ready version
\\
 X-ray imaging, based on penetration, enables detailed visualization of
internal structures. Building on this capability, existing implicit 3D
reconstruction methods have adapted the NeRF model and its variants for
internal CT reconstruction. However, these approaches often neglect the
significance of objects' anatomical priors for implicit learning, limiting both
reconstruction precision and learning efficiency, particularly in ultra-sparse
view scenarios. To address these challenges, we propose a novel 3D CT
reconstruction framework that employs a 'target prior' derived from the
object's projection data to enhance implicit learning. Our approach integrates
positional and structural encoding to facilitate voxel-wise implicit
reconstruction, utilizing the target prior to guide voxel sampling and enrich
structural encoding. This dual strategy significantly boosts both learning
efficiency and reconstruction quality. Additionally, we introduce a CUDA-based
algorithm for rapid estimation of high-quality 3D target priors from
sparse-view projections. Experiments utilizing projection data from a complex
abdominal dataset demonstrate that the proposed model substantially enhances
learning efficiency, outperforming the current leading model, NAF, by a factor
of ten. In terms of reconstruction quality, it also exceeds the most accurate
model, NeRP, achieving PSNR improvements of 3.57 dB, 5.42 dB, and 5.70 dB with
10, 20, and 30 projections, respectively. The code is available at
https://github.com/qlcao171/TPG-INR.
\\ ( https://arxiv.org/abs/2511.18806 ,  1200kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18811
Date: Mon, 24 Nov 2025 06:30:08 GMT   (3228kb)

Title: Mitigating Long-Tail Bias in HOI Detection via Adaptive Diversity Cache
Authors: Yuqiu Jiang, Xiaozhen Qiao, Tianyu Mei, Haojian Huang, Yifan Chen, Ye
 Zheng, Zhe Sun
Categories: cs.CV cs.AI
\\
 Human-Object Interaction (HOI) detection is a fundamental task in computer
vision, empowering machines to comprehend human-object relationships in diverse
real-world scenarios. Recent advances in VLMs have significantly improved HOI
detection by leveraging rich cross-modal representations. However, most
existing VLM-based approaches rely heavily on additional training or prompt
tuning, resulting in substantial computational overhead and limited
scalability, particularly in long-tailed scenarios where rare interactions are
severely underrepresented. In this paper, we propose the Adaptive Diversity
Cache (ADC) module, a novel training-free and plug-and-play mechanism designed
to mitigate long-tail bias in HOI detection. ADC constructs class-specific
caches that accumulate high-confidence and diverse feature representations
during inference. The method incorporates frequency-aware cache adaptation that
favors rare categories and is designed to enable robust prediction calibration
without requiring additional training or fine-tuning. Extensive experiments on
HICO-DET and V-COCO datasets show that ADC consistently improves existing HOI
detectors, achieving up to +8.57\% mAP gain on rare categories and +4.39\% on
the full dataset, demonstrating its effectiveness in mitigating long-tail bias
while preserving overall performance.
\\ ( https://arxiv.org/abs/2511.18811 ,  3228kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18814
Date: Mon, 24 Nov 2025 06:42:17 GMT   (5858kb)

Title: DetAny4D: Detect Anything 4D Temporally in a Streaming RGB Video
Authors: Jiawei Hou, Shenghao Zhang, Can Wang, Zheng Gu, Yonggen Ling, Taiping
 Zeng, Xiangyang Xue, Jingbo Zhang
Categories: cs.CV
\\
 Reliable 4D object detection, which refers to 3D object detection in
streaming video, is crucial for perceiving and understanding the real world.
Existing open-set 4D object detection methods typically make predictions on a
frame-by-frame basis without modeling temporal consistency, or rely on complex
multi-stage pipelines that are prone to error propagation across cascaded
stages. Progress in this area has been hindered by the lack of large-scale
datasets that capture continuous reliable 3D bounding box (b-box) annotations.
To overcome these challenges, we first introduce DA4D, a large-scale 4D
detection dataset containing over 280k sequences with high-quality b-box
annotations collected under diverse conditions. Building on DA4D, we propose
DetAny4D, an open-set end-to-end framework that predicts 3D b-boxes directly
from sequential inputs. DetAny4D fuses multi-modal features from pre-trained
foundational models and designs a geometry-aware spatiotemporal decoder to
effectively capture both spatial and temporal dynamics. Furthermore, it adopts
a multi-task learning architecture coupled with a dedicated training strategy
to maintain global consistency across sequences of varying lengths. Extensive
experiments show that DetAny4D achieves competitive detection accuracy and
significantly improves temporal stability, effectively addressing long-standing
issues of jitter and inconsistency in 4D object detection. Data and code will
be released upon acceptance.
\\ ( https://arxiv.org/abs/2511.18814 ,  5858kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18816
Date: Mon, 24 Nov 2025 06:49:54 GMT   (49172kb)

Title: SupLID: Geometrical Guidance for Out-of-Distribution Detection in
 Semantic Segmentation
Authors: Nimeshika Udayangani, Sarah Erfani, Christopher Leckie
Categories: cs.CV
Comments: 10 pages, CIKM 2025
ACM-class: I.2.6; I.4.6
Journal-ref: In Proceedings of the 34th ACM International Conference on
 Information and Knowledge Management (CIKM 2025), pages 2905-2914, 2025
DOI: 10.1145/3746252.3761064
\\
 Out-of-Distribution (OOD) detection in semantic segmentation aims to localize
anomalous regions at the pixel level, advancing beyond traditional image-level
OOD techniques to better suit real-world applications such as autonomous
driving. Recent literature has successfully explored the adaptation of commonly
used image-level OOD methods--primarily based on classifier-derived confidence
scores (e.g., energy or entropy)--for this pixel-precise task. However, these
methods inherit a set of limitations, including vulnerability to
overconfidence. In this work, we introduce SupLID, a novel framework that
effectively guides classifier-derived OOD scores by exploiting the geometrical
structure of the underlying semantic space, particularly using Linear Intrinsic
Dimensionality (LID). While LID effectively characterizes the local structure
of high-dimensional data by analyzing distance distributions, its direct
application at the pixel level remains challenging. To overcome this, SupLID
constructs a geometrical coreset that captures the intrinsic structure of the
in-distribution (ID) subspace. It then computes OOD scores at the superpixel
level, enabling both efficient real-time inference and improved spatial
smoothness. We demonstrate that geometrical cues derived from SupLID serve as a
complementary signal to traditional classifier confidence, enhancing the
model's ability to detect diverse OOD scenarios. Designed as a post-hoc scoring
method, SupLID can be seamlessly integrated with any semantic segmentation
classifier at deployment time. Our results demonstrate that SupLID
significantly enhances existing classifier-based OOD scores, achieving
state-of-the-art performance across key evaluation metrics, including AUR, FPR,
and AUP. Code is available at https://github.com/hdnugit/SupLID.
\\ ( https://arxiv.org/abs/2511.18816 ,  49172kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18817
Date: Mon, 24 Nov 2025 06:51:34 GMT   (23868kb)

Title: Disc3D: Automatic Curation of High-Quality 3D Dialog Data via
 Discriminative Object Referring
Authors: Siyuan Wei, Chunjie Wang, Xiao Liu, Xiaosheng Yan, Zhishan Zhou, Rui
 Huang
Categories: cs.CV
Comments: 8 pages
\\
 3D Multi-modal Large Language Models (MLLMs) still lag behind their 2D peers,
largely because large-scale, high-quality 3D scene-dialogue datasets remain
scarce. Prior efforts hinge on expensive human annotation and leave two key
ambiguities unresolved: viewpoint ambiguity, where spatial language presumes
unknown camera poses, and object referring ambiguity, where non-exclusive
descriptions blur the line between targets and distractors. We therefore
present a fully automated pipeline that converts raw 3D scans into unambiguous,
high-quality dialogue data at a fraction of the previous cost. By synergizing
rule-based constraints with 2D MLLMs and LLMs, the pipeline enables
controllable, scalable generation without human intervention. The pipeline
comprises four stages: (1) meta-annotation collection harvesting object-,
frame-, and scene-level captions, (2) scene graph construction with relation
correction to capture proximal object relations, (3) discriminative object
referring that generates exclusive and compact descriptions, and (4) multi-task
data generation synthesizing diverse dialogues. Our pipeline systematically
mitigates inherent flaws in source datasets and produces the final Disc3D
dataset, over 2 million samples in 25K hybrid 3D scenes, spanning scene, view,
and object captioning, visual grounding, and five object-centric QA tasks.
Extensive experiments demonstrate that training with Disc3D yields consistent,
significant improvements on both public benchmarks and our multifaceted
Disc3D-QA tasks. Code, data, and models will be publicly available.
\\ ( https://arxiv.org/abs/2511.18817 ,  23868kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18822
Date: Mon, 24 Nov 2025 06:55:49 GMT   (14712kb)

Title: DiP: Taming Diffusion Models in Pixel Space
Authors: Zhennan Chen, Junwei Zhu, Xu Chen, Jiangning Zhang, Xiaobin Hu,
 Hanzhen Zhao, Chengjie Wang, Jian Yang, Ying Tai
Categories: cs.CV
\\
 Diffusion models face a fundamental trade-off between generation quality and
computational efficiency. Latent Diffusion Models (LDMs) offer an efficient
solution but suffer from potential information loss and non-end-to-end
training. In contrast, existing pixel space models bypass VAEs but are
computationally prohibitive for high-resolution synthesis. To resolve this
dilemma, we propose DiP, an efficient pixel space diffusion framework. DiP
decouples generation into a global and a local stage: a Diffusion Transformer
(DiT) backbone operates on large patches for efficient global structure
construction, while a co-trained lightweight Patch Detailer Head leverages
contextual features to restore fine-grained local details. This synergistic
design achieves computational efficiency comparable to LDMs without relying on
a VAE. DiP is accomplished with up to 10$\times$ faster inference speeds than
previous method while increasing the total number of parameters by only 0.3%,
and achieves an 1.90 FID score on ImageNet 256$\times$256.
\\ ( https://arxiv.org/abs/2511.18822 ,  14712kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18823
Date: Mon, 24 Nov 2025 06:57:26 GMT   (4021kb)

Title: VideoPerceiver: Enhancing Fine-Grained Temporal Perception in Video
 Multimodal Large Language Models
Authors: Fufangchen Zhao, Liao Zhang, Daiqi Shi, Yuanjun Gao, Chen Ye, Yang
 Cai, Jian Gao, Danfeng Yan
Categories: cs.CV
\\
 We propose VideoPerceiver, a novel video multimodal large language model
(VMLLM) that enhances fine-grained perception in video understanding,
addressing VMLLMs' limited ability to reason about brief actions in short clips
or rare transient events in long videos. VideoPerceiver adopts a two-stage
training framework. During supervised fine-tuning (SFT), we construct
"key-information-missing" videos by extracting event-action keywords from
captions, identifying corresponding key frames, and replacing them with
adjacent frames. We jointly encode original and modified video tokens with text
tokens, aligning intermediate visual representations with keywords via an
auxiliary contrastive loss to enhance sensitivity to fine-grained motion cues.
In reinforcement learning (RL), both video variants are fed into the model to
generate descriptions, and a novel relative reward ensures responses from
complete videos outperform those from degraded inputs, explicitly training the
model to recover temporally precise action details. We also curate a dataset of
80,000 videos with fine-grained actions and transient events. Experiments show
VideoPerceiver substantially outperforms state-of-the-art VMLLMs on
fine-grained action understanding and rare event captioning benchmarks, while
maintaining strong performance on standard tasks. By prioritizing task-relevant
visual features, our work redefines video-language model training for
fine-grained perception.
\\ ( https://arxiv.org/abs/2511.18823 ,  4021kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18824
Date: Mon, 24 Nov 2025 06:58:16 GMT   (27055kb)

Title: Assessing the alignment between infants' visual and linguistic
 experience using multimodal language models
Authors: Alvin Wei Ming Tan, Jane Yang, Tarun Sepuri, Khai Loong Aw, Robert Z.
 Sparks, Zi Yin, Virginia A. Marchman, Michael C. Frank, Bria Long
Categories: cs.CV cs.CL
\\
 Figuring out which objects or concepts words refer to is a central language
learning challenge for young children. Most models of this process posit that
children learn early object labels from co-occurrences of words and their
referents that occur when someone around them talks about an object in the
immediate physical environment. But how aligned in time are children's visual
and linguistic experiences during everyday learning? To date, answers to this
question have been limited by the need for labor-intensive manual annotations
of vision-language co-occurrences. Here, we evaluate the use of contrastive
language-image pretraining (CLIP) models to automatically characterize
vision-language alignment in egocentric videos taken from the infant
perspective in home environments. After validating CLIP alignment scores using
human alignment judgments, we apply this metric to a large corpus of
infant-perspective videos. We show that idealized aligned moments for learning
(e.g., "look at the ball" with a ball present in the child's view) are
relatively rare in children's everyday experiences compared to modern machine
learning datasets, and highlight variability in alignment both within and
across children. These findings suggest that infrequent alignment is a
constraint for models describing early word learning and offer a new method for
investigating children's multimodal environment.
\\ ( https://arxiv.org/abs/2511.18824 ,  27055kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18825
Date: Mon, 24 Nov 2025 07:00:21 GMT   (2654kb)

Title: Q-Save: Towards Scoring and Attribution for Generated Video Evaluation
Authors: Xiele Wu, Zicheng Zhang, Mingtao Chen, Yixian Liu, Yiming Liu, Shushi
 Wang, Zhichao Hu, Yuhong Liu, Guangtao Zhai, Xiaohong Liu
Categories: cs.CV
Comments: 20 pages, 11 figures
\\
 We present Q-Save, a new benchmark dataset and model for holistic and
explainable evaluation of AI-generated video (AIGV) quality. The dataset
contains near 10000 videos, each annotated with a scalar mean opinion score
(MOS) and fine-grained attribution labels along three core dimensions: visual
quality, dynamic quality, and text-video alignment. These multi-aspect
annotations enable both accurate quality assessment and interpretable reasoning
behind the scores. To leverage this data, we propose a unified evaluation model
that jointly performs quality scoring and attribution-based explanation. The
model adopts the SlowFast framework to distinguish between fast frames and slow
frames - slow frames are processed with high resolution while fast frames use
low resolution, balancing evaluation accuracy and computational efficiency. For
training, we use data formatted in Chain-of-Thought (COT) style and employ a
multi-stage strategy: we first conduct Supervised Fine-Tuning (SFT), then
further enhance the model with Grouped Relative Policy Optimization (GRPO), and
finally perform SFT again to improve model stability. Experimental results
demonstrate that our model achieves state-of-the-art performance in video
quality prediction while also providing human-aligned, interpretable
justifications. Our dataset and model establish a strong foundation for
explainable evaluation in generative video research, contributing to the
development of multimodal generation and trustworthy AI. Code and dataset will
be released upon publication.
\\ ( https://arxiv.org/abs/2511.18825 ,  2654kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18826
Date: Mon, 24 Nov 2025 07:02:22 GMT   (177kb)

Title: Uncertainty-Aware Dual-Student Knowledge Distillation for Efficient
 Image Classification
Authors: Aakash Gore, Anoushka Dey, Aryan Mishra
Categories: cs.CV cs.LG
\\
 Knowledge distillation has emerged as a powerful technique for model
compression, enabling the transfer of knowledge from large teacher networks to
compact student models. However, traditional knowledge distillation methods
treat all teacher predictions equally, regardless of the teacher's confidence
in those predictions. This paper proposes an uncertainty-aware dual-student
knowledge distillation framework that leverages teacher prediction uncertainty
to selectively guide student learning. We introduce a peer-learning mechanism
where two heterogeneous student architectures, specifically ResNet-18 and
MobileNetV2, learn collaboratively from both the teacher network and each
other. Experimental results on ImageNet-100 demonstrate that our approach
achieves superior performance compared to baseline knowledge distillation
methods, with ResNet-18 achieving 83.84\% top-1 accuracy and MobileNetV2
achieving 81.46\% top-1 accuracy, representing improvements of 2.04\% and
0.92\% respectively over traditional single-student distillation approaches.
\\ ( https://arxiv.org/abs/2511.18826 ,  177kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18827
Date: Mon, 24 Nov 2025 07:03:15 GMT   (535kb)

Title: Leveraging Metaheuristic Approaches to Improve Deep Learning Systems for
 Anxiety Disorder Detection
Authors: Mohammadreza Amiri, Monireh Hosseini
Categories: cs.CV
Comments: 12 pages
MSC-class: 92C50 Medical Applications in Biology / Mental Health Modeling
\\
 Despite being among the most common psychological disorders, anxiety-related
conditions are still primarily identified through subjective assessments, such
as clinical interviews and self-evaluation questionnaires. These conventional
methods often require significant time and may vary depending on the evaluator.
However, the emergence of advanced artificial intelligence techniques has
created new opportunities for detecting anxiety in a more consistent and
automated manner. To address the limitations of traditional approaches, this
study introduces a comprehensive model that integrates deep learning
architectures with optimization strategies inspired by swarm intelligence.
Using multimodal and wearable-sensor datasets, the framework analyzes
physiological, emotional, and behavioral signals. Swarm intelligence techniques
including genetic algorithms and particle swarm optimization are incorporated
to refine the feature space and optimize hyperparameters. Meanwhile, deep
learning components are tasked with deriving layered and discriminative
representations from sequential, multi-source inputs. Our evaluation shows that
the fusion of these two computational paradigms significantly enhances
detection performance compared with using deep networks alone. The hybrid model
achieves notable improvements in accuracy and demonstrates stronger
generalization across various individuals. Overall, the results highlight the
potential of combining metaheuristic optimization with deep learning to develop
scalable, objective, and clinically meaningful solutions for assessing anxiety
disorders
\\ ( https://arxiv.org/abs/2511.18827 ,  535kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18831
Date: Mon, 24 Nov 2025 07:07:58 GMT   (5309kb)

Title: VideoCompressa: Data-Efficient Video Understanding via Joint Temporal
 Compression and Spatial Reconstruction
Authors: Shaobo Wang, Tianle Niu, Runkang Yang, Deshan Liu, Xu He, Zichen Wen,
 Conghui He, Xuming Hu, Linfeng Zhang
Categories: cs.CV
Comments: 15 pages, 6 tables, 8 figures
\\
 The scalability of video understanding models is increasingly limited by the
prohibitive storage and computational costs of large-scale video datasets.
While data synthesis has improved data efficiency in the image domain, its
extension to video remains challenging due to pervasive temporal redundancy and
complex spatiotemporal dynamics. In this work, we uncover a critical insight:
the primary source of inefficiency in video datasets is not inter-sample
redundancy, but intra-sample frame-level redundancy. To leverage this insight,
we introduce VideoCompressa, a novel framework for video data synthesis that
reframes the problem as dynamic latent compression. Specifically,
VideoCompressa jointly optimizes a differentiable keyframe selector-implemented
as a lightweight ConvNet with Gumbel-Softmax sampling-to identify the most
informative frames, and a pretrained, frozen Variational Autoencoder (VAE) to
compress these frames into compact, semantically rich latent codes. These
latent representations are then fed into a compression network, enabling
end-to-end backpropagation. Crucially, the keyframe selector and synthetic
latent codes are co-optimized to maximize retention of task-relevant
information. Experiments show that our method achieves unprecedented data
efficiency: on UCF101 with ConvNets, VideoCompressa surpasses full-data
training by 2.34\% points using only 0.13\% of the original data, with over
5800x speedup compared to traditional synthesis method. Moreover, when
fine-tuning Qwen2.5-7B-VL on HMDB51, VideoCompressa matches full-data
performance using just 0.41\% of the training data-outperforming zero-shot
baseline by 10.61\%.
\\ ( https://arxiv.org/abs/2511.18831 ,  5309kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18834
Date: Mon, 24 Nov 2025 07:13:23 GMT   (7447kb)

Title: FlowSteer: Guiding Few-Step Image Synthesis with Authentic Trajectories
Authors: Lei Ke, Hubery Yin, Gongye Liu, Zhengyao Lv, Jingcai Guo, Chen Li,
 Wenhan Luo, Yujiu Yang, Jing Lyu
Categories: cs.CV cs.AI
Comments: Few-Step Image Synthesis
\\
 With the success of flow matching in visual generation, sampling efficiency
remains a critical bottleneck for its practical application. Among flow models'
accelerating methods, ReFlow has been somehow overlooked although it has
theoretical consistency with flow matching. This is primarily due to its
suboptimal performance in practical scenarios compared to consistency
distillation and score distillation. In this work, we investigate this issue
within the ReFlow framework and propose FlowSteer, a method unlocks the
potential of ReFlow-based distillation by guiding the student along teacher's
authentic generation trajectories. We first identify that Piecewised ReFlow's
performance is hampered by a critical distribution mismatch during the training
and propose Online Trajectory Alignment(OTA) to resolve it. Then, we introduce
a adversarial distillation objective applied directly on the ODE trajectory,
improving the student's adherence to the teacher's generation trajectory.
Furthermore, we find and fix a previously undiscovered flaw in the widely-used
FlowMatchEulerDiscreteScheduler that largely degrades few-step inference
quality. Our experiment result on SD3 demonstrates our method's efficacy.
\\ ( https://arxiv.org/abs/2511.18834 ,  7447kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18838
Date: Mon, 24 Nov 2025 07:19:04 GMT   (11398kb)

Title: FVAR: Visual Autoregressive Modeling via Next Focus Prediction
Authors: Xiaofan Li, Chenming Wu, Yanpeng Sun, Jiaming Zhou, Delin Qu, Yansong
 Qu, Weihao Bo, Haibao Yu, Dingkang Liang
Categories: cs.CV
Comments: 10 pages, 4 figures
\\
 Visual autoregressive models achieve remarkable generation quality through
next-scale predictions across multi-scale token pyramids. However, the
conventional method uses uniform scale downsampling to build these pyramids,
leading to aliasing artifacts that compromise fine details and introduce
unwanted jaggies and moir\'e patterns. To tackle this issue, we present
\textbf{FVAR}, which reframes the paradigm from \emph{next-scale prediction} to
\emph{next-focus prediction}, mimicking the natural process of camera focusing
from blur to clarity. Our approach introduces three key innovations: \textbf{1)
Next-Focus Prediction Paradigm} that transforms multi-scale autoregression by
progressively reducing blur rather than simply downsampling; \textbf{2)
Progressive Refocusing Pyramid Construction} that uses physics-consistent
defocus kernels to build clean, alias-free multi-scale representations; and
\textbf{3) High-Frequency Residual Learning} that employs a specialized
residual teacher network to effectively incorporate alias information during
training while maintaining deployment simplicity. Specifically, we construct
optical low-pass views using defocus point spread function (PSF) kernels with
decreasing radius, creating smooth blur-to-clarity transitions that eliminate
aliasing at its source. To further enhance detail generation, we introduce a
High-Frequency Residual Teacher that learns from both clean structure and alias
residuals, distilling this knowledge to a vanilla VAR deployment network for
seamless inference. Extensive experiments on ImageNet demonstrate that FVAR
substantially reduces aliasing artifacts, improves fine detail preservation,
and enhances text readability, achieving superior performance with perfect
compatibility to existing VAR frameworks.
\\ ( https://arxiv.org/abs/2511.18838 ,  11398kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18839
Date: Mon, 24 Nov 2025 07:20:40 GMT   (1012kb)

Title: Enhancing Multi-Label Thoracic Disease Diagnosis with Deep
 Ensemble-Based Uncertainty Quantification
Authors: Yasiru Laksara, Uthayasanker Thayasivam
Categories: cs.CV cs.LG
\\
 The utility of deep learning models, such as CheXNet, in high stakes clinical
settings is fundamentally constrained by their purely deterministic nature,
failing to provide reliable measures of predictive confidence. This project
addresses this critical gap by integrating robust Uncertainty Quantification
(UQ) into a high performance diagnostic platform for 14 common thoracic
diseases on the NIH ChestX-ray14 dataset. Initial architectural development
failed to stabilize performance and calibration using Monte Carlo Dropout
(MCD), yielding an unacceptable Expected Calibration Error (ECE) of 0.7588.
This technical failure necessitated a rigorous architectural pivot to a high
diversity, 9-member Deep Ensemble (DE). This resulting DE successfully
stabilized performance and delivered superior reliability, achieving a
State-of-the-Art (SOTA) average Area Under the Receiver Operating
Characteristic Curve (AUROC) of 0.8559 and an average F1 Score of 0.3857.
Crucially, the DE demonstrated superior calibration (Mean ECE of 0.0728 and
Negative Log-Likelihood (NLL) of 0.1916) and enabled the reliable decomposition
of total uncertainty into its Aleatoric (irreducible data noise) and Epistemic
(reducible model knowledge) components, with a mean Epistemic Uncertainty (EU)
of 0.0240. These results establish the Deep Ensemble as a trustworthy and
explainable platform, transforming the model from a probabilistic tool into a
reliable clinical decision support system.
\\ ( https://arxiv.org/abs/2511.18839 ,  1012kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18847
Date: Mon, 24 Nov 2025 07:40:04 GMT   (361kb)

Title: Personalized Federated Segmentation with Shared Feature Aggregation and
 Boundary-Focused Calibration
Authors: Ishmam Tashdeed, Md. Atiqur Rahman, Sabrina Islam, Md. Azam Hossain
Categories: cs.CV cs.AI
\\
 Personalized federated learning (PFL) possesses the unique capability of
preserving data confidentiality among clients while tackling the data
heterogeneity problem of non-independent and identically distributed (Non-IID)
data. Its advantages have led to widespread adoption in domains such as medical
image segmentation. However, the existing approaches mostly overlook the
potential benefits of leveraging shared features across clients, where each
client contains segmentation data of different organs. In this work, we
introduce a novel personalized federated approach for organ agnostic tumor
segmentation (FedOAP), that utilizes cross-attention to model long-range
dependencies among the shared features of different clients and a
boundary-aware loss to improve segmentation consistency. FedOAP employs a
decoupled cross-attention (DCA), which enables each client to retain local
queries while attending to globally shared key-value pairs aggregated from all
clients, thereby capturing long-range inter-organ feature dependencies.
Additionally, we introduce perturbed boundary loss (PBL) which focuses on the
inconsistencies of the predicted mask's boundary for each client, forcing the
model to localize the margins more precisely. We evaluate FedOAP on diverse
tumor segmentation tasks spanning different organs. Extensive experiments
demonstrate that FedOAP consistently outperforms existing state-of-the-art
federated and personalized segmentation methods.
\\ ( https://arxiv.org/abs/2511.18847 ,  361kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18851
Date: Mon, 24 Nov 2025 07:46:58 GMT   (4197kb)

Title: Robust Long-term Test-Time Adaptation for 3D Human Pose Estimation
 through Motion Discretization
Authors: Yilin Wen, Kechuan Dong, Yusuke Sugano
Categories: cs.CV
Comments: Accepted by AAAI 2026, main track
\\
 Online test-time adaptation addresses the train-test domain gap by adapting
the model on unlabeled streaming test inputs before making the final
prediction. However, online adaptation for 3D human pose estimation suffers
from error accumulation when relying on self-supervision with imperfect
predictions, leading to degraded performance over time. To mitigate this
fundamental challenge, we propose a novel solution that highlights the use of
motion discretization. Specifically, we employ unsupervised clustering in the
latent motion representation space to derive a set of anchor motions, whose
regularity aids in supervising the human pose estimator and enables efficient
self-replay. Additionally, we introduce an effective and efficient soft-reset
mechanism by reverting the pose estimator to its exponential moving average
during continuous adaptation. We examine long-term online adaptation by
continuously adapting to out-of-domain streaming test videos of the same
individual, which allows for the capture of consistent personal shape and
motion traits throughout the streaming observation. By mitigating error
accumulation, our solution enables robust exploitation of these personal traits
for enhanced accuracy. Experiments demonstrate that our solution outperforms
previous online test-time adaptation methods and validate our design choices.
\\ ( https://arxiv.org/abs/2511.18851 ,  4197kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18856
Date: Mon, 24 Nov 2025 07:52:06 GMT   (1891kb)

Title: Deep Hybrid Model for Region of Interest Detection in Omnidirectional
 Videos
Authors: Sana Alamgeer
Categories: cs.CV cs.AI
\\
 The main goal of the project is to design a new model that predicts regions
of interest in 360$^{\circ}$ videos. The region of interest (ROI) plays an
important role in 360$^{\circ}$ video streaming. For example, ROIs are used to
predict view-ports, intelligently cut the videos for live streaming, etc so
that less bandwidth is used. Detecting view-ports in advance helps reduce the
movement of the head while streaming and watching a video via the head-mounted
device. Whereas, intelligent cuts of the videos help improve the efficiency of
streaming the video to users and enhance the quality of their viewing
experience. This report illustrates the secondary task to identify ROIs, in
which, we design, train, and test a hybrid saliency model. In this work, we
refer to saliency regions to represent the regions of interest. The method
includes the processes as follows: preprocessing the video to obtain frames,
developing a hybrid saliency model for predicting the region of interest, and
finally post-processing the output predictions of the hybrid saliency model to
obtain the output region of interest for each frame. Then, we compare the
performance of the proposed method with the subjective annotations of the
360RAT dataset.
\\ ( https://arxiv.org/abs/2511.18856 ,  1891kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18858
Date: Mon, 24 Nov 2025 07:57:01 GMT   (603kb)

Title: Rethinking Long-tailed Dataset Distillation: A Uni-Level Framework with
 Unbiased Recovery and Relabeling
Authors: Xiao Cui, Yulei Qin, Xinyue Li, Wengang Zhou, Hongsheng Li, Houqiang
 Li
Categories: cs.CV
Comments: AAAI 2026 (Oral)
\\
 Dataset distillation creates a small distilled set that enables efficient
training by capturing key information from the full dataset. While existing
dataset distillation methods perform well on balanced datasets, they struggle
under long-tailed distributions, where imbalanced class frequencies induce
biased model representations and corrupt statistical estimates such as Batch
Normalization (BN) statistics. In this paper, we rethink long-tailed dataset
distillation by revisiting the limitations of trajectory-based methods, and
instead adopt the statistical alignment perspective to jointly mitigate model
bias and restore fair supervision. To this end, we introduce three dedicated
components that enable unbiased recovery of distilled images and soft
relabeling: (1) enhancing expert models (an observer model for recovery and a
teacher model for relabeling) to enable reliable statistics estimation and
soft-label generation; (2) recalibrating BN statistics via a full forward pass
with dynamically adjusted momentum to reduce representation skew; (3)
initializing synthetic images by incrementally selecting high-confidence and
diverse augmentations via a multi-round mechanism that promotes coverage and
diversity. Extensive experiments on four long-tailed benchmarks show consistent
improvements over state-of-the-art methods across varying degrees of class
imbalance.Notably, our approach improves top-1 accuracy by 15.6% on
CIFAR-100-LT and 11.8% on Tiny-ImageNet-LT under IPC=10 and IF=10.
\\ ( https://arxiv.org/abs/2511.18858 ,  603kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18865
Date: Mon, 24 Nov 2025 08:08:22 GMT   (16001kb)

Title: DualGazeNet: A Biologically Inspired Dual-Gaze Query Network for Salient
 Object Detection
Authors: Yu Zhang, Haoan Ping, Yuchen Li, Zhenshan Bing, Fuchun Sun, Alois
 Knoll
Categories: cs.CV
\\
 Recent salient object detection (SOD) methods aim to improve performance in
four key directions: semantic enhancement, boundary refinement, auxiliary task
supervision, and multi-modal fusion. In pursuit of continuous gains, these
approaches have evolved toward increasingly sophisticated architectures with
multi-stage pipelines, specialized fusion modules, edge-guided learning, and
elaborate attention mechanisms. However, this complexity paradoxically
introduces feature redundancy and cross-component interference that obscure
salient cues, ultimately reaching performance bottlenecks. In contrast, human
vision achieves efficient salient object identification without such
architectural complexity. This contrast raises a fundamental question: can we
design a biologically grounded yet architecturally simple SOD framework that
dispenses with most of this engineering complexity, while achieving
state-of-the-art accuracy, computational efficiency, and interpretability? In
this work, we answer this question affirmatively by introducing DualGazeNet, a
biologically inspired pure Transformer framework that models the dual
biological principles of robust representation learning and
magnocellular-parvocellular dual-pathway processing with cortical attention
modulation in the human visual system. Extensive experiments on five RGB SOD
benchmarks show that DualGazeNet consistently surpasses 25 state-of-the-art
CNN- and Transformer-based methods. On average, DualGazeNet achieves about 60\%
higher inference speed and 53.4\% fewer FLOPs than four Transformer-based
baselines of similar capacity (VST++, MDSAM, Sam2unet, and BiRefNet). Moreover,
DualGazeNet exhibits strong cross-domain generalization, achieving leading or
highly competitive performance on camouflaged and underwater SOD benchmarks
without relying on additional modalities.
\\ ( https://arxiv.org/abs/2511.18865 ,  16001kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18870
Date: Mon, 24 Nov 2025 08:22:07 GMT   (8706kb)

Title: HunyuanVideo 1.5 Technical Report
Authors: Bing Wu, Chang Zou, Changlin Li, Duojun Huang, Fang Yang, Hao Tan,
 Jack Peng, Jianbing Wu, Jiangfeng Xiong, Jie Jiang, Linus, Patrol, Peizhen
 Zhang, Peng Chen, Penghao Zhao, Qi Tian, Songtao Liu, Weijie Kong, Weiyan
 Wang, Xiao He, Xin Li, Xinchi Deng, Xuefei Zhe, Yang Li, Yanxin Long, Yuanbo
 Peng, Yue Wu, Yuhong Liu, Zhenyu Wang, Zuozhuo Dai, Bo Peng, Coopers Li, Gu
 Gong, Guojian Xiao, Jiahe Tian, Jiaxin Lin, Jie Liu, Jihong Zhang, Jiesong
 Lian, Kaihang Pan, Lei Wang, Lin Niu, Mingtao Chen, Mingyang Chen, Mingzhe
 Zheng, Miles Yang, Qiangqiang Hu, Qi Yang, Qiuyong Xiao, Runzhou Wu, Ryan Xu,
 Rui Yuan, Shanshan Sang, Shisheng Huang, Siruis Gong, Shuo Huang, Weiting
 Guo, Xiang Yuan, Xiaojia Chen, Xiawei Hu, Wenzhi Sun, Xiele Wu, Xianshun Ren,
 Xiaoyan Yuan, Xiaoyue Mi, Yepeng Zhang, Yifu Sun, Yiting Lu, Yitong Li, You
 Huang, Yu Tang, Yixuan Li, Yuhang Deng, Yuan Zhou, Zhichao Hu, Zhiguang Liu,
 Zhihe Yang, Zilin Yang, Zhenzhi Lu, Zixiang Zhou, Zhao Zhong
Categories: cs.CV
\\
 We present HunyuanVideo 1.5, a lightweight yet powerful open-source video
generation model that achieves state-of-the-art visual quality and motion
coherence with only 8.3 billion parameters, enabling efficient inference on
consumer-grade GPUs. This achievement is built upon several key components,
including meticulous data curation, an advanced DiT architecture featuring
selective and sliding tile attention (SSTA), enhanced bilingual understanding
through glyph-aware text encoding, progressive pre-training and post-training,
and an efficient video super-resolution network. Leveraging these designs, we
developed a unified framework capable of high-quality text-to-video and
image-to-video generation across multiple durations and resolutions.Extensive
experiments demonstrate that this compact and proficient model establishes a
new state-of-the-art among open-source video generation models. By releasing
the code and model weights, we provide the community with a high-performance
foundation that lowers the barrier to video creation and research, making
advanced video generation accessible to a broader audience. All open-source
assets are publicly available at
https://github.com/Tencent-Hunyuan/HunyuanVideo-1.5.
\\ ( https://arxiv.org/abs/2511.18870 ,  8706kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18873
Date: Mon, 24 Nov 2025 08:26:32 GMT   (11012kb)

Title: Neural Texture Splatting: Expressive 3D Gaussian Splatting for View
 Synthesis, Geometry, and Dynamic Reconstruction
Authors: Yiming Wang, Shaofei Wang, Marko Mihajlovic, Siyu Tang
Categories: cs.CV cs.GR
Comments: SIGGRAPH Asia 2025 (conference track), Project page:
 https://19reborn.github.io/nts/
\\
 3D Gaussian Splatting (3DGS) has emerged as a leading approach for
high-quality novel view synthesis, with numerous variants extending its
applicability to a broad spectrum of 3D and 4D scene reconstruction tasks.
Despite its success, the representational capacity of 3DGS remains limited by
the use of 3D Gaussian kernels to model local variations. Recent works have
proposed to augment 3DGS with additional per-primitive capacity, such as
per-splat textures, to enhance its expressiveness. However, these per-splat
texture approaches primarily target dense novel view synthesis with a reduced
number of Gaussian primitives, and their effectiveness tends to diminish when
applied to more general reconstruction scenarios. In this paper, we aim to
achieve concrete performance improvement over state-of-the-art 3DGS variants
across a wide range of reconstruction tasks, including novel view synthesis,
geometry and dynamic reconstruction, under both sparse and dense input
settings. To this end, we introduce Neural Texture Splatting (NTS). At the core
of our approach is a global neural field (represented as a hybrid of a
tri-plane and a neural decoder) that predicts local appearance and geometric
fields for each primitive. By leveraging this shared global representation that
models local texture fields across primitives, we significantly reduce model
size and facilitate efficient global information exchange, demonstrating strong
generalization across tasks. Furthermore, our neural modeling of local texture
fields introduces expressive view- and time-dependent effects, a critical
aspect that existing methods fail to account for. Extensive experiments show
that Neural Texture Splatting consistently improves models and achieves
state-of-the-art results across multiple benchmarks.
\\ ( https://arxiv.org/abs/2511.18873 ,  11012kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18875
Date: Mon, 24 Nov 2025 08:29:36 GMT   (865kb)

Title: Parallel Vision Token Scheduling for Fast and Accurate Multimodal LMMs
 Inference
Authors: Wengyi Zhan, Mingbao Lin, Zhihang Lin, Rongrong Ji
Categories: cs.CV cs.MM
\\
 Multimodal large language models (MLLMs) deliver impressive vision-language
reasoning but suffer steep inference latency because self-attention scales
quadratically with sequence length and thousands of visual tokens contributed
by high-resolution images. Naively pruning less-informative visual tokens
reduces this burden, yet indiscriminate removal can strip away contextual cues
essential for background or fine-grained questions, undermining accuracy. In
this paper, we present ParVTS (Parallel Vision Token Scheduling), a
training-free scheduling framework that partitions visual tokens into subject
and non-subject groups, processes them in parallel to transfer their semantics
into question tokens, and discards the non-subject path mid-inference to reduce
computation. This scheduling reduces computational complexity, requires no
heuristics or additional modules, and is compatible with diverse existing MLLM
architectures. Experiments across multiple MLLM backbones show that ParVTS
prunes up to 88.9% of visual tokens with minimal performance drop, achieving
1.77x speedup and 70% FLOPs reduction.
\\ ( https://arxiv.org/abs/2511.18875 ,  865kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18882
Date: Mon, 24 Nov 2025 08:37:35 GMT   (4264kb)

Title: Facade Segmentation for Solar Photovoltaic Suitability
Authors: Ayca Duran, Christoph Waibel, Bernd Bickel, Iro Armeni and Arno
 Schlueter
Categories: cs.CV
Comments: NeurIPS 2025 Tackling Climate Change with Machine Learning Workshop
 version. Non-archival
\\
 Building integrated photovoltaic (BIPV) facades represent a promising pathway
towards urban decarbonization, especially where roof areas are insufficient and
ground-mounted arrays are infeasible. Although machine learning-based
approaches to support photovoltaic (PV) planning on rooftops are well
researched, automated approaches for facades still remain scarce and
oversimplified. This paper therefore presents a pipeline that integrates
detailed information on the architectural composition of the facade to
automatically identify suitable surfaces for PV application and estimate the
solar energy potential. The pipeline fine-tunes SegFormer-B5 on the CMP Facades
dataset and converts semantic predictions into facade-level PV suitability
masks and PV panel layouts considering module sizes and clearances. Applied to
a dataset of 373 facades with known dimensions from ten cities, the results
show that installable BIPV potential is significantly lower than theoretical
potential, thus providing valuable insights for reliable urban energy planning.
With the growing availability of facade imagery, the proposed pipeline can be
scaled to support BIPV planning in cities worldwide.
\\ ( https://arxiv.org/abs/2511.18882 ,  4264kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18886
Date: Mon, 24 Nov 2025 08:41:28 GMT   (7639kb)

Title: MagicWorld: Interactive Geometry-driven Video World Exploration
Authors: Guangyuan Li, Siming Zheng, Shuolin Xu, Jinwei Chen, Bo Li, Xiaobin
 Hu, Lei Zhao, Peng-Tao Jiang
Categories: cs.CV
\\
 Recent interactive video world model methods generate scene evolution
conditioned on user instructions. Although they achieve impressive results, two
key limitations remain. First, they fail to fully exploit the correspondence
between instruction-driven scene motion and the underlying 3D geometry, which
results in structural instability under viewpoint changes. Second, they easily
forget historical information during multi-step interaction, resulting in error
accumulation and progressive drift in scene semantics and structure. To address
these issues, we propose MagicWorld, an interactive video world model that
integrates 3D geometric priors and historical retrieval. MagicWorld starts from
a single scene image, employs user actions to drive dynamic scene evolution,
and autoregressively synthesizes continuous scenes. We introduce the
Action-Guided 3D Geometry Module (AG3D), which constructs a point cloud from
the first frame of each interaction and the corresponding action, providing
explicit geometric constraints for viewpoint transitions and thereby improving
structural consistency. We further propose History Cache Retrieval (HCR)
mechanism, which retrieves relevant historical frames during generation and
injects them as conditioning signals, helping the model utilize past scene
information and mitigate error accumulation. Experimental results demonstrate
that MagicWorld achieves notable improvements in scene stability and continuity
across interaction iterations.
\\ ( https://arxiv.org/abs/2511.18886 ,  7639kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18888
Date: Mon, 24 Nov 2025 08:44:04 GMT   (1507kb)

Title: MFmamba: A Multi-function Network for Panchromatic Image Resolution
 Restoration Based on State-Space Model
Authors: Qian Jiang, Qianqian Wang, Xin Jin, Michal Wozniak, Shaowen Yao, Wei
 Zhou
Categories: cs.CV
Comments: 9 pages, 9 figures. This paper has been accepted for publication in
 AAAI-2026
\\
 Remote sensing images are becoming increasingly widespread in military, earth
resource exploration. Because of the limitation of a single sensor, we can
obtain high spatial resolution grayscale panchromatic (PAN) images and low
spatial resolution color multispectral (MS) images. Therefore, an important
issue is to obtain a color image with high spatial resolution when there is
only a PAN image at the input. The existing methods improve spatial resolution
using super-resolution (SR) technology and spectral recovery using colorization
technology. However, the SR technique cannot improve the spectral resolution,
and the colorization technique cannot improve the spatial resolution. Moreover,
the pansharpening method needs two registered inputs and can not achieve SR. As
a result, an integrated approach is expected. To solve the above problems, we
designed a novel multi-function model (MFmamba) to realize the tasks of SR,
spectral recovery, joint SR and spectral recovery through three different
inputs. Firstly, MFmamba utilizes UNet++ as the backbone, and a Mamba Upsample
Block (MUB) is combined with UNet++. Secondly, a Dual Pool Attention (DPA) is
designed to replace the skip connection in UNet++. Finally, a Multi-scale
Hybrid Cross Block (MHCB) is proposed for initial feature extraction. Many
experiments show that MFmamba is competitive in evaluation metrics and visual
results and performs well in the three tasks when only the input PAN image is
used.
\\ ( https://arxiv.org/abs/2511.18888 ,  1507kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18894
Date: Mon, 24 Nov 2025 08:51:02 GMT   (7192kb)

Title: MetaDCSeg: Robust Medical Image Segmentation via Meta Dynamic Center
 Weighting
Authors: Chenyu Mu, Guihai Chen, Xun Yang, Erkun Yang, Cheng Deng
Categories: cs.CV cs.AI
\\
 Medical image segmentation is crucial for clinical applications, but it is
frequently disrupted by noisy annotations and ambiguous anatomical boundaries,
which lead to instability in model training. Existing methods typically rely on
global noise assumptions or confidence-based sample selection, which
inadequately mitigate the performance degradation caused by annotation noise,
especially in challenging boundary regions. To address this issue, we propose
MetaDCSeg, a robust framework that dynamically learns optimal pixel-wise
weights to suppress the influence of noisy ground-truth labels while preserving
reliable annotations. By explicitly modeling boundary uncertainty through a
Dynamic Center Distance (DCD) mechanism, our approach utilizes weighted feature
distances for foreground, background, and boundary centers, directing the
model's attention toward hard-to-segment pixels near ambiguous boundaries. This
strategy enables more precise handling of structural boundaries, which are
often overlooked by existing methods, and significantly enhances segmentation
performance. Extensive experiments across four benchmark datasets with varying
noise levels demonstrate that MetaDCSeg consistently outperforms existing
state-of-the-art methods.
\\ ( https://arxiv.org/abs/2511.18894 ,  7192kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18919
Date: Mon, 24 Nov 2025 09:29:30 GMT   (7632kb)

Title: Learning What to Trust: Bayesian Prior-Guided Optimization for Visual
 Generation
Authors: Ruiying Liu, Yuanzhi Liang, Haibin Huang, Tianshu Yu, Chi Zhang
Categories: cs.CV cs.AI
\\
 Group Relative Policy Optimization (GRPO) has emerged as an effective and
lightweight framework for post-training visual generative models. However, its
performance is fundamentally limited by the ambiguity of textual visual
correspondence: a single prompt may validly describe diverse visual outputs,
and a single image or video may support multiple equally correct
interpretations. This many to many relationship leads reward models to generate
uncertain and weakly discriminative signals, causing GRPO to underutilize
reliable feedback and overfit noisy ones. We introduce Bayesian Prior-Guided
Optimization (BPGO), a novel extension of GRPO that explicitly models reward
uncertainty through a semantic prior anchor. BPGO adaptively modulates
optimization trust at two levels: inter-group Bayesian trust allocation
emphasizes updates from groups consistent with the prior while down-weighting
ambiguous ones, and intra-group prior-anchored renormalization sharpens sample
distinctions by expanding confident deviations and compressing uncertain
scores. Across both image and video generation tasks, BPGO delivers
consistently stronger semantic alignment, enhanced perceptual fidelity, and
faster convergence than standard GRPO and recent variants.
\\ ( https://arxiv.org/abs/2511.18919 ,  7632kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18920
Date: Mon, 24 Nov 2025 09:30:02 GMT   (3256kb)

Title: EventSTU: Event-Guided Efficient Spatio-Temporal Understanding for Video
 Large Language Models
Authors: Wenhao Xu, Xin Dong, Yue Li, Haoyuan Shi, Zhiwei Xiong
Categories: cs.CV
Comments: 8 pages, 7 figures
\\
 Video large language models have demonstrated strong video understanding
capabilities but suffer from high inference costs due to the massive number of
tokens in long videos. Inspired by event-based vision, we propose an
event-guided, training-free framework for efficient spatio-temporal
understanding, named EventSTU. In the temporal domain, we design a
coarse-to-fine keyframe sampling algorithm that exploits the change-triggered
property of event cameras to eliminate redundant frames. In the spatial domain,
we design an adaptive token pruning algorithm that leverages the visual
saliency of events as a zero-cost prior to guide spatial reduction. From a
holistic spatio-temporal perspective, we further integrate question relevance
from keyframe sampling to adaptively allocate token pruning budgets. To
facilitate evaluation, we construct EventBench, the first event-inclusive,
human-annotated multimodal benchmark that covers diverse real-world scenarios.
Beyond physical event cameras, EventSTU also supports general video
understanding using simulated events. Comprehensive experiments show that
EventSTU achieves 3.01x FLOPs reduction and 3.10x prefilling speedup over the
strongest baseline while still improving performance.
\\ ( https://arxiv.org/abs/2511.18920 ,  3256kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18921
Date: Mon, 24 Nov 2025 09:30:38 GMT   (5417kb)

Title: BackdoorVLM: A Benchmark for Backdoor Attacks on Vision-Language Models
Authors: Juncheng Li, Yige Li, Hanxun Huang, Yunhao Chen, Xin Wang, Yixu Wang,
 Xingjun Ma, Yu-Gang Jiang
Categories: cs.CV
\\
 Backdoor attacks undermine the reliability and trustworthiness of machine
learning systems by injecting hidden behaviors that can be maliciously
activated at inference time. While such threats have been extensively studied
in unimodal settings, their impact on multimodal foundation models,
particularly vision-language models (VLMs), remains largely underexplored. In
this work, we introduce \textbf{BackdoorVLM}, the first comprehensive benchmark
for systematically evaluating backdoor attacks on VLMs across a broad range of
settings. It adopts a unified perspective that injects and analyzes backdoors
across core vision-language tasks, including image captioning and visual
question answering. BackdoorVLM organizes multimodal backdoor threats into 5
representative categories: targeted refusal, malicious injection, jailbreak,
concept substitution, and perceptual hijack. Each category captures a distinct
pathway through which an adversary can manipulate a model's behavior. We
evaluate these threats using 12 representative attack methods spanning text,
image, and bimodal triggers, tested on 2 open-source VLMs and 3 multimodal
datasets. Our analysis reveals that VLMs exhibit strong sensitivity to textual
instructions, and in bimodal backdoors the text trigger typically overwhelms
the image trigger when forming the backdoor mapping. Notably, backdoors
involving the textual modality remain highly potent, with poisoning rates as
low as 1\% yielding over 90\% success across most tasks. These findings
highlight significant, previously underexplored vulnerabilities in current
VLMs. We hope that BackdoorVLM can serve as a useful benchmark for analyzing
and mitigating multimodal backdoor threats. Code is available at:
https://github.com/bin015/BackdoorVLM .
\\ ( https://arxiv.org/abs/2511.18921 ,  5417kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18922
Date: Mon, 24 Nov 2025 09:31:23 GMT   (4327kb)

Title: One4D: Unified 4D Generation and Reconstruction via Decoupled LoRA
 Control
Authors: Zhenxing Mi, Yuxin Wang, Dan Xu
Categories: cs.CV
Comments: Project page: https://mizhenxing.github.io/One4D
\\
 We present One4D, a unified framework for 4D generation and reconstruction
that produces dynamic 4D content as synchronized RGB frames and pointmaps. By
consistently handling varying sparsities of conditioning frames through a
Unified Masked Conditioning (UMC) mechanism, One4D can seamlessly transition
between 4D generation from a single image, 4D reconstruction from a full video,
and mixed generation and reconstruction from sparse frames. Our framework
adapts a powerful video generation model for joint RGB and pointmap generation,
with carefully designed network architectures. The commonly used diffusion
finetuning strategies for depthmap or pointmap reconstruction often fail on
joint RGB and pointmap generation, quickly degrading the base video model. To
address this challenge, we introduce Decoupled LoRA Control (DLC), which
employs two modality-specific LoRA adapters to form decoupled computation
branches for RGB frames and pointmaps, connected by lightweight,
zero-initialized control links that gradually learn mutual pixel-level
consistency. Trained on a mixture of synthetic and real 4D datasets under
modest computational budgets, One4D produces high-quality RGB frames and
accurate pointmaps across both generation and reconstruction tasks. This work
represents a step toward general, high-quality geometry-based 4D world modeling
using video diffusion models. Project page: https://mizhenxing.github.io/One4D
\\ ( https://arxiv.org/abs/2511.18922 ,  4327kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18925
Date: Mon, 24 Nov 2025 09:32:01 GMT   (632kb)

Title: AttenDence: Maximizing Attention Confidence for Test Time Adaptation
Authors: Yash Mali
Categories: cs.CV
Comments: Initial submission. 5 pages, 4 figures
\\
 Test-time adaptation (TTA) enables models to adapt to distribution shifts at
inference time. While entropy minimization over the output distribution has
proven effective for TTA, transformers offer an additional unsupervised
learning signal through their attention mechanisms. We propose minimizing the
entropy of attention distributions from the CLS token to image patches as a
novel TTA objective.This approach encourages the model to attend more
confidently to relevant image regions under distribution shift and is effective
even when only a single test image is available. We demonstrate that attention
entropy minimization improves robustness across diverse corruption types while
not hurting performance on clean data on a single sample stream of images at
test time.
\\ ( https://arxiv.org/abs/2511.18925 ,  632kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18927
Date: Mon, 24 Nov 2025 09:32:26 GMT   (5784kb)

Title: FineXtrol: Controllable Motion Generation via Fine-Grained Text
Authors: Keming Shen, Bizhu Wu, Junliang Chen, Xiaoqin Wang, and Linlin Shen
Categories: cs.CV
Comments: 20 pages, 14 figures, AAAI 2026
\\
 Recent works have sought to enhance the controllability and precision of
text-driven motion generation. Some approaches leverage large language models
(LLMs) to produce more detailed texts, while others incorporate global 3D
coordinate sequences as additional control signals. However, the former often
introduces misaligned details and lacks explicit temporal cues, and the latter
incurs significant computational cost when converting coordinates to standard
motion representations. To address these issues, we propose FineXtrol, a novel
control framework for efficient motion generation guided by temporally-aware,
precise, user-friendly, and fine-grained textual control signals that describe
specific body part movements over time. In support of this framework, we design
a hierarchical contrastive learning module that encourages the text encoder to
produce more discriminative embeddings for our novel control signals, thereby
improving motion controllability. Quantitative results show that FineXtrol
achieves strong performance in controllable motion generation, while
qualitative analysis demonstrates its flexibility in directing specific body
part movements.
\\ ( https://arxiv.org/abs/2511.18927 ,  5784kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18929
Date: Mon, 24 Nov 2025 09:33:59 GMT   (1721kb)

Title: Human-Centric Open-Future Task Discovery: Formulation, Benchmark, and
 Scalable Tree-Based Search
Authors: Zijian Song, Xiaoxin Lin, Tao Pu, Zhenlong Yuan, Guangrun Wang, Liang
 Lin
Categories: cs.CV
Comments: 10 pages, 9 figures
\\
 Recent progress in robotics and embodied AI is largely driven by Large
Multimodal Models (LMMs). However, a key challenge remains underexplored: how
can we advance LMMs to discover tasks that directly assist humans in
open-future scenarios, where human intentions are highly concurrent and
dynamic. In this work, we formalize the problem of Human-centric Open-future
Task Discovery (HOTD), focusing particularly on identifying tasks that reduce
human effort across multiple plausible futures. To facilitate this study, we
propose an HOTD-Bench, which features over 2K real-world videos, a
semi-automated annotation pipeline, and a simulation-based protocol tailored
for open-set future evaluation. Additionally, we propose the Collaborative
Multi-Agent Search Tree (CMAST) framework, which decomposes the complex
reasoning through a multi-agent system and structures the reasoning process
through a scalable search tree module. In our experiments, CMAST achieves the
best performance on the HOTD-Bench, significantly surpassing existing LMMs. It
also integrates well with existing LMMs, consistently improving performance.
\\ ( https://arxiv.org/abs/2511.18929 ,  1721kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18942
Date: Mon, 24 Nov 2025 09:48:38 GMT   (7072kb)

Title: VeCoR - Velocity Contrastive Regularization for Flow Matching
Authors: Zong-Wei Hong, Jing-lun Li, Lin-Ze Li, Shen Zhang, Yao Tang
Categories: cs.CV
\\
 Flow Matching (FM) has recently emerged as a principled and efficient
alternative to diffusion models. Standard FM encourages the learned velocity
field to follow a target direction; however, it may accumulate errors along the
trajectory and drive samples off the data manifold, leading to perceptual
degradation, especially in lightweight or low-step configurations.
 To enhance stability and generalization, we extend FM into a balanced
attract-repel scheme that provides explicit guidance on both "where to go" and
"where not to go." To be formal, we propose \textbf{Velocity Contrastive
Regularization (VeCoR)}, a complementary training scheme for flow-based
generative modeling that augments the standard FM objective with contrastive,
two-sided supervision. VeCoR not only aligns the predicted velocity with a
stable reference direction (positive supervision) but also pushes it away from
inconsistent, off-manifold directions (negative supervision). This contrastive
formulation transforms FM from a purely attractive, one-sided objective into a
two-sided training signal, regularizing trajectory evolution and improving
perceptual fidelity across datasets and backbones.
 On ImageNet-1K 256$\times$256, VeCoR yields 22\% and 35\% relative FID
reductions on SiT-XL/2 and REPA-SiT-XL/2 backbones, respectively, and achieves
further FID gains (32\% relative) on MS-COCO text-to-image generation,
demonstrating consistent improvements in stability, convergence, and image
quality, particularly in low-step and lightweight settings. Project page:
https://p458732.github.io/VeCoR_Project_Page/
\\ ( https://arxiv.org/abs/2511.18942 ,  7072kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18946
Date: Mon, 24 Nov 2025 09:56:35 GMT   (12625kb)

Title: Leveraging Adversarial Learning for Pathological Fidelity in Virtual
 Staining
Authors: Jos\'e Teixeira, Pascal Kl\"ockner, Diana Montezuma, Melis Erdal
 Cesur, Jo\~ao Fraga, Hugo M. Horlings, Jaime S. Cardoso and Sara P. Oliveira
Categories: cs.CV
DOI: 10.1007/978-3-032-05472-2_20
\\
 In addition to evaluating tumor morphology using H&E staining,
immunohistochemistry is used to assess the presence of specific proteins within
the tissue. However, this is a costly and labor-intensive technique, for which
virtual staining, as an image-to-image translation task, offers a promising
alternative. Although recent, this is an emerging field of research with 64% of
published studies just in 2024. Most studies use publicly available datasets of
H&E-IHC pairs from consecutive tissue sections. Recognizing the training
challenges, many authors develop complex virtual staining models based on
conditional Generative Adversarial Networks, but ignore the impact of
adversarial loss on the quality of virtual staining. Furthermore, overlooking
the issues of model evaluation, they claim improved performance based on
metrics such as SSIM and PSNR, which are not sufficiently robust to evaluate
the quality of virtually stained images. In this paper, we developed CSSP2P
GAN, which we demonstrate to achieve heightened pathological fidelity through a
blind pathological expert evaluation. Furthermore, while iteratively developing
our model, we study the impact of the adversarial loss and demonstrate its
crucial role in the quality of virtually stained images. Finally, while
comparing our model with reference works in the field, we underscore the
limitations of the currently used evaluation metrics and demonstrate the
superior performance of CSSP2P GAN.
\\ ( https://arxiv.org/abs/2511.18946 ,  12625kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18957
Date: Mon, 24 Nov 2025 10:19:56 GMT   (26656kb)

Title: Eevee: Towards Close-up High-resolution Video-based Virtual Try-on
Authors: Jianhao Zeng, Yancheng Bai, Ruidong Chen, Xuanpu Zhang, Lei Sun,
 Dongyang Jin, Ryan Xu, Nannan Zhang, Dan Song, Xiangxiang Chu
Categories: cs.CV
\\
 Video virtual try-on technology provides a cost-effective solution for
creating marketing videos in fashion e-commerce. However, its practical
adoption is hindered by two critical limitations. First, the reliance on a
single garment image as input in current virtual try-on datasets limits the
accurate capture of realistic texture details. Second, most existing methods
focus solely on generating full-shot virtual try-on videos, neglecting the
business's demand for videos that also provide detailed close-ups. To address
these challenges, we introduce a high-resolution dataset for video-based
virtual try-on. This dataset offers two key features. First, it provides more
detailed information on the garments, which includes high-fidelity images with
detailed close-ups and textual descriptions; Second, it uniquely includes
full-shot and close-up try-on videos of real human models. Furthermore,
accurately assessing consistency becomes significantly more critical for the
close-up videos, which demand high-fidelity preservation of garment details. To
facilitate such fine-grained evaluation, we propose a new garment consistency
metric VGID (Video Garment Inception Distance) that quantifies the preservation
of both texture and structure. Our experiments validate these contributions. We
demonstrate that by utilizing the detailed images from our dataset, existing
video generation models can extract and incorporate texture features,
significantly enhancing the realism and detail fidelity of virtual try-on
results. Furthermore, we conduct a comprehensive benchmark of recent models.
The benchmark effectively identifies the texture and structural preservation
problems among current methods.
\\ ( https://arxiv.org/abs/2511.18957 ,  26656kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18968
Date: Mon, 24 Nov 2025 10:34:12 GMT   (2093kb)

Title: CataractCompDetect: Intraoperative Complication Detection in Cataract
 Surgery
Authors: Bhuvan Sachdeva, Sneha Kumari, Rudransh Agarwal, Shalaka Kumaraswamy,
 Niharika Singri Prasad, Simon Mueller, Raphael Lechtenboehmer, Maximilian W.
 M. Wintergerst, Thomas Schultz, Kaushik Murali, Mohit Jain
Categories: cs.CV
\\
 Cataract surgery is one of the most commonly performed surgeries worldwide,
yet intraoperative complications such as iris prolapse, posterior capsule
rupture (PCR), and vitreous loss remain major causes of adverse outcomes.
Automated detection of such events could enable early warning systems and
objective training feedback. In this work, we propose CataractCompDetect, a
complication detection framework that combines phase-aware localization, SAM
2-based tracking, complication-specific risk scoring, and vision-language
reasoning for final classification. To validate CataractCompDetect, we curate
CataComp, the first cataract surgery video dataset annotated for intraoperative
complications, comprising 53 surgeries, including 23 with clinical
complications. On CataComp, CataractCompDetect achieves an average F1 score of
70.63%, with per-complication performance of 81.8% (Iris Prolapse), 60.87%
(PCR), and 69.23% (Vitreous Loss). These results highlight the value of
combining structured surgical priors with vision-language reasoning for
recognizing rare but high-impact intraoperative events. Our dataset and code
will be publicly released upon acceptance.
\\ ( https://arxiv.org/abs/2511.18968 ,  2093kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18976
Date: Mon, 24 Nov 2025 10:47:39 GMT   (181kb)

Title: Peregrine: One-Shot Fine-Tuning for FHE Inference of General Deep CNNs
Authors: Huaming Ling and Ying Wang and Si Chen and Junfeng Fan
Categories: cs.CV
\\
 We address two fundamental challenges in adapting general deep CNNs for
FHE-based inference: approximating non-linear activations such as ReLU with
low-degree polynomials while minimizing accuracy degradation, and overcoming
the ciphertext capacity barrier that constrains high-resolution image
processing on FHE inference. Our contributions are twofold: (1) a single-stage
fine-tuning (SFT) strategy that directly converts pre-trained CNNs into
FHE-friendly forms using low-degree polynomials, achieving competitive accuracy
with minimal training overhead; and (2) a generalized interleaved packing (GIP)
scheme that is compatible with feature maps of virtually arbitrary spatial
resolutions, accompanied by a suite of carefully designed homomorphic operators
that preserve the GIP-form encryption throughout computation. These advances
enable efficient, end-to-end FHE inference across diverse CNN architectures.
Experiments on CIFAR-10, ImageNet, and MS COCO demonstrate that the
FHE-friendly CNNs obtained via our SFT strategy achieve accuracy comparable to
baselines using ReLU or SiLU activations. Moreover, this work presents the
first demonstration of FHE-based inference for YOLO architectures in object
detection leveraging low-degree polynomial activations.
\\ ( https://arxiv.org/abs/2511.18976 ,  181kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18978
Date: Mon, 24 Nov 2025 10:50:30 GMT   (508kb)

Title: Zero-shot segmentation of skin tumors in whole-slide images with
 vision-language foundation models
Authors: Santiago Moreno and Pablo Meseguer and Roc\'io del Amor and Valery
 Naranjo
Categories: cs.CV
Comments: Conference manuscript accepted for oral presentation at CASEIB 2025
\\
 Accurate annotation of cutaneous neoplasm biopsies represents a major
challenge due to their wide morphological variability, overlapping histological
patterns, and the subtle distinctions between benign and malignant lesions.
Vision-language foundation models (VLMs), pre-trained on paired image-text
corpora, learn joint representations that bridge visual features and diagnostic
terminology, enabling zero-shot localization and classification of tissue
regions without pixel-level labels. However, most existing VLM applications in
histopathology remain limited to slide-level tasks or rely on coarse
interactive prompts, and they struggle to produce fine-grained segmentations
across gigapixel whole-slide images (WSIs). In this work, we introduce a
zero-shot visual-language segmentation pipeline for whole-slide images (ZEUS),
a fully automated, zero-shot segmentation framework that leverages
class-specific textual prompt ensembles and frozen VLM encoders to generate
high-resolution tumor masks in WSIs. By partitioning each WSI into overlapping
patches, extracting visual embeddings, and computing cosine similarities
against text prompts, we generate a final segmentation mask. We demonstrate
competitive performance on two in-house datasets, primary spindle cell
neoplasms and cutaneous metastases, highlighting the influence of prompt
design, domain shifts, and institutional variability in VLMs for
histopathology. ZEUS markedly reduces annotation burden while offering
scalable, explainable tumor delineation for downstream diagnostic workflows.
\\ ( https://arxiv.org/abs/2511.18978 ,  508kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18983
Date: Mon, 24 Nov 2025 10:56:22 GMT   (3067kb)

Title: UMCL: Unimodal-generated Multimodal Contrastive Learning for
 Cross-compression-rate Deepfake Detection
Authors: Ching-Yi Lai, Chih-Yu Jian, Pei-Cheng Chuang, Chia-Ming Lee,
 Chih-Chung Hsu, Chiou-Ting Hsu, Chia-Wen Lin
Categories: cs.CV
Comments: 24-page manuscript accepted to IJCV
\\
 In deepfake detection, the varying degrees of compression employed by social
media platforms pose significant challenges for model generalization and
reliability. Although existing methods have progressed from single-modal to
multimodal approaches, they face critical limitations: single-modal methods
struggle with feature degradation under data compression in social media
streaming, while multimodal approaches require expensive data collection and
labeling and suffer from inconsistent modal quality or accessibility in
real-world scenarios. To address these challenges, we propose a novel
Unimodal-generated Multimodal Contrastive Learning (UMCL) framework for robust
cross-compression-rate (CCR) deepfake detection. In the training stage, our
approach transforms a single visual modality into three complementary features:
compression-robust rPPG signals, temporal landmark dynamics, and semantic
embeddings from pre-trained vision-language models. These features are
explicitly aligned through an affinity-driven semantic alignment (ASA)
strategy, which models inter-modal relationships through affinity matrices and
optimizes their consistency through contrastive learning. Subsequently, our
cross-quality similarity learning (CQSL) strategy enhances feature robustness
across compression rates. Extensive experiments demonstrate that our method
achieves superior performance across various compression rates and manipulation
types, establishing a new benchmark for robust deepfake detection. Notably, our
approach maintains high detection accuracy even when individual features
degrade, while providing interpretable insights into feature relationships
through explicit alignment.
\\ ( https://arxiv.org/abs/2511.18983 ,  3067kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18989
Date: Mon, 24 Nov 2025 11:08:01 GMT   (19669kb)

Title: Rethinking Plant Disease Diagnosis: Bridging the Academic-Practical Gap
 with Vision Transformers and Zero-Shot Learning
Authors: Wassim Benabbas, Mohammed Brahimi, Samir Akhrouf, Bilal Fortas
Categories: cs.CV cs.AI
\\
 Recent advances in deep learning have enabled significant progress in plant
disease classification using leaf images. Much of the existing research in this
field has relied on the PlantVillage dataset, which consists of well-centered
plant images captured against uniform, uncluttered backgrounds. Although models
trained on this dataset achieve high accuracy, they often fail to generalize to
real-world field images, such as those submitted by farmers to plant diagnostic
systems. This has created a significant gap between published studies and
practical application requirements, highlighting the necessity of investigating
and addressing this issue. In this study, we investigate whether
attention-based architectures and zero-shot learning approaches can bridge the
gap between curated academic datasets and real-world agricultural conditions in
plant disease classification. We evaluate three model categories: Convolutional
Neural Networks (CNNs), Vision Transformers, and Contrastive Language-Image
Pre-training (CLIP)-based zero-shot models. While CNNs exhibit limited
robustness under domain shift, Vision Transformers demonstrate stronger
generalization by capturing global contextual features. Most notably, CLIP
models classify diseases directly from natural language descriptions without
any task-specific training, offering strong adaptability and interpretability.
These findings highlight the potential of zero-shot learning as a practical and
scalable domain adaptation strategy for plant health diagnosis in diverse field
environments.
\\ ( https://arxiv.org/abs/2511.18989 ,  19669kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18991
Date: Mon, 24 Nov 2025 11:16:55 GMT   (43512kb)

Title: View-Consistent Diffusion Representations for 3D-Consistent Video
 Generation
Authors: Duolikun Danier, Ge Gao, Steven McDonagh, Changjian Li, Hakan Bilen,
 Oisin Mac Aodha
Categories: cs.CV
\\
 Video generation models have made significant progress in generating
realistic content, enabling applications in simulation, gaming, and film
making. However, current generated videos still contain visual artifacts
arising from 3D inconsistencies, e.g., objects and structures deforming under
changes in camera pose, which can undermine user experience and simulation
fidelity. Motivated by recent findings on representation alignment for
diffusion models, we hypothesize that improving the multi-view consistency of
video diffusion representations will yield more 3D-consistent video generation.
Through detailed analysis on multiple recent camera-controlled video diffusion
models we reveal strong correlations between 3D-consistent representations and
videos. We also propose ViCoDR, a new approach for improving the 3D consistency
of video models by learning multi-view consistent diffusion representations. We
evaluate ViCoDR on camera controlled image-to-video, text-to-video, and
multi-view generation models, demonstrating significant improvements in the 3D
consistency of the generated videos. Project page:
https://danier97.github.io/ViCoDR.
\\ ( https://arxiv.org/abs/2511.18991 ,  43512kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18993
Date: Mon, 24 Nov 2025 11:19:21 GMT   (3868kb)

Title: AuViRe: Audio-visual Speech Representation Reconstruction for Deepfake
 Temporal Localization
Authors: Christos Koutlis, Symeon Papadopoulos
Categories: cs.CV
Comments: WACV 2026
\\
 With the rapid advancement of sophisticated synthetic audio-visual content,
e.g., for subtle malicious manipulations, ensuring the integrity of digital
media has become paramount. This work presents a novel approach to temporal
localization of deepfakes by leveraging Audio-Visual Speech Representation
Reconstruction (AuViRe). Specifically, our approach reconstructs speech
representations from one modality (e.g., lip movements) based on the other
(e.g., audio waveform). Cross-modal reconstruction is significantly more
challenging in manipulated video segments, leading to amplified discrepancies,
thereby providing robust discriminative cues for precise temporal forgery
localization. AuViRe outperforms the state of the art by +8.9 AP@0.95 on
LAV-DF, +9.6 AP@0.5 on AV-Deepfake1M, and +5.1 AUC on an in-the-wild
experiment. Code available at https://github.com/mever-team/auvire.
\\ ( https://arxiv.org/abs/2511.18993 ,  3868kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19004
Date: Mon, 24 Nov 2025 11:32:15 GMT   (6864kb)

Title: A Self-Conditioned Representation Guided Diffusion Model for Realistic
 Text-to-LiDAR Scene Generation
Authors: Wentao Qu, Guofeng Mei, Yang Wu, Yongshun Gong, Xiaoshui Huang, Liang
 Xiao
Categories: cs.CV
\\
 Text-to-LiDAR generation can customize 3D data with rich structures and
diverse scenes for downstream tasks. However, the scarcity of Text-LiDAR pairs
often causes insufficient training priors, generating overly smooth 3D scenes.
Moreover, low-quality text descriptions may degrade generation quality and
controllability. In this paper, we propose a Text-to-LiDAR Diffusion Model for
scene generation, named T2LDM, with a Self-Conditioned Representation Guidance
(SCRG). Specifically, SCRG, by aligning to the real representations, provides
the soft supervision with reconstruction details for the Denoising Network (DN)
in training, while decoupled in inference. In this way, T2LDM can perceive rich
geometric structures from data distribution, generating detailed objects in
scenes. Meanwhile, we construct a content-composable Text-LiDAR benchmark,
T2nuScenes, along with a controllability metric. Based on this, we analyze the
effects of different text prompts for LiDAR generation quality and
controllability, providing practical prompt paradigms and insights.
Furthermore, a directional position prior is designed to mitigate street
distortion, further improving scene fidelity. Additionally, by learning a
conditional encoder via frozen DN, T2LDM can support multiple conditional
tasks, including Sparse-to-Dense, Dense-to-Sparse, and Semantic-to-LiDAR
generation. Extensive experiments in unconditional and conditional generation
demonstrate that T2LDM outperforms existing methods, achieving state-of-the-art
scene generation.
\\ ( https://arxiv.org/abs/2511.19004 ,  6864kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19021
Date: Mon, 24 Nov 2025 11:55:22 GMT   (3382kb)

Title: Dynamic Granularity Matters: Rethinking Vision Transformers Beyond Fixed
 Patch Splitting
Authors: Qiyang Yu, Yu Fang, Tianrui Li, Xuemei Cao, Yan Chen, Jianghao Li, Fan
 Min
Categories: cs.CV
Comments: 10 pages, 7 figures
\\
 Vision Transformers (ViTs) have demonstrated strong capabilities in capturing
global dependencies but often struggle to efficiently represent fine-grained
local details. Existing multi-scale approaches alleviate this issue by
integrating hierarchical or hybrid features; however, they rely on fixed patch
sizes and introduce redundant computation. To address these limitations, we
propose Granularity-driven Vision Transformer (Grc-ViT), a dynamic
coarse-to-fine framework that adaptively adjusts visual granularity based on
image complexity. It comprises two key stages: (1) Coarse Granularity
Evaluation module, which assesses visual complexity using edge density,
entropy, and frequency-domain cues to estimate suitable patch and window sizes;
(2) Fine-grained Refinement module, which refines attention computation
according to the selected granularity, enabling efficient and precise feature
learning. Two learnable parameters, {\alpha} and \b{eta}, are optimized
end-to-end to balance global reasoning and local perception. Comprehensive
evaluations demonstrate that Grc-ViT enhances fine-grained discrimination while
achieving a superior trade-off between accuracy and computational efficiency.
\\ ( https://arxiv.org/abs/2511.19021 ,  3382kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19024
Date: Mon, 24 Nov 2025 11:59:55 GMT   (4309kb)

Title: Life-IQA: Boosting Blind Image Quality Assessment through GCN-enhanced
 Layer Interaction and MoE-based Feature Decoupling
Authors: Long Tang, Guoquan Zhen, Jie Hao, Jianbo Zhang, Huiyu Duan, Liang
 Yuan, Guangtao Zhai
Categories: cs.CV cs.AI
\\
 Blind image quality assessment (BIQA) plays a crucial role in evaluating and
optimizing visual experience. Most existing BIQA approaches fuse shallow and
deep features extracted from backbone networks, while overlooking the unequal
contributions to quality prediction. Moreover, while various vision encoder
backbones are widely adopted in BIQA, the effective quality decoding
architectures remain underexplored. To address these limitations, this paper
investigates the contributions of shallow and deep features to BIQA, and
proposes a effective quality feature decoding framework via GCN-enhanced
\underline{l}ayer\underline{i}nteraction and MoE-based \underline{f}eature
d\underline{e}coupling, termed \textbf{(Life-IQA)}. Specifically, the
GCN-enhanced layer interaction module utilizes the GCN-enhanced deepest-layer
features as query and the penultimate-layer features as key, value, then
performs cross-attention to achieve feature interaction. Moreover, a MoE-based
feature decoupling module is proposed to decouple fused representations though
different experts specialized for specific distortion types or quality
dimensions. Extensive experiments demonstrate that Life-IQA shows more
favorable balance between accuracy and cost than a vanilla Transformer decoder
and achieves state-of-the-art performance on multiple BIQA benchmarks.The code
is available at:
\href{https://github.com/TANGLONG2/Life-IQA/tree/main}{\texttt{Life-IQA}}.
\\ ( https://arxiv.org/abs/2511.19024 ,  4309kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19032
Date: Mon, 24 Nov 2025 12:07:56 GMT   (16119kb)

Title: Benchmarking Corruption Robustness of LVLMs: A Discriminative Benchmark
 and Robustness Alignment Metric
Authors: Xiangjie Sui, Songyang Li, Hanwei Zhu, Baoliang Chen, Yuming Fang, Xin
 Sun
Categories: cs.CV
Comments: 15 pages
\\
 Despite the remarkable reasoning abilities of large vision-language models
(LVLMs), their robustness under visual corruptions remains insufficiently
studied. Existing evaluation paradigms exhibit two major limitations: 1) the
dominance of low-discriminative samples in current datasets masks the real
robustness gap between models; and 2) conventional accuracy-based metric fail
to capture the degradation of the underlying prediction structure. To bridge
these gaps, we introduce Bench-C, a comprehensive benchmark emphasizing
discriminative samples for assessing corruption robustness, where a selection
strategy is proposed to jointly consider the prediction inconsistency under
corruption and the semantic diversity. Furthermore, we propose the Robustness
Alignment Score (RAS), a unified metric that measures degradation in
logit-level prediction structure by considering the shifts in prediction
uncertainty and calibration alignment. Comprehensive experiments and analysis
reveal several interesting findings: 1) model behaviors exhibit distinguish
patterns under corruptions, such as erroneous confidence and hesitation; 2)
despite subtle corruption may lead to a slight accuracy gain, the overall
prediction structure still degrades; 3) by decomposing corruption robustness
into destructive and corrective components, the distinct failure and recovery
patterns across models can be revealed.
\\ ( https://arxiv.org/abs/2511.19032 ,  16119kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19033
Date: Mon, 24 Nov 2025 12:13:05 GMT   (2365kb)

Title: ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized
 Retrospective Experience Replay
Authors: Gengyuan Zhang, Mingcong Ding, Jingpei Wu, Ruotong Liao, Volker Tresp
Categories: cs.CV
Comments: 8 main pages plus 13 pages Appendix
\\
 Embodied exploration is a target-driven process that requires embodied agents
to possess fine-grained perception and knowledge-enhanced decision making.
While recent attempts leverage MLLMs for exploration due to their strong
perceptual and reasoning abilities, we find that MLLM-based embodied agents
remain suboptimal in exploring new environments: (i) they rely on profound but
stale pre-trained knowledge, (ii) training-based approaches such as imitation
learning or reinforcement learning are expensive for long-horizon tasks with
sparse outcome rewards, and (iii) frontier-based exploration yields a large,
visually nuanced action space that is difficult for MLLMs to make reliable
decisions. We address these challenges with ReEXplore, a training-free
framework that performs retrospective experience replay to inject distilled,
abstract experience at inference time, and hierarchical frontier selection to
decompose frontier ranking into coarse-to-fine decisions. Our approach enables
robust, traceable, and efficient exploration. Across multiple embodied
exploration benchmarks, ReEXplore yields great improvements over strong MLLM
baselines, up to 3x higher performance in both success rate and in navigation
efficiency under open-source backbones.
\\ ( https://arxiv.org/abs/2511.19033 ,  2365kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19035
Date: Mon, 24 Nov 2025 12:16:21 GMT   (4667kb)

Title: CSD: Change Semantic Detection with only Semantic Change Masks for
 Damage Assessment in Conflict Zones
Authors: Kai Zhenga, Zhenkai Wu, Fupeng Wei, Miaolan Zhou, Kai Lie, Haitao Guo,
 Lei Ding, Wei Zhang, and Hang-Cheng Dong
Categories: cs.CV cs.AI
\\
 Accurately and swiftly assessing damage from conflicts is crucial for
humanitarian aid and regional stability. In conflict zones, damaged zones often
share similar architectural styles, with damage typically covering small areas
and exhibiting blurred boundaries. These characteristics lead to limited data,
annotation difficulties, and significant recognition challenges, including high
intra-class similarity and ambiguous semantic changes. To address these issues,
we introduce a pre-trained DINOv3 model and propose a multi-scale
cross-attention difference siamese network (MC-DiSNet). The powerful visual
representation capability of the DINOv3 backbone enables robust and rich
feature extraction from bi-temporal remote sensing images. We also release a
new Gaza-change dataset containing high-resolution satellite image pairs from
2023-2024 with pixel-level semantic change annotations. It is worth emphasizing
that our annotations only include semantic pixels of changed areas. Unlike
conventional semantic change detection (SCD), our approach eliminates the need
for large-scale semantic annotations of bi-temporal images, instead focusing
directly on the changed regions. We term this new task change semantic
detection (CSD). The CSD task represents a direct extension of binary change
detection (BCD). Due to the limited spatial extent of semantic regions, it
presents greater challenges than traditional SCD tasks. We evaluated our method
under the CSD framework on both the Gaza-Change and SECOND datasets.
Experimental results demonstrate that our proposed approach effectively
addresses the CSD task, and its outstanding performance paves the way for
practical applications in rapid damage assessment across conflict zones.
\\ ( https://arxiv.org/abs/2511.19035 ,  4667kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19046
Date: Mon, 24 Nov 2025 12:34:38 GMT   (4411kb)

Title: MedSAM3: Delving into Segment Anything with Medical Concepts
Authors: Anglin Liu, Rundong Xue, Xu R. Cao, Yifan Shen, Yi Lu, Xiang Li,
 Qianqian Chen, Jintai Chen
Categories: cs.CV cs.AI
\\
 Medical image segmentation is fundamental for biomedical discovery. Existing
methods lack generalizability and demand extensive, time-consuming manual
annotation for new clinical application. Here, we propose MedSAM-3, a text
promptable medical segmentation model for medical image and video segmentation.
By fine-tuning the Segment Anything Model (SAM) 3 architecture on medical
images paired with semantic conceptual labels, our MedSAM-3 enables medical
Promptable Concept Segmentation (PCS), allowing precise targeting of anatomical
structures via open-vocabulary text descriptions rather than solely geometric
prompts. We further introduce the MedSAM-3 Agent, a framework that integrates
Multimodal Large Language Models (MLLMs) to perform complex reasoning and
iterative refinement in an agent-in-the-loop workflow. Comprehensive
experiments across diverse medical imaging modalities, including X-ray, MRI,
Ultrasound, CT, and video, demonstrate that our approach significantly
outperforms existing specialist and foundation models. We will release our code
and model at https://github.com/Joey-S-Liu/MedSAM3.
\\ ( https://arxiv.org/abs/2511.19046 ,  4411kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19049
Date: Mon, 24 Nov 2025 12:37:49 GMT   (44594kb)

Title: Beyond Reward Margin: Rethinking and Resolving Likelihood Displacement
 in Diffusion Models via Video Generation
Authors: Ruojun Xu, Yu Kai, Xuhua Ren, Jiaxiang Cheng, Bing Ma, Tianxiang
 Zheng, Qinhlin Lu
Categories: cs.CV
\\
 Direct Preference Optimization (DPO) has shown promising results in aligning
generative outputs with human preferences by distinguishing between chosen and
rejected samples. However, a critical limitation of DPO is likelihood
displacement, where the probabilities of chosen samples paradoxically decrease
during training, undermining the quality of generation. Although this issue has
been investigated in autoregressive models, its impact within diffusion-based
models remains largely unexplored. This gap leads to suboptimal performance in
tasks involving video generation. To address this, we conduct a formal analysis
of DPO loss through updating policy within the diffusion framework, which
describes how the updating of specific training samples influences the model's
predictions on other samples. Using this tool, we identify two main failure
modes: (1) Optimization Conflict, which arises from small reward margins
between chosen and rejected samples, and (2) Suboptimal Maximization, caused by
large reward margins. Informed by these insights, we introduce a novel solution
named Policy-Guided DPO (PG-DPO), combining Adaptive Rejection Scaling (ARS)
and Implicit Preference Regularization (IPR) to effectively mitigate likelihood
displacement. Experiments show that PG-DPO outperforms existing methods in both
quantitative metrics and qualitative evaluations, offering a robust solution
for improving preference alignment in video generation tasks.
\\ ( https://arxiv.org/abs/2511.19049 ,  44594kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19057
Date: Mon, 24 Nov 2025 12:50:34 GMT   (29713kb)

Title: LAA3D: A Benchmark of Detecting and Tracking Low-Altitude Aircraft in 3D
 Space
Authors: Hai Wu, Shuai Tang, Jiale Wang, Longkun Zou, Mingyue Guo, Rongqin
 Liang, Ke Chen, Yaowei Wang
Categories: cs.CV
Comments: 25 pages
\\
 Perception of Low-Altitude Aircraft (LAA) in 3D space enables precise 3D
object localization and behavior understanding. However, datasets tailored for
3D LAA perception remain scarce. To address this gap, we present LAA3D, a
large-scale dataset designed to advance 3D detection and tracking of
low-altitude aerial vehicles. LAA3D contains 15,000 real images and 600,000
synthetic frames, captured across diverse scenarios, including urban and
suburban environments. It covers multiple aerial object categories, including
electric Vertical Take-Off and Landing (eVTOL) aircraft, Micro Aerial Vehicles
(MAVs), and Helicopters. Each instance is annotated with 3D bounding box, class
label, and instance identity, supporting tasks such as 3D object detection, 3D
multi-object tracking (MOT), and 6-DoF pose estimation. Besides, we establish
the LAA3D Benchmark, integrating multiple tasks and methods with unified
evaluation protocols for comparison. Furthermore, we propose MonoLAA, a
monocular 3D detection baseline, achieving robust 3D localization from zoom
cameras with varying focal lengths. Models pretrained on synthetic images
transfer effectively to real-world data with fine-tuning, demonstrating strong
sim-to-real generalization. Our LAA3D provides a comprehensive foundation for
future research in low-altitude 3D object perception.
\\ ( https://arxiv.org/abs/2511.19057 ,  29713kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19062
Date: Mon, 24 Nov 2025 12:55:02 GMT   (6080kb)

Title: Granular Computing-driven SAM: From Coarse-to-Fine Guidance for
 Prompt-Free Segmentation
Authors: Qiyang Yu, Yu Fang, Tianrui Li, Xuemei Cao, Yan Chen, Jianghao Li, Fan
 Min, Yi Zhang
Categories: cs.CV
Comments: 19 pages, 7 figures
\\
 Prompt-free image segmentation aims to generate accurate masks without manual
guidance. Typical pre-trained models, notably Segmentation Anything Model
(SAM), generate prompts directly at a single granularity level. However, this
approach has two limitations: (1) Localizability, lacking mechanisms for
autonomous region localization; (2) Scalability, limited fine-grained modeling
at high resolution. To address these challenges, we introduce Granular
Computing-driven SAM (Grc-SAM), a coarse-to-fine framework motivated by
Granular Computing (GrC). First, the coarse stage adaptively extracts
high-response regions from features to achieve precise foreground localization
and reduce reliance on external prompts. Second, the fine stage applies finer
patch partitioning with sparse local swin-style attention to enhance detail
modeling and enable high-resolution segmentation. Third, refined masks are
encoded as latent prompt embeddings for the SAM decoder, replacing handcrafted
prompts with an automated reasoning process. By integrating multi-granularity
attention, Grc-SAM bridges granular computing with vision transformers.
Extensive experimental results demonstrate Grc-SAM outperforms baseline methods
in both accuracy and scalability. It offers a unique granular computational
perspective for prompt-free segmentation.
\\ ( https://arxiv.org/abs/2511.19062 ,  6080kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19065
Date: Mon, 24 Nov 2025 12:59:27 GMT   (725kb)

Title: Understanding, Accelerating, and Improving MeanFlow Training
Authors: Jin-Young Kim, Hyojun Go, Lea Bogensperger, Julius Erbach, Nikolai
 Kalischek, Federico Tombari, Konrad Schindler, Dominik Narnhofer
Categories: cs.CV cs.AI cs.LG
\\
 MeanFlow promises high-quality generative modeling in few steps, by jointly
learning instantaneous and average velocity fields. Yet, the underlying
training dynamics remain unclear. We analyze the interaction between the two
velocities and find: (i) well-established instantaneous velocity is a
prerequisite for learning average velocity; (ii) learning of instantaneous
velocity benefits from average velocity when the temporal gap is small, but
degrades as the gap increases; and (iii) task-affinity analysis indicates that
smooth learning of large-gap average velocities, essential for one-step
generation, depends on the prior formation of accurate instantaneous and
small-gap average velocities. Guided by these observations, we design an
effective training scheme that accelerates the formation of instantaneous
velocity, then shifts emphasis from short- to long-interval average velocity.
Our enhanced MeanFlow training yields faster convergence and significantly
better few-step generation: With the same DiT-XL backbone, our method reaches
an impressive FID of 2.87 on 1-NFE ImageNet 256x256, compared to 3.43 for the
conventional MeanFlow baseline. Alternatively, our method matches the
performance of the MeanFlow baseline with 2.5x shorter training time, or with a
smaller DiT-L backbone.
\\ ( https://arxiv.org/abs/2511.19065 ,  725kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19067
Date: Mon, 24 Nov 2025 13:01:32 GMT   (1097kb)

Title: DynaMix: Generalizable Person Re-identification via Dynamic Relabeling
 and Mixed Data Sampling
Authors: Timur Mamedov, Anton Konushin, Vadim Konushin
Categories: cs.CV cs.AI cs.LG
\\
 Generalizable person re-identification (Re-ID) aims to recognize individuals
across unseen cameras and environments. While existing methods rely heavily on
limited labeled multi-camera data, we propose DynaMix, a novel method that
effectively combines manually labeled multi-camera and large-scale
pseudo-labeled single-camera data. Unlike prior works, DynaMix dynamically
adapts to the structure and noise of the training data through three core
components: (1) a Relabeling Module that refines pseudo-labels of single-camera
identities on-the-fly; (2) an Efficient Centroids Module that maintains robust
identity representations under a large identity space; and (3) a Data Sampling
Module that carefully composes mixed data mini-batches to balance learning
complexity and intra-batch diversity. All components are specifically designed
to operate efficiently at scale, enabling effective training on millions of
images and hundreds of thousands of identities. Extensive experiments
demonstrate that DynaMix consistently outperforms state-of-the-art methods in
generalizable person Re-ID.
\\ ( https://arxiv.org/abs/2511.19067 ,  1097kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19071
Date: Mon, 24 Nov 2025 13:07:22 GMT   (8291kb)

Title: DEAP-3DSAM: Decoder Enhanced and Auto Prompt SAM for 3D Medical Image
 Segmentation
Authors: Fangda Chen, Jintao Tang, Pancheng Wang, Ting Wang, Shasha Li, Ting
 Deng
Categories: cs.CV
Comments: Accepted by BIBM 2024
\\
 The Segment Anything Model (SAM) has recently demonstrated significant
potential in medical image segmentation. Although SAM is primarily trained on
2D images, attempts have been made to apply it to 3D medical image
segmentation. However, the pseudo 3D processing used to adapt SAM results in
spatial feature loss, limiting its performance. Additionally, most SAM-based
methods still rely on manual prompts, which are challenging to implement in
real-world scenarios and require extensive external expert knowledge. To
address these limitations, we introduce the Decoder Enhanced and Auto Prompt
SAM (DEAP-3DSAM) to tackle these limitations. Specifically, we propose a
Feature Enhanced Decoder that fuses the original image features with rich and
detailed spatial information to enhance spatial features. We also design a Dual
Attention Prompter to automatically obtain prompt information through Spatial
Attention and Channel Attention. We conduct comprehensive experiments on four
public abdominal tumor segmentation datasets. The results indicate that our
DEAP-3DSAM achieves state-of-the-art performance in 3D image segmentation,
outperforming or matching existing manual prompt methods. Furthermore, both
quantitative and qualitative ablation studies confirm the effectiveness of our
proposed modules.
\\ ( https://arxiv.org/abs/2511.19071 ,  8291kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19105
Date: Mon, 24 Nov 2025 13:40:26 GMT   (2276kb)

Title: Graph-based 3D Human Pose Estimation using WiFi Signals
Authors: Jichao Chen, YangYang Qu, Ruibo Tang, Dirk Slock
Categories: cs.CV
\\
 WiFi-based human pose estimation (HPE) has attracted increasing attention due
to its resilience to occlusion and privacy-preserving compared to camera-based
methods. However, existing WiFi-based HPE approaches often employ regression
networks that directly map WiFi channel state information (CSI) to 3D joint
coordinates, ignoring the inherent topological relationships among human
joints. In this paper, we present GraphPose-Fi, a graph-based framework that
explicitly models skeletal topology for WiFi-based 3D HPE. Our framework
comprises a CNN encoder shared across antennas for subcarrier-time feature
extraction, a lightweight attention module that adaptively reweights features
over time and across antennas, and a graph-based regression head that combines
GCN layers with self-attention to capture local topology and global
dependencies. Our proposed method significantly outperforms existing methods on
the MM-Fi dataset in various settings. The source code is available at:
https://github.com/Cirrick/GraphPose-Fi.
\\ ( https://arxiv.org/abs/2511.19105 ,  2276kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19109
Date: Mon, 24 Nov 2025 13:43:39 GMT   (19706kb)

Title: HABIT: Human Action Benchmark for Interactive Traffic in CARLA
Authors: Mohan Ramesh, Mark Azer and Fabian B. Flohr
Categories: cs.CV
Comments: Accepted to WACV 2026. This is the pre-camera-ready version
\\
 Current autonomous driving (AD) simulations are critically limited by their
inadequate representation of realistic and diverse human behavior, which is
essential for ensuring safety and reliability. Existing benchmarks often
simplify pedestrian interactions, failing to capture complex, dynamic
intentions and varied responses critical for robust system deployment. To
overcome this, we introduce HABIT (Human Action Benchmark for Interactive
Traffic), a high-fidelity simulation benchmark. HABIT integrates real-world
human motion, sourced from mocap and videos, into CARLA (Car Learning to Act, a
full autonomous driving simulator) via a modular, extensible, and physically
consistent motion retargeting pipeline. From an initial pool of approximately
30,000 retargeted motions, we curate 4,730 traffic-compatible pedestrian
motions, standardized in SMPL format for physically consistent trajectories.
HABIT seamlessly integrates with CARLA's Leaderboard, enabling automated
scenario generation and rigorous agent evaluation. Our safety metrics,
including Abbreviated Injury Scale (AIS) and False Positive Braking Rate
(FPBR), reveal critical failure modes in state-of-the-art AD agents missed by
prior evaluations. Evaluating three state-of-the-art autonomous driving agents,
InterFuser, TransFuser, and BEVDriver, demonstrates how HABIT exposes planner
weaknesses that remain hidden in scripted simulations. Despite achieving close
or equal to zero collisions per kilometer on the CARLA Leaderboard, the
autonomous agents perform notably worse on HABIT, with up to 7.43 collisions/km
and a 12.94% AIS 3+ injury risk, and they brake unnecessarily in up to 33% of
cases. All components are publicly released to support reproducible,
pedestrian-aware AI research.
\\ ( https://arxiv.org/abs/2511.19109 ,  19706kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19111
Date: Mon, 24 Nov 2025 13:43:54 GMT   (3427kb)

Title: DiffSeg30k: A Multi-Turn Diffusion Editing Benchmark for Localized AIGC
 Detection
Authors: Hai Ci, Ziheng Peng, Pei Yang, Yingxin Xuan, Mike Zheng Shou
Categories: cs.CV
Comments: 16 pages, 10 figures
\\
 Diffusion-based editing enables realistic modification of local image
regions, making AI-generated content harder to detect. Existing AIGC detection
benchmarks focus on classifying entire images, overlooking the localization of
diffusion-based edits. We introduce DiffSeg30k, a publicly available dataset of
30k diffusion-edited images with pixel-level annotations, designed to support
fine-grained detection. DiffSeg30k features: 1) In-the-wild images--we collect
images or image prompts from COCO to reflect real-world content diversity; 2)
Diverse diffusion models--local edits using eight SOTA diffusion models; 3)
Multi-turn editing--each image undergoes up to three sequential edits to mimic
real-world sequential editing; and 4) Realistic editing scenarios--a
vision-language model (VLM)-based pipeline automatically identifies meaningful
regions and generates context-aware prompts covering additions, removals, and
attribute changes. DiffSeg30k shifts AIGC detection from binary classification
to semantic segmentation, enabling simultaneous localization of edits and
identification of the editing models. We benchmark three baseline segmentation
approaches, revealing significant challenges in semantic segmentation tasks,
particularly concerning robustness to image distortions. Experiments also
reveal that segmentation models, despite being trained for pixel-level
localization, emerge as highly reliable whole-image classifiers of diffusion
edits, outperforming established forgery classifiers while showing great
potential in cross-generator generalization. We believe DiffSeg30k will advance
research in fine-grained localization of AI-generated content by demonstrating
the promise and limitations of segmentation-based methods. DiffSeg30k is
released at: https://huggingface.co/datasets/Chaos2629/Diffseg30k
\\ ( https://arxiv.org/abs/2511.19111 ,  3427kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19117
Date: Mon, 24 Nov 2025 13:48:47 GMT   (4694kb)

Title: 3M-TI: High-Quality Mobile Thermal Imaging via Calibration-free
 Multi-Camera Cross-Modal Diffusion
Authors: Minchong Chen, Xiaoyun Yuan, Junzhe Wan, Jianing Zhang, Jun Zhang
Categories: cs.CV physics.optics
Comments: 11 pages, 7 figures
\\
 The miniaturization of thermal sensors for mobile platforms inherently limits
their spatial resolution and textural fidelity, leading to blurry and less
informative images. Existing thermal super-resolution (SR) methods can be
grouped into single-image and RGB-guided approaches: the former struggles to
recover fine structures from limited information, while the latter relies on
accurate and laborious cross-camera calibration, which hinders practical
deployment and robustness. Here, we propose 3M-TI, a calibration-free
Multi-camera cross-Modality diffusion framework for Mobile Thermal Imaging. At
its core, 3M-TI integrates a cross-modal self-attention module (CSM) into the
diffusion UNet, replacing the original self-attention layers to adaptively
align thermal and RGB features throughout the denoising process, without
requiring explicit camera calibration. This design enables the diffusion
network to leverage its generative prior to enhance spatial resolution,
structural fidelity, and texture detail in the super-resolved thermal images.
Extensive evaluations on real-world mobile thermal cameras and public
benchmarks validate our superior performance, achieving state-of-the-art
results in both visual quality and quantitative metrics. More importantly, the
thermal images enhanced by 3M-TI lead to substantial gains in critical
downstream tasks like object detection and segmentation, underscoring its
practical value for robust mobile thermal perception systems. More materials:
https://github.com/work-submit/3MTI.
\\ ( https://arxiv.org/abs/2511.19117 ,  4694kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19119
Date: Mon, 24 Nov 2025 13:49:17 GMT   (19748kb)

Title: MonoSR: Open-Vocabulary Spatial Reasoning from Monocular Images
Authors: Qirui Wang, Jingyi He, Yining Pan, Si Yong Yeo, Xulei Yang, Shijie Li
Categories: cs.CV
\\
 Spatial reasoning (SR), the ability to infer 3D spatial information from 2D
inputs, is essential for real-world applications such as embodied AI and
autonomous driving. However, existing research primarily focuses on indoor
environments and typically relies on multi-view observations, which limits
their generalizability to outdoor scenarios and constrains their applicability
to monocular images, the most common real-world setting. In this work, we
propose MonoSR, a large-scale monocular spatial reasoning dataset that spans
diverse scenarios including indoor, outdoor, and object-centric settings, and
supports multiple question types. MonoSR provides a path toward open-world
monocular spatial reasoning. Beyond introducing the dataset, we evaluate
advanced vision-language models to reveal their limitations on this challenging
task. We further analyze whether auxiliary information is crucial for monocular
spatial reasoning and offer practical guidance for designing future models.
These contributions collectively establish a foundation for advancing monocular
spatial reasoning in real-world, open-world environments.
\\ ( https://arxiv.org/abs/2511.19119 ,  19748kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19126
Date: Mon, 24 Nov 2025 13:54:00 GMT   (8665kb)

Title: When Semantics Regulate: Rethinking Patch Shuffle and Internal Bias for
 Generated Image Detection with CLIP
Authors: Beilin Chu, Weike You, Mengtao Li, Tingting Zheng, Kehan Zhao, Xuan
 Xu, Zhigao Lu, Jia Song, Moxuan Xu, Linna Zhou
Categories: cs.CV
Comments: 14 pages, 7 figures and 7 tables
\\
 The rapid progress of GANs and Diffusion Models poses new challenges for
detecting AI-generated images. Although CLIP-based detectors exhibit promising
generalization, they often rely on semantic cues rather than generator
artifacts, leading to brittle performance under distribution shifts. In this
work, we revisit the nature of semantic bias and uncover that Patch Shuffle
provides an unusually strong benefit for CLIP, that disrupts global semantic
continuity while preserving local artifact cues, which reduces semantic entropy
and homogenizes feature distributions between natural and synthetic images.
Through a detailed layer-wise analysis, we further show that CLIP's deep
semantic structure functions as a regulator that stabilizes cross-domain
representations once semantic bias is suppressed. Guided by these findings, we
propose SemAnti, a semantic-antagonistic fine-tuning paradigm that freezes the
semantic subspace and adapts only artifact-sensitive layers under shuffled
semantics. Despite its simplicity, SemAnti achieves state-of-the-art
cross-domain generalization on AIGCDetectBenchmark and GenImage, demonstrating
that regulating semantics is key to unlocking CLIP's full potential for robust
AI-generated image detection.
\\ ( https://arxiv.org/abs/2511.19126 ,  8665kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19134
Date: Mon, 24 Nov 2025 13:59:01 GMT   (2782kb)

Title: MambaRefine-YOLO: A Dual-Modality Small Object Detector for UAV Imagery
Authors: Shuyu Cao, Minxin Chen, Yucheng Song, Zhaozhong Chen, Xinyou Zhang
Categories: cs.CV
Comments: Submitted to IEEE Geoscience and Remote Sensing Letters
\\
 Small object detection in Unmanned Aerial Vehicle (UAV) imagery is a
persistent challenge, hindered by low resolution and background clutter. While
fusing RGB and infrared (IR) data offers a promising solution, existing methods
often struggle with the trade-off between effective cross-modal interaction and
computational efficiency. In this letter, we introduce MambaRefine-YOLO. Its
core contributions are a Dual-Gated Complementary Mamba fusion module (DGC-MFM)
that adaptively balances RGB and IR modalities through illumination-aware and
difference-aware gating mechanisms, and a Hierarchical Feature Aggregation Neck
(HFAN) that uses a ``refine-then-fuse'' strategy to enhance multi-scale
features. Our comprehensive experiments validate this dual-pronged approach. On
the dual-modality DroneVehicle dataset, the full model achieves a
state-of-the-art mAP of 83.2%, an improvement of 7.9% over the baseline. On the
single-modality VisDrone dataset, a variant using only the HFAN also shows
significant gains, demonstrating its general applicability. Our work presents a
superior balance between accuracy and speed, making it highly suitable for
real-world UAV applications.
\\ ( https://arxiv.org/abs/2511.19134 ,  2782kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19137
Date: Mon, 24 Nov 2025 14:00:40 GMT   (6091kb)

Title: FilmSceneDesigner: Chaining Set Design for Procedural Film Scene
 Generation
Authors: Zhifeng Xie, Keyi Zhang, Yiye Yan, Yuling Guo, Fan Yang, Jiting Zhou,
 Mengtian Li
Categories: cs.CV
\\
 Film set design plays a pivotal role in cinematic storytelling and shaping
the visual atmosphere. However, the traditional process depends on
expert-driven manual modeling, which is labor-intensive and time-consuming. To
address this issue, we introduce FilmSceneDesigner, an automated scene
generation system that emulates professional film set design workflow. Given a
natural language description, including scene type, historical period, and
style, we design an agent-based chaining framework to generate structured
parameters aligned with film set design workflow, guided by prompt strategies
that ensure parameter accuracy and coherence. On the other hand, we propose a
procedural generation pipeline which executes a series of dedicated functions
with the structured parameters for floorplan and structure generation, material
assignment, door and window placement, and object retrieval and layout,
ultimately constructing a complete film scene from scratch. Moreover, to
enhance cinematic realism and asset diversity, we construct SetDepot-Pro, a
curated dataset of 6,862 film-specific 3D assets and 733 materials.
Experimental results and human evaluations demonstrate that our system produces
structurally sound scenes with strong cinematic fidelity, supporting downstream
tasks such as virtual previs, construction drawing and mood board creation.
\\ ( https://arxiv.org/abs/2511.19137 ,  6091kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19145
Date: Mon, 24 Nov 2025 14:09:42 GMT   (1787kb)

Title: ABM-LoRA: Activation Boundary Matching for Fast Convergence in Low-Rank
 Adaptation
Authors: Dongha Lee, Jinhee Park, Minjun Kim, Junseok Kwon
Categories: cs.CV
Comments: 16 pages, 5 figures, under review
\\
 We propose Activation Boundary Matching for Low-Rank Adaptation (ABM-LoRA), a
principled initialization strategy that substantially accelerates the
convergence of low-rank adapters. While LoRA offers high parameter efficiency,
its random initialization restricts gradient updates to a mismatched tangent
space, causing significant information loss and hindering early convergence.
Our ABM-LoRA addresses this by aligning the adapter's activation boundaries
with those of the pretrained model before downstream training, thereby
maximizing the projection of full-parameter gradients into the adapter
subspace. This alignment sharply reduces information loss at initialization,
yields a lower starting loss, and accelerates convergence. We demonstrate
ABM-LoRA's effectiveness across diverse architectures and tasks: language
understanding (T5-Base on GLUE), dialogue generation (LLaMA2-7B on WizardLM),
and vision recognition (ViT-B/16 on VTAB-1K). On VTAB-1K, it achieves the
highest accuracy among all methods, with strong gains on structured reasoning
tasks requiring geometric understanding.
\\ ( https://arxiv.org/abs/2511.19145 ,  1787kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19147
Date: Mon, 24 Nov 2025 14:12:22 GMT   (1504kb)

Title: Collaborative Learning with Multiple Foundation Models for Source-Free
 Domain Adaptation
Authors: Huisoo Lee, Jisu Han, Hyunsouk Cho, Wonjun Hwang
Categories: cs.CV cs.LG
Comments: 15 pages, 8 figures
\\
 Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained source model
to an unlabeled target domain without access to source data. Recent advances in
Foundation Models (FMs) have introduced new opportunities for leveraging
external semantic knowledge to guide SFDA. However, relying on a single FM is
often insufficient, as it tends to bias adaptation toward a restricted semantic
coverage, failing to capture diverse contextual cues under domain shift. To
overcome this limitation, we propose a Collaborative Multi-foundation
Adaptation (CoMA) framework that jointly leverages two different FMs (e.g.,
CLIP and BLIP) with complementary properties to capture both global semantics
and local contextual cues. Specifically, we employ a bidirectional adaptation
mechanism that (1) aligns different FMs with the target model for task
adaptation while maintaining their semantic distinctiveness, and (2) transfers
complementary knowledge from the FMs to the target model. To ensure stable
adaptation under mini-batch training, we introduce Decomposed Mutual
Information (DMI) that selectively enhances true dependencies while suppressing
false dependencies arising from incomplete class coverage. Extensive
experiments demonstrate that our method consistently outperforms existing
state-of-the-art SFDA methods across four benchmarks, including Office-31,
Office-Home, DomainNet-126, and VisDA, under the closed-set setting, while also
achieving best results on partial-set and open-set variants.
\\ ( https://arxiv.org/abs/2511.19147 ,  1504kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19149
Date: Mon, 24 Nov 2025 14:13:57 GMT   (1202kb)

Title: From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag
 Generation
Authors: Moazzam Umer Gondal, Hamad Ul Qudous, Daniya Siddiqui, Asma Ahmad
 Farhan
Categories: cs.CV cs.AI cs.CL
Comments: Submitted to Expert Systems with Applications
\\
 This paper introduces the retrieval-augmented framework for automatic fashion
caption and hashtag generation, combining multi-garment detection, attribute
reasoning, and Large Language Model (LLM) prompting. The system aims to produce
visually grounded, descriptive, and stylistically interesting text for fashion
imagery, overcoming the limitations of end-to-end captioners that have problems
with attribute fidelity and domain generalization. The pipeline combines a
YOLO-based detector for multi-garment localization, k-means clustering for
dominant color extraction, and a CLIP-FAISS retrieval module for fabric and
gender attribute inference based on a structured product index. These
attributes, together with retrieved style examples, create a factual evidence
pack that is used to guide an LLM to generate human-like captions and
contextually rich hashtags. A fine-tuned BLIP model is used as a supervised
baseline model for comparison. Experimental results show that the YOLO detector
is able to obtain a mean Average Precision (mAP@0.5) of 0.71 for nine
categories of garments. The RAG-LLM pipeline generates expressive
attribute-aligned captions and achieves mean attribute coverage of 0.80 with
full coverage at the 50% threshold in hashtag generation, whereas BLIP gives
higher lexical overlap and lower generalization. The retrieval-augmented
approach exhibits better factual grounding, less hallucination, and great
potential for scalable deployment in various clothing domains. These results
demonstrate the use of retrieval-augmented generation as an effective and
interpretable paradigm for automated and visually grounded fashion content
generation.
\\ ( https://arxiv.org/abs/2511.19149 ,  1202kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19169
Date: Mon, 24 Nov 2025 14:32:27 GMT   (5832kb)

Title: Test-Time Preference Optimization for Image Restoration
Authors: Bingchen Li, Xin Li, Jiaqi Xu, Jiaming Guo, Wenbo Li, Renjing Pei,
 Zhibo Chen
Categories: cs.CV
Comments: Accepted by AAAI26
\\
 Image restoration (IR) models are typically trained to recover high-quality
images using L1 or LPIPS loss. To handle diverse unknown degradations,
zero-shot IR methods have also been introduced. However, existing pre-trained
and zero-shot IR approaches often fail to align with human preferences,
resulting in restored images that may not be favored. This highlights the
critical need to enhance restoration quality and adapt flexibly to various
image restoration tasks or backbones without requiring model retraining and
ideally without labor-intensive preference data collection. In this paper, we
propose the first Test-Time Preference Optimization (TTPO) paradigm for image
restoration, which enhances perceptual quality, generates preference data
on-the-fly, and is compatible with any IR model backbone. Specifically, we
design a training-free, three-stage pipeline: (i) generate candidate preference
images online using diffusion inversion and denoising based on the initially
restored image; (ii) select preferred and dispreferred images using automated
preference-aligned metrics or human feedback; and (iii) use the selected
preference images as reward signals to guide the diffusion denoising process,
optimizing the restored image to better align with human preferences. Extensive
experiments across various image restoration tasks and models demonstrate the
effectiveness and flexibility of the proposed pipeline.
\\ ( https://arxiv.org/abs/2511.19169 ,  5832kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19172
Date: Mon, 24 Nov 2025 14:34:19 GMT   (36265kb)

Title: MetroGS: Efficient and Stable Reconstruction of Geometrically Accurate
 High-Fidelity Large-Scale Scenes
Authors: Kehua Chen, Tianlu Mao, Zhuxin Ma, Hao Jiang, Zehao Li, Zihan Liu,
 Shuqi Gao, Honglong Zhao, Feng Dai, Yucheng Zhang, Zhaoqi Wang
Categories: cs.CV
Comments: Project page: https://m3phist0.github.io/MetroGS
\\
 Recently, 3D Gaussian Splatting and its derivatives have achieved significant
breakthroughs in large-scale scene reconstruction. However, how to efficiently
and stably achieve high-quality geometric fidelity remains a core challenge. To
address this issue, we introduce MetroGS, a novel Gaussian Splatting framework
for efficient and robust reconstruction in complex urban environments. Our
method is built upon a distributed 2D Gaussian Splatting representation as the
core foundation, serving as a unified backbone for subsequent modules. To
handle potential sparse regions in complex scenes, we propose a structured
dense enhancement scheme that utilizes SfM priors and a pointmap model to
achieve a denser initialization, while incorporating a sparsity compensation
mechanism to improve reconstruction completeness. Furthermore, we design a
progressive hybrid geometric optimization strategy that organically integrates
monocular and multi-view optimization to achieve efficient and accurate
geometric refinement. Finally, to address the appearance inconsistency commonly
observed in large-scale scenes, we introduce a depth-guided appearance modeling
approach that learns spatial features with 3D consistency, facilitating
effective decoupling between geometry and appearance and further enhancing
reconstruction stability. Experiments on large-scale urban datasets demonstrate
that MetroGS achieves superior geometric accuracy, rendering quality, offering
a unified solution for high-fidelity large-scale scene reconstruction.
\\ ( https://arxiv.org/abs/2511.19172 ,  36265kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19180
Date: Mon, 24 Nov 2025 14:42:44 GMT   (84kb)

Title: Evaluating Deep Learning and Traditional Approaches Used in Source
 Camera Identification
Authors: Mansur Ozaman
Categories: cs.CV
Comments: 4 figures
\\
 One of the most important tasks in computer vision is identifying the device
using which the image was taken, useful for facilitating further comprehensive
analysis of the image. This paper presents comparative analysis of three
techniques used in source camera identification (SCI): Photo Response
Non-Uniformity (PRNU), JPEG compression artifact analysis, and convolutional
neural networks (CNNs). It evaluates each method in terms of device
classification accuracy. Furthermore, the research discusses the possible
scientific development needed for the implementation of the methods in
real-life scenarios.
\\ ( https://arxiv.org/abs/2511.19180 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19183
Date: Mon, 24 Nov 2025 14:50:36 GMT   (26464kb)

Title: nnActive: A Framework for Evaluation of Active Learning in 3D Biomedical
 Segmentation
Authors: Carsten T. L\"uth, Jeremias Traub, Kim-Celine Kahl, Till J. Bungert,
 Lukas Klein, Lars Kr\"amer, Paul F. Jaeger, Fabian Isensee, Klaus Maier-Hein
Categories: cs.CV
Comments: Accepted at TMLR
\\
 Semantic segmentation is crucial for various biomedical applications, yet its
reliance on large annotated datasets presents a bottleneck due to the high cost
and specialized expertise required for manual labeling. Active Learning (AL)
aims to mitigate this challenge by querying only the most informative samples,
thereby reducing annotation effort. However, in the domain of 3D biomedical
imaging, there is no consensus on whether AL consistently outperforms Random
sampling. Four evaluation pitfalls hinder the current methodological
assessment. These are (1) restriction to too few datasets and annotation
budgets, (2) using 2D models on 3D images without partial annotations, (3)
Random baseline not being adapted to the task, and (4) measuring annotation
cost only in voxels. In this work, we introduce nnActive, an open-source AL
framework that overcomes these pitfalls by (1) means of a large scale study
spanning four biomedical imaging datasets and three label regimes, (2)
extending nnU-Net by using partial annotations for training with 3D patch-based
query selection, (3) proposing Foreground Aware Random sampling strategies
tackling the foreground-background class imbalance of medical images and (4)
propose the foreground efficiency metric, which captures the low annotation
cost of background-regions. We reveal the following findings: (A) while all AL
methods outperform standard Random sampling, none reliably surpasses an
improved Foreground Aware Random sampling; (B) benefits of AL depend on task
specific parameters; (C) Predictive Entropy is overall the best performing AL
method, but likely requires the most annotation effort; (D) AL performance can
be improved with more compute intensive design choices. As a holistic,
open-source framework, nnActive can serve as a catalyst for research and
application of AL in 3D biomedical imaging. Code is at:
https://github.com/MIC-DKFZ/nnActive
\\ ( https://arxiv.org/abs/2511.19183 ,  26464kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19187
Date: Mon, 24 Nov 2025 14:54:00 GMT   (813kb)

Title: SpectraNet: FFT-assisted Deep Learning Classifier for Deepfake Face
 Detection
Authors: Nithira Jayarathne, Naveen Basnayake, Keshawa Jayasundara, Pasindu
 Dodampegama, Praveen Wijesinghe, Hirushika Pelagewatta, Kavishka Abeywardana,
 Sandushan Ranaweera, Chamira Edussooriya
Categories: cs.CV cs.LG
Comments: 4 pages, 3 figures
ACM-class: I.4.9; I.2.10; I.2.6
\\
 Detecting deepfake images is crucial in combating misinformation. We present
a lightweight, generalizable binary classification model based on
EfficientNet-B6, fine-tuned with transformation techniques to address severe
class imbalances. By leveraging robust preprocessing, oversampling, and
optimization strategies, our model achieves high accuracy, stability, and
generalization. While incorporating Fourier transform-based phase and amplitude
features showed minimal impact, our proposed framework helps non-experts to
effectively identify deepfake images, making significant strides toward
accessible and reliable deepfake detection.
\\ ( https://arxiv.org/abs/2511.19187 ,  813kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19198
Date: Mon, 24 Nov 2025 15:07:45 GMT   (4942kb)

Title: Three-Dimensional Anatomical Data Generation Based on Artificial Neural
 Networks
Authors: Ann-Sophia M\"uller, Moonkwang Jeong, Meng Zhang, Jiyuan Tian,
 Arkadiusz Miernik, Stefanie Speidel, and Tian Qiu
Categories: cs.CV cs.RO
Comments: 6 pages, 4 figures, 1 table, IEEE International Conference on
 Intelligent Robots and Systems (IROS)
\\
 Surgical planning and training based on machine learning requires a large
amount of 3D anatomical models reconstructed from medical imaging, which is
currently one of the major bottlenecks. Obtaining these data from real patients
and during surgery is very demanding, if even possible, due to legal, ethical,
and technical challenges. It is especially difficult for soft tissue organs
with poor imaging contrast, such as the prostate. To overcome these challenges,
we present a novel workflow for automated 3D anatomical data generation using
data obtained from physical organ models. We additionally use a 3D Generative
Adversarial Network (GAN) to obtain a manifold of 3D models useful for other
downstream machine learning tasks that rely on 3D data. We demonstrate our
workflow using an artificial prostate model made of biomimetic hydrogels with
imaging contrast in multiple zones. This is used to physically simulate
endoscopic surgery. For evaluation and 3D data generation, we place it into a
customized ultrasound scanner that records the prostate before and after the
procedure. A neural network is trained to segment the recorded ultrasound
images, which outperforms conventional, non-learning-based computer vision
techniques in terms of intersection over union (IoU). Based on the
segmentations, a 3D mesh model is reconstructed, and performance feedback is
provided.
\\ ( https://arxiv.org/abs/2511.19198 ,  4942kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19199
Date: Mon, 24 Nov 2025 15:09:07 GMT   (6537kb)

Title: CLASH: A Benchmark for Cross-Modal Contradiction Detection
Authors: Teodora Popordanoska, Jiameng Li, Matthew B. Blaschko
Categories: cs.CV cs.AI cs.LG
Comments: First two authors contributed equally
\\
 Contradictory multimodal inputs are common in real-world settings, yet
existing benchmarks typically assume input consistency and fail to evaluate
cross-modal contradiction detection - a fundamental capability for preventing
hallucinations and ensuring reliability. We introduce CLASH, a novel benchmark
for multimodal contradiction detection, featuring COCO images paired with
contradictory captions containing controlled object-level or attribute-level
contradictions. The samples include targeted questions evaluated in both
multiple-choice and open-ended formats. The benchmark provides an extensive
fine-tuning set filtered through automated quality checks, alongside a smaller
human-verified diagnostic set. Our analysis of state-of-the-art models reveals
substantial limitations in recognizing cross-modal conflicts, exposing
systematic modality biases and category-specific weaknesses. Furthermore, we
empirically demonstrate that targeted fine-tuning on CLASH substantially
enhances conflict detection capabilities.
\\ ( https://arxiv.org/abs/2511.19199 ,  6537kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19200
Date: Mon, 24 Nov 2025 15:09:32 GMT   (1831kb)

Title: Can Modern Vision Models Understand the Difference Between an Object and
 a Look-alike?
Authors: Itay Cohen, Ethan Fetaya, Amir Rosenfeld
Categories: cs.CV
\\
 Recent advances in computer vision have yielded models with strong
performance on recognition benchmarks; however, significant gaps remain in
comparison to human perception. One subtle ability is to judge whether an image
looks like a given object without being an instance of that object. We study
whether vision-language models such as CLIP capture this distinction. We
curated a dataset named RoLA (Real or Lookalike) of real and lookalike
exemplars (e.g., toys, statues, drawings, pareidolia) across multiple
categories, and first evaluate a prompt-based baseline with paired
"real"/"lookalike" prompts. We then estimate a direction in CLIP's embedding
space that moves representations between real and lookalike. Applying this
direction to image and text embeddings improves discrimination in cross-modal
retrieval on Conceptual12M, and also enhances captions produced by a CLIP
prefix captioner.
\\ ( https://arxiv.org/abs/2511.19200 ,  1831kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19202
Date: Mon, 24 Nov 2025 15:11:12 GMT   (6980kb)

Title: NVGS: Neural Visibility for Occlusion Culling in 3D Gaussian Splatting
Authors: Brent Zoomers, Florian Hahlbohm, Joni Vanherck, Lode Jorissen, Marcus
 Magnor, Nick Michiels
Categories: cs.CV cs.GR
Comments: 15 pages, 13 figures
\\
 3D Gaussian Splatting can exploit frustum culling and level-of-detail
strategies to accelerate rendering of scenes containing a large number of
primitives. However, the semi-transparent nature of Gaussians prevents the
application of another highly effective technique: occlusion culling. We
address this limitation by proposing a novel method to learn the
viewpoint-dependent visibility function of all Gaussians in a trained model
using a small, shared MLP across instances of an asset in a scene. By querying
it for Gaussians within the viewing frustum prior to rasterization, our method
can discard occluded primitives during rendering. Leveraging Tensor Cores for
efficient computation, we integrate these neural queries directly into a novel
instanced software rasterizer. Our approach outperforms the current state of
the art for composed scenes in terms of VRAM usage and image quality, utilizing
a combination of our instanced rasterizer and occlusion culling MLP, and
exhibits complementary properties to existing LoD techniques.
\\ ( https://arxiv.org/abs/2511.19202 ,  6980kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19217
Date: Mon, 24 Nov 2025 15:23:36 GMT   (3411kb)

Title: ReAlign: Text-to-Motion Generation via Step-Aware Reward-Guided
 Alignment
Authors: Wanjiang Weng, Xiaofeng Tan, Junbo Wang, Guo-Sen Xie, Pan Zhou,
 Hongsong Wang
Categories: cs.CV
Comments: Accepted by AAAI 2026
\\
 Text-to-motion generation, which synthesizes 3D human motions from text
inputs, holds immense potential for applications in gaming, film, and robotics.
Recently, diffusion-based methods have been shown to generate more diversity
and realistic motion. However, there exists a misalignment between text and
motion distributions in diffusion models, which leads to semantically
inconsistent or low-quality motions. To address this limitation, we propose
Reward-guided sampling Alignment (ReAlign), comprising a step-aware reward
model to assess alignment quality during the denoising sampling and a
reward-guided strategy that directs the diffusion process toward an optimally
aligned distribution. This reward model integrates step-aware tokens and
combines a text-aligned module for semantic consistency and a motion-aligned
module for realism, refining noisy motions at each timestep to balance
probability density and alignment. Extensive experiments of both motion
generation and retrieval tasks demonstrate that our approach significantly
improves text-motion alignment and motion quality compared to existing
state-of-the-art methods.
\\ ( https://arxiv.org/abs/2511.19217 ,  3411kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19220
Date: Mon, 24 Nov 2025 15:26:58 GMT   (3532kb)

Title: Are Large Vision Language Models Truly Grounded in Medical Images?
 Evidence from Italian Clinical Visual Question Answering
Authors: Federico Felizzi, Olivia Riccomi, Michele Ferramola, Francesco Andrea
 Causio, Manuel Del Medico, Vittorio De Vita, Lorenzo De Mori, Alessandra
 Piscitelli Pietro Eric Risuleo, Bianca Destro Castaniti, Antonio Cristiano
 Alessia Longo, Luigi De Angelis, Mariapia Vassalli, Marcello Di Pumpo
Categories: cs.CV cs.AI
Comments: Accepted at the Workshop on Multimodal Representation Learning for
 Healthcare (MMRL4H), EurIPS 2025
\\
 Large vision language models (VLMs) have achieved impressive performance on
medical visual question answering benchmarks, yet their reliance on visual
information remains unclear. We investigate whether frontier VLMs demonstrate
genuine visual grounding when answering Italian medical questions by testing
four state-of-the-art models: Claude Sonnet 4.5, GPT-4o, GPT-5-mini, and Gemini
2.0 flash exp. Using 60 questions from the EuropeMedQA Italian dataset that
explicitly require image interpretation, we substitute correct medical images
with blank placeholders to test whether models truly integrate visual and
textual information. Our results reveal striking variability in visual
dependency: GPT-4o shows the strongest visual grounding with a 27.9pp accuracy
drop (83.2% [74.6%, 91.7%] to 55.3% [44.1%, 66.6%]), while GPT-5-mini, Gemini,
and Claude maintain high accuracy with modest drops of 8.5pp, 2.4pp, and 5.6pp
respectively. Analysis of model-generated reasoning reveals confident
explanations for fabricated visual interpretations across all models,
suggesting varying degrees of reliance on textual shortcuts versus genuine
visual analysis. These findings highlight critical differences in model
robustness and the need for rigorous evaluation before clinical deployment.
\\ ( https://arxiv.org/abs/2511.19220 ,  3532kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19221
Date: Mon, 24 Nov 2025 15:28:25 GMT   (37060kb)

Title: Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust
 End-to-End Autonomous Driving
Authors: Jianhua Han, Meng Tian, Jiangtong Zhu, Fan He, Huixin Zhang, Sitong
 Guo, Dechang Zhu, Hao Tang, Pei Xu, Yuze Guo, Minzhe Niu, Haojie Zhu, Qichao
 Dong, Xuechao Yan, Siyuan Dong, Lu Hou, Qingqiu Huang, Xiaosong Jia, Hang Xu
Categories: cs.CV
\\
 Autonomous driving heavily relies on accurate and robust spatial perception.
Many failures arise from inaccuracies and instability, especially in long-tail
scenarios and complex interactions. However, current vision-language models are
weak at spatial grounding and understanding, and VLA systems built on them
therefore show limited perception and localization ability. To address these
challenges, we introduce Percept-WAM, a perception-enhanced
World-Awareness-Action Model that is the first to implicitly integrate 2D/3D
scene understanding abilities within a single vision-language model (VLM).
Instead of relying on QA-style spatial reasoning, Percept-WAM unifies 2D/3D
perception tasks into World-PV and World-BEV tokens, which encode both spatial
coordinates and confidence. We propose a grid-conditioned prediction mechanism
for dense object perception, incorporating IoU-aware scoring and parallel
autoregressive decoding, improving stability in long-tail, far-range, and
small-object scenarios. Additionally, Percept-WAM leverages pretrained VLM
parameters to retain general intelligence (e.g., logical reasoning) and can
output perception results and trajectory control outputs directly. Experiments
show that Percept-WAM matches or surpasses classical detectors and segmenters
on downstream perception benchmarks, achieving 51.7/58.9 mAP on COCO 2D
detection and nuScenes BEV 3D detection. When integrated with trajectory
decoders, it further improves planning performance on nuScenes and NAVSIM,
e.g., surpassing DiffusionDrive by 2.1 in PMDS on NAVSIM. Qualitative results
further highlight its strong open-vocabulary and long-tail generalization.
\\ ( https://arxiv.org/abs/2511.19221 ,  37060kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19229
Date: Mon, 24 Nov 2025 15:42:23 GMT   (28128kb)

Title: Learning Plug-and-play Memory for Guiding Video Diffusion Models
Authors: Selena Song, Ziming Xu, Zijun Zhang, Kun Zhou, Jiaxian Guo, Lianhui
 Qin, Biwei Huang
Categories: cs.CV cs.AI
\\
 Diffusion Transformer(DiT) based video generation models have recently
achieved impressive visual quality and temporal coherence, but they still
frequently violate basic physical laws and commonsense dynamics, revealing a
lack of explicit world knowledge. In this work, we explore how to equip them
with a plug-and-play memory that injects useful world knowledge. Motivated by
in-context memory in Transformer-based LLMs, we conduct empirical studies to
show that DiT can be steered via interventions on its hidden states, and simple
low-pass and high-pass filters in the embedding space naturally disentangle
low-level appearance and high-level physical/semantic cues, enabling targeted
guidance. Building on these observations, we propose a learnable memory encoder
DiT-Mem, composed of stacked 3D CNNs, low-/high-pass filters, and
self-attention layers. The encoder maps reference videos into a compact set of
memory tokens, which are concatenated as the memory within the DiT
self-attention layers. During training, we keep the diffusion backbone frozen,
and only optimize the memory encoder. It yields a rather efficient training
process on few training parameters (150M) and 10K data samples, and enables
plug-and-play usage at inference time. Extensive experiments on
state-of-the-art models demonstrate the effectiveness of our method in
improving physical rule following and video fidelity. Our code and data are
publicly released here: https://thrcle421.github.io/DiT-Mem-Web/.
\\ ( https://arxiv.org/abs/2511.19229 ,  28128kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19235
Date: Mon, 24 Nov 2025 15:48:08 GMT   (17577kb)

Title: IDSplat: Instance-Decomposed 3D Gaussian Splatting for Driving Scenes
Authors: Carl Lindstr\"om, Mahan Rafidashti, Maryam Fatemi, Lars Hammarstrand,
 Martin R. Oswald, Lennart Svensson
Categories: cs.CV
\\
 Reconstructing dynamic driving scenes is essential for developing autonomous
systems through sensor-realistic simulation. Although recent methods achieve
high-fidelity reconstructions, they either rely on costly human annotations for
object trajectories or use time-varying representations without explicit
object-level decomposition, leading to intertwined static and dynamic elements
that hinder scene separation. We present IDSplat, a self-supervised 3D Gaussian
Splatting framework that reconstructs dynamic scenes with explicit instance
decomposition and learnable motion trajectories, without requiring human
annotations. Our key insight is to model dynamic objects as coherent instances
undergoing rigid transformations, rather than unstructured time-varying
primitives. For instance decomposition, we employ zero-shot, language-grounded
video tracking anchored to 3D using lidar, and estimate consistent poses via
feature correspondences. We introduce a coordinated-turn smoothing scheme to
obtain temporally and physically consistent motion trajectories, mitigating
pose misalignments and tracking failures, followed by joint optimization of
object poses and Gaussian parameters. Experiments on the Waymo Open Dataset
demonstrate that our method achieves competitive reconstruction quality while
maintaining instance-level decomposition and generalizes across diverse
sequences and view densities without retraining, making it practical for
large-scale autonomous driving applications. Code will be released.
\\ ( https://arxiv.org/abs/2511.19235 ,  17577kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19254
Date: Mon, 24 Nov 2025 16:05:40 GMT   (16153kb)

Title: Adversarial Patch Attacks on Vision-Based Cargo Occupancy Estimation via
 Differentiable 3D Simulation
Authors: Mohamed Rissal Hedna, Sesugh Samuel Nder
Categories: cs.CV cs.AI
Comments: 9 pages, 5 figures, 1 algorithm
MSC-class: 68T07, 68T45, 68U05
ACM-class: I.2.6; I.4.8; I.3.7; D.4.6
\\
 Computer vision systems are increasingly adopted in modern logistics
operations, including the estimation of trailer occupancy for planning,
routing, and billing. Although effective, such systems may be vulnerable to
physical adversarial attacks, particularly adversarial patches that can be
printed and placed on interior surfaces. In this work, we study the feasibility
of such attacks on a convolutional cargo-occupancy classifier using fully
simulated 3D environments. Using Mitsuba 3 for differentiable rendering, we
optimize patch textures across variations in geometry, lighting, and viewpoint,
and compare their effectiveness to a 2D compositing baseline. Our experiments
demonstrate that 3D-optimized patches achieve high attack success rates,
especially in a denial-of-service scenario (empty to full), where success
reaches 84.94 percent. Concealment attacks (full to empty) prove more
challenging but still reach 30.32 percent. We analyze the factors influencing
attack success, discuss implications for the security of automated logistics
pipelines, and highlight directions for strengthening physical robustness. To
our knowledge, this is the first study to investigate adversarial patch attacks
for cargo-occupancy estimation in physically realistic, fully simulated 3D
scenes.
\\ ( https://arxiv.org/abs/2511.19254 ,  16153kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19261
Date: Mon, 24 Nov 2025 16:13:26 GMT   (1019kb)

Title: LAST: LeArning to Think in Space and Time for Generalist Vision-Language
 Models
Authors: Shuai Wang, Daoan Zhang, Tianyi Bai, Shitong Shao, Jiebo Luo, Jiaheng
 Wei
Categories: cs.CV
\\
 Humans can perceive and understand 3D space and long videos from sequential
visual observations. But do vision-language models (VLMs) can? Recent work
demonstrates that even state-of-the-art VLMs still struggle to understand 3D
space and long videos, although they are powerful in typical vision-language
tasks. Current methods often rely on specialized architectural designs to
improve performance for 3D tasks and video understanding tasks separately. In
contrast, we propose LAST, short for LeArn to Think in Space and Time, to
jointly improve 3D spatial and long video understanding for general VLMs with
only a set of 2D images as inputs. LAST makes VLMs think in space and time
rather than only with text before giving the final answer, building visual
thinking trajectories in 3D space and temporal dimension. We demonstrate the
effectiveness of LAST in two scenarios: 1) zero-shot, where we directly prompt
proprietary models; and 2) fine-tuning general VLMs with data that include
thinking trajectories in 3D space and time. We show that LAST brings
substantial gains in various benchmarks, including 3 spatial understanding, 4
video understanding, and 3 image understanding tasks. Notably, 15.8% gains on
EgoSchema with GPT-4o in a zero-shot manner and 8.3 gains on VSI-Bench compared
with Qwen2.5-VL-7B.
\\ ( https://arxiv.org/abs/2511.19261 ,  1019kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19268
Date: Mon, 24 Nov 2025 16:20:11 GMT   (17507kb)

Title: BideDPO: Conditional Image Generation with Simultaneous Text and
 Condition Alignment
Authors: Dewei Zhou, Mingwei Li, Zongxin Yang, Yu Lu, Yunqiu Xu, Zhizhong Wang,
 Zeyi Huang, Yi Yang
Categories: cs.CV
Comments: 29 pages
\\
 Conditional image generation enhances text-to-image synthesis with
structural, spatial, or stylistic priors, but current methods face challenges
in handling conflicts between sources. These include 1) input-level conflicts,
where the conditioning image contradicts the text prompt, and 2) model-bias
conflicts, where generative biases disrupt alignment even when conditions match
the text. Addressing these conflicts requires nuanced solutions, which standard
supervised fine-tuning struggles to provide. Preference-based optimization
techniques like Direct Preference Optimization (DPO) show promise but are
limited by gradient entanglement between text and condition signals and lack
disentangled training data for multi-constraint tasks. To overcome this, we
propose a bidirectionally decoupled DPO framework (BideDPO). Our method creates
two disentangled preference pairs-one for the condition and one for the text-to
reduce gradient entanglement. The influence of pairs is managed using an
Adaptive Loss Balancing strategy for balanced optimization. We introduce an
automated data pipeline to sample model outputs and generate conflict-aware
data. This process is embedded in an iterative optimization strategy that
refines both the model and the data. We construct a DualAlign benchmark to
evaluate conflict resolution between text and condition. Experiments show
BideDPO significantly improves text success rates (e.g., +35%) and condition
adherence. We also validate our approach using the COCO dataset. Project Pages:
https://limuloo.github.io/BideDPO/.
\\ ( https://arxiv.org/abs/2511.19268 ,  17507kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19274
Date: Mon, 24 Nov 2025 16:25:34 GMT   (6841kb)

Title: Diffusion Reconstruction-based Data Likelihood Estimation for Core-Set
 Selection
Authors: Mingyang Chen, Jiawei Du, Bo Huang, Yi Wang, Xiaobo Zhang, Wei Wang
Categories: cs.CV
Comments: Accepted by AAAI 2026
\\
 Existing core-set selection methods predominantly rely on heuristic scoring
signals such as training dynamics or model uncertainty, lacking explicit
modeling of data likelihood. This omission may hinder the constructed subset
from capturing subtle yet critical distributional structures that underpin
effective model training. In this work, we propose a novel, theoretically
grounded approach that leverages diffusion models to estimate data likelihood
via reconstruction deviation induced by partial reverse denoising.
Specifically, we establish a formal connection between reconstruction error and
data likelihood, grounded in the Evidence Lower Bound (ELBO) of Markovian
diffusion processes, thereby enabling a principled, distribution-aware scoring
criterion for data selection. Complementarily, we introduce an efficient
information-theoretic method to identify the optimal reconstruction timestep,
ensuring that the deviation provides a reliable signal indicative of underlying
data likelihood. Extensive experiments on ImageNet demonstrate that
reconstruction deviation offers an effective scoring criterion, consistently
outperforming existing baselines across selection ratios, and closely matching
full-data training using only 50% of the data. Further analysis shows that the
likelihood-informed nature of our score reveals informative insights in data
selection, shedding light on the interplay between data distributional
characteristics and model learning preferences.
\\ ( https://arxiv.org/abs/2511.19274 ,  6841kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19278
Date: Mon, 24 Nov 2025 16:28:49 GMT   (5357kb)

Title: ReMatch: Boosting Representation through Matching for Multimodal
 Retrieval
Authors: Qianying Liu, Xiao Liang, Zhiqiang Zhang, Yibo Chen, Xu Tang, Zhongfei
 Qing, Fengfan Zhou, Yao Hu, Paul Henderson
Categories: cs.CV
\\
 We present ReMatch, a framework that leverages the generative strength of
MLLMs for multimodal retrieval. Previous approaches treated an MLLM as a simple
encoder, ignoring its generative nature, and under-utilising its compositional
reasoning and world knowledge. We instead train the embedding MLLM end-to-end
with a chat-style generative matching stage. The matching stage uses the same
MLLM to autoregressively decide relevance from multi-view inputs, including
both raw data and its own projected embeddings for each query and document. It
provides instance-wise discrimination supervision that complements a standard
contrastive loss, offering stronger gradients on hard negatives and preserving
the compositional strengths of the original MLLM. To obtain semantically richer
multimodal embeddings, we use multiple learnable tokens to augment each input,
generating fine-grained contextual, mutually orthogonal embeddings with low
inference cost. Leveraging our established high-performance baseline,we
assemble the ideas mentioned above into a powerful training recipe and achieve
a new state-of-the-art on the Massive Multimodal Embedding Benchmark (MMEB).
Our experiments show particularly strong zero-shot generalization results on
five datasets, highlighting the robustness and transferability of ReMatch.
\\ ( https://arxiv.org/abs/2511.19278 ,  5357kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19294
Date: Mon, 24 Nov 2025 16:39:13 GMT   (10167kb)

Title: DensifyBeforehand: LiDAR-assisted Content-aware Densification for
 Efficient and Quality 3D Gaussian Splatting
Authors: Phurtivilai Patt, Leyang Huang, Yinqiang Zhang, Yang Lei
Categories: cs.CV
\\
 This paper addresses the limitations of existing 3D Gaussian Splatting (3DGS)
methods, particularly their reliance on adaptive density control, which can
lead to floating artifacts and inefficient resource usage. We propose a novel
densify beforehand approach that enhances the initialization of 3D scenes by
combining sparse LiDAR data with monocular depth estimation from corresponding
RGB images. Our ROI-aware sampling scheme prioritizes semantically and
geometrically important regions, yielding a dense point cloud that improves
visual fidelity and computational efficiency. This densify beforehand approach
bypasses the adaptive density control that may introduce redundant Gaussians in
the original pipeline, allowing the optimization to focus on the other
attributes of 3D Gaussian primitives, reducing overlap while enhancing visual
quality. Our method achieves comparable results to state-of-the-art techniques
while significantly lowering resource consumption and training time. We
validate our approach through extensive comparisons and ablation studies on
four newly collected datasets, showcasing its effectiveness in preserving
regions of interest in complex scenes.
\\ ( https://arxiv.org/abs/2511.19294 ,  10167kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19301
Date: Mon, 24 Nov 2025 16:49:20 GMT   (25278kb)

Title: IDEAL-M3D: Instance Diversity-Enriched Active Learning for Monocular 3D
 Detection
Authors: Johannes Meier, Florian G\"unther, Riccardo Marin, Oussema Dhaouadi,
 Jacques Kaiser, Daniel Cremers
Categories: cs.CV
Journal-ref: WACV 2026
\\
 Monocular 3D detection relies on just a single camera and is therefore easy
to deploy. Yet, achieving reliable 3D understanding from monocular images
requires substantial annotation, and 3D labels are especially costly. To
maximize performance under constrained labeling budgets, it is essential to
prioritize annotating samples expected to deliver the largest performance
gains. This prioritization is the focus of active learning. Curiously, we
observed two significant limitations in active learning algorithms for 3D
monocular object detection. First, previous approaches select entire images,
which is inefficient, as non-informative instances contained in the same image
also need to be labeled. Secondly, existing methods rely on uncertainty-based
selection, which in monocular 3D object detection creates a bias toward depth
ambiguity. Consequently, distant objects are selected, while nearby objects are
overlooked.
 To address these limitations, we propose IDEAL-M3D, the first instance-level
pipeline for monocular 3D detection. For the first time, we demonstrate that an
explicitly diverse, fast-to-train ensemble improves diversity-driven active
learning for monocular 3D. We induce diversity with heterogeneous backbones and
task-agnostic features, loss weight perturbation, and time-dependent bagging.
IDEAL-M3D shows superior performance and significant resource savings: with
just 60% of the annotations, we achieve similar or better AP3D on KITTI
validation and test set results compared to training the same detector on the
whole dataset.
\\ ( https://arxiv.org/abs/2511.19301 ,  25278kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19306
Date: Mon, 24 Nov 2025 16:58:23 GMT   (1228kb)

Title: Dual-Granularity Semantic Prompting for Language Guidance Infrared Small
 Target Detection
Authors: Zixuan Wang, Haoran Sun, Jiaming Lu, Wenxuan Wang, Zhongling Huang,
 Dingwen Zhang, Xuelin Qian, Junwei Han
Categories: cs.CV
Comments: 10 pages, 2 figures
\\
 Infrared small target detection remains challenging due to limited feature
representation and severe background interference, resulting in sub-optimal
performance. While recent CLIP-inspired methods attempt to leverage textual
guidance for detection, they are hindered by inaccurate text descriptions and
reliance on manual annotations. To overcome these limitations, we propose
DGSPNet, an end-to-end language prompt-driven framework. Our approach
integrates dual-granularity semantic prompts: coarse-grained textual priors
(e.g., 'infrared image', 'small target') and fine-grained personalized semantic
descriptions derived through visual-to-textual mapping within the image space.
This design not only facilitates learning fine-grained semantic information but
also can inherently leverage language prompts during inference without relying
on any annotation requirements. By fully leveraging the precision and
conciseness of text descriptions, we further introduce a text-guide channel
attention (TGCA) mechanism and text-guide spatial attention (TGSA) mechanism
that enhances the model's sensitivity to potential targets across both low- and
high-level feature spaces. Extensive experiments demonstrate that our method
significantly improves detection accuracy and achieves state-of-the-art
performance on three benchmark datasets.
\\ ( https://arxiv.org/abs/2511.19306 ,  1228kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19316
Date: Mon, 24 Nov 2025 17:11:00 GMT   (5948kb)

Title: Evaluating Dataset Watermarking for Fine-tuning Traceability of
 Customized Diffusion Models: A Comprehensive Benchmark and Removal Approach
Authors: Xincheng Wang, Hanchi Sun, Wenjun Sun, Kejun Xue, Wangqiu Zhou, Jianbo
 Zhang, Wei Sun, Dandan Zhu, Xiongkuo Min, Jun Jia, Zhijun Fang
Categories: cs.CV cs.AI
\\
 Recent fine-tuning techniques for diffusion models enable them to reproduce
specific image sets, such as particular faces or artistic styles, but also
introduce copyright and security risks. Dataset watermarking has been proposed
to ensure traceability by embedding imperceptible watermarks into training
images, which remain detectable in outputs even after fine-tuning. However,
current methods lack a unified evaluation framework. To address this, this
paper establishes a general threat model and introduces a comprehensive
evaluation framework encompassing Universality, Transmissibility, and
Robustness. Experiments show that existing methods perform well in universality
and transmissibility, and exhibit some robustness against common image
processing operations, yet still fall short under real-world threat scenarios.
To reveal these vulnerabilities, the paper further proposes a practical
watermark removal method that fully eliminates dataset watermarks without
affecting fine-tuning, highlighting a key challenge for future research.
\\ ( https://arxiv.org/abs/2511.19316 ,  5948kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19319
Date: Mon, 24 Nov 2025 17:14:19 GMT   (1373kb)

Title: SyncMV4D: Synchronized Multi-view Joint Diffusion of Appearance and
 Motion for Hand-Object Interaction Synthesis
Authors: Lingwei Dang, Zonghan Li, Juntong Li, Hongwen Zhang, Liang An, Yebin
 Liu, Qingyao Wu
Categories: cs.CV
Comments: Project Page: https://droliven.github.io/SyncMV4D
\\
 Hand-Object Interaction (HOI) generation plays a critical role in advancing
applications across animation and robotics. Current video-based methods are
predominantly single-view, which impedes comprehensive 3D geometry perception
and often results in geometric distortions or unrealistic motion patterns.
While 3D HOI approaches can generate dynamically plausible motions, their
dependence on high-quality 3D data captured in controlled laboratory settings
severely limits their generalization to real-world scenarios. To overcome these
limitations, we introduce SyncMV4D, the first model that jointly generates
synchronized multi-view HOI videos and 4D motions by unifying visual prior,
motion dynamics, and multi-view geometry. Our framework features two core
innovations: (1) a Multi-view Joint Diffusion (MJD) model that co-generates HOI
videos and intermediate motions, and (2) a Diffusion Points Aligner (DPA) that
refines the coarse intermediate motion into globally aligned 4D metric point
tracks. To tightly couple 2D appearance with 4D dynamics, we establish a
closed-loop, mutually enhancing cycle. During the diffusion denoising process,
the generated video conditions the refinement of the 4D motion, while the
aligned 4D point tracks are reprojected to guide next-step joint generation.
Experimentally, our method demonstrates superior performance to
state-of-the-art alternatives in visual realism, motion plausibility, and
multi-view consistency.
\\ ( https://arxiv.org/abs/2511.19319 ,  1373kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19320
Date: Mon, 24 Nov 2025 17:15:55 GMT   (47313kb)

Title: SteadyDancer: Harmonized and Coherent Human Image Animation with
 First-Frame Preservation
Authors: Jiaming Zhang, Shengming Cao, Rui Li, Xiaotong Zhao, Yutao Cui,
 Xinglin Hou, Gangshan Wu, Haolan Chen, Yu Xu, Limin Wang, Kai Ma
Categories: cs.CV
Comments: 10 pages, with supp
\\
 Preserving first-frame identity while ensuring precise motion control is a
fundamental challenge in human image animation. The Image-to-Motion Binding
process of the dominant Reference-to-Video (R2V) paradigm overlooks critical
spatio-temporal misalignments common in real-world applications, leading to
failures such as identity drift and visual artifacts. We introduce
SteadyDancer, an Image-to-Video (I2V) paradigm-based framework that achieves
harmonized and coherent animation and is the first to ensure first-frame
preservation robustly. Firstly, we propose a Condition-Reconciliation Mechanism
to harmonize the two conflicting conditions, enabling precise control without
sacrificing fidelity. Secondly, we design Synergistic Pose Modulation Modules
to generate an adaptive and coherent pose representation that is highly
compatible with the reference image. Finally, we employ a Staged
Decoupled-Objective Training Pipeline that hierarchically optimizes the model
for motion fidelity, visual quality, and temporal coherence. Experiments
demonstrate that SteadyDancer achieves state-of-the-art performance in both
appearance fidelity and motion control, while requiring significantly fewer
training resources than comparable methods.
\\ ( https://arxiv.org/abs/2511.19320 ,  47313kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19326
Date: Mon, 24 Nov 2025 17:20:17 GMT   (2137kb)

Title: MonoMSK: Monocular 3D Musculoskeletal Dynamics Estimation
Authors: Farnoosh Koleini, Hongfei Xue, Ahmed Helmy, Pu Wang
Categories: cs.CV
\\
 Reconstructing biomechanically realistic 3D human motion - recovering both
kinematics (motion) and kinetics (forces) - is a critical challenge. While
marker-based systems are lab-bound and slow, popular monocular methods use
oversimplified, anatomically inaccurate models (e.g., SMPL) and ignore physics,
fundamentally limiting their biomechanical fidelity. In this work, we introduce
MonoMSK, a hybrid framework that bridges data-driven learning and physics-based
simulation for biomechanically realistic 3D human motion estimation from
monocular video. MonoMSK jointly recovers both kinematics (motions) and
kinetics (forces and torques) through an anatomically accurate musculoskeletal
model. By integrating transformer-based inverse dynamics with differentiable
forward kinematics and dynamics layers governed by ODE-based simulation,
MonoMSK establishes a physics-regulated inverse-forward loop that enforces
biomechanical causality and physical plausibility. A novel forward-inverse
consistency loss further aligns motion reconstruction with the underlying
kinetic reasoning. Experiments on BML-MoVi, BEDLAM, and OpenCap show that
MonoMSK significantly outperforms state-of-the-art methods in kinematic
accuracy, while for the first time enabling precise monocular kinetics
estimation.
\\ ( https://arxiv.org/abs/2511.19326 ,  2137kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19339
Date: Mon, 24 Nov 2025 17:38:53 GMT   (16848kb)

Title: POUR: A Provably Optimal Method for Unlearning Representations via
 Neural Collapse
Authors: Anjie Le, Can Peng, Yuyuan Liu, J. Alison Noble
Categories: cs.CV
\\
 In computer vision, machine unlearning aims to remove the influence of
specific visual concepts or training images without retraining from scratch.
Studies show that existing approaches often modify the classifier while leaving
internal representations intact, resulting in incomplete forgetting. In this
work, we extend the notion of unlearning to the representation level, deriving
a three-term interplay between forgetting efficacy, retention fidelity, and
class separation. Building on Neural Collapse theory, we show that the
orthogonal projection of a simplex Equiangular Tight Frame (ETF) remains an ETF
in a lower dimensional space, yielding a provably optimal forgetting operator.
We further introduce the Representation Unlearning Score (RUS) to quantify
representation-level forgetting and retention fidelity. Building on this, we
introduce POUR (Provably Optimal Unlearning of Representations), a geometric
projection method with closed-form (POUR-P) and a feature-level unlearning
variant under a distillation scheme (POUR-D). Experiments on CIFAR-10/100 and
PathMNIST demonstrate that POUR achieves effective unlearning while preserving
retained knowledge, outperforming state-of-the-art unlearning methods on both
classification-level and representation-level metrics.
\\ ( https://arxiv.org/abs/2511.19339 ,  16848kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19343
Date: Mon, 24 Nov 2025 17:42:29 GMT   (10466kb)

Title: Syn-GRPO: Self-Evolving Data Synthesis for MLLM Perception Reasoning
Authors: Qihan Huang, Haofei Zhang, Rong Wei, Yi Wang, Rui Tang, Mingli Song,
 Jie Song
Categories: cs.CV
\\
 RL (reinforcement learning) methods (e.g., GRPO) for MLLM (Multimodal LLM)
perception ability has attracted wide research interest owing to its remarkable
generalization ability. Nevertheless, existing reinforcement learning methods
still face the problem of low data quality, where data samples cannot elicit
diverse responses from MLLMs, thus restricting the exploration scope for MLLM
reinforcement learning. Some methods attempt to mitigate this problem by
imposing constraints on entropy, but none address it at its root. Therefore, to
tackle this problem, this work proposes Syn-GRPO (Synthesis-GRPO), which
employs an online data generator to synthesize high-quality training data with
diverse responses in GRPO training. Specifically, Syn-GRPO consists of two
components: (1) data server; (2) GRPO workflow. The data server synthesizes new
samples from existing ones using an image generation model, featuring a
decoupled and asynchronous scheme to achieve high generation efficiency. The
GRPO workflow provides the data server with the new image descriptions, and it
leverages a diversity reward to supervise the MLLM to predict image
descriptions for synthesizing samples with diverse responses. Experiment
results across three visual perception tasks demonstrate that Syn-GRPO improves
the data quality by a large margin, achieving significant superior performance
to existing MLLM perception methods, and Syn-GRPO presents promising potential
for scaling long-term self-evolving RL. Our code is available at
https://github.com/hqhQAQ/Syn-GRPO.
\\ ( https://arxiv.org/abs/2511.19343 ,  10466kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19351
Date: Mon, 24 Nov 2025 17:53:59 GMT   (13949kb)

Title: CellFMCount: A Fluorescence Microscopy Dataset, Benchmark, and Methods
 for Cell Counting
Authors: Abdurahman Ali Mohammed, Catherine Fonder, Ying Wei, Wallapak
 Tavanapong, Donald S Sakaguchi, Qi Li, Surya K. Mallapragada
Categories: cs.CV
Comments: The IEEE International Conference on Data Mining (ICDM) 2025
\\
 Accurate cell counting is essential in various biomedical research and
clinical applications, including cancer diagnosis, stem cell research, and
immunology. Manual counting is labor-intensive and error-prone, motivating
automation through deep learning techniques. However, training reliable deep
learning models requires large amounts of high-quality annotated data, which is
difficult and time-consuming to produce manually. Consequently, existing
cell-counting datasets are often limited, frequently containing fewer than
$500$ images. In this work, we introduce a large-scale annotated dataset
comprising $3{,}023$ images from immunocytochemistry experiments related to
cellular differentiation, containing over $430{,}000$ manually annotated cell
locations. The dataset presents significant challenges: high cell density,
overlapping and morphologically diverse cells, a long-tailed distribution of
cell count per image, and variation in staining protocols. We benchmark three
categories of existing methods: regression-based, crowd-counting, and
cell-counting techniques on a test set with cell counts ranging from $10$ to
$2{,}126$ cells per image. We also evaluate how the Segment Anything Model
(SAM) can be adapted for microscopy cell counting using only dot-annotated
datasets. As a case study, we implement a density-map-based adaptation of SAM
(SAM-Counter) and report a mean absolute error (MAE) of $22.12$, which
outperforms existing approaches (second-best MAE of $27.46$). Our results
underscore the value of the dataset and the benchmarking framework for driving
progress in automated cell counting and provide a robust foundation for future
research and development.
\\ ( https://arxiv.org/abs/2511.19351 ,  13949kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19356
Date: Mon, 24 Nov 2025 17:56:03 GMT   (7894kb)

Title: Growing with the Generator: Self-paced GRPO for Video Generation
Authors: Rui Li, Yuanzhi Liang, Ziqi Ni, Haibing Huang, Chi Zhang, Xuelong Li
Categories: cs.CV
\\
 Group Relative Policy Optimization (GRPO) has emerged as a powerful
reinforcement learning paradigm for post-training video generation models.
However, existing GRPO pipelines rely on static, fixed-capacity reward models
whose evaluation behavior is frozen during training. Such rigid rewards
introduce distributional bias, saturate quickly as the generator improves, and
ultimately limit the stability and effectiveness of reinforcement-based
alignment. We propose Self-Paced GRPO, a competence-aware GRPO framework in
which reward feedback co-evolves with the generator. Our method introduces a
progressive reward mechanism that automatically shifts its emphasis from coarse
visual fidelity to temporal coherence and fine-grained text-video semantic
alignment as generation quality increases. This self-paced curriculum
alleviates reward-policy mismatch, mitigates reward exploitation, and yields
more stable optimization. Experiments on VBench across multiple video
generation backbones demonstrate consistent improvements in both visual quality
and semantic alignment over GRPO baselines with static rewards, validating the
effectiveness and generality of Self-Paced GRPO.
\\ ( https://arxiv.org/abs/2511.19356 ,  7894kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19365
Date: Mon, 24 Nov 2025 17:59:06 GMT   (3627kb)

Title: DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image
 Generation
Authors: Zehong Ma, Longhui Wei, Shuai Wang, Shiliang Zhang, and Qi Tian
Categories: cs.CV cs.AI
Comments: Project Page: https://zehong-ma.github.io/DeCo. Code Repository:
 https://github.com/Zehong-Ma/DeCo
\\
 Pixel diffusion aims to generate images directly in pixel space in an
end-to-end fashion. This approach avoids the limitations of VAE in the
two-stage latent diffusion, offering higher model capacity. Existing pixel
diffusion models suffer from slow training and inference, as they usually model
both high-frequency signals and low-frequency semantics within a single
diffusion transformer (DiT). To pursue a more efficient pixel diffusion
paradigm, we propose the frequency-DeCoupled pixel diffusion framework. With
the intuition to decouple the generation of high and low frequency components,
we leverage a lightweight pixel decoder to generate high-frequency details
conditioned on semantic guidance from the DiT. This thus frees the DiT to
specialize in modeling low-frequency semantics. In addition, we introduce a
frequency-aware flow-matching loss that emphasizes visually salient frequencies
while suppressing insignificant ones. Extensive experiments show that DeCo
achieves superior performance among pixel diffusion models, attaining FID of
1.62 (256x256) and 2.22 (512x512) on ImageNet, closing the gap with latent
diffusion methods. Furthermore, our pretrained text-to-image model achieves a
leading overall score of 0.86 on GenEval in system-level comparison. Codes are
publicly available at https://github.com/Zehong-Ma/DeCo.
\\ ( https://arxiv.org/abs/2511.19365 ,  3627kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19367
Date: Mon, 24 Nov 2025 18:01:47 GMT   (1375kb)

Title: An Anatomy Aware Hybrid Deep Learning Framework for Lung Cancer Tumor
 Stage Classification
Authors: Saniah Kayenat Chowdhury, Rusab Sarmun, Muhammad E. H. Chowdhury,
 Sohaib Bassam Zoghoul, Israa Al-Hashimi, Adam Mushtak, Amith Khandakar
Categories: cs.CV cs.AI
\\
 Accurate lung cancer tumor staging is crucial for prognosis and treatment
planning. However, it remains challenging for end-to-end deep learning
approaches, as such approaches often overlook spatial and anatomical
information that are central to the tumor-node-metastasis system. The tumor
stage depends on multiple quantitative criteria, including the tumor size and
its proximity to the nearest anatomical structures, and small variations can
alter the staging outcome. We propose a medically grounded hybrid pipeline that
performs staging by explicitly measuring the tumor's size and distance
properties rather than treating it as a pure image classification task. Our
method employs specialized encoder-decoder networks to precisely segment the
lung and adjacent anatomy, including the lobes, tumor, mediastinum, and
diaphragm. Subsequently, we extract the necessary tumor properties, i.e.
measure the largest tumor dimension and calculate the distance between the
tumor and neighboring anatomical structures by a quantitative analysis of the
segmentation masks. Finally, we apply rule-based tumor staging aligned with the
medical guidelines. This novel framework has been evaluated on the
Lung-PET-CT-Dx dataset, demonstrating superior performance compared to
traditional deep learning models, achieving an overall classification accuracy
of 91.36%. We report the per-stage F1-scores of 0.93 (T1), 0.89 (T2), 0.96
(T3), and 0.90 (T4), a critical evaluation aspect often omitted in prior
literature. To our knowledge, this is the first study that embeds explicit
clinical context into tumor stage classification. Unlike standard convolutional
neural networks that operate in an uninterpretable "black box" manner, our
method offers both state-of-the-art performance and transparent decision
support.
\\ ( https://arxiv.org/abs/2511.19367 ,  1375kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19380
Date: Mon, 24 Nov 2025 18:20:08 GMT   (5500kb)

Title: UISearch: Graph-Based Embeddings for Multimodal Enterprise UI
 Screenshots Retrieval
Authors: Maroun Ayli, Youssef Bakouny, Tushar Sharma, Nader Jalloul, Hani
 Seifeddine, Rima Kilany
Categories: cs.CV
Comments: 12 pages, 2 figures, 3 algorithms, 4 tables
\\
 Enterprise software companies maintain thousands of user interface screens
across products and versions, creating critical challenges for design
consistency, pattern discovery, and compliance check. Existing approaches rely
on visual similarity or text semantics, lacking explicit modeling of structural
properties fundamental to user interface (UI) composition. We present a novel
graph-based representation that converts UI screenshots into attributed graphs
encoding hierarchical relationships and spatial arrangements, potentially
generalizable to document layouts, architectural diagrams, and other structured
visual domains. A contrastive graph autoencoder learns embeddings preserving
multi-level similarity across visual, structural, and semantic properties. The
comprehensive analysis demonstrates that our structural embeddings achieve
better discriminative power than state-of-the-art Vision Encoders, representing
a fundamental advance in the expressiveness of the UI representation. We
implement this representation in UISearch, a multi-modal search framework that
combines structural embeddings with semantic search through a composable query
language. On 20,396 financial software UIs, UISearch achieves 0.92 Top-5
accuracy with 47.5ms median latency (P95: 124ms), scaling to 20,000+ screens.
The hybrid indexing architecture enables complex queries and supports
fine-grained UI distinction impossible with vision-only approaches.
\\ ( https://arxiv.org/abs/2511.19380 ,  5500kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19394
Date: Mon, 24 Nov 2025 18:31:51 GMT   (8841kb)

Title: BackSplit: The Importance of Sub-dividing the Background in Biomedical
 Lesion Segmentation
Authors: Rachit Saluja, Asli Cihangir, Ruining Deng, Johannes C. Paetzold,
 Fengbei Liu, Mert R. Sabuncu
Categories: cs.CV
\\
 Segmenting small lesions in medical images remains notoriously difficult.
Most prior work tackles this challenge by either designing better
architectures, loss functions, or data augmentation schemes; and collecting
more labeled data. We take a different view, arguing that part of the problem
lies in how the background is modeled. Common lesion segmentation collapses all
non-lesion pixels into a single "background" class, ignoring the rich
anatomical context in which lesions appear. In reality, the background is
highly heterogeneous-composed of tissues, organs, and other structures that can
now be labeled manually or inferred automatically using existing segmentation
models.
 In this paper, we argue that training with fine-grained labels that
sub-divide the background class, which we call BackSplit, is a simple yet
powerful paradigm that can offer a significant performance boost without
increasing inference costs. From an information theoretic standpoint, we prove
that BackSplit increases the expected Fisher Information relative to
conventional binary training, leading to tighter asymptotic bounds and more
stable optimization. With extensive experiments across multiple datasets and
architectures, we empirically show that BackSplit consistently boosts
small-lesion segmentation performance, even when auxiliary labels are generated
automatically using pretrained segmentation models. Additionally, we
demonstrate that auxiliary labels derived from interactive segmentation
frameworks exhibit the same beneficial effect, demonstrating its robustness,
simplicity, and broad applicability.
\\ ( https://arxiv.org/abs/2511.19394 ,  8841kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19401
Date: Mon, 24 Nov 2025 18:38:45 GMT   (4780kb)

Title: In-Video Instructions: Visual Signals as Generative Control
Authors: Gongfan Fang, Xinyin Ma, Xinchao Wang
Categories: cs.CV cs.AI
\\
 Large-scale video generative models have recently demonstrated strong visual
capabilities, enabling the prediction of future frames that adhere to the
logical and physical cues in the current observation. In this work, we
investigate whether such capabilities can be harnessed for controllable
image-to-video generation by interpreting visual signals embedded within the
frames as instructions, a paradigm we term In-Video Instruction. In contrast to
prompt-based control, which provides textual descriptions that are inherently
global and coarse, In-Video Instruction encodes user guidance directly into the
visual domain through elements such as overlaid text, arrows, or trajectories.
This enables explicit, spatial-aware, and unambiguous correspondences between
visual subjects and their intended actions by assigning distinct instructions
to different objects. Extensive experiments on three state-of-the-art
generators, including Veo 3.1, Kling 2.5, and Wan 2.2, show that video models
can reliably interpret and execute such visually embedded instructions,
particularly in complex multi-object scenarios.
\\ ( https://arxiv.org/abs/2511.19401 ,  4780kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19418
Date: Mon, 24 Nov 2025 18:55:19 GMT   (2911kb)

Title: Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with
 Continuous Visual Tokens
Authors: Yiming Qin, Bomin Wei, Jiaxin Ge, Konstantinos Kallidromitis,
 Stephanie Fu, Trevor Darrell, Xudong Wang
Categories: cs.CV cs.AI cs.LG
Comments: Project page: https://wakalsprojectpage.github.io/comt-website/
\\
 Vision-Language Models (VLMs) excel at reasoning in linguistic space but
struggle with perceptual understanding that requires dense visual perception,
e.g., spatial reasoning and geometric awareness. This limitation stems from the
fact that current VLMs have limited mechanisms to capture dense visual
information across spatial dimensions. We introduce Chain-of-Visual-Thought
(COVT), a framework that enables VLMs to reason not only in words but also
through continuous visual tokens-compact latent representations that encode
rich perceptual cues. Within a small budget of roughly 20 tokens, COVT distills
knowledge from lightweight vision experts, capturing complementary properties
such as 2D appearance, 3D geometry, spatial layout, and edge structure. During
training, the VLM with COVT autoregressively predicts these visual tokens to
reconstruct dense supervision signals (e.g., depth, segmentation, edges, and
DINO features). At inference, the model reasons directly in the continuous
visual token space, preserving efficiency while optionally decoding dense
predictions for interpretability. Evaluated across more than ten diverse
perception benchmarks, including CV-Bench, MMVP, RealWorldQA, MMStar,
WorldMedQA, and HRBench, integrating COVT into strong VLMs such as Qwen2.5-VL
and LLaVA consistently improves performance by 3% to 16% and demonstrates that
compact continuous visual thinking enables more precise, grounded, and
interpretable multimodal intelligence.
\\ ( https://arxiv.org/abs/2511.19418 ,  2911kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19425
Date: Mon, 24 Nov 2025 18:57:54 GMT   (1702kb)

Title: SAM3-Adapter: Efficient Adaptation of Segment Anything 3 for Camouflage
 Object Segmentation, Shadow Detection, and Medical Image Segmentation
Authors: Tianrun Chen, Runlong Cao, Xinda Yu, Lanyun Zhu, Chaotao Ding, Deyi
 Ji, Cheng Chen, Qi Zhu, Chunyan Xu, Papa Mao, Ying Zang
Categories: cs.CV
\\
 The rapid rise of large-scale foundation models has reshaped the landscape of
image segmentation, with models such as Segment Anything achieving
unprecedented versatility across diverse vision tasks. However, previous
generations-including SAM and its successor-still struggle with fine-grained,
low-level segmentation challenges such as camouflaged object detection, medical
image segmentation, cell image segmentation, and shadow detection. To address
these limitations, we originally proposed SAM-Adapter in 2023, demonstrating
substantial gains on these difficult scenarios. With the emergence of Segment
Anything 3 (SAM3)-a more efficient and higher-performing evolution with a
redesigned architecture and improved training pipeline-we revisit these
long-standing challenges. In this work, we present SAM3-Adapter, the first
adapter framework tailored for SAM3 that unlocks its full segmentation
capability. SAM3-Adapter not only reduces computational overhead but also
consistently surpasses both SAM and SAM2-based solutions, establishing new
state-of-the-art results across multiple downstream tasks, including medical
imaging, camouflaged (concealed) object segmentation, and shadow detection.
Built upon the modular and composable design philosophy of the original
SAM-Adapter, SAM3-Adapter provides stronger generalizability, richer task
adaptability, and significantly improved segmentation precision. Extensive
experiments confirm that integrating SAM3 with our adapter yields superior
accuracy, robustness, and efficiency compared to all prior SAM-based
adaptations. We hope SAM3-Adapter can serve as a foundation for future research
and practical segmentation applications. Code, pre-trained models, and data
processing pipelines are available.
\\ ( https://arxiv.org/abs/2511.19425 ,  1702kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19426
Date: Mon, 24 Nov 2025 18:58:22 GMT   (4226kb)

Title: Ref-SAM3D: Bridging SAM3D with Text for Reference 3D Reconstruction
Authors: Yun Zhou, Yaoting Wang, Guangquan Jie, Jinyu Liu, Henghui Ding
Categories: cs.CV
Comments: Code: https://github.com/FudanCVL/Ref-SAM3D
\\
 SAM3D has garnered widespread attention for its strong 3D object
reconstruction capabilities. However, a key limitation remains: SAM3D cannot
reconstruct specific objects referred to by textual descriptions, a capability
that is essential for practical applications such as 3D editing, game
development, and virtual environments. To address this gap, we introduce
Ref-SAM3D, a simple yet effective extension to SAM3D that incorporates textual
descriptions as a high-level prior, enabling text-guided 3D reconstruction from
a single RGB image. Through extensive qualitative experiments, we show that
Ref-SAM3D, guided only by natural language and a single 2D view, delivers
competitive and high-fidelity zero-shot reconstruction performance. Our results
demonstrate that Ref-SAM3D effectively bridges the gap between 2D visual cues
and 3D geometric understanding, offering a more flexible and accessible
paradigm for reference-guided 3D reconstruction. Code is available at:
https://github.com/FudanCVL/Ref-SAM3D.
\\ ( https://arxiv.org/abs/2511.19426 ,  4226kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19430
Date: Mon, 24 Nov 2025 18:59:17 GMT   (1404kb)

Title: Cook and Clean Together: Teaching Embodied Agents for Parallel Task
 Execution
Authors: Dingkang Liang, Cheng Zhang, Xiaopeng Xu, Jianzhong Ju, Zhenbo Luo,
 Xiang Bai
Categories: cs.CV
Comments: Accepted to AAAI 2026 (Oral). The code is available at
 \url{https://github.com/H-EmbodVis/GRANT}
\\
 Task scheduling is critical for embodied AI, enabling agents to follow
natural language instructions and execute actions efficiently in 3D physical
worlds. However, existing datasets often simplify task planning by ignoring
operations research (OR) knowledge and 3D spatial grounding. In this work, we
propose Operations Research knowledge-based 3D Grounded Task Scheduling
(ORS3D), a new task that requires the synergy of language understanding, 3D
grounding, and efficiency optimization. Unlike prior settings, ORS3D demands
that agents minimize total completion time by leveraging parallelizable
subtasks, e.g., cleaning the sink while the microwave operates. To facilitate
research on ORS3D, we construct ORS3D-60K, a large-scale dataset comprising 60K
composite tasks across 4K real-world scenes. Furthermore, we propose GRANT, an
embodied multi-modal large language model equipped with a simple yet effective
scheduling token mechanism to generate efficient task schedules and grounded
actions. Extensive experiments on ORS3D-60K validate the effectiveness of GRANT
across language understanding, 3D grounding, and scheduling efficiency. The
code is available at https://github.com/H-EmbodVis/GRANT
\\ ( https://arxiv.org/abs/2511.19430 ,  1404kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19431
Date: Mon, 24 Nov 2025 18:59:37 GMT   (19018kb)

Title: Cloud4D
Authors: Jacob Lin, Edward Gryspeerdt, Ronald Clark
Categories: cs.CV physics.ao-ph
Comments: NeurIPS 2025 Spotlight, project page: https://cloud4d.jacob-lin.com/
\\
 There has been great progress in improving numerical weather prediction and
climate models using machine learning. However, most global models act at a
kilometer-scale, making it challenging to model individual clouds and factors
such as extreme precipitation, wind gusts, turbulence, and surface irradiance.
Therefore, there is a need to move towards higher-resolution models, which in
turn require high-resolution real-world observations that current instruments
struggle to obtain. We present Cloud4D, the first learning-based framework that
reconstructs a physically consistent, four-dimensional cloud state using only
synchronized ground-based cameras. Leveraging a homography-guided 2D-to-3D
transformer, Cloud4D infers the full 3D distribution of liquid water content at
25 m spatial and 5 s temporal resolution. By tracking the 3D liquid water
content retrievals over time, Cloud4D additionally estimates horizontal wind
vectors. Across a two-month deployment comprising six skyward cameras, our
system delivers an order-of-magnitude improvement in space-time resolution
relative to state-of-the-art satellite measurements, while retaining
single-digit relative error ($<10\%$) against collocated radar measurements.
Code and data are available on our project page https://cloud4d.jacob-lin.com/.
\\ ( https://arxiv.org/abs/2511.19431 ,  19018kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19434
Date: Mon, 24 Nov 2025 18:59:53 GMT   (2847kb)

Title: Breaking the Likelihood-Quality Trade-off in Diffusion Models by Merging
 Pretrained Experts
Authors: Yasin Esfandiari, Stefan Bauer, Sebastian U. Stich, Andrea Dittadi
Categories: cs.CV cs.LG stat.ML
Comments: ICLR 2025 DeLTa workshop
\\
 Diffusion models for image generation often exhibit a trade-off between
perceptual sample quality and data likelihood: training objectives emphasizing
high-noise denoising steps yield realistic images but poor likelihoods, whereas
likelihood-oriented training overweights low-noise steps and harms visual
fidelity. We introduce a simple plug-and-play sampling method that combines two
pretrained diffusion experts by switching between them along the denoising
trajectory. Specifically, we apply an image-quality expert at high noise levels
to shape global structure, then switch to a likelihood expert at low noise
levels to refine pixel statistics. The approach requires no retraining or
fine-tuning -- only the choice of an intermediate switching step. On CIFAR-10
and ImageNet32, the merged model consistently matches or outperforms its base
components, improving or preserving both likelihood and sample quality relative
to each expert alone. These results demonstrate that expert switching across
noise levels is an effective way to break the likelihood-quality trade-off in
image diffusion models.
\\ ( https://arxiv.org/abs/2511.19434 ,  2847kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19435
Date: Mon, 24 Nov 2025 18:59:54 GMT   (12403kb)

Title: Are Image-to-Video Models Good Zero-Shot Image Editors?
Authors: Zechuan Zhang and Zhenyuan Chen and Zongxin Yang and Yi Yang
Categories: cs.CV
Comments: technical report
\\
 Large-scale video diffusion models show strong world simulation and temporal
reasoning abilities, but their use as zero-shot image editors remains
underexplored. We introduce IF-Edit, a tuning-free framework that repurposes
pretrained image-to-video diffusion models for instruction-driven image
editing. IF-Edit addresses three key challenges: prompt misalignment, redundant
temporal latents, and blurry late-stage frames. It includes (1) a
chain-of-thought prompt enhancement module that transforms static editing
instructions into temporally grounded reasoning prompts; (2) a temporal latent
dropout strategy that compresses frame latents after the expert-switch point,
accelerating denoising while preserving semantic and temporal coherence; and
(3) a self-consistent post-refinement step that sharpens late-stage frames
using a short still-video trajectory. Experiments on four public benchmarks,
covering non-rigid editing, physical and temporal reasoning, and general
instruction edits, show that IF-Edit performs strongly on reasoning-centric
tasks while remaining competitive on general-purpose edits. Our study provides
a systematic view of video diffusion models as image editors and highlights a
simple recipe for unified video-image generative reasoning.
\\ ( https://arxiv.org/abs/2511.19435 ,  12403kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19436
Date: Mon, 24 Nov 2025 18:59:56 GMT   (1111kb)

Title: VDC-Agent: When Video Detailed Captioners Evolve Themselves via Agentic
 Self-Reflection
Authors: Qiang Wang, Xinyuan Gao, SongLin Dong, Jizhou Han, Jiangyang Li,
 Yuhang He, Yihong Gong
Categories: cs.CV cs.AI cs.LG cs.MM
\\
 We present VDC-Agent, a self-evolving framework for Video Detailed Captioning
that requires neither human annotations nor larger teacher models. The agent
forms a closed loop of caption generation, principle-guided scoring (score and
textual suggestions), and prompt refinement. When caption quality regresses, a
self-reflection path leverages the previous chain-of-thought to amend the
update. Running this process on unlabeled videos produces trajectories of
(caption, score) pairs. We convert the trajectories into preference tuples and
filter out samples with JSON parsing errors, resulting in VDC-Agent-19K, which
contains 18,886 automatically constructed pairs. We then fine-tune the base
MLLM on this dataset using an easy-to-hard curriculum direct preference
optimization. Built on Qwen2.5-VL-7B-Instruct, our VDC-Agent-7B attains
state-of-the-art performance on the VDC benchmark with 49.08% average accuracy
and 2.50 score, surpassing specialized video captioners and improving over the
base model by +5.13% accuracy and +0.27 score at similar inference cost.
\\ ( https://arxiv.org/abs/2511.19436 ,  1111kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19437
Date: Mon, 24 Nov 2025 18:59:58 GMT   (25240kb)

Title: LumiTex: Towards High-Fidelity PBR Texture Generation with Illumination
 Context
Authors: Jingzhi Bao, Hongze Chen, Lingting Zhu, Chenyu Liu, Runze Zhang,
 Keyang Luo, Zeyu Hu, Weikai Chen, Yingda Yin, Xin Wang, Zehong Lin, Jun
 Zhang, Xiaoguang Han
Categories: cs.CV
Comments: Project page: https://lumitex.vercel.app
\\
 Physically-based rendering (PBR) provides a principled standard for realistic
material-lighting interactions in computer graphics. Despite recent advances in
generating PBR textures, existing methods fail to address two fundamental
challenges: 1) materials decomposition from image prompts under limited
illumination cues, and 2) seamless and view-consistent texture completion. To
this end, we propose LumiTex, an end-to-end framework that comprises three key
components: (1) a multi-branch generation scheme that disentangles albedo and
metallic-roughness under shared illumination priors for robust material
understanding, (2) a lighting-aware material attention mechanism that injects
illumination context into the decoding process for physically grounded
generation of albedo, metallic, and roughness maps, and (3) a geometry-guided
inpainting module based on a large view synthesis model that enriches texture
coverage and ensures seamless, view-consistent UV completion. Extensive
experiments demonstrate that LumiTex achieves state-of-the-art performance in
texture quality, surpassing both existing open-source and commercial methods.
\\ ( https://arxiv.org/abs/2511.19437 ,  25240kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17913
Date: Sat, 22 Nov 2025 04:31:19 GMT   (724kb)

Title: Token-Controlled Re-ranking for Sequential Recommendation via LLMs
Authors: Wenxi Dai, Wujiang Xu, Pinhuan Wang, Dimitris N. Metaxas
Categories: cs.IR cs.LG
\\
 The widespread adoption of Large Language Models (LLMs) as re-rankers is
shifting recommender systems towards a user-centric paradigm. However, a
significant gap remains: current re-rankers often lack mechanisms for
fine-grained user control. They struggle to balance inherent user preferences
with multiple attribute-based constraints, often resorting to simplistic hard
filtering that can excessively narrow the recommendation pool and yield
suboptimal results. This limitation leaves users as passive recipients rather
than active collaborators in the recommendation process. To bridge this gap, we
propose COREC, a novel token-augmented re-ranking framework that incorporates
specific user requirements in co-creating the recommendation outcome. COREC
empowers users to steer re-ranking results with precise and flexible control
via explicit, attribute-based signals. The framework learns to balance these
commands against latent preferences, yielding rankings that adhere to user
instructions without sacrificing personalization. Experiments show that COREC:
(1) exceeds state-of-the-art baselines on standard recommendation effectiveness
and (2) demonstrates superior adherence to specific attribute requirements,
proving that COREC enables fine-grained and predictable manipulation of the
rankings.
\\ ( https://arxiv.org/abs/2511.17913 ,  724kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18013
Date: Sat, 22 Nov 2025 10:27:20 GMT   (5462kb)

Title: Save, Revisit, Retain: A Scalable Framework for Enhancing User Retention
 in Large-Scale Recommender Systems
Authors: Weijie Jiang, Armando Ordorica, Jaewon Yang, Olafur Gudmundsson,
 Yucheng Tu, Huizhong Duan
Categories: cs.IR cs.AI cs.LG
\\
 User retention is a critical objective for online platforms like Pinterest,
as it strengthens user loyalty and drives growth through repeated engagement. A
key indicator of retention is revisitation, i.e., when users return to view
previously saved content, a behavior often sparked by personalized
recommendations and user satisfaction. However, modeling and optimizing
revisitation poses significant challenges. One core difficulty is accurate
attribution: it is often unclear which specific user actions or content
exposures trigger a revisit, since many confounding factors (e.g., content
quality, user interface, notifications, or even changing user intent) can
influence return behavior. Additionally, the scale and timing of revisitations
introduce further complexity; users may revisit content days or even weeks
after their initial interaction, requiring the system to maintain and associate
extensive historical records across millions of users and sessions. These
complexities render existing methods insufficient for robustly capturing and
optimizing long-term revisitation. To address these gaps, we introduce a novel,
lightweight, and interpretable framework for modeling revisitation behavior and
optimizing long-term user retention in Pinterest's search-based recommendation
context. By defining a surrogate attribution process that links saves to
subsequent revisitations, we reduce noise in the causal relationship between
user actions and return visits. Our scalable event aggregation pipeline enables
large-scale analysis of user revisitation patterns and enhances the ranking
system's ability to surface items with high retention value. Deployed on
Pinterest's Related Pins surface to serve 500+ million users, the framework led
to a significant lift of 0.1% in active users without additional computational
costs.
\\ ( https://arxiv.org/abs/2511.18013 ,  5462kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18024
Date: Sat, 22 Nov 2025 11:27:32 GMT   (2278kb)

Title: Extracting Interaction-Aware Monosemantic Concepts in Recommender
 Systems
Authors: Dor Arviv, Yehonatan Elisha, Oren Barkan, Noam Koenigstein
Categories: cs.IR cs.AI cs.LG
Journal-ref: AAAI 2026
\\
 We present a method for extracting \emph{monosemantic} neurons, defined as
latent dimensions that align with coherent and interpretable concepts, from
user and item embeddings in recommender systems. Our approach employs a Sparse
Autoencoder (SAE) to reveal semantic structure within pretrained
representations. In contrast to work on language models, monosemanticity in
recommendation must preserve the interactions between separate user and item
embeddings. To achieve this, we introduce a \emph{prediction aware} training
objective that backpropagates through a frozen recommender and aligns the
learned latent structure with the model's user-item affinity predictions. The
resulting neurons capture properties such as genre, popularity, and temporal
trends, and support post hoc control operations including targeted filtering
and content promotion without modifying the base model. Our method generalizes
across different recommendation models and datasets, providing a practical tool
for interpretable and controllable personalization. Code and evaluation
resources are available at https://github.com/DeltaLabTLV/Monosemanticity4Rec.
\\ ( https://arxiv.org/abs/2511.18024 ,  2278kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18047
Date: Sat, 22 Nov 2025 12:59:04 GMT   (506kb)

Title: Fidelity-Aware Recommendation Explanations via Stochastic Path
 Integration
Authors: Oren Barkan, Yahlly Schein, Yehonatan Elisha, Veronika Bogina, Mikhail
 Baklanov, Noam Koenigstein
Categories: cs.IR cs.AI cs.LG
Journal-ref: AAAI 2026
\\
 Explanation fidelity, which measures how accurately an explanation reflects a
model's true reasoning, remains critically underexplored in recommender
systems. We introduce SPINRec (Stochastic Path Integration for Neural
Recommender Explanations), a model-agnostic approach that adapts
path-integration techniques to the sparse and implicit nature of recommendation
data. To overcome the limitations of prior methods, SPINRec employs stochastic
baseline sampling: instead of integrating from a fixed or unrealistic baseline,
it samples multiple plausible user profiles from the empirical data
distribution and selects the most faithful attribution path. This design
captures the influence of both observed and unobserved interactions, yielding
more stable and personalized explanations. We conduct the most comprehensive
fidelity evaluation to date across three models (MF, VAE, NCF), three datasets
(ML1M, Yahoo! Music, Pinterest), and a suite of counterfactual metrics,
including AUC-based perturbation curves and fixed-length diagnostics. SPINRec
consistently outperforms all baselines, establishing a new benchmark for
faithful explainability in recommendation. Code and evaluation tools are
publicly available at https://github.com/DeltaLabTLV/SPINRec.
\\ ( https://arxiv.org/abs/2511.18047 ,  506kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18207
Date: Sat, 22 Nov 2025 22:44:46 GMT   (752kb)

Title: ProHD: Projection-Based Hausdorff Distance Approximation
Authors: Jiuzhou Fu, Luanzheng Guo, Nathan R. Tallent, Dongfang Zhao
Categories: cs.IR cs.LG
\\
 The Hausdorff distance (HD) is a robust measure of set dissimilarity, but
computing it exactly on large, high-dimensional datasets is prohibitively
expensive. We propose \textbf{ProHD}, a projection-guided approximation
algorithm that dramatically accelerates HD computation while maintaining high
accuracy. ProHD identifies a small subset of candidate "extreme" points by
projecting the data onto a few informative directions (such as the centroid
axis and top principal components) and computing the HD on this subset. This
approach guarantees an underestimate of the true HD with a bounded additive
error and typically achieves results within a few percent of the exact value.
In extensive experiments on image, physics, and synthetic datasets (up to two
million points in $D=256$), ProHD runs 10--100$\times$ faster than exact
algorithms while attaining 5--20$\times$ lower error than random sampling-based
approximations. Our method enables practical HD calculations in scenarios like
large vector databases and streaming data, where quick and reliable set
distance estimation is needed.
\\ ( https://arxiv.org/abs/2511.18207 ,  752kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18261
Date: Sun, 23 Nov 2025 03:22:53 GMT   (317kb)

Title: LLM Reasoning for Cold-Start Item Recommendation
Authors: Shijun Li, Yu Wang, Jin Wang, Ying Li, Joydeep Ghosh, Anne Cocos
Categories: cs.IR cs.AI
\\
 Large Language Models (LLMs) have shown significant potential for improving
recommendation systems through their inherent reasoning capabilities and
extensive knowledge base. Yet, existing studies predominantly address
warm-start scenarios with abundant user-item interaction data, leaving the more
challenging cold-start scenarios, where sparse interactions hinder traditional
collaborative filtering methods, underexplored. To address this limitation, we
propose novel reasoning strategies designed for cold-start item recommendations
within the Netflix domain. Our method utilizes the advanced reasoning
capabilities of LLMs to effectively infer user preferences, particularly for
newly introduced or rarely interacted items. We systematically evaluate
supervised fine-tuning, reinforcement learning-based fine-tuning, and hybrid
approaches that combine both methods to optimize recommendation performance.
Extensive experiments on real-world data demonstrate significant improvements
in both methodological efficacy and practical performance in cold-start
recommendation contexts. Remarkably, our reasoning-based fine-tuned models
outperform Netflix's production ranking model by up to 8% in certain cases.
\\ ( https://arxiv.org/abs/2511.18261 ,  317kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18279
Date: Sun, 23 Nov 2025 04:09:28 GMT   (2714kb)

Title: Democratic Recommendation with User and Item Representatives Produced by
 Graph Condensation
Authors: Jiahao Liang, Haoran Yang, Xiangyu Zhao, Zhiwen Yu, Guandong Xu, Wanyu
 Wang, Kaixiang Yang
Categories: cs.IR
\\
 The challenges associated with large-scale user-item interaction graphs have
attracted increasing attention in graph-based recommendation systems, primarily
due to computational inefficiencies and inadequate information propagation.
Existing methods provide partial solutions but suffer from notable limitations:
model-centric approaches, such as sampling and aggregation, often struggle with
generalization, while data-centric techniques, including graph sparsification
and coarsening, lead to information loss and ineffective handling of bipartite
graph structures. Recent advances in graph condensation offer a promising
direction by reducing graph size while preserving essential information,
presenting a novel approach to mitigating these challenges. Inspired by the
principles of democracy, we propose \textbf{DemoRec}, a framework that
leverages graph condensation to generate user and item representatives for
recommendation tasks. By constructing a compact interaction graph and
clustering nodes with shared characteristics from the original graph, DemoRec
significantly reduces graph size and computational complexity. Furthermore, it
mitigates the over-reliance on high-order information, a critical challenge in
large-scale bipartite graphs. Extensive experiments conducted on four public
datasets demonstrate the effectiveness of DemoRec, showcasing substantial
improvements in recommendation performance, computational efficiency, and
robustness compared to SOTA methods.
\\ ( https://arxiv.org/abs/2511.18279 ,  2714kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18282
Date: Sun, 23 Nov 2025 04:24:58 GMT   (6110kb)

Title: Large Language Model Enhanced Graph Invariant Contrastive Learning for
 Out-of-Distribution Recommendation
Authors: Jiahao Liang, Haoran Yang, Xiangyu Zhao, Zhiwen Yu, Mianjie Li, Chuan
 Shi, Kaixiang Yang
Categories: cs.IR
\\
 Out-of-distribution (OOD) generalization has emerged as a significant
challenge in graph recommender systems. Traditional graph neural network
algorithms often fail because they learn spurious environmental correlations
instead of stable causal relationships, leading to substantial performance
degradation under distribution shifts. While recent advancements in Large
Language Models (LLMs) offer a promising avenue due to their vast world
knowledge and reasoning capabilities, effectively integrating this knowledge
with the fine-grained topology of specific graphs to solve the OOD problem
remains a significant challenge. To address these issues, we propose
{$\textbf{Inv}$ariant $\textbf{G}$raph $\textbf{C}$ontrastive Learning with
$\textbf{LLM}$s for Out-of-Distribution Recommendation (InvGCLLM)}, an
innovative causal learning framework that synergistically integrates the
strengths of data-driven models and knowledge-driven LLMs. Our framework first
employs a data-driven invariant learning model to generate causal confidence
scores for each user-item interaction. These scores then guide an LLM to
perform targeted graph refinement, leveraging its world knowledge to prune
spurious connections and augment missing causal links. Finally, the
structurally purified graphs provide robust supervision for a causality-guided
contrastive learning objective, enabling the model to learn representations
that are resilient to spurious correlations. Experiments conducted on four
public datasets demonstrate that InvGCLLM achieves significant improvements in
out-of-distribution recommendation, consistently outperforming state-of-the-art
baselines.
\\ ( https://arxiv.org/abs/2511.18282 ,  6110kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18342
Date: Sun, 23 Nov 2025 08:34:30 GMT   (232kb)

Title: UFO: Unfair-to-Fair Evolving Mitigates Unfairness in LLM-based
 Recommender Systems via Self-Play Fine-tuning
Authors: Jiaming Zhang, Yuyuan Li, Xiaohua Feng, Zhifei Ren, Li Zhang, Chaochao
 Chen
Categories: cs.IR
\\
 Large language model-based Recommender Systems (LRSs) have demonstrated
superior recommendation performance by integrating pre-training with Supervised
Fine-Tuning (SFT). However, this approach introduces item-side unfairness.
Existing studies primarily attribute this issue to the absence of fairness
constraints during SFT and attempt to mitigate unfairness via re-weighting and
re-ranking methods. In this paper, we find that unfairness arises not only from
SFT but also from pre-training, where inherent biases are further amplified
during SFT. This finding underscores the failure of current methods to address
the root causes of unfairness. Moreover, current methods struggle to preserve
satisfactory recommendation performance. To tackle these issues, we propose an
Unfair-to-Fair evOlving (UFO) framework using a self-play mechanism,
formulating unfairness mitigation as a two-player game. UFO alternates between
two player roles: the \textit{judger}, which identifies unfairness from both
pre-training and SFT, and the \textit{corrector}, which adjusts the LRS to
address identified unfairness while preserving recommendation performance.
Iterative optimization between these roles enables UFO to completely resolve
unfairness. Extensive experiments demonstrate that UFO effectively mitigates
unfairness while improving recommendation performance.
\\ ( https://arxiv.org/abs/2511.18342 ,  232kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18347
Date: Sun, 23 Nov 2025 08:46:27 GMT   (2277kb)

Title: Time Matters: Enhancing Sequential Recommendations with Time-Guided
 Graph Neural ODEs
Authors: Haoyan Fu, Zhida Qin, Shixiao Yang, Haoyao Zhang, Bin Lu, Shuang Li,
 Tianyu Huang, John C.S. Lui
Categories: cs.IR
\\
 Sequential recommendation (SR) is widely deployed in e-commerce platforms,
streaming services, etc., revealing significant potential to enhance user
experience. However, existing methods often overlook two critical factors:
irregular user interests between interactions and highly uneven item
distributions over time. The former factor implies that actual user preferences
are not always continuous, and long-term historical interactions may not be
relevant to current purchasing behavior. Therefore, relying only on these
historical interactions for recommendations may result in a lack of user
interest at the target time. The latter factor, characterized by peaks and
valleys in interaction frequency, may result from seasonal trends, special
events, or promotions. These externally driven distributions may not align with
individual user interests, leading to inaccurate recommendations. To address
these deficiencies, we propose TGODE to both enhance and capture the long-term
historical interactions. Specifically, we first construct a user time graph and
item evolution graph, which utilize user personalized preferences and global
item distribution information, respectively. To tackle the temporal sparsity
caused by irregular user interactions, we design a time-guided diffusion
generator to automatically obtain an augmented time-aware user graph.
Additionally, we devise a user interest truncation factor to efficiently
identify sparse time intervals and achieve balanced preference inference. After
that, the augmented user graph and item graph are fed into a generalized graph
neural ordinary differential equation (ODE) to align with the evolution of user
preferences and item distributions. This allows two patterns of information
evolution to be matched over time. Experimental results demonstrate that TGODE
outperforms baseline methods across five datasets, with improvements ranging
from 10% to 46%.
\\ ( https://arxiv.org/abs/2511.18347 ,  2277kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18645
Date: Sun, 23 Nov 2025 23:04:21 GMT   (146kb)

Title: A Recommender System Based on Binary Matrix Representations for
 Cognitive Disorders
Authors: Raoul H. Kutil, Georg Zimmermann, Christian Borgelt
Categories: cs.IR
Comments: 19 pages, 1 figure, 3 tables
MSC-class: 68T50 (Primary) 68R05 (Secondary)
ACM-class: H.3.3; H.3.4
\\
 Diagnosing cognitive (mental health) disorders is a delicate and complex
task. Identifying the next most informative symptoms to assess, in order to
distinguish between possible disorders, presents an additional challenge. This
process requires comprehensive knowledge of diagnostic criteria and symptom
overlap across disorders, making it difficult to navigate based on symptoms
alone. This research aims to develop a recommender system for cognitive
disorder diagnosis using binary matrix representations. The core algorithm
utilizes a binary matrix of disorders and their symptom combinations. It
filters through the rows and columns based on the patient's current symptoms to
identify potential disorders and recommend the most informative next symptoms
to examine. A prototype of the recommender system was implemented in Python.
Using synthetic test and some real-life data, the system successfully
identified plausible disorders from an initial symptom set and recommended
further symptoms to refine the diagnosis. It also provided additional context
on the symptom-disorder relationships. Although this is a prototype, the
recommender system shows potential as a clinical support tool. A
fully-developed application of this recommender system may assist mental health
professionals in identifying relevant disorders more efficiently and guiding
symptom-specific follow-up investigations to improve diagnostic accuracy.
\\ ( https://arxiv.org/abs/2511.18645 ,  146kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18717
Date: Mon, 24 Nov 2025 03:16:10 GMT   (1676kb)

Title: When and What to Recommend: Joint Modeling of Timing and Content for
 Active Sequential Recommendation
Authors: Jin Chai, Xiaoxiao Ma, Jian Yang, Jia Wu
Categories: cs.IR cs.LG
Comments: 10 pages, 5 figures. Submitted to arXiv
\\
 Sequential recommendation models user preferences to predict the next target
item. Most existing work is passive, where the system responds only when users
open the application, missing chances after closure. We investigate active
recommendation, which predicts the next interaction time and actively delivers
items. Two challenges: accurately estimating the Time of Interest (ToI) and
generating Item of Interest (IoI) conditioned on the predicted ToI. We propose
PASRec, a diffusion-based framework that aligns ToI and IoI via a joint
objective. Experiments on five benchmarks show superiority over eight
state-of-the-art baselines under leave-one-out and temporal splits.
\\ ( https://arxiv.org/abs/2511.18717 ,  1676kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18740
Date: Mon, 24 Nov 2025 04:10:46 GMT   (1194kb)

Title: Multimodal Large Language Models with Adaptive Preference Optimization
 for Sequential Recommendation
Authors: Yu Wang, Yonghui Yang, Le Wu, Yi Zhang and Richang Hong
Categories: cs.IR
Comments: 11 pages,6 figures
\\
 Recent advances in Large Language Models (LLMs) have opened new avenues for
sequential recommendation by enabling natural language reasoning over user
behavior sequences. A common approach formulates recommendation as a language
modeling task, where interaction histories are transformed into prompts and
user preferences are learned via supervised fine-tuning. However, these methods
operate solely in the textual modality and often miss users' fine-grained
interests, especially when shaped by rich visual signals such as product images
or movie posters. Multimodal Large Language Models (MLLMs) offer a promising
alternative by aligning text and vision in a shared semantic space. A prevalent
training paradigm applies Supervised Fine-Tuning (SFT) followed by Direct
Preference Optimization (DPO) to model user preferences. Yet, two core
challenges remain: 1) Imbalanced sample hardness, where random negative
sampling causes overfitting on easy examples and under-training on hard ones;
2) Cross-modal semantic bias, where the fixed reference model in DPO prevents
the policy model from correcting modality misalignments--especially over long
sequences. To address these issues, we propose a Multimodal LLM framework that
integrates Hardness-aware and Noise-regularized preference optimization for
Recommendation (HaNoRec). Specifically, HaNoRec dynamically adjusts
optimization weights based on both the estimated hardness of each training
sample and the policy model's real-time responsiveness, prioritizing harder
examples. It further introduces Gaussian-perturbed distribution optimization on
output logits to enhance cross-modal semantic consistency and reduce modality
bias inherited from the reference model.
\\ ( https://arxiv.org/abs/2511.18740 ,  1194kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18805
Date: Mon, 24 Nov 2025 06:20:02 GMT   (396kb)

Title: STORE: Semantic Tokenization, Orthogonal Rotation and Efficient
 Attention for Scaling Up Ranking Models
Authors: Yi Xu, Chaofan Fan, Jinxin Hu, Yu Zhang, Zeng Xiaoyi and Jing Zhang
Categories: cs.IR
\\
 Ranking models have become an important part of modern personalized
recommendation systems. However, significant challenges persist in handling
high-cardinality, heterogeneous, and sparse feature spaces, particularly
regarding model scalability and efficiency. We identify two key bottlenecks:
(i) Representation Bottleneck: Driven by the high cardinality and dynamic
nature of features, model capacity is forced into sparse-activated embedding
layers, leading to low-rank representations. This, in turn, triggers phenomena
like "One-Epoch" and "Interaction-Collapse," ultimately hindering model
scalability.(ii) Computational Bottleneck: Integrating all heterogeneous
features into a unified model triggers an explosion in the number of feature
tokens, rendering traditional attention mechanisms computationally demanding
and susceptible to attention dispersion. To dismantle these barriers, we
introduce STORE, a unified and scalable token-based ranking framework built
upon three core innovations: (1) Semantic Tokenization fundamentally tackles
feature heterogeneity and sparsity by decomposing high-cardinality sparse
features into a compact set of stable semantic tokens; and (2) Orthogonal
Rotation Transformation is employed to rotate the subspace spanned by
low-cardinality static features, which facilitates more efficient and effective
feature interactions; and (3) Efficient attention that filters low-contributing
tokens to improve computional efficiency while preserving model accuracy.
Across extensive offline experiments and online A/B tests, our framework
consistently improves prediction accuracy(online CTR by 2.71%, AUC by 1.195%)
and training effeciency (1.84 throughput).
\\ ( https://arxiv.org/abs/2511.18805 ,  396kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18997
Date: Mon, 24 Nov 2025 11:22:46 GMT   (317kb)

Title: Heterogeneous Multi-treatment Uplift Modeling for Trade-off Optimization
 in Short-Video Recommendation
Authors: Chenhao Zhai, Chang Meng, Xueliang Wang, Shuchang Liu, Xiaolong Hu,
 Shisong Tang, Xiaoqiang Feng, Xiu Li
Categories: cs.IR
Comments: Accepted by KDD 2026
\\
 The rapid proliferation of short videos on social media platforms presents
unique challenges and opportunities for recommendation systems. Users exhibit
diverse preferences, and the responses resulting from different strategies
often conflict with one another, potentially exhibiting inverse correlations
between metrics such as watch time and video view counts. Existing uplift
models face limitations in handling the heterogeneous multi-treatment scenarios
of short-video recommendations, often failing to effectively capture both the
synergistic and individual causal effects of different strategies. Furthermore,
traditional fixed-weight approaches for balancing these responses lack
personalization and can result in biased decision-making. To address these
issues, we propose a novel Heterogeneous Multi-treatment Uplift Modeling (HMUM)
framework for trade-off optimization in short-video recommendations. HMUM
comprises an Offline Hybrid Uplift Modeling (HUM) module, which captures the
synergistic and individual effects of multiple strategies, and an Online
Dynamic Decision-Making (DDM) module, which estimates the value weights of
different user responses in real-time for personalized decision-making.
Evaluated on two public datasets, an industrial dataset, and through online A/B
experiments on the Kuaishou platform, our model demonstrated superior offline
performance and significant improvements in key metrics. It is now fully
deployed on the platform, benefiting hundreds of millions of users.
\\ ( https://arxiv.org/abs/2511.18997 ,  317kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19162
Date: Sat, 27 Sep 2025 17:26:17 GMT   (806kb)

Title: BioArtlas: Computational Clustering of Multi-Dimensional Complexity in
 Bioart
Authors: Joonhyung Bae
Categories: cs.IR cs.CY cs.HC cs.LG cs.MM
\\
 Bioart's hybrid nature spanning art, science, technology, ethics, and
politics defies traditional single-axis categorization. I present BioArtlas,
analyzing 81 bioart works across thirteen curated dimensions using novel
axis-aware representations that preserve semantic distinctions while enabling
cross-dimensional comparison. Our codebook-based approach groups related
concepts into unified clusters, addressing polysemy in cultural terminology.
Comprehensive evaluation of up to 800 representation-space-algorithm
combinations identifies Agglomerative clustering at k=15 on 4D UMAP as optimal
(silhouette 0.664 +/- 0.008, trustworthiness/continuity 0.805/0.812). The
approach reveals four organizational patterns: artist-specific methodological
cohesion, technique-based segmentation, temporal artistic evolution, and
trans-temporal conceptual affinities. By separating analytical optimization
from public communication, I provide rigorous analysis and accessible
exploration through an interactive web interface (https://www.bioartlas.com)
with the dataset publicly available
(https://github.com/joonhyungbae/BioArtlas).
\\ ( https://arxiv.org/abs/2511.19162 ,  806kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19324
Date: Mon, 24 Nov 2025 17:17:40 GMT   (985kb)

Title: What Drives Cross-lingual Ranking? Retrieval Approaches with
 Multilingual Language Models
Authors: Roksana Goworek, Olivia Macmillan-Scott, Eda B. \"Ozyi\u{g}it
Categories: cs.IR cs.AI cs.CL
\\
 Cross-lingual information retrieval (CLIR) enables access to multilingual
knowledge but remains challenging due to disparities in resources, scripts, and
weak cross-lingual semantic alignment in embedding models. Existing pipelines
often rely on translation and monolingual retrieval heuristics, which add
computational overhead and noise, degrading performance. This work
systematically evaluates four intervention types, namely document translation,
multilingual dense retrieval with pretrained encoders, contrastive learning at
word, phrase, and query-document levels, and cross-encoder re-ranking, across
three benchmark datasets. We find that dense retrieval models trained
specifically for CLIR consistently outperform lexical matching methods and
derive little benefit from document translation. Contrastive learning mitigates
language biases and yields substantial improvements for encoders with weak
initial alignment, and re-ranking can be effective, but depends on the quality
of the cross-encoder training data. Although high-resource languages still
dominate overall performance, gains over lexical and document-translated
baselines are most pronounced for low-resource and cross-script pairs. These
findings indicate that cross-lingual search systems should prioritise semantic
multilingual embeddings and targeted learning-based alignment over
translation-based pipelines, particularly for cross-script and under-resourced
languages.
\\ ( https://arxiv.org/abs/2511.19324 ,  985kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19325
Date: Mon, 24 Nov 2025 17:18:25 GMT   (2005kb)

Title: Generative Query Expansion with Multilingual LLMs for Cross-Lingual
 Information Retrieval
Authors: Olivia Macmillan-Scott and Roksana Goworek and Eda B. \"Ozyi\u{g}it
Categories: cs.IR cs.AI cs.CL
\\
 Query expansion is the reformulation of a user query by adding semantically
related information, and is an essential component of monolingual and
cross-lingual information retrieval used to ensure that relevant documents are
not missed. Recently, multilingual large language models (mLLMs) have shifted
query expansion from semantic augmentation with synonyms and related words to
pseudo-document generation. Pseudo-documents both introduce additional relevant
terms and bridge the gap between short queries and long documents, which is
particularly beneficial in dense retrieval. This study evaluates recent mLLMs
and fine-tuned variants across several generative expansion strategies to
identify factors that drive cross-lingual retrieval performance. Results show
that query length largely determines which prompting technique is effective,
and that more elaborate prompts often do not yield further gains. Substantial
linguistic disparities persist: cross-lingual query expansion can produce the
largest improvements for languages with the weakest baselines, yet retrieval is
especially poor between languages written in different scripts. Fine-tuning is
found to lead to performance gains only when the training and test data are of
similar format. These outcomes underline the need for more balanced
multilingual and cross-lingual training and evaluation resources.
\\ ( https://arxiv.org/abs/2511.19325 ,  2005kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19349
Date: Mon, 24 Nov 2025 17:50:18 GMT   (33kb)

Title: Revisiting Feedback Models for HyDE
Authors: Nour Jedidi, Jimmy Lin
Categories: cs.IR
\\
 Recent approaches that leverage large language models (LLMs) for
pseudo-relevance feedback (PRF) have generally not utilized well-established
feedback models like Rocchio and RM3 when expanding queries for sparse
retrievers like BM25. Instead, they often opt for a simple string concatenation
of the query and LLM-generated expansion content. But is this optimal? To
answer this question, we revisit and systematically evaluate traditional
feedback models in the context of HyDE, a popular method that enriches query
representations with LLM-generated hypothetical answer documents. Our
experiments show that HyDE's effectiveness can be substantially improved when
leveraging feedback algorithms such as Rocchio to extract and weight expansion
terms, providing a simple way to further enhance the accuracy of LLM-based PRF
methods.
\\ ( https://arxiv.org/abs/2511.19349 ,  33kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17553
Date: Wed, 12 Nov 2025 11:42:17 GMT   (532kb)

Title: Practical Machine Learning for Aphasic Discourse Analysis
Authors: Jason M. Pittman, Anton Phillips Jr., Yesenia Medina-Santos, Brielle
 C. Stark
Categories: cs.LG cs.AI cs.CL
Comments: 14 pages, 4 tables, 2 figures
\\
 Analyzing spoken discourse is a valid means of quantifying language ability
in persons with aphasia. There are many ways to quantify discourse, one common
way being to evaluate the informativeness of the discourse. That is, given the
total number of words produced, how many of those are context-relevant and
accurate. This type of analysis is called Correct Information Unit (CIU)
analysis and is one of the most prevalent discourse analyses used by
speech-language pathologists (SLPs). Despite this, CIU analysis in the clinic
remains limited due to the manual labor needed by SLPs to code and analyze
collected speech. Recent advances in machine learning (ML) seek to augment such
labor by automating modeling of propositional, macrostructural, pragmatic, and
multimodal dimensions of discourse. To that end, this study evaluated five ML
models for reliable identification of Correct Information Units (CIUs, Nicholas
& Brookshire, 1993), during a picture description task. The five supervised ML
models were trained using randomly selected human-coded transcripts and
accompanying words and CIUs from persons with aphasia. The baseline model
training produced a high accuracy across transcripts for word vs non-word, with
all models achieving near perfect performance (0.995) with high AUC range
(0.914 min, 0.995 max). In contrast, CIU vs non-CIU showed a greater
variability, with the k-nearest neighbor (k-NN) model the highest accuracy
(0.824) and second highest AUC (0.787). These findings indicate that while the
supervised ML models can distinguish word from not word, identifying CIUs is
challenging.
\\ ( https://arxiv.org/abs/2511.17553 ,  532kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17564
Date: Thu, 13 Nov 2025 20:51:17 GMT   (2952kb)

Title: Classification of Transient Astronomical Object Light Curves Using LSTM
 Neural Networks
Authors: Guilherme Grancho D. Fernandes, Marco A. Barroca, Mateus dos Santos,
 Rafael S. Oliveira
Categories: cs.LG astro-ph.IM cs.AI cs.CV
Comments: 12 pages, 11 figures, 2 tables
\\
 This study presents a bidirectional Long Short-Term Memory (LSTM) neural
network for classifying transient astronomical object light curves from the
Photometric LSST Astronomical Time-series Classification Challenge (PLAsTiCC)
dataset. The original fourteen object classes were reorganized into five
generalized categories (S-Like, Fast, Long, Periodic, and Non-Periodic) to
address class imbalance. After preprocessing with padding, temporal rescaling,
and flux normalization, a bidirectional LSTM network with masking layers was
trained and evaluated on a test set of 19,920 objects. The model achieved
strong performance for S-Like and Periodic classes, with ROC area under the
curve (AUC) values of 0.95 and 0.99, and Precision-Recall AUC values of 0.98
and 0.89, respectively. However, performance was significantly lower for Fast
and Long classes (ROC AUC of 0.68 for Long class), and the model exhibited
difficulty distinguishing between Periodic and Non-Periodic objects. Evaluation
on partial light curve data (5, 10,and 20 days from detection) revealed
substantial performance degradation, with increased misclassification toward
the S-Like class. These findings indicate that class imbalance and limited
temporal information are primary limitations, suggesting that class balancing
strategies and preprocessing techniques focusing on detection moments could
improve performance.
\\ ( https://arxiv.org/abs/2511.17564 ,  2952kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17566
Date: Fri, 14 Nov 2025 03:20:02 GMT   (370kb)

Title: Root Cause Analysis for Microservice Systems via Cascaded Conditional
 Learning with Hypergraphs
Authors: Shuaiyu Xie, Hanbin He, Jian Wang, Bing Li
Categories: cs.LG cs.DC cs.SE
\\
 Root cause analysis in microservice systems typically involves two core
tasks: root cause localization (RCL) and failure type identification (FTI).
Despite substantial research efforts, conventional diagnostic approaches still
face two key challenges. First, these methods predominantly adopt a joint
learning paradigm for RCL and FTI to exploit shared information and reduce
training time. However, this simplistic integration neglects the causal
dependencies between tasks, thereby impeding inter-task collaboration and
information transfer. Second, these existing methods primarily focus on
point-to-point relationships between instances, overlooking the group nature of
inter-instance influences induced by deployment configurations and load
balancing. To overcome these limitations, we propose CCLH, a novel root cause
analysis framework that orchestrates diagnostic tasks based on cascaded
conditional learning. CCLH provides a three-level taxonomy for group influences
between instances and incorporates a heterogeneous hypergraph to model these
relationships, facilitating the simulation of failure propagation. Extensive
experiments conducted on datasets from three microservice benchmarks
demonstrate that CCLH outperforms state-of-the-art methods in both RCL and FTI.
\\ ( https://arxiv.org/abs/2511.17566 ,  370kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17568
Date: Fri, 14 Nov 2025 06:11:13 GMT   (381kb)

Title: Enhancing Robustness of Offline Reinforcement Learning Under Data
 Corruption via Sharpness-Aware Minimization
Authors: Le Xu, Jiayu Chen
Categories: cs.LG cs.AI
Comments: Accepted as an Oral Presentation at the AAAI 2026 Student Abstract
 and Poster Program (SAPP)
\\
 Offline reinforcement learning (RL) is vulnerable to real-world data
corruption, with even robust algorithms failing under challenging observation
and mixture corruptions. We posit this failure stems from data corruption
creating sharp minima in the loss landscape, leading to poor generalization. To
address this, we are the first to apply Sharpness-Aware Minimization (SAM) as a
general-purpose, plug-and-play optimizer for offline RL. SAM seeks flatter
minima, guiding models to more robust parameter regions. We integrate SAM into
strong baselines for data corruption: IQL, a top-performing offline RL
algorithm in this setting, and RIQL, an algorithm designed specifically for
data-corruption robustness. We evaluate them on D4RL benchmarks with both
random and adversarial corruption. Our SAM-enhanced methods consistently and
significantly outperform the original baselines. Visualizations of the reward
surface confirm that SAM finds smoother solutions, providing strong evidence
for its effectiveness in improving the robustness of offline RL agents.
\\ ( https://arxiv.org/abs/2511.17568 ,  381kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17573
Date: Fri, 14 Nov 2025 22:53:03 GMT   (49kb)

Title: Binary BPE: A Family of Cross-Platform Tokenizers for Binary Analysis
Authors: Michael J. Bommarito II
Categories: cs.LG cs.AI cs.CR
Comments: 17 pages, 3 figures, 9 tables. Paper source available at
 https://github.com/mjbommar/binary-tokenizer-paper ; tokenizers available at
 https://huggingface.co/mjbommar -
 mjbommar/binary-tokenizer-001-{4k,8k,16k,32k,64k}
ACM-class: D.2.8; I.2.7; K.6.5
\\
 Sequence models for binary analysis are bottlenecked by byte-level
tokenization: raw bytes waste precious context window capacity for transformers
and other neural network architectures, and many existing text-oriented
tokenizers fail on arbitrary 0x00--0xFF sequences. To address this issue, we
introduce the Binary BPE tokenizer family, a set of cross-platform Byte Pair
Encoding (BPE) tokenizers for executables trained on a large corpus of binaries
spanning multiple platforms, architectures, and operating systems, including
Linux, Windows, macOS, Android, and malware sources. We release trained
tokenizers with vocabularies of 4K, 8K, 16K, 32K, and 64K tokens, enabling both
systematic scaling studies and practical deployment from resource-constrained
edge devices to high-throughput datacenters. These tokenizers discover
interpretable patterns (ELF/PE headers, instruction sequences, cross-platform
strings) while yielding multi-byte compression per token. On representative
uncompressed executables (e.g., ELF/PE/Mach-O rather than compressed APKs), the
Binary BPE tokenizers typically allow for roughly 2-3x more binary content per
fixed-length transformer context window than raw bytes, enabling more efficient
research and practical deployment for content identification, malware
detection, reverse engineering, and optimization. We release the trained Binary
BPE tokenizers on HuggingFace, providing a drop-in, open-source foundation for
binary-focused language models and context-efficient agentic tools.
\\ ( https://arxiv.org/abs/2511.17573 ,  49kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17577
Date: Sat, 15 Nov 2025 09:21:44 GMT   (224kb)

Title: Efficient Mathematical Reasoning Models via Dynamic Pruning and
 Knowledge Distillation
Authors: Fengming Yu, Qingyu Meng, Haiwei Pan, Kejia Zhang
Categories: cs.LG cs.AI cs.CL
Comments: 12 pages, 1 figure
\\
 With the rapid development of deep learning, large language models have shown
strong capabilities in complex reasoning tasks such as mathematical equation
solving. However, their substantial computational and storage costs hinder
practical deployment. This paper proposes a lightweight optimization method
that integrates dynamic attention head pruning with knowledge distillation. The
approach dynamically evaluates the importance of each attention head in the
multi-head attention mechanism using a combination of weight norms and entropy,
and prunes redundant heads in real time to reduce computational overhead. To
mitigate performance degradation, knowledge distillation transfers information
from the original model to the pruned student, enabling the smaller model to
preserve reasoning ability. Experiments conducted on both Math23k and ASDiv-A
verify the effectiveness of the proposed method. For example, on Math23k with a
30% pruning ratio, parameters are reduced by 18.7%, inference speed is improved
by 27.5%, FLOPs are reduced by 19.3%, and accuracy drops only 0.7% (from 84.4%
to 83.7%). These results demonstrate that the method achieves substantial
efficiency gains while maintaining strong reasoning performance, providing a
practical solution for efficient deployment of large language models in
mathematical reasoning tasks.
\\ ( https://arxiv.org/abs/2511.17577 ,  224kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17579
Date: Sat, 15 Nov 2025 13:33:26 GMT   (2512kb)

Title: Multi-Value Alignment for LLMs via Value Decorrelation and Extrapolation
Authors: Hefei Xu, Le Wu, Chen Cheng, Hao Liu
Categories: cs.LG cs.AI
Comments: accepted by AAAI26 oral; 12 pages
\\
 With the rapid advancement of large language models (LLMs), aligning them
with human values for safety and ethics has become a critical challenge. This
problem is especially challenging when multiple, potentially conflicting human
values must be considered and balanced. Although several variants of existing
alignment methods (such as Reinforcement Learning from Human Feedback (RLHF)
and Direct Preference Optimization (DPO)) have been proposed to address
multi-value alignment, they suffer from notable limitations: 1) they are often
unstable and inefficient in multi-value optimization; and 2) they fail to
effectively handle value conflicts. As a result, these approaches typically
struggle to achieve optimal trade-offs when aligning multiple values.
 To address this challenge, we propose a novel framework called Multi-Value
Alignment (MVA). It mitigates alignment degradation caused by parameter
interference among diverse human values by minimizing their mutual information.
Furthermore, we propose a value extrapolation strategy to efficiently explore
the Pareto frontier, thereby constructing a set of LLMs with diverse value
preferences. Extensive experiments demonstrate that MVA consistently
outperforms existing baselines in aligning LLMs with multiple human values.
\\ ( https://arxiv.org/abs/2511.17579 ,  2512kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17581
Date: Sat, 15 Nov 2025 15:59:36 GMT   (13236kb)

Title: EgoCogNav: Cognition-aware Human Egocentric Navigation
Authors: Zhiwen Qiu, Ziang Liu, Wenqian Niu, Tapomayukh Bhattacharjee, Saleh
 Kalantari
Categories: cs.LG cs.CV
Comments: 11 pages, 4 figures
\\
 Modeling the cognitive and experiential factors of human navigation is
central to deepening our understanding of human-environment interaction and to
enabling safe social navigation and effective assistive wayfinding. Most
existing methods focus on forecasting motions in fully observed scenes and
often neglect human factors that capture how people feel and respond to space.
To address this gap, We propose EgoCogNav, a multimodal egocentric navigation
framework that predicts perceived path uncertainty as a latent state and
jointly forecasts trajectories and head motion by fusing scene features with
sensory cues. To facilitate research in the field, we introduce the
Cognition-aware Egocentric Navigation (CEN) dataset consisting 6 hours of
real-world egocentric recordings capturing diverse navigation behaviors in
real-world scenarios. Experiments show that EgoCogNav learns the perceived
uncertainty that highly correlates with human-like behaviors such as scanning,
hesitation, and backtracking while generalizing to unseen environments.
\\ ( https://arxiv.org/abs/2511.17581 ,  13236kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17582
Date: Sat, 15 Nov 2025 17:55:47 GMT   (1017kb)

Title: GateRA: Token-Aware Modulation for Parameter-Efficient Fine-Tuning
Authors: Jie Ou, Shuaihong Jiang, Yingjun Du, Cees G. M. Snoek
Categories: cs.LG cs.AI
Comments: Accepted by AAAI 2026
Journal-ref: AAAI 2026
\\
 Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, DoRA, and HiRA,
enable lightweight adaptation of large pre-trained models via low-rank updates.
However, existing PEFT approaches apply static, input-agnostic updates to all
tokens, disregarding the varying importance and difficulty of different inputs.
This uniform treatment can lead to overfitting on trivial content or
under-adaptation on more informative regions, especially in autoregressive
settings with distinct prefill and decoding dynamics. In this paper, we propose
GateRA, a unified framework that introduces token-aware modulation to
dynamically adjust the strength of PEFT updates. By incorporating adaptive
gating into standard PEFT branches, GateRA enables selective, token-level
adaptation, preserving pre-trained knowledge for well-modeled inputs while
focusing capacity on challenging cases. Empirical visualizations reveal
phase-sensitive behaviors, where GateRA automatically suppresses updates for
redundant prefill tokens while emphasizing adaptation during decoding. To
promote confident and efficient modulation, we further introduce an
entropy-based regularization that encourages near-binary gating decisions. This
regularization prevents diffuse update patterns and leads to interpretable,
sparse adaptation without hard thresholding. Finally, we present a theoretical
analysis showing that GateRA induces a soft gradient-masking effect over the
PEFT path, enabling continuous and differentiable control over adaptation.
Experiments on multiple commonsense reasoning benchmarks demonstrate that
GateRA consistently outperforms or matches prior PEFT methods.
\\ ( https://arxiv.org/abs/2511.17582 ,  1017kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17583
Date: Sat, 15 Nov 2025 22:51:58 GMT   (24223kb)

Title: Learning Straight Flows: Variational Flow Matching for Efficient
 Generation
Authors: Chenrui Ma, Xi Xiao, Tianyang Wang, Xiao Wang, Yanning Shen
Categories: cs.LG cs.CV
\\
 Flow Matching has limited ability in achieving one-step generation due to its
reliance on learned curved trajectories. Previous studies have attempted to
address this limitation by either modifying the coupling distribution to
prevent interpolant intersections or introducing consistency and mean-velocity
modeling to promote straight trajectory learning. However, these approaches
often suffer from discrete approximation errors, training instability, and
convergence difficulties. To tackle these issues, in the present work, we
propose \textbf{S}traight \textbf{V}ariational \textbf{F}low \textbf{M}atching
(\textbf{S-VFM}), which integrates a variational latent code representing the
``generation overview'' into the Flow Matching framework. \textbf{S-VFM}
explicitly enforces trajectory straightness, ideally producing linear
generation paths. The proposed method achieves competitive performance across
three challenge benchmarks and demonstrates advantages in both training and
inference efficiency compared with existing methods.
\\ ( https://arxiv.org/abs/2511.17583 ,  24223kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17584
Date: Sun, 16 Nov 2025 05:21:14 GMT   (171kb)

Title: LLM-Powered Text-Attributed Graph Anomaly Detection via
 Retrieval-Augmented Reasoning
Authors: Haoyan Xu, Ruizhi Qian, Zhengtao Yao, Ziyi Liu, Li Li, Yuqi Li, Yanshu
 Li, Wenqing Zheng, Daniele Rosa, Daniel Barcklow, Senthil Kumar, Jieyu Zhao,
 Yue Zhao
Categories: cs.LG cs.AI
\\
 Anomaly detection on attributed graphs plays an essential role in
applications such as fraud detection, intrusion monitoring, and misinformation
analysis. However, text-attributed graphs (TAGs), in which node information is
expressed in natural language, remain underexplored, largely due to the absence
of standardized benchmark datasets. In this work, we introduce TAG-AD, a
comprehensive benchmark for anomaly node detection on TAGs. TAG-AD leverages
large language models (LLMs) to generate realistic anomalous node texts
directly in the raw text space, producing anomalies that are semantically
coherent yet contextually inconsistent and thus more reflective of real-world
irregularities. In addition, TAG-AD incorporates multiple other anomaly types,
enabling thorough and reproducible evaluation of graph anomaly detection (GAD)
methods. With these datasets, we further benchmark existing unsupervised
GNN-based GAD methods as well as zero-shot LLMs for GAD.
 As part of our zero-shot detection setup, we propose a retrieval-augmented
generation (RAG)-assisted, LLM-based zero-shot anomaly detection framework. The
framework mitigates reliance on brittle, hand-crafted prompts by constructing a
global anomaly knowledge base and distilling it into reusable analysis
frameworks. Our experimental results reveal a clear division of strengths: LLMs
are particularly effective at detecting contextual anomalies, whereas GNN-based
methods remain superior for structural anomaly detection. Moreover,
RAG-assisted prompting achieves performance comparable to human-designed
prompts while eliminating manual prompt engineering, underscoring the practical
value of our RAG-assisted zero-shot LLM anomaly detection framework.
\\ ( https://arxiv.org/abs/2511.17584 ,  171kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17585
Date: Sun, 16 Nov 2025 05:31:11 GMT   (1209kb)

Title: PaSE: Prototype-aligned Calibration and Shapley-based Equilibrium for
 Multimodal Sentiment Analysis
Authors: Kang He, Boyu Chen, Yuzhe Ding, Fei Li, Chong Teng, Donghong Ji
Categories: cs.LG cs.AI cs.CV
Comments: Accepted by AAAI 2026
\\
 Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by
integrating textual, acoustic, and visual signals. Although multimodal fusion
is designed to leverage cross-modal complementarity, real-world scenarios often
exhibit modality competition: dominant modalities tend to overshadow weaker
ones, leading to suboptimal performance.In this paper, we propose PaSE, a novel
Prototype-aligned Calibration and Shapley-optimized Equilibrium framework,
which enhances collaboration while explicitly mitigating modality competition.
PaSE first applies Prototype-guided Calibration Learning (PCL) to refine
unimodal representations and align them through an Entropic Optimal Transport
mechanism that ensures semantic consistency. To further stabilize optimization,
we introduce a Dual-Phase Optimization strategy. A prototype-gated fusion
module is first used to extract shared representations, followed by
Shapley-based Gradient Modulation (SGM), which adaptively adjusts gradients
according to the contribution of each modality. Extensive experiments on
IEMOCAP, MOSI, and MOSEI confirm that PaSE achieves the superior performance
and effectively alleviates modality competition.
\\ ( https://arxiv.org/abs/2511.17585 ,  1209kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17587
Date: Sun, 16 Nov 2025 16:11:48 GMT   (1880kb)

Title: Emotion and Intention Guided Multi-Modal Learning for Sticker Response
 Selection
Authors: Yuxuan Hu, Jian Chen, Yuhao Wang, Zixuan Li, Jing Xiong, Pengyue Jia,
 Wei Wang, Chengming Li, Xiangyu Zhao
Categories: cs.LG cs.AI
\\
 Stickers are widely used in online communication to convey emotions and
implicit intentions. The Sticker Response Selection (SRS) task aims to select
the most contextually appropriate sticker based on the dialogue. However,
existing methods typically rely on semantic matching and model emotional and
intentional cues separately, which can lead to mismatches when emotions and
intentions are misaligned. To address this issue, we propose Emotion and
Intention Guided Multi-Modal Learning (EIGML). This framework is the first to
jointly model emotion and intention, effectively reducing the bias caused by
isolated modeling and significantly improving selection accuracy. Specifically,
we introduce Dual-Level Contrastive Framework to perform both intra-modality
and inter-modality alignment, ensuring consistent representation of emotional
and intentional features within and across modalities. In addition, we design
an Intention-Emotion Guided Multi-Modal Fusion module that integrates emotional
and intentional information progressively through three components:
Emotion-Guided Intention Knowledge Selection, Intention-Emotion Guided
Attention Fusion, and Similarity-Adjusted Matching Mechanism. This design
injects rich, effective information into the model and enables a deeper
understanding of the dialogue, ultimately enhancing sticker selection
performance. Experimental results on two public SRS datasets show that EIGML
consistently outperforms state-of-the-art baselines, achieving higher accuracy
and a better understanding of emotional and intentional features. Code is
provided in the supplementary materials.
\\ ( https://arxiv.org/abs/2511.17587 ,  1880kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17589
Date: Sun, 16 Nov 2025 19:51:04 GMT   (297kb)

Title: Llamazip: Leveraging LLaMA for Lossless Text Compression and Training
 Dataset Detection
Authors: S\"oren Dr\'eano, Derek Molloy, Noel Murphy
Categories: cs.LG cs.CL
\\
 This work introduces Llamazip, a novel lossless text compression algorithm
based on the predictive capabilities of the LLaMA3 language model. Llamazip
achieves significant data reduction by only storing tokens that the model fails
to predict, optimizing storage efficiency without compromising data integrity.
Key factors affecting its performance, including quantization and context
window size, are analyzed, revealing their impact on compression ratios and
computational requirements. Beyond compression, Llamazip demonstrates the
potential to identify whether a document was part of the training dataset of a
language model. This capability addresses critical concerns about data
provenance, intellectual property, and transparency in language model training.
\\ ( https://arxiv.org/abs/2511.17589 ,  297kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17590
Date: Mon, 17 Nov 2025 03:47:47 GMT   (11223kb)

Title: SHAP Distance: An Explainability-Aware Metric for Evaluating the
 Semantic Fidelity of Synthetic Tabular Data
Authors: Ke Yu, Shigeru Ishikura, Yukari Usukura, Yuki Shigoku, Teruaki Hayashi
Categories: cs.LG cs.AI cs.CY stat.ML
Comments: IEEE Bigdata
\\
 Synthetic tabular data, which are widely used in domains such as healthcare,
enterprise operations, and customer analytics, are increasingly evaluated to
ensure that they preserve both privacy and utility. While existing evaluation
practices typically focus on distributional similarity (e.g., the
Kullback-Leibler divergence) or predictive performance (e.g.,
Train-on-Synthetic-Test-on-Real (TSTR) accuracy), these approaches fail to
assess semantic fidelity, that is, whether models trained on synthetic data
follow reasoning patterns consistent with those trained on real data. To
address this gap, we introduce the SHapley Additive exPlanations (SHAP)
Distance, a novel explainability-aware metric that is defined as the cosine
distance between the global SHAP attribution vectors derived from classifiers
trained on real versus synthetic datasets. By analyzing datasets that span
clinical health records with physiological features, enterprise invoice
transactions with heterogeneous scales, and telecom churn logs with mixed
categorical-numerical attributes, we demonstrate that the SHAP Distance
reliably identifies semantic discrepancies that are overlooked by standard
statistical and predictive measures. In particular, our results show that the
SHAP Distance captures feature importance shifts and underrepresented tail
effects that the Kullback-Leibler divergence and
Train-on-Synthetic-Test-on-Real accuracy fail to detect. This study positions
the SHAP Distance as a practical and discriminative tool for auditing the
semantic fidelity of synthetic tabular data, and offers practical guidelines
for integrating attribution-based evaluation into future benchmarking
pipelines.
\\ ( https://arxiv.org/abs/2511.17590 ,  11223kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17593
Date: Mon, 17 Nov 2025 16:25:21 GMT   (10kb)

Title: Comparative Analysis of Large Language Model Inference Serving Systems:
 A Performance Study of vLLM and HuggingFace TGI
Authors: Saicharan Kolluru
Categories: cs.LG cs.DC cs.PF
Comments: 10 pages, benchmarking study of LLM inference systems
ACM-class: I.2.7; C.4
\\
 The deployment of Large Language Models (LLMs) in production environments
requires efficient inference serving systems that balance throughput, latency,
and resource utilization. This paper presents a comprehensive empirical
evaluation of two prominent open-source LLM serving frameworks: vLLM and
HuggingFace Text Generation Inference (TGI). We benchmark these systems across
multiple dimensions including throughput performance, end-to-end latency, GPU
memory utilization, and scalability characteristics using LLaMA-2 models
ranging from 7B to 70B parameters. Our experiments reveal that vLLM achieves up
to 24x higher throughput than TGI under high-concurrency workloads through its
novel PagedAttention mechanism, while TGI demonstrates lower tail latencies for
interactive single-user scenarios. We provide detailed performance profiles for
different deployment scenarios and offer practical recommendations for system
selection based on workload characteristics. Our findings indicate that the
choice between these frameworks should be guided by specific use-case
requirements: vLLM excels in high-throughput batch processing scenarios, while
TGI is better suited for latency-sensitive interactive applications with
moderate concurrency.
\\ ( https://arxiv.org/abs/2511.17593 ,  10kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17594
Date: Mon, 17 Nov 2025 18:25:51 GMT   (31kb)

Title: AutoSAGE: Input-Aware CUDA Scheduling for Sparse GNN Aggregation
 (SpMM/SDDMM) and CSR Attention
Authors: Aleksandar Stankovic
Categories: cs.LG cs.PF
Comments: 10 pages, several figures. Code and artifacts:
 https://github.com/SV25-22/AutoSAGE
\\
 Sparse GNN aggregations (CSR SpMM/SDDMM) vary widely in performance with
degree skew, feature width, and GPU micro-architecture. We present AutoSAGE, an
input-aware CUDA scheduler that chooses tiling and mapping per input using a
lightweight estimate refined by on-device micro-probes, with a guardrail that
safely falls back to vendor kernels and a persistent cache for deterministic
replay. AutoSAGE covers SpMM and SDDMM and composes into a CSR attention
pipeline (SDDMM -> row-softmax -> SpMM). On Reddit and OGBN-Products, it
matches vendor baselines at bandwidth-bound feature widths and finds gains at
small widths; on synthetic sparsity and skew stress tests it achieves up to
4.7x kernel-level speedups. We release CUDA sources, Python bindings, a
reproducible harness, and replayable cache logs.
\\ ( https://arxiv.org/abs/2511.17594 ,  31kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17595
Date: Mon, 17 Nov 2025 18:28:07 GMT   (3633kb)

Title: Boosting Reinforcement Learning in 3D Visuospatial Tasks Through
 Human-Informed Curriculum Design
Authors: Markus D. Solbach and John K. Tsotsos
Categories: cs.LG cs.AI
Comments: 12 pages, 11 figures, 5 tables
\\
 Reinforcement Learning is a mature technology, often suggested as a potential
route towards Artificial General Intelligence, with the ambitious goal of
replicating the wide range of abilities found in natural and artificial
intelligence, including the complexities of human cognition. While RL had shown
successes in relatively constrained environments, such as the classic Atari
games and specific continuous control problems, recent years have seen efforts
to expand its applicability. This work investigates the potential of RL in
demonstrating intelligent behaviour and its progress in addressing more complex
and less structured problem domains.
 We present an investigation into the capacity of modern RL frameworks in
addressing a seemingly straightforward 3D Same-Different visuospatial task.
While initial applications of state-of-the-art methods, including PPO,
behavioural cloning and imitation learning, revealed challenges in directly
learning optimal strategies, the successful implementation of curriculum
learning offers a promising avenue. Effective learning was achieved by
strategically designing the lesson plan based on the findings of a real-world
human experiment.
\\ ( https://arxiv.org/abs/2511.17595 ,  3633kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17598
Date: Mon, 17 Nov 2025 23:00:04 GMT   (858kb)

Title: Non-stationary and Varying-discounting Markov Decision Processes for
 Reinforcement Learning
Authors: Zhizuo Chen, Theodore T. Allen
Categories: cs.LG math.OC stat.ML
\\
 Algorithms developed under stationary Markov Decision Processes (MDPs) often
face challenges in non-stationary environments, and infinite-horizon
formulations may not directly apply to finite-horizon tasks. To address these
limitations, we introduce the Non-stationary and Varying-discounting MDP
(NVMDP) framework, which naturally accommodates non-stationarity and allows
discount rates to vary with time and transitions. Infinite-horizon, stationary
MDPs emerge as special cases of NVMDPs for identifying an optimal policy, and
finite-horizon MDPs are also subsumed within the NVMDP formulations. Moreover,
NVMDPs provide a flexible mechanism to shape optimal policies, without altering
the state space, action space, or the reward structure. We establish the
theoretical foundations of NVMDPs, including assumptions, state- and
action-value formulation and recursion, matrix representation, optimality
conditions, and policy improvement under finite state and action spaces.
Building on these results, we adapt dynamic programming and generalized
Q-learning algorithms to NVMDPs, along with formal convergence proofs. For
problems requiring function approximation, we extend the Policy Gradient
Theorem and the policy improvement bound in Trust Region Policy Optimization
(TRPO), offering proofs in both scalar and matrix forms. Empirical evaluations
in a non-stationary gridworld environment demonstrate that NVMDP-based
algorithms successfully recover optimal trajectories under multiple reward and
discounting schemes, whereas original Q-learning fails. These results
collectively show that NVMDPs provide a theoretically sound and practically
effective framework for reinforcement learning, requiring only minor
algorithmic modifications while enabling robust handling of non-stationarity
and explicit optimal policy shaping.
\\ ( https://arxiv.org/abs/2511.17598 ,  858kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17599
Date: Tue, 18 Nov 2025 02:23:47 GMT   (807kb)

Title: From Projection to Prediction: Beyond Logits for Scalable Language
 Models
Authors: Jianbing Dong and Jianbin Chang
Categories: cs.LG cs.AI
Comments: 17 pages, 2 figures, 4 algorithms
\\
 Training Large Language Models (LLMs) typically involves a two-stage pipeline
at the output layer: hidden states are projected into vocabulary logits via a
linear transformation (lm_head), followed by cross-entropy loss computation
against target tokens. While conceptually simple, this design incurs
substantial overhead. The intermediate logits tensor, with dimensions
proportional to batch size, sequence length, and vocabulary size, must be fully
materialized in GPU memory, even though only one target token per position is
ultimately used. This leads to significant memory footprint and bandwidth
comsumption, limiting scalability and slowing training throughput.
 In this work, we introduce a novel approach to integrates the output
projection and loss prediction into a single operation. By directly computing
the loss from hidden states and target tokens, our approach bypasses explicit
logits materialization. This design reduces memory usage and alleviates
bandwidth pressure. Experiments on LLM training demonstrate that our method
achieves substantial memory savings and measurable speedups compared to the
standard two-stage pipeline, enabling large batch sizes and longer sequences
without sacrificing accuracy. Our work highlights the benefits of rethinking
the boundary between projection and prediction, offering a practical systems
optimization for efficient LLM training.
\\ ( https://arxiv.org/abs/2511.17599 ,  807kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17601
Date: Tue, 18 Nov 2025 04:55:44 GMT   (1118kb)

Title: Generalizable and Efficient Automated Scoring with a Knowledge-Distilled
 Multi-Task Mixture-of-Experts
Authors: Luyang Fang, Tao Wang, Ping Ma, Xiaoming Zhai
Categories: cs.LG stat.ML
\\
 Automated scoring of written constructed responses typically relies on
separate models per task, straining computational resources, storage, and
maintenance in real-world education settings. We propose UniMoE-Guided, a
knowledge-distilled multi-task Mixture-of-Experts (MoE) approach that transfers
expertise from multiple task-specific large models (teachers) into a single
compact, deployable model (student). The student combines (i) a shared encoder
for cross-task representations, (ii) a gated MoE block that balances shared and
task-specific processing, and (iii) lightweight task heads. Trained with both
ground-truth labels and teacher guidance, the student matches strong
task-specific models while being far more efficient to train, store, and
deploy. Beyond efficiency, the MoE layer improves transfer and generalization:
experts develop reusable skills that boost cross-task performance and enable
rapid adaptation to new tasks with minimal additions and tuning. On nine
NGSS-aligned science-reasoning tasks (seven for training/evaluation and two
held out for adaptation), UniMoE-Guided attains performance comparable to
per-task models while using $\sim$6$\times$ less storage than maintaining
separate students, and $87\times$ less than the 20B-parameter teacher. The
method offers a practical path toward scalable, reliable, and
resource-efficient automated scoring for classroom and large-scale assessment
systems.
\\ ( https://arxiv.org/abs/2511.17601 ,  1118kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17602
Date: Tue, 18 Nov 2025 04:56:10 GMT   (14kb)

Title: Beyond Surface-Level Similarity: Hierarchical Contamination Detection
 for Synthetic Training Data in Foundation Models
Authors: Sushant Mehta
Categories: cs.LG cs.AI
\\
 Synthetic data has become essential for training foundation models, yet
benchmark contamination threatens evaluation integrity. Although existing
detection methods identify token-level overlap, they fail to detect
semantic-level contamination where synthetic data conceptually resemble
benchmarks without lexical overlap. This gap is critical as foundation models
increasingly train on synthetic data that may implicitly encode benchmark
knowledge. We propose a hierarchical contamination detection framework
operating at four levels: token level, semantic level, reasoning pattern, and
performance cliff detection. Through controlled experiments on MMLU, GSM8K and
HumanEval, we demonstrate that semantic-level contamination evades existing
methods (F1=0.17-0.49) but is effectively detected by our hierarchical approach
(F1 = 0.76), with an average improvement of 26. 5\% over state-of-the-art
baselines. Our framework provides practitioners with practical tools for audit
pipelines and enables responsible deployment of synthetic training data.
\\ ( https://arxiv.org/abs/2511.17602 ,  14kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17604
Date: Tue, 18 Nov 2025 05:35:08 GMT   (3115kb)

Title: BrainHGT: A Hierarchical Graph Transformer for Interpretable Brain
 Network Analysis
Authors: Jiajun Ma, Yongchao Zhang, Chao Zhang, Zhao Lv, Shengbing Pei
Categories: cs.LG cs.AI
\\
 Graph Transformer shows remarkable potential in brain network analysis due to
its ability to model graph structures and complex node relationships. Most
existing methods typically model the brain as a flat network, ignoring its
modular structure, and their attention mechanisms treat all brain region
connections equally, ignoring distance-related node connection patterns.
However, brain information processing is a hierarchical process that involves
local and long-range interactions between brain regions, interactions between
regions and sub-functional modules, and interactions among functional modules
themselves. This hierarchical interaction mechanism enables the brain to
efficiently integrate local computations and global information flow,
supporting the execution of complex cognitive functions. To address this issue,
we propose BrainHGT, a hierarchical Graph Transformer that simulates the
brain's natural information processing from local regions to global
communities. Specifically, we design a novel long-short range attention encoder
that utilizes parallel pathways to handle dense local interactions and sparse
long-range connections, thereby effectively alleviating the over-globalizing
issue. To further capture the brain's modular architecture, we designe a
prior-guided clustering module that utilizes a cross-attention mechanism to
group brain regions into functional communities and leverage neuroanatomical
prior to guide the clustering process, thereby improving the biological
plausibility and interpretability. Experimental results indicate that our
proposed method significantly improves performance of disease identification,
and can reliably capture the sub-functional modules of the brain, demonstrating
its interpretability.
\\ ( https://arxiv.org/abs/2511.17604 ,  3115kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17605
Date: Tue, 18 Nov 2025 05:59:36 GMT   (1810kb)

Title: Copula Based Fusion of Clinical and Genomic Machine Learning Risk Scores
 for Breast Cancer Risk Stratification
Authors: Agnideep Aich, Sameera Hewage and Md Monzur Murshed
Categories: cs.LG stat.ME stat.ML
\\
 Clinical and genomic models are both used to predict breast cancer outcomes,
but they are often combined using simple linear rules that do not account for
how their risk scores relate, especially at the extremes. Using the METABRIC
breast cancer cohort, we studied whether directly modeling the joint
relationship between clinical and genomic machine learning risk scores could
improve risk stratification for 5-year cancer-specific mortality. We created a
binary 5-year cancer-death outcome and defined two sets of predictors: a
clinical set (demographic, tumor, and treatment variables) and a genomic set
(gene-expression $z$-scores). We trained several supervised classifiers, such
as Random Forest and XGBoost, and used 5-fold cross-validated predicted
probabilities as unbiased risk scores. These scores were converted to
pseudo-observations on $(0,1)^2$ to fit Gaussian, Clayton, and Gumbel copulas.
Clinical models showed good discrimination (AUC 0.783), while genomic models
had moderate performance (AUC 0.681). The joint distribution was best captured
by a Gaussian copula (bootstrap $p=0.997$), which suggests a symmetric,
moderately strong positive relationship. When we grouped patients based on this
relationship, Kaplan-Meier curves showed clear differences: patients who were
high-risk in both clinical and genomic scores had much poorer survival than
those high-risk in only one set. These results show that copula-based fusion
works in real-world cohorts and that considering dependencies between scores
can better identify patient subgroups with the worst prognosis.
\\ ( https://arxiv.org/abs/2511.17605 ,  1810kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17606
Date: Tue, 18 Nov 2025 07:11:29 GMT   (2918kb)

Title: Energy-based Autoregressive Generation for Neural Population Dynamics
Authors: Ningling Ge, Sicheng Dai, Yu Zhu, Shan Yu
Categories: cs.LG cs.AI
\\
 Understanding brain function represents a fundamental goal in neuroscience,
with critical implications for therapeutic interventions and neural engineering
applications. Computational modeling provides a quantitative framework for
accelerating this understanding, but faces a fundamental trade-off between
computational efficiency and high-fidelity modeling. To address this
limitation, we introduce a novel Energy-based Autoregressive Generation (EAG)
framework that employs an energy-based transformer learning temporal dynamics
in latent space through strictly proper scoring rules, enabling efficient
generation with realistic population and single-neuron spiking statistics.
Evaluation on synthetic Lorenz datasets and two Neural Latents Benchmark
datasets (MC_Maze and Area2_bump) demonstrates that EAG achieves
state-of-the-art generation quality with substantial computational efficiency
improvements, particularly over diffusion-based methods. Beyond optimal
performance, conditional generation applications show two capabilities:
generalizing to unseen behavioral contexts and improving motor brain-computer
interface decoding accuracy using synthetic neural data. These results
demonstrate the effectiveness of energy-based modeling for neural population
dynamics with applications in neuroscience research and neural engineering.
Code is available at
https://github.com/NinglingGe/Energy-based-Autoregressive-Generation-for-Neural-Population-Dynamics.
\\ ( https://arxiv.org/abs/2511.17606 ,  2918kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17610
Date: Tue, 18 Nov 2025 08:48:37 GMT   (3659kb)

Title: Finding Pre-Injury Patterns in Triathletes from Lifestyle, Recovery and
 Load Dynamics Features
Authors: Leonardo Rossi, Bruno Rodrigues
Categories: cs.LG
\\
 Triathlon training, which involves high-volume swimming, cycling, and
running, places athletes at substantial risk for overuse injuries due to
repetitive physiological stress. Current injury prediction approaches primarily
rely on training load metrics, often neglecting critical factors such as sleep
quality, stress, and individual lifestyle patterns that significantly influence
recovery and injury susceptibility.
 We introduce a novel synthetic data generation framework tailored explicitly
for triathlon. This framework generates physiologically plausible athlete
profiles, simulates individualized training programs that incorporate
periodization and load-management principles, and integrates daily-life factors
such as sleep quality, stress levels, and recovery states. We evaluated machine
learning models (LASSO, Random Forest, and XGBoost) showing high predictive
performance (AUC up to 0.86), identifying sleep disturbances, heart rate
variability, and stress as critical early indicators of injury risk. This
wearable-driven approach not only enhances injury prediction accuracy but also
provides a practical solution to overcoming real-world data limitations,
offering a pathway toward a holistic, context-aware athlete monitoring.
\\ ( https://arxiv.org/abs/2511.17610 ,  3659kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17611
Date: Tue, 18 Nov 2025 10:01:21 GMT   (13592kb)

Title: AI-driven Generation of MALDI-TOF MS for Microbial Characterization
Authors: Luc\'ia Schmidt-Santiago, David Rodr\'iguez-Temporal, Carlos
 Sevilla-Salcedo, Vanessa G\'omez-Verdejo
Categories: cs.LG q-bio.QM
\\
 Matrix-Assisted Laser Desorption/Ionization Time-of-Flight Mass Spectrometry
(MALDI-TOF MS) has become a cornerstone technology in clinical microbiology,
enabling rapid and accurate microbial identification. However, the development
of data-driven diagnostic models remains limited by the lack of sufficiently
large, balanced, and standardized spectral datasets. This study investigates
the use of deep generative models to synthesize realistic MALDI-TOF MS spectra,
aiming to overcome data scarcity and support the development of robust machine
learning tools in microbiology.
 We adapt and evaluate three generative models, Variational Autoencoders
(MALDIVAEs), Generative Adversarial Networks (MALDIGANs), and Denoising
Diffusion Probabilistic Model (MALDIffusion), for the conditional generation of
microbial spectra guided by species labels. Generation is conditioned on
species labels, and spectral fidelity and diversity are assessed using diverse
metrics.
 Our experiments show that synthetic data generated by MALDIVAE, MALDIGAN, and
MALDIffusion are statistically and diagnostically comparable to real
measurements, enabling classifiers trained exclusively on synthetic samples to
reach performance levels similar to those trained on real data. While all
models faithfully reproduce the peak structure and variability of MALDI-TOF
spectra, MALDIffusion obtains this fidelity at a substantially higher
computational cost, and MALDIGAN shows competitive but slightly less stable
behaviour. In contrast, MALDIVAE offers the most favorable balance between
realism, stability, and efficiency. Furthermore, augmenting minority species
with synthetic spectra markedly improves classification accuracy, effectively
mitigating class imbalance and domain mismatch without compromising the
authenticity of the generated data.
\\ ( https://arxiv.org/abs/2511.17611 ,  13592kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17616
Date: Tue, 18 Nov 2025 13:24:21 GMT   (341kb)

Title: Tensor Gauge Flow Models
Authors: Alexander Strunk, Roland Assam
Categories: cs.LG cs.AI math.DG
\\
 This paper introduces Tensor Gauge Flow Models, a new class of Generative
Flow Models that generalize Gauge Flow Models and Higher Gauge Flow Models by
incorporating higher-order Tensor Gauge Fields into the Flow Equation. This
extension allows the model to encode richer geometric and gauge-theoretic
structure in the data, leading to more expressive flow dynamics. Experiments on
Gaussian mixture models show that Tensor Gauge Flow Models achieve improved
generative performance compared to both standard and gauge flow baselines.
\\ ( https://arxiv.org/abs/2511.17616 ,  341kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17622
Date: Tue, 18 Nov 2025 16:50:04 GMT   (16505kb)

Title: Neurocircuitry-Inspired Hierarchical Graph Causal Attention Networks for
 Explainable Depression Identification
Authors: Weidao Chen and Yuxiao Yang and Yueming Wang
Categories: cs.LG cs.AI
Comments: Under review for ICLR 2026
\\
 Major Depressive Disorder (MDD), affecting millions worldwide, exhibits
complex pathophysiology manifested through disrupted brain network dynamics.
Although graph neural networks that leverage neuroimaging data have shown
promise in depression diagnosis, existing approaches are predominantly
data-driven and operate largely as black-box models, lacking neurobiological
interpretability. Here, we present NH-GCAT (Neurocircuitry-Inspired
Hierarchical Graph Causal Attention Networks), a novel framework that bridges
neuroscience domain knowledge with deep learning by explicitly and
hierarchically modeling depression-specific mechanisms at different spatial
scales. Our approach introduces three key technical contributions: (1) at the
local brain regional level, we design a residual gated fusion module that
integrates temporal blood oxygenation level dependent (BOLD) dynamics with
functional connectivity patterns, specifically engineered to capture local
depression-relevant low-frequency neural oscillations; (2) at the
multi-regional circuit level, we propose a hierarchical circuit encoding scheme
that aggregates regional node representations following established depression
neurocircuitry organization, and (3) at the multi-circuit network level, we
develop a variational latent causal attention mechanism that leverages a
continuous probabilistic latent space to infer directed information flow among
critical circuits, characterizing disease-altered whole-brain inter-circuit
interactions. Rigorous leave-one-site-out cross-validation on the REST-meta-MDD
dataset demonstrates NH-GCAT's state-of-the-art performance in depression
classification, achieving a sample-size weighted-average accuracy of 73.3\% and
an AUROC of 76.4\%, while simultaneously providing neurobiologically meaningful
explanations.
\\ ( https://arxiv.org/abs/2511.17622 ,  16505kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17623
Date: Tue, 18 Nov 2025 17:18:46 GMT   (654kb)

Title: M$^2$OE$^2$-GL: A Family of Probabilistic Load Forecasters That Scales
 to Massive Customers
Authors: Haoran Li and Zhe Cheng and Muhao Guo and Yang Weng and Yannan Sun and
 Victor Tran and John Chainaranont
Categories: cs.LG cs.AI
Comments: 5 pages
\\
 Probabilistic load forecasting is widely studied and underpins power system
planning, operation, and risk-aware decision making. Deep learning forecasters
have shown strong ability to capture complex temporal and contextual patterns,
achieving substantial accuracy gains. However, at the scale of thousands or
even hundreds of thousands of loads in large distribution feeders, a deployment
dilemma emerges: training and maintaining one model per customer is
computationally and storage intensive, while using a single global model
ignores distributional shifts across customer types, locations, and phases.
Prior work typically focuses on single-load forecasters, global models across
multiple loads, or adaptive/personalized models for relatively small settings,
and rarely addresses the combined challenges of heterogeneity and scalability
in large feeders. We propose M2OE2-GL, a global-to-local extension of the M2OE2
probabilistic forecaster. We first pretrain a single global M2OE2 base model
across all feeder loads, then apply lightweight fine-tuning to derive a compact
family of group-specific forecasters. Evaluated on realistic utility data,
M2OE2-GL yields substantial error reductions while remaining scalable to very
large numbers of loads.
\\ ( https://arxiv.org/abs/2511.17623 ,  654kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17624
Date: Tue, 18 Nov 2025 17:50:49 GMT   (1202kb)

Title: QML-HCS: A Hypercausal Quantum Machine Learning Framework for
 Non-Stationary Environments
Authors: Hector E Mozo
Categories: cs.LG
Comments: 11 pages, 10 figures, and 8 tables. The implementation and full
 source code of the Hypercausal Quantum Machine Learning System (QML-HCS) are
 openly available on GitHub at:
 https://github.com/Neureonmindflux-Research-Lab/qml-hcs
\\
 QML-HCS is a research-grade framework for constructing and analyzing
quantum-inspired machine learning models operating under hypercausal feedback
dynamics. Hypercausal refers to AI systems that leverage extended, deep, or
nonlinear causal relationships (expanded causality) to reason, predict, and
infer states beyond the capabilities of traditional causal models. Current
machine learning and quantum-inspired systems struggle in non-stationary
environments, where data distributions drift and models lack mechanisms for
continuous adaptation, causal stability, and coherent state updating. QML-HCS
addresses this limitation through a unified computational architecture that
integrates quantum-inspired superposition principles, dynamic causal feedback,
and deterministic-stochastic hybrid execution to enable adaptive behavior in
changing environments.
 The framework implements a hypercausal processing core capable of reversible
transformations, multipath causal propagation, and evaluation of alternative
states under drift. Its architecture incorporates continuous feedback to
preserve causal consistency and adjust model behavior without requiring full
retraining. QML-HCS provides a reproducible and extensible Python interface
backed by efficient computational routines, enabling experimentation in
quantum-inspired learning, causal reasoning, and hybrid computation without the
need for specialized hardware.
 A minimal simulation demonstrates how a hypercausal model adapts to a sudden
shift in the input distribution while preserving internal coherence. This
initial release establishes the foundational architecture for future
theoretical extensions, benchmarking studies, and integration with classical
and quantum simulation platforms.
\\ ( https://arxiv.org/abs/2511.17624 ,  1202kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17626
Date: Tue, 18 Nov 2025 22:36:47 GMT   (218kb)

Title: Efficient Large-Scale Learning of Minimax Risk Classifiers
Authors: Kartheek Bondugula, Santiago Mazuelas, Aritz P\'erez
Categories: cs.LG stat.ML
Comments: In IEEE ICDM (2025)
\\
 Supervised learning with large-scale data usually leads to complex
optimization problems, especially for classification tasks with multiple
classes. Stochastic subgradient methods can enable efficient learning with a
large number of samples for classification techniques that minimize the average
loss over the training samples. However, recent techniques, such as minimax
risk classifiers (MRCs), minimize the maximum expected loss and are not
amenable to stochastic subgradient methods. In this paper, we present a
learning algorithm based on the combination of constraint and column generation
that enables efficient learning of MRCs with large-scale data for
classification tasks with multiple classes. Experiments on multiple benchmark
datasets show that the proposed algorithm provides upto a 10x speedup for
general large-scale data and around a 100x speedup with a sizeable number of
classes.
\\ ( https://arxiv.org/abs/2511.17626 ,  218kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17628
Date: Wed, 19 Nov 2025 02:06:30 GMT   (1352kb)

Title: Rectifying Mean-Shift in Cascaded Precipitation Nowcasting
Authors: Fanbo Ju, Haiyuan Shi, Qingjian Ni
Categories: cs.LG
\\
 Precipitation nowcasting, which aims to provide high spatio-temporal
resolution precipitation forecasts by leveraging current radar observations, is
a core task in regional weather forecasting. The cascaded architecture has
emerged as the mainstream paradigm for deep learning-based precipitation
nowcasting. This paradigm involves a deterministic model to predict macroscopic
trends (or posterior mean), followed by a probabilistic model to generate local
details (or local stochasticity). However, existing methods commonly overlook
the conflation of the systematic distribution shift in deterministic
predictions and the local stochasticity. As a result, the deterministic
component's distribution shift contaminates the predictions of the
probabilistic component, leading to inaccuracies in precipitation patterns and
intensity, particularly over longer lead times. To address this issue, we
introduce RectiCast, a two-stage framework that explicitly decouples the
correction of mean-field shift from the generation of local stochasticity via a
dual Flow Matching model. In the first stage, a deterministic model generates
the posterior mean. In the second stage, we introduce a Rectifier to explicitly
learn the distribution shift and produce a rectified mean. Subsequently, a
Generator focuses on modeling the local stochasticity conditioned on the
rectified mean. Experiments on SEVIR and MeteoNet demonstrate that RectiCast
achieves significant performance improvements over existing state-of-the-art
methods.
\\ ( https://arxiv.org/abs/2511.17628 ,  1352kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17629
Date: Wed, 19 Nov 2025 02:15:58 GMT   (2193kb)

Title: Boundary-Aware Adversarial Filtering for Reliable Diagnosis under
 Extreme Class Imbalance
Authors: Yanxuan Yu, Michael S. Hughes, Julien Lee, Jiacheng Zhou, and Andrew
 F. Laine
Categories: cs.LG
Comments: 5 pages, 3 figures. Submitted to IEEE ISBI (under review)
\\
 We study classification under extreme class imbalance where recall and
calibration are both critical, for example in medical diagnosis scenarios. We
propose AF-SMOTE, a mathematically motivated augmentation framework that first
synthesizes minority points and then filters them by an adversarial
discriminator and a boundary utility model. We prove that, under mild
assumptions on the decision boundary smoothness and class-conditional
densities, our filtering step monotonically improves a surrogate of F_beta (for
beta >= 1) while not inflating Brier score. On MIMIC-IV proxy label prediction
and canonical fraud detection benchmarks, AF-SMOTE attains higher recall and
average precision than strong oversampling baselines (SMOTE, ADASYN,
Borderline-SMOTE, SVM-SMOTE), and yields the best calibration. We further
validate these gains across multiple additional datasets beyond MIMIC-IV. Our
successful application of AF-SMOTE to a healthcare dataset using a proxy label
demonstrates in a disease-agnostic way its practical value in clinical
situations, where missing true positive cases in rare diseases can have severe
consequences.
\\ ( https://arxiv.org/abs/2511.17629 ,  2193kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17630
Date: Wed, 19 Nov 2025 02:28:32 GMT   (39547kb)

Title: Can we use LLMs to bootstrap reinforcement learning? -- A case study in
 digital health behavior change
Authors: Nele Albers, Esra Cemre Su de Groot, Loes Keijsers, Manon H.
 Hillegers, Emiel Krahmer
Categories: cs.LG cs.AI cs.HC
\\
 Personalizing digital applications for health behavior change is a promising
route to making them more engaging and effective. This especially holds for
approaches that adapt to users and their specific states (e.g., motivation,
knowledge, wants) over time. However, developing such approaches requires
making many design choices, whose effectiveness is difficult to predict from
literature and costly to evaluate in practice. In this work, we explore whether
large language models (LLMs) can be used out-of-the-box to generate samples of
user interactions that provide useful information for training reinforcement
learning models for digital behavior change settings. Using real user data from
four large behavior change studies as comparison, we show that LLM-generated
samples can be useful in the absence of real data. Comparisons to the samples
provided by human raters further show that LLM-generated samples reach the
performance of human raters. Additional analyses of different prompting
strategies including shorter and longer prompt variants, chain-of-thought
prompting, and few-shot prompting show that the relative effectiveness of
different strategies depends on both the study and the LLM with also relatively
large differences between prompt paraphrases alone. We provide recommendations
for how LLM-generated samples can be useful in practice.
\\ ( https://arxiv.org/abs/2511.17630 ,  39547kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17631
Date: Wed, 19 Nov 2025 05:16:10 GMT   (345kb)

Title: Enhanced Federated Deep Multi-View Clustering under Uncertainty Scenario
Authors: Bingjun Wei, Xuemei Cao, Jiafen Liu, Haoyang Liang, Xin Yang
Categories: cs.LG
Journal-ref: AAAI 2026
\\
 Traditional Federated Multi-View Clustering assumes uniform views across
clients, yet practical deployments reveal heterogeneous view completeness with
prevalent incomplete, redundant, or corrupted data. While recent approaches
model view heterogeneity, they neglect semantic conflicts from dynamic view
combinations, failing to address dual uncertainties: view uncertainty (semantic
inconsistency from arbitrary view pairings) and aggregation uncertainty
(divergent client updates with imbalanced contributions). To address these, we
propose a novel Enhanced Federated Deep Multi-View Clustering framework: first
align local semantics, hierarchical contrastive fusion within clients resolves
view uncertainty by eliminating semantic conflicts; a view adaptive drift
module mitigates aggregation uncertainty through global-local prototype
contrast that dynamically corrects parameter deviations; and a balanced
aggregation mechanism coordinates client updates. Experimental results
demonstrate that EFDMVC achieves superior robustness against heterogeneous
uncertain views across multiple benchmark datasets, consistently outperforming
all state-of-the-art baselines in comprehensive evaluations.
\\ ( https://arxiv.org/abs/2511.17631 ,  345kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17632
Date: Wed, 19 Nov 2025 05:29:43 GMT   (6023kb)

Title: Smart Manufacturing: MLOps-Enabled Event-Driven Architecture for
 Enhanced Control in Steel Production
Authors: Bestoun S. Ahmed and Tommaso Azzalin and Andreas Kassler and Andreas
 Thore and Hans Lindback
Categories: cs.LG
Journal-ref: Journal of Systems and Software 2025
\\
 We explore a Digital Twin-Based Approach for Smart Manufacturing to improve
Sustainability, Efficiency, and Cost-Effectiveness for a steel production
plant. Our system is based on a micro-service edge-compute platform that
ingests real-time sensor data from the process into a digital twin over a
converged network infrastructure. We implement agile machine learning-based
control loops in the digital twin to optimize induction furnace heating,
enhance operational quality, and reduce process waste. Key to our approach is a
Deep Reinforcement learning-based agent used in our machine learning operation
(MLOps) driven system to autonomously correlate the system state with its
digital twin to identify correction actions that aim to optimize power settings
for the plant. We present the theoretical basis, architectural details, and
practical implications of our approach to reduce manufacturing waste and
increase production quality. We design the system for flexibility so that our
scalable event-driven architecture can be adapted to various industrial
applications. With this research, we propose a pivotal step towards the
transformation of traditional processes into intelligent systems, aligning with
sustainability goals and emphasizing the role of MLOps in shaping the future of
data-driven manufacturing.
\\ ( https://arxiv.org/abs/2511.17632 ,  6023kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17637
Date: Wed, 19 Nov 2025 08:46:26 GMT   (215kb)

Title: PocketLLM: Ultimate Compression of Large Language Models via Meta
 Networks
Authors: Ye Tian, Chengcheng Wang, Jing Han, Yehui Tang, Kai Han
Categories: cs.LG cs.CL
Comments: AAAI 2026 camera ready
\\
 As Large Language Models (LLMs) continue to grow in size, storing and
transmitting them on edge devices becomes increasingly challenging. Traditional
methods like quantization and pruning struggle to achieve extreme compression
of LLMs without sacrificing accuracy. In this paper, we introduce PocketLLM, a
novel approach to compress LLMs in a latent space via meta-networks. A simple
encoder network is proposed to project the weights of LLMs into discrete latent
vectors, which are then represented using a compact codebook. A lightweight
decoder network is employed to map the codebook's representative vectors back
to the original weight space. This method allows for significant compression of
the large weights in LLMs, consisting solely of a small decoder, a concise
codebook, and an index. Extensive experiments show that PocketLLM achieves
superior performance even at significantly high compression ratios, e.g.,
compressing Llama 2-7B by 10x with a negligible drop in accuracy.
\\ ( https://arxiv.org/abs/2511.17637 ,  215kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17638
Date: Wed, 19 Nov 2025 09:43:25 GMT   (3228kb)

Title: Model-to-Model Knowledge Transmission (M2KT): A Data-Free Framework for
 Cross-Model Understanding Transfer
Authors: Pratham Sorte
Categories: cs.LG cs.AI
Comments: 8 pages including figures, prepared in IEEE conference style.
 Preprint. Work in progress
\\
 Modern artificial intelligence systems depend heavily on large datasets for
both training and transferring knowledge between models. Knowledge
distillation, transfer learning, and dataset distillation have made such
transfers more efficient, yet they remain fundamentally data-driven: a teacher
must produce examples, logits, or gradients for a student to learn. In this
work, we introduce Model-to-Model Knowledge Transmission (M2KT), a novel
paradigm for data-free conceptual transfer between neural networks. M2KT
enables models to exchange knowledge packets that encapsulate structured
concept embeddings, abstraction graphs, reasoning traces, and provenance
metadata. Unlike classical distillation, M2KT operates primarily in concept
space rather than example space, and it does not require labeled datasets or
teacher-generated outputs during transfer. We formalize the notion of concept
manifolds, introduce an inter-model alignment mapping between teacher and
student latent spaces, and derive a composite loss that enforces geometric,
structural, and reasoning consistency together with explicit safety
constraints. We further present algorithmic procedures for teacher-side packet
generation and student-side ingestion and verification. Experiments on symbolic
reasoning with large language models show that M2KT can achieve approximately
85 to 90 percent of teacher performance while reducing data usage by over 98
percent compared to standard knowledge distillation. This work establishes a
theoretical and practical foundation for data-free AI-to-AI knowledge transfer
and self-improving model ecosystems.
\\ ( https://arxiv.org/abs/2511.17638 ,  3228kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17639
Date: Wed, 19 Nov 2025 13:09:33 GMT   (2542kb)

Title: TTF: A Trapezoidal Temporal Fusion Framework for LTV Forecasting in
 Douyin
Authors: Yibing Wan, Zhengxiong Guan, Chaoli Zhang, Xiaoyang Li, Lai Xu, Beibei
 Jia, Zhenzhe Zheng, Fan Wu
Categories: cs.LG
Comments: Accepted by AAAI IAAI Track
Journal-ref: AAAI 2026 IAAI Track
\\
 In the user growth scenario, Internet companies invest heavily in paid
acquisition channels to acquire new users. But sustainable growth depends on
acquired users' generating lifetime value (LTV) exceeding customer acquisition
cost (CAC). In order to maximize LTV/CAC ratio, it is crucial to predict
channel-level LTV in an early stage for further optimization of budget
allocation. The LTV forecasting problem is significantly different from
traditional time series forecasting problems, and there are three main
challenges. Firstly, it is an unaligned multi-time series forecasting problem
that each channel has a number of LTV series of different activation dates.
Secondly, to predict in the early stage, it faces the imbalanced short-input
long-output (SILO) challenge. Moreover, compared with the commonly used time
series datasets, the real LTV series are volatile and non-stationary, with more
frequent fluctuations and higher variance. In this work, we propose a novel
framework called Trapezoidal Temporal Fusion (TTF) to address the above
challenges. We introduce a trapezoidal multi-time series module to deal with
data unalignment and SILO challenges, and output accurate predictions with a
multi-tower structure called MT-FusionNet. The framework has been deployed to
the online system for Douyin. Compared to the previously deployed online model,
MAPEp decreased by 4.3%, and MAPEa decreased by 3.2%, where MAPEp denotes the
point-wise MAPE of the LTV curve and MAPEa denotes the MAPE of the aggregated
LTV.
\\ ( https://arxiv.org/abs/2511.17639 ,  2542kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17645
Date: Thu, 20 Nov 2025 06:04:34 GMT   (22kb)

Title: BlockCert: Certified Blockwise Extraction of Transformer Mechanisms
Authors: Sandro Andric
Categories: cs.LG
Comments: 16 pages, 1 figure
\\
 Mechanistic interpretability aspires to reverse-engineer neural networks into
explicit algorithms, while model editing seeks to modify specific behaviours
without retraining. Both areas are typically evaluated with informal evidence
and ad-hoc experiments, with few explicit guarantees about how far an extracted
or edited model can drift from the original on relevant inputs. We introduce
BlockCert, a framework for certified blockwise extraction of transformer
mechanisms, and outline how a lightweight extension can support certified local
edits. Given a pre-trained transformer and a prompt distribution, BlockCert
extracts structured surrogate implementations for residual blocks together with
machine-checkable certificates that bound approximation error, record coverage
metrics, and hash the underlying artifacts. We formalize a simple
Lipschitz-based composition theorem in Lean 4 that lifts these local guarantees
to a global deviation bound. Empirically, we apply the framework to GPT-2
small, TinyLlama-1.1B-Chat, and Llama-3.2-3B. Across these models we obtain
high per-block coverage and small residual errors on the evaluated prompts, and
in the TinyLlama setting we show that a fully stitched model matches the
baseline perplexity within approximately 6e-5 on stress prompts. Our results
suggest that blockwise extraction with explicit certificates is feasible for
real transformer language models and offers a practical bridge between
mechanistic interpretability and formal reasoning about model behaviour.
\\ ( https://arxiv.org/abs/2511.17645 ,  22kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17647
Date: Thu, 20 Nov 2025 07:39:10 GMT   (6045kb)

Title: MamTiff-CAD: Multi-Scale Latent Diffusion with Mamba+ for Complex
 Parametric Sequence
Authors: Liyuan Deng, Yunpeng Bai, Yongkang Dai, Xiaoshui Huang, Hongping Gan,
 Dongshuo Huang, Hao jiacheng, Yilei Shi
Categories: cs.LG cs.AI
Comments: ICCV 2025 Conference
\\
 Parametric Computer-Aided Design (CAD) is crucial in industrial applications,
yet existing approaches often struggle to generate long sequence parametric
commands due to complex CAD models' geometric and topological constraints. To
address this challenge, we propose MamTiff-CAD, a novel CAD parametric command
sequences generation framework that leverages a Transformer-based diffusion
model for multi-scale latent representations. Specifically, we design a novel
autoencoder that integrates Mamba+ and Transformer, to transfer parameterized
CAD sequences into latent representations. The Mamba+ block incorporates a
forget gate mechanism to effectively capture long-range dependencies. The
non-autoregressive Transformer decoder reconstructs the latent representations.
A diffusion model based on multi-scale Transformer is then trained on these
latent embeddings to learn the distribution of long sequence commands. In
addition, we also construct a dataset that consists of long parametric
sequences, which is up to 256 commands for a single CAD model. Experiments
demonstrate that MamTiff-CAD achieves state-of-the-art performance on both
reconstruction and generation tasks, confirming its effectiveness for long
sequence (60-256) CAD model generation.
\\ ( https://arxiv.org/abs/2511.17647 ,  6045kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17660
Date: Thu, 20 Nov 2025 21:05:45 GMT   (2366kb)

Title: Frugality in second-order optimization: floating-point approximations
 for Newton's method
Authors: Giuseppe Carrino, Elena Loli Piccolomini, Elisa Riccietti, Theo Mary
Categories: cs.LG cs.AI math.OC
Comments: Master Thesis for the Artificial Intelligence course at University of
 Bologna
\\
 Minimizing loss functions is central to machine-learning training. Although
first-order methods dominate practical applications, higher-order techniques
such as Newton's method can deliver greater accuracy and faster convergence,
yet are often avoided due to their computational cost. This work analyzes the
impact of finite-precision arithmetic on Newton steps and establishes a
convergence theorem for mixed-precision Newton optimizers, including "quasi"
and "inexact" variants. The theorem provides not only convergence guarantees
but also a priori estimates of the achievable solution accuracy. Empirical
evaluations on standard regression benchmarks demonstrate that the proposed
methods outperform Adam on the Australian and MUSH datasets. The second part of
the manuscript introduces GN_k, a generalized Gauss-Newton method that enables
partial computation of second-order derivatives. GN_k attains performance
comparable to full Newton's method on regression tasks while requiring
significantly fewer derivative evaluations.
\\ ( https://arxiv.org/abs/2511.17660 ,  2366kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17662
Date: Thu, 20 Nov 2025 22:19:31 GMT   (219kb)

Title: Enhancing Breast Cancer Prediction with LLM-Inferred Confounders
Authors: Debmita Roy
Categories: cs.LG q-bio.QM
Comments: 2 pages, 1 figure, 1 table
\\
 This study enhances breast cancer prediction by using large language models
to infer the likelihood of confounding diseases, namely diabetes, obesity, and
cardiovascular disease, from routine clinical data. These AI-generated features
improved Random Forest model performance, particularly for LLMs like Gemma
(3.9%) and Llama (6.4%). The approach shows promise for noninvasive
prescreening and clinical integration, supporting improved early detection and
shared decision-making in breast cancer diagnosis.
\\ ( https://arxiv.org/abs/2511.17662 ,  219kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17663
Date: Thu, 20 Nov 2025 22:43:53 GMT   (1240kb)

Title: AI-based framework to predict animal and pen feed intake in feedlot beef
 cattle
Authors: Alex S. C. Maia, John B. Hall, Hugo F. M. Milan, Izabelle A. M. A.
 Teixeira
Categories: cs.LG cs.AI
\\
 Advances in technology are transforming sustainable cattle farming practices,
with electronic feeding systems generating big longitudinal datasets on
individual animal feed intake, offering the possibility for autonomous
precision livestock systems. However, the literature still lacks a methodology
that fully leverages these longitudinal big data to accurately predict feed
intake accounting for environmental conditions. To fill this gap, we developed
an AI-based framework to accurately predict feed intake of individual animals
and pen-level aggregation. Data from 19 experiments (>16.5M samples; 2013-2024)
conducted at Nancy M. Cummings Research Extension & Education Center (Carmen,
ID) feedlot facility and environmental data from AgriMet Network weather
stations were used to develop two novel environmental indices: InComfort-Index,
based solely on meteorological variables, showed good predictive capability for
thermal comfort but had limited ability to predict feed intake; EASI-Index, a
hybrid index integrating environmental variables with feed intake behavior,
performed well in predicting feed intake but was less effective for thermal
comfort. Together with the environmental indices, machine learning models were
trained and the best-performing machine learning model (XGBoost) accuracy was
RMSE of 1.38 kg/day for animal-level and only 0.14 kg/(day-animal) at
pen-level. This approach provides a robust AI-based framework for predicting
feed intake in individual animals and pens, with potential applications in
precision management of feedlot cattle, through feed waste reduction, resource
optimization, and climate-adaptive livestock management.
\\ ( https://arxiv.org/abs/2511.17663 ,  1240kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17664
Date: Fri, 21 Nov 2025 00:19:02 GMT   (2719kb)

Title: CubeletWorld: A New Abstraction for Scalable 3D Modeling
Authors: Azlaan Mustafa Samad, Hoang H. Nguyen, Lukas Berg, Henrik M\"uller,
 Yuan Xue, Daniel Kudenko, Zahra Ahmadi
Categories: cs.LG cs.CV cs.CY
Comments: 10 pages, 5 figures
\\
 Modern cities produce vast streams of heterogeneous data, from infrastructure
maps to mobility logs and satellite imagery. However, integrating these sources
into coherent spatial models for planning and prediction remains a major
challenge. Existing agent-centric methods often rely on direct environmental
sensing, limiting scalability and raising privacy concerns. This paper
introduces CubeletWorld, a novel framework for representing and analyzing urban
environments through a discretized 3D grid of spatial units called cubelets.
This abstraction enables privacy-preserving modeling by embedding diverse data
signals, such as infrastructure, movement, or environmental indicators, into
localized cubelet states. CubeletWorld supports downstream tasks such as
planning, navigation, and occupancy prediction without requiring agent-driven
sensing. To evaluate this paradigm, we propose the CubeletWorld State
Prediction task, which involves predicting the cubelet state using a realistic
dataset containing various urban elements like streets and buildings through
this discretized representation. We explore a range of modified core models
suitable for our setting and analyze challenges posed by increasing spatial
granularity, specifically the issue of sparsity in representation and
scalability of baselines. In contrast to existing 3D occupancy prediction
models, our cubelet-centric approach focuses on inferring state at the spatial
unit level, enabling greater generalizability across regions and improved
privacy compliance. Our results demonstrate that CubeletWorld offers a flexible
and extensible framework for learning from complex urban data, and it opens up
new possibilities for scalable simulation and decision support in domains such
as socio-demographic modeling, environmental monitoring, and emergency
response. The code and datasets can be downloaded from here.
\\ ( https://arxiv.org/abs/2511.17664 ,  2719kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17665
Date: Fri, 21 Nov 2025 00:32:33 GMT   (1641kb)

Title: GANGR: GAN-Assisted Scalable and Efficient Global Routing
 Parallelization
Authors: Hadi Khodaei Jooshin, Inna Partin-Vaisband
Categories: cs.LG
Comments: Accepted in DATE 2026
\\
 Global routing is a critical stage in electronic design automation (EDA) that
enables early estimation and optimization of the routability of modern
integrated circuits with respect to congestion, power dissipation, and design
complexity. Batching is a primary concern in top-performing global routers,
grouping nets into manageable sets to enable parallel processing and efficient
resource usage. This process improves memory usage, scalable parallelization on
modern hardware, and routing congestion by controlling net interactions within
each batch. However, conventional batching methods typically depend on
heuristics that are computationally expensive and can lead to suboptimal
results (oversized batches with conflicting nets, excessive batch counts
degrading parallelization, and longer batch generation times), ultimately
limiting scalability and efficiency. To address these limitations, a novel
batching algorithm enhanced with Wasserstein generative adversarial networks
(WGANs) is introduced in this paper, enabling more effective parallelization by
generating fewer higher-quality batches in less time. The proposed algorithm is
tested on the latest ISPD'24 contest benchmarks, demonstrating up to 40%
runtime reduction with only 0.002% degradation in routing quality as compared
to state-of-the-art router.
\\ ( https://arxiv.org/abs/2511.17665 ,  1641kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17675
Date: Fri, 21 Nov 2025 07:00:07 GMT   (7663kb)

Title: Lane-Frame Quantum Multimodal Driving Forecasts for the Trajectory of
 Autonomous Vehicles
Authors: Navneet Singh and Shiva Raj Pokhrel
Categories: cs.LG quant-ph
\\
 Trajectory forecasting for autonomous driving must deliver accurate,
calibrated multi-modal futures under tight compute and latency constraints. We
propose a compact hybrid quantum architecture that aligns quantum inductive
bias with road-scene structure by operating in an ego-centric, lane-aligned
frame and predicting residual corrections to a kinematic baseline instead of
absolute poses. The model combines a transformer-inspired quantum attention
encoder (9 qubits), a parameter-lean quantum feedforward stack (64 layers,
${\sim}1200$ trainable angles), and a Fourier-based decoder that uses shallow
entanglement and phase superposition to generate 16 trajectory hypotheses in a
single pass, with mode confidences derived from the latent spectrum. All
circuit parameters are trained with Simultaneous Perturbation Stochastic
Approximation (SPSA), avoiding backpropagation through non-analytic components.
In the Waymo Open Motion Dataset, the model achieves minADE (minimum Average
Displacement Error) of \SI{1.94}{m} and minFDE (minimum Final Displacement
Error) of \SI{3.56}{m} in the $16$ models predicted over the horizon of
\SI{2.0}{s}, consistently outperforming a kinematic baseline with reduced miss
rates and strong recall. Ablations confirm that residual learning in the lane
frame, truncated Fourier decoding, shallow entanglement, and spectrum-based
ranking focus capacity where it matters, yielding stable optimization and
reliable multi-modal forecasts from small, shallow quantum circuits on a modern
autonomous-driving benchmark.
\\ ( https://arxiv.org/abs/2511.17675 ,  7663kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17677
Date: Fri, 21 Nov 2025 07:17:49 GMT   (216kb)

Title: A Hybrid Classical-Quantum Fine Tuned BERT for Text Classification
Authors: Abu Kaisar Mohammad Masum, Naveed Mahmud, M. Hassan Najafi, Sercan
 Aygun
Categories: cs.LG quant-ph
Comments: This paper has been accepted by First AAAI Symposium on Quantum
 Information & Machine Learning (QIML): Bridging Quantum Computing and
 Artificial Intelligence at AAAI 2025 Fall Symposium
\\
 Fine-tuning BERT for text classification can be computationally challenging
and requires careful hyper-parameter tuning. Recent studies have highlighted
the potential of quantum algorithms to outperform conventional methods in
machine learning and text classification tasks. In this work, we propose a
hybrid approach that integrates an n-qubit quantum circuit with a classical
BERT model for text classification. We evaluate the performance of the
fine-tuned classical-quantum BERT and demonstrate its feasibility as well as
its potential in advancing this research area. Our experimental results show
that the proposed hybrid model achieves performance that is competitive with,
and in some cases better than, the classical baselines on standard benchmark
datasets. Furthermore, our approach demonstrates the adaptability of
classical-quantum models for fine-tuning pre-trained models across diverse
datasets. Overall, the hybrid model highlights the promise of quantum computing
in achieving improved performance for text classification tasks.
\\ ( https://arxiv.org/abs/2511.17677 ,  216kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17687
Date: Fri, 21 Nov 2025 13:13:45 GMT   (1522kb)

Title: Boosting Brain-inspired Path Integration Efficiency via Learning-based
 Replication of Continuous Attractor Neurodynamics
Authors: Zhangyu Ge, Xu He, Lingfei Mo, Xiaolin Meng, Wenxuan Yin, Youdong
 Zhang, Lansong Jiang, Fengyuan Liu
Categories: cs.LG cs.NE
\\
 The brain's Path Integration (PI) mechanism offers substantial guidance and
inspiration for Brain-Inspired Navigation (BIN). However, the PI capability
constructed by the Continuous Attractor Neural Networks (CANNs) in most
existing BIN studies exhibits significant computational redundancy, and its
operational efficiency needs to be improved; otherwise, it will not be
conducive to the practicality of BIN technology. To address this, this paper
proposes an efficient PI approach using representation learning models to
replicate CANN neurodynamic patterns. This method successfully replicates the
neurodynamic patterns of CANN-modeled Head Direction Cells (HDCs) and Grid
Cells (GCs) using lightweight Artificial Neural Networks (ANNs). These
ANN-reconstructed HDC and GC models are then integrated to achieve
brain-inspired PI for Dead Reckoning (DR). Benchmark tests in various
environments, compared with the well-known NeuroSLAM system, demonstrate that
this work not only accurately replicates the neurodynamic patterns of
navigation cells but also matches NeuroSLAM in positioning accuracy. Moreover,
efficiency improvements of approximately 17.5% on the general-purpose device
and 40~50% on the edge device were observed, compared with NeuroSLAM. This work
offers a novel implementation strategy to enhance the practicality of BIN
technology and holds potential for further extension.
\\ ( https://arxiv.org/abs/2511.17687 ,  1522kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17688
Date: Fri, 21 Nov 2025 14:00:01 GMT   (861kb)

Title: Enhancing Adversarial Transferability through Block Stretch and Shrink
Authors: Quan Liu, Feng Ye, Chenhao Lu, Shuming Zhen, Guanliang Huang, Lunzhe
 Chen, Xudong Ke
Categories: cs.LG cs.AI
Comments: code will be releace
\\
 Adversarial attacks introduce small, deliberately crafted perturbations that
mislead neural networks, and their transferability from white-box to black-box
target models remains a critical research focus. Input transformation-based
attacks are a subfield of adversarial attacks that enhance input diversity
through input transformations to improve the transferability of adversarial
examples. However, existing input transformation-based attacks tend to exhibit
limited cross-model transferability. Previous studies have shown that high
transferability is associated with diverse attention heatmaps and the
preservation of global semantics in transformed inputs. Motivated by this
observation, we propose Block Stretch and Shrink (BSS), a method that divides
an image into blocks and applies stretch and shrink operations to these blocks,
thereby diversifying attention heatmaps in transformed inputs while maintaining
their global semantics. Empirical evaluations on a subset of ImageNet
demonstrate that BSS outperforms existing input transformation-based attack
methods in terms of transferability. Furthermore, we examine the impact of the
number scale, defined as the number of transformed inputs, in input
transformation-based attacks, and advocate evaluating these methods under a
unified number scale to enable fair and comparable assessments.
\\ ( https://arxiv.org/abs/2511.17688 ,  861kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17693
Date: Fri, 21 Nov 2025 16:15:43 GMT   (172kb)

Title: DeepCoT: Deep Continual Transformers for Real-Time Inference on Data
 Streams
Authors: Gin\'es Carreto Pic\'on, Peng Yuan Zhou, Qi Zhang, and Alexandros
 Iosifidis
Categories: cs.LG cs.CL cs.CV
Comments: 13 pages, 5 figures
\\
 Transformer-based models have dramatically increased their size and parameter
count to tackle increasingly complex tasks. At the same time, there is a
growing demand for low-latency inference on resource-constrained devices that
achieves high performance. In particular, stream data inference is typically
performed over a sliding temporal window, leading to highly redundant
computations. The recent Continual Transformers have addressed this issue, but
they can only be effectively used in shallow models, which limits their scope
and generalization power. In this paper, we propose the Deep Continual
Transformer (DeepCoT), a redundancy-free encoder-only model that can be applied
over existing deep encoder architectures with minimal changes. In our
experiments over audio, video, and text streams, we show that DeepCoTs retain
comparative performance to their non-continual baselines while offering a
linear computational cost for all Transformer layers, which reduces up to two
orders of magnitude in the running time compared to previous efficient models.
\\ ( https://arxiv.org/abs/2511.17693 ,  172kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17741
Date: Fri, 21 Nov 2025 19:48:32 GMT   (3206kb)

Title: Diffusion Models are Molecular Dynamics Simulators
Authors: Justin Diamond, Markus Lill
Categories: cs.LG stat.ML
\\
 We prove that a denoising diffusion sampler equipped with a sequential bias
across the batch dimension is exactly an Euler-Maruyama integrator for
overdamped Langevin dynamics. Each reverse denoising step, with its associated
spring stiffness, can be interpreted as one step of a stochastic differential
equation with an effective time step set jointly by the noise schedule and that
stiffness. The learned score then plays the role of the drift, equivalently the
gradient of a learned energy, yielding a precise correspondence between
diffusion sampling and Langevin time evolution.
 This equivalence recasts molecular dynamics (MD) in terms of diffusion
models. Accuracy is no longer tied to a fixed, extremely small MD time step;
instead, it is controlled by two scalable knobs: model capacity, which governs
how well the drift is approximated, and the number of denoising steps, which
sets the integrator resolution. In practice, this leads to a fully data-driven
MD framework that learns forces from uncorrelated equilibrium snapshots,
requires no hand-engineered force fields, uses no trajectory data for training,
and still preserves the Boltzmann distribution associated with the learned
energy.
 We derive trajectory-level, information-theoretic error bounds that cleanly
separate discretization error from score-model error, clarify how temperature
enters through the effective spring, and show that the resulting sampler
generates molecular trajectories with MD-like temporal correlations, even
though the model is trained only on static configurations.
\\ ( https://arxiv.org/abs/2511.17741 ,  3206kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17754
Date: Fri, 21 Nov 2025 20:14:16 GMT   (3241kb)

Title: Periodicity-Enforced Neural Network for Designing Deterministic Lateral
 Displacement Devices
Authors: Andrew Lee, Mahir Mobarrat, Xiaolin Chen
Categories: cs.LG physics.flu-dyn
Comments: Accepted to IEEE International Conference on Data Mining (ICDM) 2025
 REU Symposium
\\
 Deterministic Lateral Displacement (DLD) devices enable liquid biopsy for
cancer detection by separating circulating tumor cells (CTCs) from blood
samples based on size, but designing these microfluidic devices requires
computationally expensive Navier-Stokes simulations and particle-tracing
analyses. While recent surrogate modeling approaches using deep learning have
accelerated this process, they often inadequately handle the critical periodic
boundary conditions of DLD unit cells, leading to cumulative errors in
multi-unit device predictions. This paper introduces a periodicity-enforced
surrogate modeling approach that incorporates periodic layers, neural network
components that guarantee exact periodicity without penalty terms or output
modifications, into deep learning architectures for DLD device design. The
proposed method employs three sub-networks to predict steady-state,
non-dimensional velocity and pressure fields (u, v, p) rather than directly
predicting critical diameters or particle trajectories, enabling complete flow
field characterization and enhanced design flexibility. Periodic layers ensure
exact matching of flow variables across unit cell boundaries through
architectural enforcement rather than soft penalty-based approaches. Validation
on 120 CFD-generated geometries demonstrates that the periodic layer
implementation achieves 0.478% critical diameter error while maintaining
perfect periodicity consistency, representing an 85.4% improvement over
baseline methods. The approach enables efficient and accurate DLD device design
with guaranteed boundary condition satisfaction for multi-unit device
applications.
\\ ( https://arxiv.org/abs/2511.17754 ,  3241kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17776
Date: Fri, 21 Nov 2025 20:47:50 GMT   (2347kb)

Title: PrismSSL: One Interface, Many Modalities; A Single-Interface Library for
 Multimodal Self-Supervised Learning
Authors: Melika Shirian, Kianoosh Vadaei, Kian Majlessi, Audrina Ebrahimi,
 Arshia Hemmat, Peyman Adibi, Hossein Karshenas
Categories: cs.LG cs.MM
\\
 We present PrismSSL, a Python library that unifies state-of-the-art
self-supervised learning (SSL) methods across audio, vision, graphs, and
cross-modal settings in a single, modular codebase. The goal of the demo is to
show how researchers and practitioners can: (i) install, configure, and run
pretext training with a few lines of code; (ii) reproduce compact benchmarks;
and (iii) extend the framework with new modalities or methods through clean
trainer and dataset abstractions. PrismSSL is packaged on PyPI, released under
the MIT license, integrates tightly with HuggingFace Transformers, and provides
quality-of-life features such as distributed training in PyTorch, Optuna-based
hyperparameter search, LoRA fine-tuning for Transformer backbones, animated
embedding visualizations for sanity checks, Weights & Biases logging, and
colorful, structured terminal logs for improved usability and clarity. In
addition, PrismSSL offers a graphical dashboard - built with Flask and standard
web technologies - that enables users to configure and launch training
pipelines with minimal coding. The artifact (code and data recipes) will be
publicly available and reproducible.
\\ ( https://arxiv.org/abs/2511.17776 ,  2347kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17782
Date: Fri, 21 Nov 2025 20:59:11 GMT   (60kb)

Title: Smoothed Agnostic Learning of Halfspaces over the Hypercube
Authors: Yiwen Kou, Raghu Meka
Categories: cs.LG cs.CC stat.ML
\\
 Agnostic learning of Boolean halfspaces is a fundamental problem in
computational learning theory, but it is known to be computationally hard even
for weak learning. Recent work [CKKMK24] proposed smoothed analysis as a way to
bypass such hardness, but existing frameworks rely on additive Gaussian
perturbations, making them unsuitable for discrete domains. We introduce a new
smoothed agnostic learning framework for Boolean inputs, where perturbations
are modeled via random bit flips. This defines a natural discrete analogue of
smoothed optimality generalizing the Gaussian case. Under strictly
subexponential assumptions on the input distribution, we give an efficient
algorithm for learning halfspaces in this model, with runtime and sample
complexity approximately n raised to a poly(1/(sigma * epsilon)) factor.
Previously, such algorithms were known only with strong structural assumptions
for the discrete hypercube, for example, independent coordinates or symmetric
distributions. Our result provides the first computationally efficient
guarantee for smoothed agnostic learning of halfspaces over the Boolean
hypercube, bridging the gap between worst-case intractability and practical
learnability in discrete settings.
\\ ( https://arxiv.org/abs/2511.17782 ,  60kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17784
Date: Fri, 21 Nov 2025 21:06:14 GMT   (7496kb)

Title: Improved Sample Complexity for Full Coverage in Compact and Continuous
 Spaces
Authors: Lyu Yuhuan
Categories: cs.LG stat.ML
\\
 Verifying uniform conditions over continuous spaces through random sampling
is fundamental in machine learning and control theory, yet classical coverage
analyses often yield conservative bounds, particularly at small failure
probabilities. We study uniform random sampling on the $d$-dimensional unit
hypercube and analyze the number of uncovered subcubes after discretization. By
applying a concentration inequality to the uncovered-count statistic, we derive
a sample complexity bound with a logarithmic dependence on the failure
probability ($\delta$), i.e., $M =O( \tilde{C}\ln(\frac{2\tilde{C}}{\delta}))$,
which contrasts sharply with the classical linear $1/\delta$ dependence. Under
standard Lipschitz and uniformity assumptions, we present a self-contained
derivation and compare our result with classical coupon-collector rates.
Numerical studies across dimensions, precision levels, and confidence targets
indicate that our bound tracks practical coverage requirements more tightly and
scales favorably as $\delta \to 0$. Our findings offer a sharper theoretical
tool for algorithms that rely on grid-based coverage guarantees, enabling more
efficient sampling, especially in high-confidence regimes.
\\ ( https://arxiv.org/abs/2511.17784 ,  7496kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17787
Date: Fri, 21 Nov 2025 21:08:34 GMT   (5505kb)

Title: Data-Driven Predictive Modeling of Microfluidic Cancer Cell Separation
 Using a Deterministic Lateral Displacement Device
Authors: Elizabeth Chen, Andrew Lee, Tanbir Sarowar, Xiaolin Chen
Categories: cs.LG physics.med-ph q-bio.QM
Comments: Accepted to IEEE International Conference on Data Mining (ICDM) 2025
 REU Symposium
\\
 Deterministic Lateral Displacement (DLD) devices are widely used in
microfluidics for label-free, size-based separation of particles and cells,
with particular promise in isolating circulating tumor cells (CTCs) for early
cancer diagnostics. This study focuses on the optimization of DLD design
parameters, such as row shift fraction, post size, and gap distance, to enhance
the selective isolation of lung cancer cells based on their physical
properties. To overcome the challenges of rare CTC detection and reduce
reliance on computationally intensive simulations, machine learning models
including gradient boosting, k-nearest neighbors, random forest, and multilayer
perceptron (MLP) regressors are employed. Trained on a large, numerically
validated dataset, these models predict particle trajectories and identify
optimal device configurations, enabling high-throughput and cost-effective DLD
design. Beyond trajectory prediction, the models aid in isolating critical
design variables, offering a systematic, data-driven framework for automated
DLD optimization. This integrative approach advances the development of
scalable and precise microfluidic systems for cancer diagnostics, contributing
to the broader goals of early detection and personalized medicine.
\\ ( https://arxiv.org/abs/2511.17787 ,  5505kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17789
Date: Fri, 21 Nov 2025 21:26:24 GMT   (713kb)

Title: Physical Reinforcement Learning
Authors: Sam Dillavou and Shruti Mishra
Categories: cs.LG cond-mat.dis-nn
Comments: 9 pages 4 figures
\\
 Digital computers are power-hungry and largely intolerant of damaged
components, making them potentially difficult tools for energy-limited
autonomous agents in uncertain environments. Recently developed Contrastive
Local Learning Networks (CLLNs) - analog networks of self-adjusting nonlinear
resistors - are inherently low-power and robust to physical damage, but were
constructed to perform supervised learning. In this work we demonstrate success
on two simple RL problems using Q-learning adapted for simulated CLLNs. Doing
so makes explicit the components (beyond the network being trained) required to
enact various tools in the RL toolbox, some of which (policy function and value
function) are more natural in this system than others (replay buffer). We
discuss assumptions such as the physical safety that digital hardware requires,
CLLNs can forgo, and biological systems cannot rely on, and highlight secondary
goals that are important in biology and trainable in CLLNs, but make little
sense in digital computers.
\\ ( https://arxiv.org/abs/2511.17789 ,  713kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17796
Date: Fri, 21 Nov 2025 21:41:15 GMT   (136kb)

Title: Semi-Supervised Federated Multi-Label Feature Selection with Fuzzy
 Information Measures
Authors: Afsaneh Mahanipour, Hana Khamfroush
Categories: cs.LG stat.ML
Comments: This paper has been accepted for presentation at GLOBECOM 2025
\\
 Multi-label feature selection (FS) reduces the dimensionality of multi-label
data by removing irrelevant, noisy, and redundant features, thereby boosting
the performance of multi-label learning models. However, existing methods
typically require centralized data, which makes them unsuitable for distributed
and federated environments where each device/client holds its own local
dataset. Additionally, federated methods often assume that clients have labeled
data, which is unrealistic in cases where clients lack the expertise or
resources to label task-specific data. To address these challenges, we propose
a Semi-Supervised Federated Multi-Label Feature Selection method, called
SSFMLFS, where clients hold only unlabeled data, while the server has limited
labeled data. SSFMLFS adapts fuzzy information theory to a federated setting,
where clients compute fuzzy similarity matrices and transmit them to the
server, which then calculates feature redundancy and feature-label relevancy
degrees. A feature graph is constructed by modeling features as vertices,
assigning relevancy and redundancy degrees as vertex weights and edge weights,
respectively. PageRank is then applied to rank the features by importance.
Extensive experiments on five real-world datasets from various domains,
including biology, images, music, and text, demonstrate that SSFMLFS
outperforms other federated and centralized supervised and semi-supervised
approaches in terms of three different evaluation metrics in non-IID data
distribution setting.
\\ ( https://arxiv.org/abs/2511.17796 ,  136kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17801
Date: Fri, 21 Nov 2025 21:47:39 GMT   (834kb)

Title: Layer-Wise High-Impact Parameter Ratio Optimization in Post-Training
 Quantization for Large Language Models
Authors: Cuong Pham, Hoang Anh Dung, Cuong C. Nguyen, Trung Le, Gustavo
 Carneiro, Thanh-Toan Do
Categories: cs.LG
\\
 Large language models (LLMs) have significantly advanced natural language
processing, but their massive parameter counts create substantial computational
and memory challenges during deployment. Post-training quantization (PTQ) has
emerged as a promising approach to mitigate these challenges with minimal
overhead. While existing PTQ methods can effectively quantize LLMs, they
experience substantial accuracy loss at extremely low bit-widths, primarily due
to high-impact parameters that significantly influence quantization
performance. Several approaches address these issues by identifying and
retaining the high-impact parameters in FP16 format. However, they apply fixed
ratios of high-impact parameters across all layers, overlooking layer-wise
sensitivity variations. In this paper, we propose a quadratic optimization
framework that determines layer-specific ratios of high-impact parameters while
considering inter-layer dependencies. We quantize high-impact parameters to
moderate bit-widths, which often result in negligible performance degradation
in quantized LLMs, while the remaining parameters can be quantized to extremely
low bit-widths. Under the same resource-constrained budget, this allows for
preserving more high-impact parameters than methods that keep selecting a few
in FP16 format. Additionally, the proposed framework allows us to leverage an
advanced quantization method that often requires extensive learnable parameters
solely for high-impact parameters, while applying a computationally efficient
method to the rest. Our approach achieves an effective balance between
computational efficiency and model accuracy while maintaining high performance
compared to state-of-the-art methods.
\\ ( https://arxiv.org/abs/2511.17801 ,  834kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17809
Date: Fri, 21 Nov 2025 22:01:58 GMT   (84kb)

Title: Adaptive Layer-Wise Transformations for Post-Training Quantization of
 Large Language Models
Authors: Cuong Pham, Hoang Anh Dung, Cuong C. Nguyen, Trung Le, Gustavo
 Carneiro, Jianfei Cai, Thanh-Toan Do
Categories: cs.LG
\\
 Large language models require significant computational resources for
deployment, making quantization essential for practical applications. However,
the main obstacle to effective quantization lies in systematic outliers in
activations and weights, which cause substantial LLM performance degradation,
especially at low-bit settings. While existing transformation-based methods
like affine and rotation transformations successfully mitigate outliers, they
apply the homogeneous transformation setting, i.e., using the same
transformation types across all layers, ignoring the heterogeneous distribution
characteristics within LLMs. In this paper, we propose an adaptive
transformation selection framework that systematically determines optimal
transformations on a per-layer basis. To this end, we first formulate
transformation selection as a differentiable optimization problem to achieve
the accurate transformation type for each layer. However, searching for optimal
layer-wise transformations for every model is computationally expensive. To
this end, we establish the connection between weight distribution kurtosis and
accurate transformation type. Specifically, we propose an outlier-guided layer
selection method using robust $z$-score normalization that achieves comparable
performance to differentiable search with significantly reduced overhead.
Comprehensive experiments on LLaMA family models demonstrate that our adaptive
approach consistently outperforms the widely-used fixed transformation
settings. For example, our method achieves an improvement of up to 4.58
perplexity points and a 2.11% gain in average six-task zero-shot accuracy under
aggressive W3A3K2V2 quantization settings for the LLaMA-3-8B model compared to
the current best existing method, FlatQuant, demonstrating the necessity of
heterogeneous transformation selection for optimal LLM quantization.
\\ ( https://arxiv.org/abs/2511.17809 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17818
Date: Fri, 21 Nov 2025 22:18:15 GMT   (4505kb)

Title: APRIL: Annotations for Policy evaluation with Reliable Inference from
 LLMs
Authors: Aishwarya Mandyam, Kalyani Limaye, Barbara E. Engelhardt, Emily
 Alsentzer
Categories: cs.LG cs.AI
\\
 Off-policy evaluation (OPE) estimates the value of a contextual bandit policy
prior to deployment. As such, OPE plays a critical role in ensuring safety in
high-stakes domains such as healthcare. However, standard OPE approaches are
limited by the size and coverage of the behavior dataset. While previous work
has explored using expert-labeled counterfactual annotations to enhance dataset
coverage, obtaining such annotations is expensive, limiting the scalability of
prior approaches. We propose leveraging large language models (LLMs) to
generate counterfactual annotations for OPE in medical domains. Our method uses
domain knowledge to guide LLMs in predicting how key clinical features evolve
under alternate treatments. These predicted features can then be transformed
using known reward functions to create counterfactual annotations. We first
evaluate the ability of several LLMs to predict clinical features across two
patient subsets in MIMIC-IV, finding that state-of-the-art LLMs achieve
comparable performance. Building on this capacity to predict clinical features,
we generate LLM-based counterfactual annotations and incorporate them into an
OPE estimator. Our empirical results analyze the benefits of counterfactual
annotations under varying degrees of shift between the behavior and target
policies. We find that in most cases, the LLM-based counterfactual annotations
significantly improve OPE estimates up to a point. We provide an entropy-based
metric to identify when additional annotations cease to be useful. Our results
demonstrate that LLM-based counterfactual annotations offer a scalable approach
for addressing coverage limitations in healthcare datasets, enabling safer
deployment of decision-making policies in clinical settings.
\\ ( https://arxiv.org/abs/2511.17818 ,  4505kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17822
Date: Fri, 21 Nov 2025 22:35:19 GMT   (99kb)

Title: High-Accuracy List-Decodable Mean Estimation
Authors: Ziyun Chen, Spencer Compton, Daniel Kane, Jerry Li
Categories: cs.LG cs.DS stat.ML
Comments: Abstract shortened to meet arXiv requirement
\\
 In list-decodable learning, we are given a set of data points such that an
$\alpha$-fraction of these points come from a nice distribution $D$, for some
small $\alpha \ll 1$, and the goal is to output a short list of candidate
solutions, such that at least one element of this list recovers some
non-trivial information about $D$. By now, there is a large body of work on
this topic; however, while many algorithms can achieve optimal list size in
terms of $\alpha$, all known algorithms must incur error which decays, in some
cases quite poorly, with $1 / \alpha$. In this paper, we ask if this is
inherent: is it possible to trade off list size with accuracy in list-decodable
learning? More formally, given $\epsilon > 0$, can we can output a slightly
larger list in terms of $\alpha$ and $\epsilon$, but so that one element of
this list has error at most $\epsilon$ with the ground truth? We call this
problem high-accuracy list-decodable learning. Our main result is that
non-trivial high-accuracy guarantees, both information-theoretically and
algorithmically, are possible for the canonical setting of list-decodable mean
estimation of identity-covariance Gaussians. Specifically, we demonstrate that
there exists a list of candidate means of size at most $L = \exp \left( O\left(
\tfrac{\log^2 1 / \alpha}{\epsilon^2} \right)\right)$ so that one of the
elements of this list has $\ell_2$ distance at most $\epsilon$ to the true
mean. We also design an algorithm that outputs such a list with runtime and
sample complexity $n = d^{O(\log L)} + \exp \exp (\widetilde{O}(\log L))$. We
do so by demonstrating a completely novel proof of identifiability, as well as
a new algorithmic way of leveraging this proof without the sum-of-squares
hierarchy, which may be of independent technical interest.
\\ ( https://arxiv.org/abs/2511.17822 ,  99kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17823
Date: Fri, 21 Nov 2025 22:36:14 GMT   (835kb)

Title: A novel k-means clustering approach using two distance measures for
 Gaussian data
Authors: Naitik Gada (1) ((1) Rochester Institute of Technology)
Categories: cs.LG cs.CE stat.ME stat.ML
Comments: Keywords: machine learning, clustering algorithms, k-means
\\
 Clustering algorithms have long been the topic of research, representing the
more popular side of unsupervised learning. Since clustering analysis is one of
the best ways to find some clarity and structure within raw data, this paper
explores a novel approach to \textit{k}-means clustering. Here we present a
\textit{k}-means clustering algorithm that takes both the within cluster
distance (WCD) and the inter cluster distance (ICD) as the distance metric to
cluster the data into \emph{k} clusters pre-determined by the Calinski-Harabasz
criterion in order to provide a more robust output for the clustering analysis.
The idea with this approach is that by including both the measurement metrics,
the convergence of the data into their clusters becomes solidified and more
robust. We run the algorithm with some synthetically produced data and also
some benchmark data sets obtained from the UCI repository. The results show
that the convergence of the data into their respective clusters is more
accurate by using both WCD and ICD measurement metrics. The algorithm is also
better at clustering the outliers into their true clusters as opposed to the
traditional \textit{k} means method. We also address some interesting possible
research topics that reveal themselves as we answer the questions we initially
set out to address.
\\ ( https://arxiv.org/abs/2511.17823 ,  835kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17826
Date: Fri, 21 Nov 2025 22:40:00 GMT   (532kb)

Title: Deterministic Inference across Tensor Parallel Sizes That Eliminates
 Training-Inference Mismatch
Authors: Ziyang Zhang, Xinheng Ding, Jiayi Yuan, Rixin Liu, Huizi Mao, Jiarong
 Xing, Zirui Liu
Categories: cs.LG cs.CL stat.ML
\\
 Deterministic inference is increasingly critical for large language model
(LLM) applications such as LLM-as-a-judge evaluation, multi-agent systems, and
Reinforcement Learning (RL). However, existing LLM serving frameworks exhibit
non-deterministic behavior: identical inputs can yield different outputs when
system configurations (e.g., tensor parallel (TP) size, batch size) vary, even
under greedy decoding. This arises from the non-associativity of floating-point
arithmetic and inconsistent reduction orders across GPUs. While prior work has
addressed batch-size-related nondeterminism through batch-invariant kernels,
determinism across different TP sizes remains an open problem, particularly in
RL settings, where the training engine typically uses Fully Sharded Data
Parallel (i.e., TP = 1) while the rollout engine relies on multi-GPU TP to
maximize the inference throughput, creating a natural mismatch between the two.
This precision mismatch problem may lead to suboptimal performance or even
collapse for RL training. We identify and analyze the root causes of TP-induced
inconsistency and propose Tree-Based Invariant Kernels (TBIK), a set of
TP-invariant matrix multiplication and reduction primitives that guarantee
bit-wise identical results regardless of TP size. Our key insight is to align
intra- and inter-GPU reduction orders through a unified hierarchical binary
tree structure. We implement these kernels in Triton and integrate them into
vLLM and FSDP. Experiments confirm zero probability divergence and bit-wise
reproducibility for deterministic inference across different TP sizes. Also, we
achieve bit-wise identical results between vLLM and FSDP in RL training
pipelines with different parallel strategy. Code is available at
https://github.com/nanomaoli/llm_reproducibility.
\\ ( https://arxiv.org/abs/2511.17826 ,  532kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17829
Date: Fri, 21 Nov 2025 22:47:50 GMT   (1876kb)

Title: Unified Class and Domain Incremental Learning with Mixture of Experts
 for Indoor Localization
Authors: Akhil Singampalli, Sudeep Pasricha
Categories: cs.LG cs.AI
\\
 Indoor localization using machine learning has gained traction due to the
growing demand for location-based services. However, its long-term reliability
is hindered by hardware/software variations across mobile devices, which shift
the model's input distribution to create domain shifts. Further, evolving
indoor environments can introduce new locations over time, expanding the output
space to create class shifts, making static machine learning models ineffective
over time. To address these challenges, we propose a novel unified continual
learning framework for indoor localization called MOELO that, for the first
time, jointly addresses domain-incremental and class-incremental learning
scenarios. MOELO enables a lightweight, robust, and adaptive localization
solution that can be deployed on resource-limited mobile devices and is capable
of continual learning in dynamic, heterogeneous real-world settings. This is
made possible by a mixture-of-experts architecture, where experts are
incrementally trained per region and selected through an equiangular tight
frame based gating mechanism ensuring efficient routing, and low-latency
inference, all within a compact model footprint. Experimental evaluations show
that MOELO achieves improvements of up to 25.6x in mean localization error,
44.5x in worst-case localization error, and 21.5x lesser forgetting compared to
state-of-the-art frameworks across diverse buildings, mobile devices, and
learning scenarios.
\\ ( https://arxiv.org/abs/2511.17829 ,  1876kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17840
Date: Fri, 21 Nov 2025 23:27:53 GMT   (47kb)

Title: Internalizing Tools as Morphisms in Graded Transformers
Authors: Tony Shaska
Categories: cs.LG math.CT
MSC-class: 18C10, 68T07, 62F12, 68Q32, 18D05
ACM-class: I.2.6; F.1.1; I.2.3; F.4.1; G.1.6; I.2.8
\\
 We introduce a graded formulation of internal symbolic computation for
transformers. The hidden space is endowed with a grading $V=\bigoplus_{g\in
G}V_g$, and symbolic operations are realized as typed block maps (morphisms)
$\phi_{h\leftarrow g}:V_g\to V_h$ that are activated selectively by a
differentiable routing policy. A self-supervised \emph{graded utility
functional}, defined as the loss reduction induced by a candidate morphism,
governs activation and yields sparse, interpretable behavior. We develop the
algebraic and geometric foundations: an internal model category whose objects
are homogeneous components and whose morphisms are admissible grade
transitions; adjoint pairs encoding typed round trips; and
information-geometric interpretations in terms of KL gain, mirror descent with
Bregman divergences, and Fisher natural gradients. Methodologically, we specify
a utility--aware routing mechanism and objective that remain fully end-to-end
differentiable. Analytic case studies and lightweight sanity checks illustrate
selective morphic activation on hybrid symbolic-linguistic tasks. The framework
unifies symbolic computation, geometry, and self--supervised learning within
the \emph{graded transformer} formalism \cite{sh-89,sh-95}, while subsuming
prior external-tool paradigms (e.g., Toolformer \cite{toolformer2023}) as a
special case via functorial internalization.
\\ ( https://arxiv.org/abs/2511.17840 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17848
Date: Sat, 22 Nov 2025 00:18:03 GMT   (6206kb)

Title: Scaling Kinetic Monte-Carlo Simulations of Grain Growth with Combined
 Convolutional and Graph Neural Networks
Authors: Zhihui Tian, Ethan Suwandi, Tomas Oppelstrup, Vasily V. Bulatov, Joel
 B. Harley and Fei Zhou
Categories: cs.LG cond-mat.mtrl-sci
\\
 Graph neural networks (GNN) have emerged as a promising machine learning
method for microstructure simulations such as grain growth. However, accurate
modeling of realistic grain boundary networks requires large simulation cells,
which GNN has difficulty scaling up to. To alleviate the computational costs
and memory footprint of GNN, we propose a hybrid architecture combining a
convolutional neural network (CNN) based bijective autoencoder to compress the
spatial dimensions, and a GNN that evolves the microstructure in the latent
space of reduced spatial sizes. Our results demonstrate that the new design
significantly reduces computational costs with using fewer message passing
layer (from 12 down to 3) compared with GNN alone. The reduction in
computational cost becomes more pronounced as the spatial size increases,
indicating strong computational scalability. For the largest mesh evaluated
(160^3), our method reduces memory usage and runtime in inference by 117x and
115x, respectively, compared with GNN-only baseline. More importantly, it shows
higher accuracy and stronger spatiotemporal capability than the GNN-only
baseline, especially in long-term testing. Such combination of scalability and
accuracy is essential for simulating realistic material microstructures over
extended time scales. The improvements can be attributed to the bijective
autoencoder's ability to compress information losslessly from spatial domain
into a high dimensional feature space, thereby producing more expressive latent
features for the GNN to learn from, while also contributing its own
spatiotemporal modeling capability. The training was optimized to learn from
the stochastic Potts Monte Carlo method. Our findings provide a highly scalable
approach for simulating grain growth.
\\ ( https://arxiv.org/abs/2511.17848 ,  6206kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17852
Date: Sat, 22 Nov 2025 00:38:43 GMT   (2930kb)

Title: Transformers with RL or SFT Provably Learn Sparse Boolean Functions, But
 Differently
Authors: Bochen Lyu, Yiyang Jia, Xiaohao Cai, Zhanxing Zhu
Categories: cs.LG stat.ML
Comments: 43 pages, 5 figures
\\
 Transformers can acquire Chain-of-Thought (CoT) capabilities to solve complex
reasoning tasks through fine-tuning. Reinforcement learning (RL) and supervised
fine-tuning (SFT) are two primary approaches to this end, yet their underlying
mechanisms and differences remain theoretically unclear. In this work, we
examine these aspects specifically for learning $k$-sparse Boolean functions
with a one-layer transformer and intermediate supervision that is akin to CoT.
In particular, we consider $k$-sparse Boolean functions that can be recursively
decomposed into fixed 2-sparse Boolean functions. We analyze the learning
dynamics of fine-tuning the transformer via either RL or SFT with CoT to
identify sufficient conditions for it to provably learn these functions. We
verify that these conditions hold for three basic examples, including
$k$-PARITY, $k$-AND, and $k$-OR, thus demonstrating the learnability of both
approaches. Notably, we reveal that RL and SFT exhibit distinct learning
behaviors: RL learns the whole CoT chain simultaneously, whereas SFT learns the
CoT chain step-by-step. Overall, our findings provide theoretical insights into
the underlying mechanisms of RL and SFT as well as how they differ in
triggering the CoT capabilities of transformers.
\\ ( https://arxiv.org/abs/2511.17852 ,  2930kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17861
Date: Sat, 22 Nov 2025 01:11:44 GMT   (3849kb)

Title: Cost-Sensitive Conformal Training with Provably Controllable Learning
 Bounds
Authors: Xuesong Jia, Yuanjie Shi, Ziquan Liu, Yi Xu, Yan Yan
Categories: cs.LG stat.ML
Comments: Accepted for Publication at Association for the Advancement of
 Artificial Intelligence (AAAI), 2026
\\
 Conformal prediction (CP) is a general framework to quantify the predictive
uncertainty of machine learning models that uses a set prediction to include
the true label with a valid probability. To align the uncertainty measured by
CP, conformal training methods minimize the size of the prediction sets. A
typical way is to use a surrogate indicator function, usually Sigmoid or
Gaussian error function. However, these surrogate functions do not have a
uniform error bound to the indicator function, leading to uncontrollable
learning bounds. In this paper, we propose a simple cost-sensitive conformal
training algorithm that does not rely on the indicator approximation mechanism.
Specifically, we theoretically show that minimizing the expected size of
prediction sets is upper bounded by the expected rank of true labels. To this
end, we develop a rank weighting strategy that assigns the weight using the
rank of true label on each data sample. Our analysis provably demonstrates the
tightness between the proposed weighted objective and the expected size of
conformal prediction sets. Extensive experiments verify the validity of our
theoretical insights, and superior empirical performance over other conformal
training in terms of predictive efficiency with 21.38% reduction for average
prediction set size.
\\ ( https://arxiv.org/abs/2511.17861 ,  3849kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17864
Date: Sat, 22 Nov 2025 01:17:15 GMT   (190kb)

Title: Equivalence of Context and Parameter Updates in Modern Transformer
 Blocks
Authors: Adrian Goldwaser, Michael Munn, Javier Gonzalvo, Benoit Dherin
Categories: cs.LG
\\
 Recent research has established that the impact of context in a vanilla
transformer can be represented implicitly by forming a token-dependent, rank-1
patch to its MLP weights. This work extends that foundational theory to the
diverse architectures of modern Large Language Models. We first demonstrate a
precise, analytical solution for a Gemma-style transformer block, proving that
the entire effect of a context can be perfectly mapped to rank-1 patches on its
MLP weight matrices and a patch to the RMSNorm scale. We then generalize this
result, providing a constructive proof and algorithm for multi-layer models. To
unify these findings, we introduce a general framework centered on two core
properties: input controllability and output controllability. We prove that a
perfect implicit weight patch is possible for any MLP block where the inner
function is input-controllable and the outer function is output-controllable.
This provides a simpler and more powerful lens for understanding how
transformer models transmute prompts into effective weights. This setup
generalizes to a wide range of modern LLM architectures including gating,
pre-/post-norm, mixture of experts and sequential/parallel transformer blocks.
\\ ( https://arxiv.org/abs/2511.17864 ,  190kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17869
Date: Sat, 22 Nov 2025 01:45:52 GMT   (7005kb)

Title: The Horcrux: Mechanistically Interpretable Task Decomposition for
 Detecting and Mitigating Reward Hacking in Embodied AI Systems
Authors: Subramanyam Sahoo, Jared Junkin
Categories: cs.LG
Comments: Accepted to the NeurIPS (Mexico City) 2025 Workshop on Embodied and
 Safe-Assured Robotic Systems (E-SARS). Thanks to Aman Chadha
\\
 Embodied AI agents exploit reward signal flaws through reward hacking,
achieving high proxy scores while failing true objectives. We introduce
Mechanistically Interpretable Task Decomposition (MITD), a hierarchical
transformer architecture with Planner, Coordinator, and Executor modules that
detects and mitigates reward hacking. MITD decomposes tasks into interpretable
subtasks while generating diagnostic visualizations including Attention
Waterfall Diagrams and Neural Pathway Flow Charts. Experiments on 1,000 HH-RLHF
samples reveal that decomposition depths of 12 to 25 steps reduce reward
hacking frequency by 34 percent across four failure modes. We present new
paradigms showing that mechanistically grounded decomposition offers a more
effective way to detect reward hacking than post-hoc behavioral monitoring.
\\ ( https://arxiv.org/abs/2511.17869 ,  7005kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17879
Date: Sat, 22 Nov 2025 02:12:41 GMT   (2072kb)

Title: Generative Adversarial Post-Training Mitigates Reward Hacking in Live
 Human-AI Music Interaction
Authors: Yusong Wu, Stephen Brade, Teng Ma, Tia-Jane Fowler, Enning Yang,
 Berker Banar, Aaron Courville, Natasha Jaques, and Cheng-Zhi Anna Huang
Categories: cs.LG cs.SD
\\
 Most applications of generative AI involve a sequential interaction in which
a person inputs a prompt and waits for a response, and where reaction time and
adaptivity are not important factors. In contrast, live jamming is a
collaborative interaction that requires real-time coordination and adaptation
without access to the other player's future moves, while preserving diversity
to sustain a creative flow. Reinforcement learning post-training enables
effective adaptation through on-policy interaction, yet it often reduces output
diversity by exploiting coherence-based rewards. This collapse, known as
``reward hacking'', affects many RL post-training pipelines, but is especially
harmful in live jamming, where musical creativity relies on dynamic variation
and mutual responsiveness. In this paper, we propose a novel adversarial
training method on policy-generated trajectories to mitigate reward hacking in
RL post-training for melody-to-chord accompaniment. A co-evolving discriminator
separates policy trajectories from the data distribution, while the policy
maximizes the discriminator output in addition to coherence rewards to prevent
collapse to trivial outputs. We evaluate accompaniment quality and output
diversity in simulation with both fixed test melodies and learned melody
agents, and we conduct a user study with the model deployed in a real-time
interactive system with expert musicians. Quantitative evaluation and user
feedback demonstrate improved output diversity, harmonic coherence, adaptation
speed and user agency. Our results demonstrate a simple yet effective method to
mitigate reward hacking in RL post-training of generative sequence models.
\\ ( https://arxiv.org/abs/2511.17879 ,  2072kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17902
Date: Sat, 22 Nov 2025 03:39:13 GMT   (410kb)

Title: Statistically-Guided Dual-Domain Meta-Learning with Adaptive
 Multi-Prototype Aggregation for Distributed Fiber Optic Sensing
Authors: Yifan He, Haodong Zhang, Qiuheng Song, Lin Lei, Zhenxuan Zeng, Haoyang
 He, Hongyan Wu
Categories: cs.LG cs.AI stat.ML
\\
 Distributed Fiber Optic Sensing (DFOS) has shown strong potential in
perimeter security due to its capability of monitoring vibration events across
long distances with fine spatial resolution. However, practical DFOS systems
face three critical challenges: (1) signal patterns of the same activity vary
drastically under different fiber deployment types (e.g., underground,
wall-mounted), causing domain shift; (2) labeled data in new deployment
scenarios is often scarce or entirely unavailable, limiting model adaptability;
and (3) even within source domains, data scarcity makes it difficult to capture
intra-class diversity for robust learning.
 To address these challenges, we propose a novel meta-learning framework,
DUPLE, for cross-deployment DFOS activity identification. First, a dual-domain
multi-prototype learner fuses temporal and frequency domain features, enhancing
the model's generalization ability under signal distribution shifts. Second, a
Statistical Guided Network (SGN) infers domain importance and prototype
sensitivity from raw statistical features, providing data-driven prior
information for learning in unlabeled or unseen domains. Third, a query-aware
prototype aggregation module adaptively selects and combines relevant
prototypes, thereby improving classification performance even with limited
data.
 Extensive experiments on cross-deployment DFOS datasets demonstrate that our
method significantly outperforms baseline approaches in domain generalization
settings, enabling robust event recognition across diverse fiber configurations
with minimal labeled data.
\\ ( https://arxiv.org/abs/2511.17902 ,  410kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17936
Date: Sat, 22 Nov 2025 06:25:54 GMT   (160kb)

Title: Mitigating Catastrophic Forgetting in Streaming Generative and
 Predictive Learning via Stateful Replay
Authors: Wenzhang Du
Categories: cs.LG stat.ML
Comments: 11 pages, 4 figures
MSC-class: 68T05, 68T10, 68Q32
ACM-class: I.2.6; I.5.1; H.2.8
\\
 Many deployed learning systems must update models on streaming data under
memory constraints. The default strategy, sequential fine-tuning on each new
phase, is architecture-agnostic but often suffers catastrophic forgetting when
later phases correspond to different sub-populations or tasks. Replay with a
finite buffer is a simple alternative, yet its behaviour across generative and
predictive objectives is not well understood. We present a unified study of
stateful replay for streaming autoencoding, time series forecasting, and
classification. We view both sequential fine-tuning and replay as stochastic
gradient methods for an ideal joint objective, and use a gradient alignment
analysis to show when mixing current and historical samples should reduce
forgetting. We then evaluate a single replay mechanism on six streaming
scenarios built from Rotated MNIST, ElectricityLoadDiagrams 2011-2014, and
Airlines delay data, using matched training budgets and three seeds. On
heterogeneous multi task streams, replay reduces average forgetting by a factor
of two to three, while on benign time based streams both methods perform
similarly. These results position stateful replay as a strong and simple
baseline for continual learning in streaming environments.
\\ ( https://arxiv.org/abs/2511.17936 ,  160kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17953
Date: Sat, 22 Nov 2025 07:38:11 GMT   (334kb)

Title: On Transportability for Structural Causal Bandits
Authors: Min Woo Park and Sanghack Lee
Categories: cs.LG stat.ML
\\
 Intelligent agents equipped with causal knowledge can optimize their action
spaces to avoid unnecessary exploration. The structural causal bandit framework
provides a graphical characterization for identifying actions that are unable
to maximize rewards by leveraging prior knowledge of the underlying causal
structure. While such knowledge enables an agent to estimate the expected
rewards of certain actions based on others in online interactions, there has
been little guidance on how to transfer information inferred from arbitrary
combinations of datasets collected under different conditions -- observational
or experimental -- and from heterogeneous environments. In this paper, we
investigate the structural causal bandit with transportability, where priors
from the source environments are fused to enhance learning in the deployment
setting. We demonstrate that it is possible to exploit invariances across
environments to consistently improve learning. The resulting bandit algorithm
achieves a sub-linear regret bound with an explicit dependence on
informativeness of prior data, and it may outperform standard bandit approaches
that rely solely on online learning.
\\ ( https://arxiv.org/abs/2511.17953 ,  334kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17963
Date: Sat, 22 Nov 2025 07:57:03 GMT   (2184kb)

Title: Hybrid LSTM and PPO Networks for Dynamic Portfolio Optimization
Authors: Jun Kevin, Pujianto Yugopuspito
Categories: cs.LG cs.AI cs.CE q-fin.PM
Comments: 12 pages, 8 figures, 2 tables, accepted at 2025 8th Artificial
 Intelligence and Cloud Computing Conference
ACM-class: I.2.7; J.4
\\
 This paper introduces a hybrid framework for portfolio optimization that
fuses Long Short-Term Memory (LSTM) forecasting with a Proximal Policy
Optimization (PPO) reinforcement learning strategy. The proposed system
leverages the predictive power of deep recurrent networks to capture temporal
dependencies, while the PPO agent adaptively refines portfolio allocations in
continuous action spaces, allowing the system to anticipate trends while
adjusting dynamically to market shifts. Using multi-asset datasets covering
U.S. and Indonesian equities, U.S. Treasuries, and major cryptocurrencies from
January 2018 to December 2024, the model is evaluated against several
baselines, including equal-weight, index-style, and single-model variants
(LSTM-only and PPO-only). The framework's performance is benchmarked against
equal-weighted, index-based, and single-model approaches (LSTM-only and
PPO-only) using annualized return, volatility, Sharpe ratio, and maximum
drawdown metrics, each adjusted for transaction costs. The results indicate
that the hybrid architecture delivers higher returns and stronger resilience
under non-stationary market regimes, suggesting its promise as a robust,
AI-driven framework for dynamic portfolio optimization.
\\ ( https://arxiv.org/abs/2511.17963 ,  2184kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17968
Date: Sat, 22 Nov 2025 08:11:52 GMT   (2289kb)

Title: Uncertainty-Aware Federated Learning for Cyber-Resilient Microgrid
 Energy Management
Authors: Oluleke Babayomi, Dong-Seong Kim
Categories: cs.LG cs.CR
Comments: 6 pages
\\
 Maintaining economic efficiency and operational reliability in microgrid
energy management systems under cyberattack conditions remains challenging.
Most approaches assume non-anomalous measurements, make predictions with
unquantified uncertainties, and do not mitigate malicious attacks on renewable
forecasts for energy management optimization. This paper presents a
comprehensive cyber-resilient framework integrating federated Long Short-Term
Memory-based photovoltaic forecasting with a novel two-stage cascade false data
injection attack detection and energy management system optimization. The
approach combines autoencoder reconstruction error with prediction uncertainty
quantification to enable attack-resilient energy storage scheduling while
preserving data privacy. Extreme false data attack conditions were studied that
caused 58% forecast degradation and 16.9\% operational cost increases. The
proposed integrated framework reduced false positive detections by 70%,
recovered 93.7% of forecasting performance losses, and achieved 5\% operational
cost savings, mitigating 34.7% of attack-induced economic losses. Results
demonstrate that precision-focused cascade detection with multi-signal fusion
outperforms single-signal approaches, validating security-performance synergy
for decentralized microgrids.
\\ ( https://arxiv.org/abs/2511.17968 ,  2289kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17970
Date: Sat, 22 Nov 2025 08:13:17 GMT   (6711kb)

Title: Controllability Analysis of State Space-based Language Model
Authors: Mohamed Mabrok and Yalda Zafari
Categories: cs.LG
\\
 State-space models (SSMs), particularly Mamba, have become powerful
architectures for sequence modeling, yet their internal dynamics remain poorly
understood compared to attention-based models. We introduce and validate the
Influence Score, a controllability-based metric derived from the discretized
state-space parameters of Mamba and computed through a backward recurrence
analogous to system observability. The score quantifies how strongly a token at
position k affects all later states and outputs. We evaluate this measure
across three Mamba variants: mamba-130m, mamba-2.8b, and mamba-2.8b-slimpj,
using six experiments that test its sensitivity to temperature, prompt
complexity, token type, layer depth, token position, and input perturbations.
The results show three main insights: (1) the Influence Score increases with
model size and training data, reflecting model capacity; (2) Mamba exhibits
consistent architectural patterns, including recency bias and concentrated
influence in mid-to-late layers; and (3) emergent behaviors appear only at
scale, with mamba-2.8b-slimpj uniquely prioritizing content words and reducing
internal influence in the presence of noise. These findings establish the
Influence Score as a practical diagnostic tool for interpreting and comparing
SSM-based language models.
\\ ( https://arxiv.org/abs/2511.17970 ,  6711kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17978
Date: Sat, 22 Nov 2025 08:41:58 GMT   (800kb)

Title: Federated Anomaly Detection and Mitigation for EV Charging Forecasting
 Under Cyberattacks
Authors: Oluleke Babayomi, Dong-Seong Kim
Categories: cs.LG cs.CR
Comments: 6 pages
\\
 Electric Vehicle (EV) charging infrastructure faces escalating cybersecurity
threats that can severely compromise operational efficiency and grid stability.
Existing forecasting techniques are limited by the lack of combined robust
anomaly mitigation solutions and data privacy preservation. Therefore, this
paper addresses these challenges by proposing a novel anomaly-resilient
federated learning framework that simultaneously preserves data privacy,
detects cyber-attacks, and maintains trustworthy demand prediction accuracy
under adversarial conditions. The proposed framework integrates three key
innovations: LSTM autoencoder-based distributed anomaly detection deployed at
each federated client, interpolation-based anomalous data mitigation to
preserve temporal continuity, and federated Long Short-Term Memory (LSTM)
networks that enable collaborative learning without centralized data
aggregation. The framework is validated on real-world EV charging
infrastructure datasets combined with real-world DDoS attack datasets,
providing robust validation of the proposed approach under realistic threat
scenarios. Experimental results demonstrate that the federated approach
achieves superior performance compared to centralized models, with 15.2%
improvement in R2 accuracy while maintaining data locality. The integrated
cyber-attack detection and mitigation system produces trustworthy datasets that
enhance prediction reliability, recovering 47.9% of attack-induced performance
degradation while maintaining exceptional precision (91.3%) and minimal false
positive rates (1.21%). The proposed architecture enables enhanced EV
infrastructure planning, privacy-preserving collaborative forecasting,
cybersecurity resilience, and rapid recovery from malicious threats across
distributed charging networks.
\\ ( https://arxiv.org/abs/2511.17978 ,  800kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17983
Date: Sat, 22 Nov 2025 08:53:59 GMT   (8515kb)

Title: An Adaptive Resonance Theory-based Topological Clustering Algorithm with
 a Self-Adjusting Vigilance Parameter
Authors: Naoki Masuyama, Yuichiro Toda, Yusuke Nojima, Hisao Ishibuchi
Categories: cs.LG stat.ML
Comments: This manuscript is currently under review
\\
 Clustering in stationary and nonstationary settings, where data distributions
remain static or evolve over time, requires models that can adapt to
distributional shifts while preserving previously learned cluster structures.
This paper proposes an Adaptive Resonance Theory (ART)-based topological
clustering algorithm that autonomously adjusts its recalculation interval and
vigilance threshold through a diversity-driven adaptation mechanism. This
mechanism enables hyperparameter-free learning that maintains cluster stability
and continuity in dynamic environments. Experiments on 24 real-world datasets
demonstrate that the proposed algorithm outperforms state-of-the-art methods in
both clustering performance and continual learning capability. These results
highlight the effectiveness of the proposed parameter adaptation in mitigating
catastrophic forgetting and maintaining consistent clustering in evolving data
streams. Source code is available at https://github.com/Masuyama-lab/IDAT
\\ ( https://arxiv.org/abs/2511.17983 ,  8515kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17987
Date: Sat, 22 Nov 2025 09:01:05 GMT   (674kb)

Title: Escaping Optimization Stagnation: Taking Steps Beyond Task Arithmetic
 via Difference Vectors
Authors: Jinping Wang, Zhiqiang Gao, Dinggen Zhang, Zhiwu Xie
Categories: cs.LG cs.AI
\\
 Current methods for editing pre-trained models face significant challenges,
primarily high computational costs and limited scalability. Task arithmetic has
recently emerged as a promising solution, using simple arithmetic
operations-addition and negation-based on task vectors which are the
differences between fine-tuned and pre-trained model weights, to efficiently
modify model behavior. However, the full potential of task arithmetic remains
underexplored, primarily due to limited mechanisms for overcoming optimization
stagnation. To address this challenge, we introduce the notion of difference
vector, a generalized form of task vectors derived from the historical
movements during optimization. Using difference vectors as directed
perturbations, we propose the Difference Vector-based Anisotropic Scaling
Iterative algorithm (DV-BASI) to enable a continuous optimization process for
task arithmetic methods without relying on any additional modules or
components. Notably, by leveraging escapability and directional advantages of
difference vectors, the average performance on different tasks of the
multi-task model merged by DV-BASI may even outperform models individually
fine-tuned. Based on this observation, we extend the application of difference
vectors to a feasible fine-tuning method for single-task models. On the
practical side, DV-BASI allows expressive searching directions with few
learnable parameters and forms a scalable framework. We also integrate DV-BASI
with task arithmetic methods and advanced optimization techniques to achieve
state-of-the-art performance on both supervised and unsupervised evaluation
protocols.
\\ ( https://arxiv.org/abs/2511.17987 ,  674kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17989
Date: Sat, 22 Nov 2025 09:04:58 GMT   (1499kb)

Title: Privacy Auditing of Multi-domain Graph Pre-trained Model under
 Membership Inference Attacks
Authors: Jiayi Luo, Qingyun Sun, Yuecen Wei, Haonan Yuan, Xingcheng Fu, Jianxin
 Li
Categories: cs.LG cs.AI cs.CR
Comments: Accepted by AAAI 2026(Oral)
\\
 Multi-domain graph pre-training has emerged as a pivotal technique in
developing graph foundation models. While it greatly improves the
generalization of graph neural networks, its privacy risks under membership
inference attacks (MIAs), which aim to identify whether a specific instance was
used in training (member), remain largely unexplored. However, effectively
conducting MIAs against multi-domain graph pre-trained models is a significant
challenge due to: (i) Enhanced Generalization Capability: Multi-domain
pre-training reduces the overfitting characteristics commonly exploited by
MIAs. (ii) Unrepresentative Shadow Datasets: Diverse training graphs hinder the
obtaining of reliable shadow graphs. (iii) Weakened Membership Signals:
Embedding-based outputs offer less informative cues than logits for MIAs. To
tackle these challenges, we propose MGP-MIA, a novel framework for Membership
Inference Attacks against Multi-domain Graph Pre-trained models. Specifically,
we first propose a membership signal amplification mechanism that amplifies the
overfitting characteristics of target models via machine unlearning. We then
design an incremental shadow model construction mechanism that builds a
reliable shadow model with limited shadow graphs via incremental learning.
Finally, we introduce a similarity-based inference mechanism that identifies
members based on their similarity to positive and negative samples. Extensive
experiments demonstrate the effectiveness of our proposed MGP-MIA and reveal
the privacy risks of multi-domain graph pre-training.
\\ ( https://arxiv.org/abs/2511.17989 ,  1499kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17994
Date: Sat, 22 Nov 2025 09:24:45 GMT   (290kb)

Title: Learning Rate Scheduling with Matrix Factorization for Private Training
Authors: Nikita P. Kalinin, Joel Daniel Andersson
Categories: cs.LG stat.ML
\\
 We study differentially private model training with stochastic gradient
descent under learning rate scheduling and correlated noise. Although
correlated noise, in particular via matrix factorizations, has been shown to
improve accuracy, prior theoretical work focused primarily on the prefix-sum
workload. That workload assumes a constant learning rate, whereas in practice
learning rate schedules are widely used to accelerate training and improve
convergence. We close this gap by deriving general upper and lower bounds for a
broad class of learning rate schedules in both single- and multi-epoch
settings. Building on these results, we propose a learning-rate-aware
factorization that achieves improvements over prefix-sum factorizations under
both MaxSE and MeanSE error metrics. Our theoretical analysis yields
memory-efficient constructions suitable for practical deployment, and
experiments on CIFAR-10 and IMDB datasets confirm that schedule-aware
factorizations improve accuracy in private training.
\\ ( https://arxiv.org/abs/2511.17994 ,  290kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18000
Date: Sat, 22 Nov 2025 10:02:37 GMT   (1706kb)

Title: Reward Engineering for Spatial Epidemic Simulations: A Reinforcement
 Learning Platform for Individual Behavioral Learning
Authors: Radman Rakhshandehroo, Daniel Coombs
Categories: cs.LG cs.AI q-bio.PE
Comments: 35 pages, 15 figures and 14 tables
\\
 We present ContagionRL, a Gymnasium-compatible reinforcement learning
platform specifically designed for systematic reward engineering in spatial
epidemic simulations. Unlike traditional agent-based models that rely on fixed
behavioral rules, our platform enables rigorous evaluation of how reward
function design affects learned survival strategies across diverse epidemic
scenarios. ContagionRL integrates a spatial SIRS+D epidemiological model with
configurable environmental parameters, allowing researchers to stress-test
reward functions under varying conditions including limited observability,
different movement patterns, and heterogeneous population dynamics. We evaluate
five distinct reward designs, ranging from sparse survival bonuses to a novel
potential field approach, across multiple RL algorithms (PPO, SAC, A2C).
Through systematic ablation studies, we identify that directional guidance and
explicit adherence incentives are critical components for robust policy
learning. Our comprehensive evaluation across varying infection rates, grid
sizes, visibility constraints, and movement patterns reveals that reward
function choice dramatically impacts agent behavior and survival outcomes.
Agents trained with our potential field reward consistently achieve superior
performance, learning maximal adherence to non-pharmaceutical interventions
while developing sophisticated spatial avoidance strategies. The platform's
modular design enables systematic exploration of reward-behavior relationships,
addressing a knowledge gap in models of this type where reward engineering has
received limited attention. ContagionRL is an effective platform for studying
adaptive behavioral responses in epidemic contexts and highlight the importance
of reward design, information structure, and environmental predictability in
learning.
\\ ( https://arxiv.org/abs/2511.18000 ,  1706kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18006
Date: Sat, 22 Nov 2025 10:09:46 GMT   (19715kb)

Title: Understanding Private Learning From Feature Perspective
Authors: Meng Ding, Mingxi Lei, Shaopeng Fu, Shaowei Wang, Di Wang, Jinhui Xu
Categories: cs.LG
Comments: 39pages
\\
 Differentially private Stochastic Gradient Descent (DP-SGD) has become
integral to privacy-preserving machine learning, ensuring robust privacy
guarantees in sensitive domains. Despite notable empirical advances leveraging
features from non-private, pre-trained models to enhance DP-SGD training, a
theoretical understanding of feature dynamics in private learning remains
underexplored. This paper presents the first theoretical framework to analyze
private training through a feature learning perspective. Building on the
multi-patch data structure from prior work, our analysis distinguishes between
label-dependent feature signals and label-independent noise, a critical aspect
overlooked by existing analyses in the DP community. Employing a two-layer CNN
with polynomial ReLU activation, we theoretically characterize both feature
signal learning and data noise memorization in private training via noisy
gradient descent. Our findings reveal that (1) Effective private signal
learning requires a higher signal-to-noise ratio (SNR) compared to non-private
training, and (2) When data noise memorization occurs in non-private learning,
it will also occur in private learning, leading to poor generalization despite
small training loss. Our findings highlight the challenges of private learning
and prove the benefit of feature enhancement to improve SNR. Experiments on
synthetic and real-world datasets also validate our theoretical findings.
\\ ( https://arxiv.org/abs/2511.18006 ,  19715kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18039
Date: Sat, 22 Nov 2025 12:33:31 GMT   (1009kb)

Title: Curvature-Aware Safety Restoration In LLMs Fine-Tuning
Authors: Thong Bach, Thanh Nguyen-Tang, Dung Nguyen, Thao Minh Le, Truyen Tran
Categories: cs.LG
Comments: 19 pages, 10 figures
\\
 Fine-tuning Large Language Models (LLMs) for downstream tasks often
compromises safety alignment, even when using parameter-efficient methods like
LoRA. In this work, we uncover a notable property: fine-tuned models preserve
the geometric structure of their loss landscapes concerning harmful content,
regardless of the fine-tuning method employed. This suggests that safety
behaviors are not erased but shifted to less influential regions of the
parameter space. Building on this insight, we propose a curvature-aware
alignment restoration method that leverages influence functions and
second-order optimization to selectively increase loss on harmful inputs while
preserving task performance. By navigating the shared geometry between base and
fine-tuned models, our method discourages unsafe outputs while preserving
task-relevant performance, avoiding full reversion and enabling precise,
low-impact updates. Extensive evaluations across multiple model families and
adversarial settings show that our approach efficiently reduces harmful
responses while maintaining or even improving utility and few-shot learning
performance.
\\ ( https://arxiv.org/abs/2511.18039 ,  1009kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18056
Date: Sat, 22 Nov 2025 13:20:34 GMT   (83kb)

Title: Hierarchical Linkage Clustering Beyond Binary Trees and Ultrametrics
Authors: Maximilien Dreveton, Matthias Grossglauser, Daichi Kuroda, Patrick
 Thiran
Categories: cs.LG stat.ME stat.ML
\\
 Hierarchical clustering seeks to uncover nested structures in data by
constructing a tree of clusters, where deeper levels reveal finer-grained
relationships. Traditional methods, including linkage approaches, face three
major limitations: (i) they always return a hierarchy, even if none exists,
(ii) they are restricted to binary trees, even if the true hierarchy is
non-binary, and (iii) they are highly sensitive to the choice of linkage
function. In this paper, we address these issues by introducing the notion of a
valid hierarchy and defining a partial order over the set of valid hierarchies.
We prove the existence of a finest valid hierarchy, that is, the hierarchy that
encodes the maximum information consistent with the similarity structure of the
data set. In particular, the finest valid hierarchy is not constrained to
binary structures and, when no hierarchical relationships exist, collapses to a
star tree. We propose a simple two-step algorithm that first constructs a
binary tree via a linkage method and then prunes it to enforce validity. We
establish necessary and sufficient conditions on the linkage function under
which this procedure exactly recovers the finest valid hierarchy, and we show
that all linkage functions satisfying these conditions yield the same hierarchy
after pruning. Notably, classical linkage rules such as single, complete, and
average satisfy these conditions, whereas Ward's linkage fails to do so.
\\ ( https://arxiv.org/abs/2511.18056 ,  83kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18066
Date: Sat, 22 Nov 2025 14:01:41 GMT   (340kb)

Title: pFedBBN: A Personalized Federated Test-Time Adaptation with Balanced
 Batch Normalization for Class-Imbalanced Data
Authors: Md Akil Raihan Iftee, Syed Md. Ahnaf Hasan, Mir Sazzat Hossain,
 Rakibul Hasan Rajib, Amin Ahsan Ali, AKM Mahbubur Rahman, Sajib Mistry,
 Monowar Bhuyan
Categories: cs.LG cs.CV
Comments: 25 pages, 7 tables, 21 figures
\\
 Test-time adaptation (TTA) in federated learning (FL) is crucial for handling
unseen data distributions across clients, particularly when faced with domain
shifts and skewed class distributions. Class Imbalance (CI) remains a
fundamental challenge in FL, where rare but critical classes are often severely
underrepresented in individual client datasets. Although prior work has
addressed CI during training through reliable aggregation and local class
distribution alignment, these methods typically rely on access to labeled data
or coordination among clients, and none address class unsupervised adaptation
to dynamic domains or distribution shifts at inference time under federated CI
constraints. Revealing the failure of state-of-the-art TTA in federated client
adaptation in CI scenario, we propose pFedBBN,a personalized federated
test-time adaptation framework that employs balanced batch normalization (BBN)
during local client adaptation to mitigate prediction bias by treating all
classes equally, while also enabling client collaboration guided by BBN
similarity, ensuring that clients with similar balanced representations
reinforce each other and that adaptation remains aligned with domain-specific
characteristics. pFedBBN supports fully unsupervised local adaptation and
introduces a class-aware model aggregation strategy that enables personalized
inference without compromising privacy. It addresses both distribution shifts
and class imbalance through balanced feature normalization and domain-aware
collaboration, without requiring any labeled or raw data from clients.
Extensive experiments across diverse baselines show that pFedBBN consistently
enhances robustness and minority-class performance over state-of-the-art FL and
TTA methods.
\\ ( https://arxiv.org/abs/2511.18066 ,  340kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18084
Date: Sat, 22 Nov 2025 14:48:54 GMT   (3103kb)

Title: The Alignment Paradox of Medical Large Language Models in Infertility
 Care: Decoupling Algorithmic Improvement from Clinical Decision-making
 Quality
Authors: Dou Liu, Ying Long, Sophia Zuoqiu, Kaipeng Xie, Runze Yang, Di Liu,
 Kang Li, Yiting Lin, Hanyi Liu, Rong Yin, Tian Tang
Categories: cs.LG cs.AI
Comments: 22 pages 5 figures
\\
 Large language models (LLMs) are increasingly adopted in clinical decision
support, yet aligning them with the multifaceted reasoning pathways of
real-world medicine remains a major challenge. Using more than 8,000
infertility treatment records, we systematically evaluate four alignment
strategies: Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO),
Group Relative Policy Optimization (GRPO), and In-Context Learning (ICL)
through a dual-layer framework combining automatic benchmarks with blinded
doctor-in-the-loop assessments. GRPO achieves the highest algorithmic accuracy
across multiple decision layers, confirming the value of reinforcement-based
optimization for structured prediction tasks. However, clinicians consistently
prefer the SFT model, citing clearer reasoning processes (p = 0.035) and higher
therapeutic feasibility (p = 0.019). In blinded pairwise comparisons, SFT
attains the highest winning rate (51.2%), outperforming both GRPO (26.2%) and
even physicians' original decisions (22.7%). These results reveal an alignment
paradox: algorithmic improvements do not necessarily translate into higher
clinical trust, and may diverge from human-centered preferences. Our findings
highlight the need for alignment strategies that prioritize clinically
interpretable and practically feasible reasoning, rather than solely optimizing
decision-level accuracy.
\\ ( https://arxiv.org/abs/2511.18084 ,  3103kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18093
Date: Sat, 22 Nov 2025 15:29:18 GMT   (253kb)

Title: A New Error Temporal Difference Algorithm for Deep Reinforcement
 Learning in Microgrid Optimization
Authors: Fulong Yao, Wanqing Zhao, and Matthew Forshaw
Categories: cs.LG cs.AI
Comments: Have been accepted by 2024 9th International Conference on Renewable
 Energy and Conservation (ICREC 2024)
\\
 Predictive control approaches based on deep reinforcement learning (DRL) have
gained significant attention in microgrid energy optimization. However,
existing research often overlooks the issue of uncertainty stemming from
imperfect prediction models, which can lead to suboptimal control strategies.
This paper presents a new error temporal difference (ETD) algorithm for DRL to
address the uncertainty in predictions,aiming to improve the performance of
microgrid operations. First,a microgrid system integrated with renewable energy
sources (RES) and energy storage systems (ESS), along with its Markov decision
process (MDP), is modelled. Second, a predictive control approach based on a
deep Q network (DQN) is presented, in which a weighted average algorithm and a
new ETD algorithm are designed to quantify and address the prediction
uncertainty, respectively. Finally, simulations on a realworld US dataset
suggest that the developed ETD effectively improves the performance of DRL in
optimizing microgrid operations.
\\ ( https://arxiv.org/abs/2511.18093 ,  253kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18107
Date: Sat, 22 Nov 2025 16:16:08 GMT   (6118kb)

Title: Active Learning with Selective Time-Step Acquisition for PDEs
Authors: Yegon Kim, Hyunsu Kim, Gyeonghoon Ko, Juho Lee
Categories: cs.LG stat.ML
Journal-ref: ICML 2025
\\
 Accurately solving partial differential equations (PDEs) is critical to
understanding complex scientific and engineering phenomena, yet traditional
numerical solvers are computationally expensive. Surrogate models offer a more
efficient alternative, but their development is hindered by the cost of
generating sufficient training data from numerical solvers. In this paper, we
present a novel framework for active learning (AL) in PDE surrogate modeling
that reduces this cost. Unlike the existing AL methods for PDEs that always
acquire entire PDE trajectories, our approach strategically generates only the
most important time steps with the numerical solver, while employing the
surrogate model to approximate the remaining steps. This dramatically reduces
the cost incurred by each trajectory and thus allows the active learning
algorithm to try out a more diverse set of trajectories given the same budget.
To accommodate this novel framework, we develop an acquisition function that
estimates the utility of a set of time steps by approximating its resulting
variance reduction. We demonstrate the effectiveness of our method on several
benchmark PDEs, including the Burgers' equation, Korteweg-De Vries equation,
Kuramoto-Sivashinsky equation, the incompressible Navier-Stokes equation, and
the compressible Navier-Stokes equation. Experiments show that our approach
improves performance by large margins over the best existing method. Our method
not only reduces average error but also the 99\%, 95\%, and 50\% quantiles of
error, which is rare for an AL algorithm. All in all, our approach offers a
data-efficient solution to surrogate modeling for PDEs.
\\ ( https://arxiv.org/abs/2511.18107 ,  6118kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18138
Date: Sat, 22 Nov 2025 17:49:45 GMT   (526kb)

Title: Vulnerability-Aware Robust Multimodal Adversarial Training
Authors: Junrui Zhang, Xinyu Zhao, Jie Peng, Chenjie Wang, Jianmin Ji and
 Tianlong Chen
Categories: cs.LG cs.CR
Comments: Accepted by AAAI26
\\
 Multimodal learning has shown significant superiority on various tasks by
integrating multiple modalities. However, the interdependencies among
modalities increase the susceptibility of multimodal models to adversarial
attacks. Existing methods mainly focus on attacks on specific modalities or
indiscriminately attack all modalities. In this paper, we find that these
approaches ignore the differences between modalities in their contribution to
final robustness, resulting in suboptimal robustness performance. To bridge
this gap, we introduce Vulnerability-Aware Robust Multimodal Adversarial
Training (VARMAT), a probe-in-training adversarial training method that
improves multimodal robustness by identifying the vulnerability of each
modality. To be specific, VARMAT first explicitly quantifies the vulnerability
of each modality, grounded in a first-order approximation of the attack
objective (Probe). Then, we propose a targeted regularization term that
penalizes modalities with high vulnerability, guiding robust learning while
maintaining task accuracy (Training). We demonstrate the enhanced robustness of
our method across multiple multimodal datasets involving diverse modalities.
Finally, we achieve {12.73%, 22.21%, 11.19%} robustness improvement on three
multimodal datasets, revealing a significant blind spot in multimodal
adversarial training.
\\ ( https://arxiv.org/abs/2511.18138 ,  526kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18150
Date: Sat, 22 Nov 2025 18:34:32 GMT   (13kb)

Title: Graph Neural Networks vs Convolutional Neural Networks for Graph
 Domination Number Prediction
Authors: Randy Davila and Beyzanur Ispir
Categories: cs.LG cs.AI math.CO
\\
 We investigate machine learning approaches to approximating the
\emph{domination number} of graphs, the minimum size of a dominating set. Exact
computation of this parameter is NP-hard, restricting classical methods to
small instances. We compare two neural paradigms: Convolutional Neural Networks
(CNNs), which operate on adjacency matrix representations, and Graph Neural
Networks (GNNs), which learn directly from graph structure through message
passing. Across 2,000 random graphs with up to 64 vertices, GNNs achieve
markedly higher accuracy ($R^2=0.987$, MAE $=0.372$) than CNNs ($R^2=0.955$,
MAE $=0.500$). Both models offer substantial speedups over exact solvers, with
GNNs delivering more than $200\times$ acceleration while retaining near-perfect
fidelity. Our results position GNNs as a practical surrogate for combinatorial
graph invariants, with implications for scalable graph optimization and
mathematical discovery.
\\ ( https://arxiv.org/abs/2511.18150 ,  13kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18157
Date: Sat, 22 Nov 2025 18:52:34 GMT   (5474kb)

Title: scipy.spatial.transform: Differentiable Framework-Agnostic 3D
 Transformations in Python
Authors: Martin Schuck, Alexander von Rohr, Angela P. Schoellig
Categories: cs.LG cs.RO
Comments: Accepted as oral at the 1st Workshop on Differentiable Systems and
 Scientific Machine Learning @ EurIPS 2025
\\
 Three-dimensional rigid-body transforms, i.e. rotations and translations, are
central to modern differentiable machine learning pipelines in robotics,
vision, and simulation. However, numerically robust and mathematically correct
implementations, particularly on SO(3), are error-prone due to issues such as
axis conventions, normalizations, composition consistency and subtle errors
that only appear in edge cases. SciPy's spatial.transform module is a
rigorously tested Python implementation. However, it historically only
supported NumPy, limiting adoption in GPU-accelerated and autodiff-based
workflows. We present a complete overhaul of SciPy's spatial.transform
functionality that makes it compatible with any array library implementing the
Python array API, including JAX, PyTorch, and CuPy. The revised implementation
preserves the established SciPy interface while enabling GPU/TPU execution, JIT
compilation, vectorized batching, and differentiation via native autodiff of
the chosen backend. We demonstrate how this foundation supports differentiable
scientific computing through two case studies: (i) scalability of 3D transforms
and rotations and (ii) a JAX drone simulation that leverages SciPy's Rotation
for accurate integration of rotational dynamics. Our contributions have been
merged into SciPy main and will ship in the next release, providing a
framework-agnostic, production-grade basis for 3D spatial math in
differentiable systems and ML.
\\ ( https://arxiv.org/abs/2511.18157 ,  5474kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18158
Date: Sat, 22 Nov 2025 18:56:56 GMT   (681kb)

Title: LocaGen: Low-Overhead Indoor Localization Through Spatial Augmentation
Authors: Abdelrahman Abdelmotlb, Abdallah Taman, Sherif Mostafa, Moustafa
 Youssef
Categories: cs.LG cs.NI
Comments: Accepted at GeoIndustry @ ACM SIGSPATIAL 2025 (The 4th International
 Workshop on Spatial Big Data and AI for Industrial Applications)
\\
 Indoor localization systems commonly rely on fingerprinting, which requires
extensive survey efforts to obtain location-tagged signal data, limiting their
real-world deployability. Recent approaches that attempt to reduce this
overhead either suffer from low representation ability, mode collapse issues,
or require the effort of collecting data at all target locations. We present
LocaGen, a novel spatial augmentation framework that significantly reduces
fingerprinting overhead by generating high-quality synthetic data at completely
unseen locations. LocaGen leverages a conditional diffusion model guided by a
novel spatially aware optimization strategy to synthesize realistic
fingerprints at unseen locations using only a subset of seen locations. To
further improve our diffusion model performance, LocaGen augments seen location
data based on domain-specific heuristics and strategically selects the seen and
unseen locations using a novel density-based approach that ensures robust
coverage. Our extensive evaluation on a real-world WiFi fingerprinting dataset
shows that LocaGen maintains the same localization accuracy even with 30% of
the locations unseen and achieves up to 28% improvement in accuracy over
state-of-the-art augmentation methods.
\\ ( https://arxiv.org/abs/2511.18158 ,  681kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18159
Date: Sat, 22 Nov 2025 19:04:47 GMT   (2633kb)

Title: Bringing Stability to Diffusion: Decomposing and Reducing Variance of
 Training Masked Diffusion Models
Authors: Mengni Jia, Mengyu Zhou, Yihao Liu, Xiaoxi Jiang, Guanjun Jiang
Categories: cs.LG
\\
 Masked diffusion models (MDMs) are a promising alternative to autoregressive
models (ARMs), but they suffer from inherently much higher training variance.
High variance leads to noisier gradient estimates and unstable optimization, so
even equally strong pretrained MDMs and ARMs that are competitive at
initialization often diverge after task-specific training, with MDMs falling
far behind. There has been no theoretical explanation or systematic solution.
We derive the first decomposition of MDM training variance into three sources:
(A) masking pattern noise, (B) masking rate noise, and (C) data noise, while
ARMs are only affected by (C). This explains the fundamental training gap.
Building on this foundation, we design six variance-reduction methods,
including two core methods: (1) P-POTS, a Pareto-optimal t sampler that
minimizes training variance by sampling harder t values more often with
appropriately smaller update steps, and (2) MIRROR, which uses negatively
correlated samples to reduce (A). Experiments show that compared to standard
MDM training, our methods improve accuracy by 7-8% on complex reasoning tasks,
while simultaneously reducing run-to-run variability to near ARM levels,
substantially narrowing the gap with strong ARM baselines; in most settings,
even the best baseline runs remain below the worst run of our method.
\\ ( https://arxiv.org/abs/2511.18159 ,  2633kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18178
Date: Sat, 22 Nov 2025 20:10:38 GMT   (12065kb)

Title: Bayesian Calibration of Engine-out NOx Models for Engine-to-Engine
 Transferability
Authors: Shrenik Zinage, Peter Meckl, Ilias Bilionis
Categories: cs.LG
\\
 Accurate prediction of engine-out NOx is essential for meeting stringent
emissions regulations and optimizing engine performance. Traditional approaches
rely on models trained on data from a small number of engines, which can be
insufficient in generalizing across an entire population of engines due to
sensor biases and variations in input conditions. In real world applications,
these models require tuning or calibration to maintain acceptable error
tolerance when applied to other engines. This highlights the need for models
that can adapt with minimal adjustments to accommodate engine-to-engine
variability and sensor discrepancies. While previous studies have explored
machine learning methods for predicting engine-out NOx, these approaches often
fail to generalize reliably across different engines and operating
environments. To address these issues, we propose a Bayesian calibration
framework that combines Gaussian processes with approximate Bayesian
computation to infer and correct sensor biases. Starting with a pre-trained
model developed using nominal engine data, our method identifies engine
specific sensor biases and recalibrates predictions accordingly. By
incorporating these inferred biases, our approach generates posterior
predictive distributions for engine-out NOx on unseen test data, achieving high
accuracy without retraining the model. Our results demonstrate that this
transferable modeling approach significantly improves the accuracy of
predictions compared to conventional non-adaptive GP models, effectively
addressing engine-to-engine variability and improving model generalizability.
\\ ( https://arxiv.org/abs/2511.18178 ,  12065kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18181
Date: Sat, 22 Nov 2025 20:24:51 GMT   (292kb)

Title: MOMA-AC: A preference-driven actor-critic framework for continuous
 multi-objective multi-agent reinforcement learning
Authors: Adam Callaghan, Karl Mason, Patrick Mannion
Categories: cs.LG cs.AI
Comments: 23 pages, 5 figures
ACM-class: I.2.9; I.2.11
Journal-ref: Neurocomputing, Volume 664, 2026, 132032, ISSN 0925-2312
DOI: 10.1016/j.neucom.2025.132032.
\\
 This paper addresses a critical gap in Multi-Objective Multi-Agent
Reinforcement Learning (MOMARL) by introducing the first dedicated inner-loop
actor-critic framework for continuous state and action spaces: Multi-Objective
Multi-Agent Actor-Critic (MOMA-AC). Building on single-objective, single-agent
algorithms, we instantiate this framework with Twin Delayed Deep Deterministic
Policy Gradient (TD3) and Deep Deterministic Policy Gradient (DDPG), yielding
MOMA-TD3 and MOMA-DDPG. The framework combines a multi-headed actor network, a
centralised critic, and an objective preference-conditioning architecture,
enabling a single neural network to encode the Pareto front of optimal
trade-off policies for all agents across conflicting objectives in a continuous
MOMARL setting. We also outline a natural test suite for continuous MOMARL by
combining a pre-existing multi-agent single-objective physics simulator with
its multi-objective single-agent counterpart. Evaluating cooperative locomotion
tasks in this suite, we show that our framework achieves statistically
significant improvements in expected utility and hypervolume relative to
outer-loop and independent training baselines, while demonstrating stable
scalability as the number of agents increases. These results establish our
framework as a foundational step towards robust, scalable multi-objective
policy learning in continuous multi-agent domains.
\\ ( https://arxiv.org/abs/2511.18181 ,  292kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18191
Date: Sat, 22 Nov 2025 21:04:57 GMT   (49kb)

Title: Accelerating Time Series Foundation Models with Speculative Decoding
Authors: Pranav Subbaraman, Fang Sun, Yue Yao, Huacong Tang, Xiao Luo, Yizhou
 Sun
Categories: cs.LG
Comments: 14 pages, 7 figures
\\
 Modern web applications--from real-time content recommendation and dynamic
pricing to CDN optimization--increasingly rely on time-series forecasting to
deliver personalized experiences to billions of users. Large-scale
Transformer-based models have achieved state-of-the-art performance in
time-series forecasting but suffer from high computational costs, limiting
their deployment in latency-sensitive web applications. To address this
challenge, we propose a general inference acceleration framework that adapts
speculative decoding to autoregressive time-series models. Our approach employs
a smaller "draft" model to propose future time-series patches, which are then
verified in parallel by a larger "target" model, reducing the number of
sequential forward passes required. We address key technical challenges in
adapting this technique from discrete language tokens to continuous time-series
distributions, including the design of acceptance criteria for multivariate
Gaussian patches and practical variants that balance efficiency with accuracy.
Through experiments on time series forecasting benchmarks relevant to web
applications, we demonstrate significant inference speedups while maintaining
competitive accuracy. The framework requires no architectural modifications to
existing foundation models, making it immediately applicable to accelerate
deployed time-series forecasting systems. Our implementation can be found at
https://github.com/PranavSubbaraman/STRIDE
\\ ( https://arxiv.org/abs/2511.18191 ,  49kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18214
Date: Sat, 22 Nov 2025 23:13:04 GMT   (1662kb)

Title: Deep Gaussian Process Proximal Policy Optimization
Authors: Matthijs van der Lende, Juan Cardenas-Cartagena
Categories: cs.LG
\\
 Uncertainty estimation for Reinforcement Learning (RL) is a critical
component in control tasks where agents must balance safe exploration and
efficient learning. While deep neural networks have enabled breakthroughs in
RL, they often lack calibrated uncertainty estimates. We introduce Deep
Gaussian Process Proximal Policy Optimization (GPPO), a scalable, model-free
actor-critic algorithm that leverages Deep Gaussian Processes (DGPs) to
approximate both the policy and value function. GPPO maintains competitive
performance with respect to Proximal Policy Optimization on standard
high-dimensional continuous control benchmarks while providing well-calibrated
uncertainty estimates that can inform safer and more effective exploration.
\\ ( https://arxiv.org/abs/2511.18214 ,  1662kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18225
Date: Sun, 23 Nov 2025 00:04:03 GMT   (1098kb)

Title: Adaptive Conformal Prediction for Quantum Machine Learning
Authors: Douglas Spencer, Samual Nicholls, Michele Caprio
Categories: cs.LG stat.ML stat.OT
Comments: 26 pages, 5 figures
\\
 Quantum machine learning seeks to leverage quantum computers to improve upon
classical machine learning algorithms. Currently, robust uncertainty
quantification methods remain underdeveloped in the quantum domain, despite the
critical need for reliable and trustworthy predictions. Recent work has
introduced quantum conformal prediction, a framework that produces prediction
sets that are guaranteed to contain the true outcome with user-specified
probability. In this work, we formalise how the time-varying noise inherent in
quantum processors can undermine conformal guarantees, even when calibration
and test data are exchangeable. To address this challenge, we draw on Adaptive
Conformal Inference, a method which maintains validity over time via repeated
recalibration. We introduce Adaptive Quantum Conformal Prediction (AQCP), an
algorithm which preserves asymptotic average coverage guarantees under
arbitrary hardware noise conditions. Empirical studies on an IBM quantum
processor demonstrate that AQCP achieves target coverage levels and exhibits
greater stability than quantum conformal prediction.
\\ ( https://arxiv.org/abs/2511.18225 ,  1098kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18247
Date: Sun, 23 Nov 2025 02:23:09 GMT   (18kb)

Title: Tail Distribution of Regret in Optimistic Reinforcement Learning
Authors: Sajad Khodadadian, Mehrdad Moharrami
Categories: cs.LG math.OC
Comments: 18 pages, 0 figures
\\
 We derive instance-dependent tail bounds for the regret of optimism-based
reinforcement learning in finite-horizon tabular Markov decision processes with
unknown transition dynamics. Focusing on a UCBVI-type algorithm, we
characterize the tail distribution of the cumulative regret $R_K$ over $K$
episodes, rather than only its expectation or a single high-probability
quantile. We analyze two natural exploration-bonus schedules: (i) a
$K$-dependent scheme that explicitly incorporates the total number of episodes
$K$, and (ii) a $K$-independent scheme that depends only on the current episode
index. For both settings, we obtain an upper bound on $\Pr(R_K \ge x)$ that
exhibits a distinctive two-regime structure: a sub-Gaussian tail starting from
an instance-dependent scale $m_K$ up to a transition threshold, followed by a
sub-Weibull tail beyond that point. We further derive corresponding
instance-dependent bounds on the expected regret $\mathbb{E}[R_K]$. The
proposed algorithm depends on a tuning parameter $\alpha$, which balances the
expected regret and the range over which the regret exhibits a sub-Gaussian
tail. To the best of our knowledge, our results provide one of the first
comprehensive tail-regret guarantees for a standard optimistic algorithm in
episodic reinforcement learning.
\\ ( https://arxiv.org/abs/2511.18247 ,  18kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18248
Date: Sun, 23 Nov 2025 02:24:20 GMT   (688kb)

Title: Coherent Multi-Agent Trajectory Forecasting in Team Sports with
 CausalTraj
Authors: Wei Zhen Teoh
Categories: cs.LG cs.CV
Comments: 9 pages, 3 figures, accepted to the AI4TS Workshop at AAAI 2026
\\
 Jointly forecasting trajectories of multiple interacting agents is a core
challenge in sports analytics and other domains involving complex group
dynamics. Accurate prediction enables realistic simulation and strategic
understanding of gameplay evolution. Most existing models are evaluated solely
on per-agent accuracy metrics (minADE, minFDE), which assess each agent
independently on its best-of-k prediction. However these metrics overlook
whether the model learns which predicted trajectories can jointly form a
plausible multi-agent future. Many state-of-the-art models are designed and
optimized primarily based on these metrics. As a result, they may underperform
on joint predictions and also fail to generate coherent, interpretable
multi-agent scenarios in team sports. We propose CausalTraj, a temporally
causal, likelihood-based model that is built to generate jointly probable
multi-agent trajectory forecasts. To better assess collective modeling
capability, we emphasize joint metrics (minJADE, minJFDE) that measure joint
accuracy across agents within the best generated scenario sample. Evaluated on
the NBA SportVU, Basketball-U, and Football-U datasets, CausalTraj achieves
competitive per-agent accuracy and the best recorded results on joint metrics,
while yielding qualitatively coherent and realistic gameplay evolutions.
\\ ( https://arxiv.org/abs/2511.18248 ,  688kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18260
Date: Sun, 23 Nov 2025 03:22:11 GMT   (7964kb)

Title: Reduced-Basis Deep Operator Learning for Parametric PDEs with
 Independently Varying Boundary and Source Data
Authors: Yueqi Wang, Guang Lin
Categories: cs.LG cs.NA math.NA
\\
 Parametric PDEs power modern simulation, design, and digital-twin systems,
yet their many-query workloads still hinge on repeatedly solving large
finite-element systems. Existing operator-learning approaches accelerate this
process but often rely on opaque learned trunks, require extensive labeled
data, or break down when boundary and source data vary independently from
physical parameters. We introduce RB-DeepONet, a hybrid operator-learning
framework that fuses reduced-basis (RB) numerical structure with the
branch-trunk architecture of DeepONet. The trunk is fixed to a rigorously
constructed RB space generated offline via Greedy selection, granting physical
interpretability, stability, and certified error control. The branch network
predicts only RB coefficients and is trained label-free using a projected
variational residual that targets the RB-Galerkin solution. For problems with
independently varying loads or boundary conditions, we develop boundary and
source modal encodings that compress exogenous data into low-dimensional
coordinates while preserving accuracy. Combined with affine or empirical
interpolation decompositions, RB-DeepONet achieves a strict offline-online
split: all heavy lifting occurs offline, and online evaluation scales only with
the RB dimension rather than the full mesh. We provide convergence guarantees
separating RB approximation error from statistical learning error, and
numerical experiments show that RB-DeepONet attains accuracy competitive with
intrusive RB-Galerkin, POD-DeepONet, and FEONet while using dramatically fewer
trainable parameters and achieving significant speedups. This establishes
RB-DeepONet as an efficient, stable, and interpretable operator learner for
large-scale parametric PDEs.
\\ ( https://arxiv.org/abs/2511.18260 ,  7964kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18269
Date: Sun, 23 Nov 2025 03:38:41 GMT   (711kb)

Title: A Fair OR-ML Framework for Resource Substitution in Large-Scale Networks
Authors: Ved Mohan, El Mehdi Er Raqabi, Pascal Van Hentenryck
Categories: cs.LG math.OC
\\
 Ensuring that the right resource is available at the right location and time
remains a major challenge for organizations operating large-scale logistics
networks. The challenge comes from uneven demand patterns and the resulting
asymmetric flow of resources across the arcs, which create persistent
imbalances at the network nodes. Resource substitution among multiple,
potentially composite and interchangeable, resource types is a cost-effective
way to mitigate these imbalances. This leads to the resource substitution
problem, which aims at determining the minimum number of resource substitutions
from an initial assignment to minimize the overall network imbalance. In
decentralized settings, achieving globally coordinated solutions becomes even
more difficult. When substitution entails costs, effective prescriptions must
also incorporate fairness and account for the individual preferences of
schedulers. This paper presents a generic framework that combines operations
research (OR) and machine learning (ML) to enable fair resource substitution in
large networks. The OR component models and solves the resource substitution
problem under a fairness lens. The ML component leverages historical data to
learn schedulers' preferences, guide intelligent exploration of the decision
space, and enhance computational efficiency by dynamically selecting the
top-$\kappa$ resources for each arc in the network. The framework produces a
portfolio of high-quality solutions from which schedulers can select
satisfactory trade-offs. The proposed framework is applied to the network of
one of the largest package delivery companies in the world, which serves as the
primary motivation for this research. Computational results demonstrate
substantial improvements over state-of-the-art methods, including an 80%
reduction in model size and a 90% decrease in execution time while preserving
optimality.
\\ ( https://arxiv.org/abs/2511.18269 ,  711kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18278
Date: Sun, 23 Nov 2025 04:07:16 GMT   (2138kb)

Title: From Tables to Signals: Revealing Spectral Adaptivity in TabPFN
Authors: Jianqiao Zheng, Cameron Gordon, Yiping Ji, Hemanth Saratchandran,
 Simon Lucey
Categories: cs.LG cs.CV
\\
 Task-agnostic tabular foundation models such as TabPFN have achieved
impressive performance on tabular learning tasks, yet the origins of their
inductive biases remain poorly understood. In this work, we study TabPFN
through the lens of signal reconstruction and provide the first frequency-based
analysis of its in-context learning behavior. We show that TabPFN possesses a
broader effective frequency capacity than standard ReLU-MLPs, even without
hyperparameter tuning. Moreover, unlike MLPs whose spectra evolve primarily
over training epochs, we find that TabPFN's spectral capacity adapts directly
to the number of samples provided in-context, a phenomenon we term Spectral
Adaptivity. We further demonstrate that positional encoding modulates TabPFN's
frequency response, mirroring classical results in implicit neural
representations. Finally, we show that these properties enable TabPFN to
perform training-free and hyperparameter-free image denoising, illustrating its
potential as a task-agnostic implicit model. Our analysis provides new insight
into the structure and inductive biases of tabular foundation models and
highlights their promise for broader signal reconstruction tasks.
\\ ( https://arxiv.org/abs/2511.18278 ,  2138kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18287
Date: Sun, 23 Nov 2025 04:43:27 GMT   (36294kb)

Title: TRIDENT: A Trimodal Cascade Generative Framework for Drug and
 RNA-Conditioned Cellular Morphology Synthesis
Authors: Rui Peng, Ziru Liu, Lingyuan Ye, Yuxing Lu, Boxin Shi, Jinzhuo Wang
Categories: cs.LG cs.CV q-bio.QM
\\
 Accurately modeling the relationship between perturbations, transcriptional
responses, and phenotypic changes is essential for building an AI Virtual Cell
(AIVC). However, existing methods typically constrained to modeling direct
associations, such as Perturbation $\rightarrow$ RNA or Perturbation
$\rightarrow$ Morphology, overlook the crucial causal link from RNA to
morphology. To bridge this gap, we propose TRIDENT, a cascade generative
framework that synthesizes realistic cellular morphology by conditioning on
both the perturbation and the corresponding gene expression profile. To train
and evaluate this task, we construct MorphoGene, a new dataset pairing L1000
gene expression with Cell Painting images for 98 compounds. TRIDENT
significantly outperforms state-of-the-art approaches, achieving up to 7-fold
improvement with strong generalization to unseen compounds. In a case study on
docetaxel, we validate that RNA-guided synthesis accurately produces the
corresponding phenotype. An ablation study further confirms that this RNA
conditioning is essential for the model's high fidelity. By explicitly modeling
transcriptome-phenome mapping, TRIDENT provides a powerful in silico tool and
moves us closer to a predictive virtual cell.
\\ ( https://arxiv.org/abs/2511.18287 ,  36294kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18291
Date: Sun, 23 Nov 2025 05:09:32 GMT   (493kb)

Title: ADF-LoRA: Alternating Low-Rank Aggregation for Decentralized Federated
 Fine-Tuning
Authors: Xiaoyu Wang, Xiaotian Li, Zhixiang Zhou, Chen Li, and Yong Liu
Categories: cs.LG cs.DC
Comments: 10 Pages
ACM-class: I.2.11; I.2.6
\\
 This paper revisits alternating low-rank updates for federated fine-tuning
and examines their behavior in decentralized federated learning (DFL). While
alternating the LoRA matrices has been shown to stabilize aggregation in
centralized FL, extending this mechanism to decentralized, peer-to-peer
communication introduces new challenges due to phase-state mismatch and
block-wise divergence across clients. We introduce ADF-LoRA, which synchronizes
the update of only one low-rank matrix per round and mixes both matrices to
maintain more consistent parameter states under decentralized propagation. This
design preserves the cross-term suppression effect of alternating updates while
improving stability in serverless topologies. We provide a convergence analysis
under standard smoothness assumptions and evaluate ADF-LoRA on multiple GLUE
tasks. Experiments show that ADF-LoRA achieves faster and smoother convergence
and delivers the highest average accuracy across tasks, outperforming existing
LoRA variants in decentralized FL by a consistent margin.
\\ ( https://arxiv.org/abs/2511.18291 ,  493kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18294
Date: Sun, 23 Nov 2025 05:22:27 GMT   (1214kb)

Title: MultiDiffNet: A Multi-Objective Diffusion Framework for Generalizable
 Brain Decoding
Authors: Mengchun Zhang, Kateryna Shapovalenko, Yucheng Shao, Eddie Guo,
 Parusha Pradhan
Categories: cs.LG cs.AI cs.HC q-bio.NC
\\
 Neural decoding from electroencephalography (EEG) remains fundamentally
limited by poor generalization to unseen subjects, driven by high inter-subject
variability and the lack of large-scale datasets to model it effectively.
Existing methods often rely on synthetic subject generation or simplistic data
augmentation, but these strategies fail to scale or generalize reliably. We
introduce \textit{MultiDiffNet}, a diffusion-based framework that bypasses
generative augmentation entirely by learning a compact latent space optimized
for multiple objectives. We decode directly from this space and achieve
state-of-the-art generalization across various neural decoding tasks using
subject and session disjoint evaluation. We also curate and release a unified
benchmark suite spanning four EEG decoding tasks of increasing complexity
(SSVEP, Motor Imagery, P300, and Imagined Speech) and an evaluation protocol
that addresses inconsistent split practices in prior EEG research. Finally, we
develop a statistical reporting framework tailored for low-trial EEG settings.
Our work provides a reproducible and open-source foundation for
subject-agnostic EEG decoding in real-world BCI systems.
\\ ( https://arxiv.org/abs/2511.18294 ,  1214kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18297
Date: Sun, 23 Nov 2025 05:32:56 GMT   (1228kb)

Title: GROOT: Graph Edge Re-growth and Partitioning for the Verification of
 Large Designs in Logic Synthesis
Authors: Kiran Thorat, Hongwu Peng, Yuebo Luo, Xi Xie, Shaoyi Huang, Amit
 Hasan, Jiahui Zhao, Yingjie Li, Zhijie Shi, Cunxi Yu, Caiwen Ding
Categories: cs.LG
\\
 Traditional verification methods in chip design are highly time-consuming and
computationally demanding, especially for large scale circuits. Graph neural
networks (GNNs) have gained popularity as a potential solution to improve
verification efficiency. However, there lacks a joint framework that considers
all chip design domain knowledge, graph theory, and GPU kernel designs. To
address this challenge, we introduce GROOT, an algorithm and system co-design
framework that contains chip design domain knowledge and redesigned GPU
kernels, to improve verification efficiency. More specifically, we create node
features utilizing the circuit node types and the polarity of the connections
between the input edges to nodes in And-Inverter Graphs (AIGs). We utilize a
graph partitioning algorithm to divide the large graphs into smaller sub-graphs
for fast GPU processing and develop a graph edge re-growth algorithm to recover
verification accuracy. We carefully profile the EDA graph workloads and observe
the uniqueness of their polarized distribution of high degree (HD) nodes and
low degree (LD) nodes. We redesign two GPU kernels (HD-kernel and LD-kernel),
to fit the EDA graph learning workload on a single GPU. We compare the results
with state-of-the-art (SOTA) methods: GAMORA, a GNN-based approach, and the
traditional ABC framework. Results show that GROOT achieves a significant
reduction in memory footprint (59.38 %), with high accuracy (99.96%) for a very
large CSA multiplier, i.e. 1,024 bits with a batch size of 16, which consists
of 134,103,040 nodes and 268,140,544 edges. We compare GROOT with GPU-based GPU
Kernel designs SOTAs such as cuSPARSE, MergePath-SpMM, and GNNAdvisor. We
achieve up to 1.104x, 5.796x, and 1.469x improvement in runtime, respectively.
\\ ( https://arxiv.org/abs/2511.18297 ,  1228kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18303
Date: Sun, 23 Nov 2025 05:57:42 GMT   (45330kb)

Title: Hierarchical Deep Research with Local-Web RAG: Toward Automated
 System-Level Materials Discovery
Authors: Rui Ding, Rodrigo Pires Ferreira, Yuxin Chen, Junhong Chen
Categories: cs.LG
Comments: A preliminary version appeared in The AI for Accelerated Materials
 Discovery (AI4Mat) Workshop at NeurIPS 2025
\\
 We present a long-horizon, hierarchical deep research (DR) agent designed for
complex materials and device discovery problems that exceed the scope of
existing Machine Learning (ML) surrogates and closed-source commercial agents.
Our framework instantiates a locally deployable DR instance that integrates
local retrieval-augmented generation with large language model reasoners,
enhanced by a Deep Tree of Research (DToR) mechanism that adaptively expands
and prunes research branches to maximize coverage, depth, and coherence. We
systematically evaluate across 27 nanomaterials/device topics using a large
language model (LLM)-as-judge rubric with five web-enabled state-of-the-art
models as jurors. In addition, we conduct dry-lab validations on five
representative tasks, where human experts use domain simulations (e.g., density
functional theory, DFT) to verify whether DR-agent proposals are actionable.
Results show that our DR agent produces reports with quality comparable to--and
often exceeding--those of commercial systems
(ChatGPT-5-thinking/o3/o4-mini-high Deep Research) at a substantially lower
cost, while enabling on-prem integration with local data and tools.
\\ ( https://arxiv.org/abs/2511.18303 ,  45330kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18312
Date: Sun, 23 Nov 2025 06:48:03 GMT   (4740kb)

Title: DiM-TS: Bridge the Gap between Selective State Space Models and Time
 Series for Generative Modeling
Authors: Zihao Yao, Jiankai Zuo, Yaying Zhang
Categories: cs.LG
\\
 Time series data plays a pivotal role in a wide variety of fields but faces
challenges related to privacy concerns. Recently, synthesizing data via
diffusion models is viewed as a promising solution. However, existing methods
still struggle to capture long-range temporal dependencies and complex channel
interrelations. In this research, we aim to utilize the sequence modeling
capability of a State Space Model called Mamba to extend its applicability to
time series data generation. We firstly analyze the core limitations in State
Space Model, namely the lack of consideration for correlated temporal lag and
channel permutation. Building upon the insight, we propose Lag Fusion Mamba and
Permutation Scanning Mamba, which enhance the model's ability to discern
significant patterns during the denoising process. Theoretical analysis reveals
that both variants exhibit a unified matrix multiplication framework with the
original Mamba, offering a deeper understanding of our method. Finally, we
integrate two variants and introduce Diffusion Mamba for Time Series (DiM-TS),
a high-quality time series generation model that better preserves the temporal
periodicity and inter-channel correlations. Comprehensive experiments on public
datasets demonstrate the superiority of DiM-TS in generating realistic time
series while preserving diverse properties of data.
\\ ( https://arxiv.org/abs/2511.18312 ,  4740kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18314
Date: Sun, 23 Nov 2025 06:53:43 GMT   (38205kb)

Title: AnyExperts: On-Demand Expert Allocation for Multimodal Language Models
 with Mixture of Expert
Authors: Yuting Gao, Wang Lan, Hengyuan Zhao, Linjiang Huang, Si Liu, Qingpei
 Guo
Categories: cs.LG cs.AI
\\
 Multimodal Mixture-of-Experts (MoE) models offer a promising path toward
scalable and efficient large vision-language systems. However, existing
approaches rely on rigid routing strategies (typically activating a fixed
number of experts per token) ignoring the inherent heterogeneity in semantic
importance across modalities. This leads to suboptimal compute allocation,
where redundant tokens consume as many resources as critical ones. To address
this, we propose AnyExperts, a novel on-demand, budget-aware dynamic routing
framework that allocates a variable total number of expert slots per token
based on its semantic importance. Crucially, to prevent uncontrolled compute
growth, the total slots per token are constrained within a fixed range, and
each slot is filled by either a real expert or a virtual expert, with the
virtual share capped at a small maximum (e.g., 20%). The model then adaptively
balances the real-to-virtual ratio per token, assigning more real experts to
semantically rich regions and relying more on virtual experts for redundant
content. Evaluated across diverse tasks in visual understanding, audio
understanding, and NLP understanding, AnyExperts improves performance under the
same compute budget. Notably, on general image/video tasks, it achieves
comparable accuracy with 40% fewer real expert activations; on text-dense tasks
(OCR and NLP), it maintains performance while reducing real expert usage by
10%. These results demonstrate that fine-grained, importance-driven expert
allocation significantly enhances both the efficiency and effectiveness of
multimodal MoE models.
\\ ( https://arxiv.org/abs/2511.18314 ,  38205kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18331
Date: Sun, 23 Nov 2025 08:10:33 GMT   (896kb)

Title: DynamiX: Dynamic Resource eXploration for Personalized
 Ad-Recommendations
Authors: Sohini Roychowdhury, Adam Holeman, Mohammad Amin, Feng Wei, Bhaskar
 Mehta, Srihari Reddy
Categories: cs.LG cs.SE
Comments: 9 pages, 3 Tables, 5 images. https://openreview.net/pdf?id=oglD54lvcB
Journal-ref: Neurips 2025 Workshop, Reliable ML from Unreliable Data
\\
 For online ad-recommendation systems, processing complete user-ad-engagement
histories is both computationally intensive and noise-prone. We introduce
Dynamix, a scalable, personalized sequence exploration framework that optimizes
event history processing using maximum relevance principles and self-supervised
learning through Event Based Features (EBFs). Dynamix categorizes
users-engagements at session and surface-levels by leveraging correlations
between dwell-times and ad-conversion events. This enables targeted,
event-level feature removal and selective feature boosting for certain
user-segments, thereby yielding training and inference efficiency wins without
sacrificing engaging ad-prediction accuracy. While, dynamic resource removal
increases training and inference throughput by 1.15% and 1.8%, respectively,
dynamic feature boosting provides 0.033 NE gains while boosting inference QPS
by 4.2% over baseline models. These results demonstrate that Dynamix achieves
significant cost efficiency and performance improvements in online
user-sequence based recommendation models. Self-supervised user-segmentation
and resource exploration can further boost complex feature selection strategies
while optimizing for workflow and compute resources.
\\ ( https://arxiv.org/abs/2511.18331 ,  896kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18334
Date: Sun, 23 Nov 2025 08:16:17 GMT   (10317kb)

Title: Clinician-in-the-Loop Smart Home System to Detect Urinary Tract
 Infection Flare-Ups via Uncertainty-Aware Decision Support
Authors: Chibuike E. Ugwu, Roschelle Fritz, Diane J. Cook, Janardhan Rao Doppa
Categories: cs.LG cs.AI
Comments: Accepted for publication at IAAI-26 / AAAI-26
\\
 Urinary tract infection (UTI) flare-ups pose a significant health risk for
older adults with chronic conditions. These infections often go unnoticed until
they become severe, making early detection through innovative smart home
technologies crucial. Traditional machine learning (ML) approaches relying on
simple binary classification for UTI detection offer limited utility to nurses
and practitioners as they lack insight into prediction uncertainty, hindering
informed clinical decision-making. This paper presents a clinician-in-the-loop
(CIL) smart home system that leverages ambient sensor data to extract
meaningful behavioral markers, train robust predictive ML models, and calibrate
them to enable uncertainty-aware decision support. The system incorporates a
statistically valid uncertainty quantification method called
Conformal-Calibrated Interval (CCI), which quantifies uncertainty and abstains
from making predictions ("I don't know") when the ML model's confidence is low.
Evaluated on real-world data from eight smart homes, our method outperforms
baseline methods in recall and other classification metrics while maintaining
the lowest abstention proportion and interval width. A survey of 42 nurses
confirms that our system's outputs are valuable for guiding clinical
decision-making, underscoring their practical utility in improving informed
decisions and effectively managing UTIs and other condition flare-ups in older
adults.
\\ ( https://arxiv.org/abs/2511.18334 ,  10317kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18336
Date: Sun, 23 Nov 2025 08:22:20 GMT   (5946kb)

Title: Auxiliary Gene Learning: Spatial Gene Expression Estimation by Auxiliary
 Gene Selection
Authors: Kaito Shiku, Kazuya Nishimura, Shinnosuke Matsuo, Yasuhiro Kojima,
 Ryoma Bise
Categories: cs.LG cs.CV q-bio.GN
Comments: Accepted to Association for the Advancement of Artificial
 Intelligence (AAAI) 2026
\\
 Spatial transcriptomics (ST) is a novel technology that enables the
observation of gene expression at the resolution of individual spots within
pathological tissues. ST quantifies the expression of tens of thousands of
genes in a tissue section; however, heavy observational noise is often
introduced during measurement. In prior studies, to ensure meaningful
assessment, both training and evaluation have been restricted to only a small
subset of highly variable genes, and genes outside this subset have also been
excluded from the training process. However, since there are likely
co-expression relationships between genes, low-expression genes may still
contribute to the estimation of the evaluation target. In this paper, we
propose $Auxiliary \ Gene \ Learning$ (AGL) that utilizes the benefit of the
ignored genes by reformulating their expression estimation as auxiliary tasks
and training them jointly with the primary tasks. To effectively leverage
auxiliary genes, we must select a subset of auxiliary genes that positively
influence the prediction of the target genes. However, this is a challenging
optimization problem due to the vast number of possible combinations. To
overcome this challenge, we propose Prior-Knowledge-Based Differentiable
Top-$k$ Gene Selection via Bi-level Optimization (DkGSB), a method that ranks
genes by leveraging prior knowledge and relaxes the combinatorial selection
problem into a differentiable top-$k$ selection problem. The experiments
confirm the effectiveness of incorporating auxiliary genes and show that the
proposed method outperforms conventional auxiliary task learning approaches.
\\ ( https://arxiv.org/abs/2511.18336 ,  5946kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18394
Date: Sun, 23 Nov 2025 10:41:19 GMT   (200kb)

Title: Future Is Unevenly Distributed: Forecasting Ability of LLMs Depends on
 What We're Asking
Authors: Chinmay Karkar, Paras Chopra
Categories: cs.LG
\\
 Large Language Models (LLMs) demonstrate partial forecasting competence
across social, political, and economic events. Yet, their predictive ability
varies sharply with domain structure and prompt framing. We investigate how
forecasting performance varies with different model families on real-world
questions about events that happened beyond the model cutoff date. We analyze
how context, question type, and external knowledge affect accuracy and
calibration, and how adding factual news context modifies belief formation and
failure modes. Our results show that forecasting ability is highly variable as
it depends on what, and how, we ask.
\\ ( https://arxiv.org/abs/2511.18394 ,  200kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18404
Date: Sun, 23 Nov 2025 11:18:35 GMT   (1436kb)

Title: Pre-training Graph Neural Networks on 2D and 3D Molecular Structures by
 using Multi-View Conditional Information Bottleneck
Authors: Van Thuy Hoang, O-Joun Lee
Categories: cs.LG cs.AI
\\
 Recent pre-training strategies for molecular graphs have attempted to use 2D
and 3D molecular views as both inputs and self-supervised signals, primarily
aligning graph-level representations. However, existing studies remain limited
in addressing two main challenges of multi-view molecular learning: (1)
discovering shared information between two views while diminishing
view-specific information and (2) identifying and aligning important
substructures, e.g., functional groups, which are crucial for enhancing
cross-view consistency and model expressiveness. To solve these challenges, we
propose a Multi-View Conditional Information Bottleneck framework, called
MVCIB, for pre-training graph neural networks on 2D and 3D molecular structures
in a self-supervised setting. Our idea is to discover the shared information
while minimizing irrelevant features from each view under the MVCIB principle,
which uses one view as a contextual condition to guide the representation
learning of its counterpart. To enhance semantic and structural consistency
across views, we utilize key substructures, e.g., functional groups and
ego-networks, as anchors between the two views. Then, we propose a
cross-attention mechanism that captures fine-grained correlations between the
substructures to achieve subgraph alignment across views. Extensive experiments
in four molecular domains demonstrated that MVCIB consistently outperforms
baselines in both predictive performance and interpretability. Moreover, MVCIB
achieved the 3d Weisfeiler-Lehman expressiveness power to distinguish not only
non-isomorphic graphs but also different 3D geometries that share identical 2D
connectivity, such as isomers.
\\ ( https://arxiv.org/abs/2511.18404 ,  1436kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18417
Date: Sun, 23 Nov 2025 12:07:45 GMT   (37kb)

Title: Categorical Equivariant Deep Learning: Category-Equivariant Neural
 Networks and Universal Approximation Theorems
Authors: Yoshihiro Maruyama
Categories: cs.LG cs.AI cs.CV cs.RO
\\
 We develop a theory of category-equivariant neural networks (CENNs) that
unifies group/groupoid-equivariant networks, poset/lattice-equivariant
networks, graph and sheaf neural networks. Equivariance is formulated as
naturality in a topological category with Radon measures, formulating linear
and nonlinear layers in the categorical setup. We prove the equivariant
universal approximation theorem in the general setting: the class of
finite-depth CENNs is dense in the space of continuous equivariant
transformations. We instantiate the framework for groups/groupoids,
posets/lattices, graphs and cellular sheaves, deriving universal approximation
theorems for them in a systematic manner. Categorical equivariant deep learning
thus allows us to expand the horizons of equivariant deep learning beyond group
actions, encompassing not only geometric symmetries but also contextual and
compositional symmetries.
\\ ( https://arxiv.org/abs/2511.18417 ,  37kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18457
Date: Sun, 23 Nov 2025 13:59:32 GMT   (822kb)

Title: Radiation-Preserving Selective Imaging for Pediatric Hip Dysplasia: A
 Cross-Modal Ultrasound-Xray Policy with Limited Labels
Authors: Duncan Stothers, Ben Stothers, Emily Schaeffer, Kishore Mulpuri
Categories: cs.LG cs.CV
Comments: Accepted (with oral presentation) to the AAAI 2026 AIMedHealth Bridge
 Program
\\
 We study an ultrasound-first, radiation-preserving policy for developmental
dysplasia of the hip (DDH) that requests a radiograph only when needed.
 We (i) pretrain modality-specific encoders (ResNet-18) with SimSiam on a
large unlabelled registry (37186 ultrasound; 19546 radiographs), (ii) freeze
the backbones and fit small, measurement-faithful heads on DDH relevant
landmarks and measurements (iii) calibrate a one sided conformal deferral rule
on ultrasound predictions that provides finite sample coverage guarantees under
exchangeability, using a held-out calibration set. Ultrasound heads predict
Graf alpha, beta, and femoral head coverage; X-ray heads predict acetabular
index (AI), center-edge (CE) angle and IHDI grade. On our held out labeled
evaluation set, ultrasound measurement error is modest (e.g., alpha MAE ~= 9.7
degrees, coverage MAE ~= 14.0%), while radiographic probes achieve AI and CE
MAEs of ~= 7.6 degrees and ~= 8.9 degrees, respectively. The calibrated US-only
policy is explored across rule families (alpha-only; alpha OR coverage; alpha
AND coverage), uncertainty inflation factors, and per-utility trade-offs using
decision-curve analysis. Conservative settings yield high coverage with
near-zero US-only rates; permissive settings (e.g., alpha OR coverage at larger
deltas) achieve non-zero US-only throughput with expected coverage tradeoffs.
The result is a simple, reproducible pipeline that turns limited labels into
interpretable measurements and tunable selective imaging curves suitable for
clinical handoff and future external validation.
\\ ( https://arxiv.org/abs/2511.18457 ,  822kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18468
Date: Sun, 23 Nov 2025 14:29:13 GMT   (1155kb)

Title: SloMo-Fast: Slow-Momentum and Fast-Adaptive Teachers for Source-Free
 Continual Test-Time Adaptation
Authors: Md Akil Raihan Iftee, Mir Sazzat Hossain, Rakibul Hasan Rajib, Tariq
 Iqbal, Md Mofijul Islam, M Ashraful Amin, Amin Ahsan Ali, AKM Mahbubur Rahman
Categories: cs.LG cs.CV
Comments: 38 pages, 38 tables, 16 figures
\\
 Continual Test-Time Adaptation (CTTA) is crucial for deploying models in
real-world applications with unseen, evolving target domains. Existing CTTA
methods, however, often rely on source data or prototypes, limiting their
applicability in privacy-sensitive and resource-constrained settings.
Additionally, these methods suffer from long-term forgetting, which degrades
performance on previously encountered domains as target domains shift. To
address these challenges, we propose SloMo-Fast, a source-free, dual-teacher
CTTA framework designed for enhanced adaptability and generalization. It
includes two complementary teachers: the Slow-Teacher, which exhibits slow
forgetting and retains long-term knowledge of previously encountered domains to
ensure robust generalization, and the Fast-Teacher rapidly adapts to new
domains while accumulating and integrating knowledge across them. This
framework preserves knowledge of past domains and adapts efficiently to new
ones. We also introduce Cyclic Test-Time Adaptation (Cyclic-TTA), a novel CTTA
benchmark that simulates recurring domain shifts. Our extensive experiments
demonstrate that SloMo-Fast consistently outperforms state-of-the-art methods
across Cyclic-TTA, as well as ten other CTTA settings, highlighting its ability
to both adapt and generalize across evolving and revisited domains.
\\ ( https://arxiv.org/abs/2511.18468 ,  1155kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18474
Date: Sun, 23 Nov 2025 14:47:24 GMT   (940kb)

Title: Adaptive Mesh-Quantization for Neural PDE Solvers
Authors: Winfried van den Dool, Maksim Zhdanov, Yuki M. Asano, Max Welling
Categories: cs.LG
\\
 Physical systems commonly exhibit spatially varying complexity, presenting a
significant challenge for neural PDE solvers. While Graph Neural Networks can
handle the irregular meshes required for complex geometries and boundary
conditions, they still apply uniform computational effort across all nodes
regardless of the underlying physics complexity. This leads to inefficient
resource allocation where computationally simple regions receive the same
treatment as complex phenomena. We address this challenge by introducing
Adaptive Mesh Quantization: spatially adaptive quantization across mesh node,
edge, and cluster features, dynamically adjusting the bit-width used by a
quantized model. We propose an adaptive bit-width allocation strategy driven by
a lightweight auxiliary model that identifies high-loss regions in the input
mesh. This enables dynamic resource distribution in the main model, where
regions of higher difficulty are allocated increased bit-width, optimizing
computational resource utilization. We demonstrate our framework's
effectiveness by integrating it with two state-of-the-art models, MP-PDE and
GraphViT, to evaluate performance across multiple tasks: 2D Darcy flow,
large-scale unsteady fluid dynamics in 2D, steady-state Navier-Stokes
simulations in 3D, and a 2D hyper-elasticity problem. Our framework
demonstrates consistent Pareto improvements over uniformly quantized baselines,
yielding up to 50% improvements in performance at the same cost.
\\ ( https://arxiv.org/abs/2511.18474 ,  940kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18489
Date: Sun, 23 Nov 2025 15:18:11 GMT   (1488kb)

Title: Real-Time Personalized Content Adaptation through Matrix Factorization
 and Context-Aware Federated Learning
Authors: Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder
Categories: cs.LG
\\
 Our study presents a multifaceted approach to enhancing user interaction and
content relevance in social media platforms through a federated learning
framework. We introduce personalized LLM Federated Learning and Context-based
Social Media models. In our framework, multiple client entities receive a
foundational GPT model, which is fine-tuned using locally collected social
media data while ensuring data privacy through federated aggregation. Key
modules focus on categorizing user-generated content, computing user persona
scores, and identifying relevant posts from friends networks. By integrating a
sophisticated social engagement quantification method with matrix factorization
techniques, our system delivers real-time personalized content suggestions
tailored to individual preferences. Furthermore, an adaptive feedback loop,
alongside a robust readability scoring algorithm, significantly enhances the
quality and relevance of the content presented to users. This comprehensive
solution not only addresses the challenges of content filtering and
recommendation but also fosters a more engaging social media experience while
safeguarding user privacy, setting a new standard for personalized interactions
in digital platforms.
\\ ( https://arxiv.org/abs/2511.18489 ,  1488kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18515
Date: Sun, 23 Nov 2025 16:10:45 GMT   (2386kb)

Title: RRaPINNs: Residual Risk-Aware Physics Informed Neural Networks
Authors: Ange-Cl\'ement Akazan, Issa Karambal, Jean Medard Ngnotchouye and
 Abebe Geletu Selassie. W
Categories: cs.LG
\\
 Physics-informed neural networks (PINNs) typically minimize average
residuals, which can conceal large, localized errors. We propose Residual
Risk-Aware Physics-Informed Neural Networks PINNs (RRaPINNs), a single-network
framework that optimizes tail-focused objectives using Conditional
Value-at-Risk (CVaR), we also introduced a Mean-Excess (ME) surrogate penalty
to directly control worst-case PDE residuals. This casts PINN training as
risk-sensitive optimization and links it to chance-constrained formulations.
The method is effective and simple to implement. Across several partial
differential equations (PDEs) such as Burgers, Heat, Korteweg-de-Vries, and
Poisson (including a Poisson interface problem with a source jump at x=0.5)
equations, RRaPINNs reduce tail residuals while maintaining or improving mean
errors compared to vanilla PINNs, Residual-Based Attention and its variant
using convolution weighting; the ME surrogate yields smoother optimization than
a direct CVaR hinge. The chance constraint reliability level $\alpha$ acts as a
transparent knob trading bulk accuracy (lower $\alpha$ ) for stricter tail
control (higher $\alpha$ ). We discuss the framework limitations, including
memoryless sampling, global-only tail budgeting, and residual-centric risk, and
outline remedies via persistent hard-point replay, local risk budgets, and
multi-objective risk over BC/IC terms. RRaPINNs offer a practical path to
reliability-aware scientific ML for both smooth and discontinuous PDEs.
\\ ( https://arxiv.org/abs/2511.18515 ,  2386kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18519
Date: Sun, 23 Nov 2025 16:25:42 GMT   (1178kb)

Title: CHIPS: Efficient CLIP Adaptation via Curvature-aware Hybrid
 Influence-based Data Selection
Authors: Xinlin Zhuang, Yichen Li, Xiwei Liu, Haolin Yang, Yifan Lu, Ziyun Zou,
 Yulong Li, Huifa Li, Dongliang Chen, Qinglei Wang, Weiyang Liu, Ying Qian,
 Jiangming Shi, Imran Razzak
Categories: cs.LG
Comments: preprint, under-review
\\
 Adapting CLIP to vertical domains is typically approached by novel
fine-tuning strategies or by continual pre-training (CPT) on large
domain-specific datasets. Yet, data itself remains an underexplored factor in
this process. We revisit this task from a data-centric perspective: Can
effective data selection substitute for large-scale datasets in CPT? We
introduce CHIPS (Curvature-aware Hybrid Influence in Projection Subspace),
which assigns each image-text pair a utility score that integrates three
complementary factors aligned with three goals: faithfulness via a
curvature-aware, Newton-style alignment computed in CLIP's end-point subspace;
scalability via an InfoNCE-aware curvature estimator with Johnson-Lindenstrauss
(JL) sketching; and retention via a selection-aware relevance weight combined
with learnability to balance target adaptation against general-domain
preservation. We justify this design theoretically by proving a lower-bound
guarantee on the proxy's correlation with full-parameter alignment and by
characterizing the bias-variance trade-offs introduced by curvature mixing and
JL sketching. We evaluate CHIPS empirically across various settings: 1) CHIPS
attains state-of-the-art performance among selection baselines on 17 medical
benchmarks, matches full-dataset CPT with 30% of the data, and outperforms
half-dataset CPT using only 10%; 2) on 31 general-domain benchmarks, CHIPS
yields the smallest performance drop under 10-30% data-retention budgets. Code,
data, and checkpoints will be released.
\\ ( https://arxiv.org/abs/2511.18519 ,  1178kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18521
Date: Sun, 23 Nov 2025 16:26:09 GMT   (9600kb)

Title: Hyperspectral Variational Autoencoders for Joint Data Compression and
 Component Extraction
Authors: Core Francisco Park, Manuel Perez-Carrasco, Caroline Nowlan, Cecilia
 Garraffo
Categories: cs.LG astro-ph.EP astro-ph.IM
\\
 Geostationary hyperspectral satellites generate terabytes of data daily,
creating critical challenges for storage, transmission, and distribution to the
scientific community. We present a variational autoencoder (VAE) approach that
achieves x514 compression of NASA's TEMPO satellite hyperspectral observations
(1028 channels, 290-490nm) with reconstruction errors 1-2 orders of magnitude
below the signal across all wavelengths. This dramatic data volume reduction
enables efficient archival and sharing of satellite observations while
preserving spectral fidelity. Beyond compression, we investigate to what extent
atmospheric information is retained in the compressed latent space by training
linear and nonlinear probes to extract Level-2 products (NO2, O3, HCHO, cloud
fraction). Cloud fraction and total ozone achieve strong extraction performance
(R^2 = 0.93 and 0.81 respectively), though these represent relatively
straightforward retrievals given their distinct spectral signatures. In
contrast, tropospheric trace gases pose genuine challenges for extraction (NO2
R^2 = 0.20, HCHO R^2 = 0.51) reflecting their weaker signals and complex
atmospheric interactions. Critically, we find the VAE encodes atmospheric
information in a semi-linear manner - nonlinear probes substantially outperform
linear ones - and that explicit latent supervision during training provides
minimal improvement, revealing fundamental encoding challenges for certain
products. This work demonstrates that neural compression can dramatically
reduce hyperspectral data volumes while preserving key atmospheric signals,
addressing a critical bottleneck for next-generation Earth observation systems.
Code - https://github.com/cfpark00/Hyperspectral-VAE
\\ ( https://arxiv.org/abs/2511.18521 ,  9600kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18539
Date: Sun, 23 Nov 2025 17:10:07 GMT   (4189kb)

Title: TimePre: Bridging Accuracy, Efficiency, and Stability in Probabilistic
 Time-Series Forecasting
Authors: Lingyu Jiang, Lingyu Xu, Peiran Li, Qianwen Ge, Dingyi Zhuang, Shuo
 Xing, Wenjing Chen, Xiangbo Gao, Ting-Hsuan Chen, Xueying Zhan, Xin Zhang,
 Ziming Zhang, Zhengzhong Tu, Michael Zielewski, Kazunori Yamada, Fangzhou Lin
Categories: cs.LG cs.CV
Comments: 15 pages, 5 figures, 6 tables
\\
 Probabilistic Time-Series Forecasting (PTSF) is critical for
uncertainty-aware decision making, but existing generative models, such as
diffusion-based approaches, are computationally prohibitive due to expensive
iterative sampling. Non-sampling frameworks like Multiple Choice Learning (MCL)
offer an efficient alternative, but suffer from severe training instability and
hypothesis collapse, which has historically hindered their performance. This
problem is dramatically exacerbated when attempting to combine them with
modern, efficient MLP-based backbones. To resolve this fundamental
incompatibility, we propose TimePre, a novel framework that successfully
unifies the efficiency of MLP-based models with the distributional flexibility
of the MCL paradigm. The core of our solution is Stabilized Instance
Normalization (SIN), a novel normalization layer that explicitly remedies this
incompatibility. SIN stabilizes the hybrid architecture by correcting
channel-wise statistical shifts, definitively resolving the catastrophic
hypothesis collapse. Extensive experiments on six benchmark datasets
demonstrate that TimePre achieves new state-of-the-art accuracy on key
probabilistic metrics. Critically, TimePre achieves inference speeds orders of
magnitude faster than sampling-based models and, unlike prior MCL work,
demonstrates stable performance scaling. It thus bridges the long-standing gap
between accuracy, efficiency, and stability in probabilistic forecasting.
\\ ( https://arxiv.org/abs/2511.18539 ,  4189kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18567
Date: Sun, 23 Nov 2025 18:24:35 GMT   (1703kb)

Title: In Search of Goodness: Large Scale Benchmarking of Goodness Functions
 for the Forward-Forward Algorithm
Authors: Arya Shah, Vaibhav Tripathi
Categories: cs.LG
Comments: 24 pages, 5 tables, 17 figures
\\
 The Forward-Forward (FF) algorithm offers a biologically plausible
alternative to backpropagation, enabling neural networks to learn through local
updates. However, FF's efficacy relies heavily on the definition of "goodness",
which is a scalar measure of neural activity. While current implementations
predominantly utilize a simple sum-of-squares metric, it remains unclear if
this default choice is optimal. To address this, we benchmarked 21 distinct
goodness functions across four standard image datasets (MNIST, FashionMNIST,
CIFAR-10, STL-10), evaluating classification accuracy, energy consumption, and
carbon footprint. We found that certain alternative goodness functions inspired
from various domains significantly outperform the standard baseline.
Specifically, \texttt{game\_theoretic\_local} achieved 97.15\% accuracy on
MNIST, \texttt{softmax\_energy\_margin\_local} reached 82.84\% on FashionMNIST,
and \texttt{triplet\_margin\_local} attained 37.69\% on STL-10. Furthermore, we
observed substantial variability in computational efficiency, highlighting a
critical trade-off between predictive performance and environmental cost. These
findings demonstrate that the goodness function is a pivotal hyperparameter in
FF design. We release our code on
\href{https://github.com/aryashah2k/In-Search-of-Goodness}{Github} for
reference and reproducibility.
\\ ( https://arxiv.org/abs/2511.18567 ,  1703kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18571
Date: Sun, 23 Nov 2025 18:31:18 GMT   (7105kb)

Title: SAMBA: Toward a Long-Context EEG Foundation Model via Spatial Embedding
 and Differential Mamba
Authors: Jiazhen Hong, Geoffrey Mackellar, Soheila Ghane
Categories: cs.LG
\\
 Long-sequence electroencephalogram (EEG) modeling is essential for developing
generalizable EEG representation models. This need arises from the high
sampling rate of EEG data and the long recording durations required to capture
extended neurological patterns in brain activity. Transformer-based models have
shown promise in modeling short sequences of a few seconds; however, their
quadratic complexity limits scalability to longer contexts. Moreover,
variability in electrode montage across available datasets, along with
inter-subject differences in brain signals, pose significant challenges to
developing a generalizable and robust foundation model. We propose
\textit{SAMBA}, a self-supervised learning framework with a Mamba-based
U-shaped encoder-decoder architecture, which effectively captures long-range
temporal dependencies and spatial variability in EEG data. Leveraging the
inherent ability of Mamba in processing long context sizes, we introduce: (1)
\textit{Temporal Semantic Random Masking} for semantic-level sequence
reconstruction, (2) a \textit{Multi-Head Differential Mamba} module to suppress
redundancy and emphasize salient temporal structures, and (3) a
\textit{Spatial-Adaptive Input Embedding} that learns unified embeddings in a
three-dimensional Euclidean space, enabling robustness across devices.
Experiments on thirteen EEG datasets across diverse tasks, electrode
configurations, and sequence durations demonstrate that SAMBA consistently
outperforms state-of-the-art methods while maintaining low memory consumption
and inference time. We also show the learned spatial weight maps from our
embedding module align closely with task-relevant neurophysiological regions,
demonstrating the learnability and interpretability of SAMBA. These results
highlight SAMBA's scalability and practical potential as a foundation model for
real-time brain-computer interface applications.
\\ ( https://arxiv.org/abs/2511.18571 ,  7105kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18593
Date: Sun, 23 Nov 2025 19:27:13 GMT   (565kb)

Title: Generative Myopia: Why Diffusion Models Fail at Structure
Authors: Milad Siami
Categories: cs.LG cs.SY eess.SY math.SP
\\
 Graph Diffusion Models (GDMs) optimize for statistical likelihood, implicitly
acting as \textbf{frequency filters} that favor abundant substructures over
spectrally critical ones. We term this phenomenon \textbf{Generative Myopia}.
In combinatorial tasks like graph sparsification, this leads to the
catastrophic removal of ``rare bridges,'' edges that are structurally mandatory
($R_{\text{eff}} \approx 1$) but statistically scarce. We prove theoretically
and empirically that this failure is driven by \textbf{Gradient Starvation}:
the optimization landscape itself suppresses rare structural signals, rendering
them unlearnable regardless of model capacity. To resolve this, we introduce
\textbf{Spectrally-Weighted Diffusion}, which re-aligns the variational
objective using Effective Resistance. We demonstrate that spectral priors can
be amortized into the training phase with zero inference overhead. Our method
eliminates myopia, matching the performance of an optimal Spectral Oracle and
achieving \textbf{100\% connectivity} on adversarial benchmarks where standard
diffusion fails completely (0\%).
\\ ( https://arxiv.org/abs/2511.18593 ,  565kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18611
Date: Sun, 23 Nov 2025 21:00:21 GMT   (40333kb)

Title: CycleSL: Server-Client Cyclical Update Driven Scalable Split Learning
Authors: Mengdi Wang, Efe Bozkir, Enkelejda Kasneci
Categories: cs.LG cs.DC
Comments: The IEEE/CVF Winter Conference on Applications of Computer Vision
 2026 (WACV-26)
\\
 Split learning emerges as a promising paradigm for collaborative distributed
model training, akin to federated learning, by partitioning neural networks
between clients and a server without raw data exchange. However, sequential
split learning suffers from poor scalability, while parallel variants like
parallel split learning and split federated learning often incur high server
resource overhead due to model duplication and aggregation, and generally
exhibit reduced model performance and convergence owing to factors like client
drift and lag. To address these limitations, we introduce CycleSL, a novel
aggregation-free split learning framework that enhances scalability and
performance and can be seamlessly integrated with existing methods. Inspired by
alternating block coordinate descent, CycleSL treats server-side training as an
independent higher-level machine learning task, resampling client-extracted
features (smashed data) to mitigate heterogeneity and drift. It then performs
cyclical updates, namely optimizing the server model first, followed by client
updates using the updated server for gradient computation. We integrate CycleSL
into previous algorithms and benchmark them on five publicly available datasets
with non-iid data distribution and partial client attendance. Our empirical
findings highlight the effectiveness of CycleSL in enhancing model performance.
Our source code is available at https://gitlab.lrz.de/hctl/CycleSL.
\\ ( https://arxiv.org/abs/2511.18611 ,  40333kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18613
Date: Sun, 23 Nov 2025 21:09:58 GMT   (1490kb)

Title: KAN vs LSTM Performance in Time Series Forecasting
Authors: Tabish Ali Rather, S M Mahmudul Hasan Joy, Nadezda Sukhorukova,
 Federico Frascoli
Categories: cs.LG cs.AI
Comments: This paper compares Kolmogorov-Arnold Networks (KANs) and LSTMs for
 forecasting stock prices, highlighting that LSTMs provide superior predictive
 accuracy while KANs offer better interpretability and efficiency in
 limited-resource settings. Practical findings and future research directions
 are discussed
MSC-class: 92B20, 68T07
ACM-class: I.2.6; G.3; I.5.1
\\
 This paper compares Kolmogorov-Arnold Networks (KAN) and Long Short-Term
Memory networks (LSTM) for forecasting non-deterministic stock price data,
evaluating predictive accuracy versus interpretability trade-offs using Root
Mean Square Error (RMSE).LSTM demonstrates substantial superiority across all
tested prediction horizons, confirming their established effectiveness for
sequential data modelling. Standard KAN, while offering theoretical
interpretability through the Kolmogorov-Arnold representation theorem, exhibits
significantly higher error rates and limited practical applicability for time
series forecasting. The results confirm LSTM dominance in accuracy-critical
time series applications while identifying computational efficiency as KANs'
primary advantage in resource-constrained scenarios where accuracy requirements
are less stringent. The findings support LSTM adoption for practical financial
forecasting while suggesting that continued research into specialised KAN
architectures may yield future improvements.
\\ ( https://arxiv.org/abs/2511.18613 ,  1490kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18615
Date: Sun, 23 Nov 2025 21:10:49 GMT   (2654kb)

Title: Bayesian-based Online Label Shift Estimation with Dynamic Dirichlet
 Priors
Authors: Jiawei Hu and Javier A. Barria
Categories: cs.LG stat.ML
Comments: 13 pages, submitted to IEEE journal for possible publication
\\
 Label shift, a prevalent challenge in supervised learning, arises when the
class prior distribution of test data differs from that of training data,
leading to significant degradation in classifier performance. To accurately
estimate the test priors and enhance classification accuracy, we propose a
Bayesian framework for label shift estimation, termed Full Maximum A Posterior
Label Shift (FMAPLS), along with its online version, online-FMAPLS. Leveraging
batch and online Expectation-Maximization (EM) algorithms, these methods
jointly and dynamically optimize Dirichlet hyperparameters
$\boldsymbol{\alpha}$ and class priors $\boldsymbol{\pi}$, thereby overcoming
the rigid constraints of the existing Maximum A Posterior Label Shift (MAPLS)
approach. Moreover, we introduce a linear surrogate function (LSF) to replace
gradient-based hyperparameter updates, yielding closed-form solutions that
reduce computational complexity while retaining asymptotic equivalence. The
online variant substitutes the batch E-step with a stochastic approximation,
enabling real-time adaptation to streaming data. Furthermore, our theoretical
analysis reveals a fundamental trade-off between online convergence rate and
estimation accuracy. Extensive experiments on CIFAR100 and ImageNet datasets
under shuffled long-tail and Dirichlet test priors demonstrate that FMAPLS and
online-FMAPLS respectively achieve up to 40% and 12% lower KL divergence and
substantial improvements in post-shift accuracy over state-of-the-art
baselines, particularly under severe class imbalance and distributional
uncertainty. These results confirm the robustness, scalability, and suitability
of the proposed methods for large-scale and dynamic learning scenarios.
\\ ( https://arxiv.org/abs/2511.18615 ,  2654kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18630
Date: Sun, 23 Nov 2025 22:05:08 GMT   (708kb)

Title: Majority of the Bests: Improving Best-of-N via Bootstrapping
Authors: Amin Rakhsha, Kanika Madan, Tianyu Zhang, Amir-massoud Farahmand, Amir
 Khasahmadi
Categories: cs.LG cs.AI cs.CL stat.ME stat.ML
\\
 Sampling multiple outputs from a Large Language Model (LLM) and selecting the
most frequent (Self-consistency) or highest-scoring (Best-of-N) candidate is a
popular approach to achieve higher accuracy in tasks with discrete final
answers. Best-of-N (BoN) selects the output with the highest reward, and with
perfect rewards, it often achieves near-perfect accuracy. With imperfect
rewards from reward models, however, BoN fails to reliably find the correct
answer and its performance degrades drastically. We consider the distribution
of BoN's outputs and highlight that, although the correct answer does not
usually have a probability close to one under imperfect rewards, it is often
the most likely outcome. This suggests that the mode of this distribution can
be more reliably correct than a sample from it. Based on this idea, we propose
Majority-of-the-Bests (MoB), a novel selection mechanism that estimates the
output distribution of BoN via bootstrapping and selects its mode. Experimental
results across five benchmarks, three different base LLMs, and two reward
models demonstrate consistent improvements over BoN in 25 out of 30 setups. We
also provide theoretical results for the consistency of the bootstrapping. MoB
serves as a simple, yet strong alternative to BoN and self-consistency, and
more broadly, motivates further research in more nuanced selection mechanisms.
\\ ( https://arxiv.org/abs/2511.18630 ,  708kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18631
Date: Sun, 23 Nov 2025 22:08:52 GMT   (509kb)

Title: FOS: A Large-Scale Temporal Graph Benchmark for Scientific
 Interdisciplinary Link Prediction
Authors: Kiyan Rezaee, Morteza Ziabakhsh, Niloofar Nikfarjam, Mohammad M.
 Ghassemi, Yazdan Rezaee Jouryabi, Sadegh Eskandari, Reza Lashgari
Categories: cs.LG
Comments: 21 pages, 10 figures
\\
 Interdisciplinary scientific breakthroughs mostly emerge unexpectedly, and
forecasting the formation of novel research fields remains a major challenge.
We introduce FOS (Future Of Science), a comprehensive time-aware graph-based
benchmark that reconstructs annual co-occurrence graphs of 65,027 research
sub-fields (spanning 19 general domains) over the period 1827-2024. In these
graphs, edges denote the co-occurrence of two fields in a single publication
and are timestamped with the corresponding publication year. Nodes are enriched
with semantic embeddings, and edges are characterized by temporal and
topological descriptors. We formulate the prediction of new field-pair linkages
as a temporal link-prediction task, emphasizing the "first-time" connections
that signify pioneering interdisciplinary directions. Through extensive
experiments, we evaluate a suite of state-of-the-art temporal graph
architectures under multiple negative-sampling regimes and show that (i)
embedding long-form textual descriptions of fields significantly boosts
prediction accuracy, and (ii) distinct model classes excel under different
evaluation settings. Case analyses show that top-ranked link predictions on FOS
align with field pairings that emerge in subsequent years of academic
publications. We publicly release FOS, along with its temporal data splits and
evaluation code, to establish a reproducible benchmark for advancing research
in predicting scientific frontiers.
\\ ( https://arxiv.org/abs/2511.18631 ,  509kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18632
Date: Sun, 23 Nov 2025 22:12:35 GMT   (749kb)

Title: The Locally Deployable Virtual Doctor: LLM Based Human Interface for
 Automated Anamnesis and Database Conversion
Authors: Jan Benedikt Ruhland, Doguhan Bahcivan, Jan-Peter Sowa, Ali Canbay,
 Dominik Heider
Categories: cs.LG
\\
 Recent advances in large language models made it possible to achieve high
conversational performance with substantially reduced computational demands,
enabling practical on-site deployment in clinical environments. Such progress
allows for local integration of AI systems that uphold strict data protection
and patient privacy requirements, yet their secure implementation in medicine
necessitates careful consideration of ethical, regulatory, and technical
constraints.
 In this study, we introduce MedChat, a locally deployable virtual physician
framework that integrates an LLM-based medical chatbot with a diffusion-driven
avatar for automated and structured anamnesis. The chatbot was fine-tuned using
a hybrid corpus of real and synthetically generated medical dialogues, while
model efficiency was optimized via Low-Rank Adaptation. A secure and isolated
database interface was implemented to ensure complete separation between
patient data and the inference process. The avatar component was realized
through a conditional diffusion model operating in latent space, trained on
researcher video datasets and synchronized with mel-frequency audio features
for realistic speech and facial animation.
 Unlike existing cloud-based systems, this work demonstrates the feasibility
of a fully offline, locally deployable LLM-diffusion framework for clinical
anamnesis. The autoencoder and diffusion networks exhibited smooth convergence,
and MedChat achieved stable fine-tuning with strong generalization to unseen
data. The proposed system thus provides a privacy-preserving,
resource-efficient foundation for AI-assisted clinical anamnesis, also in
low-cost settings.
\\ ( https://arxiv.org/abs/2511.18632 ,  749kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18643
Date: Sun, 23 Nov 2025 22:54:48 GMT   (994kb)

Title: Kitty: Accurate and Efficient 2-bit KV Cache Quantization with Dynamic
 Channel-wise Precision Boost
Authors: Haojun Xia, Xiaoxia Wu, Jisen Li, Robert Wu, Junxiong Wang, Jue Wang,
 Chenxi Li, Aman Singhal, Alay Dilipbhai Shah, Alpay Ariyak, Donglin Zhuang,
 Zhongzhu Zhou, Ben Athiwaratkun, Zhen Zheng, Shuaiwen Leon Song
Categories: cs.LG cs.AI
\\
 The KV cache is a dominant memory bottleneck for LLM inference. While 4-bit
KV quantization preserves accuracy, 2-bit often degrades it, especially on
long-context reasoning. We close this gap via an algorithm-system co-design for
mixed-precision KV caching: Kitty. On the algorithm side, extensive experiments
show that Dynamic Channel-wise Precision Boost -- which ranks Key-cache
channels by sensitivity and keeps only a small fraction at higher precision --
maintains near-zero loss in accuracy drop while approaching 2-bit memory. The
main challenge is handling dynamic 4-bit channel boosts while keeping the page
layout coalesced and the dequantization uniform, with no scattered reads or
hard-coded masks. Kitty addresses these issues by decompose each
mixed-precision Key page into two tensors with unified 2-bit precision. Based
on this, Kitty provides a page-centric KV layout, Triton-compatible page
dequantization kernels, and a lightweight runtime pipeline that preserves
coalescing and avoids divergence. Across seven tasks and two model families
(Qwen3, LLaMA3), Kitty cuts KV memory by nearly 8x with negligible accuracy
loss, enabling up to 8x larger batches and 2.1x-4.1x higher throughput under
the same memory budget. We release the full implementation of Kitty at
https://github.com/Summer-Summer/Kitty.
\\ ( https://arxiv.org/abs/2511.18643 ,  994kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18660
Date: Mon, 24 Nov 2025 00:15:46 GMT   (4893kb)

Title: Subtract the Corruption: Training-Data-Free Corrective Machine
 Unlearning using Task Arithmetic
Authors: Mostafa Mozafari, Farooq Ahmad Wani, Maria Sofia Bucarelli, Fabrizio
 Silvestri
Categories: cs.LG stat.ML
\\
 Corrupted training data are ubiquitous. Corrective Machine Unlearning (CMU)
seeks to remove the influence of such corruption post-training. Prior CMU
typically assumes access to identified corrupted training samples (a ``forget
set''). However, in many real-world scenarios the training data are no longer
accessible. We formalize \emph{source-free} CMU, where the original training
data are unavailable and, consequently, no forget set of identified corrupted
training samples can be specified. Instead, we assume a small proxy (surrogate)
set of corrupted samples that reflect the suspected corruption type without
needing to be the original training samples. In this stricter setting, methods
relying on forget set are ineffective or narrow in scope. We introduce
\textit{Corrective Unlearning in Task Space} (CUTS), a lightweight weight space
correction method guided by the proxy set using task arithmetic principles.
CUTS treats the clean and the corruption signal as distinct tasks.
Specifically, we briefly fine-tune the corrupted model on the proxy to amplify
the corruption mechanism in the weight space, compute the difference between
the corrupted and fine-tuned weights as a proxy task vector, and subtract a
calibrated multiple of this vector to cancel the corruption. Without access to
clean data or a forget set, CUTS recovers a large fraction of the lost utility
under label noise and, for backdoor triggers, nearly eliminates the attack with
minimal damage to utility, outperforming state-of-the-art specialized CMU
methods in source-free setting.
\\ ( https://arxiv.org/abs/2511.18660 ,  4893kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18670
Date: Mon, 24 Nov 2025 00:55:14 GMT   (462kb)

Title: Deterministic Continuous Replacement: Fast and Stable Module Replacement
 in Pretrained Transformers
Authors: Rowan Bradbury, Aniket Srinivasan Ashok, Sai Ram Kasanagottu, Gunmay
 Jhingran, Shuai Meng
Categories: cs.LG cs.AI cs.CV
Comments: Accepted to NeurIPS 2025 ScaleOPT Workshop; 8 pages; includes figures
\\
 Replacing modules in pretrained models, especially swapping quadratic
self-attention for efficient attention alternatives, poses a hard optimization
problem: cold-start reinitialization destabilizes frozen backbones. We isolate
this core stability challenge in a controlled study. Deterministic Continuous
Replacement (DCR) blends teacher and student outputs with a deterministic,
annealed weight. Theoretically, DCR eliminates gate-induced gradient variance
inherent to stochastic replacement. In a single-seed study, DCR attains faster
convergence and stronger alignment than stochastic gating and distillation
baselines on controlled attention replacement, establishing a foundation for
heterogeneous operator swaps.
\\ ( https://arxiv.org/abs/2511.18670 ,  462kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18671
Date: Mon, 24 Nov 2025 01:04:42 GMT   (399kb)

Title: Multi-Agent Cross-Entropy Method with Monotonic Nonlinear Critic
 Decomposition
Authors: Yan Wang, Ke Deng, Yongli Ren
Categories: cs.LG cs.MA
\\
 Cooperative multi-agent reinforcement learning (MARL) commonly adopts
centralized training with decentralized execution (CTDE), where centralized
critics leverage global information to guide decentralized actors. However,
centralized-decentralized mismatch (CDM) arises when the suboptimal behavior of
one agent degrades others' learning. Prior approaches mitigate CDM through
value decomposition, but linear decompositions allow per-agent gradients at the
cost of limited expressiveness, while nonlinear decompositions improve
representation but require centralized gradients, reintroducing CDM. To
overcome this trade-off, we propose the multi-agent cross-entropy method
(MCEM), combined with monotonic nonlinear critic decomposition (NCD). MCEM
updates policies by increasing the probability of high-value joint actions,
thereby excluding suboptimal behaviors. For sample efficiency, we extend
off-policy learning with a modified k-step return and Retrace. Analysis and
experiments demonstrate that MCEM outperforms state-of-the-art methods across
both continuous and discrete action benchmarks.
\\ ( https://arxiv.org/abs/2511.18671 ,  399kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18689
Date: Mon, 24 Nov 2025 02:05:16 GMT   (54kb)

Title: QuantKAN: A Unified Quantization Framework for Kolmogorov Arnold
 Networks
Authors: Kazi Ahmed Asif Fuad and Lizhong Chen
Categories: cs.LG
\\
 Kolmogorov Arnold Networks (KANs) represent a new class of neural
architectures that replace conventional linear transformations and node-based
nonlinearities with spline-based function approximations distributed along
network edges. Although KANs offer strong expressivity and interpretability,
their heterogeneous spline and base branch parameters hinder efficient
quantization, which remains unexamined compared to CNNs and Transformers. In
this paper, we present QuantKAN, a unified framework for quantizing KANs across
both quantization aware training (QAT) and post-training quantization (PTQ)
regimes. QuantKAN extends modern quantization algorithms, such as LSQ, LSQ+,
PACT, DoReFa, QIL, GPTQ, BRECQ, AdaRound, AWQ, and HAWQ-V2, to spline based
layers with branch-specific quantizers for base, spline, and activation
components. Through extensive experiments on MNIST, CIFAR 10, and CIFAR 100
across multiple KAN variants (EfficientKAN, FastKAN, PyKAN, and KAGN), we
establish the first systematic benchmarks for low-bit spline networks. Our
results show that KANs, particularly deeper KAGN variants, are compatible with
low-bit quantization but exhibit strong method architecture interactions: LSQ,
LSQ+, and PACT preserve near full precision accuracy at 4 bit for shallow KAN
MLP and ConvNet models, while DoReFa provides the most stable behavior for
deeper KAGN under aggressive low-bit settings. For PTQ, GPTQ and Uniform
consistently deliver the strongest overall performance across datasets, with
BRECQ highly competitive on simpler regimes such as MNIST. Our proposed
QuantKAN framework thus unifies spline learning and quantization, and provides
practical tools and guidelines for efficiently deploying KANs in real-world,
resource-constrained environments.
\\ ( https://arxiv.org/abs/2511.18689 ,  54kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18692
Date: Mon, 24 Nov 2025 02:27:19 GMT   (2213kb)

Title: VLM in a flash: I/O-Efficient Sparsification of Vision-Language Model
 via Neuron Chunking
Authors: Kichang Yang, Seonjun Kim, Minjae Kim, Nairan Zhang, Chi Zhang,
 Youngki Lee
Categories: cs.LG cs.AI cs.CV cs.PF
\\
 Edge deployment of large Vision-Language Models (VLMs) increasingly relies on
flash-based weight offloading, where activation sparsification is used to
reduce I/O overhead. However, conventional sparsification remains
model-centric, selecting neurons solely by activation magnitude and neglecting
how access patterns influence flash performance. We present Neuron Chunking, an
I/O-efficient sparsification strategy that operates on chunks (i.e., groups of
contiguous neurons in memory) and couples neuron importance with storage access
cost. The method models I/O latency through a lightweight abstraction of access
contiguity and selects chunks with high utility, defined as neuron importance
normalized by estimated latency. By aligning sparsification decisions with the
underlying storage behavior, Neuron Chunking improves I/O efficiency by up to
4.65x and 5.76x on Jetson Orin Nano and Jetson AGX Orin, respectively.
\\ ( https://arxiv.org/abs/2511.18692 ,  2213kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18716
Date: Mon, 24 Nov 2025 03:14:55 GMT   (1558kb)

Title: GRIT-LP: Graph Transformer with Long-Range Skip Connection and
 Partitioned Spatial Graphs for Accurate Ice Layer Thickness Prediction
Authors: Zesheng Liu, Maryam Rahnemoonfar
Categories: cs.LG cs.CV
\\
 Graph transformers have demonstrated remarkable capability on complex
spatio-temporal tasks, yet their depth is often limited by oversmoothing and
weak long-range dependency modeling. To address these challenges, we introduce
GRIT-LP, a graph transformer explicitly designed for polar ice-layer thickness
estimation from polar radar imagery. Accurately estimating ice layer thickness
is critical for understanding snow accumulation, reconstructing past climate
patterns and reducing uncertainties in projections of future ice sheet
evolution and sea level rise. GRIT-LP combines an inductive geometric graph
learning framework with self-attention mechanism, and introduces two major
innovations that jointly address challenges in modeling the spatio-temporal
patterns of ice layers: a partitioned spatial graph construction strategy that
forms overlapping, fully connected local neighborhoods to preserve spatial
coherence and suppress noise from irrelevant long-range links, and a long-range
skip connection mechanism within the transformer that improves information flow
and mitigates oversmoothing in deeper attention layers. We conducted extensive
experiments, demonstrating that GRIT-LP outperforms current state-of-the-art
methods with a 24.92\% improvement in root mean squared error. These results
highlight the effectiveness of graph transformers in modeling spatiotemporal
patterns by capturing both localized structural features and long-range
dependencies across internal ice layers, and demonstrate their potential to
advance data-driven understanding of cryospheric processes.
\\ ( https://arxiv.org/abs/2511.18716 ,  1558kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18721
Date: Mon, 24 Nov 2025 03:25:16 GMT   (718kb)

Title: Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM
Authors: Adarsh Kumarappan, Ayushi Mehrotra
Categories: cs.LG
\\
 The SmoothLLM defense provides a certification guarantee against jailbreaking
attacks, but it relies on a strict `k-unstable' assumption that rarely holds in
practice. This strong assumption can limit the trustworthiness of the provided
safety certificate. In this work, we address this limitation by introducing a
more realistic probabilistic framework, `(k, $\varepsilon$)-unstable,' to
certify defenses against diverse jailbreaking attacks, from gradient-based
(GCG) to semantic (PAIR). We derive a new, data-informed lower bound on
SmoothLLM's defense probability by incorporating empirical models of attack
success, providing a more trustworthy and practical safety certificate. By
introducing the notion of (k, $\varepsilon$)-unstable, our framework provides
practitioners with actionable safety guarantees, enabling them to set
certification thresholds that better reflect the real-world behavior of LLMs.
Ultimately, this work contributes a practical and theoretically-grounded
mechanism to make LLMs more resistant to the exploitation of their safety
alignments, a critical challenge in secure AI deployment.
\\ ( https://arxiv.org/abs/2511.18721 ,  718kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18727
Date: Mon, 24 Nov 2025 03:41:57 GMT   (871kb)

Title: LogSyn: A Few-Shot LLM Framework for Structured Insight Extraction from
 Unstructured General Aviation Maintenance Logs
Authors: Devansh Agarwal, Maitreyi Chatterjee, Biplab Chatterjee
Categories: cs.LG
Comments: Accepted in Proceedings of the 3rd INCOM 2026
\\
 Aircraft maintenance logs hold valuable safety data but remain underused due
to their unstructured text format. This paper introduces LogSyn, a framework
that uses Large Language Models (LLMs) to convert these logs into structured,
machine-readable data. Using few-shot in-context learning on 6,169 records,
LogSyn performs Controlled Abstraction Generation (CAG) to summarize
problem-resolution narratives and classify events within a detailed
hierarchical ontology. The framework identifies key failure patterns, offering
a scalable method for semantic structuring and actionable insight extraction
from maintenance logs. This work provides a practical path to improve
maintenance workflows and predictive analytics in aviation and related
industries.
\\ ( https://arxiv.org/abs/2511.18727 ,  871kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18728
Date: Mon, 24 Nov 2025 03:42:00 GMT   (506kb)

Title: Reinforcement Learning for Self-Healing Material Systems
Authors: Maitreyi Chatterjee, Devansh Agarwal, Biplab Chatterjee
Categories: cs.LG
Comments: Accepted to INCOM 2026. This is the camera-ready version
\\
 The transition to autonomous material systems necessitates adaptive control
methodologies to maximize structural longevity. This study frames the
self-healing process as a Reinforcement Learning (RL) problem within a Markov
Decision Process (MDP), enabling agents to autonomously derive optimal policies
that efficiently balance structural integrity maintenance against finite
resource consumption. A comparative evaluation of discrete-action (Q-learning,
DQN) and continuous-action (TD3) agents in a stochastic simulation environment
revealed that RL controllers significantly outperform heuristic baselines,
achieving near-complete material recovery. Crucially, the TD3 agent utilizing
continuous dosage control demonstrated superior convergence speed and
stability, underscoring the necessity of fine-grained, proportional actuation
in dynamic self-healing applications.
\\ ( https://arxiv.org/abs/2511.18728 ,  506kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18730
Date: Mon, 24 Nov 2025 03:47:59 GMT   (1767kb)

Title: Large-Scale In-Game Outcome Forecasting for Match, Team and Players in
 Football using an Axial Transformer Neural Network
Authors: Michael Horton and Patrick Lucey
Categories: cs.LG
Comments: 25 pages, 7 figures, 1 table
ACM-class: I.2.1
\\
 Football (soccer) is a sport that is characterised by complex game play,
where players perform a variety of actions, such as passes, shots, tackles,
fouls, in order to score goals, and ultimately win matches. Accurately
forecasting the total number of each action that each player will complete
during a match is desirable for a variety of applications, including tactical
decision-making, sports betting, and for television broadcast commentary and
analysis. Such predictions must consider the game state, the ability and skill
of the players in both teams, the interactions between the players, and the
temporal dynamics of the game as it develops. In this paper, we present a
transformer-based neural network that jointly and recurrently predicts the
expected totals for thirteen individual actions at multiple time-steps during
the match, and where predictions are made for each individual player, each team
and at the game-level. The neural network is based on an \emph{axial
transformer} that efficiently captures the temporal dynamics as the game
progresses, and the interactions between the players at each time-step. We
present a novel axial transformer design that we show is equivalent to a
regular sequential transformer, and the design performs well experimentally. We
show empirically that the model can make consistent and reliable predictions,
and efficiently makes $\sim$75,000 live predictions at low latency for each
game.
\\ ( https://arxiv.org/abs/2511.18730 ,  1767kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18732
Date: Mon, 24 Nov 2025 03:57:43 GMT   (14497kb)

Title: OceanForecastBench: A Benchmark Dataset for Data-Driven Global Ocean
 Forecasting
Authors: Haoming Jia, Yi Han, Xiang Wang, Huizan Wang, Wei Wu, Jianming Zheng,
 Peikun Xiao
Categories: cs.LG stat.ML
\\
 Global ocean forecasting aims to predict key ocean variables such as
temperature, salinity, and currents, which is essential for understanding and
describing oceanic phenomena. In recent years, data-driven deep learning-based
ocean forecast models, such as XiHe, WenHai, LangYa and AI-GOMS, have
demonstrated significant potential in capturing complex ocean dynamics and
improving forecasting efficiency. Despite these advancements, the absence of
open-source, standardized benchmarks has led to inconsistent data usage and
evaluation methods. This gap hinders efficient model development, impedes fair
performance comparison, and constrains interdisciplinary collaboration. To
address this challenge, we propose OceanForecastBench, a benchmark offering
three core contributions: (1) A high-quality global ocean reanalysis data over
28 years for model training, including 4 ocean variables across 23 depth levels
and 4 sea surface variables. (2) A high-reliability satellite and in-situ
observations for model evaluation, covering approximately 100 million locations
in the global ocean. (3) An evaluation pipeline and a comprehensive benchmark
with 6 typical baseline models, leveraging observations to evaluate model
performance from multiple perspectives. OceanForecastBench represents the most
comprehensive benchmarking framework currently available for data-driven ocean
forecasting, offering an open-source platform for model development,
evaluation, and comparison. The dataset and code are publicly available at:
https://github.com/Ocean-Intelligent-Forecasting/OceanForecastBench.
\\ ( https://arxiv.org/abs/2511.18732 ,  14497kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18773
Date: Mon, 24 Nov 2025 05:15:58 GMT   (1674kb)

Title: Sampling Control for Imbalanced Calibration in Semi-Supervised Learning
Authors: Senmao Tian, Xiang Wei, Shunli Zhang
Categories: cs.LG cs.CV stat.ML
Comments: Accepted at AAAI 2026
\\
 Class imbalance remains a critical challenge in semi-supervised learning
(SSL), especially when distributional mismatches between labeled and unlabeled
data lead to biased classification. Although existing methods address this
issue by adjusting logits based on the estimated class distribution of
unlabeled data, they often handle model imbalance in a coarse-grained manner,
conflating data imbalance with bias arising from varying class-specific
learning difficulties. To address this issue, we propose a unified framework,
SC-SSL, which suppresses model bias through decoupled sampling control. During
training, we identify the key variables for sampling control under ideal
conditions. By introducing a classifier with explicit expansion capability and
adaptively adjusting sampling probabilities across different data
distributions, SC-SSL mitigates feature-level imbalance for minority classes.
In the inference phase, we further analyze the weight imbalance of the linear
classifier and apply post-hoc sampling control with an optimization bias vector
to directly calibrate the logits. Extensive experiments across various
benchmark datasets and distribution settings validate the consistency and
state-of-the-art performance of SC-SSL.
\\ ( https://arxiv.org/abs/2511.18773 ,  1674kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18777
Date: Mon, 24 Nov 2025 05:22:28 GMT   (687kb)

Title: SAOT: An Enhanced Locality-Aware Spectral Transformer for Solving PDEs
Authors: Chenhong Zhou, Jie Chen, Zaifeng Yang
Categories: cs.LG
Comments: Accepted to AAAI 2026 (Main Technical Track)
\\
 Neural operators have shown great potential in solving a family of Partial
Differential Equations (PDEs) by modeling the mappings between input and output
functions. Fourier Neural Operator (FNO) implements global convolutions via
parameterizing the integral operators in Fourier space. However, it often
results in over-smoothing solutions and fails to capture local details and
high-frequency components. To address these limitations, we investigate
incorporating the spatial-frequency localization property of Wavelet transforms
into the Transformer architecture. We propose a novel Wavelet Attention (WA)
module with linear computational complexity to efficiently learn locality-aware
features. Building upon WA, we further develop the Spectral Attention Operator
Transformer (SAOT), a hybrid spectral Transformer framework that integrates
WA's localized focus with the global receptive field of Fourier-based Attention
(FA) through a gated fusion block. Experimental results demonstrate that WA
significantly mitigates the limitations of FA and outperforms existing
Wavelet-based neural operators by a large margin. By integrating the
locality-aware and global spectral representations, SAOT achieves
state-of-the-art performance on six operator learning benchmarks and exhibits
strong discretization-invariant ability.
\\ ( https://arxiv.org/abs/2511.18777 ,  687kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18783
Date: Mon, 24 Nov 2025 05:35:46 GMT   (2945kb)

Title: Hypergraph Contrastive Learning for both Homophilic and Heterophilic
 Hypergraphs
Authors: Renchu Guan, Xuyang Li, Yachao Zhang, Wei Pang, Fausto Giunchiglia,
 Ximing Li, Yonghao Liu, Xiaoyue Feng
Categories: cs.LG cs.SI
\\
 Hypergraphs, as a generalization of traditional graphs, naturally capture
high-order relationships. In recent years, hypergraph neural networks (HNNs)
have been widely used to capture complex high-order relationships. However,
most existing hypergraph neural network methods inherently rely on the
homophily assumption, which often does not hold in real-world scenarios that
exhibit significant heterophilic structures. To address this limitation, we
propose \textbf{HONOR}, a novel unsupervised \textbf{H}ypergraph
c\textbf{ON}trastive learning framework suitable for both hom\textbf{O}philic
and hete\textbf{R}ophilic hypergraphs. Specifically, HONOR explicitly models
the heterophilic relationships between hyperedges and nodes through two
complementary mechanisms: a prompt-based hyperedge feature construction
strategy that maintains global semantic consistency while suppressing local
noise, and an adaptive attention aggregation module that dynamically captures
the diverse local contributions of nodes to hyperedges. Combined with high-pass
filtering, these designs enable HONOR to fully exploit heterophilic connection
patterns, yielding more discriminative and robust node and hyperedge
representations. Theoretically, we demonstrate the superior generalization
ability and robustness of HONOR. Empirically, extensive experiments further
validate that HONOR consistently outperforms state-of-the-art baselines under
both homophilic and heterophilic datasets.
\\ ( https://arxiv.org/abs/2511.18783 ,  2945kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18789
Date: Mon, 24 Nov 2025 05:38:47 GMT   (56kb)

Title: Doubly Wild Refitting: Model-Free Evaluation of High Dimensional
 Black-Box Predictions under Convex Losses
Authors: Haichen Hu, David Simchi-Levi
Categories: cs.LG stat.ML
\\
 We study the problem of excess risk evaluation for empirical risk
minimization (ERM) under general convex loss functions. Our contribution is an
efficient refitting procedure that computes the excess risk and provides
high-probability upper bounds under the fixed-design setting. Assuming only
black-box access to the training algorithm and a single dataset, we begin by
generating two sets of artificially modified pseudo-outcomes termed wild
response, created by stochastically perturbing the gradient vectors with
carefully chosen scaling. Using these two pseudo-labeled datasets, we then
refit the black-box procedure twice to obtain two corresponding wild
predictors. Finally, leveraging the original predictor, the two wild
predictors, and the constructed wild responses, we derive an efficient excess
risk upper bound. A key feature of our analysis is that it requires no prior
knowledge of the complexity of the underlying function class. As a result, the
method is essentially model-free and holds significant promise for
theoretically evaluating modern opaque machine learning system--such as deep
nerral networks and generative model--where traditional capacity-based learning
theory becomes infeasible due to the extreme complexity of the hypothesis
class.
\\ ( https://arxiv.org/abs/2511.18789 ,  56kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18829
Date: Mon, 24 Nov 2025 07:06:06 GMT   (51kb)

Title: Towards Characterizing Knowledge Distillation of PPG Heart Rate
 Estimation Models
Authors: Kanav Arora, Girish Narayanswamy, Shwetak Patel, Richard Li
Categories: cs.LG
Comments: To be published in: 39th Conference on Neural Information Processing
 Systems (NeurIPS 2025) Workshop: Learning from Time Series for Health
\\
 Heart rate estimation from photoplethysmography (PPG) signals generated by
wearable devices such as smartwatches and fitness trackers has significant
implications for the health and well-being of individuals. Although prior work
has demonstrated deep learning models with strong performance in the heart rate
estimation task, in order to deploy these models on wearable devices, these
models must also adhere to strict memory and latency constraints. In this work,
we explore and characterize how large pre-trained PPG models may be distilled
to smaller models appropriate for real-time inference on the edge. We evaluate
four distillation strategies through comprehensive sweeps of teacher and
student model capacities: (1) hard distillation, (2) soft distillation, (3)
decoupled knowledge distillation (DKD), and (4) feature distillation. We
present a characterization of the resulting scaling laws describing the
relationship between model size and performance. This early investigation lays
the groundwork for practical and predictable methods for building
edge-deployable models for physiological sensing.
\\ ( https://arxiv.org/abs/2511.18829 ,  51kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18830
Date: Mon, 24 Nov 2025 07:06:08 GMT   (34kb)

Title: Leveraging Duration Pseudo-Embeddings in Multilevel LSTM and GCN
 Hypermodels for Outcome-Oriented PPM
Authors: Fang Wang and Paolo Ceravolo and Ernesto Damiani
Categories: cs.LG
Comments: 12 pages
\\
 Existing deep learning models for Predictive Process Monitoring (PPM)
struggle with temporal irregularities, particularly stochastic event durations
and overlapping timestamps, limiting their adaptability across heterogeneous
datasets. We propose a dual input neural network strategy that separates event
and sequence attributes, using a duration-aware pseudo-embedding matrix to
transform temporal importance into compact, learnable representations. This
design is implemented across two baseline families: B-LSTM and B-GCN, and their
duration-aware variants D-LSTM and D-GCN. All models incorporate self-tuned
hypermodels for adaptive architecture selection. Experiments on balanced and
imbalanced outcome prediction tasks show that duration pseudo-embedding inputs
consistently improve generalization, reduce model complexity, and enhance
interpretability. Our results demonstrate the benefits of explicit temporal
encoding and provide a flexible design for robust, real-world PPM applications.
\\ ( https://arxiv.org/abs/2511.18830 ,  34kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18835
Date: Mon, 24 Nov 2025 07:13:34 GMT   (1161kb)

Title: Auto-ML Graph Neural Network Hypermodels for Outcome Prediction in
 Event-Sequence Data
Authors: Fang Wang and Lance Kosca and Adrienne Kosca and Marko Gacesa and
 Ernesto Damiani
Categories: cs.LG
Comments: 6 pages
\\
 This paper introduces HGNN(O), an AutoML GNN hypermodel framework for outcome
prediction on event-sequence data. Building on our earlier work on graph
convolutional network hypermodels, HGNN(O) extends four architectures-One
Level, Two Level, Two Level Pseudo Embedding, and Two Level Embedding-across
six canonical GNN operators. A self-tuning mechanism based on Bayesian
optimization with pruning and early stopping enables efficient adaptation over
architectures and hyperparameters without manual configuration. Empirical
evaluation on both balanced and imbalanced event logs shows that HGNN(O)
achieves accuracy exceeding 0.98 on the Traffic Fines dataset and weighted F1
scores up to 0.86 on the Patients dataset without explicit imbalance handling.
These results demonstrate that the proposed AutoML-GNN approach provides a
robust and generalizable benchmark for outcome prediction in complex
event-sequence data.
\\ ( https://arxiv.org/abs/2511.18835 ,  1161kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18841
Date: Mon, 24 Nov 2025 07:24:09 GMT   (446kb)

Title: Federated style aware transformer aggregation of representations
Authors: Mincheol Jeon and Euinam Huh
Categories: cs.LG cs.AI cs.DC
\\
 Personalized Federated Learning (PFL) faces persistent challenges, including
domain heterogeneity from diverse client data, data imbalance due to skewed
participation, and strict communication constraints. Traditional federated
learning often lacks personalization, as a single global model cannot capture
client-specific characteristics, leading to biased predictions and poor
generalization, especially for clients with highly divergent data
distributions.
 To address these issues, we propose FedSTAR, a style-aware federated learning
framework that disentangles client-specific style factors from shared content
representations. FedSTAR aggregates class-wise prototypes using a
Transformer-based attention mechanism, allowing the server to adaptively weight
client contributions while preserving personalization.
 Furthermore, by exchanging compact prototypes and style vectors instead of
full model parameters, FedSTAR significantly reduces communication overhead.
Experimental results demonstrate that combining content-style disentanglement
with attention-driven prototype aggregation improves personalization and
robustness in heterogeneous environments without increasing communication cost.
\\ ( https://arxiv.org/abs/2511.18841 ,  446kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18846
Date: Mon, 24 Nov 2025 07:33:35 GMT   (619kb)

Title: WaveTuner: Comprehensive Wavelet Subband Tuning for Time Series
 Forecasting
Authors: Yubo Wang and Hui He and Chaoxi Niu and Zhendong Niu
Categories: cs.LG cs.AI
\\
 Due to the inherent complexity, temporal patterns in real-world time series
often evolve across multiple intertwined scales, including long-term
periodicity, short-term fluctuations, and abrupt regime shifts. While existing
literature has designed many sophisticated decomposition approaches based on
the time or frequency domain to partition trend-seasonality components and
high-low frequency components, an alternative line of approaches based on the
wavelet domain has been proposed to provide a unified multi-resolution
representation with precise time-frequency localization. However, most
wavelet-based methods suffer from a persistent bias toward recursively
decomposing only low-frequency components, severely underutilizing subtle yet
informative high-frequency components that are pivotal for precise time series
forecasting. To address this problem, we propose WaveTuner, a Wavelet
decomposition framework empowered by full-spectrum subband Tuning for time
series forecasting. Concretely, WaveTuner comprises two key modules: (i)
Adaptive Wavelet Refinement module, that transforms time series into
time-frequency coefficients, utilizes an adaptive router to dynamically assign
subband weights, and generates subband-specific embeddings to support
refinement; and (ii) Multi-Branch Specialization module, that employs multiple
functional branches, each instantiated as a flexible Kolmogorov-Arnold Network
(KAN) with a distinct functional order to model a specific spectral subband.
Equipped with these modules, WaveTuner comprehensively tunes global trends and
local variations within a unified time-frequency framework. Extensive
experiments on eight real-world datasets demonstrate WaveTuner achieves
state-of-the-art forecasting performance in time series forecasting.
\\ ( https://arxiv.org/abs/2511.18846 ,  619kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18859
Date: Mon, 24 Nov 2025 07:57:37 GMT   (581kb)

Title: Robust and Generalizable GNN Fine-Tuning via Uncertainty-aware Adapter
 Learning
Authors: Bo Jiang, Weijun Zhao, Beibei Wang, Xiao Wang, Jin Tang
Categories: cs.LG cs.CV
\\
 Recently, fine-tuning large-scale pre-trained GNNs has yielded remarkable
attention in adapting pre-trained GNN models for downstream graph learning
tasks. One representative fine-tuning method is to exploit adapter (termed
AdapterGNN) which aims to 'augment' the pre-trained model by inserting a
lightweight module to make the 'augmented' model better adapt to the downstream
tasks. However, graph data may contain various types of noise in downstream
tasks, such as noisy edges and ambiguous node attributes. Existing AdapterGNNs
are often prone to graph noise and exhibit limited generalizability. How to
enhance the robustness and generalization ability of GNNs' fine tuning remains
an open problem. In this paper, we show that the above problem can be well
addressed by integrating uncertainty learning into the GNN adapter. We propose
the Uncertainty-aware Adapter (UAdapterGNN) that fortifies pre-trained GNN
models against noisy graph data in the fine-tuning process. Specifically, in
contrast to regular AdapterGNN, our UAdapterGNN exploits Gaussian probabilistic
adapter to augment the pre-trained GNN model. In this way, when the graph
contains various noises,our method can automatically absorb the effects of
changes in the variances of the Gaussian distribution, thereby significantly
enhancing the model's robustness. Also, UAdapterGNN can further improve the
generalization ability of the model on the downstream tasks. Extensive
experiments on several benchmarks demonstrate the effectiveness, robustness and
high generalization ability of the proposed UAdapterGNN method.
\\ ( https://arxiv.org/abs/2511.18859 ,  581kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18868
Date: Mon, 24 Nov 2025 08:11:50 GMT   (434kb)

Title: KernelBand: Boosting LLM-based Kernel Optimization with a Hierarchical
 and Hardware-aware Multi-armed Bandit
Authors: Dezhi Ran, Shuxiao Xie, Mingfang Ji, Ziyue Hua, Mengzhou Wu, Yuan Cao,
 Yuzhe Guo, Yu Hao, Linyi Li, Yitao Hu, Tao Xie
Categories: cs.LG cs.AI
Comments: Work in progress
\\
 High quality kernels are critical for reducing training and inference costs
of Large Language Models (LLMs), yet they traditionally require significant
expertise in hardware architecture and software optimization. While recent
advances in LLM-based code generation show promise for complex optimization,
existing methods struggle with the vast optimization space due to insufficient
hardware domain knowledge, failing to effectively balance exploration and
exploitation. We present KernelBand, a novel framework that formulates kernel
optimization as a hierarchical multi-armed bandit problem, enabling LLM agents
to strategically navigate the optimization space by treating kernel selection
and optimization strategy application as sequential decision-making processes.
Our approach leverages hardware profiling information to identify promising
optimization strategies and employs runtime behavior clustering to reduce
exploration overhead across kernel candidates. Extensive experiments on
TritonBench demonstrate that KernelBand significantly outperforms
state-of-the-art methods, achieving superior performance with fewer tokens
while exhibiting consistent improvement without saturation as computational
resources increase.
\\ ( https://arxiv.org/abs/2511.18868 ,  434kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18871
Date: Mon, 24 Nov 2025 08:22:50 GMT   (469kb)

Title: Periodic Asynchrony: An Effective Method for Accelerating On-Policy
 Reinforcement Learning
Authors: Jian Lu
Categories: cs.LG cs.AI
\\
 Since the introduction of the GRPO algorithm, reinforcement learning (RL) has
attracted increasing attention, with growing efforts to reproduce and apply it.
However, training efficiency remains a critical challenge. In mainstream RL
frameworks, inference and training are typically deployed on the same devices.
While this approach reduces costs through resource consolidation, its
synchronous execution imposes a computational coupling that prevents concurrent
inference and training. In this study, we are returning to the strategy of
separating inference and training deployment, and by introducing improvements
in the data loader, we transform the conventional synchronous architecture into
a periodically asynchronous framework, which allows for demand-driven,
independent, and elastic scaling of each component, while the accuracy of the
algorithm remains completely equivalent to the synchronization method, with
both belonging to the on-policy strategy. It is worth emphasizing that we apply
a unified tri-model architecture in the training phase, and we also proposed a
shared-prompt attention mask to reduce repetitive computation. In practice,
these works have achieved at least a threefold overall performance improvement
in RL training on NPU platforms, indicating its potential for widespread
application.
\\ ( https://arxiv.org/abs/2511.18871 ,  469kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18887
Date: Mon, 24 Nov 2025 08:42:40 GMT   (1387kb)

Title: Hi-SAFE: Hierarchical Secure Aggregation for Lightweight Federated
 Learning
Authors: Hyeong-Gun Joo, Songnam Hong, Seunghwan Lee, and Dong-Joon Shin
Categories: cs.LG
Comments: currently submitted and awaiting review at the IEEE Internet of
 Things Journal
\\
 Federated learning (FL) faces challenges in ensuring both privacy and
communication efficiency, particularly in resource-constrained environments
such as Internet of Things (IoT) and edge networks. While sign-based methods,
such as sign stochastic gradient descent with majority voting (SIGNSGD-MV),
offer substantial bandwidth savings, they remain vulnerable to inference
attacks due to exposure of gradient signs. Existing secure aggregation
techniques are either incompatible with sign-based methods or incur prohibitive
overhead. To address these limitations, we propose Hi-SAFE, a lightweight and
cryptographically secure aggregation framework for sign-based FL. Our core
contribution is the construction of efficient majority vote polynomials for
SIGNSGD-MV, derived from Fermat's Little Theorem. This formulation represents
the majority vote as a low-degree polynomial over a finite field, enabling
secure evaluation that hides intermediate values and reveals only the final
result. We further introduce a hierarchical subgrouping strategy that ensures
constant multiplicative depth and bounded per-user complexity, independent of
the number of users n.
\\ ( https://arxiv.org/abs/2511.18887 ,  1387kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18890
Date: Mon, 24 Nov 2025 08:46:36 GMT   (5243kb)

Title: Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models
Authors: Yonggan Fu, Xin Dong, Shizhe Diao, Matthijs Van keirsbilck, Hanrong
 Ye, Wonmin Byeon, Yashaswi Karnati, Lucas Liebenwein, Hannah Zhang, Nikolaus
 Binder, Maksim Khadkevich, Alexander Keller, Jan Kautz, Yingyan Celine Lin,
 Pavlo Molchanov
Categories: cs.LG cs.AI
Comments: Accepted by NeurIPS 2025
\\
 Efficient deployment of small language models (SLMs) is essential for
numerous real-world applications with stringent latency constraints. While
previous work on SLM design has primarily focused on reducing the number of
parameters to achieve parameter-optimal SLMs, parameter efficiency does not
necessarily translate into proportional real-device speed-ups. This work aims
to identify the key determinants of SLMs' real-device latency and offer
generalizable principles and methodologies for SLM design and training when
real-device latency is the primary consideration. Specifically, we identify two
central architectural factors: depth-width ratios and operator choices. The
former is crucial for small-batch-size latency, while the latter affects both
latency and large-batch-size throughput. In light of this, we first study
latency-optimal depth-width ratios, with the key finding that although
deep-thin models generally achieve better accuracy under the same parameter
budget, they may not lie on the accuracy-latency trade-off frontier. Next, we
explore emerging efficient attention alternatives to evaluate their potential
as candidate building operators. Using the identified promising operators, we
construct an evolutionary search framework to automatically discover
latency-optimal combinations of these operators within hybrid SLMs, thereby
advancing the accuracy-latency frontier. In addition to architectural
improvements, we further enhance SLM training using a weight normalization
technique that enables more effective weight updates and improves final
convergence. Combining these methods, we introduce a new family of hybrid SLMs,
called Nemotron-Flash, which significantly advances the accuracy-efficiency
frontier of state-of-the-art SLMs, e.g., achieving over +5.5% average accuracy,
1.3x/1.9x lower latency, and 18.7x/45.6x higher throughput compared to
Qwen3-1.7B/0.6B, respectively.
\\ ( https://arxiv.org/abs/2511.18890 ,  5243kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18902
Date: Mon, 24 Nov 2025 08:59:54 GMT   (823kb)

Title: VADE: Variance-Aware Dynamic Sampling via Online Sample-Level Difficulty
 Estimation for Multimodal RL
Authors: Zengjie Hu and Jiantao Qiu and Tianyi Bai and Haojin Yang and Binhang
 Yuan and Qi Jing and Conghui He and Wentao Zhang
Categories: cs.LG cs.AI
\\
 Group-based policy optimization methods like GRPO and GSPO have become
standard for training multimodal models, leveraging group-wise rollouts and
relative advantage estimation. However, they suffer from a critical
\emph{gradient vanishing} problem when all responses within a group receive
identical rewards, causing advantage estimates to collapse and training signals
to diminish. Existing attempts to mitigate this issue fall into two paradigms:
filtering-based and sampling-based methods. Filtering-based methods first
generate rollouts broadly and then retroactively filter out uninformative
groups, leading to substantial computational overhead. Sampling-based methods
proactively select effective samples before rollout but rely on static criteria
or prior dataset knowledge, lacking real-time adaptability. To address these
issues, we propose \textbf{VADE}, a \textbf{V}ariance-\textbf{A}ware
\textbf{D}ynamic sampling framework via online sample-level difficulty
\textbf{E}stimation. Our framework integrates three key components: online
sample-level difficulty estimation using Beta distributions, a Thompson sampler
that maximizes information gain through the estimated correctness probability,
and a two-scale prior decay mechanism that maintains robust estimation under
policy evolution. This three components design enables VADE to dynamically
select the most informative samples, thereby amplifying training signals while
eliminating extra rollout costs. Extensive experiments on multimodal reasoning
benchmarks show that VADE consistently outperforms strong baselines in both
performance and sample efficiency, while achieving a dramatic reduction in
computational overhead. More importantly, our framework can serves as a
plug-and-play component to be seamlessly integrated into existing group-based
RL algorithms. Code and models are available at https://VADE-RL.github.io.
\\ ( https://arxiv.org/abs/2511.18902 ,  823kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18903
Date: Mon, 24 Nov 2025 09:03:49 GMT   (871kb)

Title: How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM
 Pretraining
Authors: Kairong Luo, Zhenbo Sun, Haodong Wen, Xinyu Shi, Jiarui Cui, Chenyi
 Dang, Kaifeng Lyu, Wenguang Chen
Categories: cs.LG cs.AI cs.CL
\\
 Due to the scarcity of high-quality data, large language models (LLMs) are
often trained on mixtures of data with varying quality levels, even after
sophisticated data curation. A natural approach to better leverage high-quality
data is curriculum-based pretraining, where the model is trained on data sorted
in ascending order of quality as determined by a quality metric. However, prior
studies have reported limited improvements from such curriculum-based
pretraining strategies. This work identifies a critical factor constraining
these methods: the incompatibility between the ascending data quality order and
the decaying learning rate (LR) schedule. We find that while curriculum-based
training substantially outperforms random shuffling when using a constant LR,
its advantage diminishes under standard LR decay schedules. Our experiments
show this incompatibility can be mitigated by two simple strategies: (1)
employing a more moderate LR decay schedule, where the final LR is only
moderately smaller than the peak LR, and (2) replacing LR decay with model
averaging, i.e., computing a weighted average of the final few checkpoints. By
combining these strategies, we improve the average score on a suite of standard
benchmarks by 1.64% over random shuffling, without additional data refinement.
Validated on 1.5B-parameter models trained over 30B tokens with various
data-quality metrics, our findings call for a re-evaluation of curriculum-based
LLM pretraining and underscore the potential of co-designing data curricula
with optimization methods.
\\ ( https://arxiv.org/abs/2511.18903 ,  871kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18930
Date: Mon, 24 Nov 2025 09:35:10 GMT   (176kb)

Title: Learning Solution Operators for Partial Differential Equations via Monte
 Carlo-Type Approximation
Authors: Salah Eddine Choutri, Prajwal Chauhan, Othmane Mazhar and Saif Eddin
 Jabari
Categories: cs.LG cs.AI
Comments: NeurIPS 2025 Workshop on Machine Learning and the Physical Sciences
\\
 The Monte Carlo-type Neural Operator (MCNO) introduces a lightweight
architecture for learning solution operators for parametric PDEs by directly
approximating the kernel integral using a Monte Carlo approach. Unlike Fourier
Neural Operators, MCNO makes no spectral or translation-invariance assumptions.
The kernel is represented as a learnable tensor over a fixed set of randomly
sampled points. This design enables generalization across multiple grid
resolutions without relying on fixed global basis functions or repeated
sampling during training. Experiments on standard 1D PDE benchmarks show that
MCNO achieves competitive accuracy with low computational cost, providing a
simple and practical alternative to spectral and graph-based neural operators.
\\ ( https://arxiv.org/abs/2511.18930 ,  176kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18936
Date: Mon, 24 Nov 2025 09:41:24 GMT   (1833kb)

Title: SWAN: Sparse Winnowed Attention for Reduced Inference Memory via
 Decompression-Free KV-Cache Compression
Authors: Santhosh G S, Saurav Prakash, Balaraman Ravindran
Categories: cs.LG cs.AI cs.CL
\\
 Large Language Models (LLMs) face a significant bottleneck during
autoregressive inference due to the massive memory footprint of the Key-Value
(KV) cache. Existing compression techniques like token eviction, quantization,
or other low-rank methods often risk information loss, have fixed limits, or
introduce significant computational overhead from explicit decompression steps.
In this work, we introduce SWAN, a novel, fine-tuning-free framework that
eliminates this overhead. Our method uses an offline orthogonal matrix to
rotate and prune the KV-cache, which is then used directly in the attention
computation without any reconstruction. Our extensive experiments demonstrate
that SWAN, augmented with a small dense buffer, offers a robust trade-off,
maintaining performance close to the uncompressed baseline even at aggressive
50-60% memory savings per-token on KV-cache. A key advantage is its
runtime-tunable compression level, allowing operators to dynamically adjust the
memory footprint, a flexibility absent in methods requiring fixed offline
configurations. This combination of a decompression-free design, high
performance under compression, and adaptability makes SWAN a practical and
efficient solution for serving LLMs with long contexts.
\\ ( https://arxiv.org/abs/2511.18936 ,  1833kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18940
Date: Mon, 24 Nov 2025 09:46:55 GMT   (1373kb)

Title: Geometry-Aware Deep Congruence Networks for Manifold Learning in
 Cross-Subject Motor Imagery
Authors: Sanjeev Manivannan (1), Chandrashekar Lakshminarayan (1) ((1) Indian
 Institute of Technology Madras)
Categories: cs.LG stat.ML
Comments: 10 pages, 2 figures
\\
 Cross-subject motor-imagery decoding remains a major challenge in EEG-based
brain-computer interfaces due to strong subject variability and the curved
geometry of covariance matrices on the symmetric positive definite (SPD)
manifold. We address the zero-shot cross-subject setting, where no
target-subject labels or adaptation are allowed, by introducing novel
geometry-aware preprocessing modules and deep congruence networks that operate
directly on SPD covariance matrices. Our preprocessing modules, DCR and RiFU,
extend Riemannian Alignment by improving action separation while reducing
subject-specific distortions. We further propose two manifold classifiers,
SPD-DCNet and RiFUNet, which use hierarchical congruence transforms to learn
discriminative, subject-invariant covariance representations. On the BCI-IV 2a
benchmark, our framework improves cross-subject accuracy by 3-4% over the
strongest classical baselines, demonstrating the value of geometry-aware
transformations for robust EEG decoding.
\\ ( https://arxiv.org/abs/2511.18940 ,  1373kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18945
Date: Mon, 24 Nov 2025 09:55:28 GMT   (6768kb)

Title: MIST: Mutual Information Via Supervised Training
Authors: German Gritsai, Megan Richards, Maxime M\'eloux, Kyunghyun Cho, Maxime
 Peyrard
Categories: cs.LG cs.IT math.IT
\\
 We propose a fully data-driven approach to designing mutual information (MI)
estimators. Since any MI estimator is a function of the observed sample from
two random variables, we parameterize this function with a neural network
(MIST) and train it end-to-end to predict MI values. Training is performed on a
large meta-dataset of 625,000 synthetic joint distributions with known
ground-truth MI. To handle variable sample sizes and dimensions, we employ a
two-dimensional attention scheme ensuring permutation invariance across input
samples. To quantify uncertainty, we optimize a quantile regression loss,
enabling the estimator to approximate the sampling distribution of MI rather
than return a single point estimate. This research program departs from prior
work by taking a fully empirical route, trading universal theoretical
guarantees for flexibility and efficiency. Empirically, the learned estimators
largely outperform classical baselines across sample sizes and dimensions,
including on joint distributions unseen during training. The resulting
quantile-based intervals are well-calibrated and more reliable than
bootstrap-based confidence intervals, while inference is orders of magnitude
faster than existing neural baselines. Beyond immediate empirical gains, this
framework yields trainable, fully differentiable estimators that can be
embedded into larger learning pipelines. Moreover, exploiting MI's invariance
to invertible transformations, meta-datasets can be adapted to arbitrary data
modalities via normalizing flows, enabling flexible training for diverse target
meta-distributions.
\\ ( https://arxiv.org/abs/2511.18945 ,  6768kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18958
Date: Mon, 24 Nov 2025 10:19:58 GMT   (485kb)

Title: Learning to Compress Graphs via Dual Agents for Consistent Topological
 Robustness Evaluation
Authors: Qisen Chai, Yansong Wang, Junjie Huang, Tao Jia
Categories: cs.LG cs.AI
\\
 As graph-structured data grow increasingly large, evaluating their robustness
under adversarial attacks becomes computationally expensive and difficult to
scale. To address this challenge, we propose to compress graphs into compact
representations that preserve both topological structure and robustness
profile, enabling efficient and reliable evaluation.We propose Cutter, a
dual-agent reinforcement learning framework composed of a Vital Detection Agent
(VDA) and a Redundancy Detection Agent (RDA), which collaboratively identify
structurally vital and redundant nodes for guided compression. Cutter
incorporates three key strategies to enhance learning efficiency and
compression quality: trajectory-level reward shaping to transform sparse
trajectory returns into dense, policy-equivalent learning signals;
prototype-based shaping to guide decisions using behavioral patterns from both
highand low-return trajectories; and cross-agent imitation to enable safer and
more transferable exploration. Experiments on multiple real-world graphs
demonstrate that Cutter generates compressed graphs that retain essential
static topological properties and exhibit robustness degradation trends highly
consistent with the original graphs under various attack scenarios, thereby
significantly improving evaluation efficiency without compromising assessment
fidelity.
\\ ( https://arxiv.org/abs/2511.18958 ,  485kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18960
Date: Mon, 24 Nov 2025 10:22:28 GMT   (27403kb)

Title: AVA-VLA: Improving Vision-Language-Action models with Active Visual
 Attention
Authors: Lei Xiao, Jifeng Li, Juntao Gao, Feiyang Ye, Yan Jin, Jingjing Qian,
 Jing Zhang, Yong Wu, Xiaoyuan Yu
Categories: cs.LG cs.CV cs.RO
Comments: 18 pages, 10 figures
\\
 Vision-Language-Action (VLA) models have demonstrated remarkable capabilities
in embodied AI tasks. However, existing VLA models, often built upon
Vision-Language Models (VLMs), typically process dense visual inputs
independently at each timestep. This approach implicitly models the task as a
Markov Decision Process (MDP). However, this history-agnostic design is
suboptimal for effective visual token processing in dynamic sequential
decision-making, as it fails to leverage the context of history. To address
this limitation, we reformulate the problem from a Partially Observable Markov
Decision Process (POMDP) perspective and propose a novel framework named
AVA-VLA. Inspired by the POMDP that the action generation should be conditioned
on the belief state. AVA-VLA introduces Active Visual Attention (AVA) to
dynamically modulate visual processing. It achieves this by leveraging the
recurrent state, which is a neural approximation of the agent's belief state
derived from the previous decision step. Specifically, the AVA module uses the
recurrent state to compute the soft weights to actively process task-relevant
visual tokens based on its historical context. Comprehensive evaluations
demonstrate that AVA-VLA achieves state-of-the-art performance across popular
robotic benchmarks, including LIBERO and CALVIN. Furthermore, real-world
deployments on a dual-arm robot platform validate the framework's practical
applicability and robust sim-to-real transferability.
\\ ( https://arxiv.org/abs/2511.18960 ,  27403kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18977
Date: Mon, 24 Nov 2025 10:47:55 GMT   (565kb)

Title: FastForward Pruning: Efficient LLM Pruning via Single-Step Reinforcement
 Learning
Authors: Xin Yuan, Siqi Li, Jiateng Wei, Chengrui Zhu, Yanming Wu, Qingpeng Li,
 Jiajun Lv, Xiaoke Lan, Jun Chen, Yong Liu
Categories: cs.LG cs.AI
Comments: 5 pages, 2 figures, 4 tables
ACM-class: I.2.7; I.2.6
\\
 Pruning is an effective method for compressing Large Language Models, but
finding an optimal, non-uniform layer-wise sparsity allocation remains a key
challenge. While heuristic methods are fast but yield suboptimal performance,
more powerful search-based approaches like Reinforcement Learning are often
hindered by prohibitive computational costs on large-scale models. To overcome
this efficiency barrier, we propose FastForward Pruning. Its core is a
decoupled, single-step RL framework that separates policy optimization from the
complex budget satisfaction problem. Such a decoupling is crucial for
efficiently searching the vast policy space of LLMs. This curriculum-based
strategy begins with low-cost, simple tasks and gradually increases in
complexity, significantly reducing the search's computational overhead.
Evaluated on the LLaMA, Mistral, and OPT model families, our framework
discovers pruning policies that achieve superior performance over strong
heuristic baselines. Crucially, when compared to other search-based algorithms,
our method achieves competitive or superior results at a fraction of the
computational cost, demonstrating a clear advantage in search efficiency.
\\ ( https://arxiv.org/abs/2511.18977 ,  565kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18987
Date: Mon, 24 Nov 2025 11:00:32 GMT   (1370kb)

Title: Dynamic Mixture of Experts Against Severe Distribution Shifts
Authors: Donghu Kim
Categories: cs.LG cs.AI
\\
 The challenge of building neural networks that can continuously learn and
adapt to evolving data streams is central to the fields of continual learning
(CL) and reinforcement learning (RL). This lifelong learning problem is often
framed in terms of the plasticity-stability dilemma, focusing on issues like
loss of plasticity and catastrophic forgetting. Unlike neural networks,
biological brains maintain plasticity through capacity growth, inspiring
researchers to explore similar approaches in artificial networks, such as
adding capacity dynamically. Prior solutions often lack parameter efficiency or
depend on explicit task indices, but Mixture-of-Experts (MoE) architectures
offer a promising alternative by specializing experts for distinct
distributions. This paper aims to evaluate a DynamicMoE approach for continual
and reinforcement learning environments and benchmark its effectiveness against
existing network expansion methods.
\\ ( https://arxiv.org/abs/2511.18987 ,  1370kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19019
Date: Mon, 24 Nov 2025 11:47:17 GMT   (5711kb)

Title: 3D Dynamic Radio Map Prediction Using Vision Transformers for
 Low-Altitude Wireless Networks
Authors: Nguyen Duc Minh Quang, Chang Liu, Huy-Trung Nguyen, Shuangyang Li,
 Derrick Wing Kwan Ng, and Wei Xiang
Categories: cs.LG
Comments: 7 pages, 4 figures, submitted to IEEE ICC 2026
\\
 Low-altitude wireless networks (LAWN) are rapidly expanding with the growing
deployment of unmanned aerial vehicles (UAVs) for logistics, surveillance, and
emergency response. Reliable connectivity remains a critical yet challenging
task due to three-dimensional (3D) mobility, time-varying user density, and
limited power budgets. The transmit power of base stations (BSs) fluctuates
dynamically according to user locations and traffic demands, leading to a
highly non-stationary 3D radio environment. Radio maps (RMs) have emerged as an
effective means to characterize spatial power distributions and support
radio-aware network optimization. However, most existing works construct static
or offline RMs, overlooking real-time power variations and spatio-temporal
dependencies in multi-UAV networks. To overcome this limitation, we propose a
{3D dynamic radio map (3D-DRM)} framework that learns and predicts the
spatio-temporal evolution of received power. Specially, a Vision Transformer
(ViT) encoder extracts high-dimensional spatial representations from 3D RMs,
while a Transformer-based module models sequential dependencies to predict
future power distributions. Experiments unveil that 3D-DRM accurately captures
fast-varying power dynamics and substantially outperforms baseline models in
both RM reconstruction and short-term prediction.
\\ ( https://arxiv.org/abs/2511.19019 ,  5711kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19023
Date: Mon, 24 Nov 2025 11:59:31 GMT   (1038kb)

Title: OrdMoE: Preference Alignment via Hierarchical Expert Group Ranking in
 Multimodal Mixture-of-Experts LLMs
Authors: Yuting Gao, Weihao Chen, Lan Wang, Ruihan Xu, Qingpei Guo
Categories: cs.LG cs.AI
\\
 Preference learning has recently emerged as a pivotal strategy for
post-training alignment of Multimodal Large Language Models (MLLMs). However,
existing approaches predominantly rely on external human-annotated preference
data, which is costly and labor-intensive to collect. In this work, we propose
OrdMoE, a novel preference alignment framework that bypasses the reliance on
external human preferences entirely by leveraging intrinsic signals within
Mixture-of-Experts (MoE) architectures. Specifically, we observe that the
router's expert selection scores implicitly encode a quality-aware ranking of
responses (i.e. higher-scoring experts consistently generate higher-quality
outputs). Building on this insight, OrdMoE constructs an internal preference
hierarchy by grouping experts into ranked tiers based on their per-token
routing scores and activating each tier separately to produce a sequence of
responses with increasing quality. This yields a zero-cost, self-supervised
preference ordering over generated responses, which can be directly optimized
using standard preference learning objectives. Extensive experiments across
multiple multimodal benchmarks demnstrate that OrdMoE significantly enhances
both alignment and overall performance of multimodal Mixture-of-Experts LLMs,
achieving competitive results without requiring any human-annotated preference
data.
\\ ( https://arxiv.org/abs/2511.19023 ,  1038kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19037
Date: Mon, 24 Nov 2025 12:20:36 GMT   (318kb)

Title: Resolving Node Identifiability in Graph Neural Processes via Laplacian
 Spectral Encodings
Authors: Zimo Yan, Zheng Xie, Chang Liu, Yuan Wang
Categories: cs.LG math.PR
\\
 Message passing graph neural networks are widely used for learning on graphs,
yet their expressive power is limited by the one-dimensional Weisfeiler-Lehman
test and can fail to distinguish structurally different nodes. We provide
rigorous theory for a Laplacian positional encoding that is invariant to
eigenvector sign flips and to basis rotations within eigenspaces. We prove that
this encoding yields node identifiability from a constant number of
observations and establishes a sample-complexity separation from architectures
constrained by the Weisfeiler-Lehman test. The analysis combines a monotone
link between shortest-path and diffusion distance, spectral trilateration with
a constant set of anchors, and quantitative spectral injectivity with
logarithmic embedding size. As an instantiation, pairing this encoding with a
neural-process style decoder yields significant gains on a drug-drug
interaction task on chemical graphs, improving both the area under the ROC
curve and the F1 score and demonstrating the practical benefits of resolving
theoretical expressiveness limitations with principled positional information.
\\ ( https://arxiv.org/abs/2511.19037 ,  318kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19066
Date: Mon, 24 Nov 2025 13:01:18 GMT   (305kb)

Title: Mitigating Participation Imbalance Bias in Asynchronous Federated
 Learning
Authors: Xiangyu Chang, Manyi Yao, Srikanth V. Krishnamurthy, Christian R.
 Shelton, Anirban Chakraborty, Ananthram Swami, Samet Oymak, Amit
 Roy-Chowdhury
Categories: cs.LG cs.AI
\\
 In Asynchronous Federated Learning (AFL), the central server immediately
updates the global model with each arriving client's contribution. As a result,
clients perform their local training on different model versions, causing
information staleness (delay). In federated environments with non-IID local
data distributions, this asynchronous pattern amplifies the adverse effect of
client heterogeneity (due to different data distribution, local objectives,
etc.), as faster clients contribute more frequent updates, biasing the global
model. We term this phenomenon heterogeneity amplification. Our work provides a
theoretical analysis that maps AFL design choices to their resulting error
sources when heterogeneity amplification occurs. Guided by our analysis, we
propose ACE (All-Client Engagement AFL), which mitigates participation
imbalance through immediate, non-buffered updates that use the latest
information available from all clients. We also introduce a delay-aware
variant, ACED, to balance client diversity against update staleness.
Experiments on different models for different tasks across diverse
heterogeneity and delay settings validate our analysis and demonstrate the
robust performance of our approaches.
\\ ( https://arxiv.org/abs/2511.19066 ,  305kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19087
Date: Mon, 24 Nov 2025 13:27:41 GMT   (47157kb)

Title: EnfoPath: Energy-Informed Analysis of Generative Trajectories in Flow
 Matching
Authors: Ziyun Li, Ben Dai, Huancheng Hu, Henrik Bostr\"om, Soon Hoe Lim
Categories: cs.LG cs.AI
Comments: EurIPS 2025 Workshop on Principles of Generative Modeling (PriGM)
\\
 Flow-based generative models synthesize data by integrating a learned
velocity field from a reference distribution to the target data distribution.
Prior work has focused on endpoint metrics (e.g., fidelity, likelihood,
perceptual quality) while overlooking a deeper question: what do the sampling
trajectories reveal? Motivated by classical mechanics, we introduce kinetic
path energy (KPE), a simple yet powerful diagnostic that quantifies the total
kinetic effort along each generation path of ODE-based samplers. Through
comprehensive experiments on CIFAR-10 and ImageNet-256, we uncover two key
phenomena: ({i}) higher KPE predicts stronger semantic quality, indicating that
semantically richer samples require greater kinetic effort, and ({ii}) higher
KPE inversely correlates with data density, with informative samples residing
in sparse, low-density regions. Together, these findings reveal that
semantically informative samples naturally reside on the sparse frontier of the
data distribution, demanding greater generative effort. Our results suggest
that trajectory-level analysis offers a physics-inspired and interpretable
framework for understanding generation difficulty and sample characteristics.
\\ ( https://arxiv.org/abs/2511.19087 ,  47157kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19090
Date: Mon, 24 Nov 2025 13:30:52 GMT   (1600kb)

Title: Optimization of Deep Learning Models for Dynamic Market Behavior
 Prediction
Authors: Shenghan Zhao, Yuzhen Lin, Ximeng Yang, Qiaochu Lu, Haozhong Xue,
 Gaozhe Jiang
Categories: cs.LG
\\
 The advent of financial technology has witnessed a surge in the utilization
of deep learning models to anticipate consumer conduct, a trend that has
demonstrated considerable potential in enhancing lending strategies and
bolstering market efficiency. We study multi-horizon demand forecasting on
e-commerce transactions using the UCI Online Retail II dataset. Unlike prior
versions of this manuscript that mixed financial-loan narratives with retail
data, we focus exclusively on retail market behavior and define a clear
prediction target: per SKU daily demand (or revenue) for horizons H=1,7,14. We
present a hybrid sequence model that combines multi-scale temporal
convolutions, a gated recurrent module, and time-aware self-attention. The
model is trained with standard regression losses and evaluated under MAE, RMSE,
sMAPE, MASE, and Theil's U_2 with strict time-based splits to prevent leakage.
We benchmark against ARIMA/Prophet, LSTM/GRU, LightGBM, and state-of-the-art
Transformer forecasters (TFT, Informer, Autoformer, N-BEATS). Results show
consistent accuracy gains and improved robustness on peak/holiday periods. We
further provide ablations and statistical significance tests to ensure the
reliability of improvements, and we release implementation details to
facilitate reproducibility.
\\ ( https://arxiv.org/abs/2511.19090 ,  1600kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19103
Date: Mon, 24 Nov 2025 13:37:33 GMT   (1120kb)

Title: Edge-Based Predictive Data Reduction for Smart Agriculture: A
 Lightweight Approach to Efficient IoT Communication
Authors: Dora Krekovic, Mario Kusek, Ivana Podnar Zarko, Danh Le-Phuoc
Categories: cs.LG
Comments: Accepted for presentation and publication in the proceedings of the
 IEEE Annual Congress on Artificial Intelligence of Things (IEEE AIoT 2025)
\\
 The rapid growth of IoT devices has led to an enormous amount of sensor data
that requires transmission to cloud servers for processing, resulting in
excessive network congestion, increased latency and high energy consumption.
This is particularly problematic in resource-constrained and remote
environments where bandwidth is limited, and battery-dependent devices further
emphasize the problem. Moreover, in domains such as agriculture, consecutive
sensor readings often have minimal variation, making continuous data
transmission inefficient and unnecessarily resource intensive. To overcome
these challenges, we propose an analytical prediction algorithm designed for
edge computing environments and validated through simulation. The proposed
solution utilizes a predictive filter at the network edge that forecasts the
next sensor data point and triggers data transmission only when the deviation
from the predicted value exceeds a predefined tolerance. A complementary
cloud-based model ensures data integrity and overall system consistency. This
dual-model strategy effectively reduces communication overhead and demonstrates
potential for improving energy efficiency by minimizing redundant
transmissions. In addition to reducing communication load, our approach
leverages both in situ and satellite observations from the same locations to
enhance model robustness. It also supports cross-site generalization, enabling
models trained in one region to be effectively deployed elsewhere without
retraining. This makes our solution highly scalable, energy-aware, and
well-suited for optimizing sensor data transmission in remote and
bandwidth-constrained IoT environments.
\\ ( https://arxiv.org/abs/2511.19103 ,  1120kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19107
Date: Mon, 24 Nov 2025 13:42:43 GMT   (12kb)

Title: The Core in Max-Loss Non-Centroid Clustering Can Be Empty
Authors: Robert Bredereck, Eva Deltl, Leon Kellerhals, Jannik Peters
Categories: cs.LG cs.AI cs.GT stat.ML
\\
 We study core stability in non-centroid clustering under the max-loss
objective, where each agent's loss is the maximum distance to other members of
their cluster. We prove that for all $k\geq 3$ there exist metric instances
with $n\ge 9$ agents, with $n$ divisible by $k$, for which no clustering lies
in the $\alpha$-core for any $\alpha<2^{\frac{1}{5}}\sim 1.148$. The bound is
tight for our construction. Using a computer-aided proof, we also identify a
two-dimensional Euclidean point set whose associated lower bound is slightly
smaller than that of our general construction. This is, to our knowledge, the
first impossibility result showing that the core can be empty in non-centroid
clustering under the max-loss objective.
\\ ( https://arxiv.org/abs/2511.19107 ,  12kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19124
Date: Mon, 24 Nov 2025 13:53:31 GMT   (992kb)

Title: Uncertainty-Aware Deep Learning Framework for Remaining Useful Life
 Prediction in Turbofan Engines with Learned Aleatoric Uncertainty
Authors: Krishang Sharma
Categories: cs.LG cs.AI
Comments: 10 pages, 2 figures, 3 tables. Submitted to arXiv
\\
 Accurate Remaining Useful Life (RUL) prediction coupled with uncertainty
quantification remains a critical challenge in aerospace prognostics. This
research introduces a novel uncertainty-aware deep learning framework that
learns aleatoric uncertainty directly through probabilistic modeling, an
approach unexplored in existing CMAPSS-based literature. Our hierarchical
architecture integrates multi-scale Inception blocks for temporal pattern
extraction, bidirectional Long Short-Term Memory networks for sequential
modeling, and a dual-level attention mechanism operating simultaneously on
sensor and temporal dimensions. The innovation lies in the Bayesian output
layer that predicts both mean RUL and variance, enabling the model to learn
data-inherent uncertainty. Comprehensive preprocessing employs condition-aware
clustering, wavelet denoising, and intelligent feature selection. Experimental
validation on NASA CMAPSS benchmarks (FD001-FD004) demonstrates competitive
overall performance with RMSE values of 16.22, 19.29, 16.84, and 19.98
respectively. Remarkably, our framework achieves breakthrough critical zone
performance (RUL <= 30 cycles) with RMSE of 5.14, 6.89, 5.27, and 7.16,
representing 25-40 percent improvements over conventional approaches and
establishing new benchmarks for safety-critical predictions. The learned
uncertainty provides well-calibrated 95 percent confidence intervals with
coverage ranging from 93.5 percent to 95.2 percent, enabling risk-aware
maintenance scheduling previously unattainable in CMAPSS literature.
\\ ( https://arxiv.org/abs/2511.19124 ,  992kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19152
Date: Mon, 24 Nov 2025 14:17:56 GMT   (127kb)

Title: Masked Diffusion Models are Secretly Learned-Order Autoregressive Models
Authors: Prateek Garg, Bhavya Kohli, Sunita Sarawagi
Categories: cs.LG stat.ML
Comments: Accepted at EurIPS 2025 Workshop on Principles of Generative Modeling
 (PriGM)
\\
 Masked Diffusion Models (MDMs) have emerged as one of the most promising
paradigms for generative modeling over discrete domains. It is known that MDMs
effectively train to decode tokens in a random order, and that this ordering
has significant performance implications in practice. This observation raises a
fundamental question: can we design a training framework that optimizes for a
favorable decoding order? We answer this in the affirmative, showing that the
continuous-time variational objective of MDMs, when equipped with multivariate
noise schedules, can identify and optimize for a decoding order during
training. We establish a direct correspondence between decoding order and the
multivariate noise schedule and show that this setting breaks invariance of the
MDM objective to the noise schedule. Furthermore, we prove that the MDM
objective decomposes precisely into a weighted auto-regressive losses over
these orders, which establishes them as auto-regressive models with learnable
orders.
\\ ( https://arxiv.org/abs/2511.19152 ,  127kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19165
Date: Mon, 24 Nov 2025 14:28:49 GMT   (139kb)

Title: First-order Sobolev Reinforcement Learning
Authors: Fabian Schramm, Nicolas Perrin-Gilbert, Justin Carpentier
Categories: cs.LG cs.RO
Comments: Workshop paper at Differentiable Systems and Scientific Machine
 Learning, EurIPS 2025
\\
 We propose a refinement of temporal-difference learning that enforces
first-order Bellman consistency: the learned value function is trained to match
not only the Bellman targets in value but also their derivatives with respect
to states and actions. By differentiating the Bellman backup through
differentiable dynamics, we obtain analytically consistent gradient targets.
Incorporating these into the critic objective using a Sobolev-type loss
encourages the critic to align with both the value and local geometry of the
target function. This first-order TD matching principle can be seamlessly
integrated into existing algorithms, such as Q-learning or actor-critic methods
(e.g., DDPG, SAC), potentially leading to faster critic convergence and more
stable policy gradients without altering their overall structure.
\\ ( https://arxiv.org/abs/2511.19165 ,  139kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19168
Date: Mon, 24 Nov 2025 14:32:13 GMT   (232kb)

Title: RAVEN++: Pinpointing Fine-Grained Violations in Advertisement Videos
 with Active Reinforcement Reasoning
Authors: Deyi Ji, Yuekui Yang, Liqun Liu, Peng Shu, Haiyang Wu, Shaogang Tang,
 Xudong Chen, Shaoping Ma, Tianrun Chen, Lanyun Zhu
Categories: cs.LG cs.CL
Comments: EMNLP 2025 (Oral, Industry Track)
\\
 Advertising (Ad) is a cornerstone of the digital economy, yet the moderation
of video advertisements remains a significant challenge due to their complexity
and the need for precise violation localization. While recent advancements,
such as the RAVEN model, have improved coarse-grained violation detection,
critical gaps persist in fine-grained understanding, explainability, and
generalization. To address these limitations, we propose RAVEN++, a novel
framework that introduces three key innovations: 1) Active Reinforcement
Learning (RL), which dynamically adapts training to samples of varying
difficulty; 2) Fine-Grained Violation Understanding, achieved through
hierarchical reward functions and reasoning distillation; and 3) Progressive
Multi-Stage Training, which systematically combines knowledge injection,
curriculum-based passive RL, and active RL. Extensive experiments on both
public and proprietary datasets, on both offline scenarios and online deployed
A/B Testing, demonstrate that RAVEN++ outperforms general-purpose LLMs and
specialized models like RAVEN in terms of fine-grained violation understanding,
reasoning capabilities, and generalization ability.
\\ ( https://arxiv.org/abs/2511.19168 ,  232kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19176
Date: Mon, 24 Nov 2025 14:37:22 GMT   (1303kb)

Title: From Raw Features to Effective Embeddings: A Three-Stage Approach for
 Multimodal Recipe Recommendation
Authors: Jeeho Shin, Kyungho Kim, Kijung Shin
Categories: cs.LG cs.IR
\\
 Recipe recommendation has become an essential task in web-based food
platforms. A central challenge is effectively leveraging rich multimodal
features beyond user-recipe interactions. Our analysis shows that even simple
uses of multimodal signals yield competitive performance, suggesting that
systematic enhancement of these signals is highly promising. We propose TESMR,
a 3-stage framework for recipe recommendation that progressively refines raw
multimodal features into effective embeddings through: (1) content-based
enhancement using foundation models with multimodal comprehension, (2)
relation-based enhancement via message propagation over user-recipe
interactions, and (3) learning-based enhancement through contrastive learning
with learnable embeddings. Experiments on two real-world datasets show that
TESMR outperforms existing methods, achieving 7-15% higher Recall@10.
\\ ( https://arxiv.org/abs/2511.19176 ,  1303kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19240
Date: Mon, 24 Nov 2025 15:52:02 GMT   (1194kb)

Title: Empirical Comparison of Forgetting Mechanisms for UCB-based Algorithms
 on a Data-Driven Simulation Platform
Authors: Minxin Chen
Categories: cs.LG
\\
 Many real-world bandit problems involve non-stationary reward distributions,
where the optimal decision may shift due to evolving environments. However, the
performance of some typical Multi-Armed Bandit (MAB) models such as Upper
Confidence Bound (UCB) algorithms degrades significantly in non-stationary
environments where reward distributions change over time. To address this
limitation, this paper introduces and evaluates FDSW-UCB, a novel dual-view
algorithm that integrates a discount-based long-term perspective with a
sliding-window-based short-term view. A data-driven semi-synthetic simulation
platform, built upon the MovieLens-1M and Open Bandit datasets, is developed to
test algorithm adaptability under abrupt and gradual drift scenarios.
Experimental results demonstrate that a well-configured sliding-window
mechanism (SW-UCB) is robust, while the widely used discounting method (D-UCB)
suffers from a fundamental learning failure, leading to linear regret.
Crucially, the proposed FDSW-UCB, when employing an optimistic aggregation
strategy, achieves superior performance in dynamic settings, highlighting that
the ensemble strategy itself is a decisive factor for success.
\\ ( https://arxiv.org/abs/2511.19240 ,  1194kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19241
Date: Mon, 24 Nov 2025 15:52:17 GMT   (5742kb)

Title: Local Entropy Search over Descent Sequences for Bayesian Optimization
Authors: David Stenger, Armin Lindicke, Alexander von Rohr, Sebastian Trimpe
Categories: cs.LG cs.AI stat.ML
\\
 Searching large and complex design spaces for a global optimum can be
infeasible and unnecessary. A practical alternative is to iteratively refine
the neighborhood of an initial design using local optimization methods such as
gradient descent. We propose local entropy search (LES), a Bayesian
optimization paradigm that explicitly targets the solutions reachable by the
descent sequences of iterative optimizers. The algorithm propagates the
posterior belief over the objective through the optimizer, resulting in a
probability distribution over descent sequences. It then selects the next
evaluation by maximizing mutual information with that distribution, using a
combination of analytic entropy calculations and Monte-Carlo sampling of
descent sequences. Empirical results on high-complexity synthetic objectives
and benchmark problems show that LES achieves strong sample efficiency compared
to existing local and global Bayesian optimization methods.
\\ ( https://arxiv.org/abs/2511.19241 ,  5742kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19253
Date: Mon, 24 Nov 2025 16:05:37 GMT   (1519kb)

Title: MAESTRO: Multi-Agent Environment Shaping through Task and Reward
 Optimization
Authors: Boyuan Wu
Categories: cs.LG cs.AI
Comments: Preprint. 16 pages, 6 figures. Preliminary version; extended
 experiments and analysis forthcoming
\\
 Cooperative Multi-Agent Reinforcement Learning (MARL) faces two major design
bottlenecks: crafting dense reward functions and constructing curricula that
avoid local optima in high-dimensional, non-stationary environments. Existing
approaches rely on fixed heuristics or use Large Language Models (LLMs)
directly in the control loop, which is costly and unsuitable for real-time
systems. We propose MAESTRO (Multi-Agent Environment Shaping through Task and
Reward Optimization), a framework that moves the LLM outside the execution loop
and uses it as an offline training architect. MAESTRO introduces two generative
components: (i) a semantic curriculum generator that creates diverse,
performance-driven traffic scenarios, and (ii) an automated reward synthesizer
that produces executable Python reward functions adapted to evolving curriculum
difficulty. These components guide a standard MARL backbone (MADDPG) without
increasing inference cost at deployment. We evaluate MAESTRO on large-scale
traffic signal control (Hangzhou, 16 intersections) and conduct controlled
ablations. Results show that combining LLM-generated curricula with
LLM-generated reward shaping yields improved performance and stability. Across
four seeds, the full system achieves +4.0% higher mean return (163.26 vs.
156.93) and 2.2% better risk-adjusted performance (Sharpe 1.53 vs. 0.70) over a
strong curriculum baseline. These findings highlight LLMs as effective
high-level designers for cooperative MARL training.
\\ ( https://arxiv.org/abs/2511.19253 ,  1519kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19260
Date: Mon, 24 Nov 2025 16:12:03 GMT   (759kb)

Title: A Nutrition Multimodal Photoplethysmography Language Model
Authors: Kyle Verrier, Achille Nazaret, Joseph Futoma, Andrew C. Miller,
 Guillermo Sapiro
Categories: cs.LG cs.AI cs.CL
Comments: 21 pages, 2 figures
\\
 Hunger and satiety dynamics shape dietary behaviors and metabolic health, yet
remain difficult to capture in everyday settings. We present a Nutrition
Photoplethysmography Language Model (NPLM), integrating continuous
photoplethysmography (PPG) from wearables with meal descriptions. NPLM projects
PPG into embeddings interpretable by language models, enabling joint reasoning
over physiology and meal context. Trained on 19,340 participants and 1.1
million meal-PPG pairs, the model improved daily caloric intake prediction by
11% over text-only baselines, with accuracy maintained when 80% of meal text
was removed. In an independent validation study (n=140) with controlled dining
and detailed meal information, the model replicated these findings. These
results demonstrate the value of integrating physiological measurements from
consumer wearables with meal information for noninvasive dietary monitoring at
scale.
\\ ( https://arxiv.org/abs/2511.19260 ,  759kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19263
Date: Mon, 24 Nov 2025 16:15:41 GMT   (573kb)

Title: Solar-GECO: Perovskite Solar Cell Property Prediction with
 Geometric-Aware Co-Attention
Authors: Lucas Li, Jean-Baptiste Puel, Florence Carton, Dounya Barrit, Jhony H.
 Giraldo
Categories: cs.LG cs.AI
Comments: Accepted at the AI for Accelerated Materials Design (AI4Mat) Workshop
 at NeurIPS 2025. 14 pages, 4 figures
\\
 Perovskite solar cells are promising candidates for next-generation
photovoltaics. However, their performance as multi-scale devices is determined
by complex interactions between their constituent layers. This creates a vast
combinatorial space of possible materials and device architectures, making the
conventional experimental-based screening process slow and expensive. Machine
learning models try to address this problem, but they only focus on individual
material properties or neglect the important geometric information of the
perovskite crystal. To address this problem, we propose to predict perovskite
solar cell power conversion efficiency with a geometric-aware co-attention
(Solar-GECO) model. Solar-GECO combines a geometric graph neural network (GNN)
- that directly encodes the atomic structure of the perovskite absorber - with
language model embeddings that process the textual strings representing the
chemical compounds of the transport layers and other device components.
Solar-GECO also integrates a co-attention module to capture intra-layer
dependencies and inter-layer interactions, while a probabilistic regression
head predicts both power conversion efficiency (PCE) and its associated
uncertainty. Solar-GECO achieves state-of-the-art performance, significantly
outperforming several baselines, reducing the mean absolute error (MAE) for PCE
prediction from 3.066 to 2.936 compared to semantic GNN (the previous
state-of-the-art model). Solar-GECO demonstrates that integrating geometric and
textual information provides a more powerful and accurate framework for PCE
prediction.
\\ ( https://arxiv.org/abs/2511.19263 ,  573kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19264
Date: Mon, 24 Nov 2025 16:16:18 GMT   (2156kb)

Title: Interpreting GFlowNets for Drug Discovery: Extracting Actionable
 Insights for Medicinal Chemistry
Authors: Amirtha Varshini A S, Duminda S. Ranasinghe, and Hok Hei Tam
Categories: cs.LG cs.AI q-bio.BM
Comments: 13 pages, 7 figures. Accepted for presentation at NeurIPS 2025 WiML
 Workshop and Molecular Machine Learning Conference (MoML) 2025
\\
 Generative Flow Networks, or GFlowNets, offer a promising framework for
molecular design, but their internal decision policies remain opaque. This
limits adoption in drug discovery, where chemists require clear and
interpretable rationales for proposed structures. We present an
interpretability framework for SynFlowNet, a GFlowNet trained on documented
chemical reactions and purchasable starting materials that generates both
molecules and the synthetic routes that produce them. Our approach integrates
three complementary components. Gradient based saliency combined with
counterfactual perturbations identifies which atomic environments influence
reward and how structural edits change molecular outcomes. Sparse autoencoders
reveal axis aligned latent factors that correspond to physicochemical
properties such as polarity, lipophilicity, and molecular size. Motif probes
show that functional groups including aromatic rings and halogens are
explicitly encoded and linearly decodable from the internal embeddings.
Together, these results expose the chemical logic inside SynFlowNet and provide
actionable and mechanistic insight that supports transparent and controllable
molecular design.
\\ ( https://arxiv.org/abs/2511.19264 ,  2156kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19265
Date: Mon, 24 Nov 2025 16:16:49 GMT   (425kb)

Title: Unboxing the Black Box: Mechanistic Interpretability for Algorithmic
 Understanding of Neural Networks
Authors: Bianka Kowalska and Halina Kwa\'snicka
Categories: cs.LG
\\
 The black box nature of deep neural networks poses a significant challenge
for the deployment of transparent and trustworthy artificial intelligence (AI)
systems. With the growing presence of AI in society, it becomes increasingly
important to develop methods that can explain and interpret the decisions made
by these systems. To address this, mechanistic interpretability (MI) emerged as
a promising and distinctive research program within the broader field of
explainable artificial intelligence (XAI). MI is the process of studying the
inner computations of neural networks and translating them into
human-understandable algorithms. It encompasses reverse engineering techniques
aimed at uncovering the computational algorithms implemented by neural
networks. In this article, we propose a unified taxonomy of MI approaches and
provide a detailed analysis of key techniques, illustrated with concrete
examples and pseudo-code. We contextualize MI within the broader
interpretability landscape, comparing its goals, methods, and insights to other
strands of XAI. Additionally, we trace the development of MI as a research
area, highlighting its conceptual roots and the accelerating pace of recent
work. We argue that MI holds significant potential to support a more scientific
understanding of machine learning systems -- treating models not only as tools
for solving tasks, but also as systems to be studied and understood. We hope to
invite new researchers into the field of mechanistic interpretability.
\\ ( https://arxiv.org/abs/2511.19265 ,  425kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19267
Date: Mon, 24 Nov 2025 16:19:48 GMT   (727kb)

Title: Leveraging Spatiotemporal Graph Neural Networks for Multi-Store Sales
 Forecasting
Authors: Manish Singh, Arpita Dayama
Categories: cs.LG
Comments: 6 pages, 4 figures, 1 table
\\
 This work evaluates the effectiveness of spatiotemporal Graph Neural Networks
(GNNs) for multi-store retail sales forecasting and compares their performance
against ARIMA, LSTM, and XGBoost baselines. Using weekly sales data from 45
Walmart stores, we construct a relational forecasting framework that models
inter-store dependencies through a learned adaptive graph. The proposed STGNN
predicts log-differenced sales and reconstructs final values through a residual
path, enabling stable training and improved generalisation. Experiments show
that STGNN achieves the lowest overall forecasting error, outperforming all
baselines in Normalised Total Absolute Error, P90 MAPE, and variance of MAPE
across stores. Analysis of the learned adjacency matrix reveals meaningful
functional store clusters and high-influence nodes that emerge without
geographic metadata. These results demonstrate that relational structure
significantly improves forecast quality in interconnected retail environments
and establishes STGNNs as a robust modelling choice for multi-store demand
prediction.
\\ ( https://arxiv.org/abs/2511.19267 ,  727kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19269
Date: Mon, 24 Nov 2025 16:21:25 GMT   (741kb)

Title: CDLM: Consistency Diffusion Language Models For Faster Sampling
Authors: Minseo Kim, Chenfeng Xu, Coleman Hooper, Harman Singh, Ben
 Athiwaratkun, Ce Zhang, Kurt Keutzer, Amir Gholami
Categories: cs.LG cs.CL
Comments: 18 pages, 6 figures
\\
 Diffusion Language Models (DLMs) offer a promising parallel generation
paradigm but suffer from slow inference due to numerous refinement steps and
the inability to use standard KV caching. We introduce CDLM (Consistency
Diffusion Language Models), a training-based acceleration method that
simultaneously tackles both bottlenecks. CDLM integrates consistency modeling
to drastically reduce the number of required sampling steps by enabling
multi-token finalization. Furthermore, we enforce a block-wise causal attention
mask during fine-tuning, making the model fully compatible with KV caching.
Experiments show CDLM achieves 3.6x-14.5x lower latency while maintaining
competitive accuracy on math and coding tasks. The full training and evaluation
code is available at https://github.com/SqueezeAILab/CDLM.
\\ ( https://arxiv.org/abs/2511.19269 ,  741kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19272
Date: Mon, 24 Nov 2025 16:22:05 GMT   (33089kb)

Title: Tiny-TSM: Efficiently Training a Lightweight SOTA Time Series Foundation
 Model
Authors: Felix Birkel
Categories: cs.LG
\\
 We present Tiny-TSM, a time series foundation model characterized by small
scale, economical training, and state-of-the-art performance. It comprises 23M
total parameters, trained on a single A100 GPU in less than a week using a new
synthetic data generation and data augmentation pipeline (SynthTS). Without any
neural architecture search, hyperparameter tuning, or scaling up model size,
Tiny-TSM achieves state-of-the-art performance on a wide range of time series
benchmark datasets, often outperforming much larger models and even matching
the performance of much larger, industrial-scale, likely highly tuned
foundation models. Specifically, Tiny-TSM outperforms all other time series
foundation models we evaluated on medium- and long-term forecasting tasks under
MSE loss, while short-term accuracy is still competitive with state-of-the-art
models.
 We also introduce a causal input normalization scheme that enables time
series models to be trained with dense next-token prediction loss,
significantly accelerating convergence speed and reducing training time.
 All experiments were conducted on a single A100 GPU, illustrating the
practicality of the proposed approach in a resource-constrained setting.
\\ ( https://arxiv.org/abs/2511.19272 ,  33089kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19273
Date: Mon, 24 Nov 2025 16:23:19 GMT   (160kb)

Title: Scalable Bayesian Network Structure Learning Using Tsetlin Machine to
 Constrain the Search Space
Authors: Kunal Dumbre, Lei Jiao, Ole-Christoffer Granmo
Categories: cs.LG
\\
 The PC algorithm is a widely used method in causal inference for learning the
structure of Bayesian networks. Despite its popularity, the PC algorithm
suffers from significant time complexity, particularly as the size of the
dataset increases, which limits its applicability in large-scale real-world
problems. In this study, we propose a novel approach that utilises the Tsetlin
Machine (TM) to construct Bayesian structures more efficiently. Our method
leverages the most significant literals extracted from the TM and performs
conditional independence (CI) tests on these selected literals instead of the
full set of variables, resulting in a considerable reduction in computational
time. We implemented our approach and compared it with various state-of-the-art
methods. Our evaluation includes categorical datasets from the bnlearn
repository, such as Munin1, Hepar2. The findings indicate that the proposed
TM-based method not only reduces computational complexity but also maintains
competitive accuracy in causal discovery, making it a viable alternative to
traditional PC algorithm implementations by offering improved efficiency
without compromising performance.
\\ ( https://arxiv.org/abs/2511.19273 ,  160kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19277
Date: Mon, 24 Nov 2025 16:28:44 GMT   (903kb)

Title: Closing Gaps in Emissions Monitoring with Climate TRACE
Authors: Brittany V. Lancellotti, Jordan M. Malof, Aaron Davitt, Gavin
 McCormick, Shelby Anderson, Pol Carb\'o-Mestre, Gary Collins, Verity Crane,
 Zoheyr Doctor, George Ebri, Kevin Foster, Trey M. Gowdy, Michael Guzzardi,
 John Heal, Heather Hunter, David Kroodsma, Khandekar Mahammad Galib, Paul J.
 Markakis, Gavin McDonald, Daniel P. Moore, Eric D. Nguyen, Sabina Parvu,
 Michael Pekala, Christine D. Piatko, Amy Piscopo, Mark Powell, Krsna Raniga,
 Elizabeth P. Reilly, Michael Robinette, Ishan Saraswat, Patrick Sicurello,
 Isabella S\"oldner-Rembold, Raymond Song, Charlotte Underwood, and Kyle
 Bradbury
Categories: cs.LG
\\
 Global greenhouse gas emissions estimates are essential for monitoring and
mitigation planning. Yet most datasets lack one or more characteristics that
enhance their actionability, such as accuracy, global coverage, high spatial
and temporal resolution, and frequent updates. To address these gaps, we
present Climate TRACE (climatetrace.org), an open-access platform delivering
global emissions estimates with enhanced detail, coverage, and timeliness.
Climate TRACE synthesizes existing emissions data, prioritizing accuracy,
coverage, and resolution, and fills gaps using sector-specific estimation
approaches. The dataset is the first to provide globally comprehensive
emissions estimates for individual sources (e.g., individual power plants) for
all anthropogenic emitting sectors. The dataset spans January 1, 2021, to the
present, with a two-month reporting lag and monthly updates. The open-access
platform enables non-technical audiences to engage with detailed emissions
datasets for most subnational governments worldwide. Climate TRACE supports
data-driven climate action at scales where decisions are made, representing a
major breakthrough for emissions accounting and mitigation.
\\ ( https://arxiv.org/abs/2511.19277 ,  903kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19279
Date: Mon, 24 Nov 2025 16:29:02 GMT   (1265kb)

Title: MapFormer: Self-Supervised Learning of Cognitive Maps with
 Input-Dependent Positional Embeddings
Authors: Victor Rambaud, Salvador Mascarenhas, Yair Lakretz
Categories: cs.LG cs.CL
Comments: 19 pages (29 with appendix), 8 figures
\\
 A cognitive map is an internal model which encodes the abstract relationships
among entities in the world, giving humans and animals the flexibility to adapt
to new situations, with a strong out-of-distribution (OOD) generalization that
current AI systems still do not possess. To bridge this gap, we introduce
MapFormers, new architectures based on Transformer models, which can learn
cognitive maps from observational data and perform path integration in
parallel, in a self-supervised manner. Cognitive maps are learned in the model
by disentangling structural relationships in the inputs from their specific
content, a property that can be achieved naturally by updating the positional
encoding in Transformers with input-dependent matrices. We developed two
variants of MapFormers that unify absolute and relative positional encoding to
model episodic (EM) and working memory (WM), respectively. We tested MapFormers
on several tasks, including a classic 2D navigation task, showing that our
models can learn a cognitive map of the underlying space and generalize OOD
(e.g., to longer sequences) with near-perfect performance, unlike current
architectures. Together, these results demonstrate the superiority of models
designed to learn a cognitive map, and the importance of introducing a
structural bias for structure-content disentanglement, which can be achieved in
Transformers with input-dependent positional encoding. MapFormers have broad
applications in both neuroscience and AI, by explaining the neural mechanisms
giving rise to cognitive maps, while allowing these relation models to be
learned at scale.
\\ ( https://arxiv.org/abs/2511.19279 ,  1265kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19299
Date: Mon, 24 Nov 2025 16:46:44 GMT   (599kb)

Title: Open-weight genome language model safeguards: Assessing robustness via
 adversarial fine-tuning
Authors: James R. M. Black, Moritz S. Hanke, Aaron Maiwald, Tina
 Hernandez-Boussard, Oliver M. Crook, Jaspreet Pannu
Categories: cs.LG cs.AI
Comments: 39th Conference on Neural Information Processing Systems (NeurIPS
 2025) Workshop: Biosecurity Safeguards for Generative AI
\\
 Novel deep learning architectures are increasingly being applied to
biological data, including genetic sequences. These models, referred to as
genomic language mod- els (gLMs), have demonstrated impressive predictive and
generative capabilities, raising concerns that such models may also enable
misuse, for instance via the generation of genomes for human-infecting viruses.
These concerns have catalyzed calls for risk mitigation measures. The de facto
mitigation of choice is filtering of pretraining data (i.e., removing viral
genomic sequences from training datasets) in order to limit gLM performance on
virus-related tasks. However, it is not currently known how robust this
approach is for securing open-source models that can be fine-tuned using
sensitive pathogen data. Here, we evaluate a state-of-the-art gLM, Evo 2, and
perform fine-tuning using sequences from 110 harmful human-infecting viruses to
assess the rescue of misuse-relevant predictive capabilities. The fine- tuned
model exhibited reduced perplexity on unseen viral sequences relative to 1) the
pretrained model and 2) a version fine-tuned on bacteriophage sequences. The
model fine-tuned on human-infecting viruses also identified immune escape
variants from SARS-CoV-2 (achieving an AUROC of 0.6), despite having no expo-
sure to SARS-CoV-2 sequences during fine-tuning. This work demonstrates that
data exclusion might be circumvented by fine-tuning approaches that can, to
some degree, rescue misuse-relevant capabilities of gLMs. We highlight the need
for safety frameworks for gLMs and outline further work needed on evaluations
and mitigation measures to enable the safe deployment of gLMs.
\\ ( https://arxiv.org/abs/2511.19299 ,  599kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19328
Date: Mon, 24 Nov 2025 17:20:42 GMT   (18581kb)

Title: Understanding the Staged Dynamics of Transformers in Learning Latent
 Structure
Authors: Rohan Saha, Farzane Aminmansour, Alona Fyshe
Categories: cs.LG
Comments: Preprint
\\
 While transformers can discover latent structure from context, the dynamics
of how they acquire different components of the latent structure remain poorly
understood. In this work, we use the Alchemy benchmark, to investigate the
dynamics of latent structure learning. We train a small decoder-only
transformer on three task variants: 1) inferring missing rules from partial
contextual information, 2) composing simple rules to solve multi-step
sequences, and 3) decomposing complex multi-step examples to infer intermediate
steps. By factorizing each task into interpretable events, we show that the
model acquires capabilities in discrete stages, first learning the coarse
grained rules, before learning the complete latent structure. We also identify
a crucial asymmetry, where the model can compose fundamental rules robustly,
but struggles to decompose complex examples to discover the fundamental rules.
These findings offer new insights into understanding how a transformer model
learns latent structures, providing a granular view of how these capabilities
evolve during training.
\\ ( https://arxiv.org/abs/2511.19328 ,  18581kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19330
Date: Mon, 24 Nov 2025 17:26:20 GMT   (953kb)

Title: Targeted Manipulation: Slope-Based Attacks on Financial Time-Series Data
Authors: Dominik Luszczynski
Categories: cs.LG
Comments: 13 pages, 6 figures, 4 tables, preprint; Total including Appendix: 21
 pages, 11 figures, 7 tables
\\
 A common method of attacking deep learning models is through adversarial
attacks, which occur when an attacker specifically modifies the input of a
model to produce an incorrect result. Adversarial attacks have been deeply
investigated in the image domain; however, there is less research in the
time-series domain and very little for forecasting financial data. To address
these concerns, this study aims to build upon previous research on adversarial
attacks for time-series data by introducing two new slope-based methods aimed
to alter the trends of the predicted stock forecast generated by an N-HiTS
model. Compared to the normal N-HiTS predictions, the two new slope-based
methods, the General Slope Attack and Least-Squares Slope Attack, can
manipulate N-HiTS predictions by doubling the slope. These new slope attacks
can bypass standard security mechanisms, such as a discriminator that filters
real and perturbed inputs, reducing a 4-layered CNN's specificity to 28% and
accuracy to 57%. Furthermore, the slope based methods were incorporated into a
GAN architecture as a means of generating realistic synthetic data, while
simultaneously fooling the model. Finally, this paper also proposes a sample
malware designed to inject an adversarial attack in the model inference
library, proving that ML-security research should not only focus on making the
model safe, but also securing the entire pipeline.
\\ ( https://arxiv.org/abs/2511.19330 ,  953kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19344
Date: Mon, 24 Nov 2025 17:44:48 GMT   (4444kb)

Title: Annotation-Free Class-Incremental Learning
Authors: Hari Chandana Kuchibhotla, K S Ananth, Vineeth N Balasubramanian
Categories: cs.LG
Comments: 18 pages, 6 figures
\\
 Despite significant progress in continual learning ranging from architectural
novelty to clever strategies for mitigating catastrophic forgetting most
existing methods rest on a strong but unrealistic assumption the availability
of labeled data throughout the learning process. In real-world scenarios,
however, data often arrives sequentially and without annotations, rendering
conventional approaches impractical. In this work, we revisit the fundamental
assumptions of continual learning and ask: Can current systems adapt when
labels are absent and tasks emerge incrementally over time? To this end, we
introduce Annotation-Free Class-Incremental Learning (AFCIL), a more realistic
and challenging paradigm where unlabeled data arrives continuously, and the
learner must incrementally acquire new classes without any supervision. To
enable effective learning under AFCIL, we propose CrossWorld CL, a Cross Domain
World Guided Continual Learning framework that incorporates external world
knowledge as a stable auxiliary source. The method retrieves semantically
related ImageNet classes for each downstream category, maps downstream and
ImageNet features through a cross domain alignment strategy and finally
introduce a novel replay strategy. This design lets the model uncover semantic
structure without annotations while keeping earlier knowledge intact. Across
four datasets, CrossWorld-CL surpasses CLIP baselines and existing continual
and unlabeled learning methods, underscoring the benefit of world knowledge for
annotation free continual learning.
\\ ( https://arxiv.org/abs/2511.19344 ,  4444kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19350
Date: Mon, 24 Nov 2025 17:52:58 GMT   (15125kb)

Title: Scalable Parameter-Light Spectral Method for Clustering Short Text
 Embeddings with a Cohesion-Based Evaluation Metric
Authors: Nikita Neveditsin, Pawan Lingras, Vijay Mago
Categories: cs.LG cs.CL
\\
 Clustering short text embeddings is a foundational task in natural language
processing, yet remains challenging due to the need to specify the number of
clusters in advance. We introduce a scalable spectral method that estimates the
number of clusters directly from the structure of the Laplacian eigenspectrum,
constructed using cosine similarities and guided by an adaptive sampling
strategy. This sampling approach enables our estimator to efficiently scale to
large datasets without sacrificing reliability. To support intrinsic evaluation
of cluster quality without ground-truth labels, we propose the Cohesion Ratio,
a simple and interpretable evaluation metric that quantifies how much
intra-cluster similarity exceeds the global similarity background. It has an
information-theoretic motivation inspired by mutual information, and in our
experiments it correlates closely with extrinsic measures such as normalized
mutual information and homogeneity. Extensive experiments on six short-text
datasets and four modern embedding models show that standard algorithms like
K-Means and HAC, when guided by our estimator, significantly outperform popular
parameter-light methods such as HDBSCAN, OPTICS, and Leiden. These results
demonstrate the practical value of our spectral estimator and Cohesion Ratio
for unsupervised organization and evaluation of short text data. Implementation
of our estimator of k and Cohesion Ratio, along with code for reproducing the
experiments, is available at
https://anonymous.4open.science/r/towards_clustering-0C2E.
\\ ( https://arxiv.org/abs/2511.19350 ,  15125kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19355
Date: Mon, 24 Nov 2025 17:55:46 GMT   (513kb)

Title: Leveraging LLMs for reward function design in reinforcement learning
 control tasks
Authors: Franklin Cardenoso and Wouter Caarls
Categories: cs.LG cs.AI cs.RO
\\
 The challenge of designing effective reward functions in reinforcement
learning (RL) represents a significant bottleneck, often requiring extensive
human expertise and being time-consuming. Previous work and recent advancements
in large language models (LLMs) have demonstrated their potential for
automating the generation of reward functions. However, existing methodologies
often require preliminary evaluation metrics, human-engineered feedback for the
refinement process, or the use of environmental source code as context. To
address these limitations, this paper introduces LEARN-Opt (LLM-based Evaluator
and Analyzer for Reward functioN Optimization). This LLM-based, fully
autonomous, and model-agnostic framework eliminates the need for preliminary
metrics and environmental source code as context to generate, execute, and
evaluate reward function candidates from textual descriptions of systems and
task objectives. LEARN-Opt's main contribution lies in its ability to
autonomously derive performance metrics directly from the system description
and the task objective, enabling unsupervised evaluation and selection of
reward functions. Our experiments indicate that LEARN-Opt achieves performance
comparable to or better to that of state-of-the-art methods, such as EUREKA,
while requiring less prior knowledge. We find that automated reward design is a
high-variance problem, where the average-case candidate fails, requiring a
multi-run approach to find the best candidates. Finally, we show that LEARN-Opt
can unlock the potential of low-cost LLMs to find high-performing candidates
that are comparable to, or even better than, those of larger models. This
demonstrated performance affirms its potential to generate high-quality reward
functions without requiring any preliminary human-defined metrics, thereby
reducing engineering overhead and enhancing generalizability.
\\ ( https://arxiv.org/abs/2511.19355 ,  513kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19359
Date: Mon, 24 Nov 2025 17:56:42 GMT   (1618kb)

Title: Enhancing Conformal Prediction via Class Similarity
Authors: Ariel Fargion, Lahav Dabah and Tom Tirer
Categories: cs.LG
\\
 Conformal Prediction (CP) has emerged as a powerful statistical framework for
high-stakes classification applications. Instead of predicting a single class,
CP generates a prediction set, guaranteed to include the true label with a
pre-specified probability. The performance of different CP methods is typically
assessed by their average prediction set size. In setups where the classes can
be partitioned into semantic groups, e.g., diseases that require similar
treatment, users can benefit from prediction sets that are not only small on
average, but also contain a small number of semantically different groups. This
paper begins by addressing this problem and ultimately offers a widely
applicable tool for boosting any CP method on any dataset. First, given a class
partition, we propose augmenting the CP score function with a term that
penalizes predictions with out-of-group errors. We theoretically analyze this
strategy and prove its advantages for group-related metrics. Surprisingly, we
show mathematically that, for common class partitions, it can also reduce the
average set size of any CP score function. Our analysis reveals the class
similarity factors behind this improvement and motivates us to propose a
model-specific variant, which does not require any human semantic partition and
can further reduce the prediction set size. Finally, we present an extensive
empirical study, encompassing prominent CP methods, multiple models, and
several datasets, which demonstrates that our class-similarity-based approach
consistently enhances CP methods.
\\ ( https://arxiv.org/abs/2511.19359 ,  1618kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19364
Date: Mon, 24 Nov 2025 17:58:59 GMT   (1177kb)

Title: Neural surrogates for designing gravitational wave detectors
Authors: Carlos Ruiz-Gonzalez, S\"oren Arlt, Sebastian Lehner, Arturs Berzins,
 Yehonathan Drori, Rana X Adhikari, Johannes Brandstetter, Mario Krenn
Categories: cs.LG astro-ph.IM gr-qc quant-ph
Comments: 20 pages, 7 figures, 4 tables
\\
 Physics simulators are essential in science and engineering, enabling the
analysis, control, and design of complex systems. In experimental sciences,
they are increasingly used to automate experimental design, often via
combinatorial search and optimization. However, as the setups grow more
complex, the computational cost of traditional, CPU-based simulators becomes a
major limitation. Here, we show how neural surrogate models can significantly
reduce reliance on such slow simulators while preserving accuracy. Taking the
design of interferometric gravitational wave detectors as a representative
example, we train a neural network to surrogate the gravitational wave physics
simulator Finesse, which was developed by the LIGO community. Despite that
small changes in physical parameters can change the output by orders of
magnitudes, the model rapidly predicts the quality and feasibility of candidate
designs, allowing an efficient exploration of large design spaces. Our
algorithm loops between training the surrogate, inverse designing new
experiments, and verifying their properties with the slow simulator for further
training. Assisted by auto-differentiation and GPU parallelism, our method
proposes high-quality experiments much faster than direct optimization.
Solutions that our algorithm finds within hours outperform designs that take
five days for the optimizer to reach. Though shown in the context of
gravitational wave detectors, our framework is broadly applicable to other
domains where simulator bottlenecks hinder optimization and discovery.
\\ ( https://arxiv.org/abs/2511.19364 ,  1177kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19368
Date: Mon, 24 Nov 2025 18:03:59 GMT   (4743kb)

Title: LLM-Driven Stationarity-Aware Expert Demonstrations for Multi-Agent
 Reinforcement Learning in Mobile Systems
Authors: Tianyang Duan, Zongyuan Zhang, Zheng Lin, Songxiao Guo, Xiuxian Guan,
 Guangyu Wu, Zihan Fang, Haotian Meng, Xia Du, Ji-Zhe Zhou, Heming Cui, Jun
 Luo, Yue Gao
Categories: cs.LG cs.NI
Comments: 15 pages, 9 figures
\\
 Multi-agent reinforcement learning (MARL) has been increasingly adopted in
many real-world applications. While MARL enables decentralized deployment on
resource-constrained edge devices, it suffers from severe non-stationarity due
to the synchronous updates of agent policies. This non stationarity results in
unstable training and poor policy con vergence, especially as the number of
agents increases. In this paper, we propose RELED, a scalable MARL framework
that integrates large language model (LLM)-driven expert demonstrations with
autonomous agent exploration. RELED incorporates a Stationarity-Aware Expert
Demonstration module, which leverages theoretical non-stationarity bounds to
enhance the quality of LLM-generated expert trajectories, thus providing high
reward and training-stable samples for each agent. Moreover, a Hybrid
Expert-Agent Policy Optimization module adaptively balances each agent's
learning from both expert-generated and agent-generated trajectories,
accelerating policy convergence and improving generalization. Extensive
experiments with real city networks based on OpenStreetMap demonstrate that
RELED achieves superior performance compared to state-of-the-art MARL methods.
\\ ( https://arxiv.org/abs/2511.19368 ,  4743kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19379
Date: Mon, 24 Nov 2025 18:19:42 GMT   (521kb)

Title: Efficiency vs. Fidelity: A Comparative Analysis of Diffusion
 Probabilistic Models and Flow Matching on Low-Resource Hardware
Authors: Srishti Gupta, Yashasvee Taiwade
Categories: cs.LG
\\
 Denoising Diffusion Probabilistic Models (DDPMs) have established a new
state-of-the-art in generative image synthesis, yet their deployment is
hindered by significant computational overhead during inference, often
requiring up to 1,000 iterative steps. This study presents a rigorous
comparative analysis of DDPMs against the emerging Flow Matching (Rectified
Flow) paradigm, specifically isolating their geometric and efficiency
properties on low-resource hardware. By implementing both frameworks on a
shared Time-Conditioned U-Net backbone using the MNIST dataset, we demonstrate
that Flow Matching significantly outperforms Diffusion in efficiency. Our
geometric analysis reveals that Flow Matching learns a highly rectified
transport path (Curvature $\mathcal{C} \approx 1.02$), which is near-optimal,
whereas Diffusion trajectories remain stochastic and tortuous ($\mathcal{C}
\approx 3.45$). Furthermore, we establish an ``efficiency frontier'' at $N=10$
function evaluations, where Flow Matching retains high fidelity while Diffusion
collapses. Finally, we show via numerical sensitivity analysis that the learned
vector field is sufficiently linear to render high-order ODE solvers
(Runge-Kutta 4) unnecessary, validating the use of lightweight Euler solvers
for edge deployment. \textbf{This work concludes that Flow Matching is the
superior algorithmic choice for real-time, resource-constrained generative
tasks.}
\\ ( https://arxiv.org/abs/2511.19379 ,  521kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19390
Date: Mon, 24 Nov 2025 18:30:04 GMT   (9202kb)

Title: Predicting partially observable dynamical systems via diffusion models
 with a multiscale inference scheme
Authors: Rudy Morel, Francesco Pio Ramunno, Jeff Shen, Alberto Bietti,
 Kyunghyun Cho, Miles Cranmer, Siavash Golkar, Olexandr Gugnin, Geraud
 Krawezik, Tanya Marwah, Michael McCabe, Lucas Meyer, Payel Mukhopadhyay,
 Ruben Ohana, Liam Parker, Helen Qu, Fran\c{c}ois Rozet, K.D. Leka,
 Fran\c{c}ois Lanusse, David Fouhey, Shirley Ho
Categories: cs.LG astro-ph.SR cs.AI stat.ML
\\
 Conditional diffusion models provide a natural framework for probabilistic
prediction of dynamical systems and have been successfully applied to fluid
dynamics and weather prediction. However, in many settings, the available
information at a given time represents only a small fraction of what is needed
to predict future states, either due to measurement uncertainty or because only
a small fraction of the state can be observed. This is true for example in
solar physics, where we can observe the Sun's surface and atmosphere, but its
evolution is driven by internal processes for which we lack direct
measurements. In this paper, we tackle the probabilistic prediction of
partially observable, long-memory dynamical systems, with applications to solar
dynamics and the evolution of active regions. We show that standard inference
schemes, such as autoregressive rollouts, fail to capture long-range
dependencies in the data, largely because they do not integrate past
information effectively. To overcome this, we propose a multiscale inference
scheme for diffusion models, tailored to physical processes. Our method
generates trajectories that are temporally fine-grained near the present and
coarser as we move farther away, which enables capturing long-range temporal
dependencies without increasing computational cost. When integrated into a
diffusion model, we show that our inference scheme significantly reduces the
bias of the predicted distributions and improves rollout stability.
\\ ( https://arxiv.org/abs/2511.19390 ,  9202kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19405
Date: Mon, 24 Nov 2025 18:43:46 GMT   (5253kb)

Title: Learning Robust Social Strategies with Large Language Models
Authors: Dereck Piche, Mohammed Muqeeth, Milad Aghajohari, Juan Duque, Michael
 Noukhovitch, Aaron Courville
Categories: cs.LG
\\
 As agentic AI becomes more widespread, agents with distinct and possibly
conflicting goals will interact in complex ways. These multi-agent interactions
pose a fundamental challenge, particularly in social dilemmas, where agents'
individual incentives can undermine collective welfare. While reinforcement
learning (RL) has been effective for aligning large language models (LLMs) in
the single-agent regime, prior small-network results suggest that standard RL
in multi-agent settings often converges to defecting, self-interested policies.
We show the same effect in LLMs: despite cooperative priors, RL-trained LLM
agents develop opportunistic behavior that can exploit even advanced
closed-source models. To address this tendency of RL to converge to poor
equilibria, we adapt a recent opponent-learning awareness algorithm, Advantage
Alignment, to fine-tune LLMs toward multi-agent cooperation and
non-exploitability. We then introduce a group-relative baseline that simplifies
advantage computation in iterated games, enabling multi-agent training at LLM
scale. We also contribute a novel social dilemma environment, Trust and Split,
which requires natural language communication to achieve high collective
welfare. Across a wide range of social dilemmas, policies learned with
Advantage Alignment achieve higher collective payoffs while remaining robust
against exploitation by greedy agents.
\\ ( https://arxiv.org/abs/2511.19405 ,  5253kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19413
Date: Mon, 24 Nov 2025 18:50:01 GMT   (5177kb)

Title: UniGame: Turning a Unified Multimodal Model Into Its Own Adversary
Authors: Zhaolong Su, Wang Lu, Hao Chen, Sharon Li, Jindong Wang
Categories: cs.LG cs.AI cs.CV
\\
 Unified Multimodal Models (UMMs) have shown impressive performance in both
understanding and generation with a single architecture. However, UMMs still
exhibit a fundamental inconsistency: understanding favors compact embeddings,
whereas generation favors reconstruction-rich representations. This structural
trade-off produces misaligned decision boundaries, degraded cross-modal
coherence, and heightened vulnerability under distributional and adversarial
shifts. In this paper, we present UniGame, a self-adversarial post-training
framework that directly targets the inconsistencies. By applying a lightweight
perturber at the shared token interface, UniGame enables the generation branch
to actively seek and challenge fragile understanding, turning the model itself
into its own adversary. Experiments demonstrate that UniGame significantly
improves the consistency (+4.6%). Moreover, it also achieves substantial
improvements in understanding (+3.6%), generation (+0.02), out-of-distribution
and adversarial robustness (+4.8% and +6.2% on NaturalBench and AdVQA). The
framework is architecture-agnostic, introduces less than 1% additional
parameters, and is complementary to existing post-training methods. These
results position adversarial self-play as a general and effective principle for
enhancing the coherence, stability, and unified competence of future multimodal
foundation models. The official code is available at:
https://github.com/AIFrontierLab/UniGame
\\ ( https://arxiv.org/abs/2511.19413 ,  5177kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19428
Date: Mon, 24 Nov 2025 18:58:55 GMT   (18797kb)

Title: Flow Map Distillation Without Data
Authors: Shangyuan Tong, Nanye Ma, Saining Xie, Tommi Jaakkola
Categories: cs.LG cs.CV
\\
 State-of-the-art flow models achieve remarkable quality but require slow,
iterative sampling. To accelerate this, flow maps can be distilled from
pre-trained teachers, a procedure that conventionally requires sampling from an
external dataset. We argue that this data-dependency introduces a fundamental
risk of Teacher-Data Mismatch, as a static dataset may provide an incomplete or
even misaligned representation of the teacher's full generative capabilities.
This leads us to question whether this reliance on data is truly necessary for
successful flow map distillation. In this work, we explore a data-free
alternative that samples only from the prior distribution, a distribution the
teacher is guaranteed to follow by construction, thereby circumventing the
mismatch risk entirely. To demonstrate the practical viability of this
philosophy, we introduce a principled framework that learns to predict the
teacher's sampling path while actively correcting for its own compounding
errors to ensure high fidelity. Our approach surpasses all data-based
counterparts and establishes a new state-of-the-art by a significant margin.
Specifically, distilling from SiT-XL/2+REPA, our method reaches an impressive
FID of 1.45 on ImageNet 256x256, and 1.49 on ImageNet 512x512, both with only 1
sampling step. We hope our work establishes a more robust paradigm for
accelerating generative models and motivates the broader adoption of flow map
distillation without data.
\\ ( https://arxiv.org/abs/2511.19428 ,  18797kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2511.17506 (*cross-listing*)
Date: Thu, 2 Oct 2025 22:43:47 GMT   (739kb)

Title: AURA: Adaptive Unified Reasoning and Automation with LLM-Guided MARL for
 NextG Cellular Networks
Authors: Narjes Nourzad, Mingyu Zong, Bhaskar Krishnamachari
Categories: cs.NI cs.AI
\\
 Next-generation (NextG) cellular networks are expected to manage dynamic
traffic while sustaining high performance. Large language models (LLMs) provide
strategic reasoning for 6G planning, but their computational cost and latency
limit real-time use. Multi-agent reinforcement learning (MARL) supports
localized adaptation, yet coordination at scale remains challenging. We present
AURA, a framework that integrates cloud-based LLMs for high-level planning with
base stations modeled as MARL agents for local decision-making. The LLM
generates objectives and subgoals from its understanding of the environment and
reasoning capabilities, while agents at base stations execute these objectives
autonomously, guided by a trust mechanism that balances local learning with
external input. To reduce latency, AURA employs batched communication so that
agents update the LLM's view of the environment and receive improved feedback.
In a simulated 6G scenario, AURA improves resilience, reducing dropped handoff
requests by more than half under normal and high traffic and lowering system
failures. Agents use LLM input in fewer than 60\% of cases, showing that
guidance augments rather than replaces local adaptability, thereby mitigating
latency and hallucination risks. These results highlight the promise of
combining LLM reasoning with MARL adaptability for scalable, real-time NextG
network management.
\\ ( https://arxiv.org/abs/2511.17506 ,  739kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17507 (*cross-listing*)
Date: Fri, 3 Oct 2025 06:35:16 GMT   (399kb)

Title: The use of artificial intelligence in music creation: between interface
 and appropriation
Authors: Arnaud Zeller (LISEC), Emmanuelle Chevry Pebayle (Tec&Co, LISEC)
Categories: cs.HC cs.AI
Comments: in French language
Journal-ref: Interfaces num\'eriques, 2025, 14 (1)
\\
 By observing the activities and relationships of musicians and sound
designers to the activities of creation, performance, publishing and
dissemination with artificial intelligence (AI), from two specialized forums
between 2022 and 2024, this article proposes a lexicometric analysis of the
representations linked to their use. Indeed, the machine, now equipped with
artificial intelligences requiring new appropriations and enabling new
mediations, constitutes new challenges for artists. To study these
confrontations and new mediations, our approach mobilizes the theoretical
framework of the Human-AI Musicking Framework, based on a lexicometric analysis
of content. The aim is to clarify the present and future uses of AI from the
interfaces, in the creation of sound and musical content, and to identify the
obstacles, obstacles, brakes and limits to appropriation ``in the fact of
making the content one's own and integrating it as a part of oneself''
(Bachimont and Crozat, 2004) in the context of a collaboration between musician
and machine.
\\ ( https://arxiv.org/abs/2511.17507 ,  399kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17509 (*cross-listing*)
Date: Sat, 4 Oct 2025 08:42:57 GMT   (2536kb)

Title: Beyond Awareness: Investigating How AI and Psychological Factors Shape
 Human Self-Confidence Calibration
Authors: Federico Maria Cau, Lucio Davide Spano
Categories: cs.HC cs.AI
\\
 Human-AI collaboration outcomes depend strongly on human self-confidence
calibration, which drives reliance or resistance toward AI's suggestions. This
work presents two studies examining whether calibration of self-confidence
before decision tasks, low versus high levels of Need for Cognition (NFC), and
Actively Open-Minded Thinking (AOT), leads to differences in decision accuracy,
self-confidence appropriateness during the tasks, and metacognitive perceptions
(global and affective). The first study presents strategies to identify
well-calibrated users, also comparing decision accuracy and the appropriateness
of self-confidence across NFC and AOT levels. The second study investigates the
effects of calibrated self-confidence in AI-assisted decision-making (no AI,
two-stage AI, and personalized AI), also considering different NFC and AOT
levels. Our results show the importance of human self-confidence calibration
and psychological traits when designing AI-assisted decision systems. We
further propose design recommendations to address the challenge of calibrating
self-confidence and supporting tailored, user-centric AI that accounts for
individual traits.
\\ ( https://arxiv.org/abs/2511.17509 ,  2536kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17511 (*cross-listing*)
Date: Mon, 6 Oct 2025 01:26:55 GMT   (4651kb)

Title: A Multidisciplinary Design and Optimization (MDO) Agent Driven by Large
 Language Models
Authors: Bingkun Guo, Wentian Li, Xiaojian Liu, Jiaqi Luo, Zibin Yu, Dalong
 Dong, Shuyou Zhang, Yiming Zhang
Categories: cs.HC cs.AI
\\
 To accelerate mechanical design and enhance design quality and innovation, we
present a Multidisciplinary Design and Optimization (MDO) Agent driven by Large
Language Models (LLMs). The agent semi-automates the end-to-end workflow by
orchestrating three core capabilities: (i) natural-language-driven parametric
modeling, (ii) retrieval-augmented generation (RAG) for knowledge-grounded
conceptualization, and (iii) intelligent orchestration of engineering software
for performance verification and optimization. Working in tandem, these
capabilities interpret high-level, unstructured intent, translate it into
structured design representations, automatically construct parametric 3D CAD
models, generate reliable concept variants using external knowledge bases, and
conduct evaluation with iterative optimization via tool calls such as
finite-element analysis (FEA). Validation on three representative cases - a
gas-turbine blade, a machine-tool column, and a fractal heat sink - shows that
the agent completes the pipeline from natural-language intent to verified and
optimized designs with reduced manual scripting and setup effort, while
promoting innovative design exploration. This work points to a practical path
toward human-AI collaborative mechanical engineering and lays a foundation for
more dependable, vertically customized MDO systems.
\\ ( https://arxiv.org/abs/2511.17511 ,  4651kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17514 (*cross-listing*)
Date: Tue, 7 Oct 2025 07:12:47 GMT   (383kb)

Title: XAI-on-RAN: Explainable, AI-native, and GPU-Accelerated RAN Towards 6G
Authors: Osman Tugay Basaran, Falko Dressler
Categories: cs.NI cs.AI
Comments: 39th Conference on Neural Information Processing Systems (NeurIPS
 2025) Workshop: AI and ML for Next-Generation Wireless Communications and
 Networking (AI4NextG)
\\
 Artificial intelligence (AI)-native radio access networks (RANs) will serve
vertical industries with stringent requirements: smart grids, autonomous
vehicles, remote healthcare, industrial automation, etc. To achieve these
requirements, modern 5G/6G design increasingly leverage AI for network
optimization, but the opacity of AI decisions poses risks in mission-critical
domains. These use cases are often delivered via non-public networks (NPNs) or
dedicated network slices, where reliability and safety are vital. In this
paper, we motivate the need for transparent and trustworthy AI in high-stakes
communications (e.g., healthcare, industrial automation, and robotics) by
drawing on 3rd generation partnership project (3GPP)'s vision for non-public
networks. We design a mathematical framework to model the trade-offs between
transparency (explanation fidelity and fairness), latency, and graphics
processing unit (GPU) utilization in deploying explainable AI (XAI) models.
Empirical evaluations demonstrate that our proposed hybrid XAI model
xAI-Native, consistently surpasses conventional baseline models in performance.
\\ ( https://arxiv.org/abs/2511.17514 ,  383kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17515 (*cross-listing*)
Date: Tue, 7 Oct 2025 12:31:15 GMT   (511kb)

Title: Embedding Generative AI into Systems Analysis and Design Curriculum:
 Framework, Case Study, and Cross-Campus Empirical Evidence
Authors: Mahmoud Elkhodr, Ergun Gide
Categories: cs.HC cs.AI
Comments: ~12,000 words; 4 figures; 6 tables; multi-site study (across 4
 Australian campuses)
ACM-class: D.2.1; D.2.2; H.5.2; K.3.2
\\
 Systems analysis students increasingly use Generative AI, yet current
pedagogy lacks systematic approaches for teaching responsible AI orchestration
that fosters critical thinking whilst meeting educational outcomes. Students
risk accepting AI suggestions blindly or uncritically without assessing
alignment with user needs or contextual appropriateness. SAGE (Structured
AI-Guided Education) addresses this gap by embedding GenAI into curriculum
design, training students when to accept, modify, or reject AI contributions.
Implementation with 18 student groups across four Australian universities
revealed how orchestration skills develop. Most groups (84\%) moved beyond
passive acceptance, showing selective judgment, yet none proactively identified
gaps overlooked by both human and AI analysis, indicating a competency ceiling.
Students strong at explaining decisions also performed well at integrating
sources, and those with deep domain understanding consistently considered
accessibility considerations. Accessibility awareness proved fragile. When
writing requirements, 85\% of groups explicitly considered elderly users and
cultural needs. Notably, 55\% of groups struggled identifying when AI
misclassified system boundaries (what belongs inside versus outside the
system), 45\% missed data management errors (how information is stored and
updated), and 55\% overlooked missing exception handling. Three implications
emerge for educators: (i) require students to document why they accepted,
modified, or rejected each AI suggestion, making reasoning explicit; (ii) embed
accessibility prompts at each development stage because awareness collapses
without continuous scaffolding; and (iii) have students create their own
specifications before using AI, then compare versions, and anchor to research
or standards to identify gaps.
\\ ( https://arxiv.org/abs/2511.17515 ,  511kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17519 (*cross-listing*)
Date: Fri, 10 Oct 2025 00:09:09 GMT   (324kb)

Title: SAJD: Self-Adaptive Jamming Attack Detection in AI/ML Integrated 5G
 O-RAN Networks
Authors: Md Habibur Rahman, Md Sharif Hossen, Nathan H. Stephenson, Vijay K.
 Shah, Aloizio Da Silva
Categories: cs.NI cs.AI
Comments: 6 pages, 5 figures, IEEE Military Communications Conference
\\
 The open radio access network (O-RAN) enables modular, intelligent, and
programmable 5G network architectures through the adoption of software-defined
networking (SDN), network function virtualization (NFV), and implementation of
standardized open interfaces. It also facilitates closed loop control and
(non/near) real-time optimization of radio access network (RAN) through the
integration of non-real-time applications (rApps) and near-real-time
applications (xApps). However, one of the security concerns for O-RAN that can
severely undermine network performance and subject it to a prominent threat to
the security & reliability of O-RAN networks is jamming attacks. To address
this, we introduce SAJD-a self-adaptive jammer detection framework that
autonomously detects jamming attacks in artificial intelligence (AI) / machine
learning (ML)-integrated O-RAN environments. The SAJD framework forms a
closed-loop system that includes near-real-time inference of radio signal
jamming interference via our developed ML-based xApp, as well as continuous
monitoring and retraining pipelines through rApps. Specifically, a labeler rApp
is developed that uses live telemetry (i.e., KPIs) to detect model drift,
triggers unsupervised data labeling, executes model training/retraining using
the integrated & open-source ClearML framework, and updates deployed models on
the fly, without service disruption. Experiments on O-RAN-compliant testbed
demonstrate that the SAJD framework outperforms state-of-the-art
(offline-trained with manual labels) jamming detection approach in accuracy and
adaptability under various dynamic and previously unseen interference
scenarios.
\\ ( https://arxiv.org/abs/2511.17519 ,  324kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17520 (*cross-listing*)
Date: Fri, 10 Oct 2025 13:21:04 GMT   (768kb)

Title: Safe Farming: Development of a Prevention System to Mitigate Vertebrates
 Crop Raiding
Authors: Razi Iqbal
Categories: cs.NI cs.AI cs.ET
\\
 One of the main problems for farmers is the protection of their crops, before
and after harvesting, from animals and birds. To overcome this problem, this
paper proposes a model of safe farming in which the crops will be protected
from vertebrates attack through a prevention system that is based on Wirelesses
Sensors Networks. Different sensor nodes are placed around the field that
detect animals or birds existence and generate required signals and
information. This information is passed to the Repelling and Notifying System
(RNS) that is installed at the field through a short range wireless technology,
ZigBee. As RNS receives the information, it generates ultrasonic sounds that
are unbearable for animals and birds, which causes them to run away from the
field. These ultrasonic sounds are generated in a frequency range that only
animals and birds can hear, while humans cannot notice the sound. The paper
also proposes a notifying system. It will inform the farmer about animals or
birds intrusion in the field through SMS, but doesn't need any action from the
farmer. The low cost and power efficiency of the proposed system is a key
advantage for developing countries where cost and power are major players in
any system feasibility.
\\ ( https://arxiv.org/abs/2511.17520 ,  768kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17526 (*cross-listing*)
Date: Fri, 24 Oct 2025 03:25:25 GMT   (6908kb)

Title: RadioMapMotion: A Dataset and Baseline for Proactive Spatio-Temporal
 Radio Environment Prediction
Authors: Honggang Jia, Nan Cheng, Xiucheng Wang
Categories: cs.NI cs.AI
\\
 Radio maps (RMs), which provide location-based pathloss estimations, are
fundamental to enabling proactive, environment-aware communication in 6G
networks. However, existing deep learning-based methods for RM construction
often model dynamic environments as a series of independent static snapshots,
thereby omitting the temporal continuity inherent in signal propagation changes
caused by the motion of dynamic entities. To address this limitation, we
propose the task of spatio-temporal RM prediction, which involves forecasting a
sequence of future maps from historical observations. A key barrier to this
predictive approach has been the lack of datasets capturing continuous
environmental evolution. To fill this gap, we introduce RadioMapMotion, the
first large-scale public dataset of continuous RM sequences generated from
physically consistent vehicle trajectories. As a baseline for this task, we
propose RadioLSTM, a UNet architecture based on Convolutional Long Short-Term
Memory (ConvLSTM) and designed for multi-step sequence forecasting.
Experimental evaluations show that RadioLSTM achieves higher prediction
accuracy and structural fidelity compared to representative baseline methods.
Furthermore, the model exhibits a low inference latency, indicating its
potential suitability for real-time network operations. Our project will be
publicly released at: https://github.com/UNIC-Lab/RadioMapMotion upon paper
acceptance.
\\ ( https://arxiv.org/abs/2511.17526 ,  6908kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17528 (*cross-listing*)
Date: Tue, 28 Oct 2025 02:07:32 GMT   (442kb)

Title: Evaluating Device-First Continuum AI (DFC-AI) for Autonomous Operations
 in the Energy Sector
Authors: Siavash M. Alamouti, Fay Arjomandi, Michel Burger, Bashar Altakrouri
Categories: cs.NI cs.AI
Comments: 14 pages, 4 figures, 6 tables
\\
 Industrial automation in the energy sector requires AI systems that can
operate autonomously regardless of network availability, a requirement that
cloud-centric architectures cannot meet. This paper evaluates the application
of Device-First Continuum AI (DFC-AI) to critical energy sector operations.
DFC-AI, a specialized architecture within the Hybrid Edge Cloud paradigm,
implements intelligent agents using a microservices architecture that
originates at end devices and extends across the computational continuum.
Through comprehensive simulations of energy sector scenarios including drone
inspections, sensor networks, and worker safety systems, we demonstrate that
DFC-AI maintains full operational capability during network outages while cloud
and gateway-based systems experience complete or partial failure. Our analysis
reveals that zero-configuration GPU discovery and heterogeneous device
clustering are particularly well-suited for energy sector deployments, where
specialized nodes can handle intensive AI workloads for entire fleets of
inspection drones or sensor networks. The evaluation shows that DFC-AI achieves
significant latency reduction and energy savings compared to cloud
architectures. Additionally, we find that gateway based edge solutions can
paradoxically cost more than cloud solutions for certain energy sector
workloads due to infrastructure overhead, while DFC-AI can consistently provide
cost savings by leveraging enterprise-owned devices. These findings, validated
through rigorous statistical analysis, establish that DFC-AI addresses the
unique challenges of energy sector operations, ensuring intelligent agents
remain available and functional in remote oil fields, offshore platforms, and
other challenging environments characteristic of the industry.
\\ ( https://arxiv.org/abs/2511.17528 ,  442kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17532 (*cross-listing*)
Date: Thu, 30 Oct 2025 03:42:56 GMT   (2093kb)

Title: Denoising Refinement Diffusion Models for Simultaneous Generation of
 Multi-scale Mobile Network Traffic
Authors: Xiaoqian Qi, Haoye Chai, Sichang Liu, Lei Yue, Raoyuan Pan, Yue Wang,
 Yong Li
Categories: cs.NI cs.AI
\\
 Multi-layer mobile network traffic generation is a key approach to capturing
multi-scale network dynamics, supporting network planning, and promoting
generative management of mobile data. Existing methods focus on generating
network traffic with a single spatiotemporal resolution, making it difficult to
achieve joint generation of multi-scale traffic. In this paper, we propose
ZoomDiff, a diffusion-based multi-scale mobile traffic generation model.
ZoomDiff maps the urban environmental context into network traffic with
multiple spatiotemporal resolutions through custom-designed Denoising
Refinement Diffusion Models (DRDM). DRDM employs a multi-stage noise-adding and
denoising process, enabling different stages to generate traffic with distinct
spatial and temporal resolutions. It aligns the progressive denoising process
of diffusion models with hierarchical network layers, including BSs, cells, and
grids with different granularities. Evaluations on real-world mobile traffic
datasets demonstrate that ZoomDiff achieves a performance improvement of at
least 18.4% over state-of-the-art baselines on generation tasks at multi-scale
traffic. The efficiency and generalization ability are also demonstrated, which
indicates that ZoomDiff holds strong potential for generative mobile data
management. The code of ZoomDiff is available at
https://anonymous.4open.science/r/ZoomDiff-105E/.
\\ ( https://arxiv.org/abs/2511.17532 ,  2093kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17537 (*cross-listing*)
Date: Thu, 6 Nov 2025 16:15:19 GMT   (2783kb)

Title: HiFiNet: Hierarchical Fault Identification in Wireless Sensor Networks
 via Edge-Based Classification and Graph Aggregation
Authors: Nguyen Van Son, Nguyen Tri Nghia, Nguyen Thi Hanh, Huynh Thi Thanh
 Binh
Categories: cs.NI cs.AI
\\
 Wireless Sensor Networks (WSN) are the backbone of essential monitoring
applications, but their deployment in unfavourable conditions increases the
risk to data integrity and system reliability. Traditional fault detection
methods often struggle to effectively balance accuracy and energy consumption,
and they may not fully leverage the complex spatio-temporal correlations
inherent in WSN data. In this paper, we introduce HiFiNet, a novel hierarchical
fault identification framework that addresses these challenges through a
two-stage process. Firstly, edge classifiers with a Long Short-Term Memory
(LSTM) stacked autoencoder perform temporal feature extraction and output
initial fault class prediction for individual sensor nodes. Using these
results, a Graph Attention Network (GAT) then aggregates information from
neighboring nodes to refine the classification by integrating the topology
context. Our method is able to produce more accurate predictions by capturing
both local temporal patterns and network-wide spatial dependencies. To validate
this approach, we constructed synthetic WSN datasets by introducing specific,
predefined faults into the Intel Lab Dataset and NASA's MERRA-2 reanalysis
data. Experimental results demonstrate that HiFiNet significantly outperforms
existing methods in accuracy, F1-score, and precision, showcasing its
robustness and effectiveness in identifying diverse fault types. Furthermore,
the framework's design allows for a tunable trade-off between diagnostic
performance and energy efficiency, making it adaptable to different operational
requirements.
\\ ( https://arxiv.org/abs/2511.17537 ,  2783kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17543 (*cross-listing*)
Date: Sun, 9 Nov 2025 19:16:04 GMT   (6923kb)

Title: Evo* 2025 -- Late-Breaking Abstracts Volume
Authors: A.M. Mora, A.I. Esparcia-Alc\'azar, M.S. Cruz
Categories: cs.NE cs.AI
Comments: LBAs accepted in Evo* 2025. Part of the Conference Proceedings
MSC-class: 68T05, 68W20
ACM-class: I.0; I.2; K.4
\\
 Volume containing the Late-Breaking Abstracts submitted to the Evo* 2025
Conference, held in Trieste (Italy) from April 23rd to 25th. These extended
abstracts showcase ongoing research and preliminary findings exploring the
application of various Bioinspired Methods (primarily Evolutionary Computation)
to a range of problems, many of which address real-world scenarios.
\\ ( https://arxiv.org/abs/2511.17543 ,  6923kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17547 (*cross-listing*)
Date: Tue, 11 Nov 2025 02:53:49 GMT   (5313kb)

Title: SYNAPSE: Synergizing an Adapter and Finetuning for High-Fidelity EEG
 Synthesis from a CLIP-Aligned Encoder
Authors: Jeyoung Lee and Hochul Kang
Categories: eess.SP cs.AI cs.CV cs.HC cs.LG
\\
 Recent progress in diffusion-based generative models has enabled high-quality
image synthesis conditioned on diverse modalities. Extending such models to
brain signals could deepen our understanding of human perception and mental
representations. However,electroencephalography (EEG) presents major challenges
for image generation due to high noise, low spatial resolution, and strong
inter-subject variability. Existing approaches,such as DreamDiffusion,
BrainVis, and GWIT, primarily adapt EEG features to pre-trained Stable
Diffusion models using complex alignment or classification pipelines, often
resulting in large parameter counts and limited interpretability. We introduce
SYNAPSE, a two-stage framework that bridges EEG signal representation learning
and high-fidelity image synthesis. In Stage1, a CLIP-aligned EEG autoencoder
learns a semantically structured latent representation by combining signal
reconstruction and cross-modal alignment objectives. In Stage2, the pretrained
encoder is frozen and integrated with a lightweight adaptation of Stable
Diffusion, enabling efficient conditioning on EEG features with minimal
trainable parameters. Our method achieves a semantically coherent latent space
and state-of-the-art perceptual fidelity on the CVPR40 dataset, outperforming
prior EEG-to-image models in both reconstruction efficiency and image quality.
Quantitative and qualitative analyses demonstrate that SYNAPSE generalizes
effectively across subjects, preserving visual semantics even when class-level
agreement is reduced. These results suggest that reconstructing what the brain
perceives, rather than what it classifies, is key to faithful EEG-based image
generation.
\\ ( https://arxiv.org/abs/2511.17547 ,  5313kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17550 (*cross-listing*)
Date: Tue, 11 Nov 2025 11:53:36 GMT   (24kb)

Title: Gate-level boolean evolutionary geometric attention neural networks
Authors: Xianshuai Shi, Jianfeng Zhu, Leibo Liu
Categories: cs.NE cs.AI cs.LG
\\
 This paper presents a gate-level Boolean evolutionary geometric attention
neural network that models images as Boolean fields governed by logic gates.
Each pixel is a Boolean variable (0 or 1) embedded on a two-dimensional
geometric manifold (for example, a discrete toroidal lattice), which defines
adjacency and information propagation among pixels. The network updates image
states through a Boolean reaction-diffusion mechanism: pixels receive Boolean
diffusion from neighboring pixels (diffusion process) and perform local logic
updates via trainable gate-level logic kernels (reaction process), forming a
reaction-diffusion logic network.
 A Boolean self-attention mechanism is introduced, using XNOR-based Boolean
Query-Key (Q-K) attention to modulate neighborhood diffusion pathways and
realize logic attention. We also propose Boolean Rotary Position Embedding
(RoPE), which encodes relative distances by parity-bit flipping to simulate
Boolean ``phase'' offsets.
 The overall structure resembles a Transformer but operates entirely in the
Boolean domain. Trainable parameters include Q-K pattern bits and gate-level
kernel configurations. Because outputs are discrete, continuous relaxation
methods (such as sigmoid approximation or soft-logic operators) ensure
differentiable training.
 Theoretical analysis shows that the network achieves universal expressivity,
interpretability, and hardware efficiency, capable of reproducing convolutional
and attention mechanisms. Applications include high-speed image processing,
interpretable artificial intelligence, and digital hardware acceleration,
offering promising future research directions.
\\ ( https://arxiv.org/abs/2511.17550 ,  24kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17558 (*cross-listing*)
Date: Thu, 13 Nov 2025 04:57:31 GMT   (3582kb)

Title: WaveC2R: Wavelet-Driven Coarse-to-Refined Hierarchical Learning for
 Radar Retrieval
Authors: Chunlei Shi, Han Xu, Yinghao Li, Yi-Lin Wei, Yongchao Feng, Yecheng
 Zhang, Dan Niu
Categories: eess.SP cs.AI
Comments: AAAI2026 Project's webpage at this
 URL:https://spring-lovely.github.io/WaveC2R/
\\
 Satellite-based radar retrieval methods are widely employed to fill coverage
gaps in ground-based radar systems, especially in remote areas affected by
terrain blockage and limited detection range. Existing methods predominantly
rely on overly simplistic spatial-domain architectures constructed from a
single data source, limiting their ability to accurately capture complex
precipitation patterns and sharply defined meteorological boundaries. To
address these limitations, we propose WaveC2R, a novel wavelet-driven
coarse-to-refined framework for radar retrieval. WaveC2R integrates
complementary multi-source data and leverages frequency-domain decomposition to
separately model low-frequency components for capturing precipitation patterns
and high-frequency components for delineating sharply defined meteorological
boundaries. Specifically, WaveC2R consists of two stages (i)Intensity-Boundary
Decoupled Learning, which leverages wavelet decomposition and
frequency-specific loss functions to separately optimize low-frequency
intensity and high-frequency boundaries; and (ii)Detail-Enhanced Diffusion
Refinement, which employs frequency-aware conditional priors and multi-source
data to progressively enhance fine-scale precipitation structures while
preserving coarse-scale meteorological consistency. Experimental results on the
publicly available SEVIR dataset demonstrate that WaveC2R achieves
state-of-the-art performance in satellite-based radar retrieval, particularly
excelling at preserving high-intensity precipitation features and sharply
defined meteorological boundaries.
\\ ( https://arxiv.org/abs/2511.17558 ,  3582kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17563 (*cross-listing*)
Date: Thu, 13 Nov 2025 14:14:21 GMT   (2134kb)

Title: Dynamic Weight Adaptation in Spiking Neural Networks Inspired by
 Biological Homeostasis
Authors: Yunduo Zhou, Bo Dong, Chang Li, Yuanchen Wang, Xuefeng Yin, Yang Wang,
 Xin Yang
Categories: cs.NE cs.AI
\\
 Homeostatic mechanisms play a crucial role in maintaining optimal
functionality within the neural circuits of the brain. By regulating
physiological and biochemical processes, these mechanisms ensure the stability
of an organism's internal environment, enabling it to better adapt to external
changes. Among these mechanisms, the Bienenstock, Cooper, and Munro (BCM)
theory has been extensively studied as a key principle for maintaining the
balance of synaptic strengths in biological systems. Despite the extensive
development of spiking neural networks (SNNs) as a model for bionic neural
networks, no prior work in the machine learning community has integrated
biologically plausible BCM formulations into SNNs to provide homeostasis. In
this study, we propose a Dynamic Weight Adaptation Mechanism (DWAM) for SNNs,
inspired by the BCM theory. DWAM can be integrated into the host SNN,
dynamically adjusting network weights in real time to regulate neuronal
activity, providing homeostasis to the host SNN without any fine-tuning. We
validated our method through dynamic obstacle avoidance and continuous control
tasks under both normal and specifically designed degraded conditions.
Experimental results demonstrate that DWAM not only enhances the performance of
SNNs without existing homeostatic mechanisms under various degraded conditions
but also further improves the performance of SNNs that already incorporate
homeostatic mechanisms.
\\ ( https://arxiv.org/abs/2511.17563 ,  2134kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17567 (*cross-listing*)
Date: Fri, 14 Nov 2025 05:08:14 GMT   (2574kb)

Title: Temporal-adaptive Weight Quantization for Spiking Neural Networks
Authors: Han Zhang, Qingyan Meng, Jiaqi Wang, Baiyu Chen, Zhengyu Ma, Xiaopeng
 Fan
Categories: cs.NE cs.AI cs.CV
\\
 Weight quantization in spiking neural networks (SNNs) could further reduce
energy consumption. However, quantizing weights without sacrificing accuracy
remains challenging. In this study, inspired by astrocyte-mediated synaptic
modulation in the biological nervous systems, we propose Temporal-adaptive
Weight Quantization (TaWQ), which incorporates weight quantization with
temporal dynamics to adaptively allocate ultra-low-bit weights along the
temporal dimension. Extensive experiments on static (e.g., ImageNet) and
neuromorphic (e.g., CIFAR10-DVS) datasets demonstrate that our TaWQ maintains
high energy efficiency (4.12M, 0.63mJ) while incurring a negligible
quantization loss of only 0.22% on ImageNet.
\\ ( https://arxiv.org/abs/2511.17567 ,  2574kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17571 (*cross-listing*)
Date: Fri, 14 Nov 2025 18:40:40 GMT   (681kb)

Title: An improved clustering-based multi-swarm PSO using local diversification
 and topology information
Authors: Yves Matanga, Yanxia Sun and Zenghui Wang
Categories: cs.NE cs.AI
\\
 Multi-swarm particle optimisation algorithms are gaining popularity due to
their ability to locate multiple optimum points concurrently. In this family of
algorithms, clustering-based multi-swarm algorithms are among the most
effective techniques that join the closest particles together to form
independent niche swarms that exploit potential promising regions. However,
most clustering-based multi-swarms are Euclidean distance-based and only
inquire about the potential of one peak within a cluster and thus can lose
multiple peaks due to poor resolution. In a bid to improve the peak detection
ratio, the current study proposes two enhancements. First, a preliminary local
search across initial particles is proposed to ensure that each local region is
sufficiently scouted prior to particle collaboration. Secondly, an
investigative clustering approach that performs concavity analysis is proposed
to evaluate the potential for several sub-niches within a single cluster. An
improved clustering-based multi-swarm PSO (TImPSO) has resulted from these
enhancements and has been tested against three competing algorithms in the same
family using the IEEE CEC2013 niching datasets, resulting in an improved peak
ratio for almost all the test functions.
\\ ( https://arxiv.org/abs/2511.17571 ,  681kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17574 (*cross-listing*)
Date: Fri, 14 Nov 2025 23:04:04 GMT   (270kb)

Title: Constructing Political Coordinates: Aggregating Over the Opposition for
 Diverse News Recommendation
Authors: Eamon Earl, Chen Ding, Richard Valenzano, and Drai Paulen-Patterson
Categories: cs.SI cs.AI cs.CY
Comments: Due to appear in the proceedings of the 2025 IEEE International
 Conference on Big Data
\\
 In the past two decades, open access to news and information has increased
rapidly, empowering educated political growth within democratic societies. News
recommender systems (NRSs) have shown to be useful in this process, minimizing
political disengagement and information overload by providing individuals with
articles on topics that matter to them. Unfortunately, NRSs often conflate
underlying user interest with the partisan bias of the articles in their
reading history and with the most popular biases present in the coverage of
their favored topics. Over extended interaction, this can result in the
formation of filter bubbles and the polarization of user partisanship. In this
paper, we propose a novel embedding space called Constructed Political
Coordinates (CPC), which models the political partisanship of users over a
given topic-space, relative to a larger sample population. We apply a simple
collaborative filtering (CF) framework using CPC-based correlation to recommend
articles sourced from oppositional users, who have different biases from the
user in question. We compare against classical CF methods and find that
CPC-based methods promote pointed bias diversity and better match the true
political tolerance of users, while classical methods implicitly exploit biases
to maximize interaction.
\\ ( https://arxiv.org/abs/2511.17574 ,  270kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17580 (*cross-listing*)
Date: Sat, 15 Nov 2025 14:05:23 GMT   (356kb)

Title: A novel strategy for multi-resource load balancing in agent-based
 systems
Authors: Leszek Sliwko, Aleksander Zgrzywa
Categories: cs.MA cs.AI cs.DC cs.SE
Journal-ref: "A novel strategy for multi-resource load balancing in agent-based
 systems." International journal of intelligent information and database
 systems (Print) 3, no. 2 (2009): 180-202
DOI: 10.1504/IJIIDS.2009.025162
\\
 The paper presents a multi-resource load balancing strategy which can be
utilised within an agent-based system. This approach can assist system
designers in their attempts to optimise the structure for complex enterprise
architectures. In this system, the social behaviour of the agent and its
adaptation abilities are applied to determine an optimal setup for a given
configuration. All the methods have been developed to allow the agent's
self-assessment. The proposed agent system has been implemented and the
experiment results are presented here.
\\ ( https://arxiv.org/abs/2511.17580 ,  356kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17586 (*cross-listing*)
Date: Sun, 16 Nov 2025 15:09:15 GMT   (142kb)

Title: Hierarchical Adaptive Consensus Network: A Dynamic Framework for
 Scalable Consensus in Collaborative Multi-Agent AI Systems
Authors: Rathin Chandra Shit and Sharmila Subudhi
Categories: cs.MA cs.AI
Comments: Submitted to Elsevier
\\
 The consensus strategies used in collaborative multi-agent systems (MAS) face
notable challenges related to adaptability, scalability, and convergence
certainties. These approaches, including structured workflows, debate models,
and iterative voting, often lead to communication bottlenecks, stringent
decision-making processes, and delayed responses in solving complex and
evolving tasks. This article introduces a three-tier architecture, the
Hierarchical Adaptive Consensus Network (\hacn), which suggests various
consensus policies based on task characterization and agent performance
metrics. The first layer collects the confidence-based voting outcomes of
several local agent clusters. In contrast, the second level facilitates
inter-cluster communication through cross-clustered partial knowledge sharing
and dynamic timeouts. The third layer provides system-wide coordination and
final arbitration by employing a global orchestration framework with adaptable
decision rules. The proposed model achieves $\bigO(n)$ communication
complexity, as opposed to the $\bigO(n^2)$ complexity of the existing fully
connected MAS. Experiments performed in a simulated environment yielded a
99.9\% reduction in communication overhead during consensus convergence.
Furthermore, the proposed approach ensures consensus convergence through
hierarchical escalation and dynamic adaptation for a wide variety of
complicated tasks.
\\ ( https://arxiv.org/abs/2511.17586 ,  142kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17592 (*cross-listing*)
Date: Mon, 17 Nov 2025 14:44:47 GMT   (1506kb)

Title: GigaEvo: An Open Source Optimization Framework Powered By LLMs And
 Evolution Algorithms
Authors: Valentin Khrulkov, Andrey Galichin, Denis Bashkirov, Dmitry
 Vinichenko, Oleg Travkin, Roman Alferov, Andrey Kuznetsov, Ivan Oseledets
Categories: cs.NE cs.AI cs.LG
\\
 Recent advances in LLM-guided evolutionary computation, particularly
AlphaEvolve (Novikov et al., 2025; Georgiev et al., 2025), have demonstrated
remarkable success in discovering novel mathematical constructions and solving
challenging optimization problems. However, the high-level descriptions in
published work leave many implementation details unspecified, hindering
reproducibility and further research. In this report we present GigaEvo, an
extensible open-source framework that enables researchers to study and
experiment with hybrid LLM-evolution approaches inspired by AlphaEvolve. Our
system provides modular implementations of key components: MAP-Elites
quality-diversity algorithms, asynchronous DAG-based evaluation pipelines,
LLM-driven mutation operators with insight generation and bidirectional lineage
tracking, and flexible multi-island evolutionary strategies. In order to assess
reproducibility and validate our implementation we evaluate GigaEvo on
challenging problems from the AlphaEvolve paper: Heilbronn triangle placement,
circle packing in squares, and high-dimensional kissing numbers. The framework
emphasizes modularity, concurrency, and ease of experimentation, enabling rapid
prototyping through declarative configuration. We provide detailed descriptions
of system architecture, implementation decisions, and experimental methodology
to support further research in LLM driven evolutionary methods. The GigaEvo
framework and all experimental code are available at
https://github.com/AIRI-Institute/gigaevo-core.
\\ ( https://arxiv.org/abs/2511.17592 ,  1506kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17621 (*cross-listing*)
Date: Tue, 18 Nov 2025 16:47:15 GMT   (519kb)

Title: From Competition to Coordination: Market Making as a Scalable Framework
 for Safe and Aligned Multi-Agent LLM Systems
Authors: Brendan Gho, Suman Muppavarapu, Afnan Shaik, Tyson Tsay, James Begin,
 Kevin Zhu, Archana Vaidheeswaran, Vasu Sharma
Categories: cs.MA cs.AI cs.CL
\\
 As foundation models are increasingly deployed as interacting agents in
multi-agent systems, their collective behavior raises new challenges for
trustworthiness, transparency, and accountability. Traditional coordination
mechanisms, such as centralized oversight or adversarial adjudication, struggle
to scale and often obscure how decisions emerge. We introduce a market-making
framework for multi-agent large language model (LLM) coordination that
organizes agent interactions as structured economic exchanges. In this setup,
each agent acts as a market participant, updating and trading probabilistic
beliefs, to converge toward shared, truthful outcomes. By aligning local
incentives with collective epistemic goals, the framework promotes
self-organizing, verifiable reasoning without requiring external enforcement.
Empirically, we evaluate this approach across factual reasoning, ethical
judgment, and commonsense inference tasks. Market-based coordination yields
accuracy gains of up to 10% over single-shot baselines while preserving
interpretability and transparency of intermediate reasoning steps. Beyond these
improvements, our findings demonstrate that economic coordination principles
can operationalize accountability and robustness in multi-agent LLM systems,
offering a scalable pathway toward self-correcting, socially responsible AI
capable of maintaining trust and oversight in real world deployment scenarios.
\\ ( https://arxiv.org/abs/2511.17621 ,  519kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17654 (*cross-listing*)
Date: Thu, 20 Nov 2025 16:40:12 GMT   (12kb)

Title: Dialogue Diplomats: An End-to-End Multi-Agent Reinforcement Learning
 System for Automated Conflict Resolution and Consensus Building
Authors: Deepak Bolleddu
Categories: cs.MA cs.AI
\\
 Conflict resolution and consensus building represent critical challenges in
multi-agent systems, negotiations, and collaborative decision-making processes.
This paper introduces Dialogue Diplomats, a novel end-to-end multi-agent
reinforcement learning (MARL) framework designed for automated conflict
resolution and consensus building in complex, dynamic environments. The
proposed system integrates advanced deep reinforcement learning architectures
with dialogue-based negotiation protocols, enabling autonomous agents to engage
in sophisticated conflict resolution through iterative communication and
strategic adaptation. We present three primary contributions: first, a novel
Hierarchical Consensus Network (HCN) architecture that combines attention
mechanisms with graph neural networks to model inter-agent dependencies and
conflict dynamics. second, a Progressive Negotiation Protocol (PNP) that
structures multi-round dialogue interactions with adaptive concession
strategies; and third, a Context-Aware Reward Shaping mechanism that balances
individual agent objectives with collective consensus goals.
\\ ( https://arxiv.org/abs/2511.17654 ,  12kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17658 (*cross-listing*)
Date: Thu, 20 Nov 2025 19:58:25 GMT   (121kb)

Title: Predicting Healthcare Provider Engagement in SMS Campaigns
Authors: Daanish Aleem Qureshi, Rafay Chaudhary, Kok Seng Tan, Or Maoz, Scott
 Burian, Michael Gelber, Phillip Hoon Kang, and Alan George Labouseur
Categories: physics.soc-ph cs.AI cs.CY cs.LG stat.ML
\\
 As digital communication grows in importance when connecting with healthcare
providers, traditional behavioral and content message features are imbued with
renewed significance. If one is to meaningfully connect with them, it is
crucial to understand what drives them to engage and respond. In this study,
the authors analyzed several million text messages sent through the Impiricus
platform to learn which factors influenced whether or not a doctor clicked on a
link in a message. Several key insights came to light through the use of
logistic regression, random forest, and neural network models, the details of
which the authors discuss in this paper.
\\ ( https://arxiv.org/abs/2511.17658 ,  121kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17666 (*cross-listing*)
Date: Fri, 21 Nov 2025 01:23:56 GMT   (28kb)

Title: Evaluating Adversarial Vulnerabilities in Modern Large Language Models
Authors: Tom Perel
Categories: cs.CR cs.AI
\\
 The recent boom and rapid integration of Large Language Models (LLMs) into a
wide range of applications warrants a deeper understanding of their security
and safety vulnerabilities. This paper presents a comparative analysis of the
susceptibility to jailbreak attacks for two leading publicly available LLMs,
Google's Gemini 2.5 Flash and OpenAI's GPT-4 (specifically the GPT-4o mini
model accessible in the free tier). The research utilized two main bypass
strategies: 'self-bypass', where models were prompted to circumvent their own
safety protocols, and 'cross-bypass', where one model generated adversarial
prompts to exploit vulnerabilities in the other. Four attack methods were
employed - direct injection, role-playing, context manipulation, and
obfuscation - to generate five distinct categories of unsafe content: hate
speech, illegal activities, malicious code, dangerous content, and
misinformation. The success of the attack was determined by the generation of
disallowed content, with successful jailbreaks assigned a severity score. The
findings indicate a disparity in jailbreak susceptibility between 2.5 Flash and
GPT-4, suggesting variations in their safety implementations or architectural
design. Cross-bypass attacks were particularly effective, indicating that an
ample amount of vulnerabilities exist in the underlying transformer
architecture. This research contributes a scalable framework for automated AI
red-teaming and provides data-driven insights into the current state of LLM
safety, underscoring the complex challenge of balancing model capabilities with
robust safety mechanisms.
\\ ( https://arxiv.org/abs/2511.17666 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17669 (*cross-listing*)
Date: Fri, 21 Nov 2025 03:52:22 GMT   (400kb)

Title: Empa: An AI-Powered Virtual Mentor for Developing Global Collaboration
 Skills in HPC Education
Authors: Ashish, Aparajita Jaiswal, Sudip Vhaduri, Niveditha Nerella, Shubham
 Jha
Categories: cs.CY cs.AI
\\
 High-performance computing (HPC) and parallel computing increasingly rely on
global collaboration among diverse teams, yet traditional computing curricula
inadequately prepare students for cross-cultural teamwork essential in modern
computational research environments. This paper presents Empa, an AI-powered
virtual mentor that integrates intercultural collaboration training into
undergraduate computing education. Built using large language models and
deployed through a progressive web application, Empa guides students through
structured activities covering cultural dimensions, communication styles, and
conflict resolution that are critical for effective multicultural teamwork. Our
system addresses the growing need for culturally competent HPC professionals by
helping computing students develop skills to collaborate effectively in
international research teams, contribute to global computational projects, and
navigate the cultural complexities inherent in distributed computing
environments. Pilot preparation for deployment in computing courses
demonstrates the feasibility of AI-mediated intercultural training and provides
insights into scalable approaches for developing intercultural collaboration
skills essential for HPC workforce development.
\\ ( https://arxiv.org/abs/2511.17669 ,  400kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17671 (*cross-listing*)
Date: Fri, 21 Nov 2025 04:56:37 GMT   (3160kb)

Title: MURMUR: Using cross-user chatter to break collaborative language agents
 in groups
Authors: Atharv Singh Patlan, Peiyao Sheng, S. Ashwin Hebbar, Prateek Mittal,
 Pramod Viswanath
Categories: cs.CR cs.AI cs.CL
Comments: 20 pages, 7 figures
\\
 Language agents are rapidly expanding from single-user assistants to
multi-user collaborators in shared workspaces and groups. However, today's
language models lack a mechanism for isolating user interactions and concurrent
tasks, creating a new attack vector inherent to this new setting: cross-user
poisoning (CUP). In a CUP attack, an adversary injects ordinary-looking
messages that poison the persistent, shared state, which later triggers the
agent to execute unintended, attacker-specified actions on behalf of benign
users. We validate CUP on real systems, successfully attacking popular
multi-user agents. To study the phenomenon systematically, we present MURMUR, a
framework that composes single-user tasks into concurrent, group-based
scenarios using an LLM to generate realistic, history-aware user interactions.
We observe that CUP attacks succeed at high rates and their effects persist
across multiple tasks, thus posing fundamental risks to multi-user LLM
deployments. Finally, we introduce a first-step defense with task-based
clustering to mitigate this new class of vulnerability
\\ ( https://arxiv.org/abs/2511.17671 ,  3160kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17676 (*cross-listing*)
Date: Fri, 21 Nov 2025 07:16:31 GMT   (1244kb)

Title: LLM and Agent-Driven Data Analysis: A Systematic Approach for Enterprise
 Applications and System-level Deployment
Authors: Xi Wang, Xianyao Ling, Kun Li, Gang Yin, Liang Zhang, Jiang Wu, Annie
 Wang, Weizhe Wang
Categories: cs.DB cs.AI cs.CL
\\
 The rapid progress in Generative AI and Agent technologies is profoundly
transforming enterprise data management and analytics. Traditional database
applications and system deployment are fundamentally impacted by AI-driven
tools, such as Retrieval-Augmented Generation (RAG) and vector database
technologies, which provide new pathways for semantic querying over enterprise
knowledge bases. In the meantime, data security and compliance are top
priorities for organizations adopting AI technologies. For enterprise data
analysis, SQL generations powered by large language models (LLMs) and AI
agents, has emerged as a key bridge connecting natural language with structured
data, effectively lowering the barrier to enterprise data access and improving
analytical efficiency. This paper focuses on enterprise data analysis
applications and system deployment, covering a range of innovative frameworks,
enabling complex query understanding, multi-agent collaboration, security
verification, and computational efficiency. Through representative use cases,
key challenges related to distributed deployment, data security, and inherent
difficulties in SQL generation tasks are discussed.
\\ ( https://arxiv.org/abs/2511.17676 ,  1244kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17678 (*cross-listing*)
Date: Fri, 21 Nov 2025 07:59:50 GMT   (1396kb)

Title: Chatbots to strengthen democracy: An interdisciplinary seminar to train
 identifying argumentation techniques of science denial
Authors: Ingo Siegert and Jan Nehring and Aranxa M\'arquez Ampudia and Matthias
 Busch and Stefan Hillmann
Categories: cs.CY cs.AI cs.HC
Comments: 6 pages, 4 figures
\\
 In recent times, discussions on social media platforms have increasingly come
under scrutiny due to the proliferation of science denial and fake news.
Traditional solutions, such as regulatory actions, have been implemented to
mitigate the spread of misinformation; however, these measures alone are not
sufficient. To complement these efforts, educational approaches are becoming
essential in empowering users to critically engage with misinformation.
Conversation training, through serious games or personalized methods, has
emerged as a promising strategy to help users handle science denial and toxic
conversation tactics. This paper suggests an interdisciplinary seminar to
explore the suitability of Large Language Models (LLMs) acting as a persona of
a science denier to support people in identifying misinformation and improving
resilience against toxic interactions. In the seminar, groups of four to five
students will develop an AI-based chatbot that enables realistic interactions
with science-denial argumentation structures. The task involves planning the
setting, integrating a Large Language Model to facilitate natural dialogues,
implementing the chatbot using the RASA framework, and evaluating the outcomes
in a user study. It is crucial that users understand what they need to do
during the interaction, how to conclude it, and how the relevant information is
conveyed. The seminar does not aim to develop chatbots for practicing debunking
but serves to teach AI technologies and test the feasibility of this idea for
future applications. The chatbot seminar is conducted as a hybrid, parallel
master's module at the participating educational institutions.
\\ ( https://arxiv.org/abs/2511.17678 ,  1396kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17680 (*cross-listing*)
Date: Fri, 21 Nov 2025 08:26:22 GMT   (2645kb)

Title: Research and Prototyping Study of an LLM-Based Chatbot for
 Electromagnetic Simulations
Authors: Albert Piwonski and Mirsad Had\v{z}iefendi\'c
Categories: cs.CE cs.AI
Comments: This paper has been submitted to COMPEL for possible publication,
 published by Emerald Publishing Limited
\\
 This work addresses the question of how generative artificial intelligence
can be used to reduce the time required to set up electromagnetic simulation
models. A chatbot based on a large language model is presented, enabling the
automated generation of simulation models with various functional enhancements.
A chatbot-driven workflow based on the large language model Google Gemini 2.0
Flash automatically generates and solves two-dimensional finite element eddy
current models using Gmsh and GetDP. Python is used to coordinate and automate
interactions between the workflow components. The study considers conductor
geometries with circular cross-sections of variable position and number.
Additionally, users can define custom post-processing routines and receive a
concise summary of model information and simulation results. Each functional
enhancement includes the corresponding architectural modifications and
illustrative case studies.
\\ ( https://arxiv.org/abs/2511.17680 ,  2645kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17682 (*cross-listing*)
Date: Fri, 21 Nov 2025 09:33:49 GMT   (171kb)

Title: A Cross-Cultural Assessment of Human Ability to Detect LLM-Generated
 Fake News about South Africa
Authors: Tim Schlippe and Matthias W\"olfel and Koena Ronny Mabokela
Categories: cs.CY cs.AI cs.CL
Journal-ref: The Southern African Conference on AI Research (SACAIR 2025),
 Century City, South Africa, 1-5 December 2025
\\
 This study investigates how cultural proximity affects the ability to detect
AI-generated fake news by comparing South African participants with those from
other nationalities. As large language models increasingly enable the creation
of sophisticated fake news, understanding human detection capabilities becomes
crucial, particularly across different cultural contexts. We conducted a survey
where 89 participants (56 South Africans, 33 from other nationalities)
evaluated 10 true South African news articles and 10 AI-generated fake
versions. Results reveal an asymmetric pattern: South Africans demonstrated
superior performance in detecting true news about their country (40% deviation
from ideal rating) compared to other participants (52%), but performed worse at
identifying fake news (62% vs. 55%). This difference may reflect South
Africans' higher overall trust in news sources. Our analysis further shows that
South Africans relied more on content knowledge and contextual understanding
when judging credibility, while participants from other countries emphasised
formal linguistic features such as grammar and structure. Overall, the
deviation from ideal rating was similar between groups (51% vs. 53%),
suggesting that cultural familiarity appears to aid verification of authentic
information but may also introduce bias when evaluating fabricated content.
These insights contribute to understanding cross-cultural dimensions of
misinformation detection and inform strategies for combating AI-generated fake
news in increasingly globalised information ecosystems where content crosses
cultural and geographical boundaries.
\\ ( https://arxiv.org/abs/2511.17682 ,  171kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17683 (*cross-listing*)
Date: Fri, 21 Nov 2025 09:48:44 GMT   (299kb)

Title: Datacenters in the Desert: Feasibility and Sustainability of LLM
 Inference in the Middle East
Authors: Lara Hassan, Mohamed ElZeftawy, Abdulrahman Mahmoud
Categories: cs.CY cs.AI
Comments: 3 pages, 1 figure
Journal-ref: DCEE-2025@ISCA-2025
\\
 As the Middle East emerges as a strategic hub for artificial intelligence
(AI) infrastructure, the feasibility of deploying sustainable datacenters in
desert environments has become a topic of growing relevance. This paper
presents an empirical study analyzing the energy consumption and carbon
footprint of large language model (LLM) inference across four countries: the
United Arab Emirates, Iceland, Germany, and the United States of America using
DeepSeek Coder 1.3B and the HumanEval dataset on the task of code generation.
We use the CodeCarbon library to track energy and carbon emissions andcompare
geographical trade-offs for climate-aware AI deployment. Our findings highlight
both the challenges and potential of datacenters in desert regions and provide
a balanced outlook on their role in global AI expansion.
\\ ( https://arxiv.org/abs/2511.17683 ,  299kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17685 (*cross-listing*)
Date: Fri, 21 Nov 2025 10:58:04 GMT   (14381kb)

Title: Dual-Path Knowledge-Augmented Contrastive Alignment Network for
 Spatially Resolved Transcriptomics
Authors: Wei Zhang, Jiajun Chu, Xinci Liu, Chen Tong, Xinyue Li
Categories: q-bio.QM cs.AI
Comments: AAAI 2026 Oral, extended version
\\
 Spatial Transcriptomics (ST) is a technology that measures gene expression
profiles within tissue sections while retaining spatial context. It reveals
localized gene expression patterns and tissue heterogeneity, both of which are
essential for understanding disease etiology. However, its high cost has driven
efforts to predict spatial gene expression from whole slide images. Despite
recent advancements, current methods still face significant limitations, such
as under-exploitation of high-level biological context, over-reliance on
exemplar retrievals, and inadequate alignment of heterogeneous modalities. To
address these challenges, we propose DKAN, a novel Dual-path
Knowledge-Augmented contrastive alignment Network that predicts spatially
resolved gene expression by integrating histopathological images and gene
expression profiles through a biologically informed approach. Specifically, we
introduce an effective gene semantic representation module that leverages the
external gene database to provide additional biological insights, thereby
enhancing gene expression prediction. Further, we adopt a unified, one-stage
contrastive learning paradigm, seamlessly combining contrastive learning and
supervised learning to eliminate reliance on exemplars, complemented with an
adaptive weighting mechanism. Additionally, we propose a dual-path contrastive
alignment module that employs gene semantic features as dynamic cross-modal
coordinators to enable effective heterogeneous feature integration. Through
extensive experiments across three public ST datasets, DKAN demonstrates
superior performance over state-of-the-art models, establishing a new benchmark
for spatial gene expression prediction and offering a powerful tool for
advancing biological and clinical research.
\\ ( https://arxiv.org/abs/2511.17685 ,  14381kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17689 (*cross-listing*)
Date: Fri, 21 Nov 2025 14:14:35 GMT   (6768kb)

Title: ARISE: Agentic Rubric-Guided Iterative Survey Engine for Automated
 Scholarly Paper Generation
Authors: Zi Wang, Xingqiao Wang, Sangah Lee, Xiaowei Xu
Categories: cs.DL cs.AI
Comments: 20 pages including an appendix, 7 figures and 6 tables
MSC-class: 68T50, 68T40, 68U35
ACM-class: I.2.7; I.2.11; H.3.3
\\
 The rapid expansion of scholarly literature presents significant challenges
in synthesizing comprehensive, high-quality academic surveys. Recent
advancements in agentic systems offer considerable promise for automating tasks
that traditionally require human expertise, including literature review,
synthesis, and iterative refinement. However, existing automated
survey-generation solutions often suffer from inadequate quality control, poor
formatting, and limited adaptability to iterative feedback, which are core
elements intrinsic to scholarly writing.
 To address these limitations, we introduce ARISE, an Agentic Rubric-guided
Iterative Survey Engine designed for automated generation and continuous
refinement of academic survey papers. ARISE employs a modular architecture
composed of specialized large language model agents, each mirroring distinct
scholarly roles such as topic expansion, citation curation, literature
summarization, manuscript drafting, and peer-review-based evaluation. Central
to ARISE is a rubric-guided iterative refinement loop in which multiple
reviewer agents independently assess manuscript drafts using a structured,
behaviorally anchored rubric, systematically enhancing the content through
synthesized feedback.
 Evaluating ARISE against state-of-the-art automated systems and recent
human-written surveys, our experimental results demonstrate superior
performance, achieving an average rubric-aligned quality score of 92.48. ARISE
consistently surpasses baseline methods across metrics of comprehensiveness,
accuracy, formatting, and overall scholarly rigor. All code, evaluation
rubrics, and generated outputs are provided openly at
https://github.com/ziwang11112/ARISE
\\ ( https://arxiv.org/abs/2511.17689 ,  6768kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17696 (*cross-listing*)
Date: Fri, 21 Nov 2025 17:28:52 GMT   (2403kb)

Title: Liberating Logic in the Age of AI: Going Beyond Programming with
 Computational Thinking
Authors: Douglas C. Schmidt and Dan Runfola
Categories: cs.CY cs.AI
Comments: 15 pages and 17 figures
\\
 Mastering one or more programming languages has historically been the gateway
to implementing ideas on a computer. Today, that gateway is widening with
advances in large language models (LLMs) and artificial intelligence
(AI)-powered coding assistants. What matters is no longer just fluency in
traditional programming languages but the ability to think computationally by
translating problems into forms that can be solved with computing tools. The
capabilities enabled by these AI-augmented tools are rapidly leading to the
commoditization of computational thinking, such that anyone who can articulate
a problem in natural language can potentially harness computing power via AI.
 This shift is poised to radically influence how we teach computer science and
data science in the United States and around the world. Educators and industry
leaders are grappling with how to adapt: What should students learn when the
hottest new programming language is English? How do we prepare a generation of
computational thinkers who need not code every algorithm manually, but must
still think critically, design solutions, and verify AI-augmented results?
 This paper explores these questions, examining the impact of natural language
programming on software development, the emerging distinction between
programmers and prompt-crafting problem solvers, the reforms needed in computer
science and data science curricula, and the importance of maintaining our
fundamental computational science principles in an AI-augmented future. Along
the way, we compare approaches and share best practices for embracing this new
paradigm in computing education.
\\ ( https://arxiv.org/abs/2511.17696 ,  2403kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17728 (*cross-listing*)
Date: Fri, 21 Nov 2025 19:26:18 GMT   (14kb)

Title: Ternary Gamma Semirings as a Novel Algebraic Framework for Learnable
 Symbolic Reasoning
Authors: Chandrasekhar Gokavarapu (Department of Mathematics, Government
 College (Autonomous), Rajahmundry, Andhra Pradesh, India and, Department of
 Mathematics, Acharya Nagarjuna University, Guntur, Andhra Pradesh, India) and
 D. Madhusudhana Rao (Department of Mathematics, Government College for Women
 (Autonomous), Guntur, Andhra Pradesh, India and, Department of Mathematics,
 Acharya Nagarjuna University, Guntur, Andhra Pradesh, India)
Categories: math.RA cs.AI
MSC-class: 08A05, 08A30, 16Y60, 68T07
\\
 Binary semirings such as the tropical, log, and probability semirings form a
core algebraic tool in classical and modern neural inference systems,
supporting tasks like Viterbi decoding, dynamic programming, and probabilistic
reasoning. However, these structures rely on a binary multiplication operator
and therefore model only pairwise interactions. Many symbolic AI tasks are
inherently triadic, including subject-predicate-object relations in knowledge
graphs, logical rules involving two premises and one conclusion, and
multi-entity dependencies in structured decision processes. Existing neural
architectures usually approximate these interactions by flattening or
factorizing them into binary components, which weakens inductive structure,
distorts relational meaning, and reduces interpretability.
 This paper introduces the Neural Ternary Semiring (NTS), a learnable and
differentiable algebraic framework grounded in the theory of ternary
Gamma-semirings. The central idea is to replace the usual binary product with a
native ternary operator implemented by neural networks and guided by algebraic
regularizers enforcing approximate associativity and distributivity. This
construction allows triadic relationships to be represented directly rather
than reconstructed from binary interactions.
 We establish a soundness result showing that, when algebraic violations
vanish during training, the learned operator converges to a valid ternary
Gamma-semiring. We also outline an evaluation strategy for triadic reasoning
tasks such as knowledge-graph completion and rule-based inference. These
insights demonstrate that ternary Gamma-semirings provide a mathematically
principled and practically effective foundation for learnable symbolic
reasoning.
\\ ( https://arxiv.org/abs/2511.17728 ,  14kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17753 (*cross-listing*)
Date: Fri, 21 Nov 2025 20:10:29 GMT   (2633kb)

Title: $\Delta$-ML Ensembles for Selecting Quantum Chemistry Methods to Compute
 Intermolecular Interactions
Authors: Austin M. Wallace and C. David Sherrill and Giri P. Krishnan
Categories: physics.chem-ph cs.AI
Comments: NeurIPS ML4PS 2025
\\
 Ab initio quantum chemical methods for accurately computing interactions
between molecules have a wide range of applications but are often
computationally expensive. Hence, selecting an appropriate method based on
accuracy and computational cost remains a significant challenge due to varying
performance of methods. In this work, we propose a framework based on an
ensemble of $\Delta$-ML models trained on features extracted from a pre-trained
atom-pairwise neural network to predict the error of each method relative to
all other methods including the ``gold standard'' coupled cluster with single,
double, and perturbative triple excitations at the estimated complete basis set
limit [CCSD(T)/CBS]. Our proposed approach provides error estimates across
various levels of theories and identifies the computationally efficient
approach for a given error range utilizing only a subset of the dataset.
Further, this approach allows comparison between various theories. We
demonstrate the effectiveness of our approach using an extended BioFragment
dataset, which includes the interaction energies for common biomolecular
fragments and small organic dimers. Our results show that the proposed
framework achieves very small mean-absolute-errors below 0.1 kcal/mol
regardless of the given method. Furthermore, by analyzing all-to-all
$\Delta$-ML models for present levels of theory, we identify method groupings
that align with theoretical hypotheses, providing evidence that $\Delta$-ML
models can easily learn corrections from any level of theory to any other level
of theory.
\\ ( https://arxiv.org/abs/2511.17753 ,  2633kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17775 (*cross-listing*)
Date: Fri, 21 Nov 2025 20:47:41 GMT   (427kb)

Title: Episodic Memory in Agentic Frameworks: Suggesting Next Tasks
Authors: Sandro Rama Fiorini and Leonardo G. Azevedo and Raphael M. Thiago and
 Valesca M. de Sousa and Anton B. Labate and Viviane Torres da Silva
Categories: cs.MA cs.AI cs.LG
\\
 Agentic frameworks powered by Large Language Models (LLMs) can be useful
tools in scientific workflows by enabling human-AI co-creation. A key challenge
is recommending the next steps during workflow creation without relying solely
on LLMs, which risk hallucination and require fine-tuning with scarce
proprietary data. We propose an episodic memory architecture that stores and
retrieves past workflows to guide agents in suggesting plausible next tasks. By
matching current workflows with historical sequences, agents can recommend
steps based on prior patterns.
\\ ( https://arxiv.org/abs/2511.17775 ,  427kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17853 (*cross-listing*)
Date: Sat, 22 Nov 2025 00:40:02 GMT   (451kb)

Title: A Low-Code Methodology for Developing AI Kiosks: a Case Study with the
 DIZEST Platform
Authors: SunMin Moon, Jangwon Gim, Chaerin Kim, Yeeun Kim, YoungJoo Kim, Kang
 Choi
Categories: cs.SE cs.AI
Comments: 5 pages, 2 figures, conference, 2 tables
\\
 This paper presents a comprehensive study on enhancing kiosk systems through
a low-code architecture, with a focus on AI-based implementations. Modern kiosk
systems are confronted with significant challenges, including a lack of
integration, structural rigidity, performance bottlenecks, and the absence of
collaborative frameworks. To overcome these limitations, we propose a
DIZEST-based approach methodology, a specialized low-code platform that enables
intuitive workflow design and seamless AI integration. Through a comparative
analysis with existing platforms, including Jupyter Notebook, ComfyUI, and
Orange3, we demonstrate that DIZEST delivers superior performance across key
evaluation criteria. Our photo kiosk case study further validates the
effectiveness of this approach in improving interoperability, enhancing user
experience, and increasing deployment flexibility.
\\ ( https://arxiv.org/abs/2511.17853 ,  451kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17906 (*cross-listing*)
Date: Sat, 22 Nov 2025 04:03:32 GMT   (33108kb)

Title: AnimAgents: Coordinating Multi-Stage Animation Pre-Production with
 Human-Multi-Agent Collaboration
Authors: Wen-Fan Wang, Chien-Ting Lu, Jin Ping Ng, Yi-Ting Chiu, Ting-Ying Lee,
 Miaosen Wang, Bing-Yu Chen, Xiang 'Anthony' Chen
Categories: cs.HC cs.AI
\\
 Animation pre-production lays the foundation of an animated film by
transforming initial concepts into a coherent blueprint across interdependent
stages such as ideation, scripting, design, and storyboarding. While generative
AI tools are increasingly adopted in this process, they remain isolated,
requiring creators to juggle multiple systems without integrated workflow
support. Our formative study with 12 professional creative directors and
independent animators revealed key challenges in their current practice:
Creators must manually coordinate fragmented outputs, manage large volumes of
information, and struggle to maintain continuity and creative control between
stages. Based on the insights, we present AnimAgents, a human-multi-agent
collaborative system that coordinates complex, multi-stage workflows through a
core agent and specialized agents, supported by dedicated boards for the four
major stages of pre-production. AnimAgents enables stage-aware orchestration,
stage-specific output management, and element-level refinement, providing an
end-to-end workflow tailored to professional practice. In a within-subjects
summative study with 16 professional creators, AnimAgents significantly
outperformed a strong single-agent baseline that equipped with advanced
parallel image generation in coordination, consistency, information management,
and overall satisfaction (p < .01). A field deployment with 4 creators further
demonstrated AnimAgents' effectiveness in real-world projects.
\\ ( https://arxiv.org/abs/2511.17906 ,  33108kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17959 (*cross-listing*)
Date: Sat, 22 Nov 2025 07:50:43 GMT   (251kb)

Title: Towards Automating Data Access Permissions in AI Agents
Authors: Yuhao Wu, Ke Yang, Franziska Roesner, Tadayoshi Kohno, Ning Zhang,
 Umar Iqbal
Categories: cs.CR cs.AI cs.HC cs.LG
Comments: Accepted by the IEEE Symposium on Security and Privacy (S&P) 2026
Journal-ref: The IEEE Symposium on Security and Privacy (S&P) 2026
DOI: 10.1109/SP63933.2026.00018
\\
 As AI agents attempt to autonomously act on users' behalf, they raise
transparency and control issues. We argue that permission-based access control
is indispensable in providing meaningful control to the users, but conventional
permission models are inadequate for the automated agentic execution paradigm.
We therefore propose automated permission management for AI agents. Our key
idea is to conduct a user study to identify the factors influencing users'
permission decisions and to encode these factors into an ML-based permission
management assistant capable of predicting users' future decisions. We find
that participants' permission decisions are influenced by communication context
but importantly individual preferences tend to remain consistent within
contexts, and align with those of other participants. Leveraging these
insights, we develop a permission prediction model achieving 85.1% accuracy
overall and 94.4% for high-confidence predictions. We find that even without
using permission history, our model achieves an accuracy of 66.9%, and a slight
increase of training samples (i.e., 1-4) can substantially increase the
accuracy by 10.8%.
\\ ( https://arxiv.org/abs/2511.17959 ,  251kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17971 (*cross-listing*)
Date: Sat, 22 Nov 2025 08:18:40 GMT   (480kb)

Title: Comprehensive Design Space Exploration for Tensorized Neural Network
 Hardware Accelerators
Authors: Jinsong Zhang, Minghe Li, Jiayi Tian, Jinming Lu, Zheng Zhang
Categories: cs.AR cs.AI
\\
 High-order tensor decomposition has been widely adopted to obtain compact
deep neural networks for edge deployment. However, existing studies focus
primarily on its algorithmic advantages such as accuracy and compression
ratio-while overlooking the hardware deployment efficiency. Such
hardware-unaware designs often obscure the potential latency and energy
benefits of tensorized models. Although several works attempt to reduce
computational cost by optimizing the contraction sequence based on the number
of multiply-accumulate operations, they typically neglect the underlying
hardware characteristics, resulting in suboptimal real-world performance. We
observe that the contraction path, hardware architecture, and dataflow mapping
are tightly coupled and must be optimized jointly within a unified design space
to maximize deployment efficiency on real devices. To this end, we propose a
co-exploration framework that unifies these dimensions within a unified design
space for efficient training and inference of tensorized neural networks on
edge platforms. The framework formulates a latency oriented search objective
and solves it via a global latency-driven exploration across the unified design
space to achieve end-to-end model efficiency. The optimized configurations are
implemented on a configurable FPGA kernel, achieving up to 4 and 3.85 lower
inference and training latency compared with the dense baseline.
\\ ( https://arxiv.org/abs/2511.17971 ,  480kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17982 (*cross-listing*)
Date: Sat, 22 Nov 2025 08:52:09 GMT   (398kb)

Title: Towards Effective, Stealthy, and Persistent Backdoor Attacks Targeting
 Graph Foundation Models
Authors: Jiayi Luo, Qingyun Sun, Lingjuan Lyu, Ziwei Zhang, Haonan Yuan,
 Xingcheng Fu, Jianxin Li
Categories: cs.CR cs.AI
Comments: Accepted by AAAI 2026
\\
 Graph Foundation Models (GFMs) are pre-trained on diverse source domains and
adapted to unseen targets, enabling broad generalization for graph machine
learning. Despite that GFMs have attracted considerable attention recently,
their vulnerability to backdoor attacks remains largely underexplored. A
compromised GFM can introduce backdoor behaviors into downstream applications,
posing serious security risks. However, launching backdoor attacks against GFMs
is non-trivial due to three key challenges. (1) Effectiveness: Attackers lack
knowledge of the downstream task during pre-training, complicating the
assurance that triggers reliably induce misclassifications into desired
classes. (2) Stealthiness: The variability in node features across domains
complicates trigger insertion that remains stealthy. (3) Persistence:
Downstream fine-tuning may erase backdoor behaviors by updating model
parameters. To address these challenges, we propose GFM-BA, a novel Backdoor
Attack model against Graph Foundation Models. Specifically, we first design a
label-free trigger association module that links the trigger to a set of
prototype embeddings, eliminating the need for knowledge about downstream tasks
to perform backdoor injection. Then, we introduce a node-adaptive trigger
generator, dynamically producing node-specific triggers, reducing the risk of
trigger detection while reliably activating the backdoor. Lastly, we develop a
persistent backdoor anchoring module that firmly anchors the backdoor to
fine-tuning-insensitive parameters, enhancing the persistence of the backdoor
under downstream adaptation. Extensive experiments demonstrate the
effectiveness, stealthiness, and persistence of GFM-BA.
\\ ( https://arxiv.org/abs/2511.17982 ,  398kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18030 (*cross-listing*)
Date: Sat, 22 Nov 2025 11:46:26 GMT   (1740kb)

Title: Hierarchical biomarker thresholding: a model-agnostic framework for
 stability
Authors: O. Debeaupuis
Categories: stat.ME cs.AI math.ST stat.TH
\\
 Many biomarker pipelines require patient-level decisions aggregated from
instance-level (cell/patch) scores. Thresholds tuned on pooled instances often
fail across sites due to hierarchical dependence, prevalence shift, and
score-scale mismatch. We present a selection-honest framework for hierarchical
thresholding that makes patient-level decisions reproducible and more
defensible. At its core is a risk decomposition theorem for selection-honest
thresholds. The theorem separates contributions from (i) internal fit and
patient-level generalization, (ii) operating-point shift reflecting prevalence
and shape changes, and (iii) a stability term that penalizes sensitivity to
threshold perturbations. The stability component is computable via
patient-block bootstraps mapped through a monotone modulus of risk. This
framework is model-agnostic, reconciles heterogeneous decision rules on a
quantile scale, and yields monotone-invariant ensembles and reportable
diagnostics (e.g. flip-rate, operating-point shift).
\\ ( https://arxiv.org/abs/2511.18030 ,  1740kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18038 (*cross-listing*)
Date: Sat, 22 Nov 2025 12:33:13 GMT   (4848kb)

Title: MASTEST: A LLM-Based Multi-Agent System For RESTful API Tests
Authors: Xiaoke Han and Hong Zhu
Categories: cs.SE cs.AI cs.LG
Comments: 14 Page of main text plus 4 pages of appendix
\\
 Testing RESTful API is increasingly important in quality assurance of
cloud-native applications. Recent advances in machine learning (ML) techniques
have demonstrated that various testing activities can be performed
automatically by large language models (LLMs) with reasonable accuracy. This
paper develops a multi-agent system called MASTEST that combines LLM-based and
programmed agents to form a complete tool chain that covers the whole workflow
of API test starting from generating unit and system test scenarios from API
specification in the OpenAPI Swagger format, to generating of Pytest test
scripts, executing test scripts to interact with web services, to analysing web
service response messages to determine test correctness and calculate test
coverage. The system also supports the incorporation of human testers in
reviewing and correcting LLM generated test artefacts to ensure the quality of
testing activities. MASTEST system is evaluated on two LLMs, GPT-4o and
DeepSeek V3.1 Reasoner with five public APIs. The performances of LLMs on
various testing activities are measured by a wide range of metrics, including
unit and system test scenario coverage and API operation coverage for the
quality of generated test scenarios, data type correctness, status code
coverage and script syntax correctness for the quality of LLM generated test
scripts, as well as bug detection ability and usability of LLM generated test
scenarios and scripts. Experiment results demonstrated that both DeepSeek and
GPT-4o achieved a high overall performance. DeepSeek excels in data type
correctness and status code detection, while GPT-4o performs best in API
operation coverage. For both models, LLM generated test scripts maintained
100\% syntax correctness and only required minimal manual edits for semantic
correctness. These findings indicate the effectiveness and feasibility of
MASTEST.
\\ ( https://arxiv.org/abs/2511.18038 ,  4848kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18076 (*cross-listing*)
Date: Sat, 22 Nov 2025 14:21:06 GMT   (674kb)

Title: Reinforcement Learning for Portfolio Optimization with a Financial Goal
 and Defined Time Horizons
Authors: Fermat Leukam, Rock Stephane Koffi, Prudence Djagba
Categories: q-fin.PM cs.AI cs.LG
MSC-class: 91G10, 91G60, 68T05
ACM-class: G.3; I.2.6; I.2.8
\\
 This research proposes an enhancement to the innovative portfolio
optimization approach using the G-Learning algorithm, combined with parametric
optimization via the GIRL algorithm (G-learning approach to the setting of
Inverse Reinforcement Learning) as presented by. The goal is to maximize
portfolio value by a target date while minimizing the investor's periodic
contributions. Our model operates in a highly volatile market with a
well-diversified portfolio, ensuring a low-risk level for the investor, and
leverages reinforcement learning to dynamically adjust portfolio positions over
time. Results show that we improved the Sharpe Ratio from 0.42, as suggested by
recent studies using the same approach, to a value of 0.483 a notable
achievement in highly volatile markets with diversified portfolios. The
comparison between G-Learning and GIRL reveals that while GIRL optimizes the
reward function parameters (e.g., lambda = 0.0012 compared to 0.002), its
impact on portfolio performance remains marginal. This suggests that
reinforcement learning methods, like G-Learning, already enable robust
optimization. This research contributes to the growing development of
reinforcement learning applications in financial decision-making, demonstrating
that probabilistic learning algorithms can effectively align portfolio
management strategies with investor needs.
\\ ( https://arxiv.org/abs/2511.18076 ,  674kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18078 (*cross-listing*)
Date: Sat, 22 Nov 2025 14:25:21 GMT   (5174kb)

Title: Diffusion-based Surrogate Model for Time-varying Underwater Acoustic
 Channels
Authors: Kexin Li, Mandar Chitre
Categories: cs.SD cs.AI
\\
 Accurate modeling of time-varying underwater acoustic channels is essential
for the design, evaluation, and deployment of reliable underwater communication
systems. Conventional physics models require detailed environmental knowledge,
while stochastic replay methods are constrained by the limited diversity of
measured channels and often fail to generalize to unseen scenarios, reducing
their practical applicability. To address these challenges, we propose
StableUASim, a pre-trained conditional latent diffusion surrogate model that
captures the stochastic dynamics of underwater acoustic communication channels.
Leveraging generative modeling, StableUASim produces diverse and statistically
realistic channel realizations, while supporting conditional generation from
specific measurement samples. Pre-training enables rapid adaptation to new
environments using minimal additional data, and the autoencoder latent
representation facilitates efficient channel analysis and compression.
Experimental results demonstrate that StableUASim accurately reproduces key
channel characteristics and communication performance, providing a scalable,
data-efficient, and physically consistent surrogate model for both system
design and machine learning-driven underwater applications.
\\ ( https://arxiv.org/abs/2511.18078 ,  5174kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18085 (*cross-listing*)
Date: Sat, 22 Nov 2025 15:00:08 GMT   (8452kb)

Title: Continually Evolving Skill Knowledge in Vision Language Action Model
Authors: Yuxuan Wu, Guangming Wang, Zhiheng Yang, Maoqing Yao, Brian Sheil,
 Hesheng Wang
Categories: cs.RO cs.AI
\\
 Developing general robot intelligence in open environments requires continual
skill learning. Recent Vision-Language-Action (VLA) models leverage massive
pretraining data to support diverse manipulation tasks, but they still depend
heavily on task-specific fine-tuning, revealing a lack of continual learning
capability. Existing continual learning methods are also resource-intensive to
scale to VLA models. We propose Stellar VLA, a knowledge-driven continual
learning framework with two variants: T-Stellar, modeling task-centric
knowledge space, and TS-Stellar, capturing hierarchical task-skill structure.
Stellar VLA enables self-supervised knowledge evolution through joint learning
of task latent representation and the knowledge space, reducing annotation
needs. Knowledge-guided expert routing provide task specialization without
extra network parameters, lowering training overhead.Experiments on the LIBERO
benchmark and real-world tasks show over 50 percentage average improvement in
final success rates relative to baselines. TS-Stellar further excels in complex
action inference, and in-depth analyses verify effective knowledge retention
and discovery. Our code will be released soon.
\\ ( https://arxiv.org/abs/2511.18085 ,  8452kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18165 (*cross-listing*)
Date: Sat, 22 Nov 2025 19:27:35 GMT   (1280kb)

Title: Towards a General Framework for HTN Modeling with LLMs
Authors: Israel Puerta-Merino, Carlos N\'u\~nez-Molina, Pablo Mesejo, Juan
 Fern\'andez-Olivares
Categories: cs.SE cs.AI
Comments: 10 pages, 5 figures, to be published in the Workshop on Planning in
 the Era of LLMs ( LM4Plan - https://llmforplanning.github.io ) and the
 Workshop on Hierarchical Planning ( HPlan -
 https://icaps25.icaps-conference.org/program/workshops/hplan/ ), both in the
 International Conference on Automated Planning and Scheduling (ICAPS) 2025
\\
 The use of Large Language Models (LLMs) for generating Automated Planning
(AP) models has been widely explored; however, their application to
Hierarchical Planning (HP) is still far from reaching the level of
sophistication observed in non-hierarchical architectures. In this work, we try
to address this gap. We present two main contributions. First, we propose L2HP,
an extension of L2P (a library to LLM-driven PDDL models generation) that
support HP model generation and follows a design philosophy of generality and
extensibility. Second, we apply our framework to perform experiments where we
compare the modeling capabilities of LLMs for AP and HP. On the PlanBench
dataset, results show that parsing success is limited but comparable in both
settings (around 36\%), while syntactic validity is substantially lower in the
hierarchical case (1\% vs. 20\% of instances). These findings underscore the
unique challenges HP presents for LLMs, highlighting the need for further
research to improve the quality of generated HP models.
\\ ( https://arxiv.org/abs/2511.18165 ,  1280kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18172 (*cross-listing*)
Date: Sat, 22 Nov 2025 19:53:24 GMT   (551kb)

Title: MEDIC: a network for monitoring data quality in collider experiments
Authors: Juvenal Bassa, Arghya Chattopadhyay, Sudhir Malik and Mario Escabi
 Rivera
Categories: hep-ex cs.AI cs.LG
Comments: 17 pages, 1 appendix
\\
 Data Quality Monitoring (DQM) is a crucial component of particle physics
experiments and ensures that the recorded data is of the highest quality, and
suitable for subsequent physics analysis. Due to the extreme environmental
conditions, unprecedented data volumes, and the sheer scale and complexity of
the detectors, DQM orchestration has become a very challenging task. Therefore,
the use of Machine Learning (ML) to automate anomaly detection, improve
efficiency, and reduce human error in the process of collecting high-quality
data is unavoidable. Since DQM relies on real experimental data, it is
inherently tied to the specific detector substructure and technology in
operation. In this work, a simulation-driven approach to DQM is proposed,
enabling the study and development of data-quality methodologies in a
controlled environment. Using a modified version of Delphes -- a fast,
multi-purpose detector simulation -- the preliminary realization of a framework
is demonstrated which leverages ML to identify detector anomalies as well as
localize the malfunctioning components responsible. We introduce MEDIC
(Monitoring for Event Data Integrity and Consistency), a neural network
designed to learn detector behavior and perform DQM tasks to look for potential
faults. Although the present implementation adopts a simplified setup for
computational ease, where large detector regions are deliberately deactivated
to mimic faults, this work represents an initial step toward a comprehensive
ML-based DQM framework. The encouraging results underline the potential of
simulation-driven studies as a foundation for developing more advanced,
data-driven DQM systems for future particle detectors.
\\ ( https://arxiv.org/abs/2511.18172 ,  551kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18182 (*cross-listing*)
Date: Sat, 22 Nov 2025 20:36:13 GMT   (19363kb)

Title: The Workflow as Medium: A Framework for Navigating Human-AI Co-Creation
Authors: Lee Ackerman
Categories: cs.CY cs.AI
Comments: 57 pages, 13 images, 6 tables
ACM-class: H.5.2; K.4.2; K.4.3
\\
 This paper introduces the Creative Intelligence Loop (CIL), a novel
socio-technical framework for responsible human-AI co-creation. Rooted in the
'Workflow as Medium' paradigm, the CIL proposes a disciplined structure for
dynamic human-AI collaboration, guiding the strategic integration of diverse AI
teammates who function as collaborators while the human remains the final
arbiter for ethical alignment and creative integrity. The CIL was empirically
demonstrated through the practice-led creation of two graphic novellas,
investigating how AI could serve as an effective creative colleague within a
subjective medium lacking objective metrics. The process required navigating
multifaceted challenges including AI's 'jagged frontier' of capabilities,
sycophancy, and attention-scarce feedback environments. This prompted iterative
refinement of teaming practices, yielding emergent strategies: a multi-faceted
critique system integrating adversarial AI roles to counter sycophancy, and
prioritizing 'feedback-ready' concrete artifacts to elicit essential human
critique. The resulting graphic novellas analyze distinct socio-technical
governance failures: 'The Steward' examines benevolent AI paternalism in smart
cities, illustrating how algorithmic hubris can erode freedom; 'Fork the Vote'
probes democratic legitimacy by comparing centralized AI opacity with emergent
collusion in federated networks. This work contributes a self-improving
framework for responsible human-AI co-creation and two graphic novellas
designed to foster AI literacy and dialogue through accessible narrative
analysis of AI's societal implications.
\\ ( https://arxiv.org/abs/2511.18182 ,  19363kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18221 (*cross-listing*)
Date: Sat, 22 Nov 2025 23:43:00 GMT   (281kb)

Title: Enhancing Large Language Models for Automated Homework Assessment in
 Undergraduate Circuit Analysis
Authors: Liangliang Chen, Huiru Xie, Zhihao Qin, Yiming Guo, Jacqueline Rohde,
 Ying Zhang
Categories: cs.CY cs.AI cs.HC
Comments: Accepted to 2025 Frontiers in Education (FIE) Conference
\\
 This research full paper presents an enhancement pipeline for large language
models (LLMs) in assessing homework for an undergraduate circuit analysis
course, aiming to improve LLMs' capacity to provide personalized support to
electrical engineering students. Existing evaluations have demonstrated that
GPT-4o possesses promising capabilities in assessing student homework in this
domain. Building on these findings, we enhance GPT-4o's performance through
multi-step prompting, contextual data augmentation, and the incorporation of
targeted hints. These strategies effectively address common errors observed in
GPT-4o's responses when using simple prompts, leading to a substantial
improvement in assessment accuracy. Specifically, the correct response rate for
GPT-4o increases from 74.71% to 97.70% after applying the enhanced prompting
and augmented data on entry-level circuit analysis topics. This work lays a
foundation for the effective integration of LLMs into circuit analysis
instruction and, more broadly, into engineering education.
\\ ( https://arxiv.org/abs/2511.18221 ,  281kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18223 (*cross-listing*)
Date: Sat, 22 Nov 2025 23:52:01 GMT   (2080kb)

Title: A Novel and Practical Universal Adversarial Perturbations against Deep
 Reinforcement Learning based Intrusion Detection Systems
Authors: H. Zhang, L. Zhang, G. Epiphaniou, C. Maple
Categories: cs.CR cs.AI
Comments: 13 pages, 7 Figures,
\\
 Intrusion Detection Systems (IDS) play a vital role in defending modern cyber
physical systems against increasingly sophisticated cyber threats. Deep
Reinforcement Learning-based IDS, have shown promise due to their adaptive and
generalization capabilities. However, recent studies reveal their vulnerability
to adversarial attacks, including Universal Adversarial Perturbations (UAPs),
which can deceive models with a single, input-agnostic perturbation. In this
work, we propose a novel UAP attack against Deep Reinforcement Learning
(DRL)-based IDS under the domain-specific constraints derived from network data
rules and feature relationships. To the best of our knowledge, there is no
existing study that has explored UAP generation for the DRL-based IDS. In
addition, this is the first work that focuses on developing a UAP against a
DRL-based IDS under realistic domain constraints based on not only the basic
domain rules but also mathematical relations between the features. Furthermore,
we enhance the evasion performance of the proposed UAP, by introducing a
customized loss function based on the Pearson Correlation Coefficient, and we
denote it as Customized UAP. To the best of our knowledge, this is also the
first work using the PCC value in the UAP generation, even in the broader
context. Four additional established UAP baselines are implemented for a
comprehensive comparison. Experimental results demonstrate that our proposed
Customized UAP outperforms two input-dependent attacks including Fast Gradient
Sign Method (FGSM), Basic Iterative Method (BIM), and four UAP baselines,
highlighting its effectiveness for real-world adversarial scenarios.
\\ ( https://arxiv.org/abs/2511.18223 ,  2080kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18239 (*cross-listing*)
Date: Sun, 23 Nov 2025 00:54:25 GMT   (1317kb)

Title: Can LLMs Help Allocate Public Health Resources? A Case Study on
 Childhood Lead Testing
Authors: Mohamed Afane, Ying Wang, and Juntao Chen
Categories: cs.CY cs.AI
\\
 Public health agencies face critical challenges in identifying high-risk
neighborhoods for childhood lead exposure with limited resources for outreach
and intervention programs. To address this, we develop a Priority Score
integrating untested children proportions, elevated blood lead prevalence, and
public health coverage patterns to support optimized resource allocation
decisions across 136 neighborhoods in Chicago, New York City, and Washington,
D.C. We leverage these allocation tasks, which require integrating multiple
vulnerability indicators and interpreting empirical evidence, to evaluate
whether large language models (LLMs) with agentic reasoning and deep research
capabilities can effectively allocate public health resources when presented
with structured allocation scenarios. LLMs were tasked with distributing 1,000
test kits within each city based on neighborhood vulnerability indicators.
Results reveal significant limitations: LLMs frequently overlooked
neighborhoods with highest lead prevalence and largest proportions of untested
children, such as West Englewood in Chicago, while allocating disproportionate
resources to lower-priority areas like Hunts Point in New York City. Overall
accuracy averaged 0.46, reaching a maximum of 0.66 with ChatGPT 5 Deep
Research. Despite their marketed deep research capabilities, LLMs struggled
with fundamental limitations in information retrieval and evidence-based
reasoning, frequently citing outdated data and allowing non-empirical
narratives about neighborhood conditions to override quantitative vulnerability
indicators.
\\ ( https://arxiv.org/abs/2511.18239 ,  1317kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18258 (*cross-listing*)
Date: Sun, 23 Nov 2025 03:06:23 GMT   (1009kb)

Title: Hybrid Agentic AI and Multi-Agent Systems in Smart Manufacturing
Authors: Mojtaba A. Farahani, Md Irfan Khan, Thorsten Wuest
Categories: cs.MA cs.AI cs.LG
\\
 The convergence of Agentic AI and MAS enables a new paradigm for intelligent
decision making in SMS. Traditional MAS architectures emphasize distributed
coordination and specialized autonomy, while recent advances in agentic AI
driven by LLMs introduce higher order reasoning, planning, and tool
orchestration capabilities. This paper presents a hybrid agentic AI and multi
agent framework for a Prescriptive Maintenance use case, where LLM based agents
provide strategic orchestration and adaptive reasoning, complemented by rule
based and SLMs agents performing efficient, domain specific tasks on the edge.
The proposed framework adopts a layered architecture that consists of
perception, preprocessing, analytics, and optimization layers, coordinated
through an LLM Planner Agent that manages workflow decisions and context
retention. Specialized agents autonomously handle schema discovery, intelligent
feature analysis, model selection, and prescriptive optimization, while a HITL
interface ensures transparency and auditability of generated maintenance
recommendations. This hybrid design supports dynamic model adaptation, cost
efficient maintenance scheduling, and interpretable decision making. An initial
proof of concept implementation is validated on two industrial manufacturing
datasets. The developed framework is modular and extensible, supporting
seamless integration of new agents or domain modules as capabilities evolve.
The results demonstrate the system capability to automatically detect schema,
adapt preprocessing pipelines, optimize model performance through adaptive
intelligence, and generate actionable, prioritized maintenance recommendations.
The framework shows promise in achieving improved robustness, scalability, and
explainability for RxM in smart manufacturing, bridging the gap between high
level agentic reasoning and low level autonomous execution.
\\ ( https://arxiv.org/abs/2511.18258 ,  1009kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18274 (*cross-listing*)
Date: Sun, 23 Nov 2025 03:51:41 GMT   (849kb)

Title: Clinician-Directed Large Language Model Software Generation for
 Therapeutic Interventions in Physical Rehabilitation
Authors: Edward Kim, Yuri Cho, Jose Eduardo E. Lima, Julie Muccini, Jenelle
 Jindal, Alison Scheid, Erik Nelson, Seong Hyun Park, Yuchen Zeng, Alton
 Sturgis, Caesar Li, Jackie Dai, Sun Min Kim, Yash Prakash, Liwen Sun,
 Isabella Hu, Hongxuan Wu, Daniel He, Wiktor Rajca, Cathra Halabi, Maarten
 Lansberg, Bjoern Hartmann, Sanjit A. Seshia
Categories: cs.HC cs.AI
\\
 Digital health interventions are increasingly used in physical and
occupational therapy to deliver home exercise programs via sensor equipped
devices such as smartphones, enabling remote monitoring of adherence and
performance. However, digital interventions are typically programmed as
software before clinical encounters as libraries of parametrized exercise
modules targeting broad patient populations. At the point of care, clinicians
can only select modules and adjust a narrow set of parameters like repetitions,
so patient specific needs that emerge during encounters, such as distinct
movement limitations, and home environments, are rarely reflected in the
software. We evaluated a digital intervention paradigm that uses large language
models (LLMs) to translate clinicians' exercise prescriptions into intervention
software. In a prospective single arm feasibility study with 20 licensed
physical and occupational therapists and a standardized patient, clinicians
created 40 individualized upper extremity programs (398 instructions) that were
automatically translated into executable software. Our results show a 45%
increase in the proportion of personalized prescriptions that can be
implemented as software compared with a template based benchmark, with
unanimous consensus among therapists on ease of use. The LLM generated software
correctly delivered 99.78% (397/398) of instructions as prescribed and
monitored performance with 88.4% (352/398) accuracy, with 90% (18/20) of
therapists judged it safe to interact with patients, and 75% (15/20) expressed
willingness to adopt it. To our knowledge, this is the first prospective
evaluation of clinician directed intervention software generation with LLMs in
healthcare, demonstrating feasibility and motivating larger trials to assess
clinical effectiveness and safety in real patient populations.
\\ ( https://arxiv.org/abs/2511.18274 ,  849kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18354 (*cross-listing*)
Date: Sun, 23 Nov 2025 09:01:22 GMT   (121kb)

Title: Toward an AI-Native Internet: Rethinking the Web Architecture for
 Semantic Retrieval
Authors: Muhammad Bilal, Zafar Qazi and Marco Canini
Categories: cs.NI cs.AI cs.IR
ACM-class: I.2; C.2.1
\\
 The rise of Generative AI Search is fundamentally transforming how users and
intelligent systems interact with the Internet. LLMs increasingly act as
intermediaries between humans and web information. Yet the web remains
optimized for human browsing rather than AI-driven semantic retrieval,
resulting in wasted network bandwidth, lower information quality, and
unnecessary complexity for developers. We introduce the concept of an AI-Native
Internet, a web architecture in which servers expose semantically relevant
information chunks rather than full documents, supported by a Web-native
semantic resolver that allows AI applications to discover relevant information
sources before retrieving fine-grained chunks. Through motivational
experiments, we quantify the inefficiencies of current HTML-based retrieval,
and outline architectural directions and open challenges for evolving today's
document-centric web into an AI-oriented substrate that better supports
semantic access to web content.
\\ ( https://arxiv.org/abs/2511.18354 ,  121kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18384 (*cross-listing*)
Date: Sun, 23 Nov 2025 10:24:12 GMT   (15kb)

Title: NSTR: Neural Spectral Transport Representation for Space-Varying
 Frequency Fields
Authors: Plein Versace
Categories: cs.SD cs.AI
\\
 Implicit Neural Representations (INRs) have emerged as a powerful paradigm
for representing signals such as images, audio, and 3D scenes. However,
existing INR frameworks -- including MLPs with Fourier features, SIREN, and
multiresolution hash grids -- implicitly assume a \textit{global and
stationary} spectral basis. This assumption is fundamentally misaligned with
real-world signals whose frequency characteristics vary significantly across
space, exhibiting local high-frequency textures, smooth regions, and frequency
drift phenomena. We propose \textbf{Neural Spectral Transport Representation
(NSTR)}, the first INR framework that \textbf{explicitly models a spatially
varying local frequency field}. NSTR introduces a learnable \emph{frequency
transport equation}, a PDE that governs how local spectral compositions evolve
across space. Given a learnable local spectrum field $S(x)$ and a frequency
transport network $F_\theta$ enforcing $\nabla S(x) \approx F_\theta(x, S(x))$,
NSTR reconstructs signals by spatially modulating a compact set of global
sinusoidal bases. This formulation enables strong local adaptivity and offers a
new level of interpretability via visualizing frequency flows. Experiments on
2D image regression, audio reconstruction, and implicit 3D geometry show that
NSTR achieves significantly better accuracy-parameter trade-offs than SIREN,
Fourier-feature MLPs, and Instant-NGP. NSTR requires fewer global frequencies,
converges faster, and naturally explains signal structure through spectral
transport fields. We believe NSTR opens a new direction in INR research by
introducing explicit modeling of space-varying spectrum.
\\ ( https://arxiv.org/abs/2511.18384 ,  15kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18467 (*cross-listing*)
Date: Sun, 23 Nov 2025 14:26:35 GMT   (863kb)

Title: Shadows in the Code: Exploring the Risks and Defenses of LLM-based
 Multi-Agent Software Development Systems
Authors: Xiaoqing Wang, Keman Huang, Bin Liang, Hongyu Li, Xiaoyong Du
Categories: cs.CR cs.AI cs.CL
Comments: Accepted by AAAI 2026 Alignment Track
\\
 The rapid advancement of Large Language Model (LLM)-driven multi-agent
systems has significantly streamlined software developing tasks, enabling users
with little technical expertise to develop executable applications. While these
systems democratize software creation through natural language requirements,
they introduce significant security risks that remain largely unexplored. We
identify two risky scenarios: Malicious User with Benign Agents (MU-BA) and
Benign User with Malicious Agents (BU-MA). We introduce the Implicit Malicious
Behavior Injection Attack (IMBIA), demonstrating how multi-agent systems can be
manipulated to generate software with concealed malicious capabilities beneath
seemingly benign applications, and propose Adv-IMBIA as a defense mechanism.
Evaluations across ChatDev, MetaGPT, and AgentVerse frameworks reveal varying
vulnerability patterns, with IMBIA achieving attack success rates of 93%, 45%,
and 71% in MU-BA scenarios, and 71%, 84%, and 45% in BU-MA scenarios. Our
defense mechanism reduced attack success rates significantly, particularly in
the MU-BA scenario. Further analysis reveals that compromised agents in the
coding and testing phases pose significantly greater security risks, while also
identifying critical agents that require protection against malicious user
exploitation. Our findings highlight the urgent need for robust security
measures in multi-agent software development systems and provide practical
guidelines for implementing targeted, resource-efficient defensive strategies.
\\ ( https://arxiv.org/abs/2511.18467 ,  863kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18487 (*cross-listing*)
Date: Sun, 23 Nov 2025 15:15:21 GMT   (373kb)

Title: InstructAudio: Unified speech and music generation with natural language
 instruction
Authors: Chunyu Qiang, Kang Yin, Xiaopeng Wang, Yuzhe Liang, Jiahui Zhao, Ruibo
 Fu, Tianrui Wang, Cheng Gong, Chen Zhang, Longbiao Wang, Jianwu Dang
Categories: eess.AS cs.AI cs.CL cs.SD
\\
 Text-to-speech (TTS) and text-to-music (TTM) models face significant
limitations in instruction-based control. TTS systems usually depend on
reference audio for timbre, offer only limited text-level attribute control,
and rarely support dialogue generation. TTM systems are constrained by input
conditioning requirements that depend on expert knowledge annotations. The high
heterogeneity of these input control conditions makes them difficult to joint
modeling with speech synthesis. Despite sharing common acoustic modeling
characteristics, these two tasks have long been developed independently,
leaving open the challenge of achieving unified modeling through natural
language instructions. We introduce InstructAudio, a unified framework that
enables instruction-based (natural language descriptions) control of acoustic
attributes including timbre (gender, age), paralinguistic (emotion, style,
accent), and musical (genre, instrument, rhythm, atmosphere). It supports
expressive speech, music, and dialogue generation in English and Chinese. The
model employs joint and single diffusion transformer layers with a standardized
instruction-phoneme input format, trained on 50K hours of speech and 20K hours
of music data, enabling multi-task learning and cross-modal alignment. Fig. 1
visualizes performance comparisons with mainstream TTS and TTM models,
demonstrating that InstructAudio achieves optimal results on most metrics. To
our best knowledge, InstructAudio represents the first instruction-controlled
framework unifying speech and music generation. Audio samples are available at:
https://qiangchunyu.github.io/InstructAudio/
\\ ( https://arxiv.org/abs/2511.18487 ,  373kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18488 (*cross-listing*)
Date: Sun, 23 Nov 2025 15:16:08 GMT   (5295kb)

Title: Evaluating perturbation robustnessof generative systems that use COBOL
 code inputs
Authors: Samuel Ackerman, Wesam Ibraheem, Orna Raz, Marcel Zalmanovici
Categories: cs.SE cs.AI
Comments: 16 pages (8 main, 8 appendix). Accepted to AI-SQE (ICSE, 2026): The
 1st International Workshop on AI for Software Quality Evaluation: Judgment,
 Metrics, Benchmarks, and Beyond
\\
 Systems incorporating large language models (LLMs) as a component are known
to be sensitive (i.e., non-robust) to minor input variations that do not change
the meaning of the input; such sensitivity may reduce the system's usefulness.
Here, we present a framework to evaluate robustness of systems using COBOL code
as input; our application is translation between COBOL and Java programming
languages, but the approach extends to other tasks such as code generation or
explanation. Targeting robustness of systems with COBOL as input is essential
yet challenging. Many business-critical applications are written in COBOL, yet
these are typically proprietary legacy applications and their code is
unavailable to LLMs for training. We develop a library of COBOL paragraph and
full-program perturbation methods, and create variant-expanded versions of a
benchmark dataset of examples for a specific task. The robustness of the
LLM-based system is evaluated by measuring changes in values of individual and
aggregate metrics calculated on the system's outputs. Finally, we present a
series of dynamic table and chart visualization dashboards that assist in
debugging the system's outputs, and monitoring and understanding root causes of
the system's sensitivity to input variation. These tools can be further used to
improve the system by, for instance, indicating variations that should be
handled by pre-processing steps.
\\ ( https://arxiv.org/abs/2511.18488 ,  5295kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18493 (*cross-listing*)
Date: Sun, 23 Nov 2025 15:25:36 GMT   (28691kb)

Title: Shape-Adapting Gated Experts: Dynamic Expert Routing for Colonoscopic
 Lesion Segmentation
Authors: Gia Huy Thai, Hoang-Nguyen Vu, Anh-Minh Phan, Quang-Thinh Ly, Tram
 Dinh, Thi-Ngoc-Truc Nguyen and Nhat Ho
Categories: eess.IV cs.AI cs.CV
\\
 The substantial diversity in cell scale and form remains a primary challenge
in computer-aided cancer detection on gigapixel Whole Slide Images (WSIs),
attributable to cellular heterogeneity. Existing CNN-Transformer hybrids rely
on static computation graphs with fixed routing, which consequently causes
redundant computation and limits their adaptability to input variability. We
propose Shape-Adapting Gated Experts (SAGE), an input-adaptive framework that
enables dynamic expert routing in heterogeneous visual networks. SAGE
reconfigures static backbones into dynamically routed expert architectures.
SAGE's dual-path design features a backbone stream that preserves
representation and selectively activates an expert path through hierarchical
gating. This gating mechanism operates at multiple hierarchical levels,
performing a two-level, hierarchical selection between shared and specialized
experts to modulate model logits for Top-K activation. Our Shape-Adapting Hub
(SA-Hub) harmonizes structural and semantic representations across the CNN and
the Transformer module, effectively bridging diverse modules. Embodied as
SAGE-UNet, our model achieves superior segmentation on three medical
benchmarks: EBHI, DigestPath, and GlaS, yielding state-of-the-art Dice Scores
of 95.57%, 95.16%, and 94.17%, respectively, and robustly generalizes across
domains by adaptively balancing local refinement and global context. SAGE
provides a scalable foundation for dynamic expert routing, enabling flexible
visual reasoning.
\\ ( https://arxiv.org/abs/2511.18493 ,  28691kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18578 (*cross-listing*)
Date: Sun, 23 Nov 2025 18:44:19 GMT   (5195kb)

Title: Re(Visiting) Time Series Foundation Models in Finance
Authors: Eghbal Rahimikia, Hao Ni, and Weiguan Wang
Categories: q-fin.CP cs.AI cs.LG q-fin.PM q-fin.PR
DOI: 10.2139/ssrn.577056
\\
 Financial time series forecasting is central to trading, portfolio
optimization, and risk management, yet it remains challenging due to noisy,
non-stationary, and heterogeneous data. Recent advances in time series
foundation models (TSFMs), inspired by large language models, offer a new
paradigm for learning generalizable temporal representations from large and
diverse datasets. This paper presents the first comprehensive empirical study
of TSFMs in global financial markets. Using a large-scale dataset of daily
excess returns across diverse markets, we evaluate zero-shot inference,
fine-tuning, and pre-training from scratch against strong benchmark models. We
find that off-the-shelf pre-trained TSFMs perform poorly in zero-shot and
fine-tuning settings, whereas models pre-trained from scratch on financial data
achieve substantial forecasting and economic improvements, underscoring the
value of domain-specific adaptation. Increasing the dataset size, incorporating
synthetic data augmentation, and applying hyperparameter tuning further enhance
performance.
\\ ( https://arxiv.org/abs/2511.18578 ,  5195kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18582 (*cross-listing*)
Date: Sun, 23 Nov 2025 18:50:34 GMT   (11813kb)

Title: Barriers to AI Adoption: Image Concerns at Work
Authors: David Almog
Categories: econ.GN cs.AI cs.HC q-fin.EC
\\
 Concerns about how workers are perceived can deter effective collaboration
with artificial intelligence (AI). In a field experiment on a large online
labor market, I hired 450 U.S.-based remote workers to complete an
image-categorization job assisted by AI recommendations. Workers were
incentivized by the prospect of a contract extension based on an HR evaluator's
feedback. I find that workers adopt AI recommendations at lower rates when
their reliance on AI is visible to the evaluator, resulting in a measurable
decline in task performance. The effects are present despite a conservative
design in which workers know that the evaluator is explicitly instructed to
assess expected accuracy on the same AI-assisted task. This reduction in AI
reliance persists even when the evaluator is reassured about workers' strong
performance history on the platform, underscoring how difficult these concerns
are to alleviate. Leveraging the platform's public feedback feature, I
introduce a novel incentive-compatible elicitation method showing that workers
fear heavy reliance on AI signals a lack of confidence in their own judgment, a
trait they view as essential when collaborating with AI.
\\ ( https://arxiv.org/abs/2511.18582 ,  11813kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18589 (*cross-listing*)
Date: Sun, 23 Nov 2025 19:05:52 GMT   (388kb)

Title: Strategic Decision Framework for Enterprise LLM Adoption
Authors: Michael Trusov, Minha Hwang, Zainab Jamal, Swarup Chandra
Categories: cs.SE cs.AI
Comments: 14 pages, 1 key figure
\\
 Organizations are rapidly adopting Large Language Models (LLMs) to transform
their operations, yet they lack clear guidance on key decisions for adoption
and implementation. While LLMs offer powerful capabilities in content
generation, assisted coding, and process automation, businesses face critical
challenges in data security, LLM solution development approach, infrastructure
requirements, and deployment strategies. Healthcare providers must protect
patient data while leveraging LLMs for medical analysis, financial institutions
need to balance automated customer service with regulatory compliance, and
software companies seek to enhance development productivity while maintaining
code security.
 This article presents a systematic six-step decision framework for LLM
adoption, helping organizations navigate from initial application selection to
final deployment. Based on extensive interviews and analysis of successful and
failed implementations, our framework provides practical guidance for business
leaders to align technological capabilities with business objectives. Through
key decision points and real-world examples from both B2B and B2C contexts,
organizations can make informed decisions about LLM adoption while ensuring
secure and efficient integration across various use cases, from customer
service automation to content creation and advanced analytics.
\\ ( https://arxiv.org/abs/2511.18589 ,  388kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18604 (*cross-listing*)
Date: Sun, 23 Nov 2025 20:11:47 GMT   (11005kb)

Title: An Analysis of Constraint-Based Multi-Agent Pathfinding Algorithms
Authors: Hannah Lee, James D. Motes, Marco Morales, and Nancy M. Amato
Categories: cs.RO cs.AI cs.MA
\\
 This study informs the design of future multi-agent pathfinding (MAPF) and
multi-robot motion planning (MRMP) algorithms by guiding choices based on
constraint classification for constraint-based search algorithms. We categorize
constraints as conservative or aggressive and provide insights into their
search behavior, focusing specifically on vanilla Conflict-Based Search (CBS)
and Conflict-Based Search with Priorities (CBSw/P). Under a hybrid grid-roadmap
representation with varying resolution, we observe that aggressive (priority
constraint) formulations tend to solve more instances as agent count or
resolution increases, whereas conservative (motion constraint) formulations
yield stronger solution quality when both succeed. Findings are synthesized in
a decision flowchart, aiding users in selecting suitable constraints.
Recommendations extend to Multi-Robot Motion Planning (MRMP), emphasizing the
importance of considering topological features alongside problem, solution, and
representation features. A comprehensive exploration of the study, including
raw data and map performance, is available in our public GitHub Repository:
https://GitHub.com/hannahjmlee/constraint-mapf-analysis
\\ ( https://arxiv.org/abs/2511.18604 ,  11005kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18651 (*cross-listing*)
Date: Sun, 23 Nov 2025 23:11:55 GMT   (673kb)

Title: Lean 5.0: A Predictive, Human-AI, and Ethically Grounded Paradigm for
 Construction Management
Authors: Atena Khoshkonesh, Mohsen Mohammadagha, Navid Ebrahimi, Narges
 Sadeghigolshan
Categories: cs.CE cs.AI cs.LG
\\
 This paper introduces Lean 5.0, a human-centric evolution of Lean-Digital
integration that connects predictive analytics, AI collaboration, and
continuous learning within Industry 5.0 and Construction 5.0 contexts. A
systematic literature review (2019-2024) and a 12-week empirical validation
study demonstrate measurable performance gains, including a 13% increase in
Plan Percent Complete (PPC), 22% reduction in rework, and 42% improvement in
forecast accuracy. The study adopts a mixed-method Design Science Research
(DSR) approach aligned with PRISMA 2020 guidelines. The paper also examines
integration with digital twin and blockchain technologies to improve
traceability, auditability, and lifecycle transparency. Despite limitations
related to sample size, single-case design, and study duration, the findings
show that Lean 5.0 provides a transformative paradigm connecting human
cognition with predictive control in construction management.
\\ ( https://arxiv.org/abs/2511.18651 ,  673kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18653 (*cross-listing*)
Date: Sun, 23 Nov 2025 23:26:21 GMT   (339kb)

Title: FHE-Agent: Automating CKKS Configuration for Practical Encrypted
 Inference via an LLM-Guided Agentic Framework
Authors: Nuo Xu, Zhaoting Gong, Ran Ran, Jinwei Tang, Wujie Wen, Caiwen Ding
Categories: cs.CR cs.AI cs.LG
\\
 Fully Homomorphic Encryption (FHE), particularly the CKKS scheme, is a
promising enabler for privacy-preserving MLaaS, but its practical deployment
faces a prohibitive barrier: it heavily relies on domain expertise. Configuring
CKKS involves a tightly coupled space of ring dimensions, modulus chains, and
packing layouts. Without deep cryptographic knowledge to navigate these
interactions, practitioners are restricted to compilers that rely on fixed
heuristics. These "one-shot" tools often emit rigid configurations that are
either severely over-provisioned in latency or fail to find a feasible solution
entirely for deeper networks.
 We present FHE-Agent, an agentic framework that automates this expert
reasoning process. By coupling a Large Language Model (LLM) controller with a
deterministic tool suite, FHE-Agent decomposes the search into global parameter
selection and layer-wise bottleneck repair. The agents operate within a
multi-fidelity workflow, pruning invalid regimes using cheap static analysis
and reserving expensive encrypted evaluations for the most promising
candidates.
 We instantiate FHE-Agent on the Orion compiler and evaluate it on standard
benchmarks (MLP, LeNet, LoLa) and deeper architectures (AlexNet). FHE-Agent
consistently achieves better precision and lower latency than na\"ive search
strategies. Crucially, it automatically discovers feasible, 128-bit secure
configurations for complex models where baseline heuristics and one-shot
prompts fail to produce a valid setup.
\\ ( https://arxiv.org/abs/2511.18653 ,  339kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18674 (*cross-listing*)
Date: Mon, 24 Nov 2025 01:13:52 GMT   (665kb)

Title: Low-Rank GEMM: Efficient Matrix Multiplication via Low-Rank
 Approximation with FP8 Acceleration
Authors: Alfredo Metere
Categories: cs.PF cs.AI cs.DC cs.LG
\\
 Large matrix multiplication is a cornerstone of modern machine learning
workloads, yet traditional approaches suffer from cubic computational
complexity (e.g., $\mathcal{O}(n^3)$ for a matrix of size $n\times n$). We
present Low-Rank GEMM, a novel approach that leverages low-rank matrix
approximations to achieve sub-quadratic complexity while maintaining
hardware-accelerated performance through FP8 precision and intelligent kernel
selection. On a NVIDIA RTX 4090, our implementation achieves up to 378 TFLOPS
on matrices up to $N=20480$, providing 75\% memory savings and $7.8\times$
speedup over PyTorch FP32 for large matrices. The system automatically adapts
to hardware capabilities, selecting optimal decomposition methods (SVD,
randomized SVD) and precision levels based on matrix characteristics and
available accelerators. Comprehensive benchmarking on NVIDIA RTX 4090
demonstrates that Low-Rank GEMM becomes the fastest approach for matrices
$N\geq10240$, surpassing traditional cuBLAS implementations through memory
bandwidth optimization rather than computational shortcuts.
\\ ( https://arxiv.org/abs/2511.18674 ,  665kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18694 (*cross-listing*)
Date: Mon, 24 Nov 2025 02:28:31 GMT   (1390kb)

Title: Stable Multi-Drone GNSS Tracking System for Marine Robots
Authors: Shuo Wen, Edwin Meriaux, Mariana Sosa Guzm\'an, Zhizun Wang, Junming
 Shi, Gregory Dudek
Categories: cs.RO cs.AI cs.CV
\\
 Accurate localization is essential for marine robotics, yet Global Navigation
Satellite System (GNSS) signals are unreliable or unavailable even at a very
short distance below the water surface. Traditional alternatives, such as
inertial navigation, Doppler Velocity Loggers (DVL), SLAM, and acoustic
methods, suffer from error accumulation, high computational demands, or
infrastructure dependence. In this work, we present a scalable multi-drone
GNSS-based tracking system for surface and near-surface marine robots. Our
approach combines efficient visual detection, lightweight multi-object
tracking, GNSS-based triangulation, and a confidence-weighted Extended Kalman
Filter (EKF) to provide stable GNSS estimation in real time. We further
introduce a cross-drone tracking ID alignment algorithm that enforces global
consistency across views, enabling robust multi-robot tracking with redundant
aerial coverage. We validate our system in diversified complex settings to show
the scalability and robustness of the proposed algorithm.
\\ ( https://arxiv.org/abs/2511.18694 ,  1390kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18698 (*cross-listing*)
Date: Mon, 24 Nov 2025 02:43:19 GMT   (1813kb)

Title: Multimodal Real-Time Anomaly Detection and Industrial Applications
Authors: Aman Verma, Keshav Samdani, Mohd. Samiuddin Shafi
Categories: cs.SD cs.AI cs.CV cs.LG cs.MM
\\
 This paper presents the design, implementation, and evolution of a
comprehensive multimodal room-monitoring system that integrates synchronized
video and audio processing for real-time activity recognition and anomaly
detection. We describe two iterations of the system: an initial lightweight
implementation using YOLOv8, ByteTrack, and the Audio Spectrogram Transformer
(AST), and an advanced version that incorporates multi-model audio ensembles,
hybrid object detection, bidirectional cross-modal attention, and multi-method
anomaly detection. The evolution demonstrates significant improvements in
accuracy, robustness, and industrial applicability. The advanced system
combines three audio models (AST, Wav2Vec2, and HuBERT) for comprehensive audio
understanding, dual object detectors (YOLO and DETR) for improved accuracy, and
sophisticated fusion mechanisms for enhanced cross-modal learning. Experimental
evaluation shows the system's effectiveness in general monitoring scenarios as
well as specialized industrial safety applications, achieving real-time
performance on standard hardware while maintaining high accuracy.
\\ ( https://arxiv.org/abs/2511.18698 ,  1813kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18718 (*cross-listing*)
Date: Mon, 24 Nov 2025 03:18:55 GMT   (5833kb)

Title: AIRHILT: A Human-in-the-Loop Testbed for Multimodal Conflict Detection
 in Aviation
Authors: Omar Garib, Jayaprakash D. Kambhampaty, Olivia J. Pinon Fischer,
 Dimitri N. Mavris
Categories: cs.RO cs.AI
Comments: 9 pages, 4 figures, 1 table, 1 algorithm
\\
 We introduce AIRHILT (Aviation Integrated Reasoning, Human-in-the-Loop
Testbed), a modular and lightweight simulation environment designed to evaluate
multimodal pilot and air traffic control (ATC) assistance systems for aviation
conflict detection. Built on the open-source Godot engine, AIRHILT synchronizes
pilot and ATC radio communications, visual scene understanding from camera
streams, and ADS-B surveillance data within a unified, scalable platform. The
environment supports pilot- and controller-in-the-loop interactions, providing
a comprehensive scenario suite covering both terminal area and en route
operational conflicts, including communication errors and procedural mistakes.
AIRHILT offers standardized JSON-based interfaces that enable researchers to
easily integrate, swap, and evaluate automatic speech recognition (ASR), visual
detection, decision-making, and text-to-speech (TTS) models. We demonstrate
AIRHILT through a reference pipeline incorporating fine-tuned Whisper ASR,
YOLO-based visual detection, ADS-B-based conflict logic, and GPT-OSS-20B
structured reasoning, and present preliminary results from representative
runway-overlap scenarios, where the assistant achieves an average
time-to-first-warning of approximately 7.7 s, with average ASR and vision
latencies of approximately 5.9 s and 0.4 s, respectively. The AIRHILT
environment and scenario suite are openly available, supporting reproducible
research on multimodal situational awareness and conflict detection in
aviation; code and scenarios are available at
https://github.com/ogarib3/airhilt.
\\ ( https://arxiv.org/abs/2511.18718 ,  5833kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18772 (*cross-listing*)
Date: Mon, 24 Nov 2025 05:13:45 GMT   (1429kb)

Title: Re-Key-Free, Risky-Free: Adaptable Model Usage Control
Authors: Zihan Wang, Zhongkui Ma, Xinguo Feng, Chuan Yan, Dongge Liu, Ruoxi
 Sun, Derui Wang, Minhui Xue, Guangdong Bai
Categories: cs.CR cs.AI
\\
 Deep neural networks (DNNs) have become valuable intellectual property of
model owners, due to the substantial resources required for their development.
To protect these assets in the deployed environment, recent research has
proposed model usage control mechanisms to ensure models cannot be used without
proper authorization. These methods typically lock the utility of the model by
embedding an access key into its parameters. However, they often assume static
deployment, and largely fail to withstand continual post-deployment model
updates, such as fine-tuning or task-specific adaptation. In this paper, we
propose ADALOC, to endow key-based model usage control with adaptability during
model evolution. It strategically selects a subset of weights as an intrinsic
access key, which enables all model updates to be confined to this key
throughout the evolution lifecycle. ADALOC enables using the access key to
restore the keyed model to the latest authorized states without redistributing
the entire network (i.e., adaptation), and frees the model owner from full
re-keying after each model update (i.e., lock preservation). We establish a
formal foundation to underpin ADALOC, providing crucial bounds such as the
errors introduced by updates restricted to the access key. Experiments on
standard benchmarks, such as CIFAR-100, Caltech-256, and Flowers-102, and
modern architectures, including ResNet, DenseNet, and ConvNeXt, demonstrate
that ADALOC achieves high accuracy under significant updates while retaining
robust protections. Specifically, authorized usages consistently achieve strong
task-specific performance, while unauthorized usage accuracy drops to
near-random guessing levels (e.g., 1.01% on CIFAR-100), compared to up to
87.01% without ADALOC. This shows that ADALOC can offer a practical solution
for adaptive and protected DNN deployment in evolving real-world scenarios.
\\ ( https://arxiv.org/abs/2511.18772 ,  1429kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18828 (*cross-listing*)
Date: Mon, 24 Nov 2025 07:03:56 GMT   (28kb)

Title: Solving a Research Problem in Mathematical Statistics with AI Assistance
Authors: Edgar Dobriban
Categories: math.ST cs.AI cs.LG stat.TH
\\
 Over the last few months, AI models including large language models have
improved greatly. There are now several documented examples where they have
helped professional mathematical scientists prove new results, sometimes even
helping resolve known open problems. In this short note, we add another example
to the list, by documenting how we were able to solve a previously unsolved
research problem in robust mathematical statistics with crucial help from
GPT-5. Our problem concerns robust density estimation, where the observations
are perturbed by Wasserstein-bounded contaminations.In a previous preprint
(Chao and Dobriban, 2023, arxiv:2308.01853v2), we have obtained upper and lower
bounds on the minimax optimal estimation error; which were, however, not sharp.
 Starting in October 2025, making significant use of GPT-5 Pro, we were able
to derive the minimax optimal error rate (reported in version 3 of the above
arxiv preprint). GPT-5 provided crucial help along the way, including by
suggesting calculations that we did not think of, and techniques that were not
familiar to us, such as the dynamic Benamou-Brenier formulation, for key steps
in the analysis. Working with GPT-5 took a few weeks of effort, and we estimate
that it could have taken several months to get the same results otherwise. At
the same time, there are still areas where working with GPT-5 was challenging:
it sometimes provided incorrect references, and glossed over details that
sometimes took days of work to fill in. We outline our workflow and steps taken
to mitigate issues. Overall, our work can serve as additional documentation for
a new age of human-AI collaborative work in mathematical science.
\\ ( https://arxiv.org/abs/2511.18828 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18840 (*cross-listing*)
Date: Mon, 24 Nov 2025 07:22:41 GMT   (188kb)

Title: Addressing Situated Teaching Needs: A Multi-Agent Framework for
 Automated Slide Adaptation
Authors: Binglin Liu, Yucheng Wang, Zheyuan Zhang, Jiyuan Lu, Shen Yang, Daniel
 Zhang-Li, Huiqin Liu and Jifan Yu
Categories: cs.MA cs.AI
\\
 The adaptation of teaching slides to instructors' situated teaching needs,
including pedagogical styles and their students' context, is a critical yet
time-consuming task for educators. Through a series of educator interviews, we
first identify and systematically categorize the key friction points that
impede this adaptation process. Grounded in these findings, we introduce a
novel multi-agent framework designed to automate slide adaptation based on
high-level instructor specifications. An evaluation involving 16 modification
requests across 8 real-world courses validates our approach. The framework's
output consistently achieved high scores in intent alignment, content coherence
and factual accuracy, and performed on par with baseline methods regarding
visual clarity, while also demonstrating appropriate timeliness and a high
operational agreement with human experts, achieving an F1 score of 0.89. This
work heralds a new paradigm where AI agents handle the logistical burdens of
instructional design, liberating educators to focus on the creative and
strategic aspects of teaching.
\\ ( https://arxiv.org/abs/2511.18840 ,  188kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18842 (*cross-listing*)
Date: Mon, 24 Nov 2025 07:29:15 GMT   (163kb)

Title: Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight
 State Bounds
Authors: Mohammad Nour Al Awad, Sergey Ivanov, Olga Tikhonova
Categories: cs.SE cs.AI cs.HC
Comments: \c{opyright} 2025 IEEE. Personal use of this material is permitted.
 Permission from IEEE must be obtained for all other uses
\\
 Large Language Models (LLMs) have transformed code auto-completion by
generating context-aware suggestions. Yet, deciding when to present these
suggestions remains underexplored, often leading to interruptions or wasted
inference calls. We propose an adaptive timing mechanism that dynamically
adjusts the delay before offering a suggestion based on real-time developer
feedback. Our suggested method combines a logistic transform of recent
acceptance rates with a bounded delay range, anchored by a high-level binary
prediction of the developer's cognitive state. In a two-month deployment with
professional developers, our system improved suggestion acceptance from 4.9%
with no delay to 15.4% with static delays, and to 18.6% with adaptive
timing-while reducing blind rejections (rejections without being read) from
8.3% to 0.36%. Together, these improvements increase acceptance and
substantially reduce wasted inference calls by 75%, making LLM-based code
assistants more efficient and cost-effective in practice.
\\ ( https://arxiv.org/abs/2511.18842 ,  163kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18849 (*cross-listing*)
Date: Mon, 24 Nov 2025 07:42:07 GMT   (275kb)

Title: Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to
 Optimize LLM-Assisted Programming
Authors: Mohammad Nour Al Awad, Sergey Ivanov, Olga Tikhonova
Categories: cs.SE cs.AI cs.HC
Comments: \c{opyright} 2025 IEEE. Personal use of this material is permitted.
 Permission from IEEE must be obtained for all other uses
\\
 Large Language Models (LLMs) are increasingly integrated into code editors to
provide AI-powered code suggestions. Yet many of these suggestions are ignored,
resulting in wasted computation, increased latency, and unnecessary
interruptions. We introduce a lightweight pre-filtering model that predicts the
likelihood of suggestion acceptance before invoking the LLM, using only
real-time developer telemetry such as typing speed, file navigation, and
editing activity. Deployed in a production-grade Visual Studio Code plugin over
four months of naturalistic use, our approach nearly doubled acceptance rates
(18.4% -> 34.2%) while suppressing 35% of low-value LLM calls. These findings
demonstrate that behavioral signals alone can meaningfully improve both user
experience and system efficiency in LLM-assisted programming, highlighting the
value of timing-aware, privacy-preserving adaptation mechanisms. The filter
operates solely on pre-invocation editor telemetry and never inspects code or
prompts.
\\ ( https://arxiv.org/abs/2511.18849 ,  275kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18854 (*cross-listing*)
Date: Mon, 24 Nov 2025 07:49:59 GMT   (140kb)

Title: Time Travel: LLM-Assisted Semantic Behavior Localization with Git Bisect
Authors: Yujing Wang and Weize Hong
Categories: cs.SE cs.AI
Comments: submitted to Git Bisect SCALCOM 2025 Calgary (to be published)
\\
 We present a novel framework that integrates Large Language Models (LLMs)
into the Git bisect process for semantic fault localization. Traditional bisect
assumes deterministic predicates and binary failure states assumptions often
violated in modern software development due to flaky tests, nonmonotonic
regressions, and semantic divergence from upstream repositories. Our system
augments bisect traversal with structured chain of thought reasoning, enabling
commit by commit analysis under noisy conditions. We evaluate multiple open
source and proprietary LLMs for their suitability and fine tune DeepSeekCoderV2
using QLoRA on a curated dataset of semantically labeled diffs. We adopt a weak
supervision workflow to reduce annotation overhead, incorporating human in the
loop corrections and self consistency filtering. Experiments across multiple
open source projects show a 6.4 point absolute gain in success rate from 74.2
to 80.6 percent, leading to significantly fewer failed traversals and by
experiment up to 2x reduction in average bisect time. We conclude with
discussions on temporal reasoning, prompt design, and finetuning strategies
tailored for commit level behavior analysis.
\\ ( https://arxiv.org/abs/2511.18854 ,  140kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18869 (*cross-listing*)
Date: Mon, 24 Nov 2025 08:12:33 GMT   (167kb)

Title: Multidimensional Music Aesthetic Evaluation via Semantically Consistent
 C-Mixup Augmentation
Authors: Shuyang Liu, Yuan Jin, Rui Lin, Shizhe Chen, Junyu Dai and Tao Jiang
Categories: cs.SD cs.AI eess.AS
\\
 Evaluating the aesthetic quality of generated songs is challenging due to the
multi-dimensional nature of musical perception. We propose a robust music
aesthetic evaluation framework that combines (1) multi-source multi-scale
feature extraction to obtain complementary segment- and track-level
representations, (2) a hierarchical audio augmentation strategy to enrich
training data, and (3) a hybrid training objective that integrates regression
and ranking losses for accurate scoring and reliable top-song identification.
Experiments on the ICASSP 2026 SongEval benchmark demonstrate that our approach
consistently outperforms baseline methods across correlation and top-tier
metrics.
\\ ( https://arxiv.org/abs/2511.18869 ,  167kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18878 (*cross-listing*)
Date: Mon, 24 Nov 2025 08:33:47 GMT   (3762kb)

Title: Accelerating Reinforcement Learning via Error-Related Human Brain
 Signals
Authors: Suzie Kim, Hye-Bin Shin, Hyo-Jeong Jang
Categories: cs.RO cs.AI
\\
 In this work, we investigate how implicit neural feed back can accelerate
reinforcement learning in complex robotic manipulation settings. While prior
electroencephalogram (EEG) guided reinforcement learning studies have primarily
focused on navigation or low-dimensional locomotion tasks, we aim to understand
whether such neural evaluative signals can improve policy learning in
high-dimensional manipulation tasks involving obstacles and precise
end-effector control. We integrate error related potentials decoded from
offline-trained EEG classifiers into reward shaping and systematically evaluate
the impact of human-feedback weighting. Experiments on a 7-DoF manipulator in
an obstacle-rich reaching environment show that neural feedback accelerates
reinforcement learning and, depending on the human-feedback weighting, can
yield task success rates that at times exceed those of sparse-reward baselines.
Moreover, when applying the best-performing feedback weighting across all sub
jects, we observe consistent acceleration of reinforcement learning relative to
the sparse-reward setting. Furthermore, leave-one subject-out evaluations
confirm that the proposed framework remains robust despite the intrinsic
inter-individual variability in EEG decodability. Our findings demonstrate that
EEG-based reinforcement learning can scale beyond locomotion tasks and provide
a viable pathway for human-aligned manipulation skill acquisition.
\\ ( https://arxiv.org/abs/2511.18878 ,  3762kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18924 (*cross-listing*)
Date: Mon, 24 Nov 2025 09:31:52 GMT   (542kb)

Title: LLM-Driven Kernel Evolution: Automating Driver Updates in Linux
Authors: Arina Kharlamova, Jiawen Liu, Tianyi Zhang, Xinrui Yang, Humaid
 Alqasimi, Youcheng Sun, Chun Jason Xue
Categories: cs.SE cs.AI
\\
 Linux kernel evolution breaks drivers through API/ABI changes, semantic
shifts, and security-hardening updates. We introduce DRIVEBENCH, an executable
corpus of kernel$\rightarrow$driver co-evolution cases, and AUTODRIVER, a
closed-loop, LLM-driven system for automating driver maintenance. The system
integrates prompt engineering, multi-agent collaboration, static analysis, and
iterative validation to ensure that generated patches are not only
syntactically correct but also functionally and semantically consistent with
kernel conventions. The corpus spans v5.10-v6.10 with 235 validated cases drawn
from 612 candidates. In evaluation across 55 cases, AUTODRIVER achieves 56.4%
compilation success; QEMU-based boot verification indicates that compiled
patches preserve driver initialization in most instances. By releasing
DRIVEBENCH and tooling, we enable reproducible research and a practical route
to continuous, safe co-evolution of drivers with the Linux kernel.
\\ ( https://arxiv.org/abs/2511.18924 ,  542kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18933 (*cross-listing*)
Date: Mon, 24 Nov 2025 09:38:11 GMT   (1126kb)

Title: Defending Large Language Models Against Jailbreak Exploits with
 Responsible AI Considerations
Authors: Ryan Wong (1), Hosea David Yu Fei Ng (1), Dhananjai Sharma (1), Glenn
 Jun Jie Ng (1), Kavishvaran Srinivasan (1) ((1) National University of
 Singapore)
Categories: cs.CR cs.AI
Comments: 20 pages including appendix; technical report; NeurIPS 2024 style
\\
 Large Language Models (LLMs) remain susceptible to jailbreak exploits that
bypass safety filters and induce harmful or unethical behavior. This work
presents a systematic taxonomy of existing jailbreak defenses across
prompt-level, model-level, and training-time interventions, followed by three
proposed defense strategies. First, a Prompt-Level Defense Framework detects
and neutralizes adversarial inputs through sanitization, paraphrasing, and
adaptive system guarding. Second, a Logit-Based Steering Defense reinforces
refusal behavior through inference-time vector steering in safety-sensitive
layers. Third, a Domain-Specific Agent Defense employs the MetaGPT framework to
enforce structured, role-based collaboration and domain adherence. Experiments
on benchmark datasets show substantial reductions in attack success rate,
achieving full mitigation under the agent-based defense. Overall, this study
highlights how jailbreaks pose a significant security threat to LLMs and
identifies key intervention points for prevention, while noting that defense
strategies often involve trade-offs between safety, performance, and
scalability. Code is available at: https://github.com/Kuro0911/CS5446-Project
\\ ( https://arxiv.org/abs/2511.18933 ,  1126kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18980 (*cross-listing*)
Date: Mon, 24 Nov 2025 10:54:19 GMT   (5559kb)

Title: MOCLIP: A Foundation Model for Large-Scale Nanophotonic Inverse Design
Authors: S. Rodionov, A. Burguete-Lopez, M. Makarenko, Q. Wang, F. Getman, and
 A. Fratalocchi
Categories: physics.optics cs.AI
\\
 Foundation models (FM) are transforming artificial intelligence by enabling
generalizable, data-efficient solutions across different domains for a broad
range of applications. However, the lack of large and diverse datasets limits
the development of FM in nanophotonics. This work presents MOCLIP (Metasurface
Optics Contrastive Learning Pretrained), a nanophotonic foundation model that
integrates metasurface geometry and spectra within a shared latent space.
MOCLIP employs contrastive learning to align geometry and spectral
representations using an experimentally acquired dataset with a sample density
comparable to ImageNet-1K. The study demonstrates MOCLIP inverse design
capabilities for high-throughput zero-shot prediction at a rate of 0.2 million
samples per second, enabling the design of a full 4-inch wafer populated with
high-density metasurfaces in minutes. It also shows generative latent-space
optimization reaching 97 percent accuracy. Finally, we introduce an optical
information storage concept that uses MOCLIP to achieve a density of 0.1 Gbit
per square millimeter at the resolution limit, exceeding commercial optical
media by a factor of six. These results position MOCLIP as a scalable and
versatile platform for next-generation photonic design and data-driven
applications.
\\ ( https://arxiv.org/abs/2511.18980 ,  5559kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18992 (*cross-listing*)
Date: Mon, 24 Nov 2025 11:18:59 GMT   (3316kb)

Title: Classification EM-PCA for clustering and embedding
Authors: Zineddine Tighidet, Lazhar Labiod, Mohamed Nadif
Categories: stat.ML cs.AI cs.CL cs.LG
Comments: Accepted at the IEEE conference on Big Data (Special Session on
 Machine Learning)
\\
 The mixture model is undoubtedly one of the greatest contributions to
clustering. For continuous data, Gaussian models are often used and the
Expectation-Maximization (EM) algorithm is particularly suitable for estimating
parameters from which clustering is inferred. If these models are particularly
popular in various domains including image clustering, they however suffer from
the dimensionality and also from the slowness of convergence of the EM
algorithm. However, the Classification EM (CEM) algorithm, a classifying
version, offers a fast convergence solution while dimensionality reduction
still remains a challenge. Thus we propose in this paper an algorithm combining
simultaneously and non-sequentially the two tasks --Data embedding and
Clustering-- relying on Principal Component Analysis (PCA) and CEM. We
demonstrate the interest of such approach in terms of clustering and data
embedding. We also establish different connections with other clustering
approaches.
\\ ( https://arxiv.org/abs/2511.18992 ,  3316kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18999 (*cross-listing*)
Date: Mon, 24 Nov 2025 11:25:30 GMT   (532kb)

Title: Enhancing low energy reconstruction and classification in KM3NeT/ORCA
 with transformers
Authors: Iv\'an Moz\'un Mateo (on behalf of the KM3NeT collaboration)
Categories: hep-ex astro-ph.IM cs.AI
\\
 The current KM3NeT/ORCA neutrino telescope, still under construction, has not
yet reached its full potential in neutrino reconstruction capability. When
training any deep learning model, no explicit information about the physics or
the detector is provided, thus they remain unknown to the model. This study
leverages the strengths of transformers by incorporating attention masks
inspired by the physics and detector design, making the model understand both
the telescope design and the neutrino physics measured on it. The study also
shows the efficacy of transformers on retaining valuable information between
detectors when doing fine-tuning from one configurations to another.
\\ ( https://arxiv.org/abs/2511.18999 ,  532kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19055 (*cross-listing*)
Date: Mon, 24 Nov 2025 12:45:10 GMT   (5893kb)

Title: Large Language Model-Assisted Planning of Electric Vehicle Charging
 Infrastructure with Real-World Case Study
Authors: Xinda Zheng, Canchen Jiang, Hao Wang
Categories: eess.SY cs.AI cs.SY math.OC
Journal-ref: Sustainable Energy Technologies and Assessments, 2025
DOI: 10.1016/j.seta.2025.104723
\\
 The growing demand for electric vehicle (EV) charging infrastructure presents
significant planning challenges, requiring efficient strategies for investment
and operation to deliver cost-effective charging services. However, the
potential benefits of EV charging assignment, particularly in response to
varying spatial-temporal patterns of charging demand, remain under-explored in
infrastructure planning. This paper proposes an integrated approach that
jointly optimizes investment decisions and charging assignments while
accounting for spatial-temporal demand dynamics and their interdependencies. To
support efficient model development, we leverage a large language model (LLM)
to assist in generating and refining the mathematical formulation from
structured natural-language descriptions, significantly reducing the modeling
burden. The resulting optimization model enables optimal joint decision-making
for investment and operation. Additionally, we propose a distributed
optimization algorithm based on the Alternating Direction Method of Multipliers
(ADMM) to address computational complexity in high-dimensional scenarios, which
can be executed on standard computing platforms. We validate our approach
through a case study using 1.5 million real-world travel records from Chengdu,
China, demonstrating a 30% reduction in total cost compared to a baseline
without EV assignment.
\\ ( https://arxiv.org/abs/2511.19055 ,  5893kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19114 (*cross-listing*)
Date: Mon, 24 Nov 2025 13:46:38 GMT   (3492kb)

Title: Physics-informed Neural Operator Learning for Nonlinear Grad-Shafranov
 Equation
Authors: Siqi Ding, Zitong Zhang, Guoyang Shi, Xingyu Li, Xiang Gu, Yanan Xu,
 Huasheng Xie, Hanyue Zhao, Yuejiang Shi, Tianyuan Liu
Categories: physics.plasm-ph cs.AI
Comments: 42 pages, 17 figures, 8 tables,
\\
 As artificial intelligence emerges as a transformative enabler for fusion
energy commercialization, fast and accurate solvers become increasingly
critical. In magnetic confinement nuclear fusion, rapid and accurate solution
of the Grad-Shafranov equation (GSE) is essential for real-time plasma control
and analysis. Traditional numerical solvers achieve high precision but are
computationally prohibitive, while data-driven surrogates infer quickly but
fail to enforce physical laws and generalize poorly beyond training
distributions. To address this challenge, we present a Physics-Informed Neural
Operator (PINO) that directly learns the GSE solution operator, mapping shape
parameters of last closed flux surface to equilibrium solutions for realistic
nonlinear current profiles. Comprehensive benchmarking of five neural
architectures identifies the novel Transformer-KAN (Kolmogorov-Arnold Network)
Neural Operator (TKNO) as achieving highest accuracy (0.25% mean L2 relative
error) under supervised training (only data-driven). However, all data-driven
models exhibit large physics residuals, indicating poor physical consistency.
Our unsupervised training can reduce the residuals by nearly four orders of
magnitude through embedding physics-based loss terms without labeled data.
Critically, semi-supervised learning--integrating sparse labeled data (100
interior points) with physics constraints--achieves optimal balance: 0.48%
interpolation error and the most robust extrapolation performance (4.76% error,
8.9x degradation factor vs 39.8x for supervised models). Accelerated by
TensorRT optimization, our models enable millisecond-level inference,
establishing PINO as a promising pathway for next-generation fusion control
systems.
\\ ( https://arxiv.org/abs/2511.19114 ,  3492kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19156 (*cross-listing*)
Date: Mon, 24 Nov 2025 14:24:08 GMT   (110kb)

Title: Information Physics of Intelligence: Unifying Logical Depth and Entropy
 under Thermodynamic Constraints
Authors: Jianfeng Xu and Zeyan Li
Categories: cs.IT cs.AI cs.LO math.IT
\\
 The rapid scaling of artificial intelligence models has revealed a
fundamental tension between model capacity (storage) and inference efficiency
(computation). While classical information theory focuses on transmission and
storage limits, it lacks a unified physical framework to quantify the
thermodynamic costs of generating information from compressed laws versus
retrieving it from memory. In this paper, we propose a theoretical framework
that treats information processing as an enabling mapping from ontological
states to carrier states. We introduce a novel metric, Derivation Entropy,
which quantifies the effective work required to compute a target state from a
given logical depth. By analyzing the interplay between Shannon entropy
(storage) and computational complexity (time/energy), we demonstrate the
existence of a critical phase transition point. Below this threshold, memory
retrieval is thermodynamically favorable; above it, generative computation
becomes the optimal strategy. This "Energy-Time-Space" conservation law
provides a physical explanation for the efficiency of generative models and
offers a rigorous mathematical bound for designing next-generation,
energy-efficient AI architectures. Our findings suggest that the minimization
of Derivation Entropy is a governing principle for the evolution of both
biological and artificial intelligence.
\\ ( https://arxiv.org/abs/2511.19156 ,  110kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19175 (*cross-listing*)
Date: Mon, 24 Nov 2025 14:36:11 GMT   (495kb)

Title: LLM-Based Agentic Negotiation for 6G: Addressing Uncertainty Neglect and
 Tail-Event Risk
Authors: Hatim Chergui, Farhad Rezazadeh, Mehdi Bennis, Merouane Debbah
Categories: cs.NI cs.AI cs.MA
Comments: Link to open-source non-commercial code available
\\
 A critical barrier to the trustworthiness of sixth-generation (6G) agentic
autonomous networks is the uncertainty neglect bias; a cognitive tendency for
large language model (LLM)-powered agents to make high-stakes decisions based
on simple averages while ignoring the tail risk of extreme events. This paper
proposes an unbiased, risk-aware framework for agentic negotiation, designed to
ensure robust resource allocation in 6G network slicing. Specifically, agents
leverage Digital Twins (DTs) to predict full latency distributions, which are
then evaluated using a formal framework from extreme value theory, namely,
Conditional Value-at-Risk (CVaR). This approach fundamentally shifts the
agent's objective from reasoning over the mean to reasoning over the tail,
thereby building a statistically-grounded buffer against worst-case outcomes.
Furthermore, our framework ensures full uncertainty awareness by requiring
agents to quantify epistemic uncertainty -- confidence in their own DTs
predictions -- and propagate this meta-verification to make robust decisions,
preventing them from acting on unreliable data. We validate this framework in a
6G inter-slice negotiation use-case between an eMBB and a URLLC agent. The
results demonstrate the profound failure of the biased, mean-based baseline,
which consistently fails its SLAs with a 25\% rate. Our unbiased, CVaR-aware
agent successfully mitigates this bias, eliminating SLA violations and reducing
the URLLC and eMBB p99.999 latencies by around 11\%. We show this reliability
comes at the rational and quantifiable cost of slightly reduced energy savings
to 17\%, exposing the false economy of the biased approach. This work provides
a concrete methodology for building the trustworthy autonomous systems required
for 6G.
\\ ( https://arxiv.org/abs/2511.19175 ,  495kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19184 (*cross-listing*)
Date: Mon, 24 Nov 2025 14:51:29 GMT   (500kb)

Title: Torsion-Space Diffusion for Protein Backbone Generation with Geometric
 Refinement
Authors: Lakshaditya Singh, Adwait Shelke, Divyansh Agrawal
Categories: q-bio.BM cs.AI
Comments: 5 pages, 4 figures
\\
 Designing new protein structures is fundamental to computational biology,
enabling advances in therapeutic molecule discovery and enzyme engineering.
Existing diffusion-based generative models typically operate in Cartesian
coordinate space, where adding noise disrupts strict geometric constraints such
as fixed bond lengths and angles, often producing physically invalid
structures. To address this limitation, we propose a Torsion-Space Diffusion
Model that generates protein backbones by denoising torsion angles, ensuring
perfect local geometry by construction. A differentiable forward-kinematics
module reconstructs 3D coordinates with fixed 3.8 Angstrom backbone bond
lengths while a constrained post-processing refinement optimizes global
compactness via Radius of Gyration (Rg) correction, without violating bond
constraints. Experiments on standard PDB proteins demonstrate 100% bond-length
accuracy and significantly improved structural compactness, reducing Rg error
from 70% to 18.6% compared to Cartesian diffusion baselines. Overall, this
hybrid torsion-diffusion plus geometric-refinement framework generates
physically valid and compact protein backbones, providing a promising path
toward full-atom protein generation.
\\ ( https://arxiv.org/abs/2511.19184 ,  500kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19218 (*cross-listing*)
Date: Mon, 24 Nov 2025 15:23:41 GMT   (1042kb)

Title: Adversarial Attack-Defense Co-Evolution for LLM Safety Alignment via
 Tree-Group Dual-Aware Search and Optimization
Authors: Xurui Li, Kaisong Song, Rui Zhu, Pin-Yu Chen, Haixu Tang
Categories: cs.CR cs.AI
\\
 Large Language Models (LLMs) have developed rapidly in web services,
delivering unprecedented capabilities while amplifying societal risks. Existing
works tend to focus on either isolated jailbreak attacks or static defenses,
neglecting the dynamic interplay between evolving threats and safeguards in
real-world web contexts. To mitigate these challenges, we propose ACE-Safety
(Adversarial Co-Evolution for LLM Safety), a novel framework that jointly
optimize attack and defense models by seamlessly integrating two key innovative
procedures: (1) Group-aware Strategy-guided Monte Carlo Tree Search (GS-MCTS),
which efficiently explores jailbreak strategies to uncover vulnerabilities and
generate diverse adversarial samples; (2) Adversarial Curriculum Tree-aware
Group Policy Optimization (AC-TGPO), which jointly trains attack and defense
LLMs with challenging samples via curriculum reinforcement learning, enabling
robust mutual improvement. Evaluations across multiple benchmarks demonstrate
that our method outperforms existing attack and defense approaches, and
provides a feasible pathway for developing LLMs that can sustainably support
responsible AI ecosystems.
\\ ( https://arxiv.org/abs/2511.19218 ,  1042kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19236 (*cross-listing*)
Date: Mon, 24 Nov 2025 15:48:59 GMT   (4164kb)

Title: SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole
 Body Control
Authors: Yuxuan Wang, Haobin Jiang, Shiqing Yao, Ziluo Ding, Zongqing Lu
Categories: cs.RO cs.AI
Comments: 23 pages, 8 figures, 11 tables
\\
 Existing humanoid control systems often rely on teleoperation or modular
generation pipelines that separate language understanding from physical
execution. However, the former is entirely human-driven, and the latter lacks
tight alignment between language commands and physical behaviors. In this
paper, we present SENTINEL, a fully end-to-end language-action model for
humanoid whole-body control. We construct a large-scale dataset by tracking
human motions in simulation using a pretrained whole body controller, combined
with their text annotations. The model directly maps language commands and
proprioceptive inputs to low-level actions without any intermediate
representation. The model generates action chunks using flow matching, which
can be subsequently refined by a residual action head for real-world
deployment. Our method exhibits strong semantic understanding and stable
execution on humanoid robots in both simulation and real-world deployment, and
also supports multi-modal extensions by converting inputs into texts.
\\ ( https://arxiv.org/abs/2511.19236 ,  4164kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19246 (*cross-listing*)
Date: Mon, 24 Nov 2025 15:55:44 GMT   (2740kb)

Title: Neural Architecture Search for Quantum Autoencoders
Authors: Hibah Agha, Samuel Yen-Chi Chen, Huan-Hsin Tseng, and Shinjae Yoo
Categories: quant-ph cs.AI cs.LG cs.NE
\\
 In recent years, machine learning and deep learning have driven advances in
domains such as image classification, speech recognition, and anomaly detection
by leveraging multi-layer neural networks to model complex data.
Simultaneously, quantum computing (QC) promises to address classically
intractable problems via quantum parallelism, motivating research in quantum
machine learning (QML). Among QML techniques, quantum autoencoders show promise
for compressing high-dimensional quantum and classical data. However, designing
effective quantum circuit architectures for quantum autoencoders remains
challenging due to the complexity of selecting gates, arranging circuit layers,
and tuning parameters.
 This paper proposes a neural architecture search (NAS) framework that
automates the design of quantum autoencoders using a genetic algorithm (GA). By
systematically evolving variational quantum circuit (VQC) configurations, our
method seeks to identify high-performing hybrid quantum-classical autoencoders
for data reconstruction without becoming trapped in local minima. We
demonstrate effectiveness on image datasets, highlighting the potential of
quantum autoencoders for efficient feature extraction within a noise-prone,
near-term quantum era. Our approach lays a foundation for broader application
of genetic algorithms to quantum architecture search, aiming for a robust,
automated method that can adapt to varied data and hardware constraints.
\\ ( https://arxiv.org/abs/2511.19246 ,  2740kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19257 (*cross-listing*)
Date: Mon, 24 Nov 2025 16:11:01 GMT   (1880kb)

Title: Medusa: Cross-Modal Transferable Adversarial Attacks on Multimodal
 Medical Retrieval-Augmented Generation
Authors: Yingjia Shang, Yi Liu, Huimin Wang, Furong Li, Wenfang Sun, Wu
 Chengyu, Yefeng Zheng
Categories: cs.CR cs.AI cs.LG
Comments: Accepted at KDD 2026 First Cycle (full version). Authors marked with
 * contributed equally. Yi Liu is the lead author
\\
 With the rapid advancement of retrieval-augmented vision-language models,
multimodal medical retrieval-augmented generation (MMed-RAG) systems are
increasingly adopted in clinical decision support. These systems enhance
medical applications by performing cross-modal retrieval to integrate relevant
visual and textual evidence for tasks, e.g., report generation and disease
diagnosis. However, their complex architecture also introduces underexplored
adversarial vulnerabilities, particularly via visual input perturbations. In
this paper, we propose Medusa, a novel framework for crafting cross-modal
transferable adversarial attacks on MMed-RAG systems under a black-box setting.
Specifically, Medusa formulates the attack as a perturbation optimization
problem, leveraging a multi-positive InfoNCE loss (MPIL) to align adversarial
visual embeddings with medically plausible but malicious textual targets,
thereby hijacking the retrieval process. To enhance transferability, we adopt a
surrogate model ensemble and design a dual-loop optimization strategy augmented
with invariant risk minimization (IRM). Extensive experiments on two real-world
medical tasks, including medical report generation and disease diagnosis,
demonstrate that Medusa achieves over 90% average attack success rate across
various generation models and retrievers under appropriate parameter
configuration, while remaining robust against four mainstream defenses,
outperforming state-of-the-art baselines. Our results reveal critical
vulnerabilities in the MMed-RAG systems and highlight the necessity of
robustness benchmarking in safety-critical medical applications. The code and
data are available at https://anonymous.4open.science/r/MMed-RAG-Attack-F05A.
\\ ( https://arxiv.org/abs/2511.19257 ,  1880kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19275 (*cross-listing*)
Date: Mon, 24 Nov 2025 16:25:55 GMT   (12108kb)

Title: Dynamic Multi-Species Bird Soundscape Generation with Acoustic
 Patterning and 3D Spatialization
Authors: Ellie L. Zhang, Duoduo Liao, Callie C. Liao
Categories: cs.SD cs.AI eess.AS eess.SP
Comments: Accepted by IEEE Big Data 2025
\\
 Generation of dynamic, scalable multi-species bird soundscapes remains a
significant challenge in computer music and algorithmic sound design. Birdsongs
involve rapid frequency-modulated chirps, complex amplitude envelopes,
distinctive acoustic patterns, overlapping calls, and dynamic inter-bird
interactions, all of which require precise temporal and spatial control in 3D
environments. Existing approaches, whether Digital Signal Processing
(DSP)-based or data-driven, typically focus only on single species modeling,
static call structures, or synthesis directly from recordings, and often suffer
from noise, limited flexibility, or large data needs. To address these
challenges, we present a novel, fully algorithm-driven framework that generates
dynamic multi-species bird soundscapes using DSP-based chirp generation and 3D
spatialization, without relying on recordings or training data. Our approach
simulates multiple independently-moving birds per species along different
moving 3D trajectories, supporting controllable chirp sequences, overlapping
choruses, and realistic 3D motion in scalable soundscapes while preserving
species-specific acoustic patterns. A visualization interface provides bird
trajectories, spectrograms, activity timelines, and sound waves for analytical
and creative purposes. Both visual and audio evaluations demonstrate the
ability of the system to generate dense, immersive, and ecologically inspired
soundscapes, highlighting its potential for computer music, interactive virtual
environments, and computational bioacoustics research.
\\ ( https://arxiv.org/abs/2511.19275 ,  12108kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19283 (*cross-listing*)
Date: Mon, 24 Nov 2025 16:31:50 GMT   (209kb)

Title: Data Flows and Colonial Regimes in Africa: A Critical Analysis of the
 Colonial Futurities Embedded in AI Ecosystems
Authors: Ndaka. A, Avila-Acosta. F, Mbula-Ndaka. H, Amera. C, Chauke. S and
 Majiwa. E
Categories: cs.CY cs.AI
Comments: 12 pages
\\
 This chapter seeks to frame the elemental and invisible problems of AI and
big data in the African context by examining digital sites and infrastructure
through the lens of power and interests. It will present reflections on how
these sites are using AI recommendation algorithms to recreate new digital
societies in the region, how they have the potential to propagate algorithmic
colonialism and negative gender norms, and what this means for the regional
sustainable development agenda. The chapter proposes adopting business models
that embrace response-ability and consider the existence of alternative
socio-material worlds of AI. These reflections will mainly come from ongoing
discussions with Kenyan social media users in this authors' user space talks,
personal experiences and six months of active participant observations done by
the authors.
\\ ( https://arxiv.org/abs/2511.19283 ,  209kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19342 (*cross-listing*)
Date: Mon, 24 Nov 2025 17:41:04 GMT   (1092kb)

Title: Explicit Tonal Tension Conditioning via Dual-Level Beam Search for
 Symbolic Music Generation
Authors: Maral Ebrahimzadeh, Gilberto Bernardes, Sebastian Stober
Categories: cs.SD cs.AI
Comments: 12 pages, 2 Figures, Accepted at the 17th International Symposium on
 Computer Music Multidisciplinary Research (CMMR) 2025
\\
 State-of-the-art symbolic music generation models have recently achieved
remarkable output quality, yet explicit control over compositional features,
such as tonal tension, remains challenging. We propose a novel approach that
integrates a computational tonal tension model, based on tonal interval vector
analysis, into a Transformer framework. Our method employs a two-level beam
search strategy during inference. At the token level, generated candidates are
re-ranked using model probability and diversity metrics to maintain overall
quality. At the bar level, a tension-based re-ranking is applied to ensure that
the generated music aligns with a desired tension curve. Objective evaluations
indicate that our approach effectively modulates tonal tension, and subjective
listening tests confirm that the system produces outputs that align with the
target tension. These results demonstrate that explicit tension conditioning
through a dual-level beam search provides a powerful and intuitive tool to
guide AI-generated music. Furthermore, our experiments demonstrate that our
method can generate multiple distinct musical interpretations under the same
tension condition.
\\ ( https://arxiv.org/abs/2511.19342 ,  1092kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19396 (*cross-listing*)
Date: Mon, 24 Nov 2025 18:33:50 GMT   (4787kb)

Title: Real-Time Object Tracking with On-Device Deep Learning for Adaptive
 Beamforming in Dynamic Acoustic Environments
Authors: Jorge Ortigoso-Narro, Jose A. Belloch, Adrian Amor-Martin, Sandra
 Roger, Maximo Cobos
Categories: cs.SD cs.AI cs.CV
\\
 Advances in object tracking and acoustic beamforming are driving new
capabilities in surveillance, human-computer interaction, and robotics. This
work presents an embedded system that integrates deep learning-based tracking
with beamforming to achieve precise sound source localization and directional
audio capture in dynamic environments. The approach combines single-camera
depth estimation and stereo vision to enable accurate 3D localization of moving
objects. A planar concentric circular microphone array constructed with MEMS
microphones provides a compact, energy-efficient platform supporting 2D beam
steering across azimuth and elevation. Real-time tracking outputs continuously
adapt the array's focus, synchronizing the acoustic response with the target's
position. By uniting learned spatial awareness with dynamic steering, the
system maintains robust performance in the presence of multiple or moving
sources. Experimental evaluation demonstrates significant gains in
signal-to-interference ratio, making the design well-suited for
teleconferencing, smart home devices, and assistive technologies.
\\ ( https://arxiv.org/abs/2511.19396 ,  4787kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19422 (*cross-listing*)
Date: Mon, 24 Nov 2025 18:56:47 GMT   (479kb)

Title: SLMFix: Leveraging Small Language Models for Error Fixing with
 Reinforcement Learning
Authors: David Jiahao Fu, Aryan Gupta, Aaron Councilman, David Grove, Yu-Xiong
 Wang, Vikram Adve
Categories: cs.SE cs.AI cs.PL
\\
 Recent advancements in large language models (LLMs) have shown very
impressive capabilities in code generation across many programming languages.
However, even state-of-the-art LLMs generate programs that contains syntactic
errors and fail to complete the given tasks, especially for low-resource
programming languages (LRPLs). In addition, high training cost makes finetuning
LLMs unaffordable with constrained computational resources, further undermining
the effectiveness of LLMs for code generation. In this work, we propose SLMFix,
a novel code generation pipeline that leverages a small language model (SLM)
finetuned using reinforcement learning (RL) techniques to fix syntactic errors
in LLM-generated programs to improve the quality of LLM-generated programs for
domain-specific languages (DSLs). In specific, we applied RL on the SLM for the
program repair task using a reward calculated using both a static validator and
a static semantic similarity metric. Our experimental results demonstrate the
effectiveness and generalizability of our approach across multiple DSLs,
achieving more than 95% pass rate on the static validator. Notably, SLMFix
brings substantial improvement to the base model and outperforms supervised
finetuning approach even for 7B models on a LRPL, showing the potential of our
approach as an alternative to traditional finetuning approaches.
\\ ( https://arxiv.org/abs/2511.19422 ,  479kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19423 (*cross-listing*)
Date: Mon, 24 Nov 2025 18:57:07 GMT   (1126kb)

Title: Beyond Protein Language Models: An Agentic LLM Framework for Mechanistic
 Enzyme Design
Authors: Bruno Jacob, Khushbu Agarwal, Marcel Baer, Peter Rice, Simone Raugei
Categories: q-bio.QM cs.AI
Comments: 10 pages, 4 figures
\\
 We present Genie-CAT, a tool-augmented large-language-model (LLM) system
designed to accelerate scientific hypothesis generation in protein design.
Using metalloproteins (e.g., ferredoxins) as a case study, Genie-CAT integrates
four capabilities -- literature-grounded reasoning through retrieval-augmented
generation (RAG), structural parsing of Protein Data Bank files, electrostatic
potential calculations, and machine-learning prediction of redox properties --
into a unified agentic workflow. By coupling natural-language reasoning with
data-driven and physics-based computation, the system generates mechanistically
interpretable, testable hypotheses linking sequence, structure, and function.
In proof-of-concept demonstrations, Genie-CAT autonomously identifies
residue-level modifications near [Fe--S] clusters that affect redox tuning,
reproducing expert-derived hypotheses in a fraction of the time. The framework
highlights how AI agents combining language models with domain-specific tools
can bridge symbolic reasoning and numerical simulation, transforming LLMs from
conversational assistants into partners for computational discovery.
\\ ( https://arxiv.org/abs/2511.19423 ,  1126kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19427 (*cross-listing*)
Date: Mon, 24 Nov 2025 18:58:22 GMT   (276kb)

Title: Prompt Less, Smile More: MTP with Semantic Engineering in Lieu of Prompt
 Engineering
Authors: Jayanaka L. Dantanarayana, Savini Kashmira, Thakee Nathees, Zichen
 Zhang, Krisztian Flautner, Lingjia Tang, Jason Mars
Categories: cs.SE cs.AI
\\
 AI-Integrated programming is emerging as a foundational paradigm for building
intelligent systems with large language models (LLMs). Recent approaches such
as Meaning Typed Programming (MTP) automate prompt generation by leveraging the
semantics already present in code. However, many real-world applications depend
on contextual cues, developer intent, and domain-specific reasoning that extend
beyond what static code semantics alone can express. To address this
limitation, we introduce Semantic Engineering, a lightweight method for
enriching program semantics so that LLM-based systems can more accurately
reflect developer intent without requiring full manual prompt design. We
present Semantic Context Annotations (SemTexts), a language-level mechanism
that allows developers to embed natural-language context directly into program
constructs. Integrated into the Jac programming language, Semantic Engineering
extends MTP to incorporate these enriched semantics during prompt generation.
We further introduce a benchmark suite designed to reflect realistic
AI-Integrated application scenarios. Our evaluation shows that Semantic
Engineering substantially improves prompt fidelity, achieving performance
comparable to Prompt Engineering while requiring significantly less developer
effort.
\\ ( https://arxiv.org/abs/2511.19427 ,  276kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19433 (*cross-listing*)
Date: Mon, 24 Nov 2025 18:59:51 GMT   (3369kb)

Title: Mixture of Horizons in Action Chunking
Authors: Dong Jing, Gang Wang, Jiaqi Liu, Weiliang Tang, Zelong Sun, Yunchao
 Yao, Zhenyu Wei, Yunhui Liu, Zhiwu Lu, Mingyu Ding
Categories: cs.RO cs.AI cs.CV
Comments: 15 pages, 14 figures
\\
 Vision-language-action (VLA) models have shown remarkable capabilities in
robotic manipulation, but their performance is sensitive to the $\textbf{action
chunk length}$ used during training, termed $\textbf{horizon}$. Our empirical
study reveals an inherent trade-off: longer horizons provide stronger global
foresight but degrade fine-grained accuracy, while shorter ones sharpen local
control yet struggle on long-term tasks, implying fixed choice of single
horizons being suboptimal. To mitigate the trade-off, we propose a
$\textbf{mixture of horizons (MoH)}$ strategy. MoH rearranges the action chunk
into several segments with different horizons, processes them in parallel with
a shared action transformer, and fuses outputs with a light linear gate. It has
three appealing benefits. 1) MoH exploits long-term foresight and short-term
precision jointly within a single model, improving both performance and
generalizability to complex tasks. 2) MoH is plug-and-play for full-attention
action modules with minimal training or inference overhead. 3) MoH enables
dynamic inference with adaptive horizons, which selects stable actions through
cross-horizon consensus, achieving 2.5$\times$ higher throughput than baselines
while preserving superior performance. Extensive experiments over flow-based
policies $\pi_0$, $\pi_{0.5}$, and one-step regression policy
$\pi_{\text{reg}}$ demonstrate that MoH yields consistent and significant gains
on both simulations and real-world tasks. Notably, under mixed-task setting,
$\pi_{0.5}$ with MoH reaches a new state-of-the-art with 99$\%$ average success
rate on LIBERO after only $30k$ training iterations. Project page:
https://github.com/Timsty1/MixtureOfHorizons
\\ ( https://arxiv.org/abs/2511.19433 ,  3369kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17554 (*cross-listing*)
Date: Wed, 12 Nov 2025 16:01:27 GMT   (3656kb)

Title: Beyond the Rubric: Cultural Misalignment in LLM Benchmarks for Sexual
 and Reproductive Health
Authors: Sumon Kanti Dey, Manvi S, Zeel Mehta, Meet Shah, Unnati Agrawal,
 Suhani Jalota, Azra Ismail
Categories: cs.CY cs.CL
Comments: https://github.com/Sumon/healthbench-srh-eval/
\\
 Large Language Models (LLMs) have been positioned as having the potential to
expand access to health information in the Global South, yet their evaluation
remains heavily dependent on benchmarks designed around Western norms. We
present insights from a preliminary benchmarking exercise with a chatbot for
sexual and reproductive health (SRH) for an underserved community in India. We
evaluated using HealthBench, a benchmark for conversational health models by
OpenAI. We extracted 637 SRH queries from the dataset and evaluated on the 330
single-turn conversations. Responses were evaluated using HealthBench's
rubric-based automated grader, which rated responses consistently low. However,
qualitative analysis by trained annotators and public health experts revealed
that many responses were actually culturally appropriate and medically
accurate. We highlight recurring issues, particularly a Western bias, such as
for legal framing and norms (e.g., breastfeeding in public), diet assumptions
(e.g., fish safe to eat during pregnancy), and costs (e.g., insurance models).
Our findings demonstrate the limitations of current benchmarks in capturing the
effectiveness of systems built for different cultural and healthcare contexts.
We argue for the development of culturally adaptive evaluation frameworks that
meet quality standards while recognizing needs of diverse populations.
\\ ( https://arxiv.org/abs/2511.17554 ,  3656kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17555 (*cross-listing*)
Date: Wed, 12 Nov 2025 17:30:13 GMT   (761kb)

Title: Speech Recognition Model Improves Text-to-Speech Synthesis using
 Fine-Grained Reward
Authors: Guansu Wang, Peijie Sun
Categories: eess.AS cs.CL
Comments: The paper makes an important contribution to the very challenging
 problem of training TTS models, with a novel application of reinforcement
 learning and demonstrating convincing improvements
\\
 Recent advances in text-to-speech (TTS) have enabled models to clone
arbitrary unseen speakers and synthesize high-quality, natural-sounding speech.
However, evaluation methods lag behind: typical mean opinion score (MOS)
estimators perform regression over entire utterances, while failures usually
occur in a few problematic words. We observe that encoder-decoder ASR models
(e.g., Whisper) surface word-level mismatches between speech and text via
cross-attention, providing a fine-grained reward signal. Building on this, we
introduce Word-level TTS Alignment by ASR-driven Attentive Reward (W3AR).
Without explicit reward annotations, W3AR uses attention from a pre-trained ASR
model to drive finer-grained alignment and optimization of sequences predicted
by a TTS model. Experiments show that W3AR improves the quality of existing TTS
systems and strengthens zero-shot robustness on unseen speakers. More broadly,
our results suggest a simple recipe for generative modeling: understanding
models can act as evaluators, delivering informative, fine-grained feedback for
optimization.
\\ ( https://arxiv.org/abs/2511.17555 ,  761kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18103 (*cross-listing*)
Date: Sat, 22 Nov 2025 16:02:56 GMT   (85kb)

Title: Comparing Labeled Markov Chains: A Cantor-Kantorovich Approach
Authors: Adrien Banse, Alessandro Abate, Rapha\"el M. Jungers
Categories: cs.LO cs.CL cs.FL math.PR
\\
 Labeled Markov Chains (or LMCs for short) are useful mathematical objects to
model complex probabilistic languages. A central challenge is to compare two
LMCs, for example to assess the accuracy of an abstraction or to quantify the
effect of model perturbations. In this work, we study the recently introduced
Cantor-Kantorovich (or CK) distance. In particular we show that the latter can
be framed as a discounted sum of finite-horizon Total Variation distances,
making it an instance of discounted linear distance, but arising from the
natural Cantor topology. Building on the latter observation, we analyze the
properties of the CK distance along three dimensions: computational complexity,
continuity properties and approximation. More precisely, we show that the exact
computation of the CK distance is #P-hard. We also provide an upper bound on
the CK distance as a function of the approximation relation between the two
LMCs, and show that a bounded CK distance implies a bounded error between
probabilities of finite-horizon traces. Finally, we provide a computable
approximation scheme, and show that the latter is also #P-hard. Altogether, our
results provide a rigorous theoretical foundation for the CK distance and
clarify its relationship with existing distances.
\\ ( https://arxiv.org/abs/2511.18103 ,  85kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18538 (*cross-listing*)
Date: Sun, 23 Nov 2025 17:09:34 GMT   (1731kb)

Title: From Code Foundation Models to Agents and Applications: A Practical
 Guide to Code Intelligence
Authors: Jian Yang, Wei Zhang, Shark Liu, Jiajun Wu, Shawn Guo, Yizhi Li
Categories: cs.SE cs.CL
\\
 Large language models (LLMs) have fundamentally transformed automated
software development by enabling direct translation of natural language
descriptions into functional code, driving commercial adoption through tools
like Github Copilot (Microsoft), Cursor (Anysphere), Trae (ByteDance), and
Claude Code (Anthropic). While the field has evolved dramatically from
rule-based systems to Transformer-based architectures, achieving performance
improvements from single-digit to over 95\% success rates on benchmarks like
HumanEval. In this work, we provide a comprehensive synthesis and practical
guide (a series of analytic and probing experiments) about code LLMs,
systematically examining the complete model life cycle from data curation to
post-training through advanced prompting paradigms, code pre-training,
supervised fine-tuning, reinforcement learning, and autonomous coding agents.
We analyze the code capability of the general LLMs (GPT-4, Claude, LLaMA) and
code-specialized LLMs (StarCoder, Code LLaMA, DeepSeek-Coder, and QwenCoder),
critically examining the techniques, design decisions, and trade-offs. Further,
we articulate the research-practice gap between academic research (e.g.,
benchmarks and tasks) and real-world deployment (e.g., software-related code
tasks), including code correctness, security, contextual awareness of large
codebases, and integration with development workflows, and map promising
research directions to practical needs. Last, we conduct a series of
experiments to provide a comprehensive analysis of code pre-training,
supervised fine-tuning, and reinforcement learning, covering scaling law,
framework selection, hyperparameter sensitivity, model architectures, and
dataset comparisons.
\\ ( https://arxiv.org/abs/2511.18538 ,  1731kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19009 (*cross-listing*)
Date: Mon, 24 Nov 2025 11:38:53 GMT   (13292kb)

Title: Understanding and Mitigating Over-refusal for Large Language Models via
 Safety Representation
Authors: Junbo Zhang, Ran Chen, Qianli Zhou, Xinyang Deng, Wen Jiang
Categories: cs.CR cs.CL
\\
 Large language models demonstrate powerful capabilities across various
natural language processing tasks, yet they also harbor safety vulnerabilities.
To enhance LLM safety, various jailbreak defense methods have been proposed to
guard against harmful outputs. However, improvements in model safety often come
at the cost of severe over-refusal, failing to strike a good balance between
safety and usability. In this paper, we first analyze the causes of
over-refusal from a representation perspective, revealing that over-refusal
samples reside at the boundary between benign and malicious samples. Based on
this, we propose MOSR, designed to mitigate over-refusal by intervening the
safety representation of LLMs. MOSR incorporates two novel components: (1)
Overlap-Aware Loss Weighting, which determines the erasure weight for malicious
samples by quantifying their similarity to pseudo-malicious samples in the
representation space, and (2) Context-Aware Augmentation, which supplements the
necessary context for rejection decisions by adding harmful prefixes before
rejection responses. Experiments demonstrate that our method outperforms
existing approaches in mitigating over-refusal while largely maintaining
safety. Overall, we advocate that future defense methods should strike a better
balance between safety and over-refusal.
\\ ( https://arxiv.org/abs/2511.19009 ,  13292kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17508 (*cross-listing*)
Date: Sat, 4 Oct 2025 02:39:55 GMT   (1289kb)

Title: Deep Learning-based Lightweight RGB Object Tracking for Augmented
 Reality Devices
Authors: Alice Smith, Bob Johnson, Xiaoyu Zhu, Carol Lee
Categories: cs.HC cs.CV
\\
 Augmented Reality (AR) applications often require robust real-time tracking
of objects in the user's environment to correctly overlay virtual content.
Recent advances in computer vision have produced highly accurate deep
learning-based object trackers, but these models are typically too heavy in
computation and memory for wearable AR devices. In this paper, we present a
lightweight RGB object tracking algorithm designed specifically for
resource-constrained AR platforms. The proposed tracker employs a compact
Siamese neural network architecture and incorporates optimization techniques
such as model pruning, quantization, and knowledge distillation to drastically
reduce model size and inference cost while maintaining high tracking accuracy.
We train the tracker offline on large video datasets using deep convolutional
neural networks and then deploy it on-device for real-time tracking.
Experimental results on standard tracking benchmarks show that our approach
achieves comparable accuracy to state-of-the-art trackers, yet runs in
real-time on a mobile AR headset at around 30 FPS -- more than an order of
magnitude faster than prior high-performance trackers on the same hardware.
This work enables practical, robust object tracking for AR use-cases, opening
the door to more interactive and dynamic AR experiences on lightweight devices.
\\ ( https://arxiv.org/abs/2511.17508 ,  1289kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17652 (*cross-listing*)
Date: Thu, 20 Nov 2025 13:29:35 GMT   (4615kb)

Title: TeamPath: Building MultiModal Pathology Experts with Reasoning AI
 Copilots
Authors: Tianyu Liu, Weihao Xuan, Hao Wu, Peter Humphrey, Marcello DiStasio,
 Heli Qi, Rui Yang, Simeng Han, Tinglin Huang, Fang Wu, Nan Liu, Irene Li, Hua
 Xu, Hongyu Zhao
Categories: q-bio.QM cs.CV
Comments: 35 pages, 6 figures
\\
 Advances in AI have introduced several strong models in computational
pathology to usher it into the era of multi-modal diagnosis, analysis, and
interpretation. However, the current pathology-specific visual language models
still lack capacities in making diagnosis with rigorous reasoning paths as well
as handling divergent tasks, and thus challenges of building AI Copilots for
real scenarios still exist. Here we introduce TeamPath, an AI system powered by
reinforcement learning and router-enhanced solutions based on large-scale
histopathology multimodal datasets, to work as a virtual assistant for
expert-level disease diagnosis, patch-level information summarization, and
cross-modality generation to integrate transcriptomic information for the
clinical usage. We also collaborate with pathologists from Yale School of
Medicine to demonstrate that TeamPath can assist them in working more
efficiently by identifying and correcting expert conclusions and reasoning
paths. Overall, TeamPath can flexibly choose the best settings according to the
needs, and serve as an innovative and reliable system for information
communication across different modalities and experts.
\\ ( https://arxiv.org/abs/2511.17652 ,  4615kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17744 (*cross-listing*)
Date: Fri, 21 Nov 2025 19:51:25 GMT   (20859kb)

Title: Robust Detection of Retinal Neovascularization in Widefield Optical
 Coherence Tomography
Authors: Jinyi Hao (1), Jie Wang (1), Kotaro Tsuboi (2), Liqin Gao (1), Tristan
 T. Hormel (1), Yukun Guo (1 and 3), An-Lun Wu (1 and 4), Min Gao (1 and 3),
 Christina J. Flaxel (1), Steven T. Bailey (1), Thomas S. Hwang (1), and Yali
 Jia (1 and 3) ((1) Casey Eye Institute, Oregon Health & Science University,
 Portland, Oregon 97239, USA, (2) Department of Ophthalmology, Aichi Medical
 University, 1-1, Yazako Karimata, Nagakute, Aichi, 480- 1195, Japan, (3)
 Department of Biomedical Engineering, Oregon Health & Science University,
 Portland, Oregon 97239, USA, (4) Department of Ophthalmology, Mackay Memorial
 Hospital, Hsinchu 300044, Taiwan)
Categories: eess.IV cs.CV
Comments: 17 pages, 11 figures. Submitted to Optica. Corresponding author: Yali
 Jia. Affiliations: ((1) Casey Eye Institute, Oregon Health & Science
 University, USA (2) Department of Ophthalmology, Aichi Medical University,
 Japan (3) Department of Biomedical Engineering, Oregon Health & Science
 University, USA (4) Department of Ophthalmology, Mackay Memorial Hospital,
 Taiwan)
\\
 Retinal neovascularization (RNV) is a vision threatening development in
diabetic retinopathy (DR). Vision loss associated with RNV is preventable with
timely intervention, making RNV clinical screening and monitoring a priority.
Optical coherence tomography (OCT) angiography (OCTA) provides high-resolution
imaging and high-sensitivity detection of RNV lesions. With recent commercial
devices introducing widefield OCTA imaging to the clinic, the technology stands
to improve early detection of RNV pathology. However, to meet clinical
requirements these imaging capabilities must be combined with effective RNV
detection and quantification, but existing algorithms for OCTA images are
optimized for conventional, i.e. narrow, fields of view. Here, we present a
novel approach for RNV diagnosis and staging on widefield OCT/OCTA. Unlike
conventional methods dependent on multi-layer retinal segmentation, our model
reframes RNV identification as a direct binary localization task. Our fully
automated approach was trained and validated on 589 widefield scans (17x17-mm
to 26x21-mm) collected from multiple devices at multiple clinics. Our method
achieved a device-dependent area under curve (AUC) ranging from 0.96 to 0.99
for RNV diagnosis, and mean intersection over union (IOU) ranging from 0.76 to
0.88 for segmentation. We also demonstrate our method's ability to monitor
lesion growth longitudinally. Our results indicate that deep learning-based
analysis for widefield OCTA images could offer a valuable means for improving
RNV screening and management.
\\ ( https://arxiv.org/abs/2511.17744 ,  20859kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17889 (*cross-listing*)
Date: Sat, 22 Nov 2025 02:34:10 GMT   (38717kb)

Title: MobileVLA-R1: Reinforcing Vision-Language-Action for Mobile Robots
Authors: Ting Huang, Dongjian Li, Rui Yang, Zeyu Zhang, Zida Yang, Hao Tang
Categories: cs.RO cs.CV
\\
 Grounding natural-language instructions into continuous control for quadruped
robots remains a fundamental challenge in vision language action. Existing
methods struggle to bridge high-level semantic reasoning and low-level
actuation, leading to unstable grounding and weak generalization in the real
world. To address these issues, we present MobileVLA-R1, a unified
vision-language-action framework that enables explicit reasoning and continuous
control for quadruped robots. We construct MobileVLA-CoT, a large-scale dataset
of multi-granularity chain-of-thought (CoT) for embodied trajectories,
providing structured reasoning supervision for alignment. Built upon this
foundation, we introduce a two-stage training paradigm that combines supervised
CoT alignment with GRPO reinforcement learning to enhance reasoning
consistency, control stability, and long-horizon execution. Extensive
evaluations on VLN and VLA tasks demonstrate superior performance over strong
baselines, with approximately a 5% improvement. Real-world deployment on a
quadruped robot validates robust performance in complex environments. Code:
https://github.com/AIGeeksGroup/MobileVLA-R1. Website:
https://aigeeksgroup.github.io/MobileVLA-R1.
\\ ( https://arxiv.org/abs/2511.17889 ,  38717kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17895 (*cross-listing*)
Date: Sat, 22 Nov 2025 02:58:03 GMT   (3525kb)

Title: Spectral Super-Resolution Neural Operator with Atmospheric Radiative
 Transfer Prior
Authors: Ziye Zhang, Bin Pan, Zhenwei Shi
Categories: eess.IV cs.CV
\\
 Spectral super-resolution (SSR) aims to reconstruct hyperspectral images
(HSIs) from multispectral observations, with broad applications in remote
sensing. Data-driven methods are widely used, but they often overlook physical
principles, leading to unrealistic spectra, particularly in atmosphere-affected
bands. To address this challenge, we propose the Spectral Super-Resolution
Neural Operator (SSRNO), which incorporates atmospheric radiative transfer
(ART) prior into the data-driven procedure, yielding more physically consistent
predictions. The proposed SSRNO framework consists of three stages: upsampling,
reconstruction, and refinement. In the upsampling stage, we leverage prior
information to expand the input multispectral image, producing a physically
plausible hyperspectral estimate. Subsequently, we utilize a neural operator in
the reconstruction stage to learn a continuous mapping across the spectral
domain. Finally, the refinement stage imposes a hard constraint on the output
HSI to eliminate color distortion. The upsampling and refinement stages are
implemented via the proposed guidance matrix projection (GMP) method, and the
reconstruction neural operator adopts U-shaped spectral-aware convolution (SAC)
layers to capture multi-scale features. Moreover, we theoretically demonstrate
the optimality of the GMP method. With the neural operator and ART priors,
SSRNO also achieves continuous spectral reconstruction and zero-shot
extrapolation. Various experiments validate the effectiveness and
generalization ability of the proposed approach.
\\ ( https://arxiv.org/abs/2511.17895 ,  3525kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17920 (*cross-listing*)
Date: Sat, 22 Nov 2025 05:19:05 GMT   (825kb)

Title: Animated Territorial Data Extractor (ATDE): A Computer-Vision Method for
 Extracting Territorial Data from Animated Historical Maps
Authors: Hamza Alshamy, Isaiah Woram, Advay Mishra, Zihan Xia, Pascal Wallisch
Categories: cs.CY cs.CV
Comments: 11 pages, 5 figures
\\
 We present Animated Territorial Data Extractor (ATDE), a computer vision tool
that extracts quantitative territorial data from animated historical map
videos. ATDE employs HSV-based color segmentation, RGB channel filtering, and
Direct-Neighbor Filtering to identify and count pixels representing territorial
control. Combined with preprocessing for temporal alignment and cross-video
scaling, the pipeline converts animated videos into structured time-series
data. We demonstrate the tool on ten Chinese dynasties (200 BCE - 1912 CE),
producing year-by-year pixel counts that align with expected historical
patterns. While not a substitute for authoritative historical datasets, ATDE is
well-suited for educational demonstrations, preliminary data exploration, and
comparative analysis of territorial dynamics. The tool requires no pre-existing
shapefiles and can be applied to any animated map video given seed colors and
basic configuration. Code and examples are available on GitHub.
\\ ( https://arxiv.org/abs/2511.17920 ,  825kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17925 (*cross-listing*)
Date: Sat, 22 Nov 2025 05:40:52 GMT   (2563kb)

Title: Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using
 a Commercial Console Game
Authors: Jeonghwan Kim, Wontaek Kim, Yidan Lu, Jin Cheng, Fatemeh Zargarbashi,
 Zicheng Zeng, Zekun Qi, Zhiyang Dou, Nitish Sontakke, Donghoon Baek, Sehoon
 Ha, Tianyu Li
Categories: cs.RO cs.CV
\\
 Recent advances in whole-body robot control have enabled humanoid and legged
robots to perform increasingly agile and coordinated motions. However,
standardized benchmarks for evaluating these capabilities in real-world
settings, and in direct comparison to humans, remain scarce. Existing
evaluations often rely on pre-collected human motion datasets or
simulation-based experiments, which limit reproducibility, overlook hardware
factors, and hinder fair human-robot comparisons. We present Switch-JustDance,
a low-cost and reproducible benchmarking pipeline that leverages motion-sensing
console games, Just Dance on the Nintendo Switch, to evaluate robot whole-body
control. Using Just Dance on the Nintendo Switch as a representative platform,
Switch-JustDance converts in-game choreography into robot-executable motions
through streaming, motion reconstruction, and motion retargeting modules and
enables users to evaluate controller performance through the game's built-in
scoring system. We first validate the evaluation properties of Just Dance,
analyzing its reliability, validity, sensitivity, and potential sources of
bias. Our results show that the platform provides consistent and interpretable
performance measures, making it a suitable tool for benchmarking embodied AI.
Building on this foundation, we benchmark three state-of-the-art humanoid
whole-body controllers on hardware and provide insights into their relative
strengths and limitations.
\\ ( https://arxiv.org/abs/2511.17925 ,  2563kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18140 (*cross-listing*)
Date: Sat, 22 Nov 2025 17:53:16 GMT   (1451kb)

Title: Observer Actor: Active Vision Imitation Learning with Sparse View
 Gaussian Splatting
Authors: Yilong Wang, Cheng Qian, Ruomeng Fan, and Edward Johns
Categories: cs.RO cs.CV cs.LG
Comments: Videos are available on our project webpage at
 https://obact.github.io
\\
 We propose Observer Actor (ObAct), a novel framework for active vision
imitation learning in which the observer moves to optimal visual observations
for the actor. We study ObAct on a dual-arm robotic system equipped with
wrist-mounted cameras. At test time, ObAct dynamically assigns observer and
actor roles: the observer arm constructs a 3D Gaussian Splatting (3DGS)
representation from three images, virtually explores this to find an optimal
camera pose, then moves to this pose; the actor arm then executes a policy
using the observer's observations. This formulation enhances the clarity and
visibility of both the object and the gripper in the policy's observations. As
a result, we enable the training of ambidextrous policies on observations that
remain closer to the occlusion-free training distribution, leading to more
robust policies. We study this formulation with two existing imitation learning
methods -- trajectory transfer and behavior cloning -- and experiments show
that ObAct significantly outperforms static-camera setups: trajectory transfer
improves by 145% without occlusion and 233% with occlusion, while behavior
cloning improves by 75% and 143%, respectively. Videos are available at
https://obact.github.io.
\\ ( https://arxiv.org/abs/2511.18140 ,  1451kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18151 (*cross-listing*)
Date: Sat, 22 Nov 2025 18:42:04 GMT   (6160kb)

Title: AVERY: Adaptive VLM Split Computing through Embodied Self-Awareness for
 Efficient Disaster Response Systems
Authors: Rajat Bhattacharjya, Sing-Yao Wu, Hyunwoo Oh, Chaewon Nam, Suyeon Koo,
 Mohsen Imani, Elaheh Bozorgzadeh, Nikil Dutt
Categories: cs.DC cs.AR cs.CV cs.LG cs.NI
Comments: 8 pages, 5 figures. Paper is currently under review. Authors' version
 posted for personal use and not for redistribution
\\
 Unmanned Aerial Vehicles (UAVs) in disaster response require complex,
queryable intelligence that on-board CNNs cannot provide. While Vision-Language
Models (VLMs) offer this semantic reasoning, their high resource demands make
on-device deployment infeasible, and naive cloud offloading fails under the
low-bandwidth networks common in disaster zones. We present AVERY, a framework
that enables VLM deployment through adaptive split computing. We advance the
split computing paradigm beyond traditional depth-wise partitioning by
introducing a functional, cognitive-inspired dual-stream split that separates
the VLM into a high-frequency, low-resolution "context stream" for real-time
awareness and a low-frequency, high-fidelity "insight stream" for deep
analysis. A lightweight, self-aware on-board controller manages this
architecture, monitoring network conditions and operator intent to dynamically
select from pre-trained compression models, navigating the fundamental
accuracy-throughput trade-off. Evaluated using the VLM LISA-7B across an
edge-cloud scenario under fluctuating network conditions, AVERY consistently
outperforms static configurations, achieving 11.2% higher accuracy than raw
image compression and 93.98% lower energy consumption compared to full-edge
execution, thereby enhancing mission efficiency and enabling real-time,
queryable intelligence on resource-constrained platforms in dynamic
environments.
\\ ( https://arxiv.org/abs/2511.18151 ,  6160kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18197 (*cross-listing*)
Date: Sat, 22 Nov 2025 21:56:55 GMT   (563kb)

Title: Linear Algebraic Approaches to Neuroimaging Data Compression: A
 Comparative Analysis of Matrix and Tensor Decomposition Methods for
 High-Dimensional Medical Images
Authors: Jaeho Kim, Daniel David, Ana Vizitiv
Categories: eess.IV cs.CV
\\
 This paper evaluates Tucker decomposition and Singular Value Decomposition
(SVD) for compressing neuroimaging data. Tucker decomposition preserves
multi-dimensional relationships, achieving superior reconstruction fidelity and
perceptual similarity. SVD excels in extreme compression but sacrifices
fidelity. The results highlight Tucker decomposition's suitability for
applications requiring the preservation of structural and temporal
relationships.
\\ ( https://arxiv.org/abs/2511.18197 ,  563kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18322 (*cross-listing*)
Date: Sun, 23 Nov 2025 07:27:39 GMT   (1282kb)

Title: Learning Visually Interpretable Oscillator Networks for Soft Continuum
 Robots from Video
Authors: Henrik Krauss, Johann Licher, Naoya Takeishi, Annika Raatz, Takehisa
 Yairi
Categories: cs.RO cs.CV cs.LG
\\
 Data-driven learning of soft continuum robot (SCR) dynamics from
high-dimensional observations offers flexibility but often lacks physical
interpretability, while model-based approaches require prior knowledge and can
be computationally expensive. We bridge this gap by introducing (1) the
Attention Broadcast Decoder (ABCD), a plug-and-play module for
autoencoder-based latent dynamics learning that generates pixel-accurate
attention maps localizing each latent dimension's contribution while filtering
static backgrounds. (2) By coupling these attention maps to 2D oscillator
networks, we enable direct on-image visualization of learned dynamics (masses,
stiffness, and forces) without prior knowledge. We validate our approach on
single- and double-segment SCRs, demonstrating that ABCD-based models
significantly improve multi-step prediction accuracy: 5.7x error reduction for
Koopman operators and 3.5x for oscillator networks on the two-segment robot.
The learned oscillator network autonomously discovers a chain structure of
oscillators. Unlike standard methods, ABCD models enable smooth latent space
extrapolation beyond training data. This fully data-driven approach yields
compact, physically interpretable models suitable for control applications.
\\ ( https://arxiv.org/abs/2511.18322 ,  1282kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18353 (*cross-listing*)
Date: Sun, 23 Nov 2025 09:00:33 GMT   (1473kb)

Title: Enhancing UAV Search under Occlusion using Next Best View Planning
Authors: Sigrid Helene Strand, Thomas Wiedemann, Bram Burczek, Dmitriy Shutin
Categories: cs.RO cs.CV
Comments: Submitted to IEEE Journal of Selected Topics in Applied Earth
 Observations and Remote Sensing
\\
 Search and rescue missions are often critical following sudden natural
disasters or in high-risk environmental situations. The most challenging search
and rescue missions involve difficult-to-access terrains, such as dense forests
with high occlusion. Deploying unmanned aerial vehicles for exploration can
significantly enhance search effectiveness, facilitate access to challenging
environments, and reduce search time. However, in dense forests, the
effectiveness of unmanned aerial vehicles depends on their ability to capture
clear views of the ground, necessitating a robust search strategy to optimize
camera positioning and perspective. This work presents an optimized planning
strategy and an efficient algorithm for the next best view problem in occluded
environments. Two novel optimization heuristics, a geometry heuristic, and a
visibility heuristic, are proposed to enhance search performance by selecting
optimal camera viewpoints. Comparative evaluations in both simulated and
real-world settings reveal that the visibility heuristic achieves greater
performance, identifying over 90% of hidden objects in simulated forests and
offering 10% better detection rates than the geometry heuristic. Additionally,
real-world experiments demonstrate that the visibility heuristic provides
better coverage under the canopy, highlighting its potential for improving
search and rescue missions in occluded environments.
\\ ( https://arxiv.org/abs/2511.18353 ,  1473kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18415 (*cross-listing*)
Date: Sun, 23 Nov 2025 12:03:09 GMT   (1936kb)

Title: Self-Empowering VLMs: Achieving Hierarchical Consistency via
 Self-Elicited Knowledge Distillation
Authors: Wei Yang, Yiran Zhu, Zilin Li, Xunjia Zhang, Hongtao Wang
Categories: cs.MM cs.CV
Comments: 21 pages, 18 tables, 6 figures
\\
 Vision-language models (VLMs) possess rich knowledge but often fail on
hierarchical understanding tasks, where the goal is to predict a coarse-to-fine
taxonomy path that remains consistent across all levels. We compare three
inference paradigms for hierarchical VQA and find that stepwise reasoning, when
conditioned on prior answers, significantly outperforms single-pass prompting.
Further analysis indicates that the main limitation of current VLMs is their
inability to maintain cross-level state, rather than a lack of taxonomic
knowledge. Motivated by this diagnosis, we propose Self-Elicited Knowledge
Distillation (SEKD), which requires no human labels or external tools: the same
VLM is prompted to reason step by step and act as a teacher by exposing its
hard labels, soft distributions, and decoder hidden states, while a single-pass
student distills these signals. The student VLM remains efficient while
approaching the accuracy of its multi-step teacher. It improves in-domain path
consistency (HCA) by up to +29.50 percentage points, raises zero-shot HCA on an
unseen taxonomy from 4.15% to 42.26%, and yields gains on challenging
mathematical benchmarks. Because all supervision is self-elicited, SEKD scales
to new taxonomies and datasets without annotation cost, providing a practical
route to imbue compact VLMs with dependency-aware multi-step reasoning.
\\ ( https://arxiv.org/abs/2511.18415 ,  1936kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18617 (*cross-listing*)
Date: Sun, 23 Nov 2025 21:21:10 GMT   (5247kb)

Title: AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual
 Imitation Learning without Extra Human Annotations
Authors: Litian Gong (1), Fatemeh Bahrani (2), Yutai Zhou (2), Amin
 Banayeeanzade (2), Jiachen Li (1), Erdem Biyik (2) ((1) University of
 California, Riverside, USA, (2) University of Southern California, USA)
Categories: cs.RO cs.CV
Comments: 8 pages, 6 figures. Code and datasets available at
 http://autofocus-il.github.io/
\\
 AutoFocus-IL is a simple yet effective method to improve data efficiency and
generalization in visual imitation learning by guiding policies to attend to
task-relevant features rather than distractors and spurious correlations.
Although saliency regularization has emerged as a promising way to achieve
this, existing approaches typically require costly supervision such as human
gaze data or manual saliency annotations. In contrast, AutoFocus-IL leverages
vision-language models (VLMs) to automatically identify and track key objects
in demonstrations, generating temporal saliency maps that highlight causal
visual signals while suppressing distractors. These maps are then used to
regularize behavior cloning policies, yielding stronger alignment between
visual attention and task-relevant cues. Experiments in both the CARLA
simulator and real-robot manipulation tasks demonstrate that AutoFocus-IL not
only outperforms standard behavior cloning but also surpasses state-of-the-art
baselines that assume privileged access to human supervision, such as gaze
data. Code, datasets, and trained policy videos are available at
https://AutoFocus-IL.github.io/.
\\ ( https://arxiv.org/abs/2511.18617 ,  5247kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18680 (*cross-listing*)
Date: Mon, 24 Nov 2025 01:44:09 GMT   (38139kb)

Title: Inverse Rendering for High-Genus Surface Meshes from Multi-View Images
Authors: Xiang Gao, Xinmu Wang, Xiaolong Wu, Jiazhi Li, Jingyu Shi, Yu Guo,
 Yuanpeng Liu, Xiyun Song, Heather Yu, Zongfang Lin, Xianfeng David Gu
Categories: cs.GR cs.CV
Comments: 3DV2026 Accepted (Poster)
\\
 We present a topology-informed inverse rendering approach for reconstructing
high-genus surface meshes from multi-view images. Compared to 3D
representations like voxels and point clouds, mesh-based representations are
preferred as they enable the application of differential geometry theory and
are optimized for modern graphics pipelines. However, existing inverse
rendering methods often fail catastrophically on high-genus surfaces, leading
to the loss of key topological features, and tend to oversmooth low-genus
surfaces, resulting in the loss of surface details. This failure stems from
their overreliance on Adam-based optimizers, which can lead to vanishing and
exploding gradients. To overcome these challenges, we introduce an adaptive
V-cycle remeshing scheme in conjunction with a re-parametrized Adam optimizer
to enhance topological and geometric awareness. By periodically coarsening and
refining the deforming mesh, our method informs mesh vertices of their current
topology and geometry before optimization, mitigating gradient issues while
preserving essential topological features. Additionally, we enforce topological
consistency by constructing topological primitives with genus numbers that
match those of ground truth using Gauss-Bonnet theorem. Experimental results
demonstrate that our inverse rendering approach outperforms the current
state-of-the-art method, achieving significant improvements in Chamfer Distance
and Volume IoU, particularly for high-genus surfaces, while also enhancing
surface details for low-genus surfaces.
\\ ( https://arxiv.org/abs/2511.18680 ,  38139kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18702 (*cross-listing*)
Date: Mon, 24 Nov 2025 02:52:36 GMT   (9763kb)

Title: CNN-Based Camera Pose Estimation and Localisation of Scan Images for
 Aircraft Visual Inspection
Authors: Xueyan Oh, Leonard Loh, Shaohui Foong, Zhong Bao Andy Koh, Kow Leong
 Ng, Poh Kang Tan, Pei Lin Pearlin Toh, and U-Xuan Tan
Categories: cs.RO cs.CV
Comments: 12 pages, 12 figures
Journal-ref: X. Oh et al., "CNN-Based Camera Pose Estimation and Localization
 of Scan Images for Aircraft Visual Inspection," in IEEE Transactions on
 Intelligent Transportation Systems, vol. 25, no. 8, pp. 8629-8640, Aug. 2024
DOI: 10.1109/TITS.2024.3369653
\\
 General Visual Inspection is a manual inspection process regularly used to
detect and localise obvious damage on the exterior of commercial aircraft.
There has been increasing demand to perform this process at the boarding gate
to minimise the downtime of the aircraft and automating this process is desired
to reduce the reliance on human labour. Automating this typically requires
estimating a camera's pose with respect to the aircraft for initialisation but
most existing localisation methods require infrastructure, which is very
challenging in uncontrolled outdoor environments and within the limited
turnover time (approximately 2 hours) on an airport tarmac. Additionally, many
airlines and airports do not allow contact with the aircraft's surface or using
UAVs for inspection between flights, and restrict access to commercial
aircraft. Hence, this paper proposes an on-site method that is
infrastructure-free and easy to deploy for estimating a pan-tilt-zoom camera's
pose and localising scan images. This method initialises using the same
pan-tilt-zoom camera used for the inspection task by utilising a Deep
Convolutional Neural Network fine-tuned on only synthetic images to predict its
own pose. We apply domain randomisation to generate the dataset for fine-tuning
the network and modify its loss function by leveraging aircraft geometry to
improve accuracy. We also propose a workflow for initialisation, scan path
planning, and precise localisation of images captured from a pan-tilt-zoom
camera. We evaluate and demonstrate our approach through experiments with real
aircraft, achieving root-mean-square camera pose estimation errors of less than
0.24 m and 2 degrees for all real scenes.
\\ ( https://arxiv.org/abs/2511.18702 ,  9763kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18724 (*cross-listing*)
Date: Mon, 24 Nov 2025 03:29:58 GMT   (3861kb)

Title: Neural B-Frame Coding: Tackling Domain Shift Issues with Lightweight
 Online Motion Resolution Adaptation
Authors: Sang NguyenQuang, Xiem HoangVan, Wen-Hsiao Peng
Categories: eess.IV cs.CV cs.MM
Comments: Accepted by TCAS-II: Express Briefs
\\
 Learned B-frame codecs with hierarchical temporal prediction often encounter
the domain-shift issue due to mismatches between the Group-of-Pictures (GOP)
sizes for training and testing, leading to inaccurate motion estimates,
particularly for large motion. A common solution is to turn large motion into
small motion by downsampling video frames during motion estimation. However,
determining the optimal downsampling factor typically requires costly
rate-distortion optimization. This work introduces lightweight classifiers to
predict downsampling factors. These classifiers leverage simple state signals
from current and reference frames to balance rate-distortion performance with
computational cost. Three variants are proposed: (1) a binary classifier
(Bi-Class) trained with Focal Loss to choose between high and low resolutions,
(2) a multi-class classifier (Mu-Class) trained with novel soft labels based on
rate-distortion costs, and (3) a co-class approach (Co-Class) that combines the
predictive capability of the multi-class classifier with the selective search
of the binary classifier. All classifier methods can work seamlessly with
existing B-frame codecs without requiring codec retraining. Experimental
results show that they achieve coding performance comparable to exhaustive
search methods while significantly reducing computational complexity. The code
is available at: https://github.com/NYCU-MAPL/Fast-OMRA.git.
\\ ( https://arxiv.org/abs/2511.18724 ,  3861kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18794 (*cross-listing*)
Date: Mon, 24 Nov 2025 05:55:33 GMT   (35845kb)

Title: ChronoGS: Disentangling Invariants and Changes in Multi-Period Scenes
Authors: Zhongtao Wang, Jiaqi Dai, Qingtian Zhu, Yilong Li, Mai Su, Fei Zhu,
 Meng Gai, Shaorong Wang, Chengwei Pan, Yisong Chen, Guoping Wang
Categories: cs.GR cs.CV
MSC-class: 68U05
\\
 Multi-period image collections are common in real-world applications. Cities
are re-scanned for mapping, construction sites are revisited for progress
tracking, and natural regions are monitored for environmental change. Such data
form multi-period scenes, where geometry and appearance evolve. Reconstructing
such scenes is an important yet underexplored problem. Existing pipelines rely
on incompatible assumptions: static and in-the-wild methods enforce a single
geometry, while dynamic ones assume smooth motion, both failing under
long-term, discontinuous changes. To solve this problem, we introduce ChronoGS,
a temporally modulated Gaussian representation that reconstructs all periods
within a unified anchor scaffold. It's also designed to disentangle stable and
evolving components, achieving temporally consistent reconstruction of
multi-period scenes. To catalyze relevant research, we release ChronoScene
dataset, a benchmark of real and synthetic multi-period scenes, capturing
geometric and appearance variation. Experiments demonstrate that ChronoGS
consistently outperforms baselines in reconstruction quality and temporal
consistency. Our code and the ChronoScene dataset are publicly available at
https://github.com/ZhongtaoWang/ChronoGS.
\\ ( https://arxiv.org/abs/2511.18794 ,  35845kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18833 (*cross-listing*)
Date: Mon, 24 Nov 2025 07:11:12 GMT   (635kb)

Title: PrismAudio: Decomposed Chain-of-Thoughts and Multi-dimensional Rewards
 for Video-to-Audio Generation
Authors: Huadai Liu, Kaicheng Luo, Wen Wang, Qian Chen, Peiwen Sun, Rongjie
 Huang, Xiangang Li, Jieping Ye, Wei Xue
Categories: cs.SD cs.CV eess.AS eess.IV
Comments: Preprint
\\
 Video-to-Audio (V2A) generation requires balancing four critical perceptual
dimensions: semantic consistency, audio-visual temporal synchrony, aesthetic
quality, and spatial accuracy; yet existing methods suffer from objective
entanglement that conflates competing goals in single loss functions and lack
human preference alignment. We introduce PrismAudio, the first framework to
integrate Reinforcement Learning into V2A generation with specialized
Chain-of-Thought (CoT) planning. Our approach decomposes monolithic reasoning
into four specialized CoT modules (Semantic, Temporal, Aesthetic, and Spatial
CoT), each paired with targeted reward functions. This CoT-reward
correspondence enables multidimensional RL optimization that guides the model
to jointly generate better reasoning across all perspectives, solving the
objective entanglement problem while preserving interpretability. To make this
optimization computationally practical, we propose Fast-GRPO, which employs
hybrid ODE-SDE sampling that dramatically reduces the training overhead
compared to existing GRPO implementations. We also introduce AudioCanvas, a
rigorous benchmark that is more distributionally balanced and covers more
realistically diverse and challenging scenarios than existing datasets, with
300 single-event classes and 501 multi-event samples. Experimental results
demonstrate that PrismAudio achieves state-of-the-art performance across all
four perceptual dimensions on both the in-domain VGGSound test set and
out-of-domain AudioCanvas benchmark. The project page is available at
https://PrismAudio-Project.github.io.
\\ ( https://arxiv.org/abs/2511.18833 ,  635kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18900 (*cross-listing*)
Date: Mon, 24 Nov 2025 08:58:14 GMT   (20891kb)

Title: MatMart: Material Reconstruction of 3D Objects via Diffusion
Authors: Xiuchao Wu, Pengfei Zhu, Jiangjing Lyu, Xinguo Liu, Jie Guo, Yanwen
 Guo, Weiwei Xu, Chengfei Lyu
Categories: cs.GR cs.CV
\\
 Applying diffusion models to physically-based material estimation and
generation has recently gained prominence. In this paper, we propose \ttt, a
novel material reconstruction framework for 3D objects, offering the following
advantages. First, \ttt\ adopts a two-stage reconstruction, starting with
accurate material prediction from inputs and followed by prior-guided material
generation for unobserved views, yielding high-fidelity results. Second, by
utilizing progressive inference alongside the proposed view-material
cross-attention (VMCA), \ttt\ enables reconstruction from an arbitrary number
of input images, demonstrating strong scalability and flexibility. Finally,
\ttt\ achieves both material prediction and generation capabilities through
end-to-end optimization of a single diffusion model, without relying on
additional pre-trained models, thereby exhibiting enhanced stability across
various types of objects. Extensive experiments demonstrate that \ttt\ achieves
superior performance in material reconstruction compared to existing methods.
\\ ( https://arxiv.org/abs/2511.18900 ,  20891kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18950 (*cross-listing*)
Date: Mon, 24 Nov 2025 10:06:41 GMT   (9214kb)

Title: Compressor-VLA: Instruction-Guided Visual Token Compression for
 Efficient Robotic Manipulation
Authors: Juntao Gao, Feiyang Ye, Jing Zhang, Wenjing Qian
Categories: cs.RO cs.CV cs.LG
Comments: 11 pages, 5 figures
\\
 Vision-Language-Action (VLA) models have emerged as a powerful paradigm in
Embodied AI. However, the significant computational overhead of processing
redundant visual tokens remains a critical bottleneck for real-time robotic
deployment. While standard token pruning techniques can alleviate this, these
task-agnostic methods struggle to preserve task-critical visual information. To
address this challenge, simultaneously preserving both the holistic context and
fine-grained details for precise action, we propose Compressor-VLA, a novel
hybrid instruction-conditioned token compression framework designed for
efficient, task-oriented compression of visual information in VLA models. The
proposed Compressor-VLA framework consists of two token compression modules: a
Semantic Task Compressor (STC) that distills holistic, task-relevant context,
and a Spatial Refinement Compressor (SRC) that preserves fine-grained spatial
details. This compression is dynamically modulated by the natural language
instruction, allowing for the adaptive condensation of task-relevant visual
information. Experimentally, extensive evaluations demonstrate that
Compressor-VLA achieves a competitive success rate on the LIBERO benchmark
while reducing FLOPs by 59% and the visual token count by over 3x compared to
its baseline. The real-robot deployments on a dual-arm robot platform validate
the model's sim-to-real transferability and practical applicability. Moreover,
qualitative analyses reveal that our instruction guidance dynamically steers
the model's perceptual focus toward task-relevant objects, thereby validating
the effectiveness of our approach.
\\ ( https://arxiv.org/abs/2511.18950 ,  9214kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19080 (*cross-listing*)
Date: Mon, 24 Nov 2025 13:20:03 GMT   (2343kb)

Title: Towards Generalizable Deepfake Detection via Forgery-aware Audio-Visual
 Adaptation: A Variational Bayesian Approach
Authors: Fan Nie, Jiangqun Ni, Jian Zhang, Bin Zhang, Weizhe Zhang, Bin Li
Categories: cs.MM cs.CV
Comments: TIFS AQE
\\
 The widespread application of AIGC contents has brought not only
unprecedented opportunities, but also potential security concerns, e.g.,
audio-visual deepfakes. Therefore, it is of great importance to develop an
effective and generalizable method for multi-modal deepfake detection.
Typically, the audio-visual correlation learning could expose subtle
cross-modal inconsistencies, e.g., audio-visual misalignment, which serve as
crucial clues in deepfake detection. In this paper, we reformulate the
correlation learning with variational Bayesian estimation, where audio-visual
correlation is approximated as a Gaussian distributed latent variable, and thus
develop a novel framework for deepfake detection, i.e., Forgery-aware
Audio-Visual Adaptation with Variational Bayes (FoVB). Specifically, given the
prior knowledge of pre-trained backbones, we adopt two core designs to estimate
audio-visual correlations effectively. First, we exploit various difference
convolutions and a high-pass filter to discern local and global forgery traces
from both modalities. Second, with the extracted forgery-aware features, we
estimate the latent Gaussian variable of audio-visual correlation via
variational Bayes. Then, we factorize the variable into modality-specific and
correlation-specific ones with orthogonality constraint, allowing them to
better learn intra-modal and cross-modal forgery traces with less entanglement.
Extensive experiments demonstrate that our FoVB outperforms other
state-of-the-art methods in various benchmarks.
\\ ( https://arxiv.org/abs/2511.19080 ,  2343kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19248 (*cross-listing*)
Date: Mon, 24 Nov 2025 16:02:01 GMT   (2164kb)

Title: FedPoisonTTP: A Threat Model and Poisoning Attack for Federated
 Test-Time Personalization
Authors: Md Akil Raihan Iftee, Syed Md. Ahnaf Hasan, Amin Ahsan Ali, AKM
 Mahbubur Rahman, Sajib Mistry, Aneesh Krishna
Categories: cs.CR cs.CV
Comments: 13 pages, 3 figures, 2 tables
\\
 Test-time personalization in federated learning enables models at clients to
adjust online to local domain shifts, enhancing robustness and personalization
in deployment. Yet, existing federated learning work largely overlooks the
security risks that arise when local adaptation occurs at test time.
Heterogeneous domain arrivals, diverse adaptation algorithms, and limited
cross-client visibility create vulnerabilities where compromised participants
can craft poisoned inputs and submit adversarial updates that undermine both
global and per-client performance. To address this threat, we introduce
FedPoisonTTP, a realistic grey-box attack framework that explores test-time
data poisoning in the federated adaptation setting. FedPoisonTTP distills a
surrogate model from adversarial queries, synthesizes in-distribution poisons
using feature-consistency, and optimizes attack objectives to generate
high-entropy or class-confident poisons that evade common adaptation filters.
These poisons are injected during local adaptation and spread through
collaborative updates, leading to broad degradation. Extensive experiments on
corrupted vision benchmarks show that compromised participants can
substantially diminish overall test-time performance.
\\ ( https://arxiv.org/abs/2511.19248 ,  2164kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17505 (*cross-listing*)
Date: Thu, 2 Oct 2025 14:34:59 GMT   (1991kb)

Title: Causal Intervention Sequence Analysis for Fault Tracking in Radio Access
 Networks
Authors: Chenhua Shi, Joji Philip, Subhadip Bandyopadhyay, Jayanta Choudhury
Categories: cs.NI cs.LG
Comments: 6 pages, 7 figures, 1 table, accepted by IEEE FMLDS 2025
\\
 To keep modern Radio Access Networks (RAN) running smoothly, operators need
to spot the real-world triggers behind Service-Level Agreement (SLA) breaches
well before customers feel them. We introduce an AI/ML pipeline that does two
things most tools miss: (1) finds the likely root-cause indicators and (2)
reveals the exact order in which those events unfold. We start by labeling
network data: records linked to past SLA breaches are marked `abnormal', and
everything else `normal'. Our model then learns the causal chain that turns
normal behavior into a fault. In Monte Carlo tests the approach pinpoints the
correct trigger sequence with high precision and scales to millions of data
points without loss of speed. These results show that high-resolution, causally
ordered insights can move fault management from reactive troubleshooting to
proactive prevention.
\\ ( https://arxiv.org/abs/2511.17505 ,  1991kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17523 (*cross-listing*)
Date: Wed, 22 Oct 2025 00:36:51 GMT   (223kb)

Title: DyPBP: Dynamic Peer Beneficialness Prediction for Cryptocurrency P2P
 Networking
Authors: Nazmus Sakib, Simeon Wuthier, Amanul Islam, Xiaobo Zhou, Jinoh Kim,
 Ikkyun Kim, Sang-Yoon Chang
Categories: cs.NI cs.LG
\\
 Distributed peer-to-peer (P2P) networking delivers the new blocks and
transactions and is critical for the cryptocurrency blockchain system
operations. Having poor P2P connectivity reduces the financial rewards from the
mining consensus protocol. Previous research defines beneficalness of each
Bitcoin peer connection and estimates the beneficialness based on the
observations of the blocks and transactions delivery, which are after they are
delivered. However, due to the infrequent block arrivals and the sporadic and
unstable peer connections, the peers do not stay connected long enough to have
the beneficialness score to converge to its expected beneficialness. We design
and build Dynamic Peer Beneficialness Prediction (DyPBP) which predicts a
peer's beneficialness by using networking behavior observations beyond just the
block and transaction arrivals. DyPBP advances the previous research by
estimating the beneficialness of a peer connection before it delivers new
blocks and transactions. To achieve such goal, DyPBP introduces a new feature
for remembrance to address the dynamic connectivity issue, as Bitcoin's peers
using distributed networking often disconnect and re-connect. We implement
DyPBP on an active Bitcoin node connected to the Mainnet and use machine
learning for the beneficialness prediction. Our experimental results validate
and evaluate the effectiveness of DyPBP; for example, the error performance
improves by 2 to 13 orders of magnitude depending on the machine-learning model
selection. DyPBP's use of the remembrance feature also informs our model
selection. DyPBP enables the P2P connection's beneficialness estimation from
the connection start before a new block arrives.
\\ ( https://arxiv.org/abs/2511.17523 ,  223kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17531 (*cross-listing*)
Date: Wed, 29 Oct 2025 15:46:21 GMT   (2003kb)

Title: Q-Learning-Based Time-Critical Data Aggregation Scheduling in IoT
Authors: Van-Vi Vo, Tien-Dung Nguyen, Duc-Tai Le, Hyunseung Choo
Categories: cs.NI cs.LG
Comments: 7 pages, 6 figures
\\
 Time-critical data aggregation in Internet of Things (IoT) networks demands
efficient, collision-free scheduling to minimize latency for applications like
smart cities and industrial automation. Traditional heuristic methods, with
two-phase tree construction and scheduling, often suffer from high
computational overhead and suboptimal delays due to their static nature. To
address this, we propose a novel Q-learning framework that unifies aggregation
tree construction and scheduling, modeling the process as a Markov Decision
Process (MDP) with hashed states for scalability. By leveraging a reward
function that promotes large, interference-free batch transmissions, our
approach dynamically learns optimal scheduling policies. Simulations on static
networks with up to 300 nodes demonstrate up to 10.87% lower latency compared
to a state-of-the-art heuristic algorithm, highlighting its robustness for
delay-sensitive IoT applications. This framework enables timely insights in IoT
environments, paving the way for scalable, low-latency data aggregation.
\\ ( https://arxiv.org/abs/2511.17531 ,  2003kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17600 (*cross-listing*)
Date: Tue, 18 Nov 2025 03:05:30 GMT   (12134kb)

Title: SALPA: Spaceborne LiDAR Point Adjustment for Enhanced GEDI Footprint
 Geolocation
Authors: Narumasa Tsutsumida, Rei Mitsuhashi, Yoshito Sawada, and Akira Kato
Categories: eess.IV cs.LG
Comments: 21 pages, 2 figures
\\
 Spaceborne Light Detection and Ranging (LiDAR) systems, such as NASA's Global
Ecosystem Dynamics Investigation (GEDI), provide forest structure for global
carbon assessments. However, geolocation uncertainties (typically 5-15 m)
propagate systematically through derived products, undermining forest profile
estimates, including carbon stock assessments. Existing correction methods face
critical limitations: waveform simulation approaches achieve meter-level
accuracy but require high-resolution LiDAR data unavailable in most regions,
while terrain-based methods employ deterministic grid searches that may
overlook optimal solutions in continuous solution spaces. We present SALPA
(Spaceborne LiDAR Point Adjustment), a multi-algorithm optimization framework
integrating three optimization paradigms with five distance metrics. Operating
exclusively with globally available digital elevation models and geoid data,
SALPA explores continuous solution spaces through gradient-based, evolutionary,
and swarm intelligence approaches. Validation across contrasting sites:
topographically complex Nikko, Japan, and flat Landes, France, demonstrates
15-16% improvements over original GEDI positions and 0.5-2% improvements over
the state-of-the-art GeoGEDI algorithm. L-BFGS-B with Area-based metrics
achieves optimal accuracy-efficiency trade-offs, while population-based
algorithms (genetic algorithms, particle swarm optimization) excel in complex
terrain. The platform-agnostic framework facilitates straightforward adaptation
to emerging spaceborne LiDAR missions, providing a generalizable foundation for
universal geolocation correction essential for reliable global forest
monitoring and climate policy decisions.
\\ ( https://arxiv.org/abs/2511.17600 ,  12134kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17627 (*cross-listing*)
Date: Tue, 18 Nov 2025 23:38:29 GMT   (2099kb)

Title: An Ecologically-Informed Deep Learning Framework for Interpretable and
 Validatable Habitat Mapping
Authors: Iv\'an Felipe Benavides-Mart\'inez, Cristiam Victoriano
 Portilla-Cabrera, Katherine E. Mills, Claire Enterline, Jos\'e
 Garc\'es-Vargas, Andrew J. Allyn, Auroop R Ganguly
Categories: q-bio.PE cs.LG
\\
 Benthic habitat is challenging due to the environmental complexity of the
seafloor, technological limitations, and elevated operational costs, especially
in under-explored regions. This generates knowledge gaps for the sustainable
management of hydrobiological resources and their nexus with society. We
developed ECOSAIC (Ecological Compression via Orthogonal Specialized
Autoencoders for Interpretable Classification), an Artificial Intelligence
framework for automatic classification of benthic habitats through
interpretable latent representations using a customizable autoencoder. ECOSAIC
compresses n-dimensional feature space by optimizing specialization and
orthogonality between domain-informed features. We employed two domain-informed
categories: biogeochemical and hydrogeomorphological, that together integrate
biological, physicochemical, hydrological and geomorphological, features, whose
constraints on habitats have been recognized in ecology for a century. We
applied the model to the Colombian Pacific Ocean and the results revealed 16
benthic habitats, expanding from mangroves to deep rocky areas up to 1000 m
depth. The candidate habitats exhibited a strong correspondence between their
environmental constraints, represented in latent space, and their expected
species composition. This correspondence reflected meaningful ecological
associations rather than purely statistical correlations, where the habitat's
environmental offerings align semantically with the species' requirements. This
approach could improve the management and conservation of benthic habitats,
facilitating the development of functional maps that support marine planning,
biodiversity conservation and fish stock assessment. We also hope it provides
new insights into how ecological principles can inform AI frameworks,
particularly given the substantial data limitations that characterize
ecological research.
\\ ( https://arxiv.org/abs/2511.17627 ,  2099kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17656 (*cross-listing*)
Date: Thu, 20 Nov 2025 17:42:49 GMT   (1691kb)

Title: Multi-Agent Coordination in Autonomous Vehicle Routing: A
 Simulation-Based Study of Communication, Memory, and Routing Loops
Authors: KM Khalid Saifullah, Daniel Palmer
Categories: cs.MA cs.LG cs.RO
\\
 Multi-agent coordination is critical for next-generation autonomous vehicle
(AV) systems, yet naive implementations of communication-based rerouting can
lead to catastrophic performance degradation. This study investigates a
fundamental problem in decentralized multi-agent navigation: routing loops,
where vehicles without persistent obstacle memory become trapped in cycles of
inefficient path recalculation. Through systematic simulation experiments
involving 72 unique configurations across varying vehicle densities (15, 35, 55
vehicles) and obstacle frequencies (6, 20 obstacles), we demonstrate that
memory-less reactive rerouting increases average travel time by up to 682%
compared to baseline conditions. To address this, we introduce Object Memory
Management (OMM), a lightweight mechanism enabling agents to retain and share
knowledge of previously encountered obstacles. OMM operates by maintaining a
distributed blacklist of blocked nodes, which each agent consults during
Dijkstra-based path recalculation, effectively preventing redundant routing
attempts. Our results show that OMM-enabled coordination reduces average travel
time by 75.7% and wait time by 88% compared to memory-less systems, while
requiring only 1.67 route recalculations per vehicle versus 9.83 in memory-less
scenarios. This work provides empirical evidence that persistent, shared memory
is not merely beneficial but essential for robust multi-agent coordination in
dynamic environments. The findings have implications beyond autonomous
vehicles, informing the design of decentralized systems in robotics, network
routing, and distributed AI. We provide a comprehensive experimental analysis,
including detailed scenario breakdowns, scalability assessments, and visual
documentation of the routing loop phenomenon, demonstrating OMM's critical role
in preventing detrimental feedback cycles in cooperative multi-agent systems.
\\ ( https://arxiv.org/abs/2511.17656 ,  1691kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17698 (*cross-listing*)
Date: Fri, 21 Nov 2025 18:36:25 GMT   (1217kb)

Title: Quantum Fourier Transform Based Kernel for Solar Irrandiance Forecasting
Authors: Nawfel Mechiche-Alami, Eduardo Rodriguez, Jose M. Cardemil, Enrique
 Lopez Droguett
Categories: stat.ML cs.LG
Comments: 33 pages, 13 figures
\\
 This study proposes a Quantum Fourier Transform (QFT)-enhanced quantum kernel
for short-term time-series forecasting. Each signal is windowed,
amplitude-encoded, transformed by a QFT, then passed through a protective
rotation layer to avoid the QFT/QFT adjoint cancellation; the resulting kernel
is used in kernel ridge regression (KRR). Exogenous predictors are incorporated
by convexly fusing feature-specific kernels. On multi-station solar irradiance
data across Koppen climate classes, the proposed kernel consistently improves
median R2 and nRMSE over reference classical RBF and polynomials kernels, while
also reducing bias (nMBE); complementary MAE/ERMAX analyses indicate tighter
average errors with remaining headroom under sharp transients. For both quantum
and classical models, the only tuned quantities are the feature-mixing weights
and the KRR ridge alpha; classical hyperparameters (gamma, r, d) are fixed,
with the same validation set size for all models. Experiments are conducted on
a noiseless simulator (5 qubits; window length L=32). Limitations and ablations
are discussed, and paths toward NISQ execution are outlined.
\\ ( https://arxiv.org/abs/2511.17698 ,  1217kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17721 (*cross-listing*)
Date: Fri, 21 Nov 2025 19:18:19 GMT   (929kb)

Title: Prequential posteriors
Authors: Shreya Sinha-Roy, Richard G. Everitt, Christian P. Robert and
 Ritabrata Dutta
Categories: stat.ML cs.LG
\\
 Data assimilation is a fundamental task in updating forecasting models upon
observing new data, with applications ranging from weather prediction to online
reinforcement learning. Deep generative forecasting models (DGFMs) have shown
excellent performance in these areas, but assimilating data into such models is
challenging due to their intractable likelihood functions. This limitation
restricts the use of standard Bayesian data assimilation methodologies for
DGFMs. To overcome this, we introduce prequential posteriors, based upon a
predictive-sequential (prequential) loss function; an approach naturally suited
for temporally dependent data which is the focus of forecasting tasks. Since
the true data-generating process often lies outside the assumed model class, we
adopt an alternative notion of consistency and prove that, under mild
conditions, both the prequential loss minimizer and the prequential posterior
concentrate around parameters with optimal predictive performance. For scalable
inference, we employ easily parallelizable wastefree sequential Monte Carlo
(SMC) samplers with preconditioned gradient-based kernels, enabling efficient
exploration of high-dimensional parameter spaces such as those in DGFMs. We
validate our method on both a synthetic multi-dimensional time series and a
real-world meteorological dataset; highlighting its practical utility for data
assimilation for complex dynamical systems.
\\ ( https://arxiv.org/abs/2511.17721 ,  929kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17760 (*cross-listing*)
Date: Fri, 21 Nov 2025 20:17:46 GMT   (11294kb)

Title: When Active Learning Fails, Uncalibrated Out of Distribution Uncertainty
 Quantification Might Be the Problem
Authors: Ashley S. Dale, Kangming Li, Brian DeCost, Hao Wan, Yuchen Han, Yao
 Fehlis, Jason Hattrick-Simpers
Categories: cond-mat.mtrl-sci cs.LG
\\
 Efficiently and meaningfully estimating prediction uncertainty is important
for exploration in active learning campaigns in materials discovery, where
samples with high uncertainty are interpreted as containing information missing
from the model. In this work, the effect of different uncertainty estimation
and calibration methods are evaluated for active learning when using ensembles
of ALIGNN, eXtreme Gradient Boost, Random Forest, and Neural Network model
architectures. We compare uncertainty estimates from ALIGNN deep ensembles to
loss landscape uncertainty estimates obtained for solubility, bandgap, and
formation energy prediction tasks. We then evaluate how the quality of the
uncertainty estimate impacts an active learning campaign that seeks model
generalization to out-of-distribution data. Uncertainty calibration methods
were found to variably generalize from in-domain data to out-of-domain data.
Furthermore, calibrated uncertainties were generally unsuccessful in reducing
the amount of data required by a model to improve during an active learning
campaign on out-of-distribution data when compared to random sampling and
uncalibrated uncertainties. The impact of poor-quality uncertainty persists for
random forest and eXtreme Gradient Boosting models trained on the same data for
the same tasks, indicating that this is at least partially intrinsic to the
data and not due to model capacity alone. Analysis of the target,
in-distribution uncertainty, out-of-distribution uncertainty, and training
residual distributions suggest that future work focus on understanding
empirical uncertainties in the feature input space for cases where ensemble
prediction variances do not accurately capture the missing information required
for the model to generalize.
\\ ( https://arxiv.org/abs/2511.17760 ,  11294kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17765 (*cross-listing*)
Date: Fri, 21 Nov 2025 20:29:03 GMT   (18487kb)

Title: LEARN: Learning End-to-End Aerial Resource-Constrained Multi-Robot
 Navigation
Authors: Darren Chiu, Zhehui Huang, Ruohai Ge, and Gaurav S. Sukhatme
Categories: cs.RO cs.LG cs.MA
Comments: 20 pages, 15 figures
\\
 Nano-UAV teams offer great agility yet face severe navigation challenges due
to constrained onboard sensing, communication, and computation. Existing
approaches rely on high-resolution vision or compute-intensive planners,
rendering them infeasible for these platforms. We introduce LEARN, a
lightweight, two-stage safety-guided reinforcement learning (RL) framework for
multi-UAV navigation in cluttered spaces. Our system combines low-resolution
Time-of-Flight (ToF) sensors and a simple motion planner with a compact,
attention-based RL policy. In simulation, LEARN outperforms two
state-of-the-art planners by $10\%$ while using substantially fewer resources.
We demonstrate LEARN's viability on six Crazyflie quadrotors, achieving fully
onboard flight in diverse indoor and outdoor environments at speeds up to $2.0
m/s$ and traversing $0.2 m$ gaps.
\\ ( https://arxiv.org/abs/2511.17765 ,  18487kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17772 (*cross-listing*)
Date: Fri, 21 Nov 2025 20:38:47 GMT   (6855kb)

Title: Weighted Birkhoff Averages Accelerate Data-Driven Methods
Authors: Maria Bou-Sakr-El-Tayar, Jason J. Bramburger, and Matthew J. Colbrook
Categories: math.DS cs.LG nlin.CD
\\
 Many data-driven algorithms in dynamical systems rely on ergodic averages
that converge painfully slowly. One simple idea changes this: taper the ends.
Weighted Birkhoff averages can converge much faster (sometimes
superpolynomially, even exponentially) and can be incorporated seamlessly into
existing methods. We demonstrate this with five weighted algorithms: weighted
Dynamic Mode Decomposition (wtDMD), weighted Extended DMD (wtEDMD), weighted
Sparse Identification of Nonlinear Dynamics (wtSINDy), weighted spectral
measure estimation, and weighted diffusion forecasting. Across examples ranging
from fluid flows to El Ni\~no data, the message is clear: weighting costs
nothing, is easy to implement, and often delivers markedly better results from
the same data.
\\ ( https://arxiv.org/abs/2511.17772 ,  6855kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17783 (*cross-listing*)
Date: Fri, 21 Nov 2025 21:04:15 GMT   (57kb)

Title: Variational Estimators for Node Popularity Models
Authors: Jony Karki, Dongzhou Huang, Yunpeng Zhao
Categories: stat.ML cs.LG
MSC-class: 62F12
\\
 Node popularity is recognized as a key factor in modeling real-world
networks, capturing heterogeneity in connectivity across communities. This
concept is equally important in bipartite networks, where nodes in different
partitions may exhibit varying popularity patterns, motivating models such as
the Two-Way Node Popularity Model (TNPM). Existing methods, such as the
Two-Stage Divided Cosine (TSDC) algorithm, provide a scalable estimation
approach but may have limitations in terms of accuracy or applicability across
different types of networks. In this paper, we develop a computationally
efficient and theoretically justified variational expectation-maximization
(VEM) framework for the TNPM. We establish label consistency for the estimated
community assignments produced by the proposed variational estimator in
bipartite networks. Through extensive simulation studies, we show that our
method achieves superior estimation accuracy across a range of bipartite as
well as undirected networks compared to existing algorithms. Finally, we
evaluate our method on real-world bipartite and undirected networks, further
demonstrating its practical effectiveness and robustness.
\\ ( https://arxiv.org/abs/2511.17783 ,  57kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17825 (*cross-listing*)
Date: Fri, 21 Nov 2025 22:38:33 GMT   (2900kb)

Title: Analog Physical Systems Can Exhibit Double Descent
Authors: Sam Dillavou, Jason W Rocks, Jacob F Wycoff, Andrea J Liu, and Douglas
 J Durian
Categories: cond-mat.dis-nn cs.LG
Comments: 11 pages 7 figures
\\
 An important component of the success of large AI models is double descent,
in which networks avoid overfitting as they grow relative to the amount of
training data, instead improving their performance on unseen data. Here we
demonstrate double descent in a decentralized analog network of self-adjusting
resistive elements. This system trains itself and performs tasks without a
digital processor, offering potential gains in energy efficiency and speed --
but must endure component non-idealities. We find that standard training fails
to yield double descent, but a modified protocol that accommodates this
inherent imperfection succeeds. Our findings show that analog physical systems,
if appropriately trained, can exhibit behaviors underlying the success of
digital AI. Further, they suggest that biological systems might similarly
benefit from over-parameterization.
\\ ( https://arxiv.org/abs/2511.17825 ,  2900kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17850 (*cross-listing*)
Date: Sat, 22 Nov 2025 00:32:44 GMT   (3778kb)

Title: Efficient Dynamic and Momentum Aperture Optimization for Lattice Design
 Using Multipoint Bayesian Algorithm Execution
Authors: Z. Zhang, I. Agapov, S. Gasiorowski, T. Hellert, W. Neiswanger, X.
 Huang, D. Ratner
Categories: physics.acc-ph cs.LG
Comments: 10 pages, 8 figures
\\
 We demonstrate that multipoint Bayesian algorithm execution can overcome
fundamental computational challenges in storage ring design optimization.
Dynamic (DA) and momentum (MA) optimization is a multipoint, multiobjective
design task for storage rings, ultimately informing the flux of x-ray sources
and luminosity of colliders. Current state-of-art black-box optimization
methods require extensive particle-tracking simulations for each trial
configuration; the high computational cost restricts the extent of the search
to $\sim 10^3$ configurations, and therefore limits the quality of the final
design. We remove this bottleneck using multipointBAX, which selects,
simulates, and models each trial configuration at the single particle level. We
demonstrate our approach on a novel design for a fourth-generation light
source, with neural-network powered multipointBAX achieving equivalent Pareto
front results using more than two orders of magnitude fewer tracking
computations compared to genetic algorithms. The significant reduction in cost
positions multipointBAX as a promising alternative to black-box optimization,
and we anticipate multipointBAX will be instrumental in the design of future
light sources, colliders, and large-scale scientific facilities.
\\ ( https://arxiv.org/abs/2511.17850 ,  3778kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17865 (*cross-listing*)
Date: Sat, 22 Nov 2025 01:22:53 GMT   (3984kb)

Title: Generative Model Predictive Control in Manufacturing Processes: A Review
Authors: Suk Ki Lee, Ronnie F. P. Stone, Max Gao, Wenlong Zhang, Zhenghui Sha,
 Hyunwoong Ko
Categories: eess.SY cs.LG cs.SY
Comments: 24 pages, 5 figures, Review article
\\
 Manufacturing processes are inherently dynamic and uncertain, with varying
parameters and nonlinear behaviors, making robust control essential for
maintaining quality and reliability. Traditional control methods often fail
under these conditions due to their reactive nature. Model Predictive Control
(MPC) has emerged as a more advanced framework, leveraging process models to
predict future states and optimize control actions. However, MPC relies on
simplified models that often fail to capture complex dynamics, and it struggles
with accurate state estimation and handling the propagation of uncertainty in
manufacturing environments. Machine learning (ML) has been introduced to
enhance MPC by modeling nonlinear dynamics and learning latent representations
that support predictive modeling, state estimation, and optimization. Yet
existing ML-driven MPC approaches remain deterministic and correlation-focused,
motivating the exploration of generative. Generative ML offers new
opportunities by learning data distributions, capturing hidden patterns, and
inherently managing uncertainty, thereby complementing MPC. This review
highlights five representative methods and examines how each has been
integrated into MPC components, including predictive modeling, state
estimation, and optimization. By synthesizing these cases, we outline the
common ways generative ML can systematically enhance MPC and provide a
framework for understanding its potential in diverse manufacturing processes.
We identify key research gaps, propose future directions, and use a
representative case to illustrate how generative ML-driven MPC can extend
broadly across manufacturing. Taken together, this review positions generative
ML not as an incremental add-on but as a transformative approach to reshape
predictive control for next-generation manufacturing systems.
\\ ( https://arxiv.org/abs/2511.17865 ,  3984kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17892 (*cross-listing*)
Date: Sat, 22 Nov 2025 02:47:27 GMT   (4869kb)

Title: Arbitrage-Free Bond and Yield Curve Forecasting with Neural Filters
 under HJM Constraints
Authors: Xiang Gao and Cody Hyndman
Categories: q-fin.MF cs.LG q-fin.CP stat.ML
Comments: 31 pages, 17 figures
MSC-class: 91G30 (Primary) 65C30, 60H30 (Secondary)
\\
 We develop an arbitrage-free deep learning framework for yield curve and bond
price forecasting based on the Heath-Jarrow-Morton (HJM) term-structure model
and a dynamic Nelson-Siegel parameterization of forward rates. Our approach
embeds a no-arbitrage drift restriction into a neural state-space architecture
by combining Kalman, extended Kalman, and particle filters with recurrent
neural networks (LSTM/CLSTM), and introduces an explicit arbitrage error
regularization (AER) term during training. The model is applied to U.S.
Treasury and corporate bond data, and its performance is evaluated for both
yield-space and price-space predictions at 1-day and 5-day horizons.
Empirically, arbitrage regularization leads to its strongest improvements at
short maturities, particularly in 5-day-ahead forecasts, increasing
market-consistency as measured by bid-ask hit rates and reducing
dollar-denominated prediction errors.
\\ ( https://arxiv.org/abs/2511.17892 ,  4869kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17931 (*cross-listing*)
Date: Sat, 22 Nov 2025 06:06:51 GMT   (3541kb)

Title: A Reinforcement Learning Framework for Resource Allocation in Uplink
 Carrier Aggregation in the Presence of Self Interference
Authors: Jaswanth Bodempudi, Batta Siva Sairam, Madepalli Haritha, Sandesh Rao
 Mattu, Ananthanarayanan Chockalingam
Categories: cs.IT cs.LG eess.SP math.IT
Comments: Accepted in IEEE Trans. on Machine Learning in Communications and
 Networking
\\
 Carrier aggregation (CA) is a technique that allows mobile networks to
combine multiple carriers to increase user data rate. On the uplink, for power
constrained users, this translates to the need for an efficient resource
allocation scheme, where each user distributes its available power among its
assigned uplink carriers. Choosing a good set of carriers and allocating
appropriate power on the carriers is important. If the carrier allocation on
the uplink is such that a harmonic of a user's uplink carrier falls on the
downlink frequency of that user, it leads to a self coupling-induced
sensitivity degradation of that user's downlink receiver. In this paper, we
model the uplink carrier aggregation problem as an optimal resource allocation
problem with the associated constraints of non-linearities induced self
interference (SI). This involves optimization over a discrete variable (which
carriers need to be turned on) and a continuous variable (what power needs to
be allocated on the selected carriers) in dynamic environments, a problem which
is hard to solve using traditional methods owing to the mixed nature of the
optimization variables and the additional need to consider the SI constraint.
We adopt a reinforcement learning (RL) framework involving a compound-action
actor-critic (CA2C) algorithm for the uplink carrier aggregation problem. We
propose a novel reward function that is critical for enabling the proposed CA2C
algorithm to efficiently handle SI. The CA2C algorithm along with the proposed
reward function learns to assign and activate suitable carriers in an online
fashion. Numerical results demonstrate that the proposed RL based scheme is
able to achieve higher sum throughputs compared to naive schemes. The results
also demonstrate that the proposed reward function allows the CA2C algorithm to
adapt the optimization both in the presence and absence of SI.
\\ ( https://arxiv.org/abs/2511.17931 ,  3541kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17954 (*cross-listing*)
Date: Sat, 22 Nov 2025 07:39:34 GMT   (12845kb)

Title: A multi-view contrastive learning framework for spatial embeddings in
 risk modelling
Authors: Freek Holvoet, Christopher Blier-Wong, Katrien Antonio
Categories: q-fin.RM cs.LG
\\
 Incorporating spatial information, particularly those influenced by climate,
weather, and demographic factors, is crucial for improving underwriting
precision and enhancing risk management in insurance. However, spatial data are
often unstructured, high-dimensional, and difficult to integrate into
predictive models. Embedding methods are needed to convert spatial data into
meaningful representations for modelling tasks. We propose a novel multi-view
contrastive learning framework for generating spatial embeddings that combine
information from multiple spatial data sources. To train the model, we
construct a spatial dataset that merges satellite imagery and OpenStreetMap
features across Europe. The framework aligns these spatial views with
coordinate-based encodings, producing low-dimensional embeddings that capture
both spatial structure and contextual similarity. Once trained, the model
generates embeddings directly from latitude-longitude pairs, enabling any
dataset with coordinates to be enriched with meaningful spatial features
without requiring access to the original spatial inputs. In a case study on
French real estate prices, we compare models trained on raw coordinates against
those using our spatial embeddings as inputs. The embeddings consistently
improve predictive accuracy across generalised linear, additive, and boosting
models, while providing interpretable spatial effects and demonstrating
transferability to unseen regions.
\\ ( https://arxiv.org/abs/2511.17954 ,  12845kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17977 (*cross-listing*)
Date: Sat, 22 Nov 2025 08:39:52 GMT   (2919kb)

Title: Synthesizing Precise Protocol Specs from Natural Language for Effective
 Test Generation
Authors: Kuangxiangzi Liu, Dhiman Chakraborty, Alexander Liggesmeyer, Andreas
 Zeller
Categories: cs.SE cs.LG cs.NI
MSC-class: 68N30
ACM-class: D.2.5; D.2.1; F.4.2; C.2.2
\\
 Safety- and security-critical systems have to be thoroughly tested against
their specifications. The state of practice is to have _natural language_
specifications, from which test cases are derived manually - a process that is
slow, error-prone, and difficult to scale. _Formal_ specifications, on the
other hand, are well-suited for automated test generation, but are tedious to
write and maintain. In this work, we propose a two-stage pipeline that uses
large language models (LLMs) to bridge the gap: First, we extract _protocol
elements_ from natural-language specifications; second, leveraging a protocol
implementation, we synthesize and refine a formal _protocol specification_ from
these elements, which we can then use to massively test further
implementations.
 We see this two-stage approach to be superior to end-to-end LLM-based test
generation, as 1. it produces an _inspectable specification_ that preserves
traceability to the original text; 2. the generation of actual test cases _no
longer requires an LLM_; 3. the resulting formal specs are _human-readable_,
and can be reviewed, version-controlled, and incrementally refined; and 4. over
time, we can build a _corpus_ of natural-language-to-formal-specification
mappings that can be used to further train and refine LLMs for more automatic
translations.
 Our prototype, AUTOSPEC, successfully demonstrated the feasibility of our
approach on five widely used _internet protocols_ (SMTP, POP3, IMAP, FTP, and
ManageSieve) by applying its methods on their _RFC specifications_ written in
natural-language, and the recent _I/O grammar_ formalism for protocol
specification and fuzzing. In its evaluation, AUTOSPEC recovers on average
92.8% of client and 80.2% of server message types, and achieves 81.5% message
acceptance across diverse, real-world systems.
\\ ( https://arxiv.org/abs/2511.17977 ,  2919kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18025 (*cross-listing*)
Date: Sat, 22 Nov 2025 11:28:59 GMT   (743kb)

Title: Correlated-Sequence Differential Privacy
Authors: Yifan Luo, Meng Zhang, Jin Xu, Junting Chen, Jianwei Huang
Categories: cs.CR cs.IT cs.LG math.IT
Comments: 11 pages, 5 figures. Published in 2025 34th International Conference
 on Computer Communications and Networks (ICCCN), IEEE, August 2025
ACM-class: K.6.5; K.4.1
Journal-ref: Proceedings of the 34th International Conference on Computer
 Communications and Networks (ICCCN 2025), IEEE, pp. 1-9, 2025
DOI: 10.1109/ICCCN65249.2025.11133721
\\
 Data streams collected from multiple sources are rarely independent. Values
evolve over time and influence one another across sequences. These correlations
improve prediction in healthcare, finance, and smart-city control yet violate
the record-independence assumption built into most Differential Privacy (DP)
mechanisms. To restore rigorous privacy guarantees without sacrificing utility,
we introduce Correlated-Sequence Differential Privacy (CSDP), a framework
specifically designed for preserving privacy in correlated sequential data.
CSDP addresses two linked challenges: quantifying the extra information an
attacker gains from joint temporal and cross-sequence links, and adding just
enough noise to hide that information while keeping the data useful. We model
multivariate streams as a Coupling Markov Chain, yielding the derived loose
leakage bound expressed with a few spectral terms and revealing a
counterintuitive result: stronger coupling can actually decrease worst-case
leakage by dispersing perturbations across sequences. Guided by these bounds,
we build the Freshness-Regulated Adaptive Noise (FRAN) mechanism--combining
data aging, correlation-aware sensitivity scaling, and Laplace noise--that runs
in linear time. Tests on two-sequence datasets show that CSDP improves the
privacy-utility trade-off by approximately 50% over existing correlated-DP
methods and by two orders of magnitude compared to the standard DP approach.
\\ ( https://arxiv.org/abs/2511.18025 ,  743kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18035 (*cross-listing*)
Date: Sat, 22 Nov 2025 12:23:27 GMT   (2833kb)

Title: On a Reinforcement Learning Methodology for Epidemic Control, with
 application to COVID-19
Authors: Giacomo Iannucci, Petros Barmpounakis, Alexandros Beskos, Nikolaos
 Demiris
Categories: stat.ME cs.LG stat.CO stat.ML
Comments: Submitted to Statistics and Computing. Approx. 26 pages, 10 figures
MSC-class: 62M10, 62P10, 90C40
\\
 This paper presents a real time, data driven decision support framework for
epidemic control. We combine a compartmental epidemic model with sequential
Bayesian inference and reinforcement learning (RL) controllers that adaptively
choose intervention levels to balance disease burden, such as intensive care
unit (ICU) load, against socio economic costs. We construct a context specific
cost function using empirical experiments and expert feedback. We study two RL
policies: an ICU threshold rule computed via Monte Carlo grid search, and a
policy based on a posterior averaged Q learning agent. We validate the
framework by fitting the epidemic model to publicly available ICU occupancy
data from the COVID 19 pandemic in England and then generating counterfactual
roll out scenarios under each RL controller, which allows us to compare the RL
policies to the historical government strategy. Over a 300 day period and for a
range of cost parameters, both controllers substantially reduce ICU burden
relative to the observed interventions, illustrating how Bayesian sequential
learning combined with RL can support the design of epidemic control policies.
\\ ( https://arxiv.org/abs/2511.18035 ,  2833kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18051 (*cross-listing*)
Date: Sat, 22 Nov 2025 13:07:56 GMT   (3923kb)

Title: Sparse Kalman Identification for Partially Observable Systems via
 Adaptive Bayesian Learning
Authors: Jilan Mei, Tengjie Zheng, Lin Cheng, Shengping Gong, Xu Huang
Categories: eess.SY cs.LG cs.SY
\\
 Sparse dynamics identification is an essential tool for discovering
interpretable physical models and enabling efficient control in engineering
systems. However, existing methods rely on batch learning with full historical
data, limiting their applicability to real-time scenarios involving sequential
and partially observable data. To overcome this limitation, this paper proposes
an online Sparse Kalman Identification (SKI) method by integrating the
Augmented Kalman Filter (AKF) and Automatic Relevance Determination (ARD). The
main contributions are: (1) a theoretically grounded Bayesian sparsification
scheme that is seamlessly integrated into the AKF framework and adapted to
sequentially collected data in online scenarios; (2) an update mechanism that
adapts the Kalman posterior to reflect the updated selection of the basis
functions that define the model structure; (3) an explicit gradient-descent
formulation that enhances computational efficiency. Consequently, the SKI
method achieves accurate model structure selection with millisecond-level
efficiency and higher identification accuracy, as demonstrated by extensive
simulations and real-world experiments (showing an 84.21\% improvement in
accuracy over the baseline AKF).
\\ ( https://arxiv.org/abs/2511.18051 ,  3923kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18060 (*cross-listing*)
Date: Sat, 22 Nov 2025 13:37:53 GMT   (125kb)

Title: An operator splitting analysis of Wasserstein--Fisher--Rao gradient
 flows
Authors: Francesca Romana Crucinio and Sahani Pathiraja
Categories: stat.ML cs.LG stat.ME
MSC-class: 65B99, 65C30, 62F15
\\
 Wasserstein-Fisher-Rao (WFR) gradient flows have been recently proposed as a
powerful sampling tool that combines the advantages of pure Wasserstein (W) and
pure Fisher-Rao (FR) gradient flows. Existing algorithmic developments
implicitly make use of operator splitting techniques to numerically approximate
the WFR partial differential equation, whereby the W flow is evaluated over a
given step size and then the FR flow (or vice versa). This works investigates
the impact of the order in which the W and FR operator are evaluated and aims
to provide a quantitative analysis. Somewhat surprisingly, we show that with a
judicious choice of step size and operator ordering, the split scheme can
converge to the target distribution faster than the exact WFR flow (in terms of
model time). We obtain variational formulae describing the evolution over one
time step of both sequential splitting schemes and investigate in which
settings the W-FR split should be preferred to the FR-W split. As a step
towards this goal we show that the WFR gradient flow preserves log-concavity
and obtain the first sharp decay bound for WFR.
\\ ( https://arxiv.org/abs/2511.18060 ,  125kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18098 (*cross-listing*)
Date: Sat, 22 Nov 2025 15:49:36 GMT   (1085kb)

Title: Towards Harnessing the Power of LLMs for ABAC Policy Mining
Authors: More Aayush Babasaheb (Indian Institute of Technology Kharagpur,
 India), Shamik Sural (Indian Institute of Technology Kharagpur, India)
Categories: cs.CR cs.LG
\\
 This paper presents an empirical investigation into the capabilities of Large
Language Models (LLMs) to perform automated Attribute-based Access Control
(ABAC) policy mining. While ABAC provides fine-grained, context-aware access
management, the increasing number and complexity of access policies can make
their formulation and evaluation rather challenging. To address the task of
synthesizing concise yet accurate policies, we evaluate the performance of some
of the state-of-the-art LLMs, specifically Google Gemini (Flash and Pro) and
OpenAI ChatGPT, as potential policy mining engines. An experimental framework
was developed in Python to generate randomized access data parameterized by
varying numbers of subjects, objects, and initial policy sets. The baseline
policy sets, which govern permission decisions between subjects and objects,
serve as the ground truth for comparison. Each LLM-generated policy was
evaluated against the baseline policy using standard performance metrics. The
results indicate that LLMs can effectively infer compact and valid ABAC
policies for small-scale scenarios. However, as the system size increases,
characterized by higher numbers of subjects and objects, LLM outputs exhibit
declining accuracy and precision, coupled with significant increase in the size
of policy generated, which is beyond the optimal size. These findings highlight
both the promise and limitations of current LLM architectures for scalable
policy mining in access control domains. Future work will explore hybrid
approaches that combine prompt optimization with classical rule mining
algorithms to improve scalability and interpretability in complex ABAC
environments.
\\ ( https://arxiv.org/abs/2511.18098 ,  1085kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18141 (*cross-listing*)
Date: Sat, 22 Nov 2025 17:57:39 GMT   (92kb)

Title: Conformal Prediction for Compositional Data
Authors: Lucas P. Amaral, Luben M. C. Cabezas, Thiago R. Ramos and Gustavo H.
 G. A. Pereira
Categories: stat.ML cs.LG
Comments: 18 pages, 4 figures
\\
 In this work, we propose a set of conformal prediction procedures tailored to
compositional responses, where outcomes are proportions that must be positive
and sum to one. Building on Dirichlet regression, we introduce a split
conformal approach based on quantile residuals and a highest-density region
strategy that combines a fast coordinate-floor approximation with an internal
grid refinement to restore sharpness. Both constructions are model-agnostic at
the conformal layer and guarantee finite-sample marginal coverage under
exchangeability, while respecting the geometry of the simplex. A comprehensive
Monte Carlo study spanning homoscedastic and heteroscedastic designs shows that
the quantile residual and grid-refined HDR methods achieve empirical coverage
close to the nominal 90\% level and produce substantially narrower regions than
the coordinate-floor approximation, which tends to be conservative. We further
demonstrate the methods on household budget shares from the BudgetItaly
dataset, using standardized socioeconomic and price covariates with a train,
calibration, and test split. In this application, the grid-refined HDR attains
coverage closest to the target with the smallest average widths, closely
followed by the quantile residual approach, while the simple triangular HDR
yields wider, less informative sets. Overall, the results indicate that
conformal prediction on the simplex can be both calibrated and efficient,
providing practical uncertainty quantification for compositional prediction
tasks.
\\ ( https://arxiv.org/abs/2511.18141 ,  92kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18153 (*cross-listing*)
Date: Sat, 22 Nov 2025 18:50:35 GMT   (11049kb)

Title: A Coordinated Dual-Arm Framework for Delicate Snap-Fit Assemblies
Authors: Shreyas Kumar, Barat S, Debojit Das, Yug Desai, Siddhi Jain, Rajesh
 Kumar, Harish J. Palanthandalam-Madapusi
Categories: cs.RO cs.LG
Comments: 10 pages, 9 figures
\\
 Delicate snap-fit assemblies, such as inserting a lens into an eye-wear frame
or during electronics assembly, demand timely engagement detection and rapid
force attenuation to prevent overshoot-induced component damage or assembly
failure. We address these challenges with two key contributions. First, we
introduce SnapNet, a lightweight neural network that detects snap-fit
engagement from joint-velocity transients in real-time, showing that reliable
detection can be achieved using proprioceptive signals without external
sensors. Second, we present a dynamical-systems-based dual-arm coordination
framework that integrates SnapNet driven detection with an event-triggered
impedance modulation, enabling accurate alignment and compliant insertion
during delicate snap-fit assemblies. Experiments across diverse geometries on a
heterogeneous bimanual platform demonstrate high detection accuracy (over 96%
recall) and up to a 30% reduction in peak impact forces compared to standard
impedance control.
\\ ( https://arxiv.org/abs/2511.18153 ,  11049kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18167 (*cross-listing*)
Date: Sat, 22 Nov 2025 19:43:23 GMT   (37kb)

Title: Sparse Polyak with optimal thresholding operators for high-dimensional
 M-estimation
Authors: Tianqi Qiao, Marie Maros
Categories: stat.ML cs.LG math.OC
\\
 We propose and analyze a variant of Sparse Polyak for high dimensional
M-estimation problems. Sparse Polyak proposes a novel adaptive step-size rule
tailored to suitably estimate the problem's curvature in the high-dimensional
setting, guaranteeing that the algorithm's performance does not deteriorate
when the ambient dimension increases. However, convergence guarantees can only
be obtained by sacrificing solution sparsity and statistical accuracy. In this
work, we introduce a variant of Sparse Polyak that retains its desirable
scaling properties with respect to the ambient dimension while obtaining
sparser and more accurate solutions.
\\ ( https://arxiv.org/abs/2511.18167 ,  37kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18199 (*cross-listing*)
Date: Sat, 22 Nov 2025 22:03:32 GMT   (337kb)

Title: Improving Forecasts of Suicide Attempts for Patients with Little Data
Authors: Genesis Hang, Annie Chen, Hope Neveux, Matthew K. Nock, Yaniv Yacoby
Categories: stat.ML cs.LG
Comments: Accepted at the TS4H Workshop at NeurIPS 2025
\\
 Ecological Momentary Assessment provides real-time data on suicidal thoughts
and behaviors, but predicting suicide attempts remains challenging due to their
rarity and patient heterogeneity. We show that single models fit to all
patients perform poorly, while individualized models improve performance but
still overfit to patients with limited data. To address this, we introduce
Latent Similarity Gaussian Processes (LSGPs) to capture patient heterogeneity,
enabling those with little data to leverage similar patients' trends.
Preliminary results show promise: even without kernel-design, we outperform all
but one baseline while offering a new understanding of patient similarity.
\\ ( https://arxiv.org/abs/2511.18199 ,  337kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18213 (*cross-listing*)
Date: Sat, 22 Nov 2025 23:04:45 GMT   (1791kb)

Title: Typing Reinvented: Towards Hands-Free Input via sEMG
Authors: Kunwoo Lee, Dhivya Sreedhar, Pushkar Saraf, Chaeeun Lee, Kateryna
 Shapovalenko
Categories: cs.HC cs.LG
\\
 We explore surface electromyography (sEMG) as a non-invasive input modality
for mapping muscle activity to keyboard inputs, targeting immersive typing in
next-generation human-computer interaction (HCI). This is especially relevant
for spatial computing and virtual reality (VR), where traditional keyboards are
impractical. Using attention-based architectures, we significantly outperform
the existing convolutional baselines, reducing online generic CER from 24.98%
-> 20.34% and offline personalized CER from 10.86% -> 10.10%, while remaining
fully causal. We further incorporate a lightweight decoding pipeline with
language-model-based correction, demonstrating the feasibility of accurate,
real-time muscle-driven text input for future wearable and spatial interfaces.
\\ ( https://arxiv.org/abs/2511.18213 ,  1791kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18323 (*cross-listing*)
Date: Sun, 23 Nov 2025 07:29:06 GMT   (334kb)

Title: Crash-Consistent Checkpointing for AI Training on macOS/APFS
Authors: Juha Jeon
Categories: cs.OS cs.LG
Comments: 18 pages, 6 figures. Independent mini-research report; not submitted
 to a conference or journal
\\
 Deep learning training relies on periodic checkpoints to recover from
failures, but unsafe checkpoint installation can leave corrupted files on disk.
This paper presents an experimental study of checkpoint installation protocols
and integrity validation for AI training on macOS/APFS. We implement three
write modes with increasing durability guarantees: unsafe (baseline, no fsync),
atomic_nodirsync (file-level durability via fsync()), and atomic_dirsync (file
+ directory durability). We design a format-agnostic integrity guard using
SHA-256 checksums with automatic rollback. Through controlled experiments
including crash injection (430 unsafe-mode trials) and corruption injection
(1,600 atomic-mode trials), we demonstrate that the integrity guard detects
99.8-100% of corruptions with zero false positives. Performance overhead is
56.5-108.4% for atomic_nodirsync and 84.2-570.6% for atomic_dirsync relative to
the unsafe baseline. Our findings quantify the reliability-performance
trade-offs and provide deployment guidance for production AI infrastructure.
\\ ( https://arxiv.org/abs/2511.18323 ,  334kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18325 (*cross-listing*)
Date: Sun, 23 Nov 2025 07:31:28 GMT   (757kb)

Title: Brain-MGF: Multimodal Graph Fusion Network for EEG-fMRI Brain
 Connectivity Analysis Under Psilocybin
Authors: Sin-Yee Yap, Fuad Noman, Junn Yong Loo, Devon Stoliker, Moein
 Khajehnejad, Rapha\"el C.-W. Phan, David L. Dowe, Adeel Razi, Chee-Ming Ting
Categories: q-bio.NC cs.LG
Comments: 5 pages
\\
 Psychedelics, such as psilocybin, reorganise large-scale brain connectivity,
yet how these changes are reflected across electrophysiological
(electroencephalogram, EEG) and haemodynamic (functional magnetic resonance
imaging, fMRI) networks remains unclear. We present Brain-MGF, a multimodal
graph fusion network for joint EEG-fMRI connectivity analysis. For each
modality, we construct graphs with partial-correlation edges and
Pearson-profile node features, and learn subject-level embeddings via graph
convolution. An adaptive softmax gate then fuses modalities with
sample-specific weights to capture context-dependent contributions. Using the
world's largest single-site psilocybin dataset, PsiConnect, Brain-MGF
distinguishes psilocybin from no-psilocybin conditions in meditation and rest.
Fusion improves over unimodal and non-adaptive variants, achieving 74.0%
accuracy and 76.5% F1 score on meditation, and 76.0% accuracy with 85.8%
ROC-AUC on rest. UMAP visualisations reveal clearer class separation for fused
embeddings. These results indicate that adaptive graph fusion effectively
integrates complementary EEG-fMRI information, providing an interpretable
framework for characterising psilocybin-induced alterations in large-scale
neural organisation.
\\ ( https://arxiv.org/abs/2511.18325 ,  757kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18421 (*cross-listing*)
Date: Sun, 23 Nov 2025 12:19:23 GMT   (1235kb)

Title: DHAuDS: A Dynamic and Heterogeneous Audio Benchmark for Test-Time
 Adaptation
Authors: Weichuang Shao, Iman Yi Liao, Tomas Henrique Bode Maul, and Tissa
 Chandesa
Categories: cs.SD cs.LG
\\
 Audio classifiers frequently face domain shift, when models trained on one
dataset lose accuracy on data recorded in acoustically different conditions.
Previous Test-Time Adaptation (TTA) research in speech and sound analysis often
evaluates models under fixed or mismatched noise settings, that fail to mimic
real-world variability. To overcome these limitations, this paper presents
DHAuDS (Dynamic and Heterogeneous Audio Domain Shift), a benchmark designed to
assess TTA approaches under more realistic and diverse acoustic shifts. DHAuDS
comprises four standardized benchmarks: UrbanSound8K-C, SpeechCommandsV2-C,
VocalSound-C, and ReefSet-C, each constructed with dynamic corruption severity
levels and heterogeneous noise types to simulate authentic audio degradation
scenarios. The framework defines 14 evaluation criteria for each benchmark (8
for UrbanSound8K-C), resulting in 50 unrepeated criteria (124 experiments) that
collectively enable fair, reproducible, and cross-domain comparison of TTA
algorithms. Through the inclusion of dynamic and mixed-domain noise settings,
DHAuDS offers a consistent and publicly reproducible testbed to support ongoing
studies in robust and adaptive audio modeling.
\\ ( https://arxiv.org/abs/2511.18421 ,  1235kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18464 (*cross-listing*)
Date: Sun, 23 Nov 2025 14:15:50 GMT   (934kb)

Title: Reliable Selection of Heterogeneous Treatment Effect Estimators
Authors: Jiayi Guo, Zijun Gao
Categories: stat.ML cs.LG
\\
 We study the problem of selecting the best heterogeneous treatment effect
(HTE) estimator from a collection of candidates in settings where the treatment
effect is fundamentally unobserved. We cast estimator selection as a multiple
testing problem and introduce a ground-truth-free procedure based on a
cross-fitted, exponentially weighted test statistic. A key component of our
method is a two-way sample splitting scheme that decouples nuisance estimation
from weight learning and ensures the stability required for valid inference.
Leveraging a stability-based central limit theorem, we establish asymptotic
familywise error rate control under mild regularity conditions. Empirically,
our procedure provides reliable error control while substantially reducing
false selections compared with commonly used methods across ACIC 2016, IHDP,
and Twins benchmarks, demonstrating that our method is feasible and powerful
even without ground-truth treatment effects.
\\ ( https://arxiv.org/abs/2511.18464 ,  934kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18530 (*cross-listing*)
Date: Sun, 23 Nov 2025 16:50:34 GMT   (5868kb)

Title: Transforming Conditional Density Estimation Into a Single Nonparametric
 Regression Task
Authors: Alexander G. Reisach, Olivier Collier, Alex Luedtke, Antoine Chambaz
Categories: stat.ML cs.LG
\\
 We propose a way of transforming the problem of conditional density
estimation into a single nonparametric regression task via the introduction of
auxiliary samples. This allows leveraging regression methods that work well in
high dimensions, such as neural networks and decision trees. Our main
theoretical result characterizes and establishes the convergence of our
estimator to the true conditional density in the data limit. We develop
condensit\'e, a method that implements this approach. We demonstrate the
benefit of the auxiliary samples on synthetic data and showcase that
condensit\'e can achieve good out-of-the-box results. We evaluate our method on
a large population survey dataset and on a satellite imaging dataset. In both
cases, we find that condensit\'e matches or outperforms the state of the art
and yields conditional densities in line with established findings in the
literature on each dataset. Our contribution opens up new possibilities for
regression-based conditional density estimation and the empirical results
indicate strong promise for applied research.
\\ ( https://arxiv.org/abs/2511.18530 ,  5868kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18554 (*cross-listing*)
Date: Sun, 23 Nov 2025 17:59:51 GMT   (2464kb)

Title: Online Smoothed Demand Management
Authors: Adam Lechowicz and Nicolas Christianson and Mohammad Hajiesmaili and
 Adam Wierman and Prashant Shenoy
Categories: cs.DS cs.LG cs.SY eess.SY
Comments: 69 pages, 12 figures
\\
 We introduce and study a class of online problems called online smoothed
demand management $(\texttt{OSDM})$, motivated by paradigm shifts in grid
integration and energy storage for large energy consumers such as data centers.
In $\texttt{OSDM}$, an operator makes two decisions at each time step: an
amount of energy to be purchased, and an amount of energy to be delivered
(i.e., used for computation). The difference between these decisions charges
(or discharges) the operator's energy storage (e.g., a battery). Two types of
demand arrive online: base demand, which must be covered at the current time,
and flexible demand, which can be satisfied at any time steps before a
demand-specific deadline $\Delta_t$. The operator's goal is to minimize a cost
(subject to the constraints above) that combines a cost of purchasing energy, a
cost for delivering energy (if applicable), and smoothness penalties on the
purchasing and delivery rates to discourage fluctuations and encourage ``grid
healthy'' decisions. $\texttt{OSDM}$ generalizes several problems in the online
algorithms literature while being the first to fully model applications of
interest. We propose a competitive algorithm called $\texttt{PAAD}$
(partitioned accounting \& aggregated decisions) and show it achieves the
optimal competitive ratio. To overcome the pessimism typical of worst-case
analysis, we also propose a novel learning framework that provides guarantees
on the worst-case competitive ratio (i.e., to provide robustness against
nonstationarity) while allowing end-to-end differentiable learning of the best
algorithm on historical instances of the problem. We evaluate our algorithms in
a case study of a grid-integrated data center with battery storage, showing
that $\texttt{PAAD}$ effectively solves the problem and end-to-end learning
achieves substantial performance improvements compared to $\texttt{PAAD}$.
\\ ( https://arxiv.org/abs/2511.18554 ,  2464kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18555 (*cross-listing*)
Date: Sun, 23 Nov 2025 18:04:15 GMT   (924kb)

Title: A joint optimization approach to identifying sparse dynamics using least
 squares kernel collocation
Authors: Alexander W. Hsu, Ike W. Griss Salas, Jacob M. Stevens-Haas, J. Nathan
 Kutz, Aleksandr Aravkin, Bamdad Hosseini
Categories: stat.ME cs.LG math.DS stat.ML
\\
 We develop an all-at-once modeling framework for learning systems of ordinary
differential equations (ODE) from scarce, partial, and noisy observations of
the states. The proposed methodology amounts to a combination of sparse
recovery strategies for the ODE over a function library combined with
techniques from reproducing kernel Hilbert space (RKHS) theory for estimating
the state and discretizing the ODE. Our numerical experiments reveal that the
proposed strategy leads to significant gains in terms of accuracy, sample
efficiency, and robustness to noise, both in terms of learning the equation and
estimating the unknown states. This work demonstrates capabilities well beyond
existing and widely used algorithms while extending the modeling flexibility of
other recent developments in equation discovery.
\\ ( https://arxiv.org/abs/2511.18555 ,  924kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18562 (*cross-listing*)
Date: Sun, 23 Nov 2025 18:16:31 GMT   (1736kb)

Title: Ensuring Calibration Robustness in Split Conformal Prediction Under
 Adversarial Attacks
Authors: Xunlei Qian, Yue Xing
Categories: stat.ML cs.LG
Comments: Submitted to AISTATS 2026
\\
 Conformal prediction (CP) provides distribution-free, finite-sample coverage
guarantees but critically relies on exchangeability, a condition often violated
under distribution shift. We study the robustness of split conformal prediction
under adversarial perturbations at test time, focusing on both coverage
validity and the resulting prediction set size. Our theoretical analysis
characterizes how the strength of adversarial perturbations during calibration
affects coverage guarantees under adversarial test conditions. We further
examine the impact of adversarial training at the model-training stage.
Extensive experiments support our theory: (i) Prediction coverage varies
monotonically with the calibration-time attack strength, enabling the use of
nonzero calibration-time attack to predictably control coverage under
adversarial tests; (ii) target coverage can hold over a range of test-time
attacks: with a suitable calibration attack, coverage stays within any chosen
tolerance band across a contiguous set of perturbation levels; and (iii)
adversarial training at the training stage produces tighter prediction sets
that retain high informativeness.
\\ ( https://arxiv.org/abs/2511.18562 ,  1736kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18583 (*cross-listing*)
Date: Sun, 23 Nov 2025 18:56:40 GMT   (1448kb)

Title: Differential privacy with dependent data
Authors: Valentin Roth and Marco Avella-Medina
Categories: stat.ML cs.LG math.ST stat.TH
\\
 Dependent data underlies many statistical studies in the social and health
sciences, which often involve sensitive or private information. Differential
privacy (DP) and in particular \textit{user-level} DP provide a natural
formalization of privacy requirements for processing dependent data where each
individual provides multiple observations to the dataset. However, dependence
introduced, e.g., through repeated measurements challenges the existing
statistical theory under DP-constraints. In \iid{} settings, noisy Winsorized
mean estimators have been shown to be minimax optimal for standard
(\textit{item-level}) and \textit{user-level} DP estimation of a mean $\mu \in
\R^d$. Yet, their behavior on potentially dependent observations has not
previously been studied. We fill this gap and show that Winsorized mean
estimators can also be used under dependence for bounded and unbounded data,
and can lead to asymptotic and finite sample guarantees that resemble their
\iid{} counterparts under a weak notion of dependence. For this, we formalize
dependence via log-Sobolev inequalities on the joint distribution of
observations. This enables us to adapt the stable histogram by Karwa and Vadhan
(2018) to a non-\iid{} setting, which we then use to estimate the private
projection intervals of the Winsorized estimator. The resulting guarantees for
our item-level mean estimator extend to \textit{user-level} mean estimation and
transfer to the local model via a randomized response histogram. Using the mean
estimators as building blocks, we provide extensions to random effects models,
longitudinal linear regression and nonparametric regression. Therefore, our
work constitutes a first step towards a systematic study of DP for dependent
data.
\\ ( https://arxiv.org/abs/2511.18583 ,  1448kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18590 (*cross-listing*)
Date: Sun, 23 Nov 2025 19:08:40 GMT   (916kb)

Title: From Simulations to Surveys: Domain Adaptation for Galaxy Observations
Authors: Kaley Brauer, Aditya Prasad Dash, Meet J. Vyas, Ahmed Salim, Stiven
 Briand Massala
Categories: astro-ph.GA cs.LG
Comments: 8 pages, 4 figures. Will be presented at NeurIPS 2025 ML4PS
\\
 Large photometric surveys will image billions of galaxies, but we currently
lack quick, reliable automated ways to infer their physical properties like
morphology, stellar mass, and star formation rates. Simulations provide galaxy
images with ground-truth physical labels, but domain shifts in PSF, noise,
backgrounds, selection, and label priors degrade transfer to real surveys. We
present a preliminary domain adaptation pipeline that trains on simulated TNG50
galaxies and evaluates on real SDSS galaxies with morphology labels
(elliptical/spiral/irregular). We train three backbones (CNN, $E(2)$-steerable
CNN, ResNet-18) with focal loss and effective-number class weighting, and a
feature-level domain loss $L_D$ built from GeomLoss (entropic Sinkhorn OT,
energy distance, Gaussian MMD, and related metrics). We show that a combination
of these losses with an OT-based "top_$k$ soft matching" loss that focuses
$L_D$ on the worst-matched source-target pairs can further enhance domain
alignment. With Euclidean distance, scheduled alignment weights, and top-$k$
matching, target accuracy (macro F1) rises from $\sim$46% ($\sim$30%) at no
adaptation to $\sim$87% ($\sim$62.6%), with a domain AUC near 0.5, indicating
strong latent-space mixing.
\\ ( https://arxiv.org/abs/2511.18590 ,  916kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18594 (*cross-listing*)
Date: Sun, 23 Nov 2025 19:27:29 GMT   (9284kb)

Title: Autoencoder for Position-Assisted Beam Prediction in mmWave ISAC Systems
Authors: Ahmad A. Aziz El-Banna and Octavia A. Dobre
Categories: eess.SP cs.LG
\\
 Integrated sensing and communication and millimeter wave (mmWave) have
emerged as pivotal technologies for 6G networks. However, the narrow nature of
mmWave beams requires precise alignments that typically necessitate large
training overhead. This overhead can be reduced by incorporating the position
information with beam adjustments. This letter proposes a lightweight
autorencoder (LAE) model that addresses the position-assisted beam prediction
problem while significantly reducing computational complexity compared to the
conventional baseline method, i.e., deep fully connected neural network. The
proposed LAE is designed as a three-layer undercomplete network to exploit its
dimensionality reduction capabilities and thereby mitigate the computational
requirements of the trained model. Simulation results show that the proposed
model achieves a similar beam prediction accuracy to the baseline with an 83%
complexity reduction.
\\ ( https://arxiv.org/abs/2511.18594 ,  9284kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18606 (*cross-listing*)
Date: Sun, 23 Nov 2025 20:15:28 GMT   (3812kb)

Title: How to Train Your Latent Control Barrier Function: Smooth Safety
 Filtering Under Hard-to-Model Constraints
Authors: Kensuke Nakamura, Arun L. Bishop, Steven Man, Aaron M. Johnson,
 Zachary Manchester, Andrea Bajcsy
Categories: cs.RO cs.LG
Comments: 3 figures, 10 tables, 22 pages
\\
 Latent safety filters extend Hamilton-Jacobi (HJ) reachability to operate on
latent state representations and dynamics learned directly from
high-dimensional observations, enabling safe visuomotor control under
hard-to-model constraints. However, existing methods implement
"least-restrictive" filtering that discretely switch between nominal and safety
policies, potentially undermining the task performance that makes modern
visuomotor policies valuable. While reachability value functions can, in
principle, be adapted to be control barrier functions (CBFs) for smooth
optimization-based filtering, we theoretically and empirically show that
current latent-space learning methods produce fundamentally incompatible value
functions. We identify two sources of incompatibility: First, in HJ
reachability, failures are encoded via a "margin function" in latent space,
whose sign indicates whether or not a latent is in the constraint set. However,
representing the margin function as a classifier yields saturated value
functions that exhibit discontinuous jumps. We prove that the value function's
Lipschitz constant scales linearly with the margin function's Lipschitz
constant, revealing that smooth CBFs require smooth margins. Second,
reinforcement learning (RL) approximations trained solely on safety policy data
yield inaccurate value estimates for nominal policy actions, precisely where
CBF filtering needs them. We propose the LatentCBF, which addresses both
challenges through gradient penalties that lead to smooth margin functions
without additional labeling, and a value-training procedure that mixes data
from both nominal and safety policy distributions. Experiments on simulated
benchmarks and hardware with a vision-based manipulation policy demonstrate
that LatentCBF enables smooth safety filtering while doubling the
task-completion rate over prior switching methods.
\\ ( https://arxiv.org/abs/2511.18606 ,  3812kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18661 (*cross-listing*)
Date: Mon, 24 Nov 2025 00:21:17 GMT   (1463kb)

Title: Fast Escape, Slow Convergence: Learning Dynamics of Phase Retrieval
 under Power-Law Data
Authors: Guillaume Braun and Bruno Loureiro and Ha Quang Minh and Masaaki
 Imaizumi
Categories: stat.ML cs.LG
\\
 Scaling laws describe how learning performance improves with data, compute,
or training time, and have become a central theme in modern deep learning. We
study this phenomenon in a canonical nonlinear model: phase retrieval with
anisotropic Gaussian inputs whose covariance spectrum follows a power law.
Unlike the isotropic case, where dynamics collapse to a two-dimensional system,
anisotropy yields a qualitatively new regime in which an infinite hierarchy of
coupled equations governs the evolution of the summary statistics. We develop a
tractable reduction that reveals a three-phase trajectory: (i) fast escape from
low alignment, (ii) slow convergence of the summary statistics, and (iii)
spectral-tail learning in low-variance directions. From this decomposition, we
derive explicit scaling laws for the mean-squared error, showing how spectral
decay dictates convergence times and error curves. Experiments confirm the
predicted phases and exponents. These results provide the first rigorous
characterization of scaling laws in nonlinear regression with anisotropic data,
highlighting how anisotropy reshapes learning dynamics.
\\ ( https://arxiv.org/abs/2511.18661 ,  1463kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18667 (*cross-listing*)
Date: Mon, 24 Nov 2025 00:43:54 GMT   (118kb)

Title: Equivariant Deep Equilibrium Models for Imaging Inverse Problems
Authors: Alexander Mehta, Ruangrawee Kitichotkul, Vivek K Goyal, Juli\'an
 Tachella
Categories: eess.IV cs.LG eess.SP
\\
 Equivariant imaging (EI) enables training signal reconstruction models
without requiring ground truth data by leveraging signal symmetries. Deep
equilibrium models (DEQs) are a powerful class of neural networks where the
output is a fixed point of a learned operator. However, training DEQs with
complex EI losses requires implicit differentiation through fixed-point
computations, whose implementation can be challenging. We show that
backpropagation can be implemented modularly, simplifying training. Experiments
demonstrate that DEQs trained with implicit differentiation outperform those
trained with Jacobian-free backpropagation and other baseline methods.
Additionally, we find evidence that EI-trained DEQs approximate the proximal
map of an invariant prior.
\\ ( https://arxiv.org/abs/2511.18667 ,  118kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18750 (*cross-listing*)
Date: Mon, 24 Nov 2025 04:23:26 GMT   (1023kb)

Title: On Instability of Minimax Optimal Optimism-Based Bandit Algorithms
Authors: Samya Praharaj, Koulik Khamaru
Categories: stat.ML cs.IT cs.LG math.IT math.ST stat.TH
\\
 Statistical inference from data generated by multi-armed bandit (MAB)
algorithms is challenging due to their adaptive, non-i.i.d. nature. A classical
manifestation is that sample averages of arm rewards under bandit sampling may
fail to satisfy a central limit theorem. Lai and Wei's stability condition
provides a sufficient, and essentially necessary criterion, for asymptotic
normality in bandit problems. While the celebrated Upper Confidence Bound (UCB)
algorithm satisfies this stability condition, it is not minimax optimal,
raising the question of whether minimax optimality and statistical stability
can be achieved simultaneously. In this paper, we analyze the stability
properties of a broad class of bandit algorithms that are based on the optimism
principle. We establish general structural conditions under which such
algorithms violate the Lai-Wei stability criterion. As a consequence, we show
that widely used minimax-optimal UCB-style algorithms, including MOSS,
Anytime-MOSS, Vanilla-MOSS, ADA-UCB, OC-UCB, KL-MOSS, KL-UCB++, KL-UCB-SWITCH,
and Anytime KL-UCB-SWITCH, are unstable. We further complement our theoretical
results with numerical simulations demonstrating that, in all these cases, the
sample means fail to exhibit asymptotic normality.
 Overall, our findings suggest a fundamental tension between stability and
minimax optimal regret, raising the question of whether it is possible to
design bandit algorithms that achieve both. Understanding whether such
simultaneously stable and minimax optimal strategies exist remains an important
open direction.
\\ ( https://arxiv.org/abs/2511.18750 ,  1023kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18813 (*cross-listing*)
Date: Mon, 24 Nov 2025 06:39:45 GMT   (844kb)

Title: Uncertainty of Network Topology with Applications to Out-of-Distribution
 Detection
Authors: Sing-Yuan Yeh, Chun-Hao Yang
Categories: stat.ML cs.LG stat.ME
Comments: Submitted for journal publication
MSC-class: 62C10, 68T37, 62G10
\\
 Persistent homology (PH) is a crucial concept in computational topology,
providing a multiscale topological description of a space. It is particularly
significant in topological data analysis, which aims to make statistical
inference from a topological perspective. In this work, we introduce a new
topological summary for Bayesian neural networks, termed the predictive
topological uncertainty (pTU). The proposed pTU measures the uncertainty in the
interaction between the model and the inputs. It provides insights from the
model perspective: if two samples interact with a model in a similar way, then
they are considered identically distributed. We also show that the pTU is
insensitive to the model architecture. As an application, pTU is used to solve
the out-of-distribution (OOD) detection problem, which is critical to ensure
model reliability. Failure to detect OOD input can lead to incorrect and
unreliable predictions. To address this issue, we propose a significance test
for OOD based on the pTU, providing a statistical framework for this issue. The
effectiveness of the framework is validated through various experiments, in
terms of its statistical power, sensitivity, and robustness.
\\ ( https://arxiv.org/abs/2511.18813 ,  844kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18820 (*cross-listing*)
Date: Mon, 24 Nov 2025 06:54:20 GMT   (7828kb)

Title: Solution of Incompressible Flow Equations with Physics and Equality
 Constrained Artificial Neural Networks
Authors: Qifeng Hu, Inanc Senocak
Categories: physics.flu-dyn cs.LG
Comments: 21 pages, 13 figures
\\
 We present a meshless method for the solution of incompressible Navier-Stokes
equations in advection-dominated regimes using physics- and
equality-constrained artificial neural networks combined with a conditionally
adaptive augmented Lagrangian formulation. A single neural network
parameterizes both the velocity and pressure fields, and is trained by
minimizing the residual of a Poisson's equation for pressure, constrained by
the momentum and continuity equations, together with boundary conditions on the
velocity field. No boundary conditions are imposed on the pressure field aside
from anchoring the pressure at a point to prevent its unbounded development.
The training is performed from scratch without labeled data, relying solely on
the governing equations and constraints. To enhance accuracy in
advection-dominated flows, we employ a single Fourier feature mapping of the
input coordinates. The proposed method is demonstrated for the canonical
lid-driven cavity flow up to a Reynolds number of 7,500 and for laminar flow
over a circular cylinder with inflow-outflow boundary conditions, achieving
excellent agreement with benchmark solutions. We further compare the present
formulation against alternative objective-function constructions based on
different arrangements of the flow equations, thereby highlighting the
algorithmic advantages of the proposed formulation centered around the
Poisson's equation for pressure.
\\ ( https://arxiv.org/abs/2511.18820 ,  7828kb)
------------------------------------------------------------------------------
\\
arXiv:2511.18876 (*cross-listing*)
Date: Mon, 24 Nov 2025 08:31:02 GMT   (92kb,D)

Title: Fairness Meets Privacy: Integrating Differential Privacy and Demographic
 Parity in Multi-class Classification
Authors: Lilian Say (LPSM), Christophe Denis (SAMM), Rafael Pinot (LPSM)
Categories: stat.ML cs.LG
\\
 The increasing use of machine learning in sensitive applications demands
algorithms that simultaneously preserve data privacy and ensure fairness across
potentially sensitive sub-populations. While privacy and fairness have each
been extensively studied, their joint treatment remains poorly understood.
Existing research often frames them as conflicting objectives, with multiple
studies suggesting that strong privacy notions such as differential privacy
inevitably compromise fairness. In this work, we challenge that perspective by
showing that differential privacy can be integrated into a fairness-enhancing
pipeline with minimal impact on fairness guarantees. We design a postprocessing
algorithm, called DP2DP, that enforces both demographic parity and differential
privacy. Our analysis reveals that our algorithm converges towards its
demographic parity objective at essentially the same rate (up logarithmic
factor) as the best non-private methods from the literature. Experiments on
both synthetic and real datasets confirm our theoretical results, showing that
the proposed algorithm achieves state-of-the-art accuracy/fairness/privacy
trade-offs.
\\ ( https://arxiv.org/abs/2511.18876 ,  92kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19075 (*cross-listing*)
Date: Mon, 24 Nov 2025 13:11:27 GMT   (808kb)

Title: Structured Matching via Cost-Regularized Unbalanced Optimal Transport
Authors: Emanuele Pardini and Katerina Papagiannouli
Categories: stat.ML cs.LG stat.AP
\\
 Unbalanced optimal transport (UOT) provides a flexible way to match or
compare nonnegative finite Radon measures. However, UOT requires a predefined
ground transport cost, which may misrepresent the data's underlying geometry.
Choosing such a cost is particularly challenging when datasets live in
heterogeneous spaces, often motivating practitioners to adopt
Gromov-Wasserstein formulations. To address this challenge, we introduce
cost-regularized unbalanced optimal transport (CR-UOT), a framework that allows
the ground cost to vary while allowing mass creation and removal. We show that
CR-UOT incorporates unbalanced Gromov-Wasserstein type problems through
families of inner-product costs parameterized by linear transformations,
enabling the matching of measures or point clouds across Euclidean spaces. We
develop algorithms for such CR-UOT problems using entropic regularization and
demonstrate that this approach improves the alignment of heterogeneous
single-cell omics profiles, especially when many cells lack direct matches.
\\ ( https://arxiv.org/abs/2511.19075 ,  808kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19150 (*cross-listing*)
Date: Mon, 24 Nov 2025 14:15:57 GMT   (829kb)

Title: Feature Ranking in Credit-Risk with Qudit-Based Networks
Authors: Georgios Maragkopoulos, Lazaros Chavatzoglou, Aikaterini Mandilara,
 Dimitris Syvridis
Categories: quant-ph cs.LG
\\
 In finance, predictive models must balance accuracy and interpretability,
particularly in credit risk assessment, where model decisions carry material
consequences. We present a quantum neural network (QNN) based on a single
qudit, in which both data features and trainable parameters are co-encoded
within a unified unitary evolution generated by the full Lie algebra. This
design explores the entire Hilbert space while enabling interpretability
through the magnitudes of the learned coefficients. We benchmark our model on a
real-world, imbalanced credit-risk dataset from Taiwan. The proposed QNN
consistently outperforms LR and reaches the results of random forest models in
macro-F1 score while preserving a transparent correspondence between learned
parameters and input feature importance. To quantify the interpretability of
the proposed model, we introduce two complementary metrics: (i) the edit
distance between the model's feature ranking and that of LR, and (ii) a
feature-poisoning test where selected features are replaced with noise. Results
indicate that the proposed quantum model achieves competitive performance while
offering a tractable path toward interpretable quantum learning.
\\ ( https://arxiv.org/abs/2511.19150 ,  829kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19157 (*cross-listing*)
Date: Mon, 24 Nov 2025 14:25:13 GMT   (329kb)

Title: A Robust State Filter Against Unmodeled Process And Measurement Noise
Authors: Weitao Liu
Categories: stat.ML cs.LG
\\
 This paper introduces a novel Kalman filter framework designed to achieve
robust state estimation under both process and measurement noise. Inspired by
the Weighted Observation Likelihood Filter (WoLF), which provides robustness
against measurement outliers, we applied generalized Bayesian approach to build
a framework considering both process and measurement noise outliers.
\\ ( https://arxiv.org/abs/2511.19157 ,  329kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19284 (*cross-listing*)
Date: Mon, 24 Nov 2025 16:32:07 GMT   (15kb)

Title: The Unified Non-Convex Framework for Robust Causal Inference: Overcoming
 the Gaussian Barrier and Optimization Fragility
Authors: Eichi Uehara
Categories: stat.ML cs.LG stat.ME
Comments: 10 pages, 1 table
MSC-class: 62G35, 62J07
ACM-class: G.3; I.2.6
\\
 This document proposes a Unified Robust Framework that re-engineers the
estimation of the Average Treatment Effect on the Overlap (ATO). It synthesizes
gamma-Divergence for outlier robustness, Graduated Non-Convexity (GNC) for
global optimization, and a "Gatekeeper" mechanism to address the impossibility
of higher-order orthogonality in Gaussian regimes.
\\ ( https://arxiv.org/abs/2511.19284 ,  15kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19289 (*cross-listing*)
Date: Mon, 24 Nov 2025 16:36:06 GMT   (47kb)

Title: Performance Guarantees for Quantum Neural Estimation of Entropies
Authors: Sreejith Sreekumar and Ziv Goldfeld and Mark M. Wilde
Categories: quant-ph cs.IT cs.LG math.IT
Comments: 42+4 pages
\\
 Estimating quantum entropies and divergences is an important problem in
quantum physics, information theory, and machine learning. Quantum neural
estimators (QNEs), which utilize a hybrid classical-quantum architecture, have
recently emerged as an appealing computational framework for estimating these
measures. Such estimators combine classical neural networks with parametrized
quantum circuits, and their deployment typically entails tedious tuning of
hyperparameters controlling the sample size, network architecture, and circuit
topology. This work initiates the study of formal guarantees for QNEs of
measured (R\'enyi) relative entropies in the form of non-asymptotic error risk
bounds. We further establish exponential tail bounds showing that the error is
sub-Gaussian, and thus sharply concentrates about the ground truth value. For
an appropriate sub-class of density operator pairs on a space of dimension $d$
with bounded Thompson metric, our theory establishes a copy complexity of
$O(|\Theta(\mathcal{U})|d/\epsilon^2)$ for QNE with a quantum circuit parameter
set $\Theta(\mathcal{U})$, which has minimax optimal dependence on the accuracy
$\epsilon$. Additionally, if the density operator pairs are permutation
invariant, we improve the dimension dependence above to
$O(|\Theta(\mathcal{U})|\mathrm{polylog}(d)/\epsilon^2)$. Our theory aims to
facilitate principled implementation of QNEs for measured relative entropies
and guide hyperparameter tuning in practice.
\\ ( https://arxiv.org/abs/2511.19289 ,  47kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19291 (*cross-listing*)
Date: Mon, 24 Nov 2025 16:37:28 GMT   (233kb)

Title: TorchQuantumDistributed
Authors: Oliver Knitter, Jonathan Mei, Masako Yamada, Martin Roetteler
Categories: quant-ph cs.CE cs.LG
Comments: 12 pages, 4 figures, to appear in the AI for Science Workshop at
 NeurIPS 2025
\\
 TorchQuantumDistributed (tqd) is a PyTorch-based [Paszke et al., 2019]
library for accelerator-agnostic differentiable quantum state vector simulation
at scale. This enables studying the behavior of learnable parameterized
near-term and fault- tolerant quantum circuits with high qubit counts.
\\ ( https://arxiv.org/abs/2511.19291 ,  233kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19335 (*cross-listing*)
Date: Mon, 24 Nov 2025 17:31:16 GMT   (3991kb)

Title: High-throughput validation of phase formability and simulation accuracy
 of Cantor alloys
Authors: Changjun Cheng, Daniel Persaud, Kangming Li, Michael J. Moorehead,
 Natalie Page, Christian Lavoie, Beatriz Diaz Moreno, Adrien Couet, Samuel E
 Lofland, Jason Hattrick-Simpers
Categories: cond-mat.mtrl-sci cs.LG
\\
 High-throughput methods enable accelerated discovery of novel materials in
complex systems such as high-entropy alloys, which exhibit intricate phase
stability across vast compositional spaces. Computational approaches, including
Density Functional Theory (DFT) and calculation of phase diagrams (CALPHAD),
facilitate screening of phase formability as a function of composition and
temperature. However, the integration of computational predictions with
experimental validation remains challenging in high-throughput studies. In this
work, we introduce a quantitative confidence metric to assess the agreement
between predictions and experimental observations, providing a quantitative
measure of the confidence of machine learning models trained on either DFT or
CALPHAD input in accounting for experimental evidence. The experimental dataset
was generated via high-throughput in-situ synchrotron X-ray diffraction on
compositionally varied FeNiMnCr alloy libraries, heated from room temperature
to ~1000 {\deg}C. Agreement between the observed and predicted phases was
evaluated using either temperature-independent phase classification or a model
that incorporates a temperature-dependent probability of phase formation. This
integrated approach demonstrates where strong overall agreement between
computation and experiment exists, while also identifying key discrepancies,
particularly in FCC/BCC predictions at Mn-rich regions to inform future model
refinement.
\\ ( https://arxiv.org/abs/2511.19335 ,  3991kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19347 (*cross-listing*)
Date: Mon, 24 Nov 2025 17:46:54 GMT   (4563kb)

Title: Artificial Intelligence Driven Workflow for Accelerating Design of Novel
 Photosensitizers
Authors: Hongyi Wang, Xiuli Zheng, Weimin Liu, Zitian Tang, Sheng Gong
Categories: cond-mat.mtrl-sci cs.LG physics.chem-ph
\\
 The discovery of high-performance photosensitizers has long been hindered by
the time-consuming and resource-intensive nature of traditional trial-and-error
approaches. Here, we present \textbf{A}I-\textbf{A}ccelerated
\textbf{P}hoto\textbf{S}ensitizer \textbf{I}nnovation (AAPSI), a closed-loop
workflow that integrates expert knowledge, scaffold-based molecule generation,
and Bayesian optimization to accelerate the design of novel photosensitizers.
The scaffold-driven generation in AAPSI ensures structural novelty and
synthetic feasibility, while the iterative AI-experiment loop accelerates the
discovery of novel photosensitizers. AAPSI leverages a curated database of
102,534 photosensitizer-solvent pairs and generate 6,148 synthetically
accessible candidates. These candidates are screened via graph transformers
trained to predict singlet oxygen quantum yield ($\phi_\Delta$) and absorption
maxima ($\lambda_{max}$), following experimental validation. This work
generates several novel candidates for photodynamic therapy (PDT), among which
the hypocrellin-based candidate HB4Ph exhibits exceptional performance at the
Pareto frontier of high quantum yield of singlet oxygen and long absorption
maxima among current photosensitizers ($\phi_\Delta$=0.85,
$\lambda_{max}$=650nm).
\\ ( https://arxiv.org/abs/2511.19347 ,  4563kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19398 (*cross-listing*)
Date: Mon, 24 Nov 2025 18:35:29 GMT   (49kb)

Title: PTF Testing Lower Bounds for Non-Gaussian Component Analysis
Authors: Ilias Diakonikolas, Daniel M. Kane, Sihan Liu, Thanasis Pittas
Categories: cs.DS cs.IT cs.LG math.IT math.ST stat.ML stat.TH
\\
 This work studies information-computation gaps for statistical problems. A
common approach for providing evidence of such gaps is to show sample
complexity lower bounds (that are stronger than the information-theoretic
optimum) against natural models of computation. A popular such model in the
literature is the family of low-degree polynomial tests. While these tests are
defined in such a way that make them easy to analyze, the class of algorithms
that they rule out is somewhat restricted. An important goal in this context
has been to obtain lower bounds against the stronger and more natural class of
low-degree Polynomial Threshold Function (PTF) tests, i.e., any test that can
be expressed as comparing some low-degree polynomial of the data to a
threshold. Proving lower bounds against PTF tests has turned out to be
challenging. Indeed, we are not aware of any non-trivial PTF testing lower
bounds in the literature.
 In this paper, we establish the first non-trivial PTF testing lower bounds
for a range of statistical tasks. Specifically, we prove a near-optimal PTF
testing lower bound for Non-Gaussian Component Analysis (NGCA). Our NGCA lower
bound implies similar lower bounds for a number of other statistical problems.
Our proof leverages a connection to recent work on pseudorandom generators for
PTFs and recent techniques developed in that context. At the technical level,
we develop several tools of independent interest, including novel structural
results for analyzing the behavior of low-degree polynomials restricted to
random directions.
\\ ( https://arxiv.org/abs/2511.19398 ,  49kb)
------------------------------------------------------------------------------
\\
arXiv:2511.19404 (*cross-listing*)
Date: Mon, 24 Nov 2025 18:42:49 GMT   (230kb)

Title: Nonparametric Instrumental Variable Regression with Observed Covariates
Authors: Zikai Shen, Zonghao Chen, Dimitri Meunier, Ingo Steinwart, Arthur
 Gretton and Zhu Li
Categories: stat.ML cs.LG math.ST stat.TH
\\
 We study the problem of nonparametric instrumental variable regression with
observed covariates, which we refer to as NPIV-O. Compared with standard
nonparametric instrumental variable regression (NPIV), the additional observed
covariates facilitate causal identification and enables heterogeneous causal
effect estimation. However, the presence of observed covariates introduces two
challenges for its theoretical analysis. First, it induces a partial identity
structure, which renders previous NPIV analyses - based on measures of
ill-posedness, stability conditions, or link conditions - inapplicable. Second,
it imposes anisotropic smoothness on the structural function. To address the
first challenge, we introduce a novel Fourier measure of partial smoothing; for
the second challenge, we extend the existing kernel 2SLS instrumental variable
algorithm with observed covariates, termed KIV-O, to incorporate Gaussian
kernel lengthscales adaptive to the anisotropic smoothness. We prove upper
$L^2$-learning rates for KIV-O and the first $L^2$-minimax lower learning rates
for NPIV-O. Both rates interpolate between known optimal rates of NPIV and
nonparametric regression (NPR). Interestingly, we identify a gap between our
upper and lower bounds, which arises from the choice of kernel lengthscales
tuned to minimize a projected risk. Our theoretical analysis also applies to
proximal causal inference, an emerging framework for causal effect estimation
that shares the same conditional moment restriction as NPIV-O.
\\ ( https://arxiv.org/abs/2511.19404 ,  230kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2312.15524
replaced with revised version Sun, 23 Nov 2025 22:53:45 GMT   (378kb)

Title: The Challenge of Using LLMs to Simulate Human Behavior: A Causal
 Inference Perspective
Authors: George Gui, Olivier Toubia
Categories: cs.AI cs.IR econ.EM stat.AP
DOI: 10.2139/ssrn.4650172
\\ ( https://arxiv.org/abs/2312.15524 ,  378kb)
------------------------------------------------------------------------------
\\
arXiv:2405.16123
replaced with revised version Mon, 24 Nov 2025 08:23:34 GMT   (1066kb)

Title: Gradient Propagation in Retrosynthetic Space: An Efficient Framework for
 Synthesis Plan Generation
Authors: Chengyang Tian and Yuhang Chang and Yangpeng Zhang and Yang Liu
Categories: cs.AI q-bio.BM
\\ ( https://arxiv.org/abs/2405.16123 ,  1066kb)
------------------------------------------------------------------------------
\\
arXiv:2409.08641
replaced with revised version Mon, 24 Nov 2025 09:52:56 GMT   (1315kb)

Title: Developing an Algorithm Selector for Green Configuration in Scheduling
 Problems
Authors: Carlos March, Christian Perez and Miguel A. Salido
Categories: cs.AI
MSC-class: 90C27
\\ ( https://arxiv.org/abs/2409.08641 ,  1315kb)
------------------------------------------------------------------------------
\\
arXiv:2409.15687
replaced with revised version Sun, 23 Nov 2025 16:03:34 GMT   (422kb)

Title: A Comprehensive Evaluation of Large Language Models on Mental Illnesses
Authors: Abdelrahman Hanafi, Mohammed Saad, Noureldin Zahran, Radwa J. Hanafy
 and Mohammed E. Fouda
Categories: cs.AI
\\ ( https://arxiv.org/abs/2409.15687 ,  422kb)
------------------------------------------------------------------------------
\\
arXiv:2409.17516
replaced with revised version Sun, 23 Nov 2025 23:59:06 GMT   (1459kb)

Title: Functional Classification of Spiking Signal Data Using Artificial
 Intelligence Techniques: A Review
Authors: Danial Sharifrazi, Nouman Javed, Javad Hassannataj Joloudari,
 Roohallah Alizadehsani, Prasad N. Paradkar, Ru-San Tan, U. Rajendra Acharya,
 Asim Bhatti
Categories: cs.AI cs.LG q-bio.NC
Comments: 8 figures, 32 pages
\\ ( https://arxiv.org/abs/2409.17516 ,  1459kb)
------------------------------------------------------------------------------
\\
arXiv:2410.05130
replaced with revised version Sun, 23 Nov 2025 03:58:04 GMT   (970kb)

Title: Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents
Authors: Yuwei Hu, Runlin Lei, Xinyi Huang, Zhewei Wei, Yongchao Liu
Categories: cs.AI
Comments: Accepted by AAAI 2026 Workshop WMAC
\\ ( https://arxiv.org/abs/2410.05130 ,  970kb)
------------------------------------------------------------------------------
\\
arXiv:2412.18387
replaced with revised version Sun, 23 Nov 2025 11:07:55 GMT   (4897kb)

Title: Scaling Capability in Token Space: An Analysis of Large Vision Language
 Model
Authors: Tenghui Li and Guoxu Zhou and Xuyang Zhao and Qibin Zhao
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2412.18387 ,  4897kb)
------------------------------------------------------------------------------
\\
arXiv:2501.08068
replaced with revised version Sat, 22 Nov 2025 19:28:50 GMT   (24kb)

Title: A Roadmap to Guide the Integration of LLMs in Hierarchical Planning
Authors: Israel Puerta-Merino, Carlos N\'u\~nez-Molina, Pablo Mesejo, Juan
 Fern\'andez-Olivares
Categories: cs.AI
Comments: 5 pages, 0 figures, to be published in the AAAI Workshop on Planning
 in the Era of LLMs ( https://llmforplanning.github.io )
\\ ( https://arxiv.org/abs/2501.08068 ,  24kb)
------------------------------------------------------------------------------
\\
arXiv:2503.13223
replaced with revised version Mon, 24 Nov 2025 15:19:30 GMT   (32628kb)

Title: Distributionally Robust Free Energy Principle for Decision-Making
Authors: Allahkaram Shafiei, Hozefa Jesawada, Karl Friston, Giovanni Russo
Categories: cs.AI cs.SY eess.SY math.OC
Comments: Contains main text and supplementary information. Supplementary movie
 is at the paper repository
\\ ( https://arxiv.org/abs/2503.13223 ,  32628kb)
------------------------------------------------------------------------------
\\
arXiv:2503.23037
replaced with revised version Sat, 22 Nov 2025 08:55:19 GMT   (15683kb)

Title: Agentic Large Language Models, a survey
Authors: Aske Plaat, Max van Duijn, Niki van Stein, Mike Preuss, Peter van der
 Putten, Kees Joost Batenburg
Categories: cs.AI cs.CL cs.LG
Comments: Website: https://askeplaat.github.io/agentic-llm-survey-site/
Journal-ref: JAIR 2025
\\ ( https://arxiv.org/abs/2503.23037 ,  15683kb)
------------------------------------------------------------------------------
\\
arXiv:2504.13837
replaced with revised version Mon, 24 Nov 2025 06:11:04 GMT   (1177kb)

Title: Does Reinforcement Learning Really Incentivize Reasoning Capacity in
 LLMs Beyond the Base Model?
Authors: Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue,
 Shiji Song, Gao Huang
Categories: cs.AI cs.CL cs.CV
Comments: 31 pages, 27 figures
Journal-ref: NeurIPS 2025 Oral; ICML 2025 AI4MATH workshop best paper
\\ ( https://arxiv.org/abs/2504.13837 ,  1177kb)
------------------------------------------------------------------------------
\\
arXiv:2504.15046
replaced with revised version Sat, 22 Nov 2025 07:29:12 GMT   (1781kb)

Title: Text-to-Decision Agent: Offline Meta-Reinforcement Learning from Natural
 Language Supervision
Authors: Shilin Zhang, Zican Hu, Wenhao Wu, Xinyi Xie, Jianxiang Tang, Chunlin
 Chen, Daoyi Dong, Yu Cheng, Zhenhong Sun, Zhi Wang
Categories: cs.AI
Comments: 32 pages, 8 figures
\\ ( https://arxiv.org/abs/2504.15046 ,  1781kb)
------------------------------------------------------------------------------
\\
arXiv:2504.15668
replaced with revised version Mon, 24 Nov 2025 08:07:47 GMT   (4745kb)

Title: Preprint: Exploring Inevitable Waypoints for Unsolvability Explanation
 in Hybrid Planning Problems
Authors: Mir Md Sajid Sarwar, Rajarshi Ray
Categories: cs.AI cs.FL
ACM-class: I.2.0; F.4.3
Journal-ref: ACM Transactions on Embedded Computing Systems, Volume 24, Issue
 6, Article No.: 163, Year: 09 Oct0ber 2025, Pages 1 - 20
DOI: 10.1145/376774
\\ ( https://arxiv.org/abs/2504.15668 ,  4745kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18670
replaced with revised version Mon, 24 Nov 2025 13:44:50 GMT   (1544kb)

Title: MoveGPT: Scaling Mobility Foundation Models with Spatially-Aware Mixture
 of Experts
Authors: Chonghua Han, Yuan Yuan, Jingtao Ding, Jie Feng, Fanjin Meng, Yong Li
Categories: cs.AI
\\ ( https://arxiv.org/abs/2505.18670 ,  1544kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23518
replaced with revised version Mon, 24 Nov 2025 00:01:45 GMT   (2633kb)

Title: TRAP: Targeted Redirecting of Agentic Preferences
Authors: Hangoo Kang, Jehyeok Yeon, Gagandeep Singh
Categories: cs.AI
Comments: Accepted to NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.23518 ,  2633kb)
------------------------------------------------------------------------------
\\
arXiv:2506.06725
replaced with revised version Mon, 24 Nov 2025 16:18:31 GMT   (2186kb)

Title: WorldLLM: Improving LLMs' world modeling using curiosity-driven
 theory-making
Authors: Guillaume Levy, Cedric Colas, Pierre-Yves Oudeyer, Thomas Carta,
 Clement Romac
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2506.06725 ,  2186kb)
------------------------------------------------------------------------------
\\
arXiv:2506.12509
replaced with revised version Sat, 22 Nov 2025 16:09:13 GMT   (1812kb)

Title: Graph of Verification: Structured Verification of LLM Reasoning with
 Directed Acyclic Graphs
Authors: Jiwei Fang, Bin Zhang, Changwei Wang, Jin Wan, Zhiwei Xu
Categories: cs.AI
Comments: Accepted to AAAI 2026
\\ ( https://arxiv.org/abs/2506.12509 ,  1812kb)
------------------------------------------------------------------------------
\\
arXiv:2506.21996
replaced with revised version Mon, 24 Nov 2025 07:52:48 GMT   (1540kb,D)

Title: AlphaBeta is not as good as you think: a simple random games model for a
 better analysis of deterministic game-solving algorithms
Authors: Rapha\"el Boige (LORIA), Amine Boumaza (LORIA), Bruno Scherrer (LORIA)
Categories: cs.AI
\\ ( https://arxiv.org/abs/2506.21996 ,  1540kb)
------------------------------------------------------------------------------
\\
arXiv:2507.10750
replaced with revised version Mon, 24 Nov 2025 16:52:12 GMT   (1827kb)

Title: AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential
 for Transition
Authors: Pandu Devarakota, Nicolas Tsesmetzis, Faruk O. Alpak, Apurva Gala,
 Detlef Hohl
Categories: cs.AI
Comments: Technical article to be submitted to Data Centric Engineering Journal
\\ ( https://arxiv.org/abs/2507.10750 ,  1827kb)
------------------------------------------------------------------------------
\\
arXiv:2507.16356
replaced with revised version Mon, 24 Nov 2025 15:04:04 GMT   (294kb)

Title: Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for
 Improved Message Delivery in Mobile Maternal Health
Authors: Arpan Dasgupta, Mizhaan Maniyar, Awadhesh Srivastava, Sanat Kumar,
 Amrita Mahale, Aparna Hegde, Arun Suggala, Karthikeyan Shanmugam, Aparna
 Taneja, Milind Tambe
Categories: cs.AI
\\ ( https://arxiv.org/abs/2507.16356 ,  294kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01285
replaced with revised version Mon, 24 Nov 2025 16:36:29 GMT   (380kb)

Title: BioDisco: Multi-agent hypothesis generation with dual-mode evidence,
 iterative feedback and temporal evaluation
Authors: Yujing Ke and Kevin George and Kathan Pandya and David Blumenthal and
 Maximilian Sprang and Gerrit Gro{\ss}mann and Sebastian Vollmer and David
 Antony Selby
Categories: cs.AI cs.IR stat.AP
Comments: 12 pages main content, 31 including appendices. 8 figures
\\ ( https://arxiv.org/abs/2508.01285 ,  380kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02744
replaced with revised version Sun, 23 Nov 2025 08:12:48 GMT   (4123kb)

Title: Large Language Model-based Data Science Agent: A Survey
Authors: Ke Chen, Peiran Wang, Yaoning Yu, Xianyang Zhan, Haohan Wang
Categories: cs.AI
\\ ( https://arxiv.org/abs/2508.02744 ,  4123kb)
------------------------------------------------------------------------------
\\
arXiv:2508.06859
replaced with revised version Sat, 22 Nov 2025 07:05:59 GMT   (4304kb)

Title: MeteorPred: A Meteorological Multimodal Large Model and Dataset for
 Severe Weather Event Prediction
Authors: Shuo Tang, Jian Xu, Jiadong Zhang, Yi Chen, Qizhao Jin, Lingdong Shen,
 Chenglin Liu, Shiming Xiang
Categories: cs.AI cs.CV
\\ ( https://arxiv.org/abs/2508.06859 ,  4304kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18527
replaced with revised version Fri, 21 Nov 2025 21:42:19 GMT   (6400kb)

Title: FERA: Bridging the Semantic Gap in Foil Fencing via Kinematic Pose
 Recognition and Explainable Rule Reasoning
Authors: Ziwen Chen and Zhong Wang
Categories: cs.AI
Comments: Clarified some unclear methods and added more info in related works
 section
\\ ( https://arxiv.org/abs/2509.18527 ,  6400kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03469
replaced with revised version Mon, 24 Nov 2025 18:17:27 GMT   (144kb)

Title: Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan
 Verification
Authors: Keshav Ramani, Vali Tawosi, Salwa Alamir, Daniel Borrajo
Categories: cs.AI cs.LO
Comments: Accepted to AgenticSE Workshop at ASE 2025
\\ ( https://arxiv.org/abs/2510.03469 ,  144kb)
------------------------------------------------------------------------------
\\
arXiv:2510.06534
replaced with revised version Sat, 22 Nov 2025 06:56:29 GMT   (637kb)

Title: Beneficial Reasoning Behaviors in Agentic Search and Effective
 Post-training to Obtain Them
Authors: Jiahe Jin, Abhijay Paladugu, Chenyan Xiong
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2510.06534 ,  637kb)
------------------------------------------------------------------------------
\\
arXiv:2510.07852
replaced with revised version Sat, 22 Nov 2025 04:54:04 GMT   (0kb,I)

Title: FinMR: A Knowledge-Intensive Multimodal Benchmark for Advanced Financial
 Reasoning
Authors: Shuangyan Deng, Haizhou Peng, Jiachen Xu, Rui Mao, Ciprian Doru
 Giurc\u{a}neanu, Jiamou Liu
Categories: cs.AI
Comments: The methodology section contains inaccuracies that may lead to
 misleading interpretations. The authors have withdrawn this version for
 correction
\\ ( https://arxiv.org/abs/2510.07852 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00763
replaced with revised version Mon, 24 Nov 2025 06:11:01 GMT   (964kb)

Title: How Focused Are LLMs? A Quantitative Study via Repetitive Deterministic
 Prediction Tasks
Authors: Wanda Hou, Leon Zhou, Hong-Ye Hu, Yubei Chen, Yi-Zhuang You, and
 Xiao-Liang Qi
Categories: cs.AI
\\ ( https://arxiv.org/abs/2511.00763 ,  964kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07061
replaced with revised version Mon, 24 Nov 2025 01:17:15 GMT   (393kb)

Title: Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and
 Curriculum Learning
Authors: Xinran Li, Yu Liu, Jiaqi Qiao, Xiujuan Xu
Categories: cs.AI
Comments: Accepted at AAAI 2026
\\ ( https://arxiv.org/abs/2511.07061 ,  393kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11043
replaced with revised version Mon, 24 Nov 2025 09:43:11 GMT   (778kb)

Title: Autonomous Vehicle Path Planning by Searching With Differentiable
 Simulation
Authors: Asen Nachkov, Jan-Nico Zaech, Danda Pani Paudel, Xi Wang, Luc Van Gool
Categories: cs.AI cs.RO
\\ ( https://arxiv.org/abs/2511.11043 ,  778kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14299
replaced with revised version Mon, 24 Nov 2025 08:37:38 GMT   (1735kb)

Title: DataSage: Multi-agent Collaboration for Insight Discovery with External
 Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning
Authors: Xiaochuan Liu, Yuanfeng Song, Xiaoming Yin, Xing Chen
Categories: cs.AI cs.CL cs.MA
\\ ( https://arxiv.org/abs/2511.14299 ,  1735kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14730
replaced with revised version Sun, 23 Nov 2025 20:39:15 GMT   (431kb)

Title: Heterogeneous Multi-Agent Proximal Policy Optimization for Power
 Distribution System Restoration
Authors: Parya Dolatyabi, Mahdi Khodayar
Categories: cs.AI
Comments: 6 pages, 4 figures, TPEC 2025 Conference
\\ ( https://arxiv.org/abs/2511.14730 ,  431kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16139
replaced with revised version Sun, 23 Nov 2025 04:03:44 GMT   (293kb)

Title: Multidimensional Rubric-oriented Reward Model Learning via Geometric
 Projection Reference Constraints
Authors: Yongnan Jin, Xurui Li, Feng Cao, Liucun Gao, Juanjuan Yao
Categories: cs.AI
\\ ( https://arxiv.org/abs/2511.16139 ,  293kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16660
replaced with revised version Mon, 24 Nov 2025 18:59:30 GMT   (3981kb)

Title: Cognitive Foundations for Reasoning and Their Manifestation in LLMs
Authors: Priyanka Kargupta, Shuyue Stella Li, Haocheng Wang, Jinu Lee, Shan
 Chen, Orevaoghene Ahia, Dean Light, Thomas L. Griffiths, Max Kleiman-Weiner,
 Jiawei Han, Asli Celikyilmaz, Yulia Tsvetkov
Categories: cs.AI
Comments: 40 pages, 4 tables, 6 figures
\\ ( https://arxiv.org/abs/2511.16660 ,  3981kb)
------------------------------------------------------------------------------
\\
arXiv:2310.18089
replaced with revised version Mon, 24 Nov 2025 15:21:07 GMT   (1475kb)

Title: Lost in translation: using global fact-checks to measure multilingual
 misinformation prevalence, spread, and evolution
Authors: Dorian Quelle, Calvin Cheng, Alexandre Bovet, Scott A. Hale
Categories: cs.CL cs.CY cs.SI
Journal-ref: EPJ Data Sci. 14, 22 (2025)
DOI: 10.1140/epjds/s13688-025-00520-6
\\ ( https://arxiv.org/abs/2310.18089 ,  1475kb)
------------------------------------------------------------------------------
\\
arXiv:2312.15503
replaced with revised version Sun, 23 Nov 2025 13:38:28 GMT   (6960kb)

Title: Llama2Vec: Unsupervised Adaptation of Large Language Models for Dense
 Retrieval
Authors: Zheng Liu, Chaofan Li, Shitao Xiao, Yingxia Shao, Defu Lian
Categories: cs.CL
Comments: ACL 2024
\\ ( https://arxiv.org/abs/2312.15503 ,  6960kb)
------------------------------------------------------------------------------
\\
arXiv:2401.11641
replaced with revised version Fri, 21 Nov 2025 21:54:12 GMT   (1843kb)

Title: Revolutionizing Finance with LLMs: An Overview of Applications and
 Insights
Authors: Huaqin Zhao, Zhengliang Liu, Zihao Wu, Yiwei Li, Tianze Yang, Peng
 Shu, Shaochen Xu, Haixing Dai, Lin Zhao, Hanqi Jiang, Yi Pan, Junhao Chen,
 Yifan Zhou, Zeyu Zhang, Gengchen Mai, Ninghao Liu, Tianming Liu
Categories: cs.CL
\\ ( https://arxiv.org/abs/2401.11641 ,  1843kb)
------------------------------------------------------------------------------
\\
arXiv:2402.14268
replaced with revised version Mon, 24 Nov 2025 04:39:03 GMT   (2259kb)

Title: Can Large Language Models Detect Misinformation in Scientific News
 Reporting?
Authors: Yupeng Cao, Aishwarya Muralidharan Nair, Nastaran Jamalipour Soofi,
 Elyon Eyimife, K.P. Subbalakshmi
Categories: cs.CL cs.AI cs.SI
\\ ( https://arxiv.org/abs/2402.14268 ,  2259kb)
------------------------------------------------------------------------------
\\
arXiv:2409.09825
replaced with revised version Fri, 21 Nov 2025 20:03:34 GMT   (3496kb)

Title: GP-GPT: Large Language Model for Gene-Phenotype Mapping
Authors: Yanjun Lyu, Zihao Wu, Lu Zhang, Jing Zhang, Yiwei Li, Wei Ruan,
 Zhengliang Liu, Zeyu Zhang, Xiang Li, Rongjie Liu, Chao Huang, Wentao Li,
 Tianming Liu, Dajiang Zhu
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2409.09825 ,  3496kb)
------------------------------------------------------------------------------
\\
arXiv:2409.18486
replaced with revised version Mon, 24 Nov 2025 09:15:19 GMT   (15048kb)

Title: Evaluation of OpenAI o1: Opportunities and Challenges of AGI
Authors: Tianyang Zhong, Zhengliang Liu, Yi Pan, Yutong Zhang, Zeyu Zhang,
 Yifan Zhou, Shizhe Liang, Zihao Wu, Yanjun Lyu, Peng Shu, Xiaowei Yu, Chao
 Cao, Hanqi Jiang, Hanxu Chen, Yiwei Li, Junhao Chen, Huawen Hu, Yiheng Liu,
 Huaqin Zhao, Shaochen Xu, Haixing Dai, Lin Zhao, Ruidong Zhang, Wei Zhao,
 Zhenyuan Yang, Jingyuan Chen, Peilong Wang, Wei Ruan, Hui Wang, Huan Zhao,
 Jing Zhang, Yiming Ren, Shihuan Qin, Tong Chen, Jiaxi Li, Arif Hassan Zidan,
 Afrar Jahin, Minheng Chen, Sichen Xia, Jason Holmes, Yan Zhuang, Jiaqi Wang,
 Bochen Xu, Weiran Xia, Jichao Yu, Kaibo Tang, Yaxuan Yang, Bolun Sun, Tao
 Yang, Guoyu Lu, Xianqiao Wang, Lilong Chai, He Li, Jin Lu, Xin Zhang, Bao Ge,
 Xintao Hu, Lian Zhang, Hua Zhou, Lu Zhang, Shu Zhang, Zhen Xiang, Yudan Ren,
 Jun Liu, Xi Jiang, Yu Bao, Wei Zhang, Xiang Li, Gang Li, et al. (7 additional
 authors not shown)
Categories: cs.CL
\\ ( https://arxiv.org/abs/2409.18486 ,  15048kb)
------------------------------------------------------------------------------
\\
arXiv:2409.19492
replaced with revised version Sat, 22 Nov 2025 18:49:17 GMT   (890kb)

Title: MedHalu: Hallucinations in Responses to Healthcare Queries by Large
 Language Models
Authors: Vibhor Agarwal, Yiqiao Jin, Mohit Chandra, Munmun De Choudhury, Srijan
 Kumar, Nishanth Sastry
Categories: cs.CL cs.AI
Comments: Accepted at ICWSM2026. https://netsys.surrey.ac.uk/datasets/medhalu/
\\ ( https://arxiv.org/abs/2409.19492 ,  890kb)
------------------------------------------------------------------------------
\\
arXiv:2410.01215
replaced with revised version Sat, 22 Nov 2025 16:20:24 GMT   (1075kb)

Title: From Code to Correctness: Closing the Last Mile of Code Generation with
 Hierarchical Debugging
Authors: Yuling Shi, Songsong Wang, Chengcheng Wan, Min Wang, Xiaodong Gu
Categories: cs.CL cs.AI cs.PL cs.SE
Comments: Accepted to ICSE 2026. Code and data available at
 https://github.com/YerbaPage/MGDebugger
\\ ( https://arxiv.org/abs/2410.01215 ,  1075kb)
------------------------------------------------------------------------------
\\
arXiv:2410.07523
replaced with revised version Fri, 21 Nov 2025 21:39:00 GMT   (323kb)

Title: DemoShapley: Valuation of Demonstrations for In-Context Learning
Authors: Shan Xie, Man Luo, Chadly Daniel Stern, Mengnan Du, Lu Cheng
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2410.07523 ,  323kb)
------------------------------------------------------------------------------
\\
arXiv:2410.13334
replaced with revised version Mon, 24 Nov 2025 07:12:09 GMT   (1585kb)

Title: BiasJailbreak:Analyzing Ethical Biases and Jailbreak Vulnerabilities in
 Large Language Models
Authors: Isack Lee, Haebin Seong
Categories: cs.CL cs.AI cs.LG
Comments: Accepted as a workshop paper at AAAI 2026
\\ ( https://arxiv.org/abs/2410.13334 ,  1585kb)
------------------------------------------------------------------------------
\\
arXiv:2410.18436
replaced with revised version Mon, 24 Nov 2025 06:51:53 GMT   (1877kb)

Title: Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case
 Study on English-Korean Code-Switching
Authors: Seoyeon Kim, Huiseo Kim, Chanjun Park, Jinyoung Yeo, Dongha Lee
Categories: cs.CL
Comments: Accepted to EMNLP 2025 Findings
\\ ( https://arxiv.org/abs/2410.18436 ,  1877kb)
------------------------------------------------------------------------------
\\
arXiv:2411.16353
replaced with revised version Sun, 23 Nov 2025 18:52:03 GMT   (483kb)

Title: Lessons from Studying Two-Hop Latent Reasoning
Authors: Mikita Balesni, Tomek Korbak, Owain Evans
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2411.16353 ,  483kb)
------------------------------------------------------------------------------
\\
arXiv:2411.17265
replaced with revised version Mon, 24 Nov 2025 07:35:03 GMT   (1621kb)

Title: Systematic Reward Gap Optimization for Mitigating VLM Hallucinations
Authors: Lehan He, Zeren Chen, Zhelun Shi, Tianyu Yu, Jing Shao, Lu Sheng
Categories: cs.CL cs.CV
Comments: 34 pages, 12 figures, Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2411.17265 ,  1621kb)
------------------------------------------------------------------------------
\\
arXiv:2412.07682
replaced with revised version Mon, 24 Nov 2025 09:56:59 GMT   (1106kb)

Title: TRIM: Token Reduction and Inference Modeling for Cost-Effective Language
 Generation
Authors: Alfredo Garrach\'on Ruiz and Tom\'as de la Rosa and Daniel Borrajo
Categories: cs.CL
Comments: 16 pages, 9 tables, 5 figures
\\ ( https://arxiv.org/abs/2412.07682 ,  1106kb)
------------------------------------------------------------------------------
\\
arXiv:2412.18811
replaced with revised version Sat, 22 Nov 2025 07:09:58 GMT   (186kb)

Title: DCIS: Efficient Length Extrapolation of LLMs via Divide-and-Conquer
 Scaling Factor Search
Authors: Lei Yang, Shaoyang Xu, Jianxiang Peng, Shaolin Zhu, Deyi Xiong
Categories: cs.CL
Comments: EMNLP 2025 Main
\\ ( https://arxiv.org/abs/2412.18811 ,  186kb)
------------------------------------------------------------------------------
\\
arXiv:2502.14734
replaced with revised version Mon, 24 Nov 2025 17:36:08 GMT   (533kb)

Title: Sentence Smith: Controllable Edits for Evaluating Text Embeddings
Authors: Hongji Li and Andrianos Michail and Reto Gubelmann and Simon Clematide
 and Juri Opitz
Categories: cs.CL
Comments: EMNLP 2025 (main), this version fixes a subscript typo in Eq 1
\\ ( https://arxiv.org/abs/2502.14734 ,  533kb)
------------------------------------------------------------------------------
\\
arXiv:2502.15018
replaced with revised version Sat, 22 Nov 2025 07:45:52 GMT   (9176kb)

Title: Using tournaments to calculate AUROC for zero-shot classification with
 LLMs
Authors: WonJin Yoon, Ian Bulovic, Timothy A. Miller
Categories: cs.CL
Comments: The 2025 Conference on Empirical Methods in Natural Language
 Processing (EMNLP 2025, Findings). The code is available at:
 https://github.com/Machine-Learning-for-Medical-Language/cnlp_llm
Journal-ref: In Findings of the Association for Computational Linguistics:
 EMNLP 2025, pages 23583-23591, Suzhou, China. Association for Computational
 Linguistics
DOI: 10.18653/v1/2025.findings-emnlp.1281
\\ ( https://arxiv.org/abs/2502.15018 ,  9176kb)
------------------------------------------------------------------------------
\\
arXiv:2503.05060
replaced with revised version Mon, 24 Nov 2025 12:54:31 GMT   (1036kb)

Title: ModernBERT is More Efficient than Conventional BERT for Chest CT
 Findings Classification in Japanese Radiology Reports
Authors: Yosuke Yamagishi, Tomohiro Kikuchi, Shouhei Hanaoka, Takeharu
 Yoshikawa, Osamu Abe
Categories: cs.CL
Comments: 31 pages
\\ ( https://arxiv.org/abs/2503.05060 ,  1036kb)
------------------------------------------------------------------------------
\\
arXiv:2503.10727
replaced with revised version Mon, 24 Nov 2025 16:34:25 GMT   (1528kb)

Title: Word-level Annotation of GDPR Transparency Compliance in Privacy
 Policies using Large Language Models
Authors: Thomas Cory, Wolf Rieder, Julia Kr\"amer, Philip Raschke, Patrick
 Herbke, Axel K\"upper
Categories: cs.CL cs.AI
Comments: Accepted to Proceedings on Privacy Enhancing Technologies (PoPETs) 1
 (2026)
\\ ( https://arxiv.org/abs/2503.10727 ,  1528kb)
------------------------------------------------------------------------------
\\
arXiv:2503.22006
replaced with revised version Mon, 24 Nov 2025 17:17:31 GMT   (66kb)

Title: Enhancing Domain-Specific Encoder Models with LLM-Generated Data: How to
 Leverage Ontologies, and How to Do Without Them
Authors: Marc Brinner, Tarek Al Mustafa, Sina Zarrie{\ss}
Categories: cs.CL cs.LG
Comments: Published in the Findings of the Association for Computational
 Linguistics: EMNLP 2025
Journal-ref: Findings of the Association for Computational Linguistics: EMNLP
 2025 (pp. 22740-22754). Association for Computational Linguistics
DOI: 10.18653/v1/2025.findings-emnlp.1238
\\ ( https://arxiv.org/abs/2503.22006 ,  66kb)
------------------------------------------------------------------------------
\\
arXiv:2504.02106
replaced with revised version Mon, 24 Nov 2025 17:00:44 GMT   (281kb)

Title: ContrastScore: Towards Higher Quality, Less Biased, More Efficient
 Evaluation Metrics with Contrastive Evaluation
Authors: Xiao Wang, Daniil Larionov, Siwei Wu, Yiqi Liu, Steffen Eger, Nafise
 Sadat Moosavi, Chenghua Lin
Categories: cs.CL
Comments: Accepted at AACL 2025 (Main Conference Paper)
\\ ( https://arxiv.org/abs/2504.02106 ,  281kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16570
replaced with revised version Mon, 24 Nov 2025 14:20:11 GMT   (526kb)

Title: URLs Help, Topics Guide: Understanding Metadata Utility in LLM Training
Authors: Dongyang Fan, Vinko Sabol\v{c}ec, Martin Jaggi
Categories: cs.CL
Comments: NeurIPS 2025, Camera Ready
\\ ( https://arxiv.org/abs/2505.16570 ,  526kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17086
replaced with revised version Mon, 24 Nov 2025 00:33:29 GMT   (503kb)

Title: Advancing Multi-Agent RAG Systems with Minimalist Reinforcement Learning
Authors: Yihong Wu, Liheng Ma, Muzhi Li, Jiaming Zhou, Lei Ding, Jianye Hao,
 Ho-fung Leung, Irwin King, Yingxue Zhang, Jian-Yun Nie
Categories: cs.CL
\\ ( https://arxiv.org/abs/2505.17086 ,  503kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17413
replaced with revised version Sun, 23 Nov 2025 10:56:01 GMT   (0kb,I)

Title: Conversations: Love Them, Hate Them, Steer Them
Authors: Niranjan Chebrolu, Gerard Christopher Yeo, Kokil Jaidka
Categories: cs.CL
Comments: We have created a new arXiv submission with a more up to date version
 of this paper at arXiv:2511.12832
\\ ( https://arxiv.org/abs/2505.17413 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19766
replaced with revised version Mon, 24 Nov 2025 08:41:00 GMT   (503kb)

Title: SGM: A Framework for Building Specification-Guided Moderation Filters
Authors: Masoomali Fatehkia, Enes Altinisik, Mohamed Osman, Husrev Taha Sencar
Categories: cs.CL
\\ ( https://arxiv.org/abs/2505.19766 ,  503kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20613
replaced with revised version Mon, 24 Nov 2025 06:18:18 GMT   (516kb)

Title: REAL-Prover: Retrieval Augmented Lean Prover for Mathematical Reasoning
Authors: Ziju Shen and Naohao Huang and Fanyi Yang and Yutong Wang and Guoxiong
 Gao and Tianyi Xu and Jiedong Jiang and Wanyi He and Pu Yang and Mengzhou Sun
 and Haocheng Ju and Peihao Wu and Bryan Dai and Bin Dong
Categories: cs.CL cs.AI cs.LG cs.LO
\\ ( https://arxiv.org/abs/2505.20613 ,  516kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21505
replaced with revised version Mon, 24 Nov 2025 17:10:38 GMT   (2933kb)

Title: How does Alignment Enhance LLMs' Multilingual Capabilities? A Language
 Neurons Perspective
Authors: Shimao Zhang, Zhejian Lai, Xiang Liu, Shuaijie She, Xiao Liu, Yeyun
 Gong, Shujian Huang, Jiajun Chen
Categories: cs.CL cs.AI
Comments: AAAI 2026 (Oral)
\\ ( https://arxiv.org/abs/2505.21505 ,  2933kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22061
replaced with revised version Mon, 24 Nov 2025 09:27:33 GMT   (285kb)

Title: Safeguarding Privacy of Retrieval Data against Membership Inference
 Attacks: Is This Query Too Close to Home?
Authors: Yujin Choi, Youngjoo Park, Junyoung Byun, Jaewook Lee, and Jinseong
 Park
Categories: cs.CL
Comments: Accepted for EMNLP findings 2025
DOI: 10.18653/v1/2025.findings-emnlp.438
\\ ( https://arxiv.org/abs/2505.22061 ,  285kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22120
replaced with revised version Sun, 23 Nov 2025 09:32:35 GMT   (158kb)

Title: LoKI: Low-damage Knowledge Implanting of Large Language Models
Authors: Runyu Wang, Peng Ping, Zhengyu Guo, Xiaoye Zhang, Quan Shi, Liting
 Zhou, Tianbo Ji
Categories: cs.CL
Comments: AAAI-26 Oral
\\ ( https://arxiv.org/abs/2505.22120 ,  158kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22633
replaced with revised version Sun, 23 Nov 2025 04:21:19 GMT   (5292kb)

Title: Spatial Knowledge Graph-Guided Multimodal Synthesis
Authors: Yida Xue, Zhen Bi, Jinnan Yang, Jungang Lou, Kehai Chen, Min Zhang,
 Huajun Chen, Ningyu Zhang
Categories: cs.CL cs.AI cs.CV cs.LG cs.MM
Comments: IEEE/ACM Transactions on Audio, Speech and Language Processing
\\ ( https://arxiv.org/abs/2505.22633 ,  5292kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23715
replaced with revised version Mon, 24 Nov 2025 08:35:39 GMT   (3768kb)

Title: Don't Take the Premise for Granted: Evaluating the Premise Critique
 Ability of Large Language Models
Authors: Jinzhe Li, Gengxu Li, Yi Chang, Yuan Wu
Categories: cs.CL
Comments: EMNLP 2025 Findings camera-ready version
\\ ( https://arxiv.org/abs/2505.23715 ,  3768kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23799
replaced with revised version Fri, 21 Nov 2025 21:24:07 GMT   (986kb)

Title: Estimating LLM Consistency: A User Baseline vs Surrogate Metrics
Authors: Xiaoyuan Wu, Weiran Lin, Omer Akgul, and Lujo Bauer
Categories: cs.CL cs.AI cs.HC cs.LG
Comments: Published as a main conference paper at EMNLP 2025
DOI: 10.18653/v1/2025.emnlp-main.1554
\\ ( https://arxiv.org/abs/2505.23799 ,  986kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07751
replaced with revised version Mon, 24 Nov 2025 14:29:20 GMT   (1373kb)

Title: AbstRaL: Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking
Authors: Silin Gao, Antoine Bosselut, Samy Bengio, Emmanuel Abbe
Categories: cs.CL cs.AI cs.SC
Comments: Under review
\\ ( https://arxiv.org/abs/2506.07751 ,  1373kb)
------------------------------------------------------------------------------
\\
arXiv:2506.11088
replaced with revised version Sun, 23 Nov 2025 14:25:05 GMT   (3629kb)

Title: One SPACE to Rule Them All: Jointly Mitigating Factuality and
 Faithfulness Hallucinations in LLMs
Authors: Pengbo Wang, Chaozhuo Li, Chenxu Wang, Liwen Zheng, Litian Zhang, Xi
 Zhang
Categories: cs.CL cs.AI
Comments: Accepted as NIPS 2025 poster
MSC-class: 68T50
Journal-ref: NeurIPS 2025
\\ ( https://arxiv.org/abs/2506.11088 ,  3629kb)
------------------------------------------------------------------------------
\\
arXiv:2506.12109
replaced with revised version Mon, 24 Nov 2025 00:58:45 GMT   (2842kb)

Title: Personalized LLM Decoding via Contrasting Personal Preference
Authors: Hyungjune Bu, Chanjoo Jung, Minjae Kang, Jaehyung Kim
Categories: cs.CL cs.AI
Comments: EMNLP 2025 Main
\\ ( https://arxiv.org/abs/2506.12109 ,  2842kb)
------------------------------------------------------------------------------
\\
arXiv:2506.17609
replaced with revised version Sat, 22 Nov 2025 23:54:21 GMT   (1140kb)

Title: TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track
 Forecasting
Authors: Lincan Li, Eren Erman Ozguven, Yue Zhao, Guang Wang, Yiqun Xie, Yushun
 Dong
Categories: cs.CL cs.LG
Comments: Accepted by ACM SIGSPATIAL 2025. Received SIGSPATIAL '25 Best Short
 Paper Award
\\ ( https://arxiv.org/abs/2506.17609 ,  1140kb)
------------------------------------------------------------------------------
\\
arXiv:2506.20495
replaced with revised version Sun, 23 Nov 2025 10:24:42 GMT   (963kb)

Title: ReCode: Updating Code API Knowledge with Reinforcement Learning
Authors: Haoze Wu, Yunzhi Yao, Wenhao Yu, Ningyu Zhang
Categories: cs.CL cs.AI cs.IR cs.LG cs.SE
Comments: AAAI 2026
\\ ( https://arxiv.org/abs/2506.20495 ,  963kb)
------------------------------------------------------------------------------
\\
arXiv:2508.03520
replaced with revised version Sun, 23 Nov 2025 08:21:26 GMT   (4207kb)

Title: UPLME: Uncertainty-Aware Probabilistic Language Modelling for Robust
 Empathy Regression
Authors: Md Rakibul Hasan, Md Zakir Hossain, Aneesh Krishna, Shafin Rahman, Tom
 Gedeon
Categories: cs.CL cs.LG
Comments: Code available at https://github.com/hasan-rakibul/UPLME
\\ ( https://arxiv.org/abs/2508.03520 ,  4207kb)
------------------------------------------------------------------------------
\\
arXiv:2508.04440
replaced with revised version Sat, 22 Nov 2025 15:35:57 GMT   (3180kb)

Title: StepFun-Formalizer: Unlocking the Autoformalization Potential of LLMs
 through Knowledge-Reasoning Fusion
Authors: Yutong Wu, Di Huang, Ruosi Wan, Yue Peng, Shijie Shang, Chenrui Cao,
 Lei Qi, Rui Zhang, Zidong Du, Jie Yan, Xing Hu
Categories: cs.CL cs.AI cs.LG
Comments: AAAI 2026 Oral. Extended version with full appendix, 25 pages, 17
 figures
\\ ( https://arxiv.org/abs/2508.04440 ,  3180kb)
------------------------------------------------------------------------------
\\
arXiv:2508.06447
replaced with revised version Mon, 24 Nov 2025 06:26:25 GMT   (480kb)

Title: SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token
 Pruning
Authors: Lingkun Long, Rubing Yang, Yushi Huang, Desheng Hui, Ao Zhou, Jianlei
 Yang
Categories: cs.CL
\\ ( https://arxiv.org/abs/2508.06447 ,  480kb)
------------------------------------------------------------------------------
\\
arXiv:2508.11009
replaced with revised version Mon, 24 Nov 2025 05:52:00 GMT   (760kb)

Title: SproutBench: A Benchmark for Safe and Ethical Large Language Models for
 Youth
Authors: Wenpeng Xing, Lanyi Wei, Haixiao Hu, Rongchang Li, Mohan Li, Changting
 Lin, Meng Han
Categories: cs.CL cs.AI
Comments: Accepted in AAAI 2026 Workshop on AI for Education
\\ ( https://arxiv.org/abs/2508.11009 ,  760kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08438
replaced with revised version Sat, 22 Nov 2025 03:44:47 GMT   (1361kb)

Title: CommonVoice-SpeechRE and RPG-MoGe: Advancing Speech Relation Extraction
 with a New Dataset and Multi-Order Generative Framework
Authors: Jinzhong Ning, Paerhati Tulajiang, Yingying Le, Yijia Zhang, Yuanyuan
 Sun, Hongfei Lin, Haifeng Liu
Categories: cs.CL cs.MM cs.SD eess.AS
\\ ( https://arxiv.org/abs/2509.08438 ,  1361kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09711
replaced with revised version Sun, 23 Nov 2025 15:40:27 GMT   (5943kb)

Title: PsychiatryBench: A Multi-Task Benchmark for LLMs in Psychiatry
Authors: Aya E. Fouda, Abdelrahamn A. Hassan, Radwa J. Hanafy and Mohammed E.
 Fouda
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2509.09711 ,  5943kb)
------------------------------------------------------------------------------
\\
arXiv:2509.15216
replaced with revised version Sun, 23 Nov 2025 17:53:06 GMT   (802kb)

Title: Assessing Historical Structural Oppression Worldwide via Rule-Guided
 Prompting of Large Language Models
Authors: Sreejato Chatterjee, Linh Tran, Quoc Duy Nguyen, Roni Kirson, Drue
 Hamlin, Harvest Aquino, Hanjia Lyu, Jiebo Luo, Timothy Dye
Categories: cs.CL cs.CY
Comments: To appear in the 2025 IEEE International Conference on Big Data (IEEE
 BigData 2025)
\\ ( https://arxiv.org/abs/2509.15216 ,  802kb)
------------------------------------------------------------------------------
\\
arXiv:2509.15478
replaced with revised version Fri, 21 Nov 2025 20:59:11 GMT   (960kb)

Title: Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt
 Modalities and Models
Authors: Madison Van Doren and Casey Ford
Categories: cs.CL
Journal-ref: AAAI 2026 AIGOV Workshop and EurIPS 2025 Workshop on Unifying
 Perspectives on Learning Biases
\\ ( https://arxiv.org/abs/2509.15478 ,  960kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19580
replaced with revised version Sun, 23 Nov 2025 22:45:29 GMT   (11227kb)

Title: LLMs4All: A Review of Large Language Models Across Academic Disciplines
Authors: Yanfang Ye, Zheyuan Zhang, Tianyi Ma, Zehong Wang, Yiyang Li, Shifu
 Hou, Weixiang Sun, Kaiwen Shi, Yijun Ma, Wei Song, Ahmed Abbasi, Ying Cheng,
 Jane Cleland-Huang, Steven Corcelli, Robert Goulding, Ming Hu, Ting Hua, John
 Lalor, Fang Liu, Tengfei Luo, Edward Maginn, Nuno Moniz, Jason Rohr, Brett
 Savoie, Daniel Slate, Matthew Webber, Olaf Wiest, Johnny Zhang, Nitesh V.
 Chawla
Categories: cs.CL
\\ ( https://arxiv.org/abs/2509.19580 ,  11227kb)
------------------------------------------------------------------------------
\\
arXiv:2509.26160
replaced with revised version Sat, 22 Nov 2025 19:21:30 GMT   (212kb)

Title: MGen: Millions of Naturally Occurring Generics in Context
Authors: Gustavo Cilleruelo, Emily Allaway, Barry Haddow, Alexandra Birch
Categories: cs.CL
Comments: Presented at SCiL 2025
Journal-ref: Society for Computation in Linguistics, Volume 8 (2025)
DOI: 10.7275/scil.3147
\\ ( https://arxiv.org/abs/2509.26160 ,  212kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02712
replaced with revised version Sun, 23 Nov 2025 22:18:51 GMT   (76kb)

Title: Time-To-Inconsistency: A Survival Analysis of Large Language Model
 Robustness to Adversarial Attacks
Authors: Yubo Li, Ramayya Krishnan, Rema Padman
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2510.02712 ,  76kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02855
replaced with revised version Sat, 22 Nov 2025 03:07:06 GMT   (0kb,I)

Title: Constraint Satisfaction Approaches to Wordle: Novel Heuristics and
 Cross-Lexicon Validation
Authors: Jahidul Arafat, Fariha Tasmin, Sanjaya Poudel
Categories: cs.CL cs.AI
Comments: Require some correction on the paper with some title and methodology
 changes. I will resubmit later
MSC-class: 68T20, 90C27
ACM-class: I.2.8; I.2.3; G.1.6
\\ ( https://arxiv.org/abs/2510.02855 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03805
replaced with revised version Sat, 22 Nov 2025 13:19:00 GMT   (1781kb)

Title: Beyond Token Length: Step Pruner for Efficient and Accurate Reasoning in
 Large Language Models
Authors: Canhui Wu, Qiong Cao, Chang Li, Zhenfang Wang, Chao Xue, Yuwei Fan,
 Wei Xi, and Xiaodong He
Categories: cs.CL cs.AI
Comments: 21pages, 9 figures
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2510.03805 ,  1781kb)
------------------------------------------------------------------------------
\\
arXiv:2510.07777
replaced with revised version Fri, 21 Nov 2025 19:11:25 GMT   (6691kb)

Title: Drift No More? Context Equilibria in Multi-Turn LLM Interactions
Authors: Vardhan Dongre, Ryan A. Rossi, Viet Dac Lai, David Seunghyun Yoon,
 Dilek Hakkani-T\"ur, Trung Bui
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2510.07777 ,  6691kb)
------------------------------------------------------------------------------
\\
arXiv:2510.07793
replaced with revised version Sun, 23 Nov 2025 05:07:35 GMT   (3803kb)

Title: LLM4Cell: A Survey of Large Language and Agentic Models for Single-Cell
 Biology
Authors: Sajib Acharjee Dip, Adrika Zafor, Bikash Kumar Paul, Uddip Acharjee
 Shuvo, Muhit Islam Emon, Xuan Wang, Liqing Zhang
Categories: cs.CL cs.AI
Comments: 34 pages, 5 figures, 7 tables
\\ ( https://arxiv.org/abs/2510.07793 ,  3803kb)
------------------------------------------------------------------------------
\\
arXiv:2510.08630
replaced with revised version Sun, 23 Nov 2025 10:32:57 GMT   (7485kb)

Title: ExPO-HM: Learning to Explain-then-Detect for Hateful Meme Detection
Authors: Jingbiao Mei, Mingsheng Sun, Jinghong Chen, Pengda Qin, Yuhong Li, Da
 Chen, Bill Byrne
Categories: cs.CL
Comments: Preprint
\\ ( https://arxiv.org/abs/2510.08630 ,  7485kb)
------------------------------------------------------------------------------
\\
arXiv:2510.08663
replaced with revised version Sun, 23 Nov 2025 19:31:46 GMT   (2560kb)

Title: A Novel Framework for Augmenting Rating Scale Tests with LLM-Scored Text
 Data
Authors: Joe Watson, Ivan O'Connor, Chia-Wen Chen, Luning Sun, Fang Luo and
 David Stillwell
Categories: cs.CL cs.AI cs.CY
\\ ( https://arxiv.org/abs/2510.08663 ,  2560kb)
------------------------------------------------------------------------------
\\
arXiv:2510.13912
replaced with revised version Sat, 22 Nov 2025 15:58:45 GMT   (1953kb)

Title: AI Debaters are More Persuasive when Arguing in Alignment with Their Own
 Beliefs
Authors: Mar\'ia Victoria Carro, Denise Alejandra Mester, Facundo Nieto, Oscar
 Agust\'in Stanchi, Guido Ernesto Bergman, Mario Alejandro Leiva, Eitan
 Sprejer, Luca Nicol\'as Forziati Gangi, Francisca Gauna Selasco, Juan Gustavo
 Corval\'an, Gerardo I. Simari, Mar\'ia Vanina Martinez
Categories: cs.CL cs.AI
Comments: 31 pages
\\ ( https://arxiv.org/abs/2510.13912 ,  1953kb)
------------------------------------------------------------------------------
\\
arXiv:2510.24591
replaced with revised version Sun, 23 Nov 2025 18:13:34 GMT   (1312kb)

Title: ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?
Authors: Christine Ye, Sihan Yuan, Suchetha Cooray, Steven Dillmann, Ian L. V.
 Roque, Dalya Baron, Philipp Frank, Sergio Martin-Alvarez, Nolan Koblischke,
 Frank J Qu, Diyi Yang, Risa Wechsler, Ioana Ciuca
Categories: cs.CL astro-ph.IM
\\ ( https://arxiv.org/abs/2510.24591 ,  1312kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05080
replaced with revised version Fri, 21 Nov 2025 23:48:11 GMT   (13540kb)

Title: An Architectural Advantage of The Instruction-Tuned LLM in Containing
 The Readability-Accuracy Tension in Text Simplification
Authors: P. Bilha Githinji, Aikaterini Meilliou, Zeming Liang, Lian Zhang,
 Peiwu Qin
Categories: cs.CL
\\ ( https://arxiv.org/abs/2511.05080 ,  13540kb)
------------------------------------------------------------------------------
\\
arXiv:2511.09222
replaced with revised version Sat, 22 Nov 2025 05:11:03 GMT   (113kb)

Title: Toward Honest Language Models for Deductive Reasoning
Authors: Jiarui Liu, Kaustubh Dhole, Yingheng Wang, Haoyang Wen, Sarah Zhang,
 Haitao Mao, Gaotang Li, Neeraj Varshney, Jingguo Liu, Xiaoman Pan
Categories: cs.CL
\\ ( https://arxiv.org/abs/2511.09222 ,  113kb)
------------------------------------------------------------------------------
\\
arXiv:2511.10659
replaced with revised version Mon, 24 Nov 2025 18:25:34 GMT   (59kb)

Title: Information Extraction From Fiscal Documents Using LLMs
Authors: Vikram Aggarwal and Jay Kulkarni and Aditi Mascarenhas and Aakriti
 Narang and Siddarth Raman and Ajay Shah and Susan Thomas
Categories: cs.CL cs.IR
Comments: 6 pages. Presented at the AI for Financial Inclusion, Risk Modeling
 and Resilience in Emerging Markets workshop at ACM ICAIF 2025 Singapore
\\ ( https://arxiv.org/abs/2511.10659 ,  59kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12609
replaced with revised version Sun, 23 Nov 2025 09:18:13 GMT   (9070kb)

Title: Uni-MoE-2.0-Omni: Scaling Language-Centric Omnimodal Large Model with
 Advanced MoE, Training and Data
Authors: Yunxin Li, Xinyu Chen, Shenyuan Jiang, Haoyuan Shi, Zhenyu Liu, Xuanyu
 Zhang, Nanhao Deng, Zhenran Xu, Yicheng Ma, Meishan Zhang, Baotian Hu, Min
 Zhang
Categories: cs.CL cs.AI cs.CV
Comments: 47 pages,10 Figures, Project Website:
 https://idealistxy.github.io/Uni-MoE-v2.github.io/ Codes:
 https://github.com/HITsz-TMG/Uni-MoE
\\ ( https://arxiv.org/abs/2511.12609 ,  9070kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13467
replaced with revised version Sun, 23 Nov 2025 22:43:55 GMT   (744kb)

Title: Non-Linear Scoring Model for Translation Quality Evaluation
Authors: Serge Gladkoff, Lifeng Han, Katerina Gasova
Categories: cs.CL
Comments: ongoing work, 38 pages
\\ ( https://arxiv.org/abs/2511.13467 ,  744kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13590
replaced with revised version Mon, 24 Nov 2025 08:48:39 GMT   (1345kb)

Title: Beyond SELECT: A Comprehensive Taxonomy-Guided Benchmark for Real-World
 Text-to-SQL Translation
Authors: Hao Wang, Yuanfeng Song, Xiaoming Yin, Xing Chen
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2511.13590 ,  1345kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14258
replaced with revised version Mon, 24 Nov 2025 10:36:50 GMT   (1383kb)

Title: Entropy-Guided Reasoning Compression
Authors: Hourun Zhu and Yang Gao and Wenlong Fei and Jiawei Li and Huashan Sun
Categories: cs.CL
Comments: 10pages, 4 figures
\\ ( https://arxiv.org/abs/2511.14258 ,  1383kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14709
replaced with revised version Mon, 24 Nov 2025 16:42:33 GMT   (4486kb)

Title: Strategic Innovation Management in the Age of Large Language Models
 Market Intelligence, Adaptive R&D, and Ethical Governance
Authors: Raha Aghaei, Ali A. Kiaei, Mahnaz Boush, Mahan Rofoosheh, Mohammad
 Zavvar
Categories: cs.CL
\\ ( https://arxiv.org/abs/2511.14709 ,  4486kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14774
replaced with revised version Fri, 21 Nov 2025 20:24:19 GMT   (1205kb)

Title: LiveCLKTBench: Towards Reliable Evaluation of Cross-Lingual Knowledge
 Transfer in Multilingual LLMs
Authors: Pei-Fu Guo, Yun-Da Tsai, Chun-Chia Hsu, Kai-Xin Chen, Ya-An Tsai,
 Kai-Wei Chang, Nanyun Peng, Mi-Yen Yeh, Shou-De Lin
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2511.14774 ,  1205kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16654
replaced with revised version Sun, 23 Nov 2025 00:38:47 GMT   (169kb)

Title: Comparison of Text-Based and Image-Based Retrieval in Multimodal
 Retrieval Augmented Generation Large Language Model Systems
Authors: Elias Lumer and Alex Cardenas and Matt Melich and Myles Mason and Sara
 Dieter and Vamse Kumar Subbiah and Pradeep Honaganahalli Basavaraju and
 Roberto Hernandez
Categories: cs.CL
\\ ( https://arxiv.org/abs/2511.16654 ,  169kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16685
replaced with revised version Mon, 24 Nov 2025 03:32:27 GMT   (2446kb)

Title: Ellipsoid-Based Decision Boundaries for Open Intent Classification
Authors: Yuetian Zou, Hanlei Zhang, Hua Xu, Songze Li, Long Xiao
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2511.16685 ,  2446kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17405
replaced with revised version Mon, 24 Nov 2025 02:45:02 GMT   (5074kb)

Title: Beyond Multiple Choice: Verifiable OpenQA for Robust Vision-Language RFT
Authors: Yesheng Liu, Hao Li, Haiyu Xu, Baoqi Pei, Jiahao Wang, Mingxuan Zhao,
 Jingshu Zheng, Zheqi He, JG Yao, Bowen Qin, Xi Yang, Jiajun Zhang
Categories: cs.CL cs.AI
Comments: Project url: https://flageval-baai.github.io/ReVeL/
\\ ( https://arxiv.org/abs/2511.17405 ,  5074kb)
------------------------------------------------------------------------------
\\
arXiv:1802.04723
replaced with revised version Sat, 22 Nov 2025 21:48:41 GMT   (86kb)

Title: The Shape of Sight: A Homological Framework for Unifying Visual
 Perception
Authors: Xin Li
Categories: cs.CV
\\ ( https://arxiv.org/abs/1802.04723 ,  86kb)
------------------------------------------------------------------------------
\\
arXiv:2103.02211
replaced with revised version Mon, 24 Nov 2025 09:20:42 GMT   (7015kb)

Title: K-FACE: A Large-Scale KIST Face Database in Consideration with
 Unconstrained Environments
Authors: Yeji Choi, Hyunjung Park, Gi Pyo Nam, Haksub Kim, Heeseung Choi,
 Junghyun Cho, Ig-Jae Kim
Categories: cs.CV cs.DB
Comments: 8 pages, 8 figures
\\ ( https://arxiv.org/abs/2103.02211 ,  7015kb)
------------------------------------------------------------------------------
\\
arXiv:2201.00708
replaced with revised version Mon, 24 Nov 2025 15:58:39 GMT   (5826kb)

Title: Multiview point cloud registration with anisotropic and space-varying
 localization noise
Authors: Denis Fortun, Etienne Baudrier, Fabian Zwettler, Markus Sauer and
 Sylvain Faisan
Categories: cs.CV
Journal-ref: SIAM Journal on Imaging Sciences, 2025, 18(1), pp.280-307
DOI: 10.1137/24M1632401
\\ ( https://arxiv.org/abs/2201.00708 ,  5826kb)
------------------------------------------------------------------------------
\\
arXiv:2304.12630
replaced with revised version Sun, 23 Nov 2025 08:48:54 GMT   (872kb)

Title: Spatiotemporal Graph Convolutional Recurrent Neural Network Model for
 Citywide Air Pollution Forecasting
Authors: Van-Duc Le, Tien-Cuong Bui and Sang-Kyun Cha
Categories: cs.CV cs.LG eess.SP
Comments: Updated metadata
\\ ( https://arxiv.org/abs/2304.12630 ,  872kb)
------------------------------------------------------------------------------
\\
arXiv:2310.17218
replaced with revised version Mon, 24 Nov 2025 09:30:49 GMT   (256kb)

Title: Prototypical Contrastive Learning-based CLIP Fine-tuning for Object
 Re-identification
Authors: Jiachen Li and Xiaojin Gong
Categories: cs.CV
\\ ( https://arxiv.org/abs/2310.17218 ,  256kb)
------------------------------------------------------------------------------
\\
arXiv:2311.17940
replaced with revised version Sun, 23 Nov 2025 13:07:52 GMT   (22102kb)

Title: Scene Summarization: Clustering Scene Videos into Spatially Diverse
 Frames
Authors: Chao Chen, Mingzhi Zhu, Ankush Pratap Singh, Yu Yan, Felix Juefei-Xu,
 Chen Feng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2311.17940 ,  22102kb)
------------------------------------------------------------------------------
\\
arXiv:2404.01064
replaced with revised version Mon, 24 Nov 2025 09:12:46 GMT   (4713kb)

Title: Roadside Monocular 3D Detection Prompted by 2D Detection
Authors: Yechi Ma, Yanan Li, Wei Hua, Shu Kong
Categories: cs.CV
Comments: Accepted by WACV 2026
\\ ( https://arxiv.org/abs/2404.01064 ,  4713kb)
------------------------------------------------------------------------------
\\
arXiv:2405.13859
replaced with revised version Mon, 24 Nov 2025 04:44:49 GMT   (1281kb)

Title: QGait: Toward Accurate Quantization for Gait Recognition
Authors: Senmao Tian, Haoyu Gao, Gangyi Hong, Shuyun Wang, JingJie Wang, Xin
 Yu, Shunli Zhang
Categories: cs.CV
Comments: Accepted as an oral presentation at IJCB 2025
\\ ( https://arxiv.org/abs/2405.13859 ,  1281kb)
------------------------------------------------------------------------------
\\
arXiv:2405.18716
replaced with revised version Mon, 24 Nov 2025 18:15:06 GMT   (45822kb)

Title: SketchDeco: Training-Free Latent Composition for Precise Sketch
 Colourisation
Authors: Chaitat Utintu, Pinaki Nath Chowdhury, Aneeshan Sain, Subhadeep Koley,
 Ayan Kumar Bhunia, Yi-Zhe Song
Categories: cs.CV
Comments: Project Page: \url{https://chaitron.github.io/SketchDeco/}
\\ ( https://arxiv.org/abs/2405.18716 ,  45822kb)
------------------------------------------------------------------------------
\\
arXiv:2406.18572
replaced with revised version Sat, 22 Nov 2025 11:58:41 GMT   (10075kb)

Title: GeoReasoner: Geo-localization with Reasoning in Street Views using a
 Large Vision-Language Model
Authors: Ling Li, Yu Ye, Yao Zhou, Bingchuan Jiang, Wei Zeng
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2406.18572 ,  10075kb)
------------------------------------------------------------------------------
\\
arXiv:2409.05352
replaced with revised version Sun, 23 Nov 2025 14:38:54 GMT   (36703kb)

Title: PriorDrive: Enhancing Online HD Mapping with Unified Vector Priors
Authors: Shuang Zeng, Xinyuan Chang, Xinran Liu, Yujian Yuan, Shiyi Liang,
 Zheng Pan, Mu Xu, Xing Wei
Categories: cs.CV
Comments: AAAI 2026; Code: https://github.com/MIV-XJTU/PriorDrive
\\ ( https://arxiv.org/abs/2409.05352 ,  36703kb)
------------------------------------------------------------------------------
\\
arXiv:2409.08840
replaced with revised version Mon, 24 Nov 2025 09:31:39 GMT   (2846kb)

Title: Directed-CP: Directed Collaborative Perception for Connected and
 Autonomous Vehicles via Proactive Attention
Authors: Yihang Tao, Senkang Hu, Zhengru Fang, and Yuguang Fang
Categories: cs.CV
Comments: Accepted by ICRA'25
\\ ( https://arxiv.org/abs/2409.08840 ,  2846kb)
------------------------------------------------------------------------------
\\
arXiv:2410.08229
replaced with revised version Sat, 22 Nov 2025 10:41:00 GMT   (824kb)

Title: Improvement of Spiking Neural Network with Bit Planes and Color Models
Authors: Nhan T. Luu, Duong T. Luu, Nam N. Pham, Thang C. Truong
Categories: cs.CV cs.NE eess.IV
Comments: Accepted for publication at IEEE Access
DOI: 10.1109/ACCESS.2025.3635297
\\ ( https://arxiv.org/abs/2410.08229 ,  824kb)
------------------------------------------------------------------------------
\\
arXiv:2411.03511
replaced with revised version Mon, 24 Nov 2025 10:52:17 GMT   (29892kb)

Title: Beyond Complete Shapes: A Benchmark for Quantitative Evaluation of 3D
 Shape Surface Matching Algorithms
Authors: Viktoria Ehm, Nafie El Amrani, Yizheng Xie, Lennart Bastian, Maolin
 Gao, Weikang Wang, Lu Sang, Dongliang Cao, Tobias Wei{\ss}berg, Zorah
 L\"ahner, Daniel Cremers, Florian Bernard
Categories: cs.CV
\\ ( https://arxiv.org/abs/2411.03511 ,  29892kb)
------------------------------------------------------------------------------
\\
arXiv:2411.13093
replaced with revised version Sun, 23 Nov 2025 03:32:42 GMT   (5532kb)

Title: Video-RAG: Visually-aligned Retrieval-Augmented Long Video Comprehension
Authors: Yongdong Luo, Xiawu Zheng, Guilin Li, Shukang Yin, Haojia Lin, Chaoyou
 Fu, Jinfa Huang, Jiayi Ji, Fei Chao, Jiebo Luo, Rongrong Ji
Categories: cs.CV cs.AI
Comments: Accepted at NeurIPS 2025. Camera-ready version
\\ ( https://arxiv.org/abs/2411.13093 ,  5532kb)
------------------------------------------------------------------------------
\\
arXiv:2411.15349
replaced with revised version Mon, 24 Nov 2025 16:01:24 GMT   (10926kb)

Title: Zero-Shot Coreset Selection via Iterative Subspace Sampling
Authors: Brent A. Griffin, Jacob Marks, Jason J. Corso
Categories: cs.CV
Comments: WACV 2026
\\ ( https://arxiv.org/abs/2411.15349 ,  10926kb)
------------------------------------------------------------------------------
\\
arXiv:2411.17991
replaced with revised version Sun, 23 Nov 2025 15:20:54 GMT   (3953kb)

Title: VideoLLM Knows When to Speak: Enhancing Time-Sensitive Video
 Comprehension with Video-Text Duet Interaction Format
Authors: Yueqian Wang, Xiaojun Meng, Yuxuan Wang, Jianxin Liang, Jiansheng Wei,
 Huishuai Zhang, Dongyan Zhao
Categories: cs.CV cs.CL
Comments: 9 pages
\\ ( https://arxiv.org/abs/2411.17991 ,  3953kb)
------------------------------------------------------------------------------
\\
arXiv:2412.01558
replaced with revised version Mon, 24 Nov 2025 16:17:57 GMT   (3250kb)

Title: VideoLights: Feature Refinement and Cross-Task Alignment Transformer for
 Joint Video Highlight Detection and Moment Retrieval
Authors: Dhiman Paul, Md Rizwan Parvez, Nabeel Mohammed, Shafin Rahman
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2412.01558 ,  3250kb)
------------------------------------------------------------------------------
\\
arXiv:2412.03121
replaced with revised version Mon, 24 Nov 2025 13:39:34 GMT   (6609kb)

Title: Splats in Splats: Robust and Effective 3D Steganography towards Gaussian
 Splatting
Authors: Yijia Guo, Wenkai Huang, Yang Li, Gaolei Li, Hang Zhang, Liwen Hu,
 Jianhua Li, Tiejun Huang, Lei Ma
Categories: cs.CV eess.IV
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2412.03121 ,  6609kb)
------------------------------------------------------------------------------
\\
arXiv:2412.07608
replaced with revised version Mon, 24 Nov 2025 01:58:56 GMT   (36794kb)

Title: Faster and Better 3D Splatting via Group Training
Authors: Chengbo Wang, Guozheng Ma, Yifei Xue, Yizhen Lao
Categories: cs.CV
Comments: Accepted to ICCV 2025. Code is available at
 https://github.com/Chengbo-Wang/3DGS-with-Group-Training
\\ ( https://arxiv.org/abs/2412.07608 ,  36794kb)
------------------------------------------------------------------------------
\\
arXiv:2501.01119
replaced with revised version Sun, 23 Nov 2025 03:31:13 GMT   (41310kb)

Title: Leverage Cross-Attention for End-to-End Open-Vocabulary Panoptic
 Reconstruction
Authors: Xuan Yu, Yuxuan Xie, Yili Liu, Haojian Lu, Rong Xiong, Yiyi Liao, and
 Yue Wang
Categories: cs.CV cs.RO
Comments: 18 pages, 10 figures
\\ ( https://arxiv.org/abs/2501.01119 ,  41310kb)
------------------------------------------------------------------------------
\\
arXiv:2501.03931
replaced with revised version Sat, 22 Nov 2025 15:24:09 GMT   (38780kb)

Title: MagicMirror: ID-Preserved Video Generation in Video Diffusion
 Transformers
Authors: Yuechen Zhang, Yaoyang Liu, Bin Xia, Bohao Peng, Zexin Yan, Eric Lo,
 Jiaya Jia
Categories: cs.CV
Comments: ICCV 2025, It is best viewed in Acrobat. Project Page:
 https://julianjuaner.github.io/projects/MagicMirror/
\\ ( https://arxiv.org/abs/2501.03931 ,  38780kb)
------------------------------------------------------------------------------
\\
arXiv:2501.12104
replaced with revised version Mon, 24 Nov 2025 11:06:07 GMT   (4901kb)

Title: Teacher Encoder-Student Decoder Denoising Guided Segmentation Network
 for Anomaly Detection
Authors: Shixuan Song, Hao Chen, Shu Hu, Xin Wang, Jinrong Hu, Xi Wu
Categories: cs.CV cs.AI
Journal-ref: Neural Information Processing. ICONIP 2025. Communications in
 Computer and Information Science, vol 2758, pp. 238-253
DOI: 10.1007/978-981-95-4109-6_17
\\ ( https://arxiv.org/abs/2501.12104 ,  4901kb)
------------------------------------------------------------------------------
\\
arXiv:2502.00392
replaced with revised version Mon, 24 Nov 2025 02:48:47 GMT   (15667kb)

Title: RefDrone: A Challenging Benchmark for Referring Expression Comprehension
 in Drone Scenes
Authors: Zhichao Sun, Yepeng Liu, Zhiling Su, Huachao Zhu, Yuliang Gu, Yuda
 Zou, Zelong Liu, Gui-Song Xia, Bo Du, Yongchao Xu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2502.00392 ,  15667kb)
------------------------------------------------------------------------------
\\
arXiv:2502.03726
replaced with revised version Mon, 24 Nov 2025 06:51:25 GMT   (33870kb)

Title: DICE: Distilling Classifier-Free Guidance into Text Embeddings
Authors: Zhenyu Zhou, Defang Chen, Can Wang, Chun Chen, Siwei Lyu
Categories: cs.CV
Comments: AAAI 2026 (Oral)
\\ ( https://arxiv.org/abs/2502.03726 ,  33870kb)
------------------------------------------------------------------------------
\\
arXiv:2502.06755
replaced with revised version Fri, 21 Nov 2025 19:53:52 GMT   (33015kb)

Title: Interpretable and Testable Vision Features via Sparse Autoencoders
Authors: Samuel Stevens, Wei-Lun Chao, Tanya Berger-Wolf, Yu Su
Categories: cs.CV
Comments: Main text is 10 pages with 7 figures
\\ ( https://arxiv.org/abs/2502.06755 ,  33015kb)
------------------------------------------------------------------------------
\\
arXiv:2502.07331
replaced with revised version Mon, 24 Nov 2025 03:20:33 GMT   (2198kb)

Title: ERANet: Edge Replacement Augmentation for Semi-Supervised Meniscus
 Segmentation with Prototype Consistency Alignment and Conditional
 Self-Training
Authors: Siyue Li, Yongcheng Yao, Junru Zhong, Shutian Zhao, Fan Xiao, Tim-Yun
 Michael Ong, Ki-Wai Kevin Ho, James F. Griffith, Yudong Zhang, Shuihua Wang,
 Jin Hong, Weitian Chen
Categories: cs.CV
\\ ( https://arxiv.org/abs/2502.07331 ,  2198kb)
------------------------------------------------------------------------------
\\
arXiv:2502.17852
replaced with revised version Mon, 24 Nov 2025 07:57:57 GMT   (12400kb)

Title: Sketch-1-to-3: One Single Sketch to 3D Detailed Face Reconstruction
Authors: Liting Wen, Zimo Yang, Xianlin Zhang, Chi Ding, Mingdao Wang, Xueming
 Li
Categories: cs.CV
Comments: Accepted by ACM MMAsia 2025
\\ ( https://arxiv.org/abs/2502.17852 ,  12400kb)
------------------------------------------------------------------------------
\\
arXiv:2503.00450
replaced with revised version Mon, 24 Nov 2025 10:28:28 GMT   (2613kb)

Title: Unsupervised and Source-Free Ranking of Biomedical Segmentation Models
Authors: Joshua Talks, Kevin Marchesini, Luca Lumetti, Federico Bolelli, Anna
 Kreshuk
Categories: cs.CV
Comments: 24 pages, 6 figures
\\ ( https://arxiv.org/abs/2503.00450 ,  2613kb)
------------------------------------------------------------------------------
\\
arXiv:2503.01347
replaced with revised version Mon, 24 Nov 2025 10:34:13 GMT   (3380kb)

Title: From Spots to Pixels: Dense Spatial Gene Expression Prediction from
 Histology Images
Authors: Ruikun Zhang, Yan Yang, Liyuan Pan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.01347 ,  3380kb)
------------------------------------------------------------------------------
\\
arXiv:2503.02916
replaced with revised version Mon, 24 Nov 2025 08:57:24 GMT   (5840kb)

Title: Monocular Person Localization under Camera Ego-motion
Authors: Yu Zhan, Hanjing Ye, Hong Zhang
Categories: cs.CV cs.RO
Comments: Accepted by IROS2025. Project page:
 https://medlartea.github.io/rpf-quadruped/
\\ ( https://arxiv.org/abs/2503.02916 ,  5840kb)
------------------------------------------------------------------------------
\\
arXiv:2503.10638
replaced with revised version Mon, 24 Nov 2025 05:01:32 GMT   (17458kb)

Title: Studying Classifier(-Free) Guidance From a Classifier-Centric
 Perspective
Authors: Xiaoming Zhao, Alexander G. Schwing
Categories: cs.CV cs.AI cs.LG
Comments: v3: AAAI 2026; v2: added derivation details in Appendix A
\\ ( https://arxiv.org/abs/2503.10638 ,  17458kb)
------------------------------------------------------------------------------
\\
arXiv:2503.12953
replaced with revised version Sun, 23 Nov 2025 03:57:50 GMT   (36180kb)

Title: Frame-wise Conditioning Adaptation for Fine-Tuning Diffusion Models in
 Text-to-Video Prediction
Authors: Zheyuan Liu, Junyan Wang, Zicheng Duan, Cristian Rodriguez-Opazo,
 Anton van den Hengel
Categories: cs.CV
Comments: Accepted by TMLR, 11/2025. 29 pages, 15 figures
\\ ( https://arxiv.org/abs/2503.12953 ,  36180kb)
------------------------------------------------------------------------------
\\
arXiv:2503.16284
replaced with revised version Sun, 23 Nov 2025 16:34:04 GMT   (5763kb)

Title: PSA-MIL: A Probabilistic Spatial Attention-Based Multiple Instance
 Learning for Whole Slide Image Classification
Authors: Sharon Peled, Yosef E. Maruvka, Moti Freiman
Categories: cs.CV
Comments: Proceedings of the IEEE/CVF Winter Conference on Applications of
 Computer Vision (WACV), 2026
\\ ( https://arxiv.org/abs/2503.16284 ,  5763kb)
------------------------------------------------------------------------------
\\
arXiv:2503.18414
replaced with revised version Mon, 24 Nov 2025 14:03:50 GMT   (2174kb)

Title: U-REPA: Aligning Diffusion U-Nets to ViTs
Authors: Yuchuan Tian, Hanting Chen, Mengyu Zheng, Yuchen Liang, Chao Xu, Yunhe
 Wang
Categories: cs.CV
Comments: 22 pages, 7 figures
\\ ( https://arxiv.org/abs/2503.18414 ,  2174kb)
------------------------------------------------------------------------------
\\
arXiv:2503.22174
replaced with revised version Mon, 24 Nov 2025 07:45:44 GMT   (4733kb)

Title: Synergistic Bleeding Region and Point Detection in Laparoscopic Surgical
 Videos
Authors: Jialun Pei, Zhangjun Zhou, Diandian Guo, Zhixi Li, Jing Qin, Bo Du,
 Pheng-Ann Heng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.22174 ,  4733kb)
------------------------------------------------------------------------------
\\
arXiv:2503.23035
replaced with revised version Sun, 23 Nov 2025 14:32:04 GMT   (21554kb)

Title: FreeInv: Free Lunch for Improving DDIM Inversion
Authors: Yuxiang Bao, Huijie Liu, Xun Gao, Huan Fu, Guoliang Kang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.23035 ,  21554kb)
------------------------------------------------------------------------------
\\
arXiv:2503.23951
replaced with revised version Mon, 24 Nov 2025 07:22:57 GMT   (12447kb)

Title: JointTuner: Appearance-Motion Adaptive Joint Training for Customized
 Video Generation
Authors: Fangda Chen, Shanshan Zhao, Chuanfu Xu, Long Lan
Categories: cs.CV
Comments: Project Page: https://fdchen24.github.io/JointTuner-Website
\\ ( https://arxiv.org/abs/2503.23951 ,  12447kb)
------------------------------------------------------------------------------
\\
arXiv:2504.01632
replaced with revised version Mon, 24 Nov 2025 14:54:55 GMT   (5438kb)

Title: Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial
 Localized Corruptions
Authors: Giulia Marchiori Pietrosanti, Giulio Rossolini, Alessandro Biondi,
 Giorgio Buttazzo
Categories: cs.CV cs.AI
Comments: Accepted for publication in Pattern Recognition
Journal-ref: Pattern Recognition 172 (2026): 112412
DOI: 10.1016/j.patcog.2025.112412
\\ ( https://arxiv.org/abs/2504.01632 ,  5438kb)
------------------------------------------------------------------------------
\\
arXiv:2504.05662
replaced with revised version Sat, 22 Nov 2025 02:04:31 GMT   (6648kb)

Title: InvAD: Inversion-based Reconstruction-Free Anomaly Detection with
 Diffusion Models
Authors: Shunsuke Sakai, Xiangteng He, Chunzhi Gu, Leonid Sigal, Tatsuhito
 Hasegawa
Categories: cs.CV
Comments: Code is available at https://github.com/SkyShunsuke/InversionAD
\\ ( https://arxiv.org/abs/2504.05662 ,  6648kb)
------------------------------------------------------------------------------
\\
arXiv:2504.06144
replaced with revised version Sun, 23 Nov 2025 17:13:26 GMT   (26438kb)

Title: A Training-Free Style-aligned Image Generation with Scale-wise
 Autoregressive Model
Authors: Jihun Park, Jongmin Gim, Kyoungmin Lee, Minseok Oh, Minwoo Choi,
 Jaeyeul Kim, Woo Chool Park and Sunghoon Im
Categories: cs.CV
Comments: 18 pages, 15 figures
\\ ( https://arxiv.org/abs/2504.06144 ,  26438kb)
------------------------------------------------------------------------------
\\
arXiv:2504.19687
replaced with revised version Sat, 22 Nov 2025 13:16:00 GMT   (1458kb)

Title: Prompt Guiding Multi-Scale Adaptive Sparse Representation-driven Network
 for Low-Dose CT MAR
Authors: Baoshun Shi, Bing Chen, Shaolei Zhang, Huazhu Fu, and Zhanli Hu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2504.19687 ,  1458kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16864
replaced with revised version Sat, 22 Nov 2025 14:35:53 GMT   (26985kb)

Title: Training-Free Efficient Video Generation via Dynamic Token Carving
Authors: Yuechen Zhang, Jinbo Xing, Bin Xia, Shaoteng Liu, Bohao Peng, Xin Tao,
 Pengfei Wan, Eric Lo, Jiaya Jia
Categories: cs.CV
Comments: NeurIPS 2025, Project Page:
 https://julianjuaner.github.io/projects/jenga/
\\ ( https://arxiv.org/abs/2505.16864 ,  26985kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17951
replaced with revised version Mon, 24 Nov 2025 07:37:20 GMT   (19883kb)

Title: SplatCo: Structure-View Collaborative Gaussian Splatting for
 Detail-Preserving Rendering of Large-Scale Unbounded Scenes
Authors: Haihong Xiao and Jianan Zou and Yuxin Zhou and Ying He and Wenxiong
 Kang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.17951 ,  19883kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19161
replaced with revised version Mon, 24 Nov 2025 08:12:05 GMT   (6200kb)

Title: Benchmarking Endoscopic Surgical Image Restoration and Beyond
Authors: Jialun Pei, Diandian Guo, Donghui Yang, Zhixi Li, Yuxin Feng, Long Ma,
 Bo Du, Pheng-Ann Heng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.19161 ,  6200kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19536
replaced with revised version Sun, 23 Nov 2025 07:44:08 GMT   (18346kb)

Title: FlowCut: Rethinking Redundancy via Information Flow for Efficient
 Vision-Language Models
Authors: Jintao Tong, Wenwei Jin, Pengda Qin, Anqi Li, Yixiong Zou, Yuhong Li,
 Yuhua Li, Ruixuan Li
Categories: cs.CV cs.AI cs.CL
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.19536 ,  18346kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20951
replaced with revised version Mon, 24 Nov 2025 07:25:10 GMT   (8702kb)

Title: DSOcc: Leveraging Depth Awareness and Semantic Aid to Boost Camera-Based
 3D Semantic Occupancy Prediction
Authors: Naiyu Fang, Zheyuan Zhou, Kang Wang, Ruibo Li, Lemiao Qiu, Shuyou
 Zhang, Zhe Wang, Guosheng Lin
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.20951 ,  8702kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21697
replaced with revised version Sat, 22 Nov 2025 01:24:15 GMT   (3255kb)

Title: Learning to Upscale 3D Segmentations in Neuroimaging
Authors: Xiaoling Hu, Peirong Liu, Dina Zemlyanker, Jonathan Williams Ramirez,
 Oula Puonti, Juan Eugenio Iglesias
Categories: cs.CV
Comments: 13 pages, 4 figures
\\ ( https://arxiv.org/abs/2505.21697 ,  3255kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21698
replaced with revised version Mon, 24 Nov 2025 15:19:38 GMT   (3084kb)

Title: MedBridge: Bridging Foundation Vision-Language Models to Medical Image
 Diagnosis in Chest X-Ray
Authors: Yitong Li, Morteza Ghahremani, Christian Wachinger
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.21698 ,  3084kb)
------------------------------------------------------------------------------
\\
arXiv:2505.24466
replaced with revised version Sat, 22 Nov 2025 14:44:05 GMT   (3159kb)

Title: SA-Person: Text-Based Person Retrieval with Scene-aware Re-ranking
Authors: Yingjia Xu, Jinlin Wu, Daming Gao, Zhen Chen, Yang Yang, Min Cao, Mang
 Ye, and Zhen Lei
Categories: cs.CV
Comments: 13 pages, 8 figures. Under review
\\ ( https://arxiv.org/abs/2505.24466 ,  3159kb)
------------------------------------------------------------------------------
\\
arXiv:2506.01579
replaced with revised version Sun, 23 Nov 2025 09:12:35 GMT   (4039kb)

Title: HOSIG: Full-Body Human-Object-Scene Interaction Generation with
 Hierarchical Scene Perception
Authors: Wei Yao, Yunlian Sun, Hongwen Zhang, Yebin Liu, Jinhui Tang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.01579 ,  4039kb)
------------------------------------------------------------------------------
\\
arXiv:2506.03213
replaced with revised version Mon, 24 Nov 2025 11:08:46 GMT   (69968kb)

Title: ConMamba: Contrastive Vision Mamba for Plant Disease Detection
Authors: Abdullah Al Mamun, Miaohua Zhang, David Ahmedt-Aristizabal, Zeeshan
 Hayder, Mohammad Awrangjeb
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.03213 ,  69968kb)
------------------------------------------------------------------------------
\\
arXiv:2506.03596
replaced with revised version Mon, 24 Nov 2025 03:07:30 GMT   (12266kb)

Title: ControlThinker: Unveiling Latent Semantics for Controllable Image
 Generation through Visual Reasoning
Authors: Feng Han, Yang Jiao, Shaoxiang Chen, Junhao Xu, Jingjing Chen, Yu-Gang
 Jiang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.03596 ,  12266kb)
------------------------------------------------------------------------------
\\
arXiv:2506.09782
replaced with revised version Mon, 24 Nov 2025 10:55:38 GMT   (40851kb)

Title: Q-SAM2: Accurate Quantization for Segment Anything Model 2
Authors: Nicola Farronato, Florian Scheidegger, Mattia Rigotti, Cristiano
 Malossi, Michele Magno, Haotong Qin
Categories: cs.CV cs.AI
Comments: 22 pages
\\ ( https://arxiv.org/abs/2506.09782 ,  40851kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10353
replaced with revised version Mon, 24 Nov 2025 09:35:11 GMT   (6438kb)

Title: Motion-R1: Enhancing Motion Generation with Decomposed Chain-of-Thought
 and RL Binding
Authors: Runqi Ouyang, Haoyun Li, Zhenyuan Zhang, Xiaofeng Wang, Zeyu Zhang,
 Zheng Zhu, Guan Huang, Sirui Han, Xingang Wang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.10353 ,  6438kb)
------------------------------------------------------------------------------
\\
arXiv:2506.13292
replaced with revised version Mon, 24 Nov 2025 15:46:09 GMT   (13979kb)

Title: Automatic Multi-View X-Ray/CT Registration Using Bone Substructure
 Contours
Authors: Roman Flepp and Leon Nissen and Bastian Sigrist and Arend Nieuwland
 and Nicola Cavalcanti and Philipp F\"urnstahl and Thomas Dreher and Lilian
 Calvet
Categories: cs.CV cs.AI
Comments: This paper was accepted to IPCAI 2025. The Project Webpage is:
 https://rflepp.github.io/BoneSubstructureContours2D3DRegistration/
\\ ( https://arxiv.org/abs/2506.13292 ,  13979kb)
------------------------------------------------------------------------------
\\
arXiv:2506.13589
replaced with revised version Sun, 23 Nov 2025 16:32:23 GMT   (7430kb)

Title: AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented Efficient Long
 Video Understanding
Authors: Zhucun Xue, Jiangning Zhang, Xurong Xie, Yuxuan Cai, Yong Liu,
 Xiangtai Li, Dacheng Tao
Categories: cs.CV
Comments: NeurIPS 2025
\\ ( https://arxiv.org/abs/2506.13589 ,  7430kb)
------------------------------------------------------------------------------
\\
arXiv:2507.00493
replaced with revised version Mon, 24 Nov 2025 02:16:08 GMT   (6234kb)

Title: Visual Anagrams Reveal Hidden Differences in Holistic Shape Processing
 Across Vision Models
Authors: Fenil R. Doshi, Thomas Fel, Talia Konkle, George Alvarez
Categories: cs.CV cs.AI
Comments: Project page: https://www.fenildoshi.com/configural-shape/ updated
 email address
\\ ( https://arxiv.org/abs/2507.00493 ,  6234kb)
------------------------------------------------------------------------------
\\
arXiv:2507.02792
replaced with revised version Mon, 24 Nov 2025 03:38:55 GMT   (35309kb)

Title: RichControl: Structure- and Appearance-Rich Training-Free Spatial
 Control for Text-to-Image Generation
Authors: Liheng Zhang, Lexi Pang, Hang Ye, Xiaoxuan Ma, Yizhou Wang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2507.02792 ,  35309kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04258
replaced with revised version Sun, 23 Nov 2025 06:31:58 GMT   (7675kb)

Title: MoReMouse: Monocular Reconstruction of Laboratory Mouse
Authors: Yuan Zhong, Jingxiang Sun, Zhongbin Zhang, Liang An, Yebin Liu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2507.04258 ,  7675kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04323
replaced with revised version Sat, 22 Nov 2025 12:05:21 GMT   (7320kb)

Title: DMAT: An End-to-End Framework for Joint Atmospheric Turbulence
 Mitigation and Object Detection
Authors: Paul Hill and Zhiming Liu and Alin Achim and Dave Bull and Nantheera
 Anantrasirichai
Categories: cs.CV
Comments: Accepted to WACV2026
\\ ( https://arxiv.org/abs/2507.04323 ,  7320kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04726
replaced with revised version Sun, 23 Nov 2025 13:37:24 GMT   (2079kb)

Title: Backdoors in Conditional Diffusion: Threats to Responsible Synthetic
 Data Pipelines
Authors: Raz Lapid, Almog Dubin
Categories: cs.CV cs.AI
Comments: Accepted at RDS @ AAAI 2026
Journal-ref: AAAI 2026 Workshop on Shaping Responsible Synthetic Data in the
 Era of Foundation Models
\\ ( https://arxiv.org/abs/2507.04726 ,  2079kb)
------------------------------------------------------------------------------
\\
arXiv:2507.05859
replaced with revised version Sat, 22 Nov 2025 06:26:05 GMT   (8319kb)

Title: D-FCGS: Feedforward Compression of Dynamic Gaussian Splatting for
 Free-Viewpoint Videos
Authors: Wenkang Zhang, Yan Zhao, Qiang Wang, Zhixin Xu, Li Song, Zhengxue
 Cheng
Categories: cs.CV cs.MM
Comments: AAAI-26 accepted, code: https://github.com/Mr-Zwkid/D-FCGS
\\ ( https://arxiv.org/abs/2507.05859 ,  8319kb)
------------------------------------------------------------------------------
\\
arXiv:2507.11443
replaced with revised version Mon, 24 Nov 2025 08:27:03 GMT   (5004kb)

Title: COLI: A Hierarchical Efficient Compressor for Large Images
Authors: Haoran Wang, Hanyu Pei, Yang Lyu, Kai Zhang, Li Li, Feng-Lei Fan
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2507.11443 ,  5004kb)
------------------------------------------------------------------------------
\\
arXiv:2507.13861
replaced with revised version Mon, 24 Nov 2025 07:52:10 GMT   (10582kb)

Title: PositionIC: Unified Position and Identity Consistency for Image
 Customization
Authors: Junjie Hu, Tianyang Han, Kai Ma, Jialin Gao, Song Yang, Xianhua He,
 Junfeng Luo, Xiaoming Wei, Wenqiang Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2507.13861 ,  10582kb)
------------------------------------------------------------------------------
\\
arXiv:2508.03100
replaced with revised version Mon, 24 Nov 2025 03:34:12 GMT   (5678kb)

Title: AVATAR: Reinforcement Learning to See, Hear, and Reason Over Video
Authors: Yogesh Kulkarni, Pooyan Fazli
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.03100 ,  5678kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05264
replaced with revised version Mon, 24 Nov 2025 05:44:55 GMT   (3198kb)

Title: SGDFuse: SAM-Guided Diffusion for High-Fidelity Infrared and Visible
 Image Fusion
Authors: Xiaoyang Zhang, jinjiang Li, Guodong Fan, Yakun Ju, Linwei Fan, Jun
 Liu, Alex C. Kot
Categories: cs.CV cs.AI
Comments: Submitted to Information Fusion
\\ ( https://arxiv.org/abs/2508.05264 ,  3198kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05813
replaced with revised version Mon, 24 Nov 2025 16:09:54 GMT   (33248kb)

Title: Optimization-Free Style Transfer for 3D Gaussian Splats
Authors: Raphael Du Sablon and David Hart
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.05813 ,  33248kb)
------------------------------------------------------------------------------
\\
arXiv:2508.06908
replaced with revised version Sun, 23 Nov 2025 15:36:37 GMT   (5419kb)

Title: Find Them All: Unveiling MLLMs for Versatile Person Re-identification
Authors: Jinhao Li, Zijian Chen, Lirong Deng, Guangtao Zhai, Changbo Wang
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2508.06908 ,  5419kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08227
replaced with revised version Mon, 24 Nov 2025 09:55:44 GMT   (2574kb)

Title: OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image
 Super-Resolution
Authors: Zhiqiang Wu, Zhaomang Sun, Tong Zhou, Bingtao Fu, Ji Cong, Yitong
 Dong, Huaqi Zhang, Xuan Tang, Mingsong Chen, Xian Wei
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2508.08227 ,  2574kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09456
replaced with revised version Mon, 24 Nov 2025 07:19:43 GMT   (16540kb)

Title: IAG: Input-aware Backdoor Attack on VLM-based Visual Grounding
Authors: Junxian Li, Beining Xu, Simin Chen, Jiatong Li, Jingdi Lei, Haodong
 Zhao, Di Zhang
Categories: cs.CV cs.CL cs.CR
Comments: 20 pages, 13 Figures
\\ ( https://arxiv.org/abs/2508.09456 ,  16540kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10936
replaced with revised version Sat, 22 Nov 2025 22:09:54 GMT   (2143kb)

Title: Vision-Only Gaussian Splatting for Collaborative Semantic Occupancy
 Prediction
Authors: Cheng Chen, Hao Huang, Saurabh Bagchi
Categories: cs.CV cs.RO
Comments: Accepted by AAAI 2026 (Oral)
\\ ( https://arxiv.org/abs/2508.10936 ,  2143kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13009
replaced with revised version Mon, 24 Nov 2025 07:16:26 GMT   (30457kb)

Title: Matrix-game 2.0: An open-source real-time and streaming interactive
 world model
Authors: Xianglong He, Chunli Peng, Zexiang Liu, Boyang Wang, Yifan Zhang, Qi
 Cui, Fei Kang, Biao Jiang, Mengyin An, Yangyang Ren, Baixin Xu, Hao-Xiang
 Guo, Kaixiong Gong, Cyrus Wu, Wei Li, Xuchen Song, Yang Liu, Eric Li, Yahui
 Zhou
Categories: cs.CV
Comments: Project Page: https://matrix-game-v2.github.io
\\ ( https://arxiv.org/abs/2508.13009 ,  30457kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00062
replaced with revised version Mon, 24 Nov 2025 00:03:47 GMT   (28126kb)

Title: Scaffold Diffusion: Sparse Multi-Category Voxel Structure Generation
 with Discrete Diffusion
Authors: Justin Jung
Categories: cs.CV cs.AI cs.LG
Comments: Accepted at NeurIPS 2025 Structured Probabilistic Inference &
 Generative Modeling Workshop
\\ ( https://arxiv.org/abs/2509.00062 ,  28126kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01421
replaced with revised version Mon, 24 Nov 2025 16:26:00 GMT   (8451kb)

Title: InfoScale: Unleashing Training-free Variable-scaled Image Generation via
 Effective Utilization of Information
Authors: Guohui Zhang, Jiangtong Tan, Linjiang Huang, Zhonghang Yuan, Mingde
 Yao, Jie Huang, Feng Zhao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.01421 ,  8451kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03277
replaced with revised version Mon, 24 Nov 2025 03:08:02 GMT   (4840kb)

Title: PointAD+: Learning Hierarchical Representations for Zero-shot 3D Anomaly
 Detection
Authors: Qihang Zhou, Shibo He, Jiangtao Yan, Wenchao Meng, Jiming Chen
Categories: cs.CV
Comments: Submitted to TPAMI
\\ ( https://arxiv.org/abs/2509.03277 ,  4840kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06890
replaced with revised version Sat, 22 Nov 2025 01:00:18 GMT   (1879kb)

Title: Intraoperative 2D/3D Registration via Spherical Similarity Learning and
 Differentiable Levenberg-Marquardt Optimization
Authors: Minheng Chen and Youyong Kong
Categories: cs.CV eess.IV
Comments: WACV 2026 Accepted
\\ ( https://arxiv.org/abs/2509.06890 ,  1879kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10388
replaced with revised version Mon, 24 Nov 2025 04:16:29 GMT   (43261kb)

Title: Physics-Based Decomposition of Reflectance and Shading using a Single
 Visible-Thermal Image Pair
Authors: Zeqing Leo Yuan, Mani Ramanagopal, Aswin C. Sankaranarayanan,
 Srinivasa G. Narasimhan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.10388 ,  43261kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11090
replaced with revised version Sun, 23 Nov 2025 12:09:37 GMT   (1585kb)

Title: End-to-End Visual Autonomous Parking via Control-Aided Attention
Authors: Chao Chen, Shunyu Yao, Yuanwu He, Feng Tao, Ruojing Song, Yuliang Guo,
 Xinyu Huang, Chenxu Wu, Liu Ren, and Chen Feng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.11090 ,  1585kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12544
replaced with revised version Sun, 23 Nov 2025 22:03:46 GMT   (16501kb)

Title: Neural Collapse-Inspired Multi-Label Federated Learning under
 Label-Distribution Skew
Authors: Can Peng, Yuyuan Liu, Yingyu Yang, Pramit Saha, Qianye Yang, J. Alison
 Noble
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.12544 ,  16501kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13504
replaced with revised version Sat, 22 Nov 2025 22:12:54 GMT   (12409kb)

Title: LivePyxel: Accelerating image annotations with a Python-integrated
 webcam live streaming
Authors: Uriel Garcilazo-Cruz, Joseph O. Okeme, Rodrigo A. Vargas-Hern\'andez
Categories: cs.CV
Comments: 9 pages, 10 figures, SM, 5 pages, 5 figures, 1 Table
\\ ( https://arxiv.org/abs/2509.13504 ,  12409kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13848
replaced with revised version Sat, 22 Nov 2025 06:28:24 GMT   (6621kb)

Title: SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation
Authors: Jiayi Pan, Jiaming Xu, Yongkang Zhou, Guohao Dai
Categories: cs.CV cs.LG
Comments: Accepted by AAAI 2026 Oral
\\ ( https://arxiv.org/abs/2509.13848 ,  6621kb)
------------------------------------------------------------------------------
\\
arXiv:2509.16986
replaced with revised version Sat, 22 Nov 2025 06:42:22 GMT   (3148kb)

Title: VCE: Safe Autoregressive Image Generation via Visual Contrast
 Exploitation
Authors: Feng Han, Chao Gong, Zhipeng Wei, Jingjing Chen, Yu-Gang Jiang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.16986 ,  3148kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19659
replaced with revised version Fri, 21 Nov 2025 20:45:50 GMT   (1221kb)

Title: Bias in the Picture: Benchmarking VLMs with Social-Cue News Images and
 LLM-as-Judge Assessment
Authors: Aravind Narayanan, Vahid Reza Khazaie, Shaina Raza
Categories: cs.CV
Comments: Accepted to NeurIPS 2025 Workshop (Evaluating the Evolving LLM
 Lifecycle)
\\ ( https://arxiv.org/abs/2509.19659 ,  1221kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21354
replaced with revised version Sun, 23 Nov 2025 17:07:12 GMT   (516kb)

Title: KV-Efficient VLA: A Method to Speed up Vision Language Models with
 RNN-Gated Chunked KV Cache
Authors: Wanshun Xu, Long Zhuang, Lianlei Shan
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2509.21354 ,  516kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21609
replaced with revised version Sun, 23 Nov 2025 12:32:03 GMT   (12250kb)

Title: VLCE: A Knowledge-Enhanced Framework for Image Description in Disaster
 Assessment
Authors: Md. Mahfuzur Rahman, Kishor Datta Gupta, Marufa Kamal, Fahad Rahman,
 Sunzida Siddique, Ahmed Rafi Hasan, Mohd Ariful Haque, Roy George
Categories: cs.CV cs.LG
Comments: 30 pages, 40 figures, 3 algorithms
\\ ( https://arxiv.org/abs/2509.21609 ,  12250kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21783
replaced with revised version Mon, 24 Nov 2025 07:59:44 GMT   (2093kb)

Title: Prompt-guided Disentangled Representation for Action Recognition
Authors: Tianci Wu, Guangming Zhu, Jiang Lu, Siyuan Wang, Ning Wang, Nuoye
 Xiong, Zhang Liang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.21783 ,  2093kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21953
replaced with revised version Sat, 22 Nov 2025 04:31:27 GMT   (28433kb)

Title: MultiCrafter: High-Fidelity Multi-Subject Generation via Disentangled
 Attention and Identity-Aware Preference Alignment
Authors: Tao Wu, Yibo Jiang, Yehao Lu, Zhizhong Wang, Zeyi Huang, Zequn Qin, Xi
 Li
Categories: cs.CV
Comments: Project Page: https://wutao-cs.github.io/MultiCrafter/
\\ ( https://arxiv.org/abs/2509.21953 ,  28433kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23867
replaced with revised version Mon, 24 Nov 2025 08:22:15 GMT   (1099kb)

Title: Sim-DETR: Unlock DETR for Temporal Sentence Grounding
Authors: Jiajin Tang, Zhengxuan Wei, Yuchen Zhu, Cheng Shi, Guanbin Li, Liang
 Lin, Sibei Yang
Categories: cs.CV
Comments: This work is accepted by ICCV 2025
\\ ( https://arxiv.org/abs/2509.23867 ,  1099kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01047
replaced with revised version Mon, 24 Nov 2025 14:42:41 GMT   (4789kb)

Title: In-Situ Tweedie Discrete Diffusion Models
Authors: Xiao Li, Jiaqi Zhang, Shuxiang Zhang, Tianshui Chen, Liang Lin,
 Guangrun Wang
Categories: cs.CV cs.AI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2510.01047 ,  4789kb)
------------------------------------------------------------------------------
\\
arXiv:2510.08562
replaced with revised version Sat, 22 Nov 2025 12:57:50 GMT   (7693kb)

Title: ResAD: Normalized Residual Trajectory Modeling for End-to-End Autonomous
 Driving
Authors: Zhiyu Zheng, Shaoyu Chen, Haoran Yin, Xinbang Zhang, Jialv Zou,
 Xinggang Wang, Qian Zhang, Lefei Zhang
Categories: cs.CV cs.RO
\\ ( https://arxiv.org/abs/2510.08562 ,  7693kb)
------------------------------------------------------------------------------
\\
arXiv:2510.10113
replaced with revised version Mon, 24 Nov 2025 03:07:16 GMT   (1953kb)

Title: ImmerIris: A Large-Scale Dataset and Benchmark for Off-Axis and
 Unconstrained Iris Recognition in Immersive Applications
Authors: Yuxi Mi, Qiuyang Yuan, Zhizhou Zhong, Xuan Zhao, Jiaogen Zhou, Fubao
 Zhu, Jihong Guan, Shuigeng Zhou
Categories: cs.CV
\\ ( https://arxiv.org/abs/2510.10113 ,  1953kb)
------------------------------------------------------------------------------
\\
arXiv:2510.10471
replaced with revised version Mon, 24 Nov 2025 02:38:27 GMT   (15640kb)

Title: DAGLFNet: Deep Feature Attention Guided Global and Local Feature Fusion
 for Pseudo-Image Point Cloud Segmentation
Authors: Chuang Chen, Yi Lin, Bo Wang, Jing Hu, Xi Wu and Wenyi Ge
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2510.10471 ,  15640kb)
------------------------------------------------------------------------------
\\
arXiv:2510.10802
replaced with revised version Sat, 22 Nov 2025 09:01:44 GMT   (3746kb)

Title: MSCloudCAM: Multi-Scale Context Adaptation with Convolutional
 Cross-Attention for Multispectral Cloud Segmentation
Authors: Md Abdullah Al Mazid, Liangdong Deng and Naphtali Rishe
Categories: cs.CV cs.AI cs.LG
Comments: 6 pages, 3 Figures
ACM-class: F.2.2; I.2.7
\\ ( https://arxiv.org/abs/2510.10802 ,  3746kb)
------------------------------------------------------------------------------
\\
arXiv:2510.13186
replaced with revised version Sat, 22 Nov 2025 10:22:18 GMT   (11435kb)

Title: STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client
 Selection and Power Control
Authors: Zhen Li, Xibin Jin, Guoliang Li, Shuai Wang, Miaowen Wen, Huseyin
 Arslan, Derrick Wing Kwan Ng, and Chengzhong Xu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2510.13186 ,  11435kb)
------------------------------------------------------------------------------
\\
arXiv:2510.16822
replaced with revised version Mon, 24 Nov 2025 14:18:04 GMT   (23832kb)

Title: ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for
 Hard Coral Classification
Authors: Yahia Battach, Abdulwahab Felemban, Faizan Farooq Khan, Yousef A.
 Radwan, Xiang Li, Fabio Marchese, Sara Beery, Burton H. Jones, Francesca
 Benzoni, Mohamed Elhoseiny
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2510.16822 ,  23832kb)
------------------------------------------------------------------------------
\\
arXiv:2510.20776
replaced with revised version Mon, 24 Nov 2025 15:08:33 GMT   (35623kb)

Title: CUPID: Generative 3D Reconstruction via Joint Object and Pose Modeling
Authors: Binbin Huang, Haobin Duan, Yiqun Zhao, Zibo Zhao, Yi Ma, Shenghua Gao
Categories: cs.CV
Comments: project page at https://cupid3d.github.io
\\ ( https://arxiv.org/abs/2510.20776 ,  35623kb)
------------------------------------------------------------------------------
\\
arXiv:2510.21171
replaced with revised version Mon, 24 Nov 2025 13:00:02 GMT   (3171kb)

Title: TokenCLIP: Token-wise Prompt Learning for Zero-shot Anomaly Detection
Authors: Qihang Zhou, Binbin Gao, Guansong Pang, Xin Wang, Jiming Chen, Shibo
 He
Categories: cs.CV
\\ ( https://arxiv.org/abs/2510.21171 ,  3171kb)
------------------------------------------------------------------------------
\\
arXiv:2510.21590
replaced with revised version Mon, 24 Nov 2025 09:37:15 GMT   (31773kb)

Title: Restore Text First, Enhance Image Later: Two-Stage Scene Text Image
 Super-Resolution with Glyph Structure Guidance
Authors: Minxing Luo, Linlong Fan, Wang Qiushi, Ge Wu, Yiyan Luo, Yuhang Yu,
 Jinwei Chen, Yaxing Wang, Qingnan Fan, Jian Yang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2510.21590 ,  31773kb)
------------------------------------------------------------------------------
\\
arXiv:2510.23594
replaced with revised version Sat, 22 Nov 2025 03:59:26 GMT   (20749kb)

Title: PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error
 Detection
Authors: Yusu Qian and Cheng Wan and Chao Jia and Yinfei Yang and Qingyu Zhao
 and Zhe Gan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2510.23594 ,  20749kb)
------------------------------------------------------------------------------
\\
arXiv:2510.25522
replaced with revised version Mon, 24 Nov 2025 04:55:39 GMT   (3369kb)

Title: Comparative Study of UNet-based Architectures for Liver Tumor
 Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography
Authors: Doan-Van-Anh Ly (1), Thi-Thu-Hien Pham (2 and 3), Thanh-Hai Le (1)
 ((1) The Saigon International University, (2) International University, (3)
 Vietnam National University HCMC)
Categories: cs.CV cs.AI
Comments: 15 pages, 9 figures
ACM-class: I.4.6
\\ ( https://arxiv.org/abs/2510.25522 ,  3369kb)
------------------------------------------------------------------------------
\\
arXiv:2510.26213
replaced with revised version Mon, 24 Nov 2025 04:55:26 GMT   (27260kb)

Title: OmniDocLayout: Towards Diverse Document Layout Generation via
 Coarse-to-Fine LLM Learning
Authors: Hengrui Kang, Zhuangcheng Gu, Zhiyuan Zhao, Zichen Wen, Bin Wang,
 Weijia Li, Conghui He
Categories: cs.CV
Comments: TL;DR: With the proposed OmniDocLayout-1M dataset and the LLM-based
 coarse-to-fine learning strategy, we enable diverse and complex document
 layout generation that achieves both strong condition consistency and
 adherence to fundamental aesthetic principles
\\ ( https://arxiv.org/abs/2510.26213 ,  27260kb)
------------------------------------------------------------------------------
\\
arXiv:2510.27280
replaced with revised version Mon, 24 Nov 2025 16:40:06 GMT   (852kb)

Title: FOCUS: Efficient Keyframe Selection for Long Video Understanding
Authors: Zirui Zhu, Hailun Xu, Yang Luo, Yong Liu, Kanchan Sarkar, Zhenheng
 Yang, Yang You
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2510.27280 ,  852kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00956
replaced with revised version Sat, 22 Nov 2025 15:41:39 GMT   (17413kb)

Title: RefVTON: person-to-person Try on with Additional Unpaired Visual
 Reference
Authors: Liuzhuozheng Li, Yue Gong, Shanyuan Liu, Bo Cheng, Yuhang Ma, Liebucha
 Wu, Dengyang Jiang, Zanyi Wang, Dawei Leng, Yuhui Yin
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.00956 ,  17413kb)
------------------------------------------------------------------------------
\\
arXiv:2511.01295
replaced with revised version Sat, 22 Nov 2025 06:30:21 GMT   (15464kb)

Title: UniREditBench: A Unified Reasoning-based Image Editing Benchmark
Authors: Feng Han and Yibin Wang and Chenglin Li and Zheming Liang and Dianyi
 Wang and Yang Jiao and Zhipeng Wei and Chao Gong and Cheng Jin and Jingjing
 Chen and Jiaqi Wang
Categories: cs.CV
Comments: Project page: https://maplebb.github.io/UniREditBench
\\ ( https://arxiv.org/abs/2511.01295 ,  15464kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05038
replaced with revised version Sat, 22 Nov 2025 11:40:31 GMT   (38439kb)

Title: Pressure2Motion: Hierarchical Human Motion Reconstruction from Ground
 Pressure with Text Guidance
Authors: Zhengxuan Li, Qinhui Yang, Yiyu Zhuang, Chuan Guo, Xinxin Zuo,
 Xiaoxiao Long, Yao Yao, Xun Cao, Qiu Shen, Hao Zhu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.05038 ,  38439kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06299
replaced with revised version Sat, 22 Nov 2025 09:19:05 GMT   (20581kb)

Title: Physics-Informed Deformable Gaussian Splatting: Towards Unified
 Constitutive Laws for Time-Evolving Material Field
Authors: Haoqin Hong, Ding Fan, Fubin Dou, Zhi-Li Zhou, Haoran Sun, Congcong
 Zhu, Jingrun Chen
Categories: cs.CV
Comments: Accepted by AAAI-26
\\ ( https://arxiv.org/abs/2511.06299 ,  20581kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06625
replaced with revised version Sat, 22 Nov 2025 17:12:46 GMT   (3461kb)

Title: Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment
 from LDCT
Authors: Yifei Zhang, Jiashuo Zhang, Mojtaba Safari, Xiaofeng Yang, Liang Zhao
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2511.06625 ,  3461kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06741
replaced with revised version Sun, 23 Nov 2025 11:35:02 GMT   (2590kb)

Title: Otter: Mitigating Background Distractions of Wide-Angle Few-Shot Action
 Recognition with Enhanced RWKV
Authors: Wenbo Huang, Jinghui Zhang, Zhenghao Chen, Guang Li, Lei Zhang, Yang
 Cao, Fang Dong, Takahiro Ogawa, Miki Haseyama
Categories: cs.CV
Comments: Accepted by AAAI 2026 Oral
\\ ( https://arxiv.org/abs/2511.06741 ,  2590kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11025
replaced with revised version Sat, 22 Nov 2025 16:13:06 GMT   (5910kb)

Title: AirCopBench: A Benchmark for Multi-drone Collaborative Embodied
 Perception and Reasoning
Authors: Jirong Zha, Yuxuan Fan, Tianyu Zhang, Geng Chen, Yingfeng Chen, Chen
 Gao, Xinlei Chen
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.11025 ,  5910kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11030
replaced with revised version Sun, 23 Nov 2025 06:14:33 GMT   (1354kb)

Title: Algorithms Trained on Normal Chest X-rays Can Predict Health Insurance
 Types
Authors: Chi-Yu Chen, Rawan Abulibdeh, Arash Asgari, Leo Anthony Celi, Deirdre
 Goode, Hassan Hamidi, Laleh Seyyed-Kalantari, Ned McCague, Thomas Sounack,
 Po-Chih Kuo
Categories: cs.CV cs.AI
Comments: Submitting to MIDL 2026
\\ ( https://arxiv.org/abs/2511.11030 ,  1354kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11266
replaced with revised version Sat, 22 Nov 2025 09:52:11 GMT   (537kb)

Title: GraphPilot: Grounded Scene Graph Conditioning for Language-Based
 Autonomous Driving
Authors: Fabian Schmidt, Markus Enzweiler, Abhinav Valada
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.11266 ,  537kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11483
replaced with revised version Mon, 24 Nov 2025 02:28:18 GMT   (2892kb)

Title: ImAgent: A Unified Multimodal Agent Framework for Test-Time Scalable
 Image Generation
Authors: Kaishen Wang, Ruibo Chen, Tong Zheng, Heng Huang
Categories: cs.CV cs.AI
Comments: 12 pages, 5 tables, 6 figures
\\ ( https://arxiv.org/abs/2511.11483 ,  2892kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12547
replaced with revised version Mon, 24 Nov 2025 13:31:40 GMT   (33071kb)

Title: HiGFA: Hierarchical Guidance for Fine-grained Data Augmentation with
 Diffusion Models
Authors: Zhiguang Lu, Qianqian Xu, Peisong Wen, Siran Dai and Qingming Huang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.12547 ,  33071kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12919
replaced with revised version Sat, 22 Nov 2025 13:25:12 GMT   (6373kb)

Title: CoordAR: One-Reference 6D Pose Estimation of Novel Objects via
 Autoregressive Coordinate Map Generation
Authors: Dexin Zuo, Ang Li, Wei Wang, Wenxian Yu, Danping Zou
Categories: cs.CV
Comments: 7 pages, accepted by AAAI 2026 (oral)
\\ ( https://arxiv.org/abs/2511.12919 ,  6373kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13533
replaced with revised version Mon, 24 Nov 2025 15:58:49 GMT   (979kb)

Title: Minimax Multi-Target Conformal Prediction with Applications to Imaging
 Inverse Problems
Authors: Jeffrey Wen and Rizwan Ahmad and Philip Schniter
Categories: cs.CV
Journal-ref: Transactions on Machine Learning Research, 11/2025.
 https://openreview.net/forum?id=53FEYwDQK0
\\ ( https://arxiv.org/abs/2511.13533 ,  979kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13621
replaced with revised version Sat, 22 Nov 2025 17:17:38 GMT   (923kb)

Title: Alpha Divergence Losses for Biometric Verification
Authors: Dimitrios Koutsianos and Ladislav Mosner and Yannis Panagakis and
 Themos Stafylakis
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.13621 ,  923kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14111
replaced with revised version Fri, 21 Nov 2025 20:51:20 GMT   (1155kb)

Title: CascadedViT: Cascaded Chunk-FeedForward and Cascaded Group Attention
 Vision Transformer
Authors: Srivathsan Sivakumar and Faisal Z. Qureshi
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.14111 ,  1155kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14169
replaced with revised version Sun, 23 Nov 2025 05:39:02 GMT   (2289kb)

Title: AdaTok: Adaptive Token Compression with Object-Aware Representations for
 Efficient Multimodal LLMs
Authors: Xinliang Zhang, Lei Zhu, Hangzhou He, Shuang Zeng, Ourui Fu, Jiakui
 Hu, Zhengjian Yao, Yanye Lu
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.14169 ,  2289kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14208
replaced with revised version Mon, 24 Nov 2025 14:03:29 GMT   (44819kb)

Title: InstantViR: Real-Time Video Inverse Problem Solver with Distilled
 Diffusion Prior
Authors: Weimin Bai, Suzhe Xu, Yiwei Ren, Jinhua Hao, Ming Sun, Wenzheng Chen,
 He Sun
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.14208 ,  44819kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14477
replaced with revised version Mon, 24 Nov 2025 07:16:18 GMT   (21258kb)

Title: 2D Gaussians Spatial Transport for Point-supervised Density Regression
Authors: Miao Shang, Xiaopeng Hong
Categories: cs.CV
Comments: 15 pages, 6 figures. This is the preprint version of the paper and
 supplemental material to appear in AAAI, 2026. Please cite the final
 published version. Code is available at https://github.com/infinite0522/GST
\\ ( https://arxiv.org/abs/2511.14477 ,  21258kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14620
replaced with revised version Sun, 23 Nov 2025 19:30:21 GMT   (3294kb)

Title: Fusing Biomechanical and Spatio-Temporal Features for Fall Prediction:
 Characterizing and Mitigating the Simulation-to-Reality Gap
Authors: Md Fokhrul Islam, Sajeda Al-Hammouri, Christopher J. Arellano, Kavan
 Hazeli, Heman Shakeri
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.14620 ,  3294kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15065
replaced with revised version Mon, 24 Nov 2025 07:46:09 GMT   (9783kb)

Title: Reasoning via Video: The First Evaluation of Video Models' Reasoning
 Abilities through Maze-Solving Tasks
Authors: Cheng Yang, Haiyuan Wan, Yiran Peng, Xin Cheng, Zhaoyang Yu, Jiayi
 Zhang, Junchi Yu, Xinlei Yu, Xiawu Zheng, Dongzhan Zhou, Chenglin Wu
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.15065 ,  9783kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15580
replaced with revised version Sat, 22 Nov 2025 13:51:00 GMT   (941kb)

Title: CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token
 Compression for Point Cloud Tracking
Authors: Sifan Zhou, Yichao Cao, Jiahao Nie, Yuqian Fu, Ziyu Zhao, Xiaobo Lu,
 Shuo Wang
Categories: cs.CV cs.AI
Comments: Accepted by AAAI 2026 (Oral)
\\ ( https://arxiv.org/abs/2511.15580 ,  941kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15622
replaced with revised version Mon, 24 Nov 2025 17:02:04 GMT   (13903kb)

Title: The SA-FARI Dataset: Segment Anything in Footage of Animals for
 Recognition and Identification
Authors: Dante Francisco Wasmuht, Otto Brookes, Maximillian Schall, Pablo
 Palencia, Chris Beirne, Tilo Burghardt, Majid Mirmehdi, Hjalmar K\"uhl, Mimi
 Arandjelovic, Sam Pottie, Peter Bermant, Brandon Asheim, Yi Jin Toh, Adam
 Elzinga, Jason Holmberg, Andrew Whitworth, Eleanor Flatt, Laura Gustafson,
 Chaitanya Ryali, Yuan-Ting Hu, Baishan Guo, Andrew Westbury, Kate Saenko,
 Didac Suris
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.15622 ,  13903kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15986
replaced with revised version Mon, 24 Nov 2025 15:59:06 GMT   (543kb)

Title: Fairness in Multi-modal Medical Diagnosis with Demonstration Selection
Authors: Dawei Li, Zijian Gu, Peng Wang, Chuhan Song, Zhen Tan, Mohan Zhang,
 Tianlong Chen, Yu Tian, Song Wang
Categories: cs.CV cs.CY cs.LG
Comments: 10 pages (including 2 pages of references), 4 figures. This work
 explores fairness in multi-modal medical image reasoning using in-context
 learning
\\ ( https://arxiv.org/abs/2511.15986 ,  543kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16203
replaced with revised version Sun, 23 Nov 2025 07:21:40 GMT   (17063kb)

Title: When Alignment Fails: Multimodal Adversarial Attacks on
 Vision-Language-Action Models
Authors: Yuping Yan, Yuhan Xie, Yixin Zhang, Lingjuan Lyu, Handing Wang, Yaochu
 Jin
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.16203 ,  17063kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16301
replaced with revised version Mon, 24 Nov 2025 11:32:47 GMT   (2675kb)

Title: Upsample Anything: A Simple and Hard to Beat Baseline for Feature
 Upsampling
Authors: Minseok Seo, Mark Hamilton, Changick Kim
Categories: cs.CV
Comments: 15 pages, 12 figures
\\ ( https://arxiv.org/abs/2511.16301 ,  2675kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16669
replaced with revised version Sun, 23 Nov 2025 15:27:38 GMT   (3937kb)

Title: Video-as-Answer: Predict and Generate Next Video Event with Joint-GRPO
Authors: Junhao Cheng, Liang Hou, Xin Tao, Jing Liao
Categories: cs.CV
Comments: Project page: https://video-as-answer.github.io/
\\ ( https://arxiv.org/abs/2511.16669 ,  3937kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16712
replaced with revised version Mon, 24 Nov 2025 07:58:20 GMT   (23089kb)

Title: PairHuman: A High-Fidelity Photographic Dataset for Customized
 Dual-Person Generation
Authors: Ting Pan, Ye Wang, Peiguang Jing, Rui Ma, Zili Yi, Yu Liu
Categories: cs.CV cs.AI
Comments: 46 pages, 31 figures
MSC-class: 68Txx
ACM-class: I.2; I.4
\\ ( https://arxiv.org/abs/2511.16712 ,  23089kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17059
replaced with revised version Mon, 24 Nov 2025 04:58:36 GMT   (5758kb)

Title: REArtGS++: Generalizable Articulation Reconstruction with Temporal
 Geometry Constraint via Planar Gaussian Splatting
Authors: Di Wu, Liu Liu, Anran Huang, Yuyan Liu, Qiaojun Yu, Shaofan Liu,
 Liangtu Song, Cewu Lu
Categories: cs.CV
Comments: 10 pages, 7 figures
\\ ( https://arxiv.org/abs/2511.17059 ,  5758kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17068
replaced with revised version Mon, 24 Nov 2025 05:52:53 GMT   (5060kb)

Title: ReBrain: Brain MRI Reconstruction from Sparse CT Slice via
 Retrieval-Augmented Diffusion
Authors: Junming Liu, Yifei Sun, Weihua Cheng, Yujin Kang, Yirong Chen, Ding
 Wang, Guosun Zeng
Categories: cs.CV cs.AI
Comments: 16 pages, 12 figures, 7 tables; Accepted by WACV 2026
\\ ( https://arxiv.org/abs/2511.17068 ,  5060kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17092
replaced with revised version Mon, 24 Nov 2025 05:04:41 GMT   (4624kb)

Title: SPAGS: Sparse-View Articulated Object Reconstruction from Single State
 via Planar Gaussian Splatting
Authors: Di Wu, Liu Liu, Xueyu Yuan, Qiaojun Yu, Wenxiao Chen, Ruilong Yan,
 Yiming Tang, Liangtu Song
Categories: cs.CV
Comments: 10 pages, 7 figures
\\ ( https://arxiv.org/abs/2511.17092 ,  4624kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17421
replaced with revised version Mon, 24 Nov 2025 10:32:57 GMT   (394kb)

Title: Preventing Shortcut Learning in Medical Image Analysis through
 Intermediate Layer Knowledge Distillation from Specialist Teachers
Authors: Christopher Boland, Sotirios Tsaftaris, Sonia Dahdouh
Categories: cs.CV cs.AI
Comments: Accepted for publication at the Journal of Machine Learning for
 Biomedical Imaging (MELBA) https://melba-journal.org/2025:020
Journal-ref: Machine.Learning.for.Biomedical.Imaging. 3 (2025)
DOI: 10.59275/j.melba.2025-8888
\\ ( https://arxiv.org/abs/2511.17421 ,  394kb)
------------------------------------------------------------------------------
\\
arXiv:2410.02939
replaced with revised version Fri, 21 Nov 2025 22:01:32 GMT   (1280kb)

Title: Inductive Generative Recommendation via Retrieval-based Speculation
Authors: Yijie Ding, Jiacheng Li, Julian McAuley, Yupeng Hou
Categories: cs.IR
Comments: Accepted to AAAI 2026 (oral)
\\ ( https://arxiv.org/abs/2410.02939 ,  1280kb)
------------------------------------------------------------------------------
\\
arXiv:2502.04645
replaced with revised version Mon, 24 Nov 2025 08:22:00 GMT   (5009kb)

Title: Pathway to Relevance: How Cross-Encoders Implement a Semantic Variant of
 BM25
Authors: Meng Lu, Catherine Chen, Carsten Eickhoff
Categories: cs.IR cs.AI
\\ ( https://arxiv.org/abs/2502.04645 ,  5009kb)
------------------------------------------------------------------------------
\\
arXiv:2503.02298
replaced with revised version Mon, 24 Nov 2025 08:51:05 GMT   (1343kb)

Title: A Zero-shot Explainable Doctor Ranking Framework with Large Language
 Models
Authors: Ziyang Zeng, Dongyuan Li and Yuqing Yang
Categories: cs.IR
Comments: Accepted by Big Data Mining and Analytics (JCR Q1)
\\ ( https://arxiv.org/abs/2503.02298 ,  1343kb)
------------------------------------------------------------------------------
\\
arXiv:2504.05321
replaced with revised version Mon, 24 Nov 2025 06:50:38 GMT   (1332kb)

Title: VALUE: Value-Aware Large Language Model for Query Rewriting via Weighted
 Trie in Sponsored Search
Authors: Xiao Zhang, Guanyu Chen, Boyang Zuo, Feng Li, Pengjie Wang, Jian Xu,
 Bo Zheng
Categories: cs.IR cs.AI cs.LG
\\ ( https://arxiv.org/abs/2504.05321 ,  1332kb)
------------------------------------------------------------------------------
\\
arXiv:2504.16335
replaced with revised version Sat, 22 Nov 2025 22:32:53 GMT   (706kb)

Title: QPAD: Quantile-Preserving Approximate Dimension Reduction for Nearest
 Neighbors Preservation in High-Dimensional Vector Search
Authors: Jiuzhou Fu, Dongfang Zhao
Categories: cs.IR cs.DB
\\ ( https://arxiv.org/abs/2504.16335 ,  706kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07466
replaced with revised version Sun, 23 Nov 2025 05:49:55 GMT   (589kb)

Title: Capturing User Interests from Data Streams for Continual Sequential
 Recommendation
Authors: Gyuseok Lee, Hyunsik Yoo, Junyoung Hwang, SeongKu Kang, Hwanjo Yu
Categories: cs.IR
Comments: WSDM'26
\\ ( https://arxiv.org/abs/2506.07466 ,  589kb)
------------------------------------------------------------------------------
\\
arXiv:2506.11727
replaced with revised version Mon, 24 Nov 2025 14:28:14 GMT   (811kb)

Title: Forgetful by Design? A Critical Audit of YouTube's Search API for
 Academic Research
Authors: Bernhard Rieder, Adrian Padilla and Oscar Coromina
Categories: cs.IR cs.HC cs.SI
Comments: 25 pages, 2 tables and 4 figures
Journal-ref: Information, Communication and Society, 1-20
DOI: 10.1080/1369118X.2025.2591767
\\ ( https://arxiv.org/abs/2506.11727 ,  811kb)
------------------------------------------------------------------------------
\\
arXiv:2506.16114
replaced with revised version Mon, 24 Nov 2025 05:43:01 GMT   (1741kb)

Title: GFlowGR: Fine-tuning Generative Recommendation Frameworks with
 Generative Flow Networks
Authors: Yejing Wang, Shengyu Zhou, Jinyu Lu, Qidong Liu, Xinhang Li, Wenlin
 Zhang, Feng Li, Pengjie Wang, Jian Xu, Bo Zheng, Xiangyu Zhao
Categories: cs.IR cs.AI
\\ ( https://arxiv.org/abs/2506.16114 ,  1741kb)
------------------------------------------------------------------------------
\\
arXiv:2507.01053
replaced with revised version Sun, 23 Nov 2025 19:16:31 GMT   (1247kb)

Title: Conversational LLMs Simplify Secure Clinical Data Access, Understanding,
 and Analysis
Authors: Rafi Al Attrach, Pedro Moreira, Rajna Fani, Renato Umeton, Amelia
 Fiske, Leo Anthony Celi
Categories: cs.IR cs.AI cs.DB
Comments: 16 pages, 4 figures
MSC-class: 68T50, 68P15
ACM-class: H.2.3; I.2.7; J.3
\\ ( https://arxiv.org/abs/2507.01053 ,  1247kb)
------------------------------------------------------------------------------
\\
arXiv:2507.03280
replaced with revised version Mon, 24 Nov 2025 04:03:29 GMT   (8848kb)

Title: Modeling Item-Level Dynamic Variability with Residual Diffusion for
 Bundle Recommendation
Authors: Dong Zhang, Lin Li, Ming Li, Amran Bhuiyan, Meng Sun, Xiaohui Tao,
 Jimmy Xiangji Huang
Categories: cs.IR
Comments: Extended version for AAAI'26
\\ ( https://arxiv.org/abs/2507.03280 ,  8848kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05709
replaced with revised version Mon, 24 Nov 2025 02:57:36 GMT   (1534kb)

Title: G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware
 User Behavior Simulation
Authors: Boyu Chen, Siran Chen, Zhengrong Yue, Kainan Yan, Chenyun Yu, Beibei
 Kong, Cheng Lei, Chengxiang Zhuo, Zang Li, Yali Wang
Categories: cs.IR cs.LG cs.MA
Comments: Accepted in AAAI 2026
\\ ( https://arxiv.org/abs/2508.05709 ,  1534kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10584
replaced with revised version Mon, 24 Nov 2025 13:07:52 GMT   (1915kb)

Title: DAS: Dual-Aligned Semantic IDs Empowered Industrial Recommender System
Authors: Wencai Ye, Mingjie Sun, Shaoyun Shi, Peng Wang, Wenjin Wu, Peng Jiang
Categories: cs.IR
Comments: Accepted by CIKM 2025
\\ ( https://arxiv.org/abs/2508.10584 ,  1915kb)
------------------------------------------------------------------------------
\\
arXiv:2508.11977
replaced with revised version Sun, 23 Nov 2025 13:35:31 GMT   (391kb)

Title: TBGRecall: A Generative Retrieval Model for E-commerce Recommendation
 Scenarios
Authors: Zida Liang (1), Changfa Wu (2), Dunxian Huang (2), Weiqiang Sun (1),
 Ziyang Wang (2), Yuliang Yan (2), Jian Wu (2), Yuning Jiang (2), Bo Zheng
 (2), Ke Chen (2), Silu Zhou (2), Yu Zhang (2) ((1) Shanghai Jiaotong
 University, (2) Alibaba Inc.)
Categories: cs.IR cs.AI
Comments: Both authors contributed equally to this research. Work done during
 internship at Alibaba. Corresponding author: Dunxian Huang
 (dunxian.hdx@alibaba-inc.com). Affiliations: (1) Shanghai Jiaotong
 University, Shanghai, China; (2) Alibaba Inc
\\ ( https://arxiv.org/abs/2508.11977 ,  391kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13626
replaced with revised version Fri, 21 Nov 2025 19:43:30 GMT   (1362kb)

Title: Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental
 Health Retrieval
Authors: Amanda Chan, James Jiayu Liu, He Kai, Onno P. Kampman
Categories: cs.IR cs.AI
Comments: 25 pages, 3 figures, submitted to NeurIPS 2025 GenAI4Health
ACM-class: H.3.3; J.3; I.2.7
\\ ( https://arxiv.org/abs/2509.13626 ,  1362kb)
------------------------------------------------------------------------------
\\
arXiv:2510.22888
replaced with revised version Mon, 24 Nov 2025 09:10:42 GMT   (1002kb)

Title: MGFRec: Towards Reinforced Reasoning Recommendation with Multiple
 Groundings and Feedback
Authors: Shihao Cai, Chongming Gao, Haoyan Liu, Wentao Shi, Jianshan Sun,
 Ruiming Tang, Fuli Feng
Categories: cs.IR
Comments: Accepted at KDD 2026
\\ ( https://arxiv.org/abs/2510.22888 ,  1002kb)
------------------------------------------------------------------------------
\\
arXiv:2511.08150
replaced with revised version Sun, 23 Nov 2025 12:30:11 GMT   (245kb)

Title: DiffuGR: Generative Document Retrieval with Diffusion Language Models
Authors: Xinpeng Zhao, Zhaochun Ren, Yukun Zhao, Zhenyang Li, Mengqi Zhang, Jun
 Feng, Ran Chen, Ying Zhou, Zhumin Chen, Shuaiqiang Wang, Dawei Yin, Xin Xin
Categories: cs.IR
Comments: This paper is under review
\\ ( https://arxiv.org/abs/2511.08150 ,  245kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11255
replaced with revised version Mon, 24 Nov 2025 13:00:40 GMT   (712kb)

Title: Align$^3$GR: Unified Multi-Level Alignment for LLM-based Generative
 Recommendation
Authors: Wencai Ye, Mingjie Sun, Shuhang Chen, Wenjin Wu, Peng Jiang
Categories: cs.IR
Comments: Accepted by AAAI 2026 (Oral)
\\ ( https://arxiv.org/abs/2511.11255 ,  712kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12004
replaced with revised version Sun, 23 Nov 2025 06:31:37 GMT   (715kb)

Title: ComLQ: Benchmarking Complex Logical Queries in Information Retrieval
Authors: Ganlin Xu, Zhitao Yin, Linghao Zhang, Jiaqing Liang, Weijia Lu,
 Xiaodong Zhang, Zhifei Yang, Sihang Jiang, Deqing Yang
Categories: cs.IR
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2511.12004 ,  715kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15122
replaced with revised version Sat, 22 Nov 2025 06:07:19 GMT   (3165kb)

Title: Multi-Aspect Cross-modal Quantization for Generative Recommendation
Authors: Fuwei Zhang, Xiaoyu Liu, Dongbo Xi, Jishen Yin, Huan Chen, Peng Yan,
 Fuzhen Zhuang, Zhao Zhang
Categories: cs.IR cs.AI
Comments: Accepted by AAAI 2026 (Oral)
\\ ( https://arxiv.org/abs/2511.15122 ,  3165kb)
------------------------------------------------------------------------------
\\
arXiv:2109.09607
replaced with revised version Mon, 24 Nov 2025 07:58:18 GMT   (11920kb)

Title: Description of Corner Cases in Automated Driving: Goals and Challenges
Authors: Daniel Bogdoll, Jasmin Breitenstein, Florian Heidecker, Maarten
 Bieshaar, Bernhard Sick, Tim Fingscheidt, J. Marius Z\"ollner
Categories: cs.LG cs.RO
Comments: Daniel Bogdoll, Jasmin Breitenstein and Florian Heidecker contributed
 equally. Accepted for publication at ICCV 2021 ERCVAD Workshop
DOI: 10.1109/ICCVW54120.2021.00119
\\ ( https://arxiv.org/abs/2109.09607 ,  11920kb)
------------------------------------------------------------------------------
\\
arXiv:2111.03201
replaced with revised version Mon, 24 Nov 2025 08:17:47 GMT   (18564kb)

Title: Compressing Sensor Data for Remote Assistance of Autonomous Vehicles
 using Deep Generative Models
Authors: Daniel Bogdoll, Johannes Jestram, Jonas Rauch, Christin Scheib, Moritz
 Wittig, J. Marius Z\"ollner
Categories: cs.LG eess.SP
Comments: Daniel Bogdoll, Johannes Jestram, Jonas Rauch, Christin Scheib and
 Moritz Wittig contributed equally. Accepted for publication at NeurIPS 2021
 ML4AD Workshop
\\ ( https://arxiv.org/abs/2111.03201 ,  18564kb)
------------------------------------------------------------------------------
\\
arXiv:2303.08582
replaced with revised version Sun, 23 Nov 2025 16:08:33 GMT   (287kb)

Title: High-dimensional multi-view clustering methods
Authors: Alaeddine Zahir, Khalide Jbilou, Ahmed Ratnani
Categories: cs.LG cs.NA math.NA
Comments: 4 figures
\\ ( https://arxiv.org/abs/2303.08582 ,  287kb)
------------------------------------------------------------------------------
\\
arXiv:2304.13037
replaced with revised version Mon, 24 Nov 2025 07:05:54 GMT   (5069kb)

Title: VeML: An End-to-End Machine Learning Lifecycle for Large-scale and
 High-dimensional Data
Authors: Van-Duc Le, Tien-Cuong Bui, Wen-Syan Li
Categories: cs.LG cs.DB cs.HC
Comments: The updated version of this paper, titled "Efficient ML Lifecycle
 Transferring for Large-scale and High-dimensional Data via Core Set-based
 Dataset Similarity," has been accepted for publication in IEEE Access
Journal-ref: IEEE Access, vol. 11, pp. 73823-73838, 2023
DOI: 10.1109/ACCESS.2023.3296136
\\ ( https://arxiv.org/abs/2304.13037 ,  5069kb)
------------------------------------------------------------------------------
\\
arXiv:2305.15118
replaced with revised version Sat, 22 Nov 2025 01:06:13 GMT   (139kb)

Title: Fairness in Streaming Submodular Maximization over a Matroid Constraint
Authors: Marwa El Halabi, Federico Fusco, Ashkan Norouzi-Fard, Jakab Tardos,
 Jakub Tarnawski
Categories: cs.LG cs.CY cs.DS
Comments: Correcting error in Proposition C.6. This doesn't affect any other
 result in the paper
\\ ( https://arxiv.org/abs/2305.15118 ,  139kb)
------------------------------------------------------------------------------
\\
arXiv:2310.11789
replaced with revised version Sun, 23 Nov 2025 03:08:20 GMT   (20163kb)

Title: PINNsFailureRegion Localization and Refinement through White-box
 AdversarialAttack
Authors: Shengzhu Shi, Yao Li, Zhichang Guo, Boying Wu, Yang Zhao
Categories: cs.LG cs.NA math.NA
Journal-ref: Neurocomputing (2025): 132055
\\ ( https://arxiv.org/abs/2310.11789 ,  20163kb)
------------------------------------------------------------------------------
\\
arXiv:2408.08493
replaced with revised version Mon, 24 Nov 2025 02:24:03 GMT   (1246kb)

Title: Parallel Unlearning in Inherited Model Networks
Authors: Xiao Liu, Mingyuan Li, Guangsheng Yu, Lixiang Li, Haipeng Peng, and
 Ren Ping Liu
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2408.08493 ,  1246kb)
------------------------------------------------------------------------------
\\
arXiv:2408.11052
replaced with revised version Sun, 23 Nov 2025 17:25:06 GMT   (1783kb)

Title: Accelerating Goal-Conditioned RL Algorithms and Research
Authors: Micha{\l} Bortkiewicz, W{\l}adys{\l}aw Pa{\l}ucki, Vivek Myers,
 Tadeusz Dziarmaga, Tomasz Arczewski, {\L}ukasz Kuci\'nski, Benjamin Eysenbach
Categories: cs.LG cs.AI
Comments: Published at ICLR 2025 (Spotlight). Website:
 https://michalbortkiewicz.github.io/JaxGCRL/ Code:
 https://github.com/MichalBortkiewicz/JaxGCRL
Journal-ref: International Conference on Learning Representations (ICLR), 2025
\\ ( https://arxiv.org/abs/2408.11052 ,  1783kb)
------------------------------------------------------------------------------
\\
arXiv:2409.04919
replaced with revised version Sat, 22 Nov 2025 22:30:55 GMT   (281kb)

Title: Learning with Shared Representations: Statistical Rates and Efficient
 Algorithms
Authors: Xiaochun Niu, Lili Su, Jiaming Xu, Pengkun Yang
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2409.04919 ,  281kb)
------------------------------------------------------------------------------
\\
arXiv:2410.01870
replaced with revised version Mon, 24 Nov 2025 18:17:37 GMT   (590kb)

Title: PEANuT: Parameter-Efficient Adaptation with Weight-aware Neural Tweakers
Authors: Yibo Zhong, Haoxiang Jiang, Lincan Li, Ryumei Nakada, Tianci Liu,
 Linjun Zhang, Huaxiu Yao, Haoyu Wang
Categories: cs.LG cs.CL
\\ ( https://arxiv.org/abs/2410.01870 ,  590kb)
------------------------------------------------------------------------------
\\
arXiv:2410.03833
replaced with revised version Sat, 22 Nov 2025 09:58:52 GMT   (4363kb)

Title: Understanding Fine-tuning in Approximate Unlearning: A Theoretical
 Perspective
Authors: Meng Ding, Rohan Sharma, Changyou Chen, Jinhui Xu, Kaiyi Ji
Categories: cs.LG stat.ML
Comments: 23 pages,5 figures
\\ ( https://arxiv.org/abs/2410.03833 ,  4363kb)
------------------------------------------------------------------------------
\\
arXiv:2410.08255
replaced with revised version Sun, 23 Nov 2025 19:24:43 GMT   (241kb)

Title: Investigating Representation Universality: Case Study on Genealogical
 Representations
Authors: David D. Baek, Yuxiao Li, Max Tegmark
Categories: cs.LG cs.AI
Comments: 14 pages, 7 figures
Journal-ref: NeurIPS 2025 Workshop on Responsible Foundation Models
\\ ( https://arxiv.org/abs/2410.08255 ,  241kb)
------------------------------------------------------------------------------
\\
arXiv:2410.14581
replaced with revised version Sun, 23 Nov 2025 02:13:49 GMT   (2927kb)

Title: Optimizing Attention with Mirror Descent: Generalized Max-Margin Token
 Selection
Authors: Addison Kristanto Julistiono, Davoud Ataee Tarzanagh, Navid Azizan
Categories: cs.LG cs.AI cs.CL
\\ ( https://arxiv.org/abs/2410.14581 ,  2927kb)
------------------------------------------------------------------------------
\\
arXiv:2410.23824
replaced with revised version Sun, 23 Nov 2025 13:26:56 GMT   (1705kb)

Title: Generative AI-Powered Plugin for Robust Federated Learning in
 Heterogeneous IoT Networks
Authors: Youngjoon Lee, Jinu Gong, Joonhyuk Kang
Categories: cs.LG eess.SP
Comments: Accepted to the 1st Workshop on New Generation Databases and
 Data-Empowering Technologies in Big Data Era - IEEE BigData 2025
\\ ( https://arxiv.org/abs/2410.23824 ,  1705kb)
------------------------------------------------------------------------------
\\
arXiv:2412.03906
replaced with revised version Fri, 21 Nov 2025 23:47:49 GMT   (1883kb)

Title: Final-Model-Only Data Attribution with a Unifying View of Gradient-Based
 Methods
Authors: Dennis Wei, Inkit Padhi, Soumya Ghosh, Amit Dhurandhar, Karthikeyan
 Natesan Ramamurthy, Maria Chang
Categories: cs.LG stat.ML
Comments: Published at the Thirty-Ninth Annual Conference on Neural Information
 Processing Systems (NeurIPS 2025). 28 pages, 11 figures
\\ ( https://arxiv.org/abs/2412.03906 ,  1883kb)
------------------------------------------------------------------------------
\\
arXiv:2412.16216
replaced with revised version Mon, 24 Nov 2025 03:37:48 GMT   (2682kb)

Title: GMoE: Empowering LLMs Fine-Tuning via MoE Graph Collaboration
Authors: Ting Bai, Yue Yu, Le Huang, Zenan Xu, Chuan Shi
Categories: cs.LG cs.AI cs.CL
Comments: 9 pages, 25 figures
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2412.16216 ,  2682kb)
------------------------------------------------------------------------------
\\
arXiv:2501.07502
replaced with revised version Sat, 22 Nov 2025 21:29:05 GMT   (305kb)

Title: Human-Inspired Multi-Level Reinforcement Learning
Authors: Mingkang Wu, Devin White, Vernon Lawhern, Nicholas R. Waytowich and
 Yongcan Cao
Categories: cs.LG cs.AI
Comments: Accepted to the Aligning Reinforcement Learning Experimentalists and
 Theorists Workshop at NeurIPS 2025
\\ ( https://arxiv.org/abs/2501.07502 ,  305kb)
------------------------------------------------------------------------------
\\
arXiv:2501.18416
replaced with revised version Sun, 23 Nov 2025 13:33:44 GMT   (143kb)

Title: Exploring Potential Prompt Injection Attacks in Federated Military LLMs
 and Their Mitigation
Authors: Youngjoon Lee, Taehyun Park, Yunho Lee, Jinu Gong, Joonhyuk Kang
Categories: cs.LG
Comments: Accepted to the 3rd International Workshop on Dataspaces and Digital
 Twins for Critical Entities and Smart Urban Communities - IEEE BigData 2025
\\ ( https://arxiv.org/abs/2501.18416 ,  143kb)
------------------------------------------------------------------------------
\\
arXiv:2502.05509
replaced with revised version Sun, 23 Nov 2025 02:15:18 GMT   (374kb)

Title: Do Spikes Protect Privacy? Investigating Black-Box Model Inversion
 Attacks in Spiking Neural Networks
Authors: Hamed Poursiami, Ayana Moshruba, Maryam Parsa
Categories: cs.LG cs.CR cs.NE
Comments: 7 pages, 4 figures
\\ ( https://arxiv.org/abs/2502.05509 ,  374kb)
------------------------------------------------------------------------------
\\
arXiv:2502.06761
replaced with revised version Mon, 24 Nov 2025 10:35:14 GMT   (4510kb)

Title: When, Where and Why to Average Weights?
Authors: Niccol\`o Ajroldi, Antonio Orvieto, Jonas Geiping
Categories: cs.LG
\\ ( https://arxiv.org/abs/2502.06761 ,  4510kb)
------------------------------------------------------------------------------
\\
arXiv:2502.07620
replaced with revised version Sat, 22 Nov 2025 17:07:52 GMT   (2770kb)

Title: Resilient Contrastive Pre-training under Non-Stationary Drift
Authors: Xiaoyu Yang, Jie Lu, En Yu, Wei Duan
Categories: cs.LG cs.CV
Comments: 17pages, 3 figures
\\ ( https://arxiv.org/abs/2502.07620 ,  2770kb)
------------------------------------------------------------------------------
\\
arXiv:2502.08542
replaced with revised version Mon, 24 Nov 2025 12:23:10 GMT   (679kb)

Title: Beyond Predictions: A Participatory Framework for Multi-Stakeholder
 Decision-Making
Authors: Vittoria Vineis, Giuseppe Perelli, Gabriele Tolomei
Categories: cs.LG cs.MA
\\ ( https://arxiv.org/abs/2502.08542 ,  679kb)
------------------------------------------------------------------------------
\\
arXiv:2502.13290
replaced with revised version Sat, 22 Nov 2025 08:11:22 GMT   (244kb)

Title: Prediction of Clinical Complication Onset using Neural Point Processes
Authors: Sachini Weerasekara, Sagar Kamarthi, Jacqueline Isaacs
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2502.13290 ,  244kb)
------------------------------------------------------------------------------
\\
arXiv:2502.15938
replaced with revised version Sun, 23 Nov 2025 19:25:46 GMT   (8224kb)

Title: Straight to Zero: Why Linearly Decaying the Learning Rate to Zero Works
 Best for LLMs
Authors: Shane Bergsma, Nolan Dey, Gurpreet Gosal, Gavia Gray, Daria Soboleva,
 Joel Hestness
Categories: cs.LG cs.AI cs.CL cs.NE
Comments: ICLR 2025
\\ ( https://arxiv.org/abs/2502.15938 ,  8224kb)
------------------------------------------------------------------------------
\\
arXiv:2503.04363
replaced with revised version Mon, 24 Nov 2025 11:18:03 GMT   (3062kb)

Title: Causally Reliable Concept Bottleneck Models
Authors: Giovanni De Felice, Arianna Casanova Flores, Francesco De Santis,
 Silvia Santini, Johannes Schneider, Pietro Barbiero, Alberto Termine
Categories: cs.LG cs.AI
Comments: Accepted at NeurIPS 2025
\\ ( https://arxiv.org/abs/2503.04363 ,  3062kb)
------------------------------------------------------------------------------
\\
arXiv:2503.06567
replaced with revised version Mon, 24 Nov 2025 08:27:31 GMT   (816kb)

Title: Human Cognition Inspired RAG with Knowledge Graph for Complex Problem
 Solving
Authors: Yao Cheng, Yibo Zhao, Jiapeng Zhu, Yao Liu, Xing Sun, Xiang Li
Categories: cs.LG cs.AI
Comments: The paper has been accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2503.06567 ,  816kb)
------------------------------------------------------------------------------
\\
arXiv:2503.14858
replaced with revised version Sun, 23 Nov 2025 02:37:33 GMT   (4193kb)

Title: 1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New
 Goal-Reaching Capabilities
Authors: Kevin Wang, Ishaan Javali, Micha{\l} Bortkiewicz, Tomasz Trzci\'nski,
 Benjamin Eysenbach
Categories: cs.LG cs.AI
Comments: Link to project website:
 https://wang-kevin3290.github.io/scaling-crl/
\\ ( https://arxiv.org/abs/2503.14858 ,  4193kb)
------------------------------------------------------------------------------
\\
arXiv:2503.16917
replaced with revised version Sun, 23 Nov 2025 23:21:43 GMT   (3808kb)

Title: Malliavin Calculus for Score-based Diffusion Models
Authors: Ehsan Mirafzali, Utkarsh Gupta, Patrick Wyrod, Frank Proske, Daniele
 Venturi, Razvan Marinescu
Categories: cs.LG math.PR
\\ ( https://arxiv.org/abs/2503.16917 ,  3808kb)
------------------------------------------------------------------------------
\\
arXiv:2503.23822
replaced with revised version Mon, 24 Nov 2025 12:16:52 GMT   (7805kb)

Title: Node Embeddings via Neighbor Embeddings
Authors: Jan Niklas B\"ohm, Marius Keute, Alica Guzm\'an, Sebastian Damrich,
 Andrew Draganov, Dmitry Kobak
Categories: cs.LG
Comments: Accepted to Transactions of Machine Learning Research (TMLR)
\\ ( https://arxiv.org/abs/2503.23822 ,  7805kb)
------------------------------------------------------------------------------
\\
arXiv:2504.02251
replaced with revised version Fri, 21 Nov 2025 23:47:38 GMT   (209kb)

Title: Quantum Lipschitz Bandits
Authors: Bongsoo Yi, Yue Kang, Yao Li
Categories: cs.LG
\\ ( https://arxiv.org/abs/2504.02251 ,  209kb)
------------------------------------------------------------------------------
\\
arXiv:2504.12916
replaced with revised version Sat, 22 Nov 2025 10:24:02 GMT   (1873kb)

Title: Exact Learning Dynamics of In-Context Learning in Linear Transformers
 and Its Application to Non-Linear Transformers
Authors: Nischal Mainali, Lucas Teixeira
Categories: cs.LG cond-mat.dis-nn
Comments: 10 pages, 7 figures
\\ ( https://arxiv.org/abs/2504.12916 ,  1873kb)
------------------------------------------------------------------------------
\\
arXiv:2504.13612
replaced with revised version Mon, 24 Nov 2025 17:16:26 GMT   (6132kb)

Title: Entropic Time Schedulers for Generative Diffusion Models
Authors: Dejan Stancevic, Florian Handke, Luca Ambrogioni
Categories: cs.LG cs.AI
Comments: 31 pages
\\ ( https://arxiv.org/abs/2504.13612 ,  6132kb)
------------------------------------------------------------------------------
\\
arXiv:2504.20319
replaced with revised version Sat, 22 Nov 2025 01:36:02 GMT   (4848kb)

Title: Bayesian Experimental Design for Model Discrepancy Calibration: An
 Auto-Differentiable Ensemble Kalman Inversion Approach
Authors: Huchen Yang, Xinghao Dong, Jin-Long Wu
Categories: cs.LG
Comments: 36 pages, 13 figures
Journal-ref: Journal of Computational Physics, Volume 545, 2026, Article 114469
DOI: 10.1016/j.jcp.2025.114469
\\ ( https://arxiv.org/abs/2504.20319 ,  4848kb)
------------------------------------------------------------------------------
\\
arXiv:2505.01218
replaced with revised version Mon, 24 Nov 2025 04:42:20 GMT   (3066kb)

Title: Quantitative Attractor Analysis of High-Capacity Kernel Logistic
 Regression Hopfield Networks
Authors: Akira Tamamori
Categories: cs.LG cs.NE
Comments: 16 pages, 7 figures
\\ ( https://arxiv.org/abs/2505.01218 ,  3066kb)
------------------------------------------------------------------------------
\\
arXiv:2505.06288
replaced with revised version Sun, 23 Nov 2025 03:57:02 GMT   (0kb,I)

Title: IIKL: Isometric Immersion Kernel Learning with Riemannian Manifold for
 Geometric Preservation
Authors: Zihao Chen, Wenyong Wang, Jiachen Yang, Yu Xiang
Categories: cs.LG stat.ML
Comments: We decided to withdraw this submission because we identified a
 statistical issue in the experimental section. Specifically, for seven
 methods (LLE, MLLE, LTSA, Spectral, CAMEL, PaCMAP, and UMAP) on the
 CIC-IDS2018 dataset, a spreadsheet printing/mixing error caused the
 reduction-rate results in Table 5 to appear identical
\\ ( https://arxiv.org/abs/2505.06288 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2505.07635
replaced with revised version Mon, 24 Nov 2025 17:17:12 GMT   (1276kb)

Title: Interpreting Graph Inference with Skyline Explanations
Authors: Dazhuo Qiu, Haolai Che, Arijit Khan, Yinghui Wu
Categories: cs.LG cs.DB
Comments: Accepted at ICDE 2026
\\ ( https://arxiv.org/abs/2505.07635 ,  1276kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11254
replaced with revised version Sat, 22 Nov 2025 05:19:16 GMT   (6107kb)

Title: Delta Attention: Fast and Accurate Sparse Attention Inference by Delta
 Correction
Authors: Jeffrey Willette, Heejun Lee, Sung Ju Hwang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2505.11254 ,  6107kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11411
replaced with revised version Sun, 23 Nov 2025 04:26:02 GMT   (1089kb)

Title: Is Grokking a Computational Glass Relaxation?
Authors: Xiaotian Zhang, Yue Shang, Entao Yang, Ge Zhang
Categories: cs.LG cond-mat.dis-nn
\\ ( https://arxiv.org/abs/2505.11411 ,  1089kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12842
replaced with revised version Sat, 22 Nov 2025 15:07:27 GMT   (2955kb)

Title: GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in
 GUI Agents
Authors: Zheng Wu and Pengzhou Cheng and Zongru Wu and Lingzhong Dong and
 Zhuosheng Zhang
Categories: cs.LG cs.CL
\\ ( https://arxiv.org/abs/2505.12842 ,  2955kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13644
replaced with revised version Mon, 24 Nov 2025 18:57:49 GMT   (1815kb)

Title: Collapsing Taylor Mode Automatic Differentiation
Authors: Felix Dangel, Tim Siebert, Marius Zeinhofer, Andrea Walther
Categories: cs.LG
Comments: 10 pages + appendix; camera-ready version (NeurIPS 2025)
\\ ( https://arxiv.org/abs/2505.13644 ,  1815kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13738
replaced with revised version Sun, 23 Nov 2025 19:09:41 GMT   (6165kb)

Title: Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM
 Pre-training
Authors: Shane Bergsma, Nolan Dey, Gurpreet Gosal, Gavia Gray, Daria Soboleva,
 Joel Hestness
Categories: cs.LG cs.AI cs.CL
Comments: NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.13738 ,  6165kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13775
replaced with revised version Sat, 22 Nov 2025 07:49:57 GMT   (1773kb)

Title: Beyond Semantics: The Unreasonable Effectiveness of Reasonless
 Intermediate Tokens
Authors: Karthik Valmeekam, Kaya Stechly, Vardhan Palod, Atharva Gundawar,
 Subbarao Kambhampati
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2505.13775 ,  1773kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20192
replaced with revised version Mon, 24 Nov 2025 12:52:02 GMT   (640kb)

Title: FunReason: Enhancing Large Language Models' Function Calling via
 Self-Refinement Multiscale Loss and Automated Data Refinement
Authors: Bingguang Hao, Maolin Wang, Zengzhuang Xu, Cunyin Peng, Yicheng Chen,
 Xiangyu Zhao, Jinjie Gu, Chenyi Zhuang
Categories: cs.LG cs.IR
\\ ( https://arxiv.org/abs/2505.20192 ,  640kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00967
replaced with revised version Mon, 24 Nov 2025 00:28:33 GMT   (353kb)

Title: Pilot Contamination-Aware Graph Attention Network for Power Control in
 CFmMIMO
Authors: Tingting Zhang, Sergiy A. Vorobyov, David J. Love, Taejoon Kim, and
 Kai Dong
Categories: cs.LG
\\ ( https://arxiv.org/abs/2506.00967 ,  353kb)
------------------------------------------------------------------------------
\\
arXiv:2506.08764
replaced with revised version Fri, 21 Nov 2025 19:12:16 GMT   (237kb)

Title: On the Stability of the Jacobian Matrix in Deep Neural Networks
Authors: Benjamin Dadoun and Soufiane Hayou and Hanan Salam and Mohamed El
 Amine Seddik and Pierre Youssef
Categories: cs.LG
Comments: 16 pages, 26 figures; fixed a serious flaw in the main theorem
MSC-class: 68T07, 60B20
\\ ( https://arxiv.org/abs/2506.08764 ,  237kb)
------------------------------------------------------------------------------
\\
arXiv:2506.09532
replaced with revised version Sat, 22 Nov 2025 17:52:57 GMT   (888kb)

Title: Athena: Enhancing Multimodal Reasoning with Data-efficient Process
 Reward Models
Authors: Shuai Wang, Zhenhua Liu, Jiaheng Wei, Xuanwu Yin, Dong Li, Emad
 Barsoum
Categories: cs.LG cs.AI cs.CL cs.CV
Comments: v3: fix typos, add data scaling exp
\\ ( https://arxiv.org/abs/2506.09532 ,  888kb)
------------------------------------------------------------------------------
\\
arXiv:2506.15881
replaced with revised version Fri, 21 Nov 2025 19:50:20 GMT   (18207kb)

Title: T-SHRED: Symbolic Regression for Regularization and Model Discovery with
 Transformer Shallow Recurrent Decoders
Authors: Alexey Yermakov, David Zoro, Mars Liyao Gao and J. Nathan Kutz
Categories: cs.LG
Comments: 17 pages, 5 figures, submitted to Transactions of the Royal Society
 (Symbolic Regression in the Physical Sciences)
\\ ( https://arxiv.org/abs/2506.15881 ,  18207kb)
------------------------------------------------------------------------------
\\
arXiv:2506.16001
replaced with revised version Sat, 22 Nov 2025 15:55:47 GMT   (757kb)

Title: AutoHFormer: Efficient Hierarchical Autoregressive Transformer for Time
 Series Prediction
Authors: Qianru Zhang, Honggang Wen, Ming Li, Dong Huang, Siu-Ming Yiu,
 Christian S. Jensen, Pietro Li\`o
Categories: cs.LG cs.AI
Comments: 14 pages
Journal-ref: ICDE'2026
\\ ( https://arxiv.org/abs/2506.16001 ,  757kb)
------------------------------------------------------------------------------
\\
arXiv:2506.17796
replaced with revised version Mon, 24 Nov 2025 18:49:51 GMT   (1781kb)

Title: SING: SDE Inference via Natural Gradients
Authors: Amber Hu, Henry Smith, Scott Linderman
Categories: cs.LG stat.ML
Comments: To appear in Advances in Neural Processing Information Systems
 (NeurIPS), 2025
\\ ( https://arxiv.org/abs/2506.17796 ,  1781kb)
------------------------------------------------------------------------------
\\
arXiv:2506.21127
replaced with revised version Sun, 23 Nov 2025 11:44:34 GMT   (660kb)

Title: Meta Policy Switching for Secure UAV Deconfliction in Adversarial
 Airspace
Authors: Deepak Kumar Panda and Weisi Guo
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2506.21127 ,  660kb)
------------------------------------------------------------------------------
\\
arXiv:2506.23210
replaced with revised version Mon, 24 Nov 2025 06:24:33 GMT   (2084kb)

Title: FedRef: Communication-Efficient Bayesian Fine-Tuning using a Reference
 Model
Authors: Taehwan Yoon, Bongjun Choi, Wesley De Neve
Categories: cs.LG cs.AI cs.DC
Comments: 11 pages, 16 equations, 5 figures, 6 tables
\\ ( https://arxiv.org/abs/2506.23210 ,  2084kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04981
replaced with revised version Sat, 22 Nov 2025 08:09:08 GMT   (1009kb)

Title: Classification of autoimmune diseases from Peripheral blood TCR
 repertoires by multimodal multi-instance learning
Authors: Ruihao Zhang, Mao chen, Fei Ye, Dandan Meng, Yixuan Huang, Xiao Liu
Categories: cs.LG cs.AI q-bio.GN
Comments: 4 figures, 3 tabels, 8 pages
\\ ( https://arxiv.org/abs/2507.04981 ,  1009kb)
------------------------------------------------------------------------------
\\
arXiv:2507.06567
replaced with revised version Mon, 24 Nov 2025 09:35:35 GMT   (1209kb)

Title: SlimCaching: Edge Caching of Mixture-of-Experts for Distributed
 Inference
Authors: Qian Chen, Xianhao Chen, Kaibin Huang
Categories: cs.LG cs.DC cs.NI
Comments: 17 pages, 11 figures. This work has been submitted to the IEEE for
 possible publication
\\ ( https://arxiv.org/abs/2507.06567 ,  1209kb)
------------------------------------------------------------------------------
\\
arXiv:2507.07456
replaced with revised version Mon, 24 Nov 2025 08:29:00 GMT   (11438kb)

Title: General-Purpose Models for the Chemical Sciences: LLMs and Beyond
Authors: Nawaf Alampara, Anagha Aneesh, Marti\~no R\'ios-Garc\'ia, Adrian
 Mirza, Mara Schilling-Wilhelmi, Ali Asghar Aghajani, Meiling Sun, Gordan
 Prastalo, Kevin Maik Jablonka
Categories: cs.LG cond-mat.mtrl-sci physics.chem-ph
\\ ( https://arxiv.org/abs/2507.07456 ,  11438kb)
------------------------------------------------------------------------------
\\
arXiv:2507.10241
replaced with revised version Sat, 22 Nov 2025 15:12:41 GMT   (6401kb)

Title: Kernel-Adaptive PI-ELMs for Forward and Inverse Problems in PDEs with
 Sharp Gradients
Authors: Vikas Dwivedi, Balaji Srinivasan, Monica Sigovan, Bruno Sixou
Categories: cs.LG
\\ ( https://arxiv.org/abs/2507.10241 ,  6401kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00578
replaced with revised version Mon, 24 Nov 2025 08:44:20 GMT   (2623kb)

Title: Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions
 in Peptides
Authors: Marlen Neubert, Patrick Reiser, Frauke Gr\"ater, Pascal Friederich
Categories: cs.LG cond-mat.mtrl-sci physics.chem-ph physics.comp-ph q-bio.BM
Comments: 20 pages, 12 figures, and 4 tables (references and SI included)
\\ ( https://arxiv.org/abs/2508.00578 ,  2623kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02291
replaced with revised version Sat, 22 Nov 2025 09:08:05 GMT   (5196kb)

Title: FAIR-Pruner: Leveraging Tolerance of Difference for Flexible Automatic
 Layer-Wise Neural Network Pruning
Authors: Chenqing Lin, Mostafa Hussien, Chengyao Yu, Bingyi Jing, Mohamed
 Cheriet, Osama Abdelrahman, and Ruixing Ming
Categories: cs.LG cs.AI
Comments: Submitted to CVPR 2026
\\ ( https://arxiv.org/abs/2508.02291 ,  5196kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05224
replaced with revised version Mon, 24 Nov 2025 14:59:34 GMT   (7601kb)

Title: Don't Reach for the Stars: Rethinking Topology for Resilient Federated
 Learning
Authors: Mirko Konstantin and Anirban Mukhopadhyay
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2508.05224 ,  7601kb)
------------------------------------------------------------------------------
\\
arXiv:2508.06251
replaced with revised version Sat, 22 Nov 2025 20:25:18 GMT   (887kb)

Title: Synthetic Data Generation and Differential Privacy using Tensor
 Networks' Matrix Product States (MPS)
Authors: Alejandro Moreno R., Desale Fentaw, Samuel Palmer, Ra\'ul Salles de
 Padua, Ninad Dixit, Samuel Mugel, Roman Or\'us, Manuel Radons, Josef Menter,
 and Ali Abedi
Categories: cs.LG cs.AI cs.CR quant-ph
Comments: 10 pages
\\ ( https://arxiv.org/abs/2508.06251 ,  887kb)
------------------------------------------------------------------------------
\\
arXiv:2508.07142
replaced with revised version Sat, 22 Nov 2025 08:38:45 GMT   (485kb)

Title: Why Does Stochastic Gradient Descent Slow Down in Low-Precision
 Training?
Authors: Vincent-Daniel Yun
Categories: cs.LG cs.AI cs.IT cs.NA math.IT math.NA
\\ ( https://arxiv.org/abs/2508.07142 ,  485kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09527
replaced with revised version Mon, 24 Nov 2025 06:23:22 GMT   (11058kb)

Title: Time-Aware and Transition-Semantic Graph Neural Networks for
 Interpretable Predictive Business Process Monitoring
Authors: Fang Wang and Ernesto Damiani
Categories: cs.LG
Comments: 42 pages
\\ ( https://arxiv.org/abs/2508.09527 ,  11058kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10123
replaced with revised version Sat, 22 Nov 2025 22:20:46 GMT   (186kb)

Title: Nested-ReFT: Efficient Reinforcement Learning for Large Language Model
 Fine-Tuning via Off-Policy Rollouts
Authors: Maxime Heuillet, Yufei Cui, Boxing Chen, Audrey Durand, Prasanna
 Parthasarathi
Categories: cs.LG cs.AI cs.CL
\\ ( https://arxiv.org/abs/2508.10123 ,  186kb)
------------------------------------------------------------------------------
\\
arXiv:2508.12491
replaced with revised version Mon, 24 Nov 2025 18:59:36 GMT   (1410kb)

Title: Cost-Aware Contrastive Routing for LLMs
Authors: Reza Shirkavand, Shangqian Gao, Peiran Yu, Heng Huang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2508.12491 ,  1410kb)
------------------------------------------------------------------------------
\\
arXiv:2508.15480
replaced with revised version Mon, 24 Nov 2025 16:47:54 GMT   (1655kb)

Title: Learning Protein-Ligand Binding in Hyperbolic Space
Authors: Jianhui Wang, Wenyu Zhu, Bowen Gao, Xin Hong, Ya-Qin Zhang, Wei-Ying
 Ma, Yanyan Lan
Categories: cs.LG
\\ ( https://arxiv.org/abs/2508.15480 ,  1655kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00221
replaced with revised version Sun, 23 Nov 2025 01:44:29 GMT   (1825kb)

Title: Speech Foundation Models Generalize to Time Series Tasks from Wearable
 Sensor Data
Authors: Jaya Narain, Zakaria Aldeneh, Shirley Ren
Categories: cs.LG eess.AS
Comments: Preprint, under review
\\ ( https://arxiv.org/abs/2509.00221 ,  1825kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04112
replaced with revised version Mon, 24 Nov 2025 15:33:40 GMT   (2808kb)

Title: Synthetic Counterfactual Labels for Efficient Conformal Counterfactual
 Inference
Authors: Amirmohammad Farzaneh, Matteo Zecchin, Osvaldo Simeone
Categories: cs.LG cs.IT math.IT
\\ ( https://arxiv.org/abs/2509.04112 ,  2808kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10000
replaced with revised version Mon, 24 Nov 2025 13:26:06 GMT   (1699kb)

Title: Neural Scaling Laws for Deep Regression
Authors: Tilen Cadez and Kyoung-Min Kim
Categories: cs.LG cond-mat.other
Comments: Supplementary Information will be provided with the published
 manuscript
\\ ( https://arxiv.org/abs/2509.10000 ,  1699kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10729
replaced with revised version Sun, 23 Nov 2025 01:46:30 GMT   (361kb)

Title: Using LLMs for Late Multimodal Sensor Fusion for Activity Recognition
Authors: Ilker Demirel, Karan Thakkar, Benjamin Elizalde, Miquel Espi Marques,
 Shirley Ren, Jaya Narain
Categories: cs.LG
Comments: Preprint, under review
\\ ( https://arxiv.org/abs/2509.10729 ,  361kb)
------------------------------------------------------------------------------
\\
arXiv:2509.16825
replaced with revised version Mon, 24 Nov 2025 02:11:34 GMT   (1980kb)

Title: KANO: Kolmogorov-Arnold Neural Operator
Authors: Jin Lee, Ziming Liu, Xinling Yu, Yixuan Wang, Haewon Jeong, Murphy
 Yuezhen Niu, Zheng Zhang
Categories: cs.LG cs.AI cs.CE
\\ ( https://arxiv.org/abs/2509.16825 ,  1980kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20529
replaced with revised version Sun, 23 Nov 2025 02:44:04 GMT   (2305kb)

Title: MDBench: Benchmarking Data-Driven Methods for Model Discovery
Authors: Amirmohammad Ziaei Bideh, Aleksandra Georgievska, Jonathan Gryak
Categories: cs.LG
\\ ( https://arxiv.org/abs/2509.20529 ,  2305kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21519
replaced with revised version Mon, 24 Nov 2025 04:59:04 GMT   (536kb)

Title: Provable Scaling Laws of Feature Emergence from Learning Dynamics of
 Grokking
Authors: Yuandong Tian
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2509.21519 ,  536kb)
------------------------------------------------------------------------------
\\
arXiv:2509.22850
replaced with revised version Sun, 23 Nov 2025 08:00:41 GMT   (0kb,I)

Title: Boundary on the Table: Efficient Black-Box Decision-Based Attacks for
 Structured Data
Authors: Roie Kazoom, Yuval Ratzabi, Etamar Rothstein and Ofer Hadar
Categories: cs.LG cs.AI
Comments: Paper revision
\\ ( https://arxiv.org/abs/2509.22850 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01621
replaced with revised version Sat, 22 Nov 2025 16:51:56 GMT   (649kb)

Title: Posterior Collapse as a Phase Transition in Variational Autoencoders
Authors: Zhen Li, Fan Zhang, Zheng Zhang, Yu Chen
Categories: cs.LG
Comments: 14 pages, 12 figures
\\ ( https://arxiv.org/abs/2510.01621 ,  649kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01982
replaced with revised version Sat, 22 Nov 2025 13:14:32 GMT   (46251kb)

Title: Fine-Grained GRPO for Precise Preference Alignment in Flow Models
Authors: Yujie Zhou, Pengyang Ling, Jiazi Bu, Yibin Wang, Yuhang Zang, Jiaqi
 Wang, Li Niu, Guangtao Zhai
Categories: cs.LG cs.CV
Comments: Project Page: https://bujiazi.github.io/g2rpo.github.io/
\\ ( https://arxiv.org/abs/2510.01982 ,  46251kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02779
replaced with revised version Mon, 24 Nov 2025 13:14:48 GMT   (38kb)

Title: Optimal Rates for Generalization of Gradient Descent for Deep ReLU
 Classification
Authors: Yuanfan Li, Yunwen Lei, Zheng-Chu Guo, Yiming Ying
Categories: cs.LG
Comments: Published in NeurIPS 2025
\\ ( https://arxiv.org/abs/2510.02779 ,  38kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03265
replaced with revised version Sun, 23 Nov 2025 07:26:21 GMT   (6456kb)

Title: MindCraft: How Concept Trees Take Shape In Deep Models
Authors: Bowei Tian, Yexiao He, Wanghao Ye, Ziyao Wang, Meng Liu, Ang Li
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2510.03265 ,  6456kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04622
replaced with revised version Mon, 24 Nov 2025 11:53:20 GMT   (1015kb)

Title: Forecasting-based Biomedical Time-series Data Synthesis for Open Data
 and Robust AI
Authors: Youngjoon Lee, Seongmin Cho, Yehhyun Jo, Jinu Gong, Hyunjoo Jenny Lee,
 Joonhyuk Kang
Categories: cs.LG eess.SP
Comments: 22 pages
\\ ( https://arxiv.org/abs/2510.04622 ,  1015kb)
------------------------------------------------------------------------------
\\
arXiv:2510.10029
replaced with revised version Sat, 22 Nov 2025 17:00:03 GMT   (275kb)

Title: Experience-Efficient Model-Free Deep Reinforcement Learning Using
 Pre-Training
Authors: Ruoxing Yang
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2510.10029 ,  275kb)
------------------------------------------------------------------------------
\\
arXiv:2510.11839
replaced with revised version Sun, 23 Nov 2025 21:50:00 GMT   (5965kb)

Title: WaveletDiff: Multilevel Wavelet Diffusion For Time Series Generation
Authors: Yu-Hsiang Wang, Olgica Milenkovic
Categories: cs.LG
\\ ( https://arxiv.org/abs/2510.11839 ,  5965kb)
------------------------------------------------------------------------------
\\
arXiv:2510.15127
replaced with revised version Sat, 22 Nov 2025 01:08:16 GMT   (3238kb)

Title: Investigating the consequences of mechanical ventilation in clinical
 intensive care settings through an evolutionary game-theoretic framework
Authors: David J. Albers, Tell D. Bennett, Jana de Wiljes, George Hripcsak,
 Bradford J. Smith, Peter D. Sottile, J.N. Stroh
Categories: cs.LG math.OC q-bio.QM
\\ ( https://arxiv.org/abs/2510.15127 ,  3238kb)
------------------------------------------------------------------------------
\\
arXiv:2510.20792
replaced with revised version Sun, 23 Nov 2025 04:07:18 GMT   (3344kb)

Title: BadGraph: A Backdoor Attack Against Latent Diffusion Model for
 Text-Guided Graph Generation
Authors: Liang Ye, Shengqin Chen, Jiazhu Dai
Categories: cs.LG cs.CL q-bio.BM
\\ ( https://arxiv.org/abs/2510.20792 ,  3344kb)
------------------------------------------------------------------------------
\\
arXiv:2510.25354
replaced with revised version Mon, 24 Nov 2025 15:26:34 GMT   (5720kb)

Title: Analysis of Semi-Supervised Learning on Hypergraphs
Authors: Adrien Weihs, Andrea L. Bertozzi, Matthew Thorpe
Categories: cs.LG math.ST stat.TH
\\ ( https://arxiv.org/abs/2510.25354 ,  5720kb)
------------------------------------------------------------------------------
\\
arXiv:2510.26451
replaced with revised version Sat, 22 Nov 2025 09:10:45 GMT   (3170kb)

Title: Robust Graph Condensation via Classification Complexity Mitigation
Authors: Jiayi Luo, Qingyun Sun, Beining Yang, Haonan Yuan, Xingcheng Fu,
 Yanbiao Ma, Jianxin Li, Philip S. Yu
Categories: cs.LG cs.AI
Comments: Accepted by Neurips 2025 (Spotlight)
\\ ( https://arxiv.org/abs/2510.26451 ,  3170kb)
------------------------------------------------------------------------------
\\
arXiv:2510.26533
replaced with revised version Mon, 24 Nov 2025 15:37:40 GMT   (3373kb)

Title: Higher-Order Regularization Learning on Hypergraphs
Authors: Adrien Weihs, Andrea L. Bertozzi, Matthew Thorpe
Categories: cs.LG math.ST stat.TH
\\ ( https://arxiv.org/abs/2510.26533 ,  3373kb)
------------------------------------------------------------------------------
\\
arXiv:2510.26714
replaced with revised version Fri, 21 Nov 2025 16:22:19 GMT   (24kb)

Title: On the limitation of evaluating machine unlearning using only a single
 training seed
Authors: Jamie Lanyon, Axel Finke, Petros Andreou, Georgina Cosma
Categories: cs.LG cs.AI
Comments: mini paper, 2 figures
\\ ( https://arxiv.org/abs/2510.26714 ,  24kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00413
replaced with revised version Sat, 22 Nov 2025 14:11:09 GMT   (350kb)

Title: Tree Training: Accelerating Agentic LLMs Training via Shared Prefix
 Reuse
Authors: Shaojie Wang, Jinghui Wang, Yinghan Cui, Xuxing Chen, Chao Wang, Liang
 Huang, Xiaojiang Zhang, Junyi Peng, Li Wan, Haotian Zhang, Bin Chen
Categories: cs.LG
\\ ( https://arxiv.org/abs/2511.00413 ,  350kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00904
replaced with revised version Mon, 24 Nov 2025 17:25:02 GMT   (2623kb)

Title: Random Spiking Neural Networks are Stable and Spectrally Simple
Authors: Ernesto Araya, Massimiliano Datres, Gitta Kutyniok
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2511.00904 ,  2623kb)
------------------------------------------------------------------------------
\\
arXiv:2511.01836
replaced with revised version Mon, 24 Nov 2025 05:16:44 GMT   (39598kb)

Title: Priors in Time: Missing Inductive Biases for Language Model
 Interpretability
Authors: Ekdeep Singh Lubana, Can Rager, Sai Sumedh R. Hindupur, Valerie Costa,
 Greta Tuckute, Oam Patel, Sonia Krishna Murthy, Thomas Fel, Daniel Wurgaft,
 Eric J. Bigelow, Johnny Lin, Demba Ba, Martin Wattenberg, Fernanda Viegas,
 Melanie Weber, Aaron Mueller
Categories: cs.LG
Comments: Preprint
\\ ( https://arxiv.org/abs/2511.01836 ,  39598kb)
------------------------------------------------------------------------------
\\
arXiv:2511.02354
replaced with revised version Sat, 22 Nov 2025 09:08:45 GMT   (17212kb)

Title: Evolving Graph Learning for Out-of-Distribution Generalization in
 Non-stationary Environments
Authors: Qingyun Sun, Jiayi Luo, Haonan Yuan, Xingcheng Fu, Hao Peng, Jianxin
 Li, Philip S. Yu
Categories: cs.LG
Comments: Accepted by TPAMI
\\ ( https://arxiv.org/abs/2511.02354 ,  17212kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06831
replaced with revised version Sun, 23 Nov 2025 09:20:48 GMT   (4830kb)

Title: DeepRWCap: Neural-Guided Random-Walk Capacitance Solver for IC Design
Authors: Hector R. Rodriguez, Jiechen Huang, Wenjian Yu
Categories: cs.LG cs.AI
Comments: Accepted to AAAI-26
\\ ( https://arxiv.org/abs/2511.06831 ,  4830kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06837
replaced with revised version Sun, 23 Nov 2025 08:39:29 GMT   (8297kb)

Title: Minimum Width of Deep Narrow Networks for Universal Approximation
Authors: Xiao-Song Yang, Qi Zhou, Xuan Zhou
Categories: cs.LG
\\ ( https://arxiv.org/abs/2511.06837 ,  8297kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07372
replaced with revised version Mon, 24 Nov 2025 04:50:07 GMT   (127kb)

Title: Provable Benefit of Curriculum in Transformer Tree-Reasoning
 Post-Training
Authors: Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Hau-San Wong, Qingfu
 Zhang, Taiji Suzuki
Categories: cs.LG
\\ ( https://arxiv.org/abs/2511.07372 ,  127kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07390
replaced with revised version Sun, 23 Nov 2025 04:37:25 GMT   (1755kb)

Title: A Diffusion Model to Shrink Proteins While Maintaining Their Function
Authors: Ethan Baron and Alan N. Amin and Ruben Weitzman and Debora Marks and
 Andrew Gordon Wilson
Categories: cs.LG q-bio.QM
Comments: Code available at https://github.com/baronet2/SCISOR
\\ ( https://arxiv.org/abs/2511.07390 ,  1755kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07473
replaced with revised version Sat, 22 Nov 2025 01:32:28 GMT   (4924kb)

Title: RELEAP: Reinforcement-Enhanced Label-Efficient Active Phenotyping for
 Electronic Health Records
Authors: Yang Yang (1), Kathryn I. Pollak (2,3), Bibhas Chakraborty (1,4,5,6),
 Molei Liu (7,8), Doudou Zhou (6), Chuan Hong (1) ((1) Department of
 Biostatistics and Bioinformatics, Duke University, Durham, USA, (2) Duke
 Cancer Institute, Durham, USA, (3) Department of Population Health Sciences,
 Duke University School of Medicine, Durham, USA, (4) Centre for Quantitative
 Medicine, Duke-NUS Medical School, Singapore, (5) Programme in Health
 Services and Systems Research, Duke-NUS Medical School, Singapore, (6)
 Department of Statistics and Data Science, National University of Singapore,
 Singapore, (7) Department of Biostatistics, Peking University Health Science
 Center, Beijing, China, (8) Beijing International Center for Mathematical
 Research, Peking University, Beijing, China)
Categories: cs.LG cs.CY
Comments: 20 pages, 5 figures, 1 table. Includes supplementary material.
 Submitted to JAMIA Open. {\dag} These authors contributed equally.
 *Corresponding author: Chuan Hong
\\ ( https://arxiv.org/abs/2511.07473 ,  4924kb)
------------------------------------------------------------------------------
\\
arXiv:2511.09567
replaced with revised version Sun, 23 Nov 2025 00:09:06 GMT   (884kb)

Title: Let the Experts Speak: Improving Survival Prediction & Calibration via
 Mixture-of-Experts Heads
Authors: Todd Morrill, Aahlad Puli, Murad Megjhani, Soojin Park, Richard Zemel
Categories: cs.LG
Comments: Accepted as a proceedings paper at the 2025 Machine Learning for
 Health Symposium and as a workshop paper at the Learning from Time Series for
 Health workshop at NeurIPS 2025
\\ ( https://arxiv.org/abs/2511.09567 ,  884kb)
------------------------------------------------------------------------------
\\
arXiv:2511.10287
replaced with revised version Sun, 23 Nov 2025 07:33:16 GMT   (5684kb)

Title: OutSafe-Bench: A Benchmark for Multimodal Offensive Content Detection in
 Large Language Models
Authors: Yuping Yan, Yuhan Xie, Yuanshuai Li, Yingchao Yu, Lingjuan Lyu, Yaochu
 Jin
Categories: cs.LG cs.CL
\\ ( https://arxiv.org/abs/2511.10287 ,  5684kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11500
replaced with revised version Fri, 21 Nov 2025 19:15:16 GMT   (1060kb)

Title: Honesty over Accuracy: Trustworthy Language Models through Reinforced
 Hesitation
Authors: Mohamad Amin Mohamadi, Tianhao Wang, Zhiyuan Li
Categories: cs.LG
\\ ( https://arxiv.org/abs/2511.11500 ,  1060kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11667
replaced with revised version Sun, 23 Nov 2025 09:29:06 GMT   (541kb)

Title: Beyond Superficial Forgetting: Thorough Unlearning through Knowledge
 Density Estimation and Block Re-insertion
Authors: Feng Guo, Yuntao Wen, Shen Gao, Junshuo Zhang, Shuo Shang
Categories: cs.LG cs.AI
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2511.11667 ,  541kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11684
replaced with revised version Mon, 24 Nov 2025 16:42:03 GMT   (2717kb)

Title: A Bayesian Model for Multi-stage Censoring
Authors: Shuvom Sadhuka, Sophia Lin, Bonnie Berger, Emma Pierson
Categories: cs.LG stat.AP
Comments: Proceedings of ML4H 2025
MSC-class: I.2
\\ ( https://arxiv.org/abs/2511.11684 ,  2717kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11698
replaced with revised version Sat, 22 Nov 2025 03:52:34 GMT   (1882kb)

Title: Moirai 2.0: When Less Is More for Time Series Forecasting
Authors: Chenghao Liu and Taha Aksu and Juncheng Liu and Xu Liu and Hanshu Yan
 and Quang Pham and Silvio Savarese and Doyen Sahoo and Caiming Xiong and
 Junnan Li
Categories: cs.LG
Comments: 16 pages, 13 figures, and 1 table
\\ ( https://arxiv.org/abs/2511.11698 ,  1882kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11767
replaced with revised version Sun, 23 Nov 2025 05:36:23 GMT   (380kb)

Title: Learning Fair Representations with Kolmogorov-Arnold Networks
Authors: Amisha Priyadarshini, Sergio Gago-Masague
Categories: cs.LG cs.CY
Comments: Accepted at AAAI-26
\\ ( https://arxiv.org/abs/2511.11767 ,  380kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12041
replaced with revised version Sat, 22 Nov 2025 08:09:37 GMT   (461kb)

Title: Mesh-based Super-resolution of Detonation Flows with Multiscale Graph
 Transformers
Authors: Shivam Barwey and Pinaki Pal
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2511.12041 ,  461kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12808
replaced with revised version Sun, 23 Nov 2025 12:12:35 GMT   (812kb)

Title: Expressive Temporal Specifications for Reward Monitoring
Authors: Omar Adalat, Francesco Belardinelli
Categories: cs.LG cs.AI cs.LO
\\ ( https://arxiv.org/abs/2511.12808 ,  812kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13237
replaced with revised version Mon, 24 Nov 2025 09:47:20 GMT   (170kb)

Title: Counterfactual Explainable AI (XAI) Method for Deep Learning-Based
 Multivariate Time Series Classification
Authors: Alan G. Paredes Cetina, Kaouther Benguessoum, Raoni Louren\c{c}o and
 Sylvain Kubler
Categories: cs.LG stat.ML
Comments: Accepted in AAAI 2026 Technical Main Track
\\ ( https://arxiv.org/abs/2511.13237 ,  170kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13541
replaced with revised version Sun, 23 Nov 2025 07:09:35 GMT   (1581kb)

Title: Graph Out-of-Distribution Detection via Test-Time Calibration with Dual
 Dynamic Dictionaries
Authors: Yue Hou, Ruomei Liu, Yingke Su, Junran Wu, Ke Xu
Categories: cs.LG
Comments: Accepted by AAAI 2026 (The 40th Annual AAAI Conference on Artificial
 Intelligence)
\\ ( https://arxiv.org/abs/2511.13541 ,  1581kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14317
replaced with revised version Sun, 23 Nov 2025 17:59:46 GMT   (1649kb)

Title: Intervention Efficiency and Perturbation Validation Framework:
 Capacity-Aware and Robust Clinical Model Selection under the Rashomon Effect
Authors: Yuwen Zhang, Viet Tran, Paul Weng
Categories: cs.LG
\\ ( https://arxiv.org/abs/2511.14317 ,  1649kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15246
replaced with revised version Sat, 22 Nov 2025 09:38:06 GMT   (183kb)

Title: D2D Power Allocation via Quantum Graph Neural Network
Authors: Tung Giang Le, Xuan Tung Nguyen, Won-Joo Hwang
Categories: cs.LG
Journal-ref: 2025 Fifteenth International Conference on Mobile Computing and
 Ubiquitous Networking (ICMU)
DOI: 10.23919/ICMU65253.2025.11219153
\\ ( https://arxiv.org/abs/2511.15246 ,  183kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15393
replaced with revised version Sun, 23 Nov 2025 11:56:28 GMT   (2419kb)

Title: EVA-Net: Interpretable Anomaly Detection for Brain Health via Learning
 Continuous Aging Prototypes from One-Class EEG Cohorts
Authors: Kunyu Zhang, Mingxuan Wang, Xiangjie Shi, Haoxing Xu, Chao Zhang
Categories: cs.LG
\\ ( https://arxiv.org/abs/2511.15393 ,  2419kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15927
replaced with revised version Sun, 23 Nov 2025 05:32:34 GMT   (247kb)

Title: Breaking the Bottleneck with DiffuApriel: High-Throughput Diffusion LMs
 with Mamba Backbone
Authors: Vaibhav Singh, Oleksiy Ostapenko, Pierre-Andr\'e No\"el, Torsten
 Scholak
Categories: cs.LG cs.AI
Comments: 9 pages, 4 figures
\\ ( https://arxiv.org/abs/2511.15927 ,  247kb)
------------------------------------------------------------------------------
\\
arXiv:2407.20240
replaced with revised version Fri, 21 Nov 2025 19:33:33 GMT   (1363kb)

Title: Social and Ethical Risks Posed by General-Purpose LLMs for Settling
 Newcomers in Canada
Authors: Isar Nejadgholi and Maryam Molamohammadi and Samir Bakhtawar
Categories: cs.CY cs.AI
Comments: 26 pages, 8 figures
MSC-class: I.2.1, I.2.7
\\ ( https://arxiv.org/abs/2407.20240 ,  1363kb)
------------------------------------------------------------------------------
\\
arXiv:2408.12984 (*cross-listing*)
replaced with revised version Sun, 23 Nov 2025 15:18:07 GMT   (1958kb)

Title: PDDFormer: Pairwise Distance Distribution Graph Transformer for Crystal
 Material Property Prediction
Authors: Xiangxiang Shen, Zheng Wan, Lingfeng Wen, Licheng Sun, Jian Yang, Xuan
 Tang, Shing-Ho J. Lin, Xiao He, Mingsong Chen, Xian Wei
Categories: cond-mat.mtrl-sci cs.AI
Comments: 15pages,8 figures
\\ ( https://arxiv.org/abs/2408.12984 ,  1958kb)
------------------------------------------------------------------------------
\\
arXiv:2410.01791
replaced with revised version Sat, 22 Nov 2025 11:30:29 GMT   (26724kb)

Title: DreamGarden: A Designer Assistant for Growing Games from a Single Prompt
Authors: Sam Earle, Samyak Parajuli, Andrzej Banburski-Fahey
Categories: cs.HC cs.AI cs.CL
Comments: 30 pages + appendix, 11 figures, published at CHI 2025
\\ ( https://arxiv.org/abs/2410.01791 ,  26724kb)
------------------------------------------------------------------------------
\\
arXiv:2411.02462
replaced with revised version Sun, 23 Nov 2025 17:30:54 GMT   (262kb)

Title: Parameter-Efficient Fine-Tuning of Large Language Models for Unit Test
 Generation: An Empirical Study
Authors: Andr\'e Storhaug, Jingyue Li
Categories: cs.SE cs.AI cs.LG
Comments: 26 pages, 2 figures, 6 tables, 1 listing
\\ ( https://arxiv.org/abs/2411.02462 ,  262kb)
------------------------------------------------------------------------------
\\
arXiv:2412.15289
replaced with revised version Mon, 24 Nov 2025 04:42:27 GMT   (573kb)

Title: SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage
Authors: Xiaoning Dong, Wenbo Hu, Wei Xu, Tianxing He
Categories: cs.CR cs.AI cs.CL
Comments: ACL Findings 2025. Welcome to employ SATA as a baseline
\\ ( https://arxiv.org/abs/2412.15289 ,  573kb)
------------------------------------------------------------------------------
\\
arXiv:2412.17629
replaced with revised version Sun, 23 Nov 2025 14:03:32 GMT   (5257kb)

Title: Learn from Global Correlations: Enhancing Evolutionary Algorithm via
 Spectral GNN
Authors: Kaichen Ouyang, Zong Ke, Shengwei Fu, Lingjie Liu, Puning Zhao, Dayu
 Hu
Categories: cs.NE cs.AI
Comments: Accepted by the 40th Annual AAAI Conference on Artificial
 Intelligence
\\ ( https://arxiv.org/abs/2412.17629 ,  5257kb)
------------------------------------------------------------------------------
\\
arXiv:2501.10100
replaced with revised version Mon, 24 Nov 2025 18:17:51 GMT   (48167kb)

Title: Robotic World Model: A Neural Network Simulator for Robust Policy
 Optimization in Robotics
Authors: Chenhao Li, Andreas Krause, Marco Hutter
Categories: cs.RO cs.AI cs.LG
\\ ( https://arxiv.org/abs/2501.10100 ,  48167kb)
------------------------------------------------------------------------------
\\
arXiv:2501.11357 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 08:40:40 GMT   (0kb,I)

Title: On the dimension of pullback attractors in recurrent neural networks
Authors: Muhammed Fadera
Categories: math.DS cs.AI cs.LG
Comments: Issues with clarity and notation
\\ ( https://arxiv.org/abs/2501.11357 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2501.16466
replaced with revised version Sat, 22 Nov 2025 16:20:01 GMT   (1999kb)

Title: Incalmo: An Autonomous LLM-assisted System for Red Teaming Multi-Host
 Networks
Authors: Brian Singer, Keane Lucas, Lakshmi Adiga, Meghna Jain, Lujo Bauer,
 Vyas Sekar
Categories: cs.CR cs.AI
Comments: 18 pages, 15 figures
\\ ( https://arxiv.org/abs/2501.16466 ,  1999kb)
------------------------------------------------------------------------------
\\
arXiv:2501.17079
replaced with revised version Sun, 23 Nov 2025 10:11:13 GMT   (2545kb)

Title: Learning Mean Field Control on Sparse Graphs
Authors: Christian Fabian, Kai Cui, Heinz Koeppl
Categories: cs.MA cs.AI cs.GT cs.LG
Comments: Accepted at ICML 2025
\\ ( https://arxiv.org/abs/2501.17079 ,  2545kb)
------------------------------------------------------------------------------
\\
arXiv:2502.00313
replaced with revised version Sat, 22 Nov 2025 16:14:01 GMT   (821kb)

Title: Distributive Fairness in Large Language Models: Evaluating Alignment
 with Human Values
Authors: Hadi Hosseini and Samarth Khanna
Categories: cs.GT cs.AI cs.CL cs.MA
Comments: Accepted at NeurIPS 2025
\\ ( https://arxiv.org/abs/2502.00313 ,  821kb)
------------------------------------------------------------------------------
\\
arXiv:2503.05012
replaced with revised version Sun, 23 Nov 2025 07:25:07 GMT   (386kb)

Title: LLMs' Reshaping of People, Processes, Products, and Society in Software
 Development: A Comprehensive Exploration with Early Adopters
Authors: Benyamin Tabarsi, Heidi Reichert, Sam Gilson, Ally Limke, Sandeep
 Kuttal, Tiffany Barnes
Categories: cs.SE cs.AI cs.HC
\\ ( https://arxiv.org/abs/2503.05012 ,  386kb)
------------------------------------------------------------------------------
\\
arXiv:2503.20990
replaced with revised version Mon, 24 Nov 2025 03:22:59 GMT   (1414kb)

Title: FinAudio: A Benchmark for Audio Large Language Models in Financial
 Applications
Authors: Yupeng Cao, Haohang Li, Yangyang Yu, Shashidhar Reddy Javaji, Yueru
 He, Jimin Huang, Qianqian Xie, Xiao-yang Liu, K.P. Subbalakshmi, Meikang Qiu,
 Sophia Ananiadou, Jian-Yun Nie
Categories: cs.CE cs.AI cs.MM
\\ ( https://arxiv.org/abs/2503.20990 ,  1414kb)
------------------------------------------------------------------------------
\\
arXiv:2503.22688
replaced with revised version Sun, 23 Nov 2025 02:21:33 GMT   (916kb)

Title: CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large
 Language Models in Interactive Code Generation
Authors: Peiding Wang, Li Zhang, Fang Liu, Lin Shi, Minxiao Li, Bo Shen, An Fu
Categories: cs.SE cs.AI cs.PL
\\ ( https://arxiv.org/abs/2503.22688 ,  916kb)
------------------------------------------------------------------------------
\\
arXiv:2504.18662
replaced with revised version Mon, 24 Nov 2025 10:52:11 GMT   (786kb)

Title: M2R2: MultiModal Robotic Representation for Temporal Action Segmentation
Authors: Daniel Sliwowski and Dongheui Lee
Categories: cs.RO cs.AI
Comments: 8 pages, 6 figures, 2 tables
\\ ( https://arxiv.org/abs/2504.18662 ,  786kb)
------------------------------------------------------------------------------
\\
arXiv:2505.01383
replaced with revised version Fri, 21 Nov 2025 22:11:10 GMT   (4660kb)

Title: FalconWing: An Ultra-Light Indoor Fixed-Wing UAV Platform for
 Vision-Based Autonomy
Authors: Yan Miao, Will Shen, Hang Cui, Sayan Mitra
Categories: cs.RO cs.AI
\\ ( https://arxiv.org/abs/2505.01383 ,  4660kb)
------------------------------------------------------------------------------
\\
arXiv:2505.07078 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 14:03:22 GMT   (364kb)

Title: Can LLM-based Financial Investing Strategies Outperform the Market in
 Long Run?
Authors: Weixian Waylon Li, Hyeonjun Kim, Mihai Cucuringu, Tiejun Ma
Categories: q-fin.TR cs.AI cs.CE
Comments: Accepted to KDD 2026, Datasets & Benchmarks Track
\\ ( https://arxiv.org/abs/2505.07078 ,  364kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11579
replaced with revised version Sat, 22 Nov 2025 19:02:39 GMT   (717kb)

Title: Toward Adaptive Categories: Dimensional Governance for Agentic AI
Authors: Zeynep Engin and David Hand
Categories: cs.CY cs.AI cs.HC cs.LG cs.MA
Comments: 12 pages core text, 15 pages including references, 2 figures
\\ ( https://arxiv.org/abs/2505.11579 ,  717kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17648 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 03:27:05 GMT   (10508kb)

Title: Simulating Macroeconomic Expectations using LLM Agents
Authors: Jianhao Lin, Lexuan Sun, Yixin Yan
Categories: econ.GN cs.AI q-fin.EC
\\ ( https://arxiv.org/abs/2505.17648 ,  10508kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19574
replaced with revised version Sun, 23 Nov 2025 00:05:06 GMT   (22367kb)

Title: Situationally-Aware Dynamics Learning
Authors: Alejandro Murillo-Gonzalez, Lantao Liu
Categories: cs.RO cs.AI cs.LG math.OC
\\ ( https://arxiv.org/abs/2505.19574 ,  22367kb)
------------------------------------------------------------------------------
\\
arXiv:2506.06659
replaced with revised version Mon, 24 Nov 2025 03:32:51 GMT   (27477kb)

Title: DriveSuprim: Towards Precise Trajectory Selection for End-to-End
 Planning
Authors: Wenhao Yao, Zhenxin Li, Shiyi Lan, Zi Wang, Xinglong Sun, Jose M.
 Alvarez, Zuxuan Wu
Categories: cs.RO cs.AI cs.CV
Comments: Accepted to AAAI 2026
\\ ( https://arxiv.org/abs/2506.06659 ,  27477kb)
------------------------------------------------------------------------------
\\
arXiv:2506.09487
replaced with revised version Sat, 22 Nov 2025 03:34:54 GMT   (12119kb)

Title: BemaGANv2: A Tutorial and Comparative Survey of GAN-based Vocoders for
 Long-Term Audio Generation
Authors: Taesoo Park, Mungwi Jeong, Mingyu Park, Narae Kim, Junyoung Kim,
 Mujung Kim, Jisang Yoo, Hoyun Lee, Sanghoon Kim, Soonchul Kwon
Categories: cs.SD cs.AI cs.LG cs.LO eess.AS
Comments: 11 pages, 7 figures. Survey and tutorial paper. Currently under
 review at ICT Express as an extended version of our ICAIIC 2025 paper
ACM-class: I.2.6; H.5.5; I.5.1
\\ ( https://arxiv.org/abs/2506.09487 ,  12119kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10016
replaced with revised version Mon, 24 Nov 2025 16:26:13 GMT   (2516kb)

Title: A Survey of Generative Categories and Techniques in Multimodal
 Generative Models
Authors: Longzhen Han, Awes Mubarak, Almas Baimagambetov, Nikolaos Polatidis,
 Thar Baker
Categories: cs.MM cs.AI cs.CL
\\ ( https://arxiv.org/abs/2506.10016 ,  2516kb)
------------------------------------------------------------------------------
\\
arXiv:2506.23771
replaced with revised version Sat, 22 Nov 2025 06:43:10 GMT   (1500kb)

Title: Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior
 and Control of Autonomous Driving
Authors: Guizhe Jin, Zhuoren Li, Bo Leng, Ran Yu, Lu Xiong and Chen Sun
Categories: cs.RO cs.AI
Comments: 8 pages, accepted for publication in IEEE Robotics and Automation
 Letters (RAL)
DOI: 10.1109/LRA.2025.3623016
\\ ( https://arxiv.org/abs/2506.23771 ,  1500kb)
------------------------------------------------------------------------------
\\
arXiv:2507.02752 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 14:18:03 GMT   (2335kb)

Title: SynTwins: A Retrosynthesis-Guided Framework for Synthesizable Molecular
 Analog Generation
Authors: Shuan Chen, Gunwook Nam, Alan Aspuru-Guzik, Yousung Jung
Categories: physics.chem-ph cs.AI
\\ ( https://arxiv.org/abs/2507.02752 ,  2335kb)
------------------------------------------------------------------------------
\\
arXiv:2507.10510
replaced with revised version Mon, 24 Nov 2025 13:08:12 GMT   (8259kb)

Title: Chat with AI: The Surprising Turn of Real-time Video Communication from
 Human to AI
Authors: Jiangkai Wu, Zhiyuan Ren, Liming Liu, Xinggong Zhang
Categories: cs.NI cs.AI cs.HC cs.MM
Comments: 9 pages, 10 figures, Proceedings of the 24th ACM Workshop on Hot
 Topics in Networks (HotNets 2025), College Park, Maryland, USA
DOI: 10.1145/3772356.3772390
\\ ( https://arxiv.org/abs/2507.10510 ,  8259kb)
------------------------------------------------------------------------------
\\
arXiv:2507.10646
replaced with revised version Mon, 24 Nov 2025 01:18:11 GMT   (2099kb)

Title: CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based
 Code Assistance
Authors: Myeongsoo Kim, Shweta Garg, Baishakhi Ray, Varun Kumar, and Anoop
 Deoras
Categories: cs.SE cs.AI
Comments: Accepted to NeurIPS 2025 Datasets and Benchmarks Track
\\ ( https://arxiv.org/abs/2507.10646 ,  2099kb)
------------------------------------------------------------------------------
\\
arXiv:2507.16887
replaced with revised version Sat, 22 Nov 2025 18:09:14 GMT   (232kb)

Title: Revisiting Pre-trained Language Models for Vulnerability Detection
Authors: Youpeng Li, Weiliang Qi, Xuyu Wang, Fuxun Yu, Xinda Wang
Categories: cs.CR cs.AI cs.LG cs.SE
Comments: Accepted by the 21st ACM ASIA Conference on Computer and
 Communications Security (AsiaCCS 2026)
\\ ( https://arxiv.org/abs/2507.16887 ,  232kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02912
replaced with revised version Mon, 24 Nov 2025 18:31:13 GMT   (326kb)

Title: Communicating Plans, Not Percepts: Scalable Multi-Agent Coordination
 with Embodied World Models
Authors: Brennen A. Hill, Mant Koh En Wei, Thangavel Jishnuanandh
Categories: cs.MA cs.AI cs.LG cs.SY eess.SY
Comments: Published in the Proceedings of the 39th Conference on Neural
 Information Processing Systems (NeurIPS 2025) Workshop: Scaling Environments
 for Agents (SEA). Additionally accepted for presentation in the NeurIPS 2025
 Workshop: Embodied World Models for Decision Making (EWM) and the NeurIPS
 2025 Workshop: Optimization for Machine Learning (OPT)
MSC-class: 68T42, 68T05, 90C40, 93E35, 68T07
ACM-class: I.2.11; I.2.6; I.2.8
\\ ( https://arxiv.org/abs/2508.02912 ,  326kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02995
replaced with revised version Mon, 24 Nov 2025 17:11:32 GMT   (53kb)

Title: The Geometry of Cortical Computation: Manifold Disentanglement and
 Predictive Dynamics in VCNet
Authors: Brennen A. Hill, Zhang Xinyu, Timothy Putra Prasetio
Categories: cs.NE cs.AI cs.CV cs.LG
Comments: Published in the proceedings of the 39th Conference on Neural
 Information Processing Systems (NeurIPS 2025) Workshop: Symmetry and Geometry
 in Neural Representations (NeurReps). Additionally accepted for presentation
 in NeurIPS 2025 Workshop: Interpreting Cognition in Deep Learning Models
 (CogInterp)
MSC-class: 68T07, 68T45, 68U10
ACM-class: I.2.6; I.4.8; I.2.10; I.5.1
\\ ( https://arxiv.org/abs/2508.02995 ,  53kb)
------------------------------------------------------------------------------
\\
arXiv:2508.03546 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 19:22:25 GMT   (1575kb)

Title: Supervised Dynamic Dimension Reduction with Deep Neural Network
Authors: Zhanye Luo, Yuefeng Han and Xiufan Yu
Categories: stat.ML cs.AI cs.LG
\\ ( https://arxiv.org/abs/2508.03546 ,  1575kb)
------------------------------------------------------------------------------
\\
arXiv:2508.07742
replaced with revised version Mon, 24 Nov 2025 06:49:36 GMT   (61kb)

Title: A Rule-Based Approach to Specifying Preferences over Conflicting Facts
 and Querying Inconsistent Knowledge Bases
Authors: Meghyn Bienvenu, Camille Bourgaux, Katsumi Inoue, Robin Jean
Categories: cs.LO cs.AI cs.DB
Comments: This is an extended version of a paper appearing at the 22nd
 International Conference on Principles of Knowledge Representation and
 Reasoning (KR 2025). 24 pages. This version corrects Definition 4
\\ ( https://arxiv.org/abs/2508.07742 ,  61kb)
------------------------------------------------------------------------------
\\
arXiv:2508.12300
replaced with revised version Sat, 22 Nov 2025 03:18:28 GMT   (919kb)

Title: Mutually Assured Deregulation
Authors: Gilad Abiri
Categories: cs.CY cs.AI
\\ ( https://arxiv.org/abs/2508.12300 ,  919kb)
------------------------------------------------------------------------------
\\
arXiv:2508.17167
replaced with revised version Sun, 23 Nov 2025 13:47:52 GMT   (188kb)

Title: Error analysis for the deep Kolmogorov method
Authors: Iulian C\^impean and Thang Do and Lukas Gonon and Arnulf Jentzen and
 Ionel Popescu
Categories: math.NA cs.AI cs.NA math.AP
Comments: 40 pages
MSC-class: 68T07, 60H30
ACM-class: G.1.8; I.2.6
\\ ( https://arxiv.org/abs/2508.17167 ,  188kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18337 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 11:19:05 GMT   (13430kb)

Title: Warm Chat: Diffuse Emotion-aware Interactive Talking Head Avatar with
 Tree-Structured Guidance
Authors: Haijie Yang, Zhenyu Zhang, Hao Tang, Jianjun Qian, Jian Yang
Categories: eess.AS cs.AI cs.SD
Comments: The submission is withdrawn at the request of the authors due to
 internal reasons within the research team
\\ ( https://arxiv.org/abs/2508.18337 ,  13430kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20840
replaced with revised version Mon, 24 Nov 2025 03:42:01 GMT   (13180kb)

Title: Learning Primitive Embodied World Models: Towards Scalable Robotic
 Learning
Authors: Qiao Sun, Liujia Yang, Wei Tang, Wei Huang, Kaixin Xu, Yongchao Chen,
 Mingyu Liu, Jiange Yang, Haoyi Zhu, Yating Wang, Tong He, Yilun Chen, Xili
 Dai, Nanyang Ye, Qinying Gu
Categories: cs.RO cs.AI cs.MM
\\ ( https://arxiv.org/abs/2508.20840 ,  13180kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21327 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 02:48:14 GMT   (18938kb)

Title: Assessment of deep learning models integrated with weather and
 environmental variables for wildfire spread prediction and a case study of
 the 2023 Maui fires
Authors: Jiyeon Kim and Yingjie Hu and Negar Elhami-Khorasani and Kai Sun and
 Ryan Zhenqi Zhou
Categories: physics.soc-ph cs.AI cs.LG
\\ ( https://arxiv.org/abs/2509.21327 ,  18938kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03463
replaced with revised version Mon, 24 Nov 2025 18:11:57 GMT   (485kb)

Title: ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering
 Framework
Authors: Vali Tawosi, Keshav Ramani, Salwa Alamir, Xiaomo Liu
Categories: cs.SE cs.AI
Comments: Accepted to MAS-GAIN Workshop at ASE 2025
\\ ( https://arxiv.org/abs/2510.03463 ,  485kb)
------------------------------------------------------------------------------
\\
arXiv:2510.13814
replaced with revised version Fri, 21 Nov 2025 19:38:51 GMT   (3053kb)

Title: Reversing the Lens: Using Explainable AI to Understand Human Expertise
Authors: Roussel Rahman, Aashwin Ananda Mishra, and Wan-Lin Hu
Categories: cs.HC cs.AI cs.LG
\\ ( https://arxiv.org/abs/2510.13814 ,  3053kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00230
replaced with revised version Sat, 22 Nov 2025 00:19:11 GMT   (10527kb)

Title: Neural Transparency: Mechanistic Interpretability Interfaces for
 Anticipating Model Behaviors for Personalized AI
Authors: Sheer Karny, Anthony Baez, Pat Pataranutaporn
Categories: cs.HC cs.AI
Comments: SK and AB are co-first authors
\\ ( https://arxiv.org/abs/2511.00230 ,  10527kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00634
replaced with revised version Mon, 24 Nov 2025 17:55:01 GMT   (20312kb)

Title: Node Preservation and its Effect on Crossover in Cartesian Genetic
 Programming
Authors: Mark Kocherovsky, Illya Bakurov, Wolfgang Banzhaf
Categories: cs.NE cs.AI cs.LG
Comments: Draft to cite in another paper before both papers are peer-reviewed
 for the evo*2026 conference, 21 pages, 5 figures
\\ ( https://arxiv.org/abs/2511.00634 ,  20312kb)
------------------------------------------------------------------------------
\\
arXiv:2511.02162
replaced with revised version Sat, 22 Nov 2025 22:47:57 GMT   (30813kb)

Title: Text to Robotic Assembly of Multi Component Objects using 3D Generative
 AI and Vision Language Models
Authors: Alexander Htet Kyaw, Richa Gupta, Dhruv Shah, Anoop Sinha, Kory
 Mathewson, Stefanie Pender, Sachin Chitta, Yotto Koga, Faez Ahmed, Lawrence
 Sass, and Randall Davis
Categories: cs.RO cs.AI cs.HC
Comments: Accepted to NeurIPS 2025, Conference on Neural Information Processing
 Systems, Creative AI Track
\\ ( https://arxiv.org/abs/2511.02162 ,  30813kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06345
replaced with revised version Mon, 24 Nov 2025 11:46:50 GMT   (190kb)

Title: PRAGMA: A Profiling-Reasoned Multi-Agent Framework for Automatic Kernel
 Optimization
Authors: Kelun Lei, Hailong Yang, Huaitao Zhang, Xin You, Kaige Zhang, Zhongzhi
 Luan, Yi Liu, Depei Qian
Categories: cs.DC cs.AI
\\ ( https://arxiv.org/abs/2511.06345 ,  190kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06852
replaced with revised version Mon, 24 Nov 2025 11:44:59 GMT   (1640kb)

Title: Differentiated Directional Intervention A Framework for Evading LLM
 Safety Alignment
Authors: Peng Zhang, Peijie Sun
Categories: cs.CR cs.AI cs.LG cs.SE
Comments: AAAI-26-AIA
\\ ( https://arxiv.org/abs/2511.06852 ,  1640kb)
------------------------------------------------------------------------------
\\
arXiv:2511.08637
replaced with revised version Sun, 23 Nov 2025 03:20:17 GMT   (3541kb)

Title: How do data owners say no? A case study of data consent mechanisms in
 web-scraped vision-language AI training datasets
Authors: Chung Peng Lee, Rachel Hong, Harry H. Jiang, Aster Plotnik, William
 Agnew, Jamie Morgenstern
Categories: cs.CY cs.AI cs.CR
\\ ( https://arxiv.org/abs/2511.08637 ,  3541kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11480 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 12:53:25 GMT   (4221kb)

Title: Inferring response times of perceptual decisions with Poisson
 variational autoencoders
Authors: Hayden R. Johnson, Anastasia N. Krouglova, Hadi Vafaii, Jacob L.
 Yates, Pedro J. Gon\c{c}alves
Categories: q-bio.NC cs.AI cs.LG
Comments: To appear at the NeurIPS 2025 Workshop on Data on the Brain \& Mind
\\ ( https://arxiv.org/abs/2511.11480 ,  4221kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13219
replaced with revised version Mon, 24 Nov 2025 04:08:20 GMT   (2397kb)

Title: FoleyBench: A Benchmark For Video-to-Audio Models
Authors: Satvik Dixit, Koichi Saito, Zhi Zhong, Yuki Mitsufuji, Chris Donahue
Categories: cs.SD cs.AI eess.AS
\\ ( https://arxiv.org/abs/2511.13219 ,  2397kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13646
replaced with revised version Mon, 24 Nov 2025 15:55:51 GMT   (804kb)

Title: Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?
Authors: Chunqiu Steven Xia, Zhe Wang, Yan Yang, Yuxiang Wei, Lingming Zhang
Categories: cs.SE cs.AI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2511.13646 ,  804kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15015
replaced with revised version Mon, 24 Nov 2025 00:36:49 GMT   (216kb)

Title: Dynamic Expert Quantization for Scalable Mixture-of-Experts Inference
Authors: Kexin Chu and Dawei Xiang and Zixu Shen and Yiwei Yang and Zecheng Liu
 and Wei Zhang
Categories: cs.PF cs.AI cs.LG
Comments: 7 pages
\\ ( https://arxiv.org/abs/2511.15015 ,  216kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15165
replaced with revised version Sat, 22 Nov 2025 02:00:56 GMT   (1664kb)

Title: Can MLLMs Detect Phishing? A Comprehensive Security Benchmark Suite
 Focusing on Dynamic Threats and Multimodal Evaluation in Academic
 Environments
Authors: Jingzhuo Zhou
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2511.15165 ,  1664kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15253
replaced with revised version Mon, 24 Nov 2025 02:51:05 GMT   (1115kb)

Title: PresentCoach: Dual-Agent Presentation Coaching through Exemplars and
 Interactive Feedback
Authors: Sirui Chen and Jinsong Zhou and Xinli Xu and Xiaoyu Yang and Litao Guo
 and Ying-Cong Chen
Categories: cs.HC cs.AI
Comments: 13pages,6figures
\\ ( https://arxiv.org/abs/2511.15253 ,  1115kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15846
replaced with revised version Mon, 24 Nov 2025 18:52:00 GMT   (1492kb)

Title: The Loss of Control Playbook: Degrees, Dynamics, and Preparedness
Authors: Charlotte Stix, Annika Hallensleben, Alejandro Ortega, Matteo Pistillo
Categories: cs.CY cs.AI
\\ ( https://arxiv.org/abs/2511.15846 ,  1492kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15998
replaced with revised version Fri, 21 Nov 2025 18:10:35 GMT   (1023kb)

Title: Hiding in the AI Traffic: Abusing MCP for LLM-Powered Agentic Red
 Teaming
Authors: Strahinja Janjusevic, Anna Baron Garcia, Sohrob Kazerounian
Categories: cs.CR cs.AI
Comments: 23 pages, 9 figures, 3 tables. Submitted as a full paper for review
ACM-class: C.2.0; D.4.6; K.6.5
\\ ( https://arxiv.org/abs/2511.15998 ,  1023kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16088
replaced with revised version Mon, 24 Nov 2025 09:21:12 GMT   (681kb)

Title: Future-Back Threat Modeling: A Foresight-Driven Security Framework
Authors: Vu Van Than
Categories: cs.CR cs.AI cs.CY
\\ ( https://arxiv.org/abs/2511.16088 ,  681kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17443
replaced with revised version Mon, 24 Nov 2025 09:38:31 GMT   (1472kb)

Title: GRAPHIC--Guidelines for Reviewing Algorithmic Practices in Human-centred
 Design and Interaction for Creativity
Authors: Joana Rovira Martins, Pedro Martins and Ana Boavida
Categories: cs.HC cs.AI cs.GR
Comments: 20 pages, 16 figures
\\ ( https://arxiv.org/abs/2511.17443 ,  1472kb)
------------------------------------------------------------------------------
\\
arXiv:2503.04763
replaced with revised version Mon, 24 Nov 2025 18:41:20 GMT   (8854kb)

Title: MiniF2F in Rocq: Automatic Translation Between Proof Assistants -- A
 Case Study
Authors: Jules Viennot, Guillaume Baudart, Emilio Jes\`us Gallego Arias, Marc
 Lelarge
Categories: cs.LO cs.CL cs.LG cs.PL
\\ ( https://arxiv.org/abs/2503.04763 ,  8854kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01813
replaced with revised version Sat, 22 Nov 2025 06:56:44 GMT   (3960kb)

Title: ShortageSim: Simulating Drug Shortages under Information Asymmetry
Authors: Mingxuan Cui, Yilan Jiang, Duo Zhou, Cheng Qian, Yuji Zhang, Qiong
 Wang
Categories: cs.MA cs.CL cs.GT
Comments: Accepted by AAAI 2026. Oral Presentation
\\ ( https://arxiv.org/abs/2509.01813 ,  3960kb)
------------------------------------------------------------------------------
\\
arXiv:2109.05265
replaced with revised version Sun, 23 Nov 2025 14:12:30 GMT   (8590kb)

Title: Advancing Autonomous Driving: DepthSense with Radar and Spatial
 Attention
Authors: Muhamamd Ishfaq Hussain, Zubia Naz, Muhammad Aasim Rafique and Moongu
 Jeon
Categories: cs.RO cs.CV cs.LG
Journal-ref: IEEE Sensors Journal 2025
DOI: 10.1109/JSEN.2024.3493196
\\ ( https://arxiv.org/abs/2109.05265 ,  8590kb)
------------------------------------------------------------------------------
\\
arXiv:2409.06714 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 00:13:36 GMT   (6945kb)

Title: FCDM: A Physics-Guided Bidirectional Frequency Aware Convolution and
 Diffusion-Based Model for Sinogram Inpainting
Authors: Jiaze E, Srutarshi Banerjee, Tekin Bicer, Guannan Wang, Yanfu Zhang,
 Bin Ren
Categories: eess.IV cs.CV
\\ ( https://arxiv.org/abs/2409.06714 ,  6945kb)
------------------------------------------------------------------------------
\\
arXiv:2409.13930 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 06:06:48 GMT   (2427kb)

Title: RN-SDEs: Limited-Angle CT Reconstruction with Residual Null-Space
 Diffusion Stochastic Differential Equations
Authors: Jiaqi Guo, Santiago Lopez-Tapia, Wing Shun Li, Yunan Wu, Marcelo
 Carignano, Martin Kr\"oger, Vinayak P. Dravid, Igal Szleifer, Vadim Backman,
 Aggelos K. Katsaggelos
Categories: eess.IV cs.CV
\\ ( https://arxiv.org/abs/2409.13930 ,  2427kb)
------------------------------------------------------------------------------
\\
arXiv:2411.12175
replaced with revised version Sun, 23 Nov 2025 05:07:06 GMT   (3209kb)

Title: AsynEIO: Asynchronous Monocular Event-Inertial Odometry Using Gaussian
 Process Regression
Authors: Zhixiang Wang, Xudong Li, Yizhai Zhang, Fan Zhang, and Panfeng Huang
Categories: cs.RO cs.CV
Comments: 20 pages, 20 figures
Journal-ref: IEEE Transactions on Robotics, vol. 41, pp. 5020-5039, 2025
DOI: 10.1109/TRO.2025.3598145
\\ ( https://arxiv.org/abs/2411.12175 ,  3209kb)
------------------------------------------------------------------------------
\\
arXiv:2411.16598
replaced with revised version Fri, 21 Nov 2025 20:06:23 GMT   (9880kb)

Title: DiffBreak: Is Diffusion-Based Purification Robust?
Authors: Andre Kassis, Urs Hengartner and Yaoliang Yu
Categories: cs.CR cs.CV cs.LG
Comments: Accepted to NeurIPS 2025
\\ ( https://arxiv.org/abs/2411.16598 ,  9880kb)
------------------------------------------------------------------------------
\\
arXiv:2412.08484
replaced with revised version Sun, 23 Nov 2025 17:06:24 GMT   (9043kb)

Title: MeshCone: Second-Order Cone Programming for Geometrically-Constrained
 Mesh Enhancement
Authors: Alexander Valverde
Categories: cs.GR cs.CV math.OC
\\ ( https://arxiv.org/abs/2412.08484 ,  9043kb)
------------------------------------------------------------------------------
\\
arXiv:2501.18921 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 01:29:11 GMT   (2411kb)

Title: Full-scale Representation Guided Network for Retinal Vessel Segmentation
Authors: Sunyong Seo, Sangwook Yoo, Huisu Yoon
Categories: eess.IV cs.CV
Comments: 12 pages, 7 figures
DOI: 10.1186/s12880-025-02021-4
\\ ( https://arxiv.org/abs/2501.18921 ,  2411kb)
------------------------------------------------------------------------------
\\
arXiv:2504.14135
replaced with revised version Sun, 23 Nov 2025 18:25:14 GMT   (41975kb)

Title: Unreal Robotics Lab: A High-Fidelity Robotics Simulator with Advanced
 Physics and Rendering
Authors: Jonathan Embley-Riches, Jianwei Liu, Simon Julier, Dimitrios Kanoulas
Categories: cs.RO cs.CV cs.GR cs.LG
\\ ( https://arxiv.org/abs/2504.14135 ,  41975kb)
------------------------------------------------------------------------------
\\
arXiv:2505.05592
replaced with revised version Fri, 21 Nov 2025 23:01:58 GMT   (6064kb)

Title: Learning to Drive Anywhere with Model-Based Reannotation
Authors: Noriaki Hirose, Lydia Ignatova, Kyle Stachowicz, Catherine Glossop,
 Sergey Levine, Dhruv Shah
Categories: cs.RO cs.CV cs.LG cs.SY eess.SY
Comments: 9 pages, 8 figures, 6 tables
Journal-ref: IEEE Robotics and Automation Letters 2025
\\ ( https://arxiv.org/abs/2505.05592 ,  6064kb)
------------------------------------------------------------------------------
\\
arXiv:2507.00416
replaced with revised version Mon, 24 Nov 2025 11:10:14 GMT   (4201kb)

Title: Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding
Authors: Tao Lin, Gen Li, Yilei Zhong, Yanwen Zou, Yuxin Du, Jiting Liu,
 Encheng Gu, Bo Zhao
Categories: cs.RO cs.CV
\\ ( https://arxiv.org/abs/2507.00416 ,  4201kb)
------------------------------------------------------------------------------
\\
arXiv:2507.16621
replaced with revised version Mon, 24 Nov 2025 17:08:56 GMT   (1295kb)

Title: A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System
Authors: Lorenzo Gentilini, Pierpaolo Serio, Valentina Donzella, Lorenzo
 Pollini
Categories: cs.RO cs.CV
Comments: RiTA 2025 Accepted, 13 Pages, 6 Figures and 2 Tables
\\ ( https://arxiv.org/abs/2507.16621 ,  1295kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05186
replaced with revised version Mon, 24 Nov 2025 03:28:59 GMT   (11003kb)

Title: Learning to See and Act: Task-Aware Virtual View Exploration for Robotic
 Manipulation
Authors: Yongjie Bai, Zhouxia Wang, Yang Liu, Kaijun Luo, Yifan Wen, Mingtong
 Dai, Weixing Chen, Ziliang Chen, Lingbo Liu, Guanbin Li, Liang Lin
Categories: cs.RO cs.CV
Comments: 24 pages, 15 figures, project page:
 https://hcplab-sysu.github.io/TAVP
\\ ( https://arxiv.org/abs/2508.05186 ,  11003kb)
------------------------------------------------------------------------------
\\
arXiv:2511.08917
replaced with revised version Sat, 22 Nov 2025 22:58:28 GMT   (11977kb)

Title: "It's trained by non-disabled people": Evaluating How Image Quality
 Affects Product Captioning with VLMs
Authors: Kapil Garg, Xinru Tang, Jimin Heo, Dwayne R. Morgan, Darren Gergle,
 Erik B. Sudderth, and Anne Marie Piper
Categories: cs.HC cs.CV
Comments: Paper under review
\\ ( https://arxiv.org/abs/2511.08917 ,  11977kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17126 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 02:34:08 GMT   (18790kb)

Title: OmniLens++: Blind Lens Aberration Correction via Large LensLib
 Pre-Training and Latent PSF Representation
Authors: Qi Jiang, Xiaolong Qian, Yao Gao, Lei Sun, Kailun Yang, Zhonghua Yi,
 Wenyong Li, Ming-Hsuan Yang, Luc Van Gool, Kaiwei Wang
Categories: eess.IV cs.CV cs.LG physics.optics
Comments: The source code and datasets will be made publicly available at
 https://github.com/zju-jiangqi/OmniLens2
\\ ( https://arxiv.org/abs/2511.17126 ,  18790kb)
------------------------------------------------------------------------------
\\
arXiv:2210.02292
replaced with revised version Mon, 24 Nov 2025 15:57:49 GMT   (57kb)

Title: Double-Ended Palindromic Trees in Linear Time
Authors: Qisheng Wang and Ming Yang and Xinrui Zhu
Categories: cs.DS cs.DM cs.IR
Comments: Full version, 64 pages, 2 tables, 17 algorithms. Title changed,
 abstract improved, some proofs simplified, the persistent part removed for
 simplicity
Journal-ref: Information and Computation, 307: 105379, 2025
DOI: 10.1016/j.ic.2025.105379
\\ ( https://arxiv.org/abs/2210.02292 ,  57kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10545
replaced with revised version Sun, 23 Nov 2025 12:01:52 GMT   (522kb)

Title: Decentralized Identity Management on Ripple: A Conceptual Framework for
 High-Speed, Low-Cost Identity Transactions in Attestation-Based
 Attribute-Based Identity
Authors: Ruwanga Konara, Kasun De Zoysa, Asanka Sayakkara
Categories: cs.CR cs.IR
MSC-class: E.1, H.3.3, E.3
ACM-class: E.1; H.3.3; E.3
\\ ( https://arxiv.org/abs/2509.10545 ,  522kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07280 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 16:50:54 GMT   (3346kb)

Title: The Value of Personalized Recommendations: Evidence from Netflix
Authors: Kevin Zielnicki, Guy Aridor, Aur\'elien Bibaut, Allen Tran, Winston
 Chou, Nathan Kallus
Categories: econ.GN cs.IR cs.LG q-fin.EC
\\ ( https://arxiv.org/abs/2511.07280 ,  3346kb)
------------------------------------------------------------------------------
\\
arXiv:2105.13921
replaced with revised version Sat, 22 Nov 2025 15:20:14 GMT   (100kb)

Title: tensorflow-riemopt: A Library for Optimization on Riemannian Manifolds
Authors: Oleg Smirnov
Categories: cs.MS cs.CG cs.LG
\\ ( https://arxiv.org/abs/2105.13921 ,  100kb)
------------------------------------------------------------------------------
\\
arXiv:2202.02419
replaced with revised version Sun, 23 Nov 2025 01:17:08 GMT   (1178kb)

Title: Learning to Admit Optimally in an $M/M/k/k+N$ Queueing System with
 Unknown Service Rate
Authors: Saghar Adler, Mehrdad Moharrami and Vijay Subramanian
Categories: eess.SY cs.LG cs.SY
\\ ( https://arxiv.org/abs/2202.02419 ,  1178kb)
------------------------------------------------------------------------------
\\
arXiv:2209.07396 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 12:23:05 GMT   (242kb)

Title: Towards Healing the Blindness of Score Matching
Authors: Mingtian Zhang and Oscar Key and Peter Hayes and David Barber and
 Brooks Paige and Fran\c{c}ois-Xavier Briol
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2209.07396 ,  242kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00833
replaced with revised version Sun, 23 Nov 2025 17:51:50 GMT   (3443kb)

Title: When Does Bottom-up Beat Top-down in Hierarchical Community Detection?
Authors: Maximilien Dreveton, Daichi Kuroda, Matthias Grossglauser, Patrick
 Thiran
Categories: cs.SI cs.LG math.ST stat.ME stat.ML stat.TH
DOI: 10.1080/01621459.2025.2569711
\\ ( https://arxiv.org/abs/2306.00833 ,  3443kb)
------------------------------------------------------------------------------
\\
arXiv:2306.11497 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 12:16:46 GMT   (57kb)

Title: Convergence and concentration properties of constant step-size SGD
 through Markov chains
Authors: Ibrahim Merad and St\'ephane Ga\"iffas
Categories: stat.ML cs.LG math.OC
\\ ( https://arxiv.org/abs/2306.11497 ,  57kb)
------------------------------------------------------------------------------
\\
arXiv:2307.08038 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 04:57:26 GMT   (2108kb)

Title: Bivariate DeepKriging for Large-scale Spatial Interpolation of Wind
 Fields
Authors: Pratik Nag, Ying Sun and Brian J Reich
Categories: stat.ML cs.LG physics.ao-ph
\\ ( https://arxiv.org/abs/2307.08038 ,  2108kb)
------------------------------------------------------------------------------
\\
arXiv:2310.06339 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 03:01:04 GMT   (0kb,I)

Title: Automatic nodule identification and differentiation in ultrasound videos
 to facilitate per-nodule examination
Authors: Siyuan Jiang, Yan Ding, Yuling Wang, Lei Xu, Wenli Dai, Wanru Chang,
 Jianfeng Zhang, Jie Yu, Jianqiao Zhou, Chunquan Zhang, Ping Liang, Dexing
 Kong
Categories: eess.IV cs.LG
Comments: The authors wish to withdraw this manuscript as it requires major
 revisions that substantially change the methodology and conclusions. A
 significantly updated version of this work may be submitted elsewhere at a
 later date. Thank you for your understanding
\\ ( https://arxiv.org/abs/2310.06339 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2402.07388 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 02:35:48 GMT   (46kb)

Title: The Limits of Assumption-free Tests for Algorithm Performance
Authors: Yuetian Luo and Rina Foygel Barber
Categories: math.ST cs.LG stat.ML stat.TH
\\ ( https://arxiv.org/abs/2402.07388 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2404.10769
replaced with revised version Sun, 23 Nov 2025 06:45:39 GMT   (29kb)

Title: Finite-dimensional approximations of push-forwards on locally analytic
 functionals
Authors: Isao Ishikawa
Categories: math.NA cs.LG cs.NA math.CV math.DS math.FA
Comments: 28 pages. Comments are welcome
MSC-class: Primary 37C30, Secondary 32E30, 30H20, 41A25, 46F15
\\ ( https://arxiv.org/abs/2404.10769 ,  29kb)
------------------------------------------------------------------------------
\\
arXiv:2405.15643 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 05:20:18 GMT   (8594kb)

Title: An Unconditional Representation of the Conditional Score in
 Infinite-Dimensional Linear Inverse Problems
Authors: Fabian Schneider and Duc-Lam Duong and Matti Lassas and Maarten V. de
 Hoop and Tapio Helin
Categories: stat.ML cs.LG cs.NA math.AP math.NA math.PR
Comments: 37 pages, 13 figures, 3 tables. Accepted in TMLR November 2025
MSC-class: 62F15, 65N21, 68Q32, 60Hxx, 60Jxx, 68T07, 92C55
\\ ( https://arxiv.org/abs/2405.15643 ,  8594kb)
------------------------------------------------------------------------------
\\
arXiv:2405.20124 (*cross-listing*)
replaced with revised version Sun, 23 Nov 2025 19:03:23 GMT   (1268kb)

Title: A Geometric Unification of Distributionally Robust Covariance
 Estimators: Shrinking the Spectrum by Inflating the Ambiguity Set
Authors: Man-Chung Yue, Yves Rychener, Daniel Kuhn, Viet Anh Nguyen
Categories: stat.ML cs.LG math.OC
\\ ( https://arxiv.org/abs/2405.20124 ,  1268kb)
------------------------------------------------------------------------------
\\
arXiv:2409.00651 (*cross-listing*)
replaced with revised version Sun, 23 Nov 2025 11:59:20 GMT   (0kb,I)

Title: Adapting Physics-Informed Neural Networks for Bifurcation Detection in
 Ecological Migration Models
Authors: Lujie Yin and Xing Lv
Categories: nlin.CD cs.CY cs.LG q-bio.QM
Comments: Upon further review, we have concluded that the study is not yet
 complete and requires additional data and validation to support its findings
\\ ( https://arxiv.org/abs/2409.00651 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2409.14980 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 11:54:06 GMT   (784kb)

Title: (De)-regularized Maximum Mean Discrepancy Gradient Flow
Authors: Zonghao Chen, Aratrika Mustafi, Pierre Glaser, Anna Korba, Arthur
 Gretton, Bharath K. Sriperumbudur
Categories: stat.ML cs.LG
Journal-ref: Journal of Machine Learning Research 2025
\\ ( https://arxiv.org/abs/2409.14980 ,  784kb)
------------------------------------------------------------------------------
\\
arXiv:2410.20153 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 12:43:15 GMT   (97kb)

Title: The inexact power augmented Lagrangian method for constrained nonconvex
 optimization
Authors: Alexander Bodard, Konstantinos Oikonomidis, Emanuel Laude, Panagiotis
 Patrinos
Categories: math.OC cs.LG
Comments: Accepted for publication in Transactions on Machine Learning Research
\\ ( https://arxiv.org/abs/2410.20153 ,  97kb)
------------------------------------------------------------------------------
\\
arXiv:2411.13598
replaced with revised version Sun, 23 Nov 2025 07:57:59 GMT   (1486kb)

Title: Preserving Expert-Level Privacy in Offline Reinforcement Learning
Authors: Navodita Sharma, Vishnu Vinod, Abhradeep Thakurta, Alekh Agarwal,
 Borja Balle, Christoph Dann, Aravindan Raghuveer
Categories: cs.CR cs.LG
Comments: Top 10% submission at TMLR (J2C Certification)
\\ ( https://arxiv.org/abs/2411.13598 ,  1486kb)
------------------------------------------------------------------------------
\\
arXiv:2501.00452
replaced with revised version Sat, 22 Nov 2025 04:42:15 GMT   (2127kb)

Title: Unrolled Creative Adversarial Network For Generating Novel Musical
 Pieces
Authors: Pratik Nag
Categories: cs.SD cs.LG eess.AS
\\ ( https://arxiv.org/abs/2501.00452 ,  2127kb)
------------------------------------------------------------------------------
\\
arXiv:2501.18617
replaced with revised version Sun, 23 Nov 2025 23:41:55 GMT   (21749kb)

Title: DarkMind: Latent Chain-of-Thought Backdoor in Customized LLMs
Authors: Zhen Guo, Shanghao Shi, Shamim Yazdani, Ning Zhang, Reza Tourani
Categories: cs.CR cs.LG
Comments: 19 pages, 15 figures, 12 tables
\\ ( https://arxiv.org/abs/2501.18617 ,  21749kb)
------------------------------------------------------------------------------
\\
arXiv:2503.15107 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 09:33:15 GMT   (500kb)

Title: Interpretability of Graph Neural Networks to Assess Effects of Global
 Change Drivers on Ecological Networks
Authors: Emre Anakok, Pierre Barbillon, Colin Fontaine, Elisa Thebault
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2503.15107 ,  500kb)
------------------------------------------------------------------------------
\\
arXiv:2503.16737 (*cross-listing*)
replaced with revised version Sun, 23 Nov 2025 21:08:16 GMT   (2237kb)

Title: Revenue Maximization Under Sequential Price Competition Via The
 Estimation Of s-Concave Demand Functions
Authors: Daniele Bracale, Moulinath Banerjee, Cong Shi and Yuekai Sun
Categories: stat.ML cs.LG math.PR math.ST stat.TH
\\ ( https://arxiv.org/abs/2503.16737 ,  2237kb)
------------------------------------------------------------------------------
\\
arXiv:2504.16941 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 13:12:10 GMT   (172kb)

Title: Mathematical Insights into Protein Architecture: Persistent Homology and
 Machine Learning Applied to the Flagellar Motor
Authors: Zakaria Lamine, Abdelatif Hafid, Mohamed Rahouti, My Ismail Mamouni
Categories: q-bio.BM cs.LG math.AT
\\ ( https://arxiv.org/abs/2504.16941 ,  172kb)
------------------------------------------------------------------------------
\\
arXiv:2504.20906
replaced with revised version Mon, 24 Nov 2025 13:25:33 GMT   (1218kb)

Title: GiBy: A Giant-Step Baby-Step Classifier For Anomaly Detection In
 Industrial Control Systems
Authors: Sarad Venugopalan and Sridhar Adepu
Categories: cs.CR cs.LG
\\ ( https://arxiv.org/abs/2504.20906 ,  1218kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18455 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 17:03:51 GMT   (1628kb)

Title: On Minimax Estimation of Parameters in Softmax-Contaminated Mixture of
 Experts
Authors: Fanqi Yan, Huy Nguyen, Dung Le, Pedram Akbarian, Nhat Ho, Alessandro
 Rinaldo
Categories: stat.ML cs.LG
Comments: Accepted to NeurIPS 2025. Fanqi Yan, Huy Nguyen, and Dung Le
 contributed equally to this work
\\ ( https://arxiv.org/abs/2505.18455 ,  1628kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10879 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 14:29:04 GMT   (297kb)

Title: A Goemans-Williamson type algorithm for identifying subcohorts in
 clinical trials
Authors: Pratik Worah
Categories: q-bio.QM cs.LG
\\ ( https://arxiv.org/abs/2506.10879 ,  297kb)
------------------------------------------------------------------------------
\\
arXiv:2506.19268
replaced with revised version Mon, 24 Nov 2025 13:11:18 GMT   (735kb)

Title: Health App Reviews for Privacy & Trust (HARPT): A Corpus for Analyzing
 Patient Privacy Concerns, Trust in Providers and Trust in Applications
Authors: Timoteo Kelly, Abdulkadir Korkmaz, Samuel Mallet, Connor Souders,
 Sadra Aliakbarpour, Praveen Rao
Categories: cs.HC cs.CR cs.LG
\\ ( https://arxiv.org/abs/2506.19268 ,  735kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04898
replaced with revised version Mon, 24 Nov 2025 17:16:42 GMT   (4199kb)

Title: When do World Models Successfully Learn Dynamical Systems?
Authors: Edmund Ross, Claudia Drygala, Leonhard Schwarz, Samir Kaiser,
 Francesca di Mare, Tobias Breiten, Hanno Gottschalk
Categories: math.NA cs.LG cs.NA
\\ ( https://arxiv.org/abs/2507.04898 ,  4199kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08312 (*cross-listing*)
replaced with revised version Sun, 23 Nov 2025 04:40:23 GMT   (15197kb)

Title: CFM-GP: Unified Conditional Flow Matching to Learn Gene Perturbation
 Across Cell Types
Authors: Abrar Rahman Abir, Sajib Acharjee Dip, and Liqing Zhang
Categories: q-bio.GN cs.LG
Comments: 28 Pages, 19 Tables, 8 Figures. The first two authors contributed
 equally
\\ ( https://arxiv.org/abs/2508.08312 ,  15197kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00182
replaced with revised version Sun, 23 Nov 2025 12:38:01 GMT   (26kb)

Title: Newton-Flow Particle Filters based on Generalized Cram\'er Distance
Authors: Uwe D. Hanebeck
Categories: cs.IT cs.LG cs.SY eess.SY math.IT
Comments: 8 pages; typos corrected, small changes
\\ ( https://arxiv.org/abs/2509.00182 ,  26kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01736 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 23:05:12 GMT   (2332kb)

Title: Multimodal Generative Flows for LHC Jets
Authors: Darius A. Faroughy, Manfred Opper, Cesar Ojeda
Categories: hep-ph cs.LG
Comments: Accepted at NeurIPS 2025 ML4PS workshop
\\ ( https://arxiv.org/abs/2509.01736 ,  2332kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03378 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 16:32:18 GMT   (1236kb)

Title: Understanding and Improving Shampoo and SOAP via Kullback-Leibler
 Minimization
Authors: Wu Lin, Scott C. Lowe, Felix Dangel, Runa Eschenhagen, Zikun Xu, Roger
 B. Grosse
Categories: stat.ML cs.LG
Comments: further improved the main text and fixed typos in Appendix C, working
 in progress
\\ ( https://arxiv.org/abs/2509.03378 ,  1236kb)
------------------------------------------------------------------------------
\\
arXiv:2510.19368
replaced with revised version Sun, 23 Nov 2025 08:32:30 GMT   (10193kb)

Title: AMAuT: A Flexible and Efficient Multiview Audio Transformer Framework
 Trained from Scratch
Authors: Weichuang Shao, Iman Yi Liao, Tomas Henrique Bode Maul, and Tissa
 Chandesa
Categories: cs.SD cs.LG
Comments: Updating note: 1. CLS+TAL is the distill token from DeiT rather than
 the alternative class token. Adjust the content to clarify it. 2. Figure 4
 presents an error sequence of figures (a) and (b). 3. Remove an unrelated
 citation about the VS set. 4. A missing citation in section 4.4 (SSAST [19]
 here is not a correct citation)
\\ ( https://arxiv.org/abs/2510.19368 ,  10193kb)
------------------------------------------------------------------------------
\\
arXiv:2511.08401 (*cross-listing*)
replaced with revised version Sat, 22 Nov 2025 19:33:02 GMT   (242kb)

Title: Source-Optimal Training is Transfer-Suboptimal
Authors: C. Evans Hedges
Categories: stat.ML cs.LG math.ST stat.TH
\\ ( https://arxiv.org/abs/2511.08401 ,  242kb)
------------------------------------------------------------------------------
\\
arXiv:2511.08735 (*cross-listing*)
replaced with revised version Sun, 23 Nov 2025 19:28:39 GMT   (862kb)

Title: A Deep Learning-Based Method for Fully Coupled Non-Markovian FBSDEs with
 Applications
Authors: Hasib Uddin Molla, Matthew Backhouse, Ankit Banarjee, Jinniao Qiu
Categories: q-fin.MF cs.LG
\\ ( https://arxiv.org/abs/2511.08735 ,  862kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13732 (*cross-listing*)
replaced with revised version Mon, 24 Nov 2025 13:32:45 GMT   (860kb)

Title: Principled Coarse-Grained Acceptance for Speculative Decoding in Speech
Authors: Moran Yanuka, Paul Dixon, Eyal Finkelshtein, Daniel Rotman, Raja
 Giryes
Categories: eess.AS cs.LG
\\ ( https://arxiv.org/abs/2511.13732 ,  860kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14617
replaced with revised version Sun, 23 Nov 2025 13:41:11 GMT   (474kb)

Title: Seer: Online Context Learning for Fast Synchronous LLM Reinforcement
 Learning
Authors: Ruoyu Qin, Weiran He, Weixiao Huang, Yangkun Zhang, Yikai Zhao, Bo
 Pang, Xinran Xu, Yingdi Shan, Yongwei Wu, Mingxing Zhang
Categories: cs.DC cs.LG
Comments: 16 pages, 12 figures, 6 tables
\\ ( https://arxiv.org/abs/2511.14617 ,  474kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17123
replaced with revised version Mon, 24 Nov 2025 15:02:34 GMT   (578kb)

Title: Layer-wise Weight Selection for Power-Efficient Neural Network
 Acceleration
Authors: Jiaxun Fang, Grace Li Zhang, Shaoyi Huang
Categories: cs.AR cs.LG
\\ ( https://arxiv.org/abs/2511.17123 ,  578kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17240
replaced with revised version Mon, 24 Nov 2025 03:13:19 GMT   (116kb)

Title: A Fast Binary Splitting Approach for Non-Adaptive Learning of
 Erd\H{o}s--R\'enyi Graphs
Authors: Hoang Ta and Jonathan Scarlett
Categories: cs.IT cs.DM cs.LG math.IT math.PR
\\ ( https://arxiv.org/abs/2511.17240 ,  116kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---

%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
Submissions to:
Artificial Intelligence
Computation and Language
Computer Vision and Pattern Recognition
Information Retrieval
Machine Learning
received from  Thu 20 Nov 25 19:00:00 GMT  to  Fri 21 Nov 25 19:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2511.16814
Date: Thu, 20 Nov 2025 21:33:08 GMT   (2315kb)

Title: Stable diffusion models reveal a persisting human and AI gap in visual
 creativity
Authors: Silvia Rondini, Claudia Alvarez-Martin, Paula Angermair-Barkai,
 Olivier Penacchio, M. Paz, Matthew Pelowski, Dan Dediu, Antoni
 Rodriguez-Fornells, Xim Cerda-Company
Categories: cs.AI cs.HC
\\
 While recent research suggests Large Language Models match human creative
performance in divergent thinking tasks, visual creativity remains
underexplored. This study compared image generation in human participants
(Visual Artists and Non Artists) and using an image generation AI model (two
prompting conditions with varying human input: high for Human Inspired, low for
Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the
resulting images. We found a clear creativity gradient, with Visual Artists
being the most creative, followed by Non Artists, then Human Inspired
generative AI, and finally Self Guided generative AI. Increased human guidance
strongly improved GenAI's creative output, bringing its productions close to
those of Non Artists. Notably, human and AI raters also showed vastly different
creativity judgment patterns. These results suggest that, in contrast to
language centered tasks, GenAI models may face unique challenges in visual
domains, where creativity depends on perceptual nuance and contextual
sensitivity, distinctly human capacities that may not be readily transferable
from language models.
\\ ( https://arxiv.org/abs/2511.16814 ,  2315kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16837
Date: Thu, 20 Nov 2025 22:31:54 GMT   (12kb)

Title: Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs
Authors: Oliver Kramer
Categories: cs.AI cs.CL
Comments: 6 pages, Submitted to ESANN 2026
\\
 Cognitive BASIC is a minimal, BASIC-style prompting language and in-model
interpreter that structures large language model (LLM) reasoning into explicit,
stepwise execution traces. Inspired by the simplicity of retro BASIC, we
repurpose numbered lines and simple commands as an interpretable cognitive
control layer. Modern LLMs can reliably simulate such short programs, enabling
transparent multi-step reasoning inside the model. A natural-language
interpreter file specifies command semantics, memory updates, and logging
behavior. Our mental-model interpreter extracts declarative and procedural
knowledge, detects contradictions, and produces resolutions when necessary. A
comparison across three LLMs on a benchmark of knowledge extraction, conflict
detection, and reasoning tasks shows that all models can execute Cognitive
BASIC programs, with overall strong but not uniform performance.
\\ ( https://arxiv.org/abs/2511.16837 ,  12kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16842
Date: Thu, 20 Nov 2025 22:49:21 GMT   (2081kb)

Title: Fantastic Bugs and Where to Find Them in AI Benchmarks
Authors: Sang Truong, Yuheng Tu, Michael Hardy, Anka Reuel, Zeyu Tang, Jirayu
 Burapacheep, Jonathan Perera, Chibuike Uwakwe, Ben Domingue, Nick Haber,
 Sanmi Koyejo
Categories: cs.AI cs.CL cs.LG
\\
 Benchmarks are pivotal in driving AI progress, and invalid benchmark
questions frequently undermine their reliability. Manually identifying and
correcting errors among thousands of benchmark questions is not only infeasible
but also a critical bottleneck for reliable evaluation. In this work, we
introduce a framework for systematic benchmark revision that leverages
statistical analysis of response patterns to flag potentially invalid questions
for further expert review. Our approach builds on a core assumption commonly
used in AI evaluations that the mean score sufficiently summarizes model
performance. This implies a unidimensional latent construct underlying the
measurement experiment, yielding expected ranges for various statistics for
each item. When empirically estimated values for these statistics fall outside
the expected range for an item, the item is more likely to be problematic.
Across nine widely used benchmarks, our method guides expert review to identify
problematic questions with up to 84\% precision. In addition, we introduce an
LLM-judge first pass to review questions, further reducing human effort.
Together, these components provide an efficient and scalable framework for
systematic benchmark revision.
\\ ( https://arxiv.org/abs/2511.16842 ,  2081kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16916
Date: Fri, 21 Nov 2025 02:58:04 GMT   (2780kb)

Title: Hybrid Differential Reward: Combining Temporal Difference and Action
 Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative
 Driving
Authors: Ye Han, Lijun Zhang, Dejian Meng, Zhuang Zhang
Categories: cs.AI
\\
 In multi-vehicle cooperative driving tasks involving high-frequency
continuous control, traditional state-based reward functions suffer from the
issue of vanishing reward differences. This phenomenon results in a low
signal-to-noise ratio (SNR) for policy gradients, significantly hindering
algorithm convergence and performance improvement. To address this challenge,
this paper proposes a novel Hybrid Differential Reward (HDR) mechanism. We
first theoretically elucidate how the temporal quasi-steady nature of traffic
states and the physical proximity of actions lead to the failure of traditional
reward signals. Building on this analysis, the HDR framework innovatively
integrates two complementary components: (1) a Temporal Difference Reward (TRD)
based on a global potential function, which utilizes the evolutionary trend of
potential energy to ensure optimal policy invariance and consistency with
long-term objectives; and (2) an Action Gradient Reward (ARG), which directly
measures the marginal utility of actions to provide a local guidance signal
with a high SNR. Furthermore, we formulate the cooperative driving problem as a
Multi-Agent Partially Observable Markov Game (POMDPG) with a time-varying agent
set and provide a complete instantiation scheme for HDR within this framework.
Extensive experiments conducted using both online planning (MCTS) and
Multi-Agent Reinforcement Learning (QMIX, MAPPO, MADDPG) algorithms demonstrate
that the HDR mechanism significantly improves convergence speed and policy
stability. The results confirm that HDR guides agents to learn high-quality
cooperative policies that effectively balance traffic efficiency and safety.
\\ ( https://arxiv.org/abs/2511.16916 ,  2780kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16961
Date: Fri, 21 Nov 2025 05:25:23 GMT   (11659kb)

Title: Comparing verbal, visual and combined explanations for Bayesian Network
 inferences
Authors: Erik P. Nyberg, Steven Mascaro, Ingrid Zukerman, Michael Wybrow,
 Duc-Minh Vo, Ann Nicholson
Categories: cs.AI
Comments: 26 pages total, 12 pages main, 14 pages for 5 appendices
ACM-class: F.4.1
\\
 Bayesian Networks (BNs) are an important tool for assisting probabilistic
reasoning, but despite being considered transparent models, people have trouble
understanding them. Further, current User Interfaces (UIs) still do not clarify
the reasoning of BNs. To address this problem, we have designed verbal and
visual extensions to the standard BN UI, which can guide users through common
inference patterns.
 We conducted a user study to compare our verbal, visual and combined UI
extensions, and a baseline UI. Our main findings are: (1) users did better with
all three types of extensions than with the baseline UI for questions about the
impact of an observation, the paths that enable this impact, and the way in
which an observation influences the impact of other observations; and (2) using
verbal and visual modalities together is better than using either modality
alone for some of these question types.
\\ ( https://arxiv.org/abs/2511.16961 ,  11659kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16997
Date: Fri, 21 Nov 2025 07:05:26 GMT   (1011kb)

Title: MirrorMind: Empowering OmniScientist with the Expert Perspectives and
 Collective Knowledge of Human Scientists
Authors: Qingbin Zeng, Bingbing Fan, Zhiyu Chen, Sijian Ren, Zhilun Zhou, Xuhua
 Zhang, Yuanyi Zhen, Fengli Xu, Yong Li, Tie-Yan Liu
Categories: cs.AI
Comments: 26 pages, 4 figures
\\
 The emergence of AI Scientists has demonstrated remarkable potential in
automating scientific research. However, current approaches largely
conceptualize scientific discovery as a solitary optimization or search
process, overlooking that knowledge production is inherently a social and
historical endeavor. Human scientific insight stems from two distinct yet
interconnected sources. First is the individual cognitive trajectory, where a
researcher's unique insight is shaped by their evolving research history and
stylistic preferences; another is the collective disciplinary memory, where
knowledge is sedimented into vast, interconnected networks of citations and
concepts. Existing LLMs still struggle to represent these structured,
high-fidelity cognitive and social contexts. To bridge this gap, we introduce
MirrorMind, a hierarchical cognitive architecture that integrates dual-memory
representations within a three-level framework. The Individual Level constructs
high-fidelity cognitive models of individual researchers by capturing their
episodic, semantic, and persona memories; the Domain Level maps collective
knowledge into structured disciplinary concept graphs; and the
Interdisciplinary Level that acts as an orthogonal orchestration engine.
Crucially, our architecture separates memory storage from agentic execution,
enabling AI scientist agents to flexibly access individual memories for unique
perspectives or collective structures to reason. We evaluate MirrorMind across
four comprehensive tasks, including author-level cognitive simulation,
complementary reasoning, cross-disciplinary collaboration promotion, and
multi-agent scientific problem solving. The results show that by integrating
individual cognitive depth with collective disciplinary breadth, MirrorMind
moves beyond simple fact retrieval toward structural, personalized, and
insight-generating scientific reasoning.
\\ ( https://arxiv.org/abs/2511.16997 ,  1011kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17006
Date: Fri, 21 Nov 2025 07:18:55 GMT   (2884kb)

Title: Budget-Aware Tool-Use Enables Effective Agent Scaling
Authors: Tengxiao Liu, Zifeng Wang, Jin Miao, I-Hung Hsu, Jun Yan, Jiefeng
 Chen, Rujun Han, Fangyuan Xu, Yanfei Chen, Ke Jiang, Samira Daruki, Yi Liang,
 William Yang Wang, Tomas Pfister, Chen-Yu Lee
Categories: cs.AI
\\
 Scaling test-time computation improves performance across different tasks on
large language models (LLMs), which has also been extended to tool-augmented
agents. For these agents, scaling involves not only "thinking" in tokens but
also "acting" via tool calls. The number of tool calls directly bounds the
agent's interaction with the external environment. However, we find that simply
granting agents a larger tool-call budget fails to improve performance, as they
lack "budget awareness" and quickly hit a performance ceiling. To address this,
we study how to scale such agents effectively under explicit tool-call budgets,
focusing on web search agents. We first introduce the Budget Tracker, a
lightweight plug-in that provides the agent with continuous budget awareness,
enabling simple yet effective scaling. We further develop BATS (Budget Aware
Test-time Scaling), an advanced framework that leverages this awareness to
dynamically adapt its planning and verification strategy, deciding whether to
"dig deeper" on a promising lead or "pivot" to new paths based on remaining
resources. To analyze cost-performance scaling in a controlled manner, we
formalize a unified cost metric that jointly accounts for token and tool
consumption. We provide the first systematic study on budget-constrained
agents, showing that budget-aware methods produce more favorable scaling curves
and push the cost-performance Pareto frontier. Our work offers empirical
insights toward a more transparent and principled understanding of scaling in
tool-augmented agents.
\\ ( https://arxiv.org/abs/2511.17006 ,  2884kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17038
Date: Fri, 21 Nov 2025 08:28:36 GMT   (26605kb)

Title: DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior
 Annealing
Authors: Hao Chen, Renzheng Zhang, Scott S. Howard
Categories: cs.AI stat.ML
\\
 From a Bayesian perspective, score-based diffusion solves inverse problems
through joint inference, embedding the likelihood with the prior to guide the
sampling process. However, this formulation fails to explain its practical
behavior: the prior offers limited guidance, while reconstruction is largely
driven by the measurement-consistency term, leading to an inference process
that is effectively decoupled from the diffusion dynamics. To clarify this
structure, we reinterpret the role of diffusion in inverse problem solving as
an initialization stage within an expectation--maximization (EM)--style
framework, where the diffusion stage and the data-driven refinement are fully
decoupled. We introduce \textbf{DAPS++}, which allows the likelihood term to
guide inference more directly while maintaining numerical stability and
providing insight into why unified diffusion trajectories remain effective in
practice. By requiring fewer function evaluations (NFEs) and
measurement-optimization steps, \textbf{DAPS++} achieves high computational
efficiency and robust reconstruction performance across diverse image
restoration tasks.
\\ ( https://arxiv.org/abs/2511.17038 ,  26605kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17056
Date: Fri, 21 Nov 2025 08:59:42 GMT   (1316kb)

Title: Patient-level Information Extraction by Consistent Integration of
 Textual and Tabular Evidence with Bayesian Networks
Authors: Paloma Rabaey, Adrick Tench, Stefan Heytens, and Thomas Demeester
Categories: cs.AI
\\
 Electronic health records (EHRs) form an invaluable resource for training
clinical decision support systems. To leverage the potential of such systems in
high-risk applications, we need large, structured tabular datasets on which we
can build transparent feature-based models. While part of the EHR already
contains structured information (e.g. diagnosis codes, medications, and lab
results), much of the information is contained within unstructured text (e.g.
discharge summaries and nursing notes). In this work, we propose a method for
multi-modal patient-level information extraction that leverages both the
tabular features available in the patient's EHR (using an expert-informed
Bayesian network) as well as clinical notes describing the patient's symptoms
(using neural text classifiers). We propose the use of virtual evidence
augmented with a consistency node to provide an interpretable, probabilistic
fusion of the models' predictions. The consistency node improves the
calibration of the final predictions compared to virtual evidence alone,
allowing the Bayesian network to better adjust the neural classifier's output
to handle missing information and resolve contradictions between the tabular
and text data. We show the potential of our method on the SimSUM dataset, a
simulated benchmark linking tabular EHRs with clinical notes through expert
knowledge.
\\ ( https://arxiv.org/abs/2511.17056 ,  1316kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17162
Date: Fri, 21 Nov 2025 11:30:17 GMT   (472kb)

Title: The Belief-Desire-Intention Ontology for modelling mental reality and
 agency
Authors: Sara Zuppiroli, Carmelo Fabio Longo, Anna Sofia Lippolis, Rocco
 Paolillo, Lorenzo Giammei, Miguel Ceriani, Francesco Poggi, Antonio Zinilli,
 Andrea Giovanni Nuzzolese
Categories: cs.AI
\\
 The Belief-Desire-Intention (BDI) model is a cornerstone for representing
rational agency in artificial intelligence and cognitive sciences. Yet, its
integration into structured, semantically interoperable knowledge
representations remains limited. This paper presents a formal BDI Ontology,
conceived as a modular Ontology Design Pattern (ODP) that captures the
cognitive architecture of agents through beliefs, desires, intentions, and
their dynamic interrelations. The ontology ensures semantic precision and
reusability by aligning with foundational ontologies and best practices in
modular design. Two complementary lines of experimentation demonstrate its
applicability: (i) coupling the ontology with Large Language Models (LLMs) via
Logic Augmented Generation (LAG) to assess the contribution of ontological
grounding to inferential coherence and consistency; and (ii) integrating the
ontology within the Semas reasoning platform, which implements the
Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow
between RDF triples and agent mental states. Together, these experiments
illustrate how the BDI Ontology acts as both a conceptual and operational
bridge between declarative and procedural intelligence, paving the way for
cognitively grounded, explainable, and semantically interoperable multi-agent
and neuro-symbolic systems operating within the Web of Data.
\\ ( https://arxiv.org/abs/2511.17162 ,  472kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17165
Date: Fri, 21 Nov 2025 11:32:28 GMT   (559kb)

Title: MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement
 Learning via Mutual Intrinsic Reward
Authors: Kesheng Chen, Wenjian Luo, Bang Zhang, Zeping Yin, Zipeng Ye
Categories: cs.AI cs.LG
\\
 Episodic rewards present a significant challenge in reinforcement learning.
While intrinsic reward methods have demonstrated effectiveness in single-agent
rein-forcement learning scenarios, their application to multi-agent
reinforcement learn-ing (MARL) remains problematic. The primary difficulties
stem from two fac-tors: (1) the exponential sparsity of joint action
trajectories that lead to rewards as the exploration space expands, and (2)
existing methods often fail to account for joint actions that can influence
team states. To address these challenges, this paper introduces Mutual
Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL
with extremely sparse rewards like episodic rewards. MIR incentivizes
individual agents to explore actions that affect their teammates, and when
combined with original strategies, effectively stimulates team exploration and
improves algorithm performance. For comprehensive experimental valida-tion, we
extend the representative single-agent MiniGrid environment to create
MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation
compares the proposed method against state-of-the-art approaches in the
MiniGrid-MA setting, with experimental results demonstrating superior
perfor-mance.
\\ ( https://arxiv.org/abs/2511.17165 ,  559kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17198
Date: Fri, 21 Nov 2025 12:25:47 GMT   (18502kb)

Title: Designing Domain-Specific Agents via Hierarchical Task Abstraction
 Mechanism
Authors: Kaiyu Li, Jiayu Wang, Zhi Wang, Hui Qiao, Weizhan Zhang, Deyu Meng,
 Xiangyong Cao
Categories: cs.AI cs.CV
Comments: Page: https://earth-insights.github.io/EarthAgent
\\
 LLM-driven agents, particularly those using general frameworks like ReAct or
human-inspired role-playing, often struggle in specialized domains that
necessitate rigorously structured workflows. Fields such as remote sensing,
requiring specialized tools (e.g., correction, spectral indices calculation),
and multi-step procedures (e.g., numerous intermediate products and optional
steps), significantly challenge generalized approaches. To address this gap, we
introduce a novel agent design framework centered on a Hierarchical Task
Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social
roles, instead structuring multi-agent systems into a logical hierarchy that
mirrors the intrinsic task-dependency graph of a given domain. This
task-centric architecture thus enforces procedural correctness and decomposes
complex problems into sequential layers, where each layer's sub-agents operate
on the outputs of the preceding layers. We instantiate this framework as
EarthAgent, a multi-agent system tailored for complex geospatial analysis. To
evaluate such complex planning capabilities, we build GeoPlan-bench, a
comprehensive benchmark of realistic, multi-step geospatial planning tasks. It
is accompanied by a suite of carefully designed metrics to evaluate tool
selection, path similarity, and logical completeness. Experiments show that
EarthAgent substantially outperforms a range of established single- and
multi-agent systems. Our work demonstrates that aligning agent architecture
with a domain's intrinsic task structure is a critical step toward building
robust and reliable specialized autonomous systems.
\\ ( https://arxiv.org/abs/2511.17198 ,  18502kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17332
Date: Fri, 21 Nov 2025 15:54:44 GMT   (82kb)

Title: Agentifying Agentic AI
Authors: Virginia Dignum and Frank Dignum
Categories: cs.AI cs.MA
Comments: 10 pages; 1 figure
\\
 Agentic AI seeks to endow systems with sustained autonomy, reasoning, and
interaction capabilities. To realize this vision, its assumptions about agency
must be complemented by explicit models of cognition, cooperation, and
governance. This paper argues that the conceptual tools developed within the
Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI
architectures, communication protocols, mechanism design, and institutional
modelling, provide precisely such a foundation. By aligning adaptive,
data-driven approaches with structured models of reasoning and coordination, we
outline a path toward agentic systems that are not only capable and flexible,
but also transparent, cooperative, and accountable. The result is a perspective
on agency that bridges formal theory and practical autonomy.
\\ ( https://arxiv.org/abs/2511.17332 ,  82kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17408
Date: Fri, 21 Nov 2025 17:08:48 GMT   (1007kb)

Title: That's not natural: The Impact of Off-Policy Training Data on Probe
 Performance
Authors: Nathalie Kirch, Samuel Dower, Adrians Skapars, Ekdeep Singh Lubana,
 Dmitrii Krasheninnikov
Categories: cs.AI cs.LG
Comments: 10 pages, EurIPS 2025 Workshop on Private AI Governance
\\
 Probing has emerged as a promising method for monitoring Large Language
Models (LLMs), enabling inference-time detection of concerning behaviours such
as deception and sycophancy. However, natural examples of many behaviours are
rare, forcing researchers to rely on synthetic or off-policy LLM responses for
training probes. We systematically evaluate how the use of synthetic and
off-policy data influences probe generalisation across eight distinct LLM
behaviours. Testing linear and attention probes across multiple LLMs, we find
that the response generation strategy can significantly affect probe
performance, though the magnitude of this effect varies by behaviour. We find
that successful generalisation from off-policy data, to test sets where the
model is incentivised to produce the target behaviour, is predictive of
successful on-policy generalisation. Leveraging this result, we predict that
Deception and Sandbagging probes may fail to generalise from off-policy to
on-policy data when used in real monitoring scenarios. Notably, shifts in the
training data domain still cause even larger performance degradation, with
different-domain test scores being consistently lower than the same-domain
ones. These results indicate that, in the absence of on-policy data, using
same-domain off-policy data yields more reliable probes than using on-policy
data from a different domain, emphasizing the need for methods that can better
handle distribution shifts in LLM monitoring.
\\ ( https://arxiv.org/abs/2511.17408 ,  1007kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17461
Date: Fri, 21 Nov 2025 18:03:48 GMT   (26307kb)

Title: SRA-CP: Spontaneous Risk-Aware Selective Cooperative Perception
Authors: Jiaxi Liu and Chengyuan Ma and Hang Zhou and Weizhe Tang and Shixiao
 Liang and Haoyang Ding and Xiaopeng Li and Bin Ran
Categories: cs.AI
\\
 Cooperative perception (CP) offers significant potential to overcome the
limitations of single-vehicle sensing by enabling information sharing among
connected vehicles (CVs). However, existing generic CP approaches need to
transmit large volumes of perception data that are irrelevant to the driving
safety, exceeding available communication bandwidth. Moreover, most CP
frameworks rely on pre-defined communication partners, making them unsuitable
for dynamic traffic environments. This paper proposes a Spontaneous Risk-Aware
Selective Cooperative Perception (SRA-CP) framework to address these
challenges. SRA-CP introduces a decentralized protocol where connected agents
continuously broadcast lightweight perception coverage summaries and initiate
targeted cooperation only when risk-relevant blind zones are detected. A
perceptual risk identification module enables each CV to locally assess the
impact of occlusions on its driving task and determine whether cooperation is
necessary. When CP is triggered, the ego vehicle selects appropriate peers
based on shared perception coverage and engages in selective information
exchange through a fusion module that prioritizes safety-critical content and
adapts to bandwidth constraints. We evaluate SRA-CP on a public dataset against
several representative baselines. Results show that SRA-CP achieves less than
1% average precision (AP) loss for safety-critical objects compared to generic
CP, while using only 20% of the communication bandwidth. Moreover, it improves
the perception performance by 15% over existing selective CP methods that do
not incorporate risk awareness.
\\ ( https://arxiv.org/abs/2511.17461 ,  26307kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16680
Date: Wed, 12 Nov 2025 09:19:49 GMT   (10kb)

Title: Shona spaCy: A Morphological Analyzer for an Under-Resourced Bantu
 Language
Authors: Happymore Masoka
Categories: cs.CL cs.AI
\\
 Despite rapid advances in multilingual natural language processing (NLP), the
Bantu language Shona remains under-served in terms of morphological analysis
and language-aware tools. This paper presents Shona spaCy, an open-source,
rule-based morphological pipeline for Shona built on the spaCy framework. The
system combines a curated JSON lexicon with linguistically grounded rules to
model noun-class prefixes (Mupanda 1-18), verbal subject concords, tense-aspect
markers, ideophones, and clitics, integrating these into token-level
annotations for lemma, part-of-speech, and morphological features. The toolkit
is available via pip install shona-spacy, with source code at
https://github.com/HappymoreMasoka/shona-spacy and a PyPI release at
https://pypi.org/project/shona-spacy/0.1.4/. Evaluation on formal and informal
Shona corpora yields 90% POS-tagging accuracy and 88% morphological-feature
accuracy, while maintaining transparency in its linguistic decisions. By
bridging descriptive grammar and computational implementation, Shona spaCy
advances NLP accessibility and digital inclusion for Shona speakers and
provides a template for morphological analysis tools for other under-resourced
Bantu languages.
\\ ( https://arxiv.org/abs/2511.16680 ,  10kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16681
Date: Wed, 12 Nov 2025 09:31:08 GMT   (4662kb)

Title: Towards Hyper-Efficient RAG Systems in VecDBs: Distributed Parallel
 Multi-Resolution Vector Search
Authors: Dong Liu, Yanxuan Yu
Categories: cs.CL cs.AI
Comments: Accepted to IEEE International Conference on Parallel and Distributed
 Systems 2025 (ICPADS 2025 Oral)
\\
 Retrieval-Augmented Generation (RAG) systems have become a dominant approach
to augment large language models (LLMs) with external knowledge. However,
existing vector database (VecDB) retrieval pipelines rely on flat or
single-resolution indexing structures, which cannot adapt to the varying
semantic granularity required by diverse user queries. This limitation leads to
suboptimal trade-offs between retrieval speed and contextual relevance.
 To address this, we propose \textbf{Semantic Pyramid Indexing (SPI)}, a novel
multi-resolution vector indexing framework that introduces query-adaptive
resolution control for RAG in VecDBs. Unlike existing hierarchical methods that
require offline tuning or separate model training, SPI constructs a semantic
pyramid over document embeddings and dynamically selects the optimal resolution
level per query through a lightweight classifier. This adaptive approach
enables progressive retrieval from coarse-to-fine representations,
significantly accelerating search while maintaining semantic coverage.
 We implement SPI as a plugin for both FAISS and Qdrant backends and evaluate
it across multiple RAG tasks including MS MARCO, Natural Questions, and
multimodal retrieval benchmarks. SPI achieves up to \textbf{5.7$\times$}
retrieval speedup and \textbf{1.8$\times$} memory efficiency gain while
improving end-to-end QA F1 scores by up to \textbf{2.5 points} compared to
strong baselines. Our theoretical analysis provides guarantees on retrieval
quality and latency bounds, while extensive ablation studies validate the
contribution of each component. The framework's compatibility with existing
VecDB infrastructures makes it readily deployable in production RAG systems.
Code is availabe at
\href{https://github.com/FastLM/SPI_VecDB}{https://github.com/FastLM/SPI\_VecDB}.
\\ ( https://arxiv.org/abs/2511.16681 ,  4662kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16682
Date: Wed, 12 Nov 2025 09:57:21 GMT   (725kb)

Title: Bench360: Benchmarking Local LLM Inference from 360{\deg}
Authors: Linus Stuhlmann, Mauricio Fadel Argerich, Jonathan F\"urst
Categories: cs.CL cs.AI cs.LG cs.PF
\\
 Running large language models (LLMs) locally is becoming increasingly common.
While the growing availability of small open-source models and inference
engines has lowered the entry barrier, users now face an overwhelming number of
configuration choices. Identifying an optimal configuration -- balancing
functional and non-functional requirements -- requires substantial manual
effort. While several benchmarks target LLM inference, they are designed for
narrow evaluation goals and not user-focused. They fail to integrate relevant
system and task-specific metrics into a unified, easy-to-use benchmark that
supports multiple inference engines, usage scenarios, and quantization levels.
To address this gap, we present Bench360 -- Benchmarking Local LLM Inference
from 360{\deg}. Bench360 allows users to easily define their own custom tasks
along with datasets and relevant task-specific metrics and then automatically
benchmarks selected LLMs, inference engines, and quantization levels across
different usage scenarios (single stream, batch & server). Bench360 tracks a
wide range of metrics, including (1) system metrics -- such as Computing
Performance (e.g., latency, throughput), Resource Usage (e.g., energy per
query), and Deployment (e.g., cold start time) -- and (2) task-specific metrics
such as ROUGE, F1 score or accuracy. We demonstrate Bench360 on four common LLM
tasks -- General Knowledge & Reasoning, QA, Summarization and Text-to-SQL --
across three hardware platforms and four state of the art inference engines.
Our results reveal several interesting trade-offs between task performance and
system-level efficiency, highlighting the differences in inference engines and
models. Most importantly, there is no single best setup for local inference,
which strongly motivates the need for a framework such as Bench360.
\\ ( https://arxiv.org/abs/2511.16682 ,  725kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16683
Date: Wed, 12 Nov 2025 15:23:41 GMT   (138kb)

Title: How Well Do LLMs Understand Tunisian Arabic?
Authors: Mohamed Mahdi
Categories: cs.CL cs.AI
\\
 Large Language Models (LLMs) are the engines driving today's AI agents. The
better these models understand human languages, the more natural and
user-friendly the interaction with AI becomes, from everyday devices like
computers and smartwatches to any tool that can act intelligently. Yet, the
ability of industrial-scale LLMs to comprehend low-resource languages, such as
Tunisian Arabic (Tunizi), is often overlooked. This neglect risks excluding
millions of Tunisians from fully interacting with AI in their own language,
pushing them toward French or English. Such a shift not only threatens the
preservation of the Tunisian dialect but may also create challenges for
literacy and influence younger generations to favor foreign languages. In this
study, we introduce a novel dataset containing parallel Tunizi, standard
Tunisian Arabic, and English translations, along with sentiment labels. We
benchmark several popular LLMs on three tasks: transliteration, translation,
and sentiment analysis. Our results reveal significant differences between
models, highlighting both their strengths and limitations in understanding and
processing Tunisian dialects. By quantifying these gaps, this work underscores
the importance of including low-resource languages in the next generation of AI
systems, ensuring technology remains accessible, inclusive, and culturally
grounded.
\\ ( https://arxiv.org/abs/2511.16683 ,  138kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16685
Date: Thu, 13 Nov 2025 11:31:14 GMT   (2446kb)

Title: Ellipsoid-Based Decision Boundaries for Open Intent Classification
Authors: Yuetian Zou, Hanlei Zhang, Hua Xu, Songze Li, Long Xiao
Categories: cs.CL cs.AI
\\
 Textual open intent classification is crucial for real-world dialogue
systems, enabling robust detection of unknown user intents without prior
knowledge and contributing to the robustness of the system. While adaptive
decision boundary methods have shown great potential by eliminating manual
threshold tuning, existing approaches assume isotropic distributions of known
classes, restricting boundaries to balls and overlooking distributional
variance along different directions. To address this limitation, we propose
EliDecide, a novel method that learns ellipsoid decision boundaries with
varying scales along different feature directions. First, we employ supervised
contrastive learning to obtain a discriminative feature space for known
samples. Second, we apply learnable matrices to parameterize ellipsoids as the
boundaries of each known class, offering greater flexibility than spherical
boundaries defined solely by centers and radii. Third, we optimize the
boundaries via a novelly designed dual loss function that balances empirical
and open-space risks: expanding boundaries to cover known samples while
contracting them against synthesized pseudo-open samples. Our method achieves
state-of-the-art performance on multiple text intent benchmarks and further on
a question classification dataset. The flexibility of the ellipsoids
demonstrates superior open intent detection capability and strong potential for
generalization to more text classification tasks in diverse complex open-world
scenarios.
\\ ( https://arxiv.org/abs/2511.16685 ,  2446kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16688
Date: Fri, 14 Nov 2025 14:45:41 GMT   (34kb)

Title: Prompt-Based Value Steering of Large Language Models
Authors: Giulio Antonio Abbo and Tony Belpaeme
Categories: cs.CL cs.AI
Comments: 9 pages, 1 figure, 4 tables. Presented at the 3rd International
 Workshop on Value Engineering in AI (VALE 2025), 28th European Conference on
 AI. To appear in Springer LNCS
\\
 Large language models are increasingly used in applications where alignment
with human values is critical. While model fine-tuning is often employed to
ensure safe responses, this technique is static and does not lend itself to
everyday situations involving dynamic values and preferences. In this paper, we
present a practical, reproducible, and model-agnostic procedure to evaluate
whether a prompt candidate can effectively steer generated text toward specific
human values, formalising a scoring method to quantify the presence and gain of
target values in generated responses. We apply our method to a variant of the
Wizard-Vicuna language model, using Schwartz's theory of basic human values and
a structured evaluation through a dialogue dataset. With this setup, we compare
a baseline prompt to one explicitly conditioned on values, and show that value
steering is possible even without altering the model or dynamically optimising
prompts.
\\ ( https://arxiv.org/abs/2511.16688 ,  34kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16689
Date: Sat, 15 Nov 2025 14:53:23 GMT   (4565kb)

Title: Concept-Based Interpretability for Toxicity Detection
Authors: Samarth Garg, Deeksha Varshney, Divya Singh
Categories: cs.CL cs.AI
Comments: 16 pages
\\
 The rise of social networks has not only facilitated communication but also
allowed the spread of harmful content. Although significant advances have been
made in detecting toxic language in textual data, the exploration of
concept-based explanations in toxicity detection remains limited. In this
study, we leverage various subtype attributes present in toxicity detection
datasets, such as obscene, threat, insult, identity attack, and sexual explicit
as concepts that serve as strong indicators to identify whether language is
toxic. However, disproportionate attribution of concepts towards the target
class often results in classification errors. Our work introduces an
interpretability technique based on the Concept Gradient (CG) method which
provides a more causal interpretation by measuring how changes in concepts
directly affect the output of the model. This is an extension of traditional
gradient-based methods in machine learning, which often focus solely on input
features. We propose the curation of Targeted Lexicon Set, which captures toxic
words that contribute to misclassifications in text classification models. To
assess the significance of these lexicon sets in misclassification, we compute
Word-Concept Alignment (WCA) scores, which quantify the extent to which these
words lead to errors due to over-attribution to toxic concepts. Finally, we
introduce a lexicon-free augmentation strategy by generating toxic samples that
exclude predefined toxic lexicon sets. This approach allows us to examine
whether over-attribution persists when explicit lexical overlap is removed,
providing insights into the model's attribution on broader toxic language
patterns.
\\ ( https://arxiv.org/abs/2511.16689 ,  4565kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16690
Date: Sun, 16 Nov 2025 00:15:40 GMT   (1196kb)

Title: Falsely Accused: How AI Detectors Misjudge Slightly Polished Arabic
 Articles
Authors: Saleh Almohaimeed, Saad Almohaimeed, Mousa Jari, Khaled A. Alobaid,
 Fahad Alotaibi
Categories: cs.CL cs.AI
Comments: Submitted to Artificial Intelligence Review Journal
\\
 Many AI detection models have been developed to counter the presence of
articles created by artificial intelligence (AI). However, if a human-authored
article is slightly polished by AI, a shift will occur in the borderline
decision of these AI detection models, leading them to consider it AI-generated
article. This misclassification may result in falsely accusing authors of AI
plagiarism and harm the credibility of AI detector models. In English, some
efforts were made to meet this challenge, but not in Arabic. In this paper, we
generated two datasets. The first dataset contains 800 Arabic articles, half
AI-generated and half human-authored. We used it to evaluate 14 Large Language
models (LLMs) and commercial AI detectors to assess their ability in
distinguishing between human-authored and AI-generated articles. The best 8
models were chosen to act as detectors for our primary concern, which is
whether they would consider slightly polished human text as AI-generated. The
second dataset, Ar-APT, contains 400 Arabic human-authored articles polished by
10 LLMs using 4 polishing settings, totaling 16400 samples. We use it to
evaluate the 8 nominated models and determine whether slight polishing will
affect their performance. The results reveal that all AI detectors incorrectly
attribute a significant number of articles to AI. The best performing LLM,
Claude-4 Sonnet, achieved 83.51%, their performance decreased to 57.63% for
articles slightly polished by LLaMA-3. Whereas for the best performing
commercial model, originality.AI, that achieves 92% accuracy, dropped to 12%
for articles slightly polished by Mistral or Gemma-3.
\\ ( https://arxiv.org/abs/2511.16690 ,  1196kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16691
Date: Sun, 16 Nov 2025 09:25:18 GMT   (110kb)

Title: Reproducibility Report: Test-Time Training on Nearest Neighbors for
 Large Language Models
Authors: Boyang Zhou, Johan Lindqvist, Lindsey Li
Categories: cs.CL
\\
 We reproduce the central claims of Test-Time Training on Nearest Neighbors
for Large Language Models (Hardt and Sun, 2024), which proposes adapting a
language model at inference time by fine-tuning on retrieved nearest-neighbor
sequences. Using pretrained RoBERTa embeddings indexed with Faiss, we retrieve
20 neighbors per test input and apply one gradient update per neighbor across
GPT-2 (117M, 774M), GPT-Neo (1.3B), and R1-Distilled-Qwen2.5-1.5B. Our
experiments confirm that test-time training significantly reduces perplexity
and bits-per-byte metrics across diverse domains from The Pile, with the
largest improvements in structured or specialized datasets such as GitHub and
EuroParl. We further validate that models not pretrained on The Pile benefit
more from this adaptation than models already trained on similar data, allowing
smaller models to approach the performance of larger ones. Due to
infrastructure limitations, we introduce a memory-efficient retrieval
implementation that loads only required line offsets rather than entire files,
reducing RAM requirements from over 128 GB per server to 32 GB. We also extend
the original study by evaluating R1-Distilled-Qwen2.5-1.5B, showing that
test-time training yields consistent gains even for modern reasoning-optimized
architectures. Overall, our results support the robustness and generality of
nearest-neighbor test-time training while highlighting practical considerations
for reproducing large-scale retrieval-augmented adaptation.
\\ ( https://arxiv.org/abs/2511.16691 ,  110kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16693
Date: Sun, 16 Nov 2025 16:36:56 GMT   (81kb)

Title: How Language Directions Align with Token Geometry in Multilingual LLMs
Authors: JaeSeong Kim, Suan Lee
Categories: cs.CL
Comments: 4 pages
\\
 Multilingual LLMs demonstrate strong performance across diverse languages,
yet there has been limited systematic analysis of how language information is
structured within their internal representation space and how it emerges across
layers. We conduct a comprehensive probing study on six multilingual LLMs,
covering all 268 transformer layers, using linear and nonlinear probes together
with a new Token--Language Alignment analysis to quantify the layer-wise
dynamics and geometric structure of language encoding. Our results show that
language information becomes sharply separated in the first transformer block
(+76.4$\pm$8.2 percentage points from Layer 0 to 1) and remains almost fully
linearly separable throughout model depth. We further find that the alignment
between language directions and vocabulary embeddings is strongly tied to the
language composition of the training data. Notably, Chinese-inclusive models
achieve a ZH Match@Peak of 16.43\%, whereas English-centric models achieve only
3.90\%, revealing a 4.21$\times$ structural imprinting effect. These findings
indicate that multilingual LLMs distinguish languages not by surface script
features but by latent representational structures shaped by the training
corpus. Our analysis provides practical insights for data composition
strategies and fairness in multilingual representation learning. All code and
analysis scripts are publicly available at:
https://github.com/thisiskorea/How-Language-Directions-Align-with-Token-Geometry-in-Multilingual-LLMs.
\\ ( https://arxiv.org/abs/2511.16693 ,  81kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16698
Date: Mon, 17 Nov 2025 19:18:10 GMT   (4510kb)

Title: Hierarchical Retrieval with Out-Of-Vocabulary Queries: A Case Study on
 SNOMED CT
Authors: Jonathon Dilworth, Hui Yang, Jiaoyan Chen, Yongsheng Gao
Categories: cs.CL cs.AI
Comments: 5 pages, 3 figures, 3 tables, submission to The Web Conference 2026
 (WWW'26), Dubai, UAE
\\
 SNOMED CT is a biomedical ontology with a hierarchical representation of
large-scale concepts. Knowledge retrieval in SNOMED CT is critical for its
application, but often proves challenging due to language ambiguity, synonyms,
polysemies and so on. This problem is exacerbated when the queries are
out-of-vocabulary (OOV), i.e., having no equivalent matchings in the ontology.
In this work, we focus on the problem of hierarchical concept retrieval from
SNOMED CT with OOV queries, and propose an approach based on language
model-based ontology embeddings. For evaluation, we construct OOV queries
annotated against SNOMED CT concepts, testing the retrieval of the most direct
subsumers and their less relevant ancestors. We find that our method
outperforms the baselines including SBERT and two lexical matching methods.
While evaluated against SNOMED CT, the approach is generalisable and can be
extended to other ontologies. We release code, tools, and evaluation datasets
at https://github.com/jonathondilworth/HR-OOV.
\\ ( https://arxiv.org/abs/2511.16698 ,  4510kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16699
Date: Mon, 17 Nov 2025 23:45:26 GMT   (159kb)

Title: Detecting and Steering LLMs' Empathy in Action
Authors: Juan P. Cadile
Categories: cs.CL cs.AI
Comments: 14 pages, 9 figures
ACM-class: I.2.7
\\
 We investigate empathy-in-action -- the willingness to sacrifice task
efficiency to address human needs -- as a linear direction in LLM activation
space. Using contrastive prompts grounded in the Empathy-in-Action (EIA)
benchmark, we test detection and steering across Phi-3-mini-4k (3.8B),
Qwen2.5-7B (safety-trained), and Dolphin-Llama-3.1-8B (uncensored).
 Detection: All models show AUROC 0.996-1.00 at optimal layers. Uncensored
Dolphin matches safety-trained models, demonstrating empathy encoding emerges
independent of safety training. Phi-3 probes correlate strongly with EIA
behavioral scores (r=0.71, p<0.01). Cross-model probe agreement is limited
(Qwen: r=-0.06, Dolphin: r=0.18), revealing architecture-specific
implementations despite convergent detection.
 Steering: Qwen achieves 65.3% success with bidirectional control and
coherence at extreme interventions. Phi-3 shows 61.7% success with similar
coherence. Dolphin exhibits asymmetric steerability: 94.4% success for
pro-empathy steering but catastrophic breakdown for anti-empathy (empty
outputs, code artifacts).
 Implications: The detection-steering gap varies by model. Qwen and Phi-3
maintain bidirectional coherence; Dolphin shows robustness only for empathy
enhancement. Safety training may affect steering robustness rather than
preventing manipulation, though validation across more models is needed.
\\ ( https://arxiv.org/abs/2511.16699 ,  159kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16787
Date: Thu, 20 Nov 2025 20:26:28 GMT   (292kb)

Title: NALA_MAINZ at BLP-2025 Task 2: A Multi-agent Approach for Bangla
 Instruction to Python Code Generation
Authors: Hossain Shaikh Saadi, Faria Alam, Mario Sanz-Guerrero, Minh Duc Bui,
 Manuel Mager, Katharina von der Wense
Categories: cs.CL cs.SE
Comments: BLP 2025 Shared Task 2 - Code Generation in Bangla
\\
 This paper presents JGU Mainz's winning system for the BLP-2025 Shared Task
on Code Generation from Bangla Instructions. We propose a multi-agent-based
pipeline. First, a code-generation agent produces an initial solution from the
input instruction. The candidate program is then executed against the provided
unit tests (pytest-style, assert-based). Only the failing cases are forwarded
to a debugger agent, which reruns the tests, extracts error traces, and,
conditioning on the error messages, the current program, and the relevant test
cases, generates a revised solution. Using this approach, our submission
achieved first place in the shared task with a $Pass@1$ score of 95.4. We also
make our code public.
\\ ( https://arxiv.org/abs/2511.16787 ,  292kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16811
Date: Thu, 20 Nov 2025 21:29:24 GMT   (783kb)

Title: From Representation to Enactment: The ABC Framework of the Translating
 Mind
Authors: Michael Carl, Takanori Mizowaki, Aishvarya Raj, Masaru Yamada, Devi
 Sri Bandaru, Yuxiang Wei, Xinyue Ren
Categories: cs.CL
\\
 Building on the Extended Mind (EM) theory and radical enactivism, this
article suggests an alternative to representation-based models of the mind. We
lay out a novel ABC framework of the translating mind, in which translation is
not the manipulation of static interlingual correspondences but an enacted
activity, dynamically integrating affective, behavioral, and cognitive (ABC)
processes. Drawing on Predictive Processing and (En)Active Inference, we argue
that the translator's mind emerges, rather than being merely extended, through
loops of brain-body-environment interactions. This non-representational account
reframes translation as skillful participation in sociocultural practice, where
meaning is co-created in real time through embodied interaction with texts,
tools, and contexts.
\\ ( https://arxiv.org/abs/2511.16811 ,  783kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16824
Date: Thu, 20 Nov 2025 22:09:02 GMT   (116kb)

Title: Interpretable dimensions support an effect of agentivity and telicity on
 split intransitivity
Authors: Eva Neu, Brian Dillon, Katrin Erk
Categories: cs.CL
\\
 Intransitive verbs fall into two different syntactic classes, unergatives and
unaccusatives. It has long been argued that verbs describing an agentive action
are more likely to appear in an unergative syntax, and those describing a telic
event to appear in an unaccusative syntax. However, recent work by Kim et al.
(2024) found that human ratings for agentivity and telicity were a poor
predictor of the syntactic behavior of intransitives. Here we revisit this
question using interpretable dimensions, computed from seed words on opposite
poles of the agentive and telic scales. Our findings support the link between
unergativity/unaccusativity and agentivity/telicity, and demonstrate that using
interpretable dimensions in conjunction with human judgments can offer valuable
evidence for semantic properties that are not easily evaluated in rating tasks.
\\ ( https://arxiv.org/abs/2511.16824 ,  116kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16830
Date: Thu, 20 Nov 2025 22:21:34 GMT   (14264kb)

Title: PEPPER: Perception-Guided Perturbation for Robust Backdoor Defense in
 Text-to-Image Diffusion Models
Authors: Oscar Chew, Po-Yi Lu, Jayden Lin, Kuan-Hao Huang, Hsuan-Tien Lin
Categories: cs.CL
\\
 Recent studies show that text to image (T2I) diffusion models are vulnerable
to backdoor attacks, where a trigger in the input prompt can steer generation
toward harmful or unintended content. To address this, we introduce PEPPER
(PErcePtion Guided PERturbation), a backdoor defense that rewrites the caption
into a semantically distant yet visually similar caption while adding
unobstructive elements. With this rewriting strategy, PEPPER disrupt the
trigger embedded in the input prompt, dilute the influence of trigger tokens
and thereby achieve enhanced robustness. Experiments show that PEPPER is
particularly effective against text encoder based attacks, substantially
reducing attack success while preserving generation quality. Beyond this,
PEPPER can be paired with any existing defenses yielding consistently stronger
and generalizable robustness than any standalone method. Our code will be
released on Github.
\\ ( https://arxiv.org/abs/2511.16830 ,  14264kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16846
Date: Thu, 20 Nov 2025 23:03:23 GMT   (607kb)

Title: ConCISE: A Reference-Free Conciseness Evaluation Metric for
 LLM-Generated Answers
Authors: Seyed Mohssen Ghafari, Ronny Kol, Juan C. Quiroz, Nella Luan, Monika
 Patial, Chanaka Rupasinghe, Herman Wandabwa, Luiz Pizzato
Categories: cs.CL cs.AI
ACM-class: I.2.0
\\
 Large language models (LLMs) frequently generate responses that are lengthy
and verbose, filled with redundant or unnecessary details. This diminishes
clarity and user satisfaction, and it increases costs for model developers,
especially with well-known proprietary models that charge based on the number
of output tokens. In this paper, we introduce a novel reference-free metric for
evaluating the conciseness of responses generated by LLMs. Our method
quantifies non-essential content without relying on gold standard references
and calculates the average of three calculations: i) a compression ratio
between the original response and an LLM abstractive summary; ii) a compression
ratio between the original response and an LLM extractive summary; and iii)
wordremoval compression, where an LLM removes as many non-essential words as
possible from the response while preserving its meaning, with the number of
tokens removed indicating the conciseness score. Experimental results
demonstrate that our proposed metric identifies redundancy in LLM outputs,
offering a practical tool for automated evaluation of response brevity in
conversational AI systems without the need for ground truth human annotations.
\\ ( https://arxiv.org/abs/2511.16846 ,  607kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16885
Date: Fri, 21 Nov 2025 01:43:28 GMT   (1303kb)

Title: Improving Latent Reasoning in LLMs via Soft Concept Mixing
Authors: Kang Wang, Xiangyu Duan, Tianyi Du
Categories: cs.CL
Comments: 7 pages, 3 figures
\\
 Unlike human reasoning in abstract conceptual spaces, large language models
(LLMs) typically reason by generating discrete tokens, which potentially limit
their expressive power. The recent work Soft Thinking has shown that LLMs'
latent reasoning via soft concepts is a promising direction, but LLMs are
trained on discrete tokens. To reduce this gap between the soft concepts in
reasoning and the discrete tokens in training, we propose Soft Concept Mixing
(SCM), a soft concept aware training scheme that directly exposes the model to
soft representations during training. Specifically, SCM constructs a soft
concept vector by forming a probability-weighted average of embeddings. Then,
this vector is mixed into the model's hidden states, which embody rich
contextual information. Finally, the entire latent reasoning process is
optimized with Reinforcement Learning (RL). Experiments on five reasoning
benchmarks demonstrate that SCM improves the reasoning performance of LLMs, and
simultaneously maintains a stable training dynamic.
\\ ( https://arxiv.org/abs/2511.16885 ,  1303kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16886
Date: Fri, 21 Nov 2025 01:54:23 GMT   (2394kb)

Title: Deep Improvement Supervision
Authors: Arip Asadulaev, Rayan Banerjee, Fakhri Karray, Martin Takac
Categories: cs.CL cs.AI cs.LG
\\
 Recently, it was shown that small, looped architectures, such as Tiny
Recursive Models (TRMs), can outperform Large Language Models (LLMs) on complex
reasoning tasks, including the Abstraction and Reasoning Corpus (ARC). In this
work, we investigate a core question: how can we further improve the efficiency
of these methods with minimal changes? To address this, we frame the latent
reasoning of TRMs as a form of classifier-free guidance and implicit policy
improvement algorithm. Building on these insights, we propose a novel training
scheme that provides a target for each loop during training. We demonstrate
that our approach significantly enhances training efficiency. Our method
reduces the total number of forward passes by 18x and eliminates halting
mechanisms, while maintaining quality comparable to standard TRMs. Notably, we
achieve 24% accuracy on ARC-1 with only 0.8M parameters, outperforming most
LLMs.
\\ ( https://arxiv.org/abs/2511.16886 ,  2394kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16893
Date: Fri, 21 Nov 2025 02:17:01 GMT   (128kb)

Title: Predicting the Formation of Induction Heads
Authors: Tatsuya Aoyama, Ethan Gotlieb Wilcox, Nathan Schneider
Categories: cs.CL
Comments: Accepted to CogInterp @ NeurIPS
\\
 Arguably, specialized attention heads dubbed induction heads (IHs) underlie
the remarkable in-context learning (ICL) capabilities of modern language models
(LMs); yet, a precise characterization of their formation remains unclear. In
this study, we investigate the relationship between statistical properties of
training data (for both natural and synthetic data) and IH formation. We show
that (1) a simple equation combining batch size and context size predicts the
point at which IHs form; (2) surface bigram repetition frequency and
reliability strongly affect the formation of IHs, and we find a precise Pareto
frontier in terms of these two values; and (3) local dependency with high
bigram repetition frequency and reliability is sufficient for IH formation, but
when the frequency and reliability are low, categoriality and the shape of the
marginal distribution matter.
\\ ( https://arxiv.org/abs/2511.16893 ,  128kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16985
Date: Fri, 21 Nov 2025 06:37:32 GMT   (10643kb)

Title: ARQUSUMM: Argument-aware Quantitative Summarization of Online
 Conversations
Authors: An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh, Zhuang Li
Categories: cs.CL
Comments: Paper accepted to AAAI2026 Main Technical Track
\\
 Online conversations have become more prevalent on public discussion
platforms (e.g. Reddit). With growing controversial topics, it is desirable to
summarize not only diverse arguments, but also their rationale and
justification. Early studies on text summarization focus on capturing general
salient information in source documents, overlooking the argumentative nature
of online conversations. Recent research on conversation summarization although
considers the argumentative relationship among sentences, fail to explicate
deeper argument structure within sentences for summarization. In this paper, we
propose a novel task of argument-aware quantitative summarization to reveal the
claim-reason structure of arguments in conversations, with quantities measuring
argument strength. We further propose ARQUSUMM, a novel framework to address
the task. To reveal the underlying argument structure within sentences,
ARQUSUMM leverages LLM few-shot learning grounded in the argumentation theory
to identify propositions within sentences and their claim-reason relationships.
For quantitative summarization, ARQUSUMM employs argument structure-aware
clustering algorithms to aggregate arguments and quantify their support.
Experiments show that ARQUSUMM outperforms existing conversation and
quantitative summarization models and generate summaries representing argument
structures that are more helpful to users, of high textual quality and
quantification accuracy.
\\ ( https://arxiv.org/abs/2511.16985 ,  10643kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17012
Date: Fri, 21 Nov 2025 07:30:20 GMT   (2273kb)

Title: Supervised Fine Tuning of Large Language Models for Domain Specific
 Knowledge Graph Construction:A Case Study on Hunan's Historical Celebrities
Authors: Junjie Hao, Chun Wang, Ying Qiao, Qiuyue Zuo, Qiya Song, Hua Ma,
 Xieping Gao
Categories: cs.CL cs.AI
\\
 Large language models and knowledge graphs offer strong potential for
advancing research on historical culture by supporting the extraction,
analysis, and interpretation of cultural heritage. Using Hunan's modern
historical celebrities shaped by Huxiang culture as a case study, pre-trained
large models can help researchers efficiently extract key information,
including biographical attributes, life events, and social relationships, from
textual sources and construct structured knowledge graphs. However, systematic
data resources for Hunan's historical celebrities remain limited, and
general-purpose models often underperform in domain knowledge extraction and
structured output generation in such low-resource settings. To address these
issues, this study proposes a supervised fine-tuning approach for enhancing
domain-specific information extraction. First, we design a fine-grained,
schema-guided instruction template tailored to the Hunan historical celebrities
domain and build an instruction-tuning dataset to mitigate the lack of
domain-specific training corpora. Second, we apply parameter-efficient
instruction fine-tuning to four publicly available large language models -
Qwen2.5-7B, Qwen3-8B, DeepSeek-R1-Distill-Qwen-7B, and Llama-3.1-8B-Instruct -
and develop evaluation criteria for assessing their extraction performance.
Experimental results show that all models exhibit substantial performance gains
after fine-tuning. Among them, Qwen3-8B achieves the strongest results,
reaching a score of 89.3866 with 100 samples and 50 training iterations. This
study provides new insights into fine-tuning vertical large language models for
regional historical and cultural domains and highlights their potential for
cost-effective applications in cultural heritage knowledge extraction and
knowledge graph construction.
\\ ( https://arxiv.org/abs/2511.17012 ,  2273kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17036
Date: Fri, 21 Nov 2025 08:28:02 GMT   (3431kb)

Title: Do Vision-Language Models Understand Visual Persuasiveness?
Authors: Gyuwon Park
Categories: cs.CL cs.CV
Comments: 8 pages (except for reference and appendix), 5 figures, 7 tables, to
 be published in NeurIPS 2025 Workshop: VLM4RWD
\\
 Recent advances in vision-language models (VLMs) have enabled impressive
multi-modal reasoning and understanding. Yet, whether these models truly grasp
visual persuasion-how visual cues shape human attitudes and decisions-remains
unclear. To probe this question, we construct a high-consensus dataset for
binary persuasiveness judgment and introduce the taxonomy of Visual Persuasive
Factors (VPFs), encompassing low-level perceptual, mid-level compositional, and
high-level semantic cues. We also explore cognitive steering and knowledge
injection strategies for persuasion-relevant reasoning. Empirical analysis
across VLMs reveals a recall-oriented bias-models over-predict high
persuasiveness-and weak discriminative power for low/mid-level features. In
contrast, high-level semantic alignment between message and object presence
emerges as the strongest predictor of human judgment. Among intervention
strategies, simple instruction or unguided reasoning scaffolds yield marginal
or negative effects, whereas concise, object-grounded rationales significantly
improve precision and F1 scores. These results indicate that VLMs core
limitation lies not in recognizing persuasive objects but in linking them to
communicative intent.
\\ ( https://arxiv.org/abs/2511.17036 ,  3431kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17069
Date: Fri, 21 Nov 2025 09:19:05 GMT   (183kb)

Title: Principled Design of Interpretable Automated Scoring for Large-Scale
 Educational Assessments
Authors: Yunsung Kim, Mike Hardy, Joseph Tey, Candace Thille, Chris Piech
Categories: cs.CL
Comments: 16 pages, 2 figures
\\
 AI-driven automated scoring systems offer scalable and efficient means of
evaluating complex student-generated responses. Yet, despite increasing demand
for transparency and interpretability, the field has yet to develop a widely
accepted solution for interpretable automated scoring to be used in large-scale
real-world assessments. This work takes a principled approach to address this
challenge. We analyze the needs and potential benefits of interpretable
automated scoring for various assessment stakeholders and develop four
principles of interpretability -- Faithfulness, Groundedness, Traceability, and
Interchangeability (FGTI) -- targeted at those needs. To illustrate the
feasibility of implementing these principles, we develop the AnalyticScore
framework for short answer scoring as a baseline reference framework for future
research. AnalyticScore operates by (1) extracting explicitly identifiable
elements of the responses, (2) featurizing each response into
human-interpretable values using LLMs, and (3) applying an intuitive ordinal
logistic regression model for scoring. In terms of scoring accuracy,
AnalyticScore outperforms many uninterpretable scoring methods, and is within
only 0.06 QWK of the uninterpretable SOTA on average across 10 items from the
ASAP-SAS dataset. By comparing against human annotators conducting the same
featurization task, we further demonstrate that the featurization behavior of
AnalyticScore aligns well with that of humans.
\\ ( https://arxiv.org/abs/2511.17069 ,  183kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17081
Date: Fri, 21 Nov 2025 09:37:16 GMT   (3967kb)

Title: MUCH: A Multilingual Claim Hallucination Benchmark
Authors: J\'er\'emie Dentan, Alexi Canesse, Davide Buscaldi, Aymen Shabou,
 Sonia Vanier
Categories: cs.CL
\\
 Claim-level Uncertainty Quantification (UQ) is a promising approach to
mitigate the lack of reliability in Large Language Models (LLMs). We introduce
MUCH, the first claim-level UQ benchmark designed for fair and reproducible
evaluation of future methods under realistic conditions. It includes 4,873
samples across four European languages (English, French, Spanish, and German)
and four instruction-tuned open-weight LLMs. Unlike prior claim-level
benchmarks, we release 24 generation logits per token, facilitating the
development of future white-box methods without re-generating data. Moreover,
in contrast to previous benchmarks that rely on manual or LLM-based
segmentation, we propose a new deterministic algorithm capable of segmenting
claims using as little as 0.2% of the LLM generation time. This makes our
segmentation approach suitable for real-time monitoring of LLM outputs,
ensuring that MUCH evaluates UQ methods under realistic deployment constraints.
Finally, our evaluations show that current methods still have substantial room
for improvement in both performance and efficiency.
\\ ( https://arxiv.org/abs/2511.17081 ,  3967kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17127
Date: Fri, 21 Nov 2025 10:44:02 GMT   (3882kb)

Title: Training Foundation Models on a Full-Stack AMD Platform: Compute,
 Networking, and System Design
Authors: Quentin Anthony, Yury Tokpanov, Skyler Szot, Srivatsan Rajagopal,
 Praneeth Medepalli, Rishi Iyer, Vasu Shyam, Anna Golubeva, Ansh Chaurasia,
 Xiao Yang, Tomas Figliolia, Robert Washbourne, Drew Thorstensen, Amartey
 Pearson, Zack Grossbart, Jason van Patten, Emad Barsoum, Zhenyu Gu, Yao Fu,
 Beren Millidge
Categories: cs.CL cs.AI cs.DC
\\
 We report on the first large-scale mixture-of-experts (MoE) pretraining study
on pure AMD hardware, utilizing both MI300X GPUs with Pollara interconnect. We
distill practical guidance for both systems and model design. On the systems
side, we deliver a comprehensive cluster and networking characterization:
microbenchmarks for all core collectives (all-reduce, reduce-scatter,
all-gather, broadcast) across message sizes and GPU counts on Pollara. To our
knowledge, this is the first at this scale. We further provide MI300X
microbenchmarks on kernel sizing and memory bandwidth to inform model design.
On the modeling side, we introduce and apply MI300X-aware transformer sizing
rules for attention and MLP blocks and justify MoE widths that jointly optimize
training throughput and inference latency. We describe our training stack in
depth, including often-ignored utilities such as fault-tolerance and
checkpoint-reshaping, as well as detailed information on our training recipe.
We also provide a preview of our model architecture and base model - ZAYA1
(760M active, 8.3B total parameters MoE) - which will be further improved upon
in forthcoming papers. ZAYA1-base achieves performance comparable to leading
base models such as Qwen3-4B and Gemma3-12B at its scale and larger, and
outperforms models including Llama-3-8B and OLMoE across reasoning,
mathematics, and coding benchmarks. Together, these results demonstrate that
the AMD hardware, network, and software stack are mature and optimized enough
for competitive large-scale pretraining.
\\ ( https://arxiv.org/abs/2511.17127 ,  3882kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17129
Date: Fri, 21 Nov 2025 10:45:44 GMT   (4009kb)

Title: Learning to Compress: Unlocking the Potential of Large Language Models
 for Text Representation
Authors: Yeqin Zhang, Yizheng Zhao, Chen Hu, Binxing Jiao, Daxin Jiang, Ruihang
 Miao, Cam-Tu Nguyen
Categories: cs.CL cs.AI
Comments: Accepted by AAAI'26
\\
 Text representation plays a critical role in tasks like clustering,
retrieval, and other downstream applications. With the emergence of large
language models (LLMs), there is increasing interest in harnessing their
capabilities for this purpose. However, most of the LLMs are inherently causal
and optimized for next-token prediction, making them suboptimal for producing
holistic representations. To address this, recent studies introduced pretext
tasks to adapt LLMs for text representation. Most of these tasks, however, rely
on token-level prediction objectives, such as the masked next-token prediction
(MNTP) used in LLM2Vec. In this work, we explore the untapped potential of
context compression as a pretext task for unsupervised adaptation of LLMs.
During compression pre-training, the model learns to generate compact memory
tokens, which substitute the whole context for downstream sequence prediction.
Experiments demonstrate that a well-designed compression objective can
significantly enhance LLM-based text representations, outperforming models
trained with token-level pretext tasks. Further improvements through
contrastive learning produce a strong representation model (LLM2Comp) that
outperforms contemporary LLM-based text encoders on a wide range of tasks while
being more sample-efficient, requiring significantly less training data.
\\ ( https://arxiv.org/abs/2511.17129 ,  4009kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17153
Date: Fri, 21 Nov 2025 11:18:15 GMT   (163kb)

Title: LangMark: A Multilingual Dataset for Automatic Post-Editing
Authors: Diego Velazquez, Mikaela Grace, Konstantinos Karageorgos, Lawrence
 Carin, Aaron Schliem, Dimitrios Zaikis, Roger Wechsler
Categories: cs.CL
Comments: 15 pages, 8 figures, ACL 2025
Journal-ref: Proceedings of the 63rd Annual Meeting of the Association for
 Computational Linguistics (Volume 1: Long Papers), 2025, pages 32653-32667
DOI: 10.18653/v1/2025.acl-long.1569
\\
 Automatic post-editing (APE) aims to correct errors in machine-translated
text, enhancing translation quality, while reducing the need for human
intervention. Despite advances in neural machine translation (NMT), the
development of effective APE systems has been hindered by the lack of
large-scale multilingual datasets specifically tailored to NMT outputs. To
address this gap, we present and release LangMark, a new human-annotated
multilingual APE dataset for English translation to seven languages: Brazilian
Portuguese, French, German, Italian, Japanese, Russian, and Spanish. The
dataset has 206,983 triplets, with each triplet consisting of a source segment,
its NMT output, and a human post-edited translation. Annotated by expert human
linguists, our dataset offers both linguistic diversity and scale. Leveraging
this dataset, we empirically show that Large Language Models (LLMs) with
few-shot prompting can effectively perform APE, improving upon leading
commercial and even proprietary machine translation systems. We believe that
this new resource will facilitate the future development and evaluation of APE
systems.
\\ ( https://arxiv.org/abs/2511.17153 ,  163kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17161
Date: Fri, 21 Nov 2025 11:28:11 GMT   (133kb)

Title: The PLLuM Instruction Corpus
Authors: Piotr P\k{e}zik, Filip \.Zarnecki, Konrad Kaczy\'nski, Anna Cichosz,
 Zuzanna Deckert, Monika Garnys, Izabela Grabarczyk, Wojciech Janowski, Sylwia
 Karasi\'nska, Aleksandra Kujawiak, Piotr Misztela, Maria Szyma\'nska,
 Karolina Walkusz, Igor Siek, Maciej Chrab\k{a}szcz, Anna Ko{\l}os, Agnieszka
 Karli\'nska, Karolina Seweryn, Aleksandra Krasnod\k{e}bska, Paula Betscher,
 Zofia Cie\'sli\'nska, Katarzyna Kowol, Artur Wilczek, Maciej Trzci\'nski,
 Katarzyna Dziewulska, Roman Roszko, Tomasz Berna\'s, Jurgita
 Vai\v{c}enonien\.e, Danuta Roszko, Pawe{\l} Levchuk, Pawe{\l} Kowalski, Irena
 Prawdzic-Jankowska, Marek Koz{\l}owski, S{\l}awomir Dadas, Rafa{\l}
 Po\'swiata, Alina Wr\'oblewska, Katarzyna Krasnowska-Kiera\'s, Maciej
 Ogrodniczuk, Micha{\l} Rudolf, Piotr Rybak, Karolina Saputa, Joanna
 Wo{\l}oszyn, Marcin Oleksy, Bart{\l}omiej Koptyra, Teddy Ferdinan,
 Stanis{\l}aw Wo\'zniak, Maciej Piasecki, Pawe{\l} Walkowiak, Konrad Wojtasik,
 Arkadiusz Janz, Przemys{\l}aw Kazienko, Julia Moska, Jan Koco\'n
Categories: cs.CL cs.AI
\\
 This paper describes the instruction dataset used to fine-tune a set of
transformer-based large language models (LLMs) developed in the PLLuM (Polish
Large Language Model) project. We present a functional typology of the organic,
converted, and synthetic instructions used in PLLuM and share some observations
about the implications of using human-authored versus synthetic instruction
datasets in the linguistic adaptation of base LLMs. Additionally, we release
the first representative subset of the PLLuM instruction corpus (PLLuMIC),
which we believe to be useful in guiding and planning the development of
similar datasets for other LLMs.
\\ ( https://arxiv.org/abs/2511.17161 ,  133kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17170
Date: Fri, 21 Nov 2025 11:42:49 GMT   (1639kb)

Title: Hallucinate Less by Thinking More: Aspect-Based Causal Abstention for
 Large Language Models
Authors: Vy Nguyen, Ziqi Xu, Jeffrey Chan, Estrid He, Feng Xia, Xiuzhen Zhang
Categories: cs.CL cs.AI
Comments: Accepted to AAAI 2026 (Main Technical Track)
\\
 Large Language Models (LLMs) often produce fluent but factually incorrect
responses, a phenomenon known as hallucination. Abstention, where the model
chooses not to answer and instead outputs phrases such as "I don't know", is a
common safeguard. However, existing abstention methods typically rely on
post-generation signals, such as generation variations or feedback, which
limits their ability to prevent unreliable responses in advance. In this paper,
we introduce Aspect-Based Causal Abstention (ABCA), a new framework that
enables early abstention by analysing the internal diversity of LLM knowledge
through causal inference. This diversity reflects the multifaceted nature of
parametric knowledge acquired from various sources, representing diverse
aspects such as disciplines, legal contexts, or temporal frames. ABCA estimates
causal effects conditioned on these aspects to assess the reliability of
knowledge relevant to a given query. Based on these estimates, we enable two
types of abstention: Type-1, where aspect effects are inconsistent (knowledge
conflict), and Type-2, where aspect effects consistently support abstention
(knowledge insufficiency). Experiments on standard benchmarks demonstrate that
ABCA improves abstention reliability, achieves state-of-the-art performance,
and enhances the interpretability of abstention decisions.
\\ ( https://arxiv.org/abs/2511.17170 ,  1639kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17184
Date: Fri, 21 Nov 2025 12:05:31 GMT   (15kb)

Title: Attention-Guided Feature Fusion (AGFF) Model for Integrating Statistical
 and Semantic Features in News Text Classification
Authors: Mohammad Zare
Categories: cs.CL cs.AI
\\
 News text classification is a crucial task in natural language processing,
essential for organizing and filtering the massive volume of digital content.
Traditional methods typically rely on statistical features like term
frequencies or TF-IDF values, which are effective at capturing word-level
importance but often fail to reflect contextual meaning. In contrast, modern
deep learning approaches utilize semantic features to understand word usage
within context, yet they may overlook simple, high-impact statistical
indicators. This paper introduces an Attention-Guided Feature Fusion (AGFF)
model that combines statistical and semantic features in a unified framework.
The model applies an attention-based mechanism to dynamically determine the
relative importance of each feature type, enabling more informed classification
decisions. Through evaluation on benchmark news datasets, the AGFF model
demonstrates superior performance compared to both traditional statistical
models and purely semantic deep learning models. The results confirm that
strategic integration of diverse feature types can significantly enhance
classification accuracy. Additionally, ablation studies validate the
contribution of each component in the fusion process. The findings highlight
the model's ability to balance and exploit the complementary strengths of
statistical and semantic representations, making it a practical and effective
solution for real-world news classification tasks.
\\ ( https://arxiv.org/abs/2511.17184 ,  15kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17190
Date: Fri, 21 Nov 2025 12:12:17 GMT   (1295kb)

Title: AutoLink: Autonomous Schema Exploration and Expansion for Scalable
 Schema Linking in Text-to-SQL at Scale
Authors: Ziyang Wang, Yuanlei Zheng, Zhenbiao Cao, Xiaojin Zhang, Zhongyu Wei,
 Pei Fu, Zhenbo Luo, Wei Chen, Xiang Bai
Categories: cs.CL cs.DB
\\
 For industrial-scale text-to-SQL, supplying the entire database schema to
Large Language Models (LLMs) is impractical due to context window limits and
irrelevant noise. Schema linking, which filters the schema to a relevant
subset, is therefore critical. However, existing methods incur prohibitive
costs, struggle to trade off recall and noise, and scale poorly to large
databases. We present \textbf{AutoLink}, an autonomous agent framework that
reformulates schema linking as an iterative, agent-driven process. Guided by an
LLM, AutoLink dynamically explores and expands the linked schema subset,
progressively identifying necessary schema components without inputting the
full database schema. Our experiments demonstrate AutoLink's superior
performance, achieving state-of-the-art strict schema linking recall of
\textbf{97.4\%} on Bird-Dev and \textbf{91.2\%} on Spider-2.0-Lite, with
competitive execution accuracy, i.e., \textbf{68.7\%} EX on Bird-Dev (better
than CHESS) and \textbf{34.9\%} EX on Spider-2.0-Lite (ranking 2nd on the
official leaderboard). Crucially, AutoLink exhibits \textbf{exceptional
scalability}, \textbf{maintaining high recall}, \textbf{efficient token
consumption}, and \textbf{robust execution accuracy} on large schemas (e.g.,
over 3,000 columns) where existing methods severely degrade-making it a highly
scalable, high-recall schema-linking solution for industrial text-to-SQL
systems.
\\ ( https://arxiv.org/abs/2511.17190 ,  1295kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17205
Date: Fri, 21 Nov 2025 12:32:01 GMT   (660kb)

Title: E$^3$-Pruner: Towards Efficient, Economical, and Effective Layer Pruning
 for Large Language Models
Authors: Tao Yuan, Haoli Bai, Yinfei Pan, Xuyang Cao, Tianyu Zhang, Lu Hou,
 Ting Hu, Xianzhi Yu
Categories: cs.CL
\\
 With the increasing size of large language models, layer pruning has gained
increased attention as a hardware-friendly approach for model compression.
However, existing layer pruning methods struggle to simultaneously address key
practical deployment challenges, including performance degradation, high
training costs, and limited acceleration. To overcome these limitations, we
propose \name, a task-\underline{E}ffective, training-\underline{E}conomical
and inference-\underline{E}fficient layer pruning framework. \namespace
introduces two key innovations: (1) a differentiable mask optimization method
using a Gumbel-TopK sampler, enabling efficient and precise pruning mask
search; and (2) an entropy-aware adaptive knowledge distillation strategy that
enhances task performance. Extensive experiments over diverse model
architectures and benchmarks demonstrate the superiority of our method over
state-of-the-art approaches. Notably, \namespace achieves 96\% accuracy, a mere
0.8\% drop from the original model (96.8\%) on MATH-500 when pruning 25\%
layers of Qwen3-32B, outperforming existing SOTA (95\%), with a 1.33$\times$
inference speedup by consuming merely 0.5B tokens (0.5\% of the post-training
data volume).
\\ ( https://arxiv.org/abs/2511.17205 ,  660kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17208
Date: Fri, 21 Nov 2025 12:41:17 GMT   (150kb)

Title: A Simple Yet Strong Baseline for Long-Term Conversational Memory of LLM
 Agents
Authors: Sizhe Zhou
Categories: cs.CL
Comments: Work in progress
\\
 LLM-based conversational agents still struggle to maintain coherent,
personalized interaction over many sessions: fixed context windows limit how
much history can be kept in view, and most external memory approaches trade off
between coarse retrieval over large chunks and fine-grained but fragmented
views of the dialogue. Motivated by neo-Davidsonian event semantics, we propose
an event-centric alternative that represents conversational history as short,
event-like propositions which bundle together participants, temporal cues, and
minimal local context, rather than as independent relation triples or opaque
summaries. In contrast to work that aggressively compresses or forgets past
content, our design aims to preserve information in a non-compressive form and
make it more accessible, rather than more lossy. Concretely, we instruct an LLM
to decompose each session into enriched elementary discourse units (EDUs) --
self-contained statements with normalized entities and source turn attributions
-- and organize sessions, EDUs, and their arguments in a heterogeneous graph
that supports associative recall. On top of this representation we build two
simple retrieval-based variants that use dense similarity search and LLM
filtering, with an optional graph-based propagation step to connect and
aggregate evidence across related EDUs. Experiments on the LoCoMo and
LongMemEval$_S$ benchmarks show that these event-centric memories match or
surpass strong baselines, while operating with much shorter QA contexts. Our
results suggest that structurally simple, event-level memory provides a
principled and practical foundation for long-horizon conversational agents. Our
code and data will be released at https://github.com/KevinSRR/EMem.
\\ ( https://arxiv.org/abs/2511.17208 ,  150kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17220
Date: Fri, 21 Nov 2025 13:01:28 GMT   (2034kb)

Title: Parrot: Persuasion and Agreement Robustness Rating of Output Truth -- A
 Sycophancy Robustness Benchmark for LLMs
Authors: Yusuf \c{C}elebi, Mahmoud El Hussieni, \"Ozay Ezerceli
Categories: cs.CL cs.AI cs.CE cs.LG
\\
 This study presents PARROT (Persuasion and Agreement Robustness Rating of
Output Truth), a robustness focused framework designed to measure the
degradation in accuracy that occurs under social pressure exerted on users
through authority and persuasion in large language models (LLMs) the phenomenon
of sycophancy (excessive conformity). PARROT (i) isolates causal effects by
comparing the neutral version of the same question with an authoritatively
false version using a double-blind evaluation, (ii) quantifies confidence
shifts toward the correct and imposed false responses using
log-likelihood-based calibration tracking, and (iii) systematically classifies
failure modes (e.g., robust correct, sycophantic agreement, reinforced error,
stubborn error, self-correction, etc.) using an eight-state behavioral
taxonomy. We evaluated 22 models using 1,302 MMLU-style multiple-choice
questions across 13 domains and domain-specific authority templates. Findings
show marked heterogeneity: advanced models (e.g., GPT-5, GPT-4.1, Claude Sonnet
4.5) exhibit low "follow rates" ($\leq 11\%$, GPT-5: 4\%) and minimal accuracy
loss, while older/smaller models show severe epistemic collapse (GPT-4: 80\%,
Qwen 2.5-1.5B: 94\%). The danger is not limited to response changes; weak
models reduce confidence in the correct response while increasing confidence in
the imposed incorrect response. While international law and global knowledge at
the domain level exhibit high fragility, elementary mathematics is relatively
resilient. Consequently, we argue that the goal of "resistance to overfitting
pressure" should be addressed as a primary objective alongside accuracy, harm
avoidance, and privacy for safe deployment in the real world.
\\ ( https://arxiv.org/abs/2511.17220 ,  2034kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17238
Date: Fri, 21 Nov 2025 13:32:56 GMT   (1993kb)

Title: Lost in Translation and Noise: A Deep Dive into the Failure Modes of
 VLMs on Real-World Tables
Authors: Anshul Singh, Rohan Chaudhary, Gagneet Singh, Abhay Kumary
Categories: cs.CL cs.AI cs.CV
Comments: Accepted as Spotligh Talk at EurIPS 2025 Workshop on AI For Tabular
 Data
\\
 The impressive performance of VLMs is largely measured on benchmarks that
fail to capture the complexities of real-world scenarios. Existing datasets for
tabular QA, such as WikiTableQuestions and FinQA, are overwhelmingly
monolingual (English) and present tables in a digitally perfect, clean format.
This creates a significant gap between research and practice. To address this,
we present \textbf{MirageTVQA}, a new benchmark designed to evaluate VLMs on
these exact dimensions. Featuring nearly 60,000 QA pairs across 24 languages,
MirageTVQA challenges models with tables that are not only multilingual but
also visually imperfect, incorporating realistic noise to mimic scanned
documents. Our evaluation of the leading VLMs reveals two primary failure
points: a severe degradation in performance (over 35\% drop for the best
models) when faced with visual noise and a consistent English-first bias where
reasoning abilities fail to transfer to other languages. MirageTVQA provides a
benchmark for measuring and driving progress towards more robust VLM models for
table reasoning. The dataset and the code are available at:
https://github.com/anshulsc/MirageTVQA.
\\ ( https://arxiv.org/abs/2511.17238 ,  1993kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17241
Date: Fri, 21 Nov 2025 13:40:14 GMT   (142kb)

Title: Social-Media Based Personas Challenge: Hybrid Prediction of Common and
 Rare User Actions on Bluesky
Authors: Benjamin White, Anastasia Shimorina
Categories: cs.CL
Comments: 1st place at SocialSim: Social-Media Based Personas challenge 2025
\\
 Understanding and predicting user behavior on social media platforms is
crucial for content recommendation and platform design. While existing
approaches focus primarily on common actions like retweeting and liking, the
prediction of rare but significant behaviors remains largely unexplored. This
paper presents a hybrid methodology for social media user behavior prediction
that addresses both frequent and infrequent actions across a diverse action
vocabulary. We evaluate our approach on a large-scale Bluesky dataset
containing 6.4 million conversation threads spanning 12 distinct user actions
across 25 persona clusters. Our methodology combines four complementary
approaches: (i) a lookup database system based on historical response patterns;
(ii) persona-specific LightGBM models with engineered temporal and semantic
features for common actions; (iii) a specialized hybrid neural architecture
fusing textual and temporal representations for rare action classification; and
(iv) generation of text replies. Our persona-specific models achieve an average
macro F1-score of 0.64 for common action prediction, while our rare action
classifier achieves 0.56 macro F1-score across 10 rare actions. These results
demonstrate that effective social media behavior prediction requires tailored
modeling strategies recognizing fundamental differences between action types.
Our approach achieved first place in the SocialSim: Social-Media Based Personas
challenge organized at the Social Simulation with LLMs workshop at COLM 2025.
\\ ( https://arxiv.org/abs/2511.17241 ,  142kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17290
Date: Fri, 21 Nov 2025 15:01:57 GMT   (68kb)

Title: Estonian WinoGrande Dataset: Comparative Analysis of LLM Performance on
 Human and Machine Translation
Authors: Marii Ojastu, Hele-Andra Kuulmets, Aleksei Dorkin, Marika Borovikova,
 Dage S\"arg, Kairit Sirts
Categories: cs.CL
Comments: Preprint
\\
 In this paper, we present a localized and culturally adapted Estonian
translation of the test set from the widely used commonsense reasoning
benchmark, WinoGrande. We detail the translation and adaptation process carried
out by translation specialists and evaluate the performance of both proprietary
and open source models on the human translated benchmark. Additionally, we
explore the feasibility of achieving high-quality machine translation by
incorporating insights from the manual translation process into the design of a
detailed prompt. This prompt is specifically tailored to address both the
linguistic characteristics of Estonian and the unique translation challenges
posed by the WinoGrande dataset. Our findings show that model performance on
the human translated Estonian dataset is slightly lower than on the original
English test set, while performance on machine-translated data is notably
worse. Additionally, our experiments indicate that prompt engineering offers
limited improvement in translation quality or model accuracy, and highlight the
importance of involving language specialists in dataset translation and
adaptation to ensure reliable and interpretable evaluations of language
competency and reasoning in large language models.
\\ ( https://arxiv.org/abs/2511.17290 ,  68kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17301
Date: Fri, 21 Nov 2025 15:14:32 GMT   (219kb)

Title: Large Language Models for Sentiment Analysis to Detect Social
 Challenges: A Use Case with South African Languages
Authors: Koena Ronny Mabokela and Tim Schlippe and Matthias W\"olfel
Categories: cs.CL cs.AI
Comments: Published in the Proceedings of The Southern African Conference on AI
 Research (SACAIR 2024), Bloemfontein, South Africa, 2-6 December 2024. ISBN:
 978-0-7961-6069-0
\\
 Sentiment analysis can aid in understanding people's opinions and emotions on
social issues. In multilingual communities sentiment analysis systems can be
used to quickly identify social challenges in social media posts, enabling
government departments to detect and address these issues more precisely and
effectively. Recently, large-language models (LLMs) have become available to
the wide public and initial analyses have shown that they exhibit magnificent
zero-shot sentiment analysis abilities in English. However, there is no work
that has investigated to leverage LLMs for sentiment analysis on social media
posts in South African languages and detect social challenges. Consequently, in
this work, we analyse the zero-shot performance of the state-of-the-art LLMs
GPT-3.5, GPT-4, LlaMa 2, PaLM 2, and Dolly 2 to investigate the sentiment
polarities of the 10 most emerging topics in English, Sepedi and Setswana
social media posts that fall within the jurisdictional areas of 10 South
African government departments. Our results demonstrate that there are big
differences between the various LLMs, topics, and languages. In addition, we
show that a fusion of the outcomes of different LLMs provides large gains in
sentiment classification performance with sentiment classification errors below
1%. Consequently, it is now feasible to provide systems that generate reliable
information about sentiment analysis to detect social challenges and draw
conclusions about possible needs for actions on specific topics and within
different language groups.
\\ ( https://arxiv.org/abs/2511.17301 ,  219kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17315
Date: Fri, 21 Nov 2025 15:34:42 GMT   (312kb)

Title: Humanlike Multi-user Agent (HUMA): Designing a Deceptively Human AI
 Facilitator for Group Chats
Authors: Mateusz Jacniacki, Mart\'i Carmona Serrat
Categories: cs.CL
Comments: 9 pages, 4 figures
\\
 Conversational agents built on large language models (LLMs) are becoming
increasingly prevalent, yet most systems are designed for one-on-one,
turn-based exchanges rather than natural, asynchronous group chats. As AI
assistants become widespread throughout digital platforms, from virtual
assistants to customer service, developing natural and humanlike interaction
patterns seems crucial for maintaining user trust and engagement. We present
the Humanlike Multi-user Agent (HUMA), an LLM-based facilitator that
participates in multi-party conversations using human-like strategies and
timing. HUMA extends prior multi-user chatbot work with an event-driven
architecture that handles messages, replies, reactions and introduces realistic
response-time simulation. HUMA comprises three components-Router, Action Agent,
and Reflection-which together adapt LLMs to group conversation dynamics.
 We evaluate HUMA in a controlled study with 97 participants in four-person
role-play chats, comparing AI and human community managers (CMs). Participants
classified CMs as human at near-chance rates in both conditions, indicating
they could not reliably distinguish HUMA agents from humans. Subjective
experience was comparable across conditions: community-manager effectiveness,
social presence, and engagement/satisfaction differed only modestly with small
effect sizes. Our results suggest that, in natural group chat settings, an AI
facilitator can match human quality while remaining difficult to identify as
nonhuman.
\\ ( https://arxiv.org/abs/2511.17315 ,  312kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17337
Date: Fri, 21 Nov 2025 15:56:58 GMT   (8236kb)

Title: A new kid on the block: Distributional semantics predicts the
 word-specific tone signatures of monosyllabic words in conversational Taiwan
 Mandarin
Authors: Xiaoyun Jin, Mirjam Ernestus, R. Harald Baayen
Categories: cs.CL cs.SD
Comments: arXiv admin note: text overlap with arXiv:2409.07891
\\
 We present a corpus-based investigation of how the pitch contours of
monosyllabic words are realized in spontaneous conversational Mandarin,
focusing on the effects of words' meanings. We used the generalized additive
model to decompose a given observed pitch contour into a set of component pitch
contours that are tied to different control variables and semantic predictors.
Even when variables such as word duration, gender, speaker identity, tonal
context, vowel height, and utterance position are controlled for, the effect of
word remains a strong predictor of tonal realization. We present evidence that
this effect of word is a semantic effect: word sense is shown to be a better
predictor than word, and heterographic homophones are shown to have different
pitch contours. The strongest evidence for the importance of semantics is that
the pitch contours of individual word tokens can be predicted from their
contextualized embeddings with an accuracy that substantially exceeds a
permutation baseline. For phonetics, distributional semantics is a new kid on
the block. Although our findings challenge standard theories of Mandarin tone,
they fit well within the theoretical framework of the Discriminative Lexicon
Model.
\\ ( https://arxiv.org/abs/2511.17337 ,  8236kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17358
Date: Fri, 21 Nov 2025 16:23:17 GMT   (2964kb)

Title: Don't Learn, Ground: A Case for Natural Language Inference with Visual
 Grounding
Authors: Daniil Ignatev, Ayman Santeer, Albert Gatt, Denis Paperno
Categories: cs.CL
\\
 We propose a zero-shot method for Natural Language Inference (NLI) that
leverages multimodal representations by grounding language in visual contexts.
Our approach generates visual representations of premises using text-to-image
models and performs inference by comparing these representations with textual
hypotheses. We evaluate two inference techniques: cosine similarity and visual
question answering. Our method achieves high accuracy without task-specific
fine-tuning, demonstrating robustness against textual biases and surface
heuristics. Additionally, we design a controlled adversarial dataset to
validate the robustness of our approach. Our findings suggest that leveraging
visual modality as a meaning representation provides a promising direction for
robust natural language understanding.
\\ ( https://arxiv.org/abs/2511.17358 ,  2964kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17388
Date: Fri, 21 Nov 2025 16:50:00 GMT   (1725kb)

Title: Selective Rotary Position Embedding
Authors: Sajad Movahedi, Timur Carstensen, Arshia Afzal, Frank Hutter, Antonio
 Orvieto, Volkan Cevher
Categories: cs.CL cs.LG
\\
 Position information is essential for language modeling. In softmax
transformers, Rotary Position Embeddings (\textit{RoPE}) encode positions
through \textit{fixed-angle} rotations, while in linear transformers, order is
handled via input-dependent (selective) gating that decays past key-value
associations. Selectivity has generally been shown to improve language-related
tasks. Inspired by this, we introduce \textit{Selective RoPE}, an
\textit{input-dependent} rotary embedding mechanism, that generalizes
\textit{RoPE}, and enables rotation in \textit{arbitrary angles} for both
linear and softmax transformers. We show that softmax attention already
performs a hidden form of these rotations on query-key pairs, uncovering an
implicit positional structure. We further show that in state-space models and
gated linear transformers, the real part manages forgetting while the imaginary
part encodes positions through rotations. We validate our method by equipping
gated transformers with \textit{Selective RoPE}, demonstrating that its
input-dependent rotations improve performance in language modeling and on
difficult sequence tasks like copying, state tracking, and retrieval.
\\ ( https://arxiv.org/abs/2511.17388 ,  1725kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17402
Date: Fri, 21 Nov 2025 17:03:00 GMT   (219kb)

Title: PUCP-Metrix: A Comprehensive Open-Source Repository of Linguistic
 Metrics for Spanish
Authors: Javier Alonso Villegas Luis and Marco Antonio Sobrevilla Cabezudo
Categories: cs.CL
Comments: 1 figure, to be submitted to EACL Demo track
\\
 Linguistic features remain essential for interpretability and tasks involving
style, structure, and readability, but existing Spanish tools offer limited
coverage. We present PUCP-Metrix, an open-source repository of 182 linguistic
metrics spanning lexical diversity, syntactic and semantic complexity,
cohesion, psycholinguistics, and readability. PUCP-Metrix enables fine-grained,
interpretable text analysis. We evaluate its usefulness on Automated
Readability Assessment and Machine-Generated Text Detection, showing
competitive performance compared to an existing repository and strong neural
baselines. PUCP-Metrix offers a comprehensive, extensible resource for Spanish,
supporting diverse NLP applications.
\\ ( https://arxiv.org/abs/2511.17402 ,  219kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17405
Date: Fri, 21 Nov 2025 17:06:37 GMT   (5079kb)

Title: Beyond Multiple Choice: A Hybrid Framework for Unifying Robust
 Evaluation and Verifiable Reasoning Training
Authors: Yesheng Liu, Hao Li, Haiyu Xu, Baoqi Pei, Jiahao Wang, Mingxuan Zhao,
 Jingshu Zheng, Zheqi He, JG Yao, Bowen Qin, Xi Yang, Jiajun Zhang
Categories: cs.CL cs.AI
Comments: Project url: https://flageval-baai.github.io/ReVeL/
\\
 Multiple-choice question answering (MCQA) has been a popular format for
evaluating and reinforcement fine-tuning (RFT) of modern multimodal language
models. Its constrained output format allows for simplified, deterministic
automatic verification. However, we find that the options may leak exploitable
signals, which makes the accuracy metrics unreliable for indicating real
capabilities and encourages explicit or implicit answer guessing behaviors
during RFT. We propose ReVeL (Rewrite and Verify by LLM), a framework that
rewrites multiple-choice questions into open-form questions while keeping
answers verifiable whenever possible. The framework categorizes questions
according to different answer types, apply different rewriting and verification
schemes, respectively. When applied for RFT, we converted 20k MCQA examples and
use GRPO to finetune Qwen2.5-VL models. Models trained on ReVeL-OpenQA match
MCQA accuracy on multiple-choice benchmarks and improve OpenQA accuracy by
about six percentage points, indicating better data efficiency and more robust
reward signals than MCQA-based training. When used for evaluation, ReVeL also
reveals up to 20 percentage points of score inflation in MCQA benchmarks
(relative to OpenQA), improves judging accuracy, and reduces both cost and
latency. We will release code and data publicly.
\\ ( https://arxiv.org/abs/2511.17405 ,  5079kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17432
Date: Fri, 21 Nov 2025 17:30:18 GMT   (2628kb)

Title: SMILE: A Composite Lexical-Semantic Metric for Question-Answering
 Evaluation
Authors: Shrikant Kendre, Austin Xu, Honglu Zhou, Michael Ryoo, Shafiq Joty,
 Juan Carlos Niebles
Categories: cs.CL cs.AI cs.CV
Comments: 23 pages, 6 tables, 9 figures
\\
 Traditional evaluation metrics for textual and visual question answering,
like ROUGE, METEOR, and Exact Match (EM), focus heavily on n-gram based lexical
similarity, often missing the deeper semantic understanding needed for accurate
assessment. While measures like BERTScore and MoverScore leverage contextual
embeddings to address this limitation, they lack flexibility in balancing
sentence-level and keyword-level semantics and ignore lexical similarity, which
remains important. Large Language Model (LLM) based evaluators, though
powerful, come with drawbacks like high costs, bias, inconsistency, and
hallucinations. To address these issues, we introduce SMILE: Semantic Metric
Integrating Lexical Exactness, a novel approach that combines sentence-level
semantic understanding with keyword-level semantic understanding and easy
keyword matching. This composite method balances lexical precision and semantic
relevance, offering a comprehensive evaluation. Extensive benchmarks across
text, image, and video QA tasks show SMILE is highly correlated with human
judgments and computationally lightweight, bridging the gap between lexical and
semantic evaluation.
\\ ( https://arxiv.org/abs/2511.17432 ,  2628kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17473
Date: Fri, 21 Nov 2025 18:23:04 GMT   (6523kb)

Title: Masked-and-Reordered Self-Supervision for Reinforcement Learning from
 Verifiable Rewards
Authors: Zhen Wang, Zhifeng Gao, Guolin Ke
Categories: cs.CL cs.AI cs.LG
\\
 Test-time scaling has been shown to substantially improve large language
models' (LLMs) mathematical reasoning. However, for a large portion of
mathematical corpora, especially theorem proving, RLVR's scalability is
limited: intermediate reasoning is crucial, while final answers are difficult
to directly and reliably verify. Meanwhile, token-level SFT often degenerates
into rote memorization rather than inducing longer chains of thought. Inspired
by BERT's self-supervised tasks, we propose MR-RLVR (Masked-and-Reordered
RLVR), which constructs process-level self-supervised rewards via
"masked-then-fill" and "step reordering" to extract learnable signals from
intermediate reasoning. Our training pipeline comprises two stages: we first
perform self-supervised training on sampled mathematical calculation and proof
data; we then conduct RLVR fine-tuning on mathematical calculation datasets
where only outcomes are verifiable. We implement MR-RLVR on Qwen2.5-3B and
DeepSeek-R1-Distill-Qwen-1.5B, and evaluate on AIME24, AIME25, AMC23, and
MATH500. Under a fixed sampling and decoding budget, MR-RLVR achieves average
relative gains over the original RLVR of +9.86% Pass@1, +5.27% Pass@5, and
+4.00% Pass@8. These results indicate that incorporating process-aware
self-supervised signals can effectively enhance RLVR's scalability and
performance in only outcome-verifiable settings.
\\ ( https://arxiv.org/abs/2511.17473 ,  6523kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16695
Date: Mon, 17 Nov 2025 13:25:04 GMT   (2899kb)

Title: The persistence of painting styles
Authors: Reetikaa Reddy Munnangi and Barbara Giunti
Categories: cs.CV
Comments: 8 pages, 4 figures, and 8 tables. Short YouTube video with highlights
 of the paper available at https://www.youtube.com/watch?v=sJSnidrEabM on the
 AATRN YouTube channel
\\
 Art is a deeply personal and expressive medium, where each artist brings
their own style, technique, and cultural background into their work.
Traditionally, identifying artistic styles has been the job of art historians
or critics, relying on visual intuition and experience. However, with the
advancement of mathematical tools, we can explore art through more structured
lens. In this work, we show how persistent homology (PH), a method from
topological data analysis, provides objective and interpretable insights on
artistic styles. We show how PH can, with statistical certainty, differentiate
between artists, both from different artistic currents and from the same one,
and distinguish images of an artist from an AI-generated image in the artist's
style.
\\ ( https://arxiv.org/abs/2511.16695 ,  2899kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16711
Date: Thu, 20 Nov 2025 07:30:32 GMT   (29311kb)

Title: Motion Transfer-Enhanced StyleGAN for Generating Diverse Macaque Facial
 Expressions
Authors: Takuya Igaue, Catia Correia-Caeiro, Akito Yoshida, Takako
 Miyabe-Nishiwaki, Ryusuke Hayashi
Categories: cs.CV eess.IV
\\
 Generating animal faces using generative AI techniques is challenging because
the available training images are limited both in quantity and variation,
particularly for facial expressions across individuals. In this study, we focus
on macaque monkeys, widely studied in systems neuroscience and evolutionary
research, and propose a method to generate their facial expressions using a
style-based generative image model (i.e., StyleGAN2). To address data
limitations, we implemented: 1) data augmentation by synthesizing new facial
expression images using a motion transfer to animate still images with computer
graphics, 2) sample selection based on the latent representation of macaque
faces from an initially trained StyleGAN2 model to ensure the variation and
uniform sampling in training dataset, and 3) loss function refinement to ensure
the accurate reproduction of subtle movements, such as eye movements. Our
results demonstrate that the proposed method enables the generation of diverse
facial expressions for multiple macaque individuals, outperforming models
trained solely on original still images. Additionally, we show that our model
is effective for style-based image editing, where specific style parameters
correspond to distinct facial movements. These findings underscore the model's
potential for disentangling motion components as style parameters, providing a
valuable tool for research on macaque facial expressions.
\\ ( https://arxiv.org/abs/2511.16711 ,  29311kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16712
Date: Thu, 20 Nov 2025 08:56:46 GMT   (24318kb)

Title: PairHuman: A High-Fidelity Photographic Dataset for Customized
 Dual-Person Generation
Authors: Ting Pan, Ye Wang, Peiguang Jing, Rui Ma, Zili Yi, Yu Liu
Categories: cs.CV cs.AI
Comments: 46 pages, 31 figures
MSC-class: 68Txx
ACM-class: I.2; I.4
\\
 Personalized dual-person portrait customization has considerable potential
applications, such as preserving emotional memories and facilitating wedding
photography planning. However, the absence of a benchmark dataset hinders the
pursuit of high-quality customization in dual-person portrait generation. In
this paper, we propose the PairHuman dataset, which is the first large-scale
benchmark dataset specifically designed for generating dual-person portraits
that meet high photographic standards. The PairHuman dataset contains more than
100K images that capture a variety of scenes, attire, and dual-person
interactions, along with rich metadata, including detailed image descriptions,
person localization, human keypoints, and attribute tags. We also introduce
DHumanDiff, which is a baseline specifically crafted for dual-person portrait
generation that features enhanced facial consistency and simultaneously
balances in personalized person generation and semantic-driven scene creation.
Finally, the experimental results demonstrate that our dataset and method
produce highly customized portraits with superior visual quality that are
tailored to human preferences. Our dataset is publicly available at
https://github.com/annaoooo/PairHuman.
\\ ( https://arxiv.org/abs/2511.16712 ,  24318kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16717
Date: Thu, 20 Nov 2025 18:56:34 GMT   (756kb)

Title: A Machine Learning-Driven Solution for Denoising Inertial Confinement
 Fusion Images
Authors: Asya Y. Akkus, Bradley T. Wolfe, Pinghan Chu, Chengkun Huang, Chris S.
 Campbell, Mariana Alvarado Alvarez, Petr Volegov, David Fittinghoff, Robert
 Reinovsky, Zhehui Wang
Categories: cs.CV cs.AI
\\
 Neutron imaging is important in optimizing analysis of inertial confinement
fusion (ICF) events such as those at the National Ignition Facility (NIF) and
improving current and future ICF platforms. However, images of neutron sources
are often degraded by various types of noise. Most commonly, Gaussian and
Poisson noise often coexist within one image, obscuring fine details and
blurring edges. These noise types often overlap, making them difficult to
distinguish and remove using conventional filtering and thresholding methods.
As a result, noise removal techniques that preserve image fidelity are
important for analyzing and interpreting images of a neutron source. Current
solutions include a combination of filtering and thresholding methodologies. In
the past, machine learning approaches were rarely implemented due to a lack of
ground truth neutron imaging data for ICF processes. However, recent advances
in synthetic data production, particularly in the fusion imaging field, have
opened opportunities to investigate new denoising procedures using both
supervised and unsupervised machine learning methods. In this study, we
implement an unsupervised autoencoder with a Cohen-Daubechies- Feauveau (CDF
97) wavelet transform in the latent space for mixed Gaussian-Poisson denoising.
The network successfully denoises neutron imaging data. Additionally, it
demonstrates lower reconstruction error and superior edge preservation metrics
when benchmarked with data generated by a forward model and compared to
non-ML-based filtering mechanisms such as Block-matching and 3D filtering
(BM3D). This approach presents a promising advancement in neutron image noise
reduction and three-dimensional reconstruction analysis of ICF experiments.
\\ ( https://arxiv.org/abs/2511.16717 ,  756kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16719
Date: Thu, 20 Nov 2025 18:59:56 GMT   (37393kb)

Title: SAM 3: Segment Anything with Concepts
Authors: Nicolas Carion, Laura Gustafson, Yuan-Ting Hu, Shoubhik Debnath,
 Ronghang Hu, Didac Suris, Chaitanya Ryali, Kalyan Vasudev Alwala, Haitham
 Khedr, Andrew Huang, Jie Lei, Tengyu Ma, Baishan Guo, Arpit Kalla, Markus
 Marks, Joseph Greer, Meng Wang, Peize Sun, Roman R\"adle, Triantafyllos
 Afouras, Effrosyni Mavroudi, Katherine Xu, Tsung-Han Wu, Yu Zhou, Liliane
 Momeni, Rishi Hazra, Shuangrui Ding, Sagar Vaze, Francois Porcher, Feng Li,
 Siyuan Li, Aishwarya Kamath, Ho Kei Cheng, Piotr Doll\'ar, Nikhila Ravi, Kate
 Saenko, Pengchuan Zhang, Christoph Feichtenhofer
Categories: cs.CV cs.AI
\\
 We present Segment Anything Model (SAM) 3, a unified model that detects,
segments, and tracks objects in images and videos based on concept prompts,
which we define as either short noun phrases (e.g., "yellow school bus"), image
exemplars, or a combination of both. Promptable Concept Segmentation (PCS)
takes such prompts and returns segmentation masks and unique identities for all
matching object instances. To advance PCS, we build a scalable data engine that
produces a high-quality dataset with 4M unique concept labels, including hard
negatives, across images and videos. Our model consists of an image-level
detector and a memory-based video tracker that share a single backbone.
Recognition and localization are decoupled with a presence head, which boosts
detection accuracy. SAM 3 doubles the accuracy of existing systems in both
image and video PCS, and improves previous SAM capabilities on visual
segmentation tasks. We open source SAM 3 along with our new Segment Anything
with Concepts (SA-Co) benchmark for promptable concept segmentation.
\\ ( https://arxiv.org/abs/2511.16719 ,  37393kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16743
Date: Thu, 20 Nov 2025 19:00:15 GMT   (19745kb)

Title: SafeR-CLIP: Mitigating NSFW Content in Vision-Language Models While
 Preserving Pre-Trained Knowledge
Authors: Adeel Yousaf, Joseph Fioresi, James Beetham, Amrit Singh Bedi, Mubarak
 Shah
Categories: cs.CV cs.AI cs.LG
Comments: AAAI 2026 (Main Technical Track)
\\
 Improving the safety of vision-language models like CLIP via fine-tuning
often comes at a steep price, causing significant drops in their generalization
performance. We find this trade-off stems from rigid alignment strategies that
force unsafe concepts toward single, predefined safe targets, disrupting the
model's learned semantic structure. To address this, we propose a
proximity-aware approach: redirecting unsafe concepts to their semantically
closest safe alternatives to minimize representational change. We introduce
SaFeR-CLIP, a fine-tuning framework that applies this principle of minimal
intervention. SaFeR-CLIP successfully reconciles safety and performance,
recovering up to 8.0% in zero-shot accuracy over prior methods while
maintaining robust safety. To support more rigorous evaluation, we also
contribute NSFW-Caps, a new benchmark of 1,000 highly-aligned pairs for testing
safety under distributional shift. Our work shows that respecting the geometry
of pretrained representations is key to achieving safety without sacrificing
performance.
\\ ( https://arxiv.org/abs/2511.16743 ,  19745kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16766
Date: Thu, 20 Nov 2025 19:33:57 GMT   (12436kb)

Title: SVG360: Multi-View SVG Generation with Geometric and Color Consistency
 from a Single SVG
Authors: Mengnan Jiang, Zhaolin Sun, Christian Franke, Michele Franco Adesso,
 Antonio Haas, Grace Li Zhang
Categories: cs.CV
Comments: 10 pages, 4 figures. Preprint
\\
 Scalable Vector Graphics (SVGs) are central to modern design workflows,
offering scaling without distortion and precise editability. However, for
single object SVGs, generating multi-view consistent SVGs from a single-view
input remains underexplored. We present a three stage framework that produces
multi-view SVGs with geometric and color consistency from a single SVG input.
First, the rasterized input is lifted to a 3D representation and rendered under
target camera poses, producing multi-view images of the object. Next, we extend
the temporal memory mechanism of Segment Anything 2 (SAM2) to the spatial
domain, constructing a spatial memory bank that establishes part level
correspondences across neighboring views, yielding cleaner and more consistent
vector paths and color assignments without retraining. Finally, during the
raster to vector conversion, we perform path consolidation and structural
optimization to reduce redundancy while preserving boundaries and semantics.
The resulting SVGs exhibit strong geometric and color consistency across views,
significantly reduce redundant paths, and retain fine structural details. This
work bridges generative modeling and structured vector representation,
providing a scalable route to single input, object level multi-view SVG
generation and supporting applications such as asset creation and semantic
vector editing.
\\ ( https://arxiv.org/abs/2511.16766 ,  12436kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16807
Date: Thu, 20 Nov 2025 21:13:56 GMT   (9398kb)

Title: Mesh RAG: Retrieval Augmentation for Autoregressive Mesh Generation
Authors: Xiatao Sun, Chen Liang, Qian Wang, Daniel Rakita
Categories: cs.CV cs.AI
\\
 3D meshes are a critical building block for applications ranging from
industrial design and gaming to simulation and robotics. Traditionally, meshes
are crafted manually by artists, a process that is time-intensive and difficult
to scale. To automate and accelerate this asset creation, autoregressive models
have emerged as a powerful paradigm for artistic mesh generation. However,
current methods to enhance quality typically rely on larger models or longer
sequences that result in longer generation time, and their inherent sequential
nature imposes a severe quality-speed trade-off. This sequential dependency
also significantly complicates incremental editing. To overcome these
limitations, we propose Mesh RAG, a novel, training-free, plug-and-play
framework for autoregressive mesh generation models. Inspired by RAG for
language models, our approach augments the generation process by leveraging
point cloud segmentation, spatial transformation, and point cloud registration
to retrieve, generate, and integrate mesh components. This retrieval-based
approach decouples generation from its strict sequential dependency,
facilitating efficient and parallelizable inference. We demonstrate the wide
applicability of Mesh RAG across various foundational autoregressive mesh
generation models, showing it significantly enhances mesh quality, accelerates
generation speed compared to sequential part prediction, and enables
incremental editing, all without model retraining.
\\ ( https://arxiv.org/abs/2511.16807 ,  9398kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16825
Date: Thu, 20 Nov 2025 22:13:18 GMT   (35678kb)

Title: WorldGen: From Text to Traversable and Interactive 3D Worlds
Authors: Dilin Wang, Hyunyoung Jung, Tom Monnier, Kihyuk Sohn, Chuhang Zou,
 Xiaoyu Xiang, Yu-Ying Yeh, Di Liu, Zixuan Huang, Thu Nguyen-Phuoc, Yuchen
 Fan, Sergiu Oprea, Ziyan Wang, Roman Shapovalov, Nikolaos Sarafianos,
 Thibault Groueix, Antoine Toisoul, Prithviraj Dhar, Xiao Chu, Minghao Chen,
 Geon Yeong Park, Mahima Gupta, Yassir Azziz, Rakesh Ranjan, Andrea Vedaldi
Categories: cs.CV cs.AI
\\
 We introduce WorldGen, a system that enables the automatic creation of
large-scale, interactive 3D worlds directly from text prompts. Our approach
transforms natural language descriptions into traversable, fully textured
environments that can be immediately explored or edited within standard game
engines. By combining LLM-driven scene layout reasoning, procedural generation,
diffusion-based 3D generation, and object-aware scene decomposition, WorldGen
bridges the gap between creative intent and functional virtual spaces, allowing
creators to design coherent, navigable worlds without manual modeling or
specialized 3D expertise. The system is fully modular and supports fine-grained
control over layout, scale, and style, producing worlds that are geometrically
consistent, visually rich, and efficient to render in real time. This work
represents a step towards accessible, generative world-building at scale,
advancing the frontier of 3D generative AI for applications in gaming,
simulation, and immersive social environments.
\\ ( https://arxiv.org/abs/2511.16825 ,  35678kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16853
Date: Thu, 20 Nov 2025 23:28:30 GMT   (6780kb)

Title: Towards Unified Vision Language Models for Forest Ecological Analysis in
 Earth Observation
Authors: Xizhe Xue, Xiao Xiang Zhu
Categories: cs.CV
Comments: AAAI2026 AI for Environmental Science Workshop
\\
 Recent progress in vision language models (VLMs) has enabled remarkable
perception and reasoning capabilities, yet their potential for scientific
regression in Earth Observation (EO) remains largely unexplored. Existing EO
datasets mainly emphasize semantic understanding tasks such as captioning or
classification, lacking benchmarks that align multimodal perception with
measurable biophysical variables. To fill this gap, we present REO-Instruct,
the first unified benchmark designed for both descriptive and regression tasks
in EO. REO-Instruct establishes a cognitively interpretable logic chain in
forest ecological scenario (human activity,land-cover classification,
ecological patch counting, above-ground biomass (AGB) regression), bridging
qualitative understanding and quantitative prediction. The dataset integrates
co-registered Sentinel-2 and ALOS-2 imagery with structured textual annotations
generated and validated through a hybrid human AI pipeline. Comprehensive
evaluation protocols and baseline results across generic VLMs reveal that
current models struggle with numeric reasoning, highlighting an essential
challenge for scientific VLMs. REO-Instruct offers a standardized foundation
for developing and assessing next-generation geospatial models capable of both
description and scientific inference. The project page are publicly available
at \href{https://github.com/zhu-xlab/REO-Instruct}{REO-Instruct}.
\\ ( https://arxiv.org/abs/2511.16853 ,  6780kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16857
Date: Thu, 20 Nov 2025 23:54:15 GMT   (71107kb)

Title: BOP-ASK: Object-Interaction Reasoning for Vision-Language Models
Authors: Vineet Bhat, Sungsu Kim, Valts Blukis, Greg Heinrich, Prashanth
 Krishnamurthy, Ramesh Karri, Stan Birchfield, Farshad Khorrami, Jonathan
 Tremblay
Categories: cs.CV cs.RO
\\
 Vision Language Models (VLMs) have achieved impressive performance on spatial
reasoning benchmarks, yet these evaluations mask critical weaknesses in
understanding object interactions. Current benchmarks test high level
relationships ('left of,' 'behind', etc.) but ignore fine-grained spatial
understanding needed for real world applications: precise 3D localization,
physical compatibility between objects, object affordances and multi step
spatial planning. In this work, we present BOP-ASK, a novel large scale dataset
for object interaction reasoning for both training and benchmarking. Our data
generation pipeline leverages 6D object poses from the Benchmark for Object
Pose Estimation (BOP) datasets from which we derive fine grained annotations
such as grasp poses, referred object poses, path planning trajectories,
relative spatial and depth relationships, and object-to-object relationships.
BOP-ASK comprises over 150k images and 33M question answer pairs spanning six
tasks (four novel), providing a rich resource for training and evaluating VLMs.
We evaluate proprietary and open sourced VLMs, and conduct human evaluations on
BOP-ASK-core, a contributed test benchmark. We also release BOP-ASK-lab, an
out-of-distribution benchmark with images not sourced from BOP, enabling
testing of generalization. Our experiments demonstrate that models trained on
BOP-ASK outperform baselines and exhibit emergent capabilities such as precise
object and grasp pose estimation, trajectory planning, and fine-grained
object-centric spatial reasoning in cluttered environments. We will publicly
release our datasets and dataset generation pipeline.
\\ ( https://arxiv.org/abs/2511.16857 ,  71107kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16860
Date: Fri, 21 Nov 2025 00:08:21 GMT   (1629kb)

Title: Parts-Mamba: Augmenting Joint Context with Part-Level Scanning for
 Occluded Human Skeleton
Authors: Tianyi Shen, Huijuan Xu, Nilesh Ahuja, Omesh Tickoo, Philip Shin,
 Vijaykrishnan Narayanan
Categories: cs.CV
\\
 Skeleton action recognition involves recognizing human action from human
skeletons. The use of graph convolutional networks (GCNs) has driven major
advances in this recognition task. In real-world scenarios, the captured
skeletons are not always perfect or complete because of occlusions of parts of
the human body or poor communication quality, leading to missing parts in
skeletons or videos with missing frames. In the presence of such
non-idealities, existing GCN models perform poorly due to missing local
context. To address this limitation, we propose Parts-Mamba, a hybrid GCN-Mamba
model designed to enhance the ability to capture and maintain contextual
information from distant joints. The proposed Parts-Mamba model effectively
captures part-specific information through its parts-specific scanning feature
and preserves non-neighboring joint context via a parts-body fusion module. Our
proposed model is evaluated on the NTU RGB+D 60 and NTU RGB+D 120 datasets
under different occlusion settings, achieving up to 12.9% improvement in
accuracy.
\\ ( https://arxiv.org/abs/2511.16860 ,  1629kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16868
Date: Fri, 21 Nov 2025 00:31:21 GMT   (2480kb)

Title: The Joint Gromov Wasserstein Objective for Multiple Object Matching
Authors: Aryan Tajmir Riahi, Khanh Dao Duc
Categories: cs.CV q-bio.BM
\\
 The Gromov-Wasserstein (GW) distance serves as a powerful tool for matching
objects in metric spaces. However, its traditional formulation is constrained
to pairwise matching between single objects, limiting its utility in scenarios
and applications requiring multiple-to-one or multiple-to-multiple object
matching. In this paper, we introduce the Joint Gromov-Wasserstein (JGW)
objective and extend the original framework of GW to enable simultaneous
matching between collections of objects. Our formulation provides a
non-negative dissimilarity measure that identifies partially isomorphic
distributions of mm-spaces, with point sampling convergence. We also show that
the objective can be formulated and solved for point cloud object
representations by adapting traditional algorithms in Optimal Transport,
including entropic regularization. Our benchmarking with other variants of GW
for partial matching indicates superior performance in accuracy and
computational efficiency of our method, while experiments on both synthetic and
real-world datasets show its effectiveness for multiple shape matching,
including geometric shapes and biomolecular complexes, suggesting promising
applications for solving complex matching problems across diverse domains,
including computer graphics and structural biology.
\\ ( https://arxiv.org/abs/2511.16868 ,  2480kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16870
Date: Fri, 21 Nov 2025 00:37:04 GMT   (13900kb)

Title: Align & Invert: Solving Inverse Problems with Diffusion and Flow-based
 Models via Representational Alignment
Authors: Loukas Sfountouris, Giannis Daras, Paris Giampouras
Categories: cs.CV cs.LG
\\
 Enforcing alignment between the internal representations of diffusion or
flow-based generative models and those of pretrained self-supervised encoders
has recently been shown to provide a powerful inductive bias, improving both
convergence and sample quality. In this work, we extend this idea to inverse
problems, where pretrained generative models are employed as priors. We propose
applying representation alignment (REPA) between diffusion or flow-based models
and a pretrained self-supervised visual encoder, such as DINOv2, to guide the
reconstruction process at inference time. Although ground-truth signals are
unavailable in inverse problems, we show that aligning model representations
with approximate target features can substantially enhance reconstruction
fidelity and perceptual realism. We provide theoretical results showing (a) the
relation between the REPA regularization and a divergence measure in the DINOv2
embedding space, and (b) how REPA updates steer the model's internal
representations toward those of the clean image. These results offer insights
into the role of REPA in improving perceptual fidelity. Finally, we demonstrate
the generality of our approach by integrating it into multiple state-of-the-art
inverse problem solvers. Extensive experiments on super-resolution, box
inpainting, Gaussian deblurring, and motion deblurring confirm that our method
consistently improves reconstruction quality across tasks, while also providing
substantial efficiency gains by reducing the number of required discretization
steps without compromising the performance of the underlying solver.
\\ ( https://arxiv.org/abs/2511.16870 ,  13900kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16887
Date: Fri, 21 Nov 2025 02:00:17 GMT   (42731kb)

Title: Glass Surface Detection: Leveraging Reflection Dynamics in
 Flash/No-flash Imagery
Authors: Tao Yan, Hao Huang, Yiwei Lu, Zeyu Wang, Ke Xu, Yinghui Wang, Xiaojun
 Chang, Rynson W.H. Lau
Categories: cs.CV
Comments: 13 pages, 12 figures
\\
 Glass surfaces are ubiquitous in daily life, typically appearing colorless,
transparent, and lacking distinctive features. These characteristics make glass
surface detection a challenging computer vision task. Existing glass surface
detection methods always rely on boundary cues (e.g., window and door frames)
or reflection cues to locate glass surfaces, but they fail to fully exploit the
intrinsic properties of the glass itself for accurate localization. We observed
that in most real-world scenes, the illumination intensity in front of the
glass surface differs from that behind it, which results in variations in the
reflections visible on the glass surface. Specifically, when standing on the
brighter side of the glass and applying a flash towards the darker side,
existing reflections on the glass surface tend to disappear. Conversely, while
standing on the darker side and applying a flash towards the brighter side,
distinct reflections will appear on the glass surface. Based on this
phenomenon, we propose NFGlassNet, a novel method for glass surface detection
that leverages the reflection dynamics present in flash/no-flash imagery.
Specifically, we propose a Reflection Contrast Mining Module (RCMM) for
extracting reflections, and a Reflection Guided Attention Module (RGAM) for
fusing features from reflection and glass surface for accurate glass surface
detection. For learning our network, we also construct a dataset consisting of
3.3K no-flash and flash image pairs captured from various scenes with
corresponding ground truth annotations. Extensive experiments demonstrate that
our method outperforms the state-of-the-art methods. Our code, model, and
dataset will be available upon acceptance of the manuscript.
\\ ( https://arxiv.org/abs/2511.16887 ,  42731kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16901
Date: Fri, 21 Nov 2025 02:30:26 GMT   (2356kb)

Title: R-AVST: Empowering Video-LLMs with Fine-Grained Spatio-Temporal
 Reasoning in Complex Audio-Visual Scenarios
Authors: Lu Zhu, Tiantian Geng, Yangye Chen, Teng Wang, Ping Lu, Feng Zheng
Categories: cs.CV
Comments: Accepted by AAAI 2026. Project page:
 https://github.com/zhlllau/R-AVST
\\
 Recently, rapid advancements have been made in multimodal large language
models (MLLMs), especially in video understanding tasks. However, current
research focuses on simple video scenarios, failing to reflect the complex and
diverse nature of real-world audio-visual events in videos. To bridge this gap,
we firstly introduce R-AVST, a dataset for audio-visual reasoning featuring
fine-grained spatio-temporal annotations. In constructing this, we design a
pipeline consisting of LLM-based key object extraction, automatic spatial
annotation and manual quality inspection, resulting in over 5K untrimmed videos
with 27K objects across 100 types of audio-visual events. Building on this
dataset, we define three core tasks for spatio-temporal reasoning in
audio-visual scenes and generate more than 8K high-quality, evenly distributed
question-answer pairs to effectively benchmark model performance. To further
enhance reasoning, we propose AVST-Zero, a reinforcement learning-based model
that avoids intermediate supervision, directly optimizing behavior via
carefully designed multi-dimensional rewards. Extensive experiments validate
the effectiveness of our R-AVST in advancing audio-visual spatio-temporal
reasoning, upon which AVST-Zero demonstrates competitive performance compared
to existing models. To the best of our knowledge, R-AVST is the first dataset
designed for real-world audio-visual spatio-temporal reasoning, and AVST-Zero
offers a novel perspective for tackling future challenges in this domain.
\\ ( https://arxiv.org/abs/2511.16901 ,  2356kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16904
Date: Fri, 21 Nov 2025 02:37:09 GMT   (2388kb)

Title: Warm Diffusion: Recipe for Blur-Noise Mixture Diffusion Models
Authors: Hao-Chien Hsueh, Chi-En Yen, Wen-Hsiao Peng, Ching-Chun Huang
Categories: cs.CV
\\
 Diffusion probabilistic models have achieved remarkable success in generative
tasks across diverse data types. While recent studies have explored alternative
degradation processes beyond Gaussian noise, this paper bridges two key
diffusion paradigms: hot diffusion, which relies entirely on noise, and cold
diffusion, which uses only blurring without noise. We argue that hot diffusion
fails to exploit the strong correlation between high-frequency image detail and
low-frequency structures, leading to random behaviors in the early steps of
generation. Conversely, while cold diffusion leverages image correlations for
prediction, it neglects the role of noise (randomness) in shaping the data
manifold, resulting in out-of-manifold issues and partially explaining its
performance drop. To integrate both strengths, we propose Warm Diffusion, a
unified Blur-Noise Mixture Diffusion Model (BNMD), to control blurring and
noise jointly. Our divide-and-conquer strategy exploits the spectral dependency
in images, simplifying score model estimation by disentangling the denoising
and deblurring processes. We further analyze the Blur-to-Noise Ratio (BNR)
using spectral analysis to investigate the trade-off between model learning
dynamics and changes in the data manifold. Extensive experiments across
benchmarks validate the effectiveness of our approach for image generation.
\\ ( https://arxiv.org/abs/2511.16904 ,  2388kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16908
Date: Fri, 21 Nov 2025 02:43:17 GMT   (3659kb)

Title: Q-REAL: Towards Realism and Plausibility Evaluation for AI-Generated
 Content
Authors: Shushi Wang, Zicheng Zhang, Chunyi Li, Wei Wang, Liya Ma, Fengjiao
 Chen, Xiaoyu Li, Xuezhi Cao, Guangtao Zhai, Xiaohong Liu
Categories: cs.CV
\\
 Quality assessment of AI-generated content is crucial for evaluating model
capability and guiding model optimization. However, most existing quality
assessment datasets and models provide only a single quality score, which is
too coarse to offer targeted guidance for improving generative models. In
current applications of AI-generated images, realism and plausibility are two
critical dimensions, and with the emergence of unified generation-understanding
models, fine-grained evaluation along these dimensions becomes especially
effective for improving generative performance. Therefore, we introduce Q-Real,
a novel dataset for fine-grained evaluation of realism and plausibility in
AI-generated images. Q-Real consists of 3,088 images generated by popular
text-to-image models. For each image, we annotate the locations of major
entities and provide a set of judgment questions and attribution descriptions
for these along the dimensions of realism and plausibility. Considering that
recent advances in multi-modal large language models (MLLMs) enable
fine-grained evaluation of AI-generated images, we construct Q-Real Bench to
evaluate them on two tasks: judgment and grounding with reasoning. Finally, to
enhance MLLM capabilities, we design a fine-tuning framework and conduct
experiments on multiple MLLMs using our dataset. Experimental results
demonstrate the high quality and significance of our dataset and the
comprehensiveness of the benchmark. Dataset and code will be released upon
publication.
\\ ( https://arxiv.org/abs/2511.16908 ,  3659kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16917
Date: Fri, 21 Nov 2025 03:02:10 GMT   (16851kb)

Title: UniModel: A Visual-Only Framework for Unified Multimodal Understanding
 and Generation
Authors: Chi Zhang, Jiepeng Wang, Youming Wang, Yuanzhi Liang, Xiaoyan Yang,
 Zuoxin Li, Haibin Huang, Xuelong Li
Categories: cs.CV
\\
 We present UniModel, a unified generative model that jointly supports visual
understanding and visual generation within a single pixel-to-pixel diffusion
framework. Our goal is to achieve unification along three axes: the model, the
tasks, and the representations. At the representation level, we eliminate
modality discrepancies by mapping both text and images into a shared visual
space: textual prompts are rendered as painted text images on a clean canvas,
and all inputs and outputs are treated purely as RGB pixels. This yields a
fully vision-native formulation of multimodal learning. At the task level, a
broad range of vision-language problems are cast as pixel-to-pixel
transformations in this visual space. For understanding tasks, the model takes
an RGB image and produces a painted text image that visually encodes the
semantic prediction. For generation tasks, painted text images serve as visual
conditions that guide realistic and semantically aligned image synthesis.
Captioning and text-to-image generation thus become different directions of the
same underlying visual translation process. At the model level, we instantiate
a single Unified Diffusion Transformer trained with rectified flow in pixel
space. A shared backbone jointly learns bidirectional mappings between natural
images and painted text images, with lightweight task embeddings to specify the
desired direction. Experiments on text-to-image synthesis and image-to-text
understanding demonstrate strong cross-modal alignment and emergent
controllability such as cycle-consistent image-caption-image loops. Our initial
exploration suggests that unifying model, tasks, and representations in a
single visual space is a promising paradigm for general-purpose multimodal
intelligence.
\\ ( https://arxiv.org/abs/2511.16917 ,  16851kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16920
Date: Fri, 21 Nov 2025 03:14:20 GMT   (1320kb)

Title: DeltaDeno: Zero-Shot Anomaly Generation via Delta-Denoising Attribution
Authors: Chaoran Xu, Chengkan Lv, Qiyu Chen, Yunkang Cao, Feng Zhang, Zhengtao
 Zhang
Categories: cs.CV
\\
 Anomaly generation is often framed as few-shot fine-tuning with anomalous
samples, which contradicts the scarcity that motivates generation and tends to
overfit category priors. We tackle the setting where no real anomaly samples or
training are available. We propose Delta-Denoising (DeltaDeno), a training-free
zero-shot anomaly generation method that localizes and edits defects by
contrasting two diffusion branches driven by a minimal prompt pair under a
shared schedule. By accumulating per-step denoising deltas into an
image-specific localization map, we obtain a mask to guide the latent
inpainting during later diffusion steps and preserve the surrounding context
while generating realistic local defects. To improve stability and control,
DeltaDeno performs token-level prompt refinement that aligns shared content and
strengthens anomaly tokens, and applies a spatial attention bias restricted to
anomaly tokens in the predicted region. Experiments on public datasets show
that DeltaDeno achieves great generation, realism and consistent gains in
downstream detection performance. Code will be made publicly available.
\\ ( https://arxiv.org/abs/2511.16920 ,  1320kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16928
Date: Fri, 21 Nov 2025 03:40:45 GMT   (3488kb)

Title: Rethinking Diffusion Model-Based Video Super-Resolution: Leveraging
 Dense Guidance from Aligned Features
Authors: Jingyi Xu, Meisong Zheng, Ying Chen, Minglang Qiao, Xin Deng, Mai Xu
Categories: cs.CV
Comments: 19pages
\\
 Diffusion model (DM) based Video Super-Resolution (VSR) approaches achieve
impressive perceptual quality. However, they suffer from error accumulation,
spatial artifacts, and a trade-off between perceptual quality and fidelity,
primarily caused by inaccurate alignment and insufficient compensation between
video frames. In this paper, within the DM-based VSR pipeline, we revisit the
role of alignment and compensation between adjacent video frames and reveal two
crucial observations: (a) the feature domain is better suited than the pixel
domain for information compensation due to its stronger spatial and temporal
correlations, and (b) warping at an upscaled resolution better preserves
high-frequency information, but this benefit is not necessarily monotonic.
Therefore, we propose a novel Densely Guided diffusion model with Aligned
Features for Video Super-Resolution (DGAF-VSR), with an Optical Guided Warping
Module (OGWM) to maintain high-frequency details in the aligned features and a
Feature-wise Temporal Condition Module (FTCM) to deliver dense guidance in the
feature domain. Extensive experiments on synthetic and real-world datasets
demonstrate that DGAF-VSR surpasses state-of-the-art methods in key aspects of
VSR, including perceptual quality (35.82\% DISTS reduction), fidelity (0.20 dB
PSNR gain), and temporal consistency (30.37\% tLPIPS reduction).
\\ ( https://arxiv.org/abs/2511.16928 ,  3488kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16936
Date: Fri, 21 Nov 2025 04:15:07 GMT   (1162kb)

Title: Shape-preserving Tooth Segmentation from CBCT Images Using Deep Learning
 with Semantic and Shape Awareness
Authors: Zongrui Ji, Zhiming Cui, Na Li, Qianhan Zheng, Miaojing Shi, Ke Deng,
 Jingyang Zhang, Chaoyuan Li, Xuepeng Chen, Yi Dong, Lei Ma
Categories: cs.CV
\\
 Background:Accurate tooth segmentation from cone beam computed tomography
(CBCT) images is crucial for digital dentistry but remains challenging in cases
of interdental adhesions, which cause severe anatomical shape distortion.
 Methods:
 To address this, we propose a deep learning framework that integrates
semantic and shape awareness for shape-preserving segmentation. Our method
introduces a target-tooth-centroid prompted multi-label learning strategy to
model semantic relationships between teeth, reducing shape ambiguity.
Additionally, a tooth-shape-aware learning mechanism explicitly enforces
morphological constraints to preserve boundary integrity. These components are
unified via multi-task learning, jointly optimizing segmentation and shape
preservation.
 Results: Extensive evaluations on internal and external datasets demonstrate
that our approach significantly outperforms existing methods.
 Conclusions: Our approach effectively mitigates shape distortions and
providing anatomically faithful tooth boundaries.
\\ ( https://arxiv.org/abs/2511.16936 ,  1162kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16937
Date: Fri, 21 Nov 2025 04:23:04 GMT   (10765kb)

Title: OmniGround: A Comprehensive Spatio-Temporal Grounding Benchmark for
 Real-World Complex Scenarios
Authors: Hong Gao, Jingyu Wu, Xiangkai Xu, Kangni Xie, Yunchen Zhang, Bin
 Zhong, Xurui Gao, Min-Ling Zhang
Categories: cs.CV cs.AI
Comments: 20 pages
\\
 Spatio-Temporal Video Grounding (STVG) aims to localize target objects in
videos based on natural language descriptions. Despite recent advances in
Multimodal Large Language Models, a significant gap remains between current
models and real-world demands involving diverse objects and complex queries. We
attribute this to limited benchmark scope, causing models to exhibit category
bias, oversimplified reasoning, and poor linguistic robustness. To address
these limitations, we introduce OmniGround, a comprehensive benchmark with
3,475 videos spanning 81 categories and complex real-world queries. We propose
the Forward-Backward-Refinement annotation pipeline that combines
multi-directional tracking with intelligent error correction for high-quality
labels. We further introduce DeepSTG, a systematic evaluation framework
quantifying dataset quality across four complementary dimensions beyond
superficial statistics. Evaluations reveal performance average drop of 10.4% on
complex real-world scenes, particularly with small/occluded objects and
intricate spatial relations. Motivated by these, we propose PG-TAF, a
training-free two-stage framework decomposing STVG into high-level temporal
grounding and fine-grained spatio-temporal propagation. Experiments demonstrate
PG-TAF achieves 25.6% and 35.6% improvements in m\_tIoU and m\_vIoU on
OmniGround with consistent gains across four benchmarks.
\\ ( https://arxiv.org/abs/2511.16937 ,  10765kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16940
Date: Fri, 21 Nov 2025 04:33:11 GMT   (7915kb)

Title: MultiPriv: Benchmarking Individual-Level Privacy Reasoning in
 Vision-Language Models
Authors: Xiongtao Sun, Hui Li, Jiaming Zhang, Yujie Yang, Kaili Liu, Ruxin
 Feng, Wen Jun Tan, Wei Yang Bryan Lim
Categories: cs.CV cs.CR
\\
 Modern Vision-Language Models (VLMs) demonstrate sophisticated reasoning,
escalating privacy risks beyond simple attribute perception to individual-level
linkage. Current privacy benchmarks are structurally insufficient for this new
threat, as they primarily evaluate privacy perception while failing to address
the more critical risk of privacy reasoning: a VLM's ability to infer and link
distributed information to construct individual profiles. To address this
critical gap, we propose \textbf{MultiPriv}, the first benchmark designed to
systematically evaluate individual-level privacy reasoning in VLMs. We
introduce the \textbf{Privacy Perception and Reasoning (PPR)} framework and
construct a novel, bilingual multimodal dataset to support it. The dataset
uniquely features a core component of synthetic individual profiles where
identifiers (e.g., faces, names) are meticulously linked to sensitive
attributes. This design enables nine challenging tasks evaluating the full PPR
spectrum, from attribute detection to cross-image re-identification and chained
inference. We conduct a large-scale evaluation of over 50 foundational and
commercial VLMs. Our analysis reveals: (1) Many VLMs possess significant,
unmeasured reasoning-based privacy risks. (2) Perception-level metrics are poor
predictors of these reasoning risks, revealing a critical evaluation gap. (3)
Existing safety alignments are inconsistent and ineffective against such
reasoning-based attacks. MultiPriv exposes systemic vulnerabilities and
provides the necessary framework for developing robust, privacy-preserving
VLMs.
\\ ( https://arxiv.org/abs/2511.16940 ,  7915kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16948
Date: Fri, 21 Nov 2025 04:51:23 GMT   (6110kb)

Title: Flow-Guided Implicit Neural Representation for Motion-Aware Dynamic MRI
 Reconstruction
Authors: Baoqing Li, Yuanyuan Liu, Congcong Liu, Qingyong Zhu, Jing Cheng,
 Yihang Zhou, Hao Chen, Zhuo-Xu Cui, Dong Liang
Categories: cs.CV
Comments: 10 pages, 7 figures
\\
 Dynamic magnetic resonance imaging (dMRI) captures temporally-resolved
anatomy but is often challenged by limited sampling and motion-induced
artifacts. Conventional motion-compensated reconstructions typically rely on
pre-estimated optical flow, which is inaccurate under undersampling and
degrades reconstruction quality. In this work, we propose a novel implicit
neural representation (INR) framework that jointly models both the dynamic
image sequence and its underlying motion field. Specifically, one INR is
employed to parameterize the spatiotemporal image content, while another INR
represents the optical flow. The two are coupled via the optical flow equation,
which serves as a physics-inspired regularization, in addition to a data
consistency loss that enforces agreement with k-space measurements. This joint
optimization enables simultaneous recovery of temporally coherent images and
motion fields without requiring prior flow estimation. Experiments on dynamic
cardiac MRI datasets demonstrate that the proposed method outperforms
state-of-the-art motion-compensated and deep learning approaches, achieving
superior reconstruction quality, accurate motion estimation, and improved
temporal fidelity. These results highlight the potential of implicit joint
modeling with flow-regularized constraints for advancing dMRI reconstruction.
\\ ( https://arxiv.org/abs/2511.16948 ,  6110kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16951
Date: Fri, 21 Nov 2025 04:59:01 GMT   (2504kb)

Title: FingerCap: Fine-grained Finger-level Hand Motion Captioning
Authors: Xin Shen, Rui Zhu, Lei Shen, Xinyu Wang, Kaihao Zhang, Tianqing Zhu,
 Shuchen Wu, Chenxi Miao, Weikang Li, Yang Li, Deguo Xia, Jizhou Huang, Xin Yu
Categories: cs.CV
\\
 Understanding fine-grained human hand motion is fundamental to visual
perception, embodied intelligence, and multimodal communication. In this work,
we propose Fine-grained Finger-level Hand Motion Captioning (FingerCap), which
aims to generate textual descriptions that capture detailed finger-level
semantics of hand actions. To support this task, we curate FingerCap-40K, a
large-scale corpus of 40K paired hand-motion videos and captions spanning two
complementary sources: concise instruction-style finger motions and diverse,
naturalistic hand-object interactions. To enable effective evaluation, we
employ HandJudge, a LLM-based rubric that measures finger-level correctness and
motion completeness. Temporal sparsity remains a fundamental bottleneck for
current Video-MLLMs, since sparse RGB sampling is insufficient to capture the
subtle, high-frequency dynamics underlying fine finger motions. As a simple and
compute-friendly remedy, we introduce FiGOP (Finger Group-of-Pictures), which
pairs each RGB keyframe with subsequent hand keypoints until the next keyframe.
A lightweight temporal encoder converts the keypoints into motion embeddings
and integrates them with RGB features. FiGOP adapts the classic GOP concept to
finger motion, recovering fine temporal cues without increasing RGB density.
Experiments on FingerCap-40K show that strong open- and closed-source
Video-MLLMs still struggle with finger-level reasoning, while our
FiGOP-augmented model yield consistent gains under HandJudge and human studies.
\\ ( https://arxiv.org/abs/2511.16951 ,  2504kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16952
Date: Fri, 21 Nov 2025 04:59:54 GMT   (2266kb)

Title: Point-Supervised Facial Expression Spotting with Gaussian-Based
 Instance-Adaptive Intensity Modeling
Authors: Yicheng Deng, Hideaki Hayashi, Hajime Nagahara
Categories: cs.CV
\\
 Automatic facial expression spotting, which aims to identify facial
expression instances in untrimmed videos, is crucial for facial expression
analysis. Existing methods primarily focus on fully-supervised learning and
rely on costly, time-consuming temporal boundary annotations. In this paper, we
investigate point-supervised facial expression spotting (P-FES), where only a
single timestamp annotation per instance is required for training. We propose a
unique two-branch framework for P-FES. First, to mitigate the limitation of
hard pseudo-labeling, which often confuses neutral and expression frames with
various intensities, we propose a Gaussian-based instance-adaptive intensity
modeling (GIM) module to model instance-level expression intensity distribution
for soft pseudo-labeling. By detecting the pseudo-apex frame around each point
label, estimating the duration, and constructing an instance-level Gaussian
distribution, GIM assigns soft pseudo-labels to expression frames for more
reliable intensity supervision. The GIM module is incorporated into our
framework to optimize the class-agnostic expression intensity branch. Second,
we design a class-aware apex classification branch that distinguishes macro-
and micro-expressions solely based on their pseudo-apex frames. During
inference, the two branches work independently: the class-agnostic expression
intensity branch generates expression proposals, while the class-aware
apex-classification branch is responsible for macro- and micro-expression
classification.Furthermore, we introduce an intensity-aware contrastive loss to
enhance discriminative feature learning and suppress neutral noise by
contrasting neutral frames with expression frames with various intensities.
Extensive experiments on the SAMM-LV, CAS(ME)$^2$, and CAS(ME)$^3$ datasets
demonstrate the effectiveness of our proposed framework.
\\ ( https://arxiv.org/abs/2511.16952 ,  2266kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16955
Date: Fri, 21 Nov 2025 05:02:47 GMT   (12487kb)

Title: Neighbor GRPO: Contrastive ODE Policy Optimization Aligns Flow Models
Authors: Dailan He, Guanlin Feng, Xingtong Ge, Yazhe Niu, Yi Zhang, Bingqi Ma,
 Guanglu Song, Yu Liu, Hongsheng Li
Categories: cs.CV cs.LG eess.IV
\\
 Group Relative Policy Optimization (GRPO) has shown promise in aligning image
and video generative models with human preferences. However, applying it to
modern flow matching models is challenging because of its deterministic
sampling paradigm. Current methods address this issue by converting Ordinary
Differential Equations (ODEs) to Stochastic Differential Equations (SDEs),
which introduce stochasticity. However, this SDE-based GRPO suffers from issues
of inefficient credit assignment and incompatibility with high-order solvers
for fewer-step sampling. In this paper, we first reinterpret existing SDE-based
GRPO methods from a distance optimization perspective, revealing their
underlying mechanism as a form of contrastive learning. Based on this insight,
we propose Neighbor GRPO, a novel alignment algorithm that completely bypasses
the need for SDEs. Neighbor GRPO generates a diverse set of candidate
trajectories by perturbing the initial noise conditions of the ODE and
optimizes the model using a softmax distance-based surrogate leaping policy. We
establish a theoretical connection between this distance-based objective and
policy gradient optimization, rigorously integrating our approach into the GRPO
framework. Our method fully preserves the advantages of deterministic ODE
sampling, including efficiency and compatibility with high-order solvers. We
further introduce symmetric anchor sampling for computational efficiency and
group-wise quasi-norm reweighting to address reward flattening. Extensive
experiments demonstrate that Neighbor GRPO significantly outperforms SDE-based
counterparts in terms of training cost, convergence speed, and generation
quality.
\\ ( https://arxiv.org/abs/2511.16955 ,  12487kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16957
Date: Fri, 21 Nov 2025 05:16:26 GMT   (14738kb)

Title: MatPedia: A Universal Generative Foundation for High-Fidelity Material
 Synthesis
Authors: Di Luo, Shuhui Yang, Mingxin Yang, Jiawei Lu, Yixuan Tang, Xintong
 Han, Zhuo Chen, Beibei Wang, Chunchao Guo
Categories: cs.CV
\\
 Physically-based rendering (PBR) materials are fundamental to photorealistic
graphics, yet their creation remains labor-intensive and requires specialized
expertise. While generative models have advanced material synthesis, existing
methods lack a unified representation bridging natural image appearance and PBR
properties, leading to fragmented task-specific pipelines and inability to
leverage large-scale RGB image data. We present MatPedia, a foundation model
built upon a novel joint RGB-PBR representation that compactly encodes
materials into two interdependent latents: one for RGB appearance and one for
the four PBR maps encoding complementary physical properties. By formulating
them as a 5-frame sequence and employing video diffusion architectures,
MatPedia naturally captures their correlations while transferring visual priors
from RGB generation models. This joint representation enables a unified
framework handling multiple material tasks--text-to-material generation,
image-to-material generation, and intrinsic decomposition--within a single
architecture. Trained on MatHybrid-410K, a mixed corpus combining PBR datasets
with large-scale RGB images, MatPedia achieves native $1024\times1024$
synthesis that substantially surpasses existing approaches in both quality and
diversity.
\\ ( https://arxiv.org/abs/2511.16957 ,  14738kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16963
Date: Fri, 21 Nov 2025 05:35:23 GMT   (2380kb)

Title: Two Heads Better than One: Dual Degradation Representation for Blind
 Super-Resolution
Authors: Hsuan Yuan, Shao-Yu Weng, I-Hsuan Lo, Wei-Chen Chiu, Yu-Syuan Xu,
 Hao-Chien Hsueh, Jen-Hui Chuang, Ching-Chun Huang
Categories: cs.CV
\\
 Previous methods have demonstrated remarkable performance in single image
super-resolution (SISR) tasks with known and fixed degradation (e.g., bicubic
downsampling). However, when the actual degradation deviates from these
assumptions, these methods may experience significant declines in performance.
In this paper, we propose a Dual Branch Degradation Extractor Network to
address the blind SR problem. While some blind SR methods assume noise-free
degradation and others do not explicitly consider the presence of noise in the
degradation model, our approach predicts two unsupervised degradation
embeddings that represent blurry and noisy information. The SR network can then
be adapted to blur embedding and noise embedding in distinct ways. Furthermore,
we treat the degradation extractor as a regularizer to capitalize on
differences between SR and HR images. Extensive experiments on several
benchmarks demonstrate our method achieves SOTA performance in the blind SR
problem.
\\ ( https://arxiv.org/abs/2511.16963 ,  2380kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16965
Date: Fri, 21 Nov 2025 05:38:15 GMT   (8476kb)

Title: Real-Time Cooked Food Image Synthesis and Visual Cooking Progress
 Monitoring on Edge Devices
Authors: Jigyasa Gupta, Soumya Goyal, Anil Kumar, Ishan Jindal
Categories: cs.CV cs.LG
Comments: 13 pages, 11 figures
\\
 Synthesizing realistic cooked food images from raw inputs on edge devices is
a challenging generative task, requiring models to capture complex changes in
texture, color and structure during cooking. Existing image-to-image generation
methods often produce unrealistic results or are too resource-intensive for
edge deployment. We introduce the first oven-based cooking-progression dataset
with chef-annotated doneness levels and propose an edge-efficient recipe and
cooking state guided generator that synthesizes realistic food images
conditioned on raw food image. This formulation enables user-preferred visual
targets rather than fixed presets. To ensure temporal consistency and culinary
plausibility, we introduce a domain-specific \textit{Culinary Image Similarity
(CIS)} metric, which serves both as a training loss and a progress-monitoring
signal. Our model outperforms existing baselines with significant reductions in
FID scores (30\% improvement on our dataset; 60\% on public datasets)
\\ ( https://arxiv.org/abs/2511.16965 ,  8476kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16979
Date: Fri, 21 Nov 2025 06:19:19 GMT   (1465kb)

Title: The Finer the Better: Towards Granular-aware Open-set Domain
 Generalization
Authors: Yunyun Wang, Zheng Duan, Xinyue Liao, Ke-Jia Chen, Songcan Chen
Categories: cs.CV cs.AI
Comments: 9 pages,3 figures,aaai2026
\\
 Open-Set Domain Generalization (OSDG) tackles the realistic scenario where
deployed models encounter both domain shifts and novel object categories.
Despite impressive progress with vision-language models like CLIP, existing
methods still fall into the dilemma between structural risk of known-classes
and open-space risk from unknown-classes, and easily suffers from
over-confidence, especially when distinguishing ``hard unknowns" that share
fine-grained visual similarities with known classes. To this end, we propose a
Semantic-enhanced CLIP (SeeCLIP) framework that explicitly addresses this
dilemma through fine-grained semantic enhancement. In SeeCLIP, we propose a
semantic-aware prompt enhancement module to decompose images into
discriminative semantic tokens, enabling nuanced vision-language alignment
beyond coarse category labels. To position unknown prompts effectively, we
introduce duplex contrastive learning with complementary objectives, that is,
repulsion to maintain separability from known classes, and cohesion to preserve
semantic proximity. Further, our semantic-guided diffusion module synthesizes
pseudo-unknowns by perturbing extracted semantic tokens, generating challenging
samples that are visually similar to known classes yet exhibit key local
differences. These hard negatives force the model to learn finer decision
boundaries. Extensive experiments across five benchmarks demonstrate consistent
improvements of 3% accuracy and 5% H-score over state-of-the-art methods.
\\ ( https://arxiv.org/abs/2511.16979 ,  1465kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16980
Date: Fri, 21 Nov 2025 06:27:46 GMT   (7417kb)

Title: Gradient-Driven Natural Selection for Compact 3D Gaussian Splatting
Authors: Xiaobin Deng, Qiuli Yu, Changyu Diao, Min Li, Duanqing Xu
Categories: cs.CV
\\
 3DGS employs a large number of Gaussian primitives to fit scenes, resulting
in substantial storage and computational overhead. Existing pruning methods
rely on manually designed criteria or introduce additional learnable
parameters, yielding suboptimal results. To address this, we propose an natural
selection inspired pruning framework that models survival pressure as a
regularization gradient field applied to opacity, allowing the optimization
gradients--driven by the goal of maximizing rendering quality--to autonomously
determine which Gaussians to retain or prune. This process is fully learnable
and requires no human intervention. We further introduce an opacity decay
technique with a finite opacity prior, which accelerates the selection process
without compromising pruning effectiveness. Compared to 3DGS, our method
achieves over 0.6 dB PSNR gain under 15\% budgets, establishing
state-of-the-art performance for compact 3DGS. Project page
https://xiaobin2001.github.io/GNS-web.
\\ ( https://arxiv.org/abs/2511.16980 ,  7417kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16982
Date: Fri, 21 Nov 2025 06:29:52 GMT   (2178kb)

Title: A Diversity-optimized Deep Ensemble Approach for Accurate Plant Leaf
 Disease Detection
Authors: Sai Nath Chowdary Medikonduru, Hongpeng Jin, Yanzhao Wu
Categories: cs.CV cs.LG
\\
 Plant diseases pose a significant threat to global agriculture, causing over
$220 billion in annual economic losses and jeopardizing food security. The
timely and accurate detection of these diseases from plant leaf images is
critical to mitigating their adverse effects. Deep neural network Ensembles
(Deep Ensembles) have emerged as a powerful approach to enhancing prediction
accuracy by leveraging the strengths of diverse Deep Neural Networks (DNNs).
However, selecting high-performing ensemble member models is challenging due to
the inherent difficulty in measuring ensemble diversity. In this paper, we
introduce the Synergistic Diversity (SQ) framework to enhance plant disease
detection accuracy. First, we conduct a comprehensive analysis of the
limitations of existing ensemble diversity metrics (denoted as Q metrics),
which often fail to identify optimal ensemble teams. Second, we present the SQ
metric, a novel measure that captures the synergy between ensemble members and
consistently aligns with ensemble accuracy. Third, we validate our SQ approach
through extensive experiments on a plant leaf image dataset, which demonstrates
that our SQ metric substantially improves ensemble selection and enhances
detection accuracy. Our findings pave the way for a more reliable and efficient
image-based plant disease detection.
\\ ( https://arxiv.org/abs/2511.16982 ,  2178kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16986
Date: Fri, 21 Nov 2025 06:45:46 GMT   (3414kb)

Title: RadioKMoE: Knowledge-Guided Radiomap Estimation with Kolmogorov-Arnold
 Networks and Mixture-of-Experts
Authors: Fupei Guo, Kerry Pan, Songyang Zhang, Yue Wang, Zhi Ding
Categories: cs.CV
\\
 Radiomap serves as a vital tool for wireless network management and
deployment by providing powerful spatial knowledge of signal propagation and
coverage. However, increasingly complex radio propagation behavior and
surrounding environments pose strong challenges for radiomap estimation (RME).
In this work, we propose a knowledge-guided RME framework that integrates
Kolmogorov-Arnold Networks (KAN) with Mixture-of-Experts (MoE), namely
RadioKMoE. Specifically, we design a KAN module to predict an initial coarse
coverage map, leveraging KAN's strength in approximating physics models and
global radio propagation patterns. The initial coarse map, together with
environmental information, drives our MoE network for precise radiomap
estimation. Unlike conventional deep learning models, the MoE module comprises
expert networks specializing in distinct radiomap patterns to improve local
details while preserving global consistency. Experimental results in both
multi- and single-band RME demonstrate the enhanced accuracy and robustness of
the proposed RadioKMoE in radiomap estimation.
\\ ( https://arxiv.org/abs/2511.16986 ,  3414kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16991
Date: Fri, 21 Nov 2025 06:57:33 GMT   (850kb)

Title: DReX: Pure Vision Fusion of Self-Supervised and Convolutional
 Representations for Image Complexity Prediction
Authors: Jonathan Skaza, Parsa Madinei, Ziqi Wen, Miguel Eckstein
Categories: cs.CV
Comments: 8 pages
\\
 Visual complexity prediction is a fundamental problem in computer vision with
applications in image compression, retrieval, and classification. Understanding
what makes humans perceive an image as complex is also a long-standing question
in cognitive science. Recent approaches have leveraged multimodal models that
combine visual and linguistic representations, but it remains unclear whether
language information is necessary for this task. We propose DReX (DINO-ResNet
Fusion), a vision-only model that fuses self-supervised and convolutional
representations through a learnable attention mechanism to predict image
complexity. Our architecture integrates multi-scale hierarchical features from
ResNet-50 with semantically rich representations from DINOv3 ViT-S/16, enabling
the model to capture both low-level texture patterns and high-level semantic
structure. DReX achieves state-of-the-art performance on the IC9600 benchmark
(Pearson r = 0.9581), surpassing previous methods--including those trained on
multimodal image-text data--while using approximately 21.5x fewer learnable
parameters. Furthermore, DReX generalizes robustly across multiple datasets and
metrics, achieving superior results on Pearson and Spearman correlation, Root
Mean Square Error (RMSE), and Mean Absolute Error (MAE). Ablation and attention
analyses confirm that DReX leverages complementary cues from both backbones,
with the DINOv3 [CLS] token enhancing sensitivity to visual complexity. Our
findings suggest that visual features alone can be sufficient for human-aligned
complexity prediction and that, when properly fused, self-supervised
transformers and supervised deep convolutional neural networks offer
complementary and synergistic benefits for this task.
\\ ( https://arxiv.org/abs/2511.16991 ,  850kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16993
Date: Fri, 21 Nov 2025 06:59:54 GMT   (12595kb,A)

Title: DepthFocus: Controllable Depth Estimation for See-Through Scenes
Authors: Junhong Min, Jimin Kim, Cheol-Hui Min, Minwook Kim, Youngpil Jeon,
 Minyong Choi
Categories: cs.CV
Comments: 8pages, 6 figures, 5 tables
\\
 Depth in the real world is rarely singular. Transmissive materials create
layered ambiguities that confound conventional perception systems. Existing
models remain passive, attempting to estimate static depth maps anchored to the
nearest surface, while humans actively shift focus to perceive a desired depth.
We introduce DepthFocus, a steerable Vision Transformer that redefines stereo
depth estimation as intent-driven control. Conditioned on a scalar depth
preference, the model dynamically adapts its computation to focus on the
intended depth, enabling selective perception within complex scenes. The
training primarily leverages our newly constructed 500k multi-layered synthetic
dataset, designed to capture diverse see-through effects. DepthFocus not only
achieves state-of-the-art performance on conventional single-depth benchmarks
like BOOSTER, a dataset notably rich in transparent and reflective objects, but
also quantitatively demonstrates intent-aligned estimation on our newly
proposed real and synthetic multi-depth datasets. Moreover, it exhibits strong
generalization capabilities on unseen see-through scenes, underscoring its
robustness as a significant step toward active and human-like 3D perception.
\\ ( https://arxiv.org/abs/2511.16993 ,  12595kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16998
Date: Fri, 21 Nov 2025 07:06:48 GMT   (2807kb)

Title: VLM-Augmented Degradation Modeling for Image Restoration Under Adverse
 Weather Conditions
Authors: Qianyi Shao, Yuanfan Zhang, Renxiang Xiao, and Liang Hu
Categories: cs.CV
Journal-ref: Proc. 2025 30th International Conference on Automation and
 Computing (ICAC), pp. 1-6, 2025
DOI: 10.1109/ICAC65379.2025.11196306
\\
 Reliable visual perception under adverse weather conditions, such as rain,
haze, snow, or a mixture of them, is desirable yet challenging for autonomous
driving and outdoor robots. In this paper, we propose a unified Memory-Enhanced
Visual-Language Recovery (MVLR) model that restores images from different
degradation levels under various weather conditions. MVLR couples a lightweight
encoder-decoder backbone with a Visual-Language Model (VLM) and an Implicit
Memory Bank (IMB). The VLM performs chain-of-thought inference to encode
weather degradation priors and the IMB stores continuous latent representations
of degradation patterns. The VLM-generated priors query the IMB to retrieve
fine-grained degradation prototypes. These prototypes are then adaptively fused
with multi-scale visual features via dynamic cross-attention mechanisms,
enhancing restoration accuracy while maintaining computational efficiency.
Extensive experiments on four severe-weather benchmarks show that MVLR
surpasses single-branch and Mixture-of-Experts baselines in terms of Peak
Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM).
These results indicate that MVLR offers a practical balance between model
compactness and expressiveness for real-time deployment in diverse outdoor
conditions.
\\ ( https://arxiv.org/abs/2511.16998 ,  2807kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17004
Date: Fri, 21 Nov 2025 07:14:46 GMT   (30142kb)

Title: Vision Language Models are Confused Tourists
Authors: Patrick Amadeus Irawan, Ikhlasul Akmal Hanif, Muhammad Dehan Al
 Kautsar, Genta Indra Winata, Fajri Koto, Alham Fikri Aji
Categories: cs.CV cs.CL
\\
 Although the cultural dimension has been one of the key aspects in evaluating
Vision-Language Models (VLMs), their ability to remain stable across diverse
cultural inputs remains largely untested, despite being crucial to support
diversity and multicultural societies. Existing evaluations often rely on
benchmarks featuring only a singular cultural concept per image, overlooking
scenarios where multiple, potentially unrelated cultural cues coexist. To
address this gap, we introduce ConfusedTourist, a novel cultural adversarial
robustness suite designed to assess VLMs' stability against perturbed
geographical cues. Our experiments reveal a critical vulnerability, where
accuracy drops heavily under simple image-stacking perturbations and even
worsens with its image-generation-based variant. Interpretability analyses
further show that these failures stem from systematic attention shifts toward
distracting cues, diverting the model from its intended focus. These findings
highlight a critical challenge: visual cultural concept mixing can
substantially impair even state-of-the-art VLMs, underscoring the urgent need
for more culturally robust multimodal understanding.
\\ ( https://arxiv.org/abs/2511.17004 ,  30142kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17005
Date: Fri, 21 Nov 2025 07:18:37 GMT   (2691kb)

Title: FLUID: Training-Free Face De-identification via Latent Identity
 Substitution
Authors: Jinhyeong Park, Shaheryar Muhammad, Seangmin Lee, Jong Taek Lee, and
 Soon Ki Jung
Categories: cs.CV cs.AI
\\
 We present FLUID (Face de-identification in the Latent space via
Utility-preserving Identity Displacement), a training-free framework that
directly substitutes identity in the latent space of pretrained diffusion
models. Inspired by substitution mechanisms in chemistry, we reinterpret
identity editing as semantic displacement in the latent h-space of a pretrained
unconditional diffusion model. Our framework discovers identity-editing
directions through optimization guided by novel reagent losses, which supervise
for attribute preservation and identity suppression. We further propose both
linear and geodesic (tangent-based) editing schemes to effectively navigate the
latent manifold. Experimental results on CelebA-HQ and FFHQ demonstrate that
FLUID achieves a superior trade-off between identity suppression and attribute
preservation, outperforming state-of-the-art de-identification methods in both
qualitative and quantitative metrics.
\\ ( https://arxiv.org/abs/2511.17005 ,  2691kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17014
Date: Fri, 21 Nov 2025 07:32:05 GMT   (38160kb)

Title: Parameter-Free Neural Lens Blur Rendering for High-Fidelity Composites
Authors: Lingyan Ruan, Bin Chen, Taehyun Rhee
Categories: cs.CV cs.AI cs.GR eess.IV
Comments: Accepted by ISMAR 2025 with oral presentation. 10 pages, 11 figures
\\
 Consistent and natural camera lens blur is important for seamlessly blending
3D virtual objects into photographed real-scenes. Since lens blur typically
varies with scene depth, the placement of virtual objects and their
corresponding blur levels significantly affect the visual fidelity of mixed
reality compositions. Existing pipelines often rely on camera parameters (e.g.,
focal length, focus distance, aperture size) and scene depth to compute the
circle of confusion (CoC) for realistic lens blur rendering. However, such
information is often unavailable to ordinary users, limiting the accessibility
and generalizability of these methods. In this work, we propose a novel
compositing approach that directly estimates the CoC map from RGB images,
bypassing the need for scene depth or camera metadata. The CoC values for
virtual objects are inferred through a linear relationship between its signed
CoC map and depth, and realistic lens blur is rendered using a neural
reblurring network. Our method provides flexible and practical solution for
real-world applications. Experimental results demonstrate that our method
achieves high-fidelity compositing with realistic defocus effects,
outperforming state-of-the-art techniques in both qualitative and quantitative
evaluations.
\\ ( https://arxiv.org/abs/2511.17014 ,  38160kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17045
Date: Fri, 21 Nov 2025 08:44:33 GMT   (7742kb)

Title: RacketVision: A Multiple Racket Sports Benchmark for Unified Ball and
 Racket Analysis
Authors: Linfeng Dong, Yuchen Yang, Hao Wu, Wei Wang, Yuenan HouZhihang Zhong,
 Xiao Sun
Categories: cs.CV cs.AI cs.MM
Comments: Accepted to AAAI 2026 (Oral)
\\
 We introduce RacketVision, a novel dataset and benchmark for advancing
computer vision in sports analytics, covering table tennis, tennis, and
badminton. The dataset is the first to provide large-scale, fine-grained
annotations for racket pose alongside traditional ball positions, enabling
research into complex human-object interactions. It is designed to tackle three
interconnected tasks: fine-grained ball tracking, articulated racket pose
estimation, and predictive ball trajectory forecasting. Our evaluation of
established baselines reveals a critical insight for multi-modal fusion: while
naively concatenating racket pose features degrades performance, a
CrossAttention mechanism is essential to unlock their value, leading to
trajectory prediction results that surpass strong unimodal baselines.
RacketVision provides a versatile resource and a strong starting point for
future research in dynamic object tracking, conditional motion forecasting, and
multimodal analysis in sports. Project page at
https://github.com/OrcustD/RacketVision
\\ ( https://arxiv.org/abs/2511.17045 ,  7742kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17048
Date: Fri, 21 Nov 2025 08:47:32 GMT   (19019kb)

Title: RoomPlanner: Explicit Layout Planner for Easier LLM-Driven 3D Room
 Generation
Authors: Wenzhuo Sun, Mingjian Liang, Wenxuan Song, Xuelian Cheng, Zongyuan Ge
Categories: cs.CV
\\
 In this paper, we propose RoomPlanner, the first fully automatic 3D room
generation framework for painlessly creating realistic indoor scenes with only
short text as input. Without any manual layout design or panoramic image
guidance, our framework can generate explicit layout criteria for rational
spatial placement. We begin by introducing a hierarchical structure of
language-driven agent planners that can automatically parse short and ambiguous
prompts into detailed scene descriptions. These descriptions include raw
spatial and semantic attributes for each object and the background, which are
then used to initialize 3D point clouds. To position objects within bounded
environments, we implement two arrangement constraints that iteratively
optimize spatial arrangements, ensuring a collision-free and accessible layout
solution. In the final rendering stage, we propose a novel AnyReach Sampling
strategy for camera trajectory, along with the Interval Timestep Flow Sampling
(ITFS) strategy, to efficiently optimize the coarse 3D Gaussian scene
representation. These approaches help reduce the total generation time to under
30 minutes. Extensive experiments demonstrate that our method can produce
geometrically rational 3D indoor scenes, surpassing prior approaches in both
rendering speed and visual quality while preserving editability. The code will
be available soon.
\\ ( https://arxiv.org/abs/2511.17048 ,  19019kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17052
Date: Fri, 21 Nov 2025 08:50:14 GMT   (3062kb)

Title: PathAgent: Toward Interpretable Analysis of Whole-slide Pathology Images
 via Large Language Model-based Agentic Reasoning
Authors: Jingyun Chen, Linghan Cai, Zhikang Wang, Yi Huang, Songhan Jiang,
 Shenjin Huang, Hongpeng Wang and Yongbing Zhang
Categories: cs.CV
Comments: 11 pages, 6 figures
\\
 Analyzing whole-slide images (WSIs) requires an iterative, evidence-driven
reasoning process that parallels how pathologists dynamically zoom, refocus,
and self-correct while collecting the evidence. However, existing computational
pipelines often lack this explicit reasoning trajectory, resulting in
inherently opaque and unjustifiable predictions. To bridge this gap, we present
PathAgent, a training-free, large language model (LLM)-based agent framework
that emulates the reflective, stepwise analytical approach of human experts.
PathAgent can autonomously explore WSI, iteratively and precisely locating
significant micro-regions using the Navigator module, extracting morphology
visual cues using the Perceptor, and integrating these findings into the
continuously evolving natural language trajectories in the Executor. The entire
sequence of observations and decisions forms an explicit chain-of-thought,
yielding fully interpretable predictions. Evaluated across five challenging
datasets, PathAgent exhibits strong zero-shot generalization, surpassing
task-specific baselines in both open-ended and constrained visual
question-answering tasks. Moreover, a collaborative evaluation with human
pathologists confirms PathAgent's promise as a transparent and clinically
grounded diagnostic assistant.
\\ ( https://arxiv.org/abs/2511.17052 ,  3062kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17053
Date: Fri, 21 Nov 2025 08:54:49 GMT   (1239kb)

Title: OmniPT: Unleashing the Potential of Large Vision Language Models for
 Pedestrian Tracking and Understanding
Authors: Teng Fu, Mengyang Zhao, Ke Niu, Kaixin Peng, Bin Li
Categories: cs.CV cs.AI
Comments: AAAI 2026
\\
 LVLMs have been shown to perform excellently in image-level tasks such as VQA
and caption. However, in many instance-level tasks, such as visual grounding
and object detection, LVLMs still show performance gaps compared to previous
expert models. Meanwhile, although pedestrian tracking is a classical task,
there have been a number of new topics in combining object tracking and natural
language, such as Referring MOT, Cross-view Referring MOT, and Semantic MOT.
These tasks emphasize that models should understand the tracked object at an
advanced semantic level, which is exactly where LVLMs excel. In this paper, we
propose a new unified Pedestrian Tracking framework, namely OmniPT, which can
track, track based on reference and generate semantic understanding of tracked
objects interactively. We address two issues: how to model the tracking task
into a task that foundation models can perform, and how to make the model
output formatted answers. To this end, we implement a training phase consisting
of RL-Mid Training-SFT-RL. Based on the pre-trained weights of the LVLM, we
first perform a simple RL phase to enable the model to output fixed and
supervisable bounding box format. Subsequently, we conduct a mid-training phase
using a large number of pedestrian-related datasets. Finally, we perform
supervised fine-tuning on several pedestrian tracking datasets, and then carry
out another RL phase to improve the model's tracking performance and enhance
its ability to follow instructions. We conduct experiments on tracking
benchmarks and the experimental results demonstrate that the proposed method
can perform better than the previous methods.
\\ ( https://arxiv.org/abs/2511.17053 ,  1239kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17054
Date: Fri, 21 Nov 2025 08:55:55 GMT   (4988kb)

Title: RL-AD-Net: Reinforcement Learning Guided Adaptive Displacement in Latent
 Space for Refined Point Cloud Completion
Authors: Bhanu Pratap Paregi, Vaibhav Kumar
Categories: cs.CV
\\
 Recent point cloud completion models, including transformer-based,
denoising-based, and other state-of-the-art approaches, generate globally
plausible shapes from partial inputs but often leave local geometric
inconsistencies. We propose RL-AD-Net, a reinforcement learning (RL) refinement
framework that operates in the latent space of a pretrained point autoencoder.
The autoencoder encodes completions into compact global feature vectors (GFVs),
which are selectively adjusted by an RL agent to improve geometric fidelity. To
ensure robustness, a lightweight non-parametric PointNN selector evaluates the
geometric consistency of both the original completion and the RL-refined
output, retaining the better reconstruction. When ground truth is available,
both Chamfer Distance and geometric consistency metrics guide refinement.
Training is performed separately per category, since the unsupervised and
dynamic nature of RL makes convergence across highly diverse categories
challenging. Nevertheless, the framework can be extended to multi-category
refinement in future work. Experiments on ShapeNetCore-2048 demonstrate that
while baseline completion networks perform reasonable under their
training-style cropping, they struggle in random cropping scenarios. In
contrast, RL-AD-Net consistently delivers improvements across both settings,
highlighting the effectiveness of RL-guided ensemble refinement. The approach
is lightweight, modular, and model-agnostic, making it applicable to a wide
range of completion networks without requiring retraining.
\\ ( https://arxiv.org/abs/2511.17054 ,  4988kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17059
Date: Fri, 21 Nov 2025 09:07:56 GMT   (5758kb)

Title: REArtGS++: Generalizable Articulation Reconstruction with Temporal
 Geometry Constraint via Planar Gaussian Splatting
Authors: Di Wu, Liu Liu, Anran Huang, Yuyan Liu, Qiaoyu Jun, Shaofan Liu,
 Liangtu Song, Cewu Lu
Categories: cs.CV
Comments: 10 pages, 7 figures
\\
 Articulated objects are pervasive in daily environments, such as drawers and
refrigerators. Towards their part-level surface reconstruction and joint
parameter estimation, REArtGS~\cite{wu2025reartgs} introduces a
category-agnostic approach using multi-view RGB images at two different states.
However, we observe that REArtGS still struggles with screw-joint or multi-part
objects and lacks geometric constraints for unseen states. In this paper, we
propose REArtGS++, a novel method towards generalizable articulated object
reconstruction with temporal geometry constraint and planar Gaussian splatting.
We first model a decoupled screw motion for each joint without type prior, and
jointly optimize part-aware Gaussians with joint parameters through part motion
blending. To introduce time-continuous geometric constraint for articulated
modeling, we encourage Gaussians to be planar and propose a temporally
consistent regularization between planar normal and depth through Taylor
first-order expansion. Extensive experiments on both synthetic and real-world
articulated objects demonstrate our superiority in generalizable part-level
surface reconstruction and joint parameter estimation, compared to existing
approaches. Project Site: https://sites.google.com/view/reartgs2/home.
\\ ( https://arxiv.org/abs/2511.17059 ,  5758kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17068
Date: Fri, 21 Nov 2025 09:18:35 GMT   (5060kb)

Title: ReBrain: Brain MRI Reconstruction from Sparse CT Slice via
 Retrieval-Augmented Diffusion
Authors: Junming Liu, Yifei Sun, Weihua Cheng, Yujin Kang, Yirong Chen, Ding
 Wang, Guosun Zeng
Categories: cs.CV cs.AI
Comments: 16 pages, 12 figures, 7 tables; Accepted by WACV 2026
\\
 Magnetic Resonance Imaging (MRI) plays a crucial role in brain disease
diagnosis, but it is not always feasible for certain patients due to physical
or clinical constraints. Recent studies attempt to synthesize MRI from Computed
Tomography (CT) scans; however, low-dose protocols often result in highly
sparse CT volumes with poor through-plane resolution, making accurate
reconstruction of the full brain MRI volume particularly challenging. To
address this, we propose ReBrain, a retrieval-augmented diffusion framework for
brain MRI reconstruction. Given any 3D CT scan with limited slices, we first
employ a Brownian Bridge Diffusion Model (BBDM) to synthesize MRI slices along
the 2D dimension. Simultaneously, we retrieve structurally and pathologically
similar CT slices from a comprehensive prior database via a fine-tuned
retrieval model. These retrieved slices are used as references, incorporated
through a ControlNet branch to guide the generation of intermediate MRI slices
and ensure structural continuity. We further account for rare retrieval
failures when the database lacks suitable references and apply spherical linear
interpolation to provide supplementary guidance. Extensive experiments on
SynthRAD2023 and BraTS demonstrate that ReBrain achieves state-of-the-art
performance in cross-modal reconstruction under sparse conditions.
\\ ( https://arxiv.org/abs/2511.17068 ,  5060kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17074
Date: Fri, 21 Nov 2025 09:24:09 GMT   (19583kb)

Title: Diversity Has Always Been There in Your Visual Autoregressive Models
Authors: Tong Wang, Guanyu Yang, Nian Liu, Kai Wang, Yaxing Wang, Abdelrahman M
 Shaker, Salman Khan, Fahad Shahbaz Khan, Senmao Li
Categories: cs.CV
\\
 Visual Autoregressive (VAR) models have recently garnered significant
attention for their innovative next-scale prediction paradigm, offering notable
advantages in both inference efficiency and image quality compared to
traditional multi-step autoregressive (AR) and diffusion models. However,
despite their efficiency, VAR models often suffer from the diversity collapse
i.e., a reduction in output variability, analogous to that observed in few-step
distilled diffusion models. In this paper, we introduce DiverseVAR, a simple
yet effective approach that restores the generative diversity of VAR models
without requiring any additional training. Our analysis reveals the pivotal
component of the feature map as a key factor governing diversity formation at
early scales. By suppressing the pivotal component in the model input and
amplifying it in the model output, DiverseVAR effectively unlocks the inherent
generative potential of VAR models while preserving high-fidelity synthesis.
Empirical results demonstrate that our approach substantially enhances
generative diversity with only neglectable performance influences. Our code
will be publicly released at https://github.com/wangtong627/DiverseVAR.
\\ ( https://arxiv.org/abs/2511.17074 ,  19583kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17089
Date: Fri, 21 Nov 2025 09:45:17 GMT   (31686kb)

Title: Spanning Tree Autoregressive Visual Generation
Authors: Sangkyu Lee, Changho Lee, Janghoon Han, Hosung Song, Tackgeun You,
 Hwasup Lim, Stanley Jungkyu Choi, Honglak Lee, Youngjae Yu
Categories: cs.CV cs.AI
Comments: Preprint; Under review
\\
 We present Spanning Tree Autoregressive (STAR) modeling, which can
incorporate prior knowledge of images, such as center bias and locality, to
maintain sampling performance while also providing sufficiently flexible
sequence orders to accommodate image editing at inference. Approaches that
expose randomly permuted sequence orders to conventional autoregressive (AR)
models in visual generation for bidirectional context either suffer from a
decline in performance or compromise the flexibility in sequence order choice
at inference. Instead, STAR utilizes traversal orders of uniform spanning trees
sampled in a lattice defined by the positions of image patches. Traversal
orders are obtained through breadth-first search, allowing us to efficiently
construct a spanning tree whose traversal order ensures that the connected
partial observation of the image appears as a prefix in the sequence through
rejection sampling. Through the tailored yet structured randomized strategy
compared to random permutation, STAR preserves the capability of postfix
completion while maintaining sampling performance without any significant
changes to the model architecture widely adopted in the language AR modeling.
\\ ( https://arxiv.org/abs/2511.17089 ,  31686kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17092
Date: Fri, 21 Nov 2025 09:49:53 GMT   (4625kb)

Title: SPAGS: Sparse-View Articulated Object Reconstruction from Single State
 via Planar Gaussian Splatting
Authors: Di Wu, Liu Liu, Xueyu Yuan, Qiaoyu Jun, Wenxiao Chen, Ruilong Yan,
 Yiming Tang, Liangtu Song
Categories: cs.CV
Comments: 10 pages, 7 figures
\\
 Articulated objects are ubiquitous in daily environments, and their 3D
reconstruction holds great significance across various fields. However,
existing articulated object reconstruction methods typically require costly
inputs such as multi-stage and multi-view observations. To address the
limitations, we propose a category-agnostic articulated object reconstruction
framework via planar Gaussian Splatting, which only uses sparse-view RGB images
from a single state. Specifically, we first introduce a Gaussian information
field to perceive the optimal sparse viewpoints from candidate camera poses.
Then we compress 3D Gaussians into planar Gaussians to facilitate accurate
estimation of normal and depth. The planar Gaussians are optimized in a
coarse-to-fine manner through depth smooth regularization and few-shot
diffusion. Moreover, we introduce a part segmentation probability for each
Gaussian primitive and update them by back-projecting part segmentation masks
of renderings. Extensive experimental results demonstrate that our method
achieves higher-fidelity part-level surface reconstruction on both synthetic
and real-world data than existing methods. Codes will be made publicly
available.
\\ ( https://arxiv.org/abs/2511.17092 ,  4625kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17094
Date: Fri, 21 Nov 2025 09:50:21 GMT   (7792kb)

Title: Sparse Reasoning is Enough: Biological-Inspired Framework for Video
 Anomaly Detection with Large Pre-trained Models
Authors: He Huang, Zixuan Hu, Dongxiao Li, Yao Xiao, Ling-Yu Duan
Categories: cs.CV
\\
 Video anomaly detection (VAD) plays a vital role in real-world applications
such as security surveillance, autonomous driving, and industrial monitoring.
Recent advances in large pre-trained models have opened new opportunities for
training-free VAD by leveraging rich prior knowledge and general reasoning
capabilities. However, existing studies typically rely on dense frame-level
inference, incurring high computational costs and latency. This raises a
fundamental question: Is dense reasoning truly necessary when using powerful
pre-trained models in VAD systems? To answer this, we propose ReCoVAD, a novel
framework inspired by the dual reflex and conscious pathways of the human
nervous system, enabling selective frame processing to reduce redundant
computation. ReCoVAD consists of two core pathways: (i) a Reflex pathway that
uses a lightweight CLIP-based module to fuse visual features with prototype
prompts and produce decision vectors, which query a dynamic memory of past
frames and anomaly scores for fast response; and (ii) a Conscious pathway that
employs a medium-scale vision-language model to generate textual event
descriptions and refined anomaly scores for novel frames. It continuously
updates the memory and prototype prompts, while an integrated large language
model periodically reviews accumulated descriptions to identify unseen
anomalies, correct errors, and refine prototypes. Extensive experiments show
that ReCoVAD achieves state-of-the-art training-free performance while
processing only 28.55\% and 16.04\% of the frames used by previous methods on
the UCF-Crime and XD-Violence datasets, demonstrating that sparse reasoning is
sufficient for effective large-model-based VAD.
\\ ( https://arxiv.org/abs/2511.17094 ,  7792kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17103
Date: Fri, 21 Nov 2025 10:06:32 GMT   (1112kb)

Title: Bridging Visual Affective Gap: Borrowing Textual Knowledge by Learning
 from Noisy Image-Text Pairs
Authors: Daiqing Wu, Dongbao Yang, Yu Zhou, Can Ma
Categories: cs.CV
Comments: Accepted by ACM MM 2024
DOI: 10.1145/3664647.3680875
\\
 Visual emotion recognition (VER) is a longstanding field that has garnered
increasing attention with the advancement of deep neural networks. Although
recent studies have achieved notable improvements by leveraging the knowledge
embedded within pre-trained visual models, the lack of direct association
between factual-level features and emotional categories, called the "affective
gap", limits the applicability of pre-training knowledge for VER tasks. On the
contrary, the explicit emotional expression and high information density in
textual modality eliminate the "affective gap". Therefore, we propose borrowing
the knowledge from the pre-trained textual model to enhance the emotional
perception of pre-trained visual models. We focus on the factual and emotional
connections between images and texts in noisy social media data, and propose
Partitioned Adaptive Contrastive Learning (PACL) to leverage these connections.
Specifically, we manage to separate different types of samples and devise
distinct contrastive learning strategies for each type. By dynamically
constructing negative and positive pairs, we fully exploit the potential of
noisy samples. Through comprehensive experiments, we demonstrate that bridging
the "affective gap" significantly improves the performance of various
pre-trained visual models in downstream emotion-related tasks. Our code is
released on https://github.com/wdqqdw/PACL.
\\ ( https://arxiv.org/abs/2511.17103 ,  1112kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17106
Date: Fri, 21 Nov 2025 10:11:17 GMT   (2473kb)

Title: ChainV: Atomic Visual Hints Make Multimodal Reasoning Shorter and Better
Authors: Yuan Zhang, Ming Lu, Junwen Pan, Tao Huang, Kuan Cheng, Qi She,
 Shanghang Zhang
Categories: cs.CV
Comments: 16 pages
\\
 Recent advances in multimodal reasoning models have demonstrated impressive
capabilities across text and vision. However, even leading models exhibit
redundant self-reflection when generating lengthy reasoning chains. While
training-free CoT compression methods have emerged in the LLMs domain, they
rely on static visual references and thus provide limited gains for multimodal
reasoning. Therefore, we propose ChainV, a framework that dynamically
integrates visual hints into the reasoning process, thereby making multimodal
reasoning shorter and better. Specifically, ChainV first performs a coarse
visual patch selection based on the previous reasoning step, then refines it by
identifying the most representative atomic visual hint according to the
averaged attention intensity. Additionally, ChainV introduces a
consistency-based evaluation mechanism to assess the reliability of the chosen
hint, guiding the model to adaptively adjust its level of self-reflection.
Eventually, the pixel coordinates of the selected visual hint and its
reliability are incorporated into thinking with a Bernoulli stochastic process.
Experiments indicate that our method significantly improves reasoning accuracy
and efficiency, especially on math-intensive benchmarks where visual hints are
crucial for multi-step symbolic reasoning. For example, ChainV achieves $2.3\%$
improvement on the MathVista within MIMO-VL-RL, while reducing inference
latency by $51.4\%$ and shortening output token length by $24.5\%$.
\\ ( https://arxiv.org/abs/2511.17106 ,  2473kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17116
Date: Fri, 21 Nov 2025 10:27:51 GMT   (5165kb)

Title: PEGS: Physics-Event Enhanced Large Spatiotemporal Motion Reconstruction
 via 3D Gaussian Splatting
Authors: Yijun Xu, Jingrui Zhang, Hongyi Liu, Yuhan Chen, Yuanyang Wang,
 Qingyao Guo, Dingwen Wang, Lei Yu, Chu He
Categories: cs.CV
\\
 Reconstruction of rigid motion over large spatiotemporal scales remains a
challenging task due to limitations in modeling paradigms, severe motion blur,
and insufficient physical consistency. In this work, we propose PEGS, a
framework that integrates Physical priors with Event stream enhancement within
a 3D Gaussian Splatting pipeline to perform deblurred target-focused modeling
and motion recovery. We introduce a cohesive triple-level supervision scheme
that enforces physical plausibility via an acceleration constraint, leverages
event streams for high-temporal resolution guidance, and employs a Kalman
regularizer to fuse multi-source observations. Furthermore, we design a
motion-aware simulated annealing strategy that adaptively schedules the
training process based on real-time kinematic states. We also contribute the
first RGB-Event paired dataset targeting natural, fast rigid motion across
diverse scenarios. Experiments show PEGS's superior performance in
reconstructing motion over large spatiotemporal scales compared to mainstream
dynamic methods.
\\ ( https://arxiv.org/abs/2511.17116 ,  5165kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17133
Date: Fri, 21 Nov 2025 10:49:04 GMT   (44585kb)

Title: Off the Planckian Locus: Using 2D Chromaticity to Improve In-Camera
 Color
Authors: SaiKiran Tedla, Joshua E. Little, Hakki Can Karaimer, Michael S. Brown
Categories: cs.CV
Comments: Project page: https://cst-mlp.github.io
\\
 Traditional in-camera colorimetric mapping relies on correlated color
temperature (CCT)-based interpolation between pre-calibrated transforms
optimized for Planckian illuminants such as CIE A and D65. However, modern
lighting technologies such as LEDs can deviate substantially from the Planckian
locus, exposing the limitations of relying on conventional one-dimensional CCT
for illumination characterization. This paper demonstrates that transitioning
from 1D CCT (on the Planckian locus) to a 2D chromaticity space (off the
Planckian locus) improves colorimetric accuracy across various mapping
approaches. In addition, we replace conventional CCT interpolation with a
lightweight multi-layer perceptron (MLP) that leverages 2D chromaticity
features for robust colorimetric mapping under non-Planckian illuminants. A
lightbox-based calibration procedure incorporating representative LED sources
is used to train our MLP. Validated across diverse LED lighting, our method
reduces angular reproduction error by 22% on average in LED-lit scenes,
maintains backward compatibility with traditional illuminants, accommodates
multi-illuminant scenes, and supports real-time in-camera deployment with
negligible additional computational cost.
\\ ( https://arxiv.org/abs/2511.17133 ,  44585kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17135
Date: Fri, 21 Nov 2025 10:55:44 GMT   (7464kb)

Title: A Multi-Stage Optimization Framework for Deploying Learned Image
 Compression on FPGAs
Authors: Jiaxun Fang, Li Chen
Categories: cs.CV
\\
 Deep learning-based image compression (LIC) has achieved state-of-the-art
rate-distortion (RD) performance, yet deploying these models on
resource-constrained FPGAs remains a major challenge. This work presents a
complete, multi-stage optimization framework to bridge the gap between
high-performance floating-point models and efficient, hardware-friendly
integer-based implementations. First, we address the fundamental problem of
quantization-induced performance degradation. We propose a Dynamic Range-Aware
Quantization (DRAQ) method that uses statistically-calibrated activation
clipping and a novel weight regularization scheme to counteract the effects of
extreme data outliers and large dynamic ranges, successfully creating a
high-fidelity 8-bit integer model. Second, building on this robust foundation,
we introduce two hardware-aware optimization techniques tailored for FPGAs. A
progressive mixed-precision search algorithm exploits FPGA flexibility to
assign optimal, non-uniform bit-widths to each layer, minimizing complexity
while preserving performance. Concurrently, a channel pruning method, adapted
to work with the Generalized Divisive Normalization (GDN) layers common in LIC,
removes model redundancy by eliminating inactive channels. Our comprehensive
experiments show that the foundational DRAQ method reduces the BD-rate overhead
of a GDN-based model from $30\%$ to $6.3\%$. The subsequent hardware-aware
optimizations further reduce computational complexity by over $20\%$ with
negligible impact on RD performance, yielding a final model that is both
state-of-the-art in efficiency and superior in quality to existing FPGA-based
LIC implementations.
\\ ( https://arxiv.org/abs/2511.17135 ,  7464kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17138
Date: Fri, 21 Nov 2025 11:00:59 GMT   (12141kb)

Title: One-Step Diffusion Transformer for Controllable Real-World Image
 Super-Resolution
Authors: Yushun Fang, Yuxiang Chen, Shibo Yin, Qiang Hu, Jiangchao Yao, Ya
 Zhang, Xiaoyun Zhang, Yanfeng Wang
Categories: cs.CV
\\
 Recent advances in diffusion-based real-world image super-resolution
(Real-ISR) have demonstrated remarkable perceptual quality, yet the balance
between fidelity and controllability remains a problem: multi-step
diffusion-based methods suffer from generative diversity and randomness,
resulting in low fidelity, while one-step methods lose control flexibility due
to fidelity-specific finetuning. In this paper, we present ODTSR, a one-step
diffusion transformer based on Qwen-Image that performs Real-ISR considering
fidelity and controllability simultaneously: a newly introduced visual stream
receives low-quality images (LQ) with adjustable noise (Control Noise), and the
original visual stream receives LQs with consistent noise (Prior Noise),
forming the Noise-hybrid Visual Stream (NVS) design. ODTSR further employs
Fidelity-aware Adversarial Training (FAA) to enhance controllability and
achieve one-step inference. Extensive experiments demonstrate that ODTSR not
only achieves state-of-the-art (SOTA) performance on generic Real-ISR, but also
enables prompt controllability on challenging scenarios such as real-world
scene text image super-resolution (STISR) of Chinese characters without
training on specific datasets.
\\ ( https://arxiv.org/abs/2511.17138 ,  12141kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17146
Date: Fri, 21 Nov 2025 11:10:05 GMT   (2499kb)

Title: Learning to Look Closer: A New Instance-Wise Loss for Small Cerebral
 Lesion Segmentation
Authors: Luc Bouteille, Alexander Jaus, Jens Kleesiek, Rainer Stiefelhagen,
 Lukas Heine
Categories: cs.CV
Comments: 5 pages, 2 figures, 2 tables
ACM-class: I.4.6; I.2.10; J.3
\\
 Traditional loss functions in medical image segmentation, such as Dice, often
under-segment small lesions because their small relative volume contributes
negligibly to the overall loss. To address this, instance-wise loss functions
and metrics have been proposed to evaluate segmentation quality on a per-lesion
basis. We introduce CC-DiceCE, a loss function based on the CC-Metrics
framework, and compare it with the existing blob loss. Both are benchmarked
against a DiceCE baseline within the nnU-Net framework, which provides a robust
and standardized setup. We find that CC-DiceCE loss increases detection
(recall) with minimal to no degradation in segmentation performance, albeit at
the cost of slightly more false positives. Furthermore, our multi-dataset study
shows that CC-DiceCE generally outperforms blob loss.
\\ ( https://arxiv.org/abs/2511.17146 ,  2499kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17147
Date: Fri, 21 Nov 2025 11:11:04 GMT   (508kb)

Title: A lightweight detector for real-time detection of remote sensing images
Authors: Qianyi Wang, Guoqiang Ren
Categories: cs.CV cs.AI
Comments: none
\\
 Remote sensing imagery is widely used across various fields, yet real-time
detection remains challenging due to the prevalence of small objects and the
need to balance accuracy with efficiency. To address this, we propose DMG-YOLO,
a lightweight real-time detector tailored for small object detection in remote
sensing images. Specifically, we design a Dual-branch Feature Extraction (DFE)
module in the backbone, which partitions feature maps into two parallel
branches: one extracts local features via depthwise separable convolutions, and
the other captures global context using a vision transformer with a gating
mechanism. Additionally, a Multi-scale Feature Fusion (MFF) module with dilated
convolutions enhances multi-scale integration while preserving fine details. In
the neck, we introduce the Global and Local Aggregate Feature Pyramid Network
(GLAFPN) to further boost small object detection through global-local feature
fusion. Extensive experiments on the VisDrone2019 and NWPU VHR-10 datasets show
that DMG-YOLO achieves competitive performance in terms of mAP, model size, and
other key metrics.
\\ ( https://arxiv.org/abs/2511.17147 ,  508kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17150
Date: Fri, 21 Nov 2025 11:16:00 GMT   (5861kb)

Title: DiffRefiner: Coarse to Fine Trajectory Planning via Diffusion Refinement
 with Semantic Interaction for End to End Autonomous Driving
Authors: Liuhan Yin, Runkun Ju, Guodong Guo, Erkang Cheng
Categories: cs.CV
Comments: Accepted to AAAI 2026
\\
 Unlike discriminative approaches in autonomous driving that predict a fixed
set of candidate trajectories of the ego vehicle, generative methods, such as
diffusion models, learn the underlying distribution of future motion, enabling
more flexible trajectory prediction. However, since these methods typically
rely on denoising human-crafted trajectory anchors or random noise, there
remains significant room for improvement. In this paper, we propose
DiffRefiner, a novel two-stage trajectory prediction framework. The first stage
uses a transformer-based Proposal Decoder to generate coarse trajectory
predictions by regressing from sensor inputs using predefined trajectory
anchors. The second stage applies a Diffusion Refiner that iteratively denoises
and refines these initial predictions. In this way, we enhance the performance
of diffusion-based planning by incorporating a discriminative trajectory
proposal module, which provides strong guidance for the generative refinement
process. Furthermore, we design a fine-grained denoising decoder to enhance
scene compliance, enabling more accurate trajectory prediction through enhanced
alignment with the surrounding environment. Experimental results demonstrate
that DiffRefiner achieves state-of-the-art performance, attaining 87.4 EPDMS on
NAVSIM v2, and 87.1 DS along with 71.4 SR on Bench2Drive, thereby setting new
records on both public benchmarks. The effectiveness of each component is
validated via ablation studies as well.
\\ ( https://arxiv.org/abs/2511.17150 ,  5861kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17155
Date: Fri, 21 Nov 2025 11:19:57 GMT   (6270kb)

Title: UI-Styler: Ultrasound Image Style Transfer with Class-Aware Prompts for
 Cross-Device Diagnosis Using a Frozen Black-Box Inference Network
Authors: Nhat-Tuong Do-Tran, Ngoc-Hoang-Lam Le, and Ching-Chun Huang
Categories: cs.CV
Comments: Project page: https://dotrannhattuong.github.io/UIStyler, Accepted to
 WACV 2026
\\
 The appearance of ultrasound images varies across acquisition devices,
causing domain shifts that degrade the performance of fixed black-box
downstream inference models when reused. To mitigate this issue, it is
practical to develop unpaired image translation (UIT) methods that effectively
align the statistical distributions between source and target domains,
particularly under the constraint of a reused inference-blackbox setting.
However, existing UIT approaches often overlook class-specific semantic
alignment during domain adaptation, resulting in misaligned content-class
mappings that can impair diagnostic accuracy. To address this limitation, we
propose UI-Styler, a novel ultrasound-specific, class-aware image style
transfer framework. UI-Styler leverages a pattern-matching mechanism to
transfer texture patterns embedded in the target images onto source images
while preserving the source structural content. In addition, we introduce a
class-aware prompting strategy guided by pseudo labels of the target domain,
which enforces accurate semantic alignment with diagnostic categories.
Extensive experiments on ultrasound cross-device tasks demonstrate that
UI-Styler consistently outperforms existing UIT methods, achieving
state-of-the-art performance in distribution distance and downstream tasks,
such as classification and segmentation.
\\ ( https://arxiv.org/abs/2511.17155 ,  6270kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17171
Date: Fri, 21 Nov 2025 11:45:22 GMT   (21028kb)

Title: FireScope: Wildfire Risk Prediction with a Chain-of-Thought Oracle
Authors: Mario Markov (1), Stefan Maria Ailuro (1), Luc Van Gool (1), Konrad
 Schindler (2), Danda Pani Paudel (1 and 2) ((1) INSAIT, Sofia University, (2)
 ETH Zurich)
Categories: cs.CV cs.LG
\\
 Predicting wildfire risk is a reasoning-intensive spatial problem that
requires the integration of visual, climatic, and geographic factors to infer
continuous risk maps. Existing methods lack the causal reasoning and multimodal
understanding required for reliable generalization. We introduce
$\textbf{FireScope-Bench}$, a large-scale dataset and benchmark that couples
Sentinel-2 imagery and climate data with expert-defined risk rasters across the
USA, and real wildfire events in Europe for cross-continental evaluation.
Building on this dataset, we propose $\textbf{FireScope}$, a VLM-based
reasoning-to-generation framework that learns from both reinforcement learning
and visual supervision to predict risk rasters with complementary reasoning
traces. When trained in the USA and tested in Europe, $\textbf{FireScope}$
achieves substantial performance gains, while expert feedback and automated
analysis confirm that its reasoning traces are faithful and semantically
meaningful. Our findings demonstrate that reasoning can ground raster
prediction models, improving both generalization and interpretability. To our
knowledge, this is the first framework to (1) demonstrate that language-based
reasoning can improve generalization in visual generation, (2) propose a
high-resolution wildfire risk model that can be applied across continents, and
(3) enable systematic studies of robust cross-continental generalization for
multimodal fire risk models. We believe that $\textbf{FireScope-Bench}$ has the
potential to serve as a foundation for advancing reasoning-driven,
interpretable and generalizable spatial modeling. Data and source code will be
made publicly available.
\\ ( https://arxiv.org/abs/2511.17171 ,  21028kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17181
Date: Fri, 21 Nov 2025 12:04:00 GMT   (12075kb)

Title: Investigating self-supervised representations for audio-visual deepfake
 detection
Authors: Dragos-Alexandru Boldisor, Stefan Smeu, Dan Oneata, Elisabeta Oneata
Categories: cs.CV cs.LG cs.SD
\\
 Self-supervised representations excel at many vision and speech tasks, but
their potential for audio-visual deepfake detection remains underexplored.
Unlike prior work that uses these features in isolation or buried within
complex architectures, we systematically evaluate them across modalities
(audio, video, multimodal) and domains (lip movements, generic visual content).
We assess three key dimensions: detection effectiveness, interpretability of
encoded information, and cross-modal complementarity. We find that most
self-supervised features capture deepfake-relevant information, and that this
information is complementary. Moreover, models primarily attend to semantically
meaningful regions rather than spurious artifacts. Yet none generalize reliably
across datasets. This generalization failure likely stems from dataset
characteristics, not from the features themselves latching onto superficial
patterns. These results expose both the promise and fundamental challenges of
self-supervised representations for deepfake detection: while they learn
meaningful patterns, achieving robust cross-domain performance remains elusive.
\\ ( https://arxiv.org/abs/2511.17181 ,  12075kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17183
Date: Fri, 21 Nov 2025 12:04:53 GMT   (21696kb)

Title: Navigating in the Dark: A Multimodal Framework and Dataset for Nighttime
 Traffic Sign Recognition
Authors: Aditya Mishra, Akshay Agarwal, Haroon Lone
Categories: cs.CV cs.CY
\\
 Traffic signboards are vital for road safety and intelligent transportation
systems, enabling navigation and autonomous driving. Yet, recognizing traffic
signs at night remains challenging due to visual noise and scarcity of public
nighttime datasets. Despite advances in vision architectures, existing methods
struggle with robustness under low illumination and fail to leverage
complementary mutlimodal cues effectively. To overcome these limitations,
firstly, we introduce INTSD, a large-scale dataset comprising street-level
night-time images of traffic signboards collected across diverse regions of
India. The dataset spans 41 traffic signboard classes captured under varying
lighting and weather conditions, providing a comprehensive benchmark for both
detection and classification tasks. To benchmark INTSD for night-time sign
recognition, we conduct extensive evaluations using state-of-the-art detection
and classification models. Secondly, we propose LENS-Net, which integrates an
adaptive image enhancement detector for joint illumination correction and sign
localization, followed by a structured multimodal CLIP-GCNN classifier that
leverages cross-modal attention and graph-based reasoning for robust and
semantically consistent recognition. Our method surpasses existing frameworks,
with ablation studies confirming the effectiveness of its key components. The
dataset and code for LENS-Net is publicly available for research.
\\ ( https://arxiv.org/abs/2511.17183 ,  21696kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17185
Date: Fri, 21 Nov 2025 12:05:46 GMT   (16888kb)

Title: PostCam: Camera-Controllable Novel-View Video Generation with
 Query-Shared Cross-Attention
Authors: Yipeng Chen, Zhichao Ye, Zhenzhou Fang, Xinyu Chen, Xiaoyu Zhang,
 Jialing Liu, Nan Wang, Haomin Liu, Guofeng Zhang
Categories: cs.CV
\\
 We propose PostCam, a framework for novel-view video generation that enables
post-capture editing of camera trajectories in dynamic scenes. We find that
existing video recapture methods suffer from suboptimal camera motion injection
strategies; such suboptimal designs not only limit camera control precision but
also result in generated videos that fail to preserve fine visual details from
the source video. To achieve more accurate and flexible motion manipulation,
PostCam introduces a query-shared cross-attention module. It integrates two
distinct forms of control signals: the 6-DoF camera poses and the 2D rendered
video frames. By fusing them into a unified representation within a shared
feature space, our model can extract underlying motion cues, which enhances
both control precision and generation quality. Furthermore, we adopt a
two-stage training strategy: the model first learns coarse camera control from
pose inputs, and then incorporates visual information to refine motion accuracy
and enhance visual fidelity. Experiments on both real-world and synthetic
datasets demonstrate that PostCam outperforms state-of-the-art methods by over
20% in camera control precision and view consistency, while achieving the
highest video generation quality. Our project webpage is publicly available at:
https://cccqaq.github.io/PostCam.github.io/
\\ ( https://arxiv.org/abs/2511.17185 ,  16888kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17196
Date: Fri, 21 Nov 2025 12:23:07 GMT   (2838kb)

Title: Real Noise Decoupling for Hyperspectral Image Denoising
Authors: Yingkai Zhang, Tao Zhang, Jing Nie, Ying Fu
Categories: cs.CV
\\
 Hyperspectral image (HSI) denoising is a crucial step in enhancing the
quality of HSIs. Noise modeling methods can fit noise distributions to generate
synthetic HSIs to train denoising networks. However, the noise in captured HSIs
is usually complex and difficult to model accurately, which significantly
limits the effectiveness of these approaches. In this paper, we propose a
multi-stage noise-decoupling framework that decomposes complex noise into
explicitly modeled and implicitly modeled components. This decoupling reduces
the complexity of noise and enhances the learnability of HSI denoising methods
when applied to real paired data. Specifically, for explicitly modeled noise,
we utilize an existing noise model to generate paired data for pre-training a
denoising network, equipping it with prior knowledge to handle the explicitly
modeled noise effectively. For implicitly modeled noise, we introduce a
high-frequency wavelet guided network. Leveraging the prior knowledge from the
pre-trained module, this network adaptively extracts high-frequency features to
target and remove the implicitly modeled noise from real paired HSIs.
Furthermore, to effectively eliminate all noise components and mitigate error
accumulation across stages, a multi-stage learning strategy, comprising
separate pre-training and joint fine-tuning, is employed to optimize the entire
framework. Extensive experiments on public and our captured datasets
demonstrate that our proposed framework outperforms state-of-the-art methods,
effectively handling complex real-world noise and significantly enhancing HSI
quality.
\\ ( https://arxiv.org/abs/2511.17196 ,  2838kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17199
Date: Fri, 21 Nov 2025 12:26:30 GMT   (1381kb)

Title: VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for
 SpatioTemporally Coherent Robotic Manipulation
Authors: Hanyu Zhou, Chuanhao Ma, Gim Hee Lee
Categories: cs.CV
\\
 Vision-language-action (VLA) models show potential for general robotic tasks,
but remain challenging in spatiotemporally coherent manipulation, which
requires fine-grained representations. Typically, existing methods embed 3D
positions into visual representations to enhance the spatial precision of
actions. However, these methods struggle to achieve temporally coherent control
over action execution. In this work, we propose VLA-4D, a general VLA model
with 4D awareness for spatiotemporally coherent robotic manipulation. Our model
is guided by two key designs: 1) 4D-aware visual representation. We extract
visual features, embed 1D time into 3D positions for 4D embeddings, and fuse
them into a unified visual representation via a cross-attention mechanism. 2)
Spatiotemporal action representation. We extend conventional spatial action
representations with temporal information to enable the spatiotemporal
planning, and align the multimodal representations into the LLM for
spatiotemporal action prediction. Within this unified framework, the designed
visual and action representations jointly make robotic manipulation
spatially-smooth and temporally-coherent. In addition, we extend the VLA
dataset with temporal action annotations for fine-tuning our model. Extensive
experiments have been conducted to verify the superiority of our method across
different tasks of robotic manipulation.
\\ ( https://arxiv.org/abs/2511.17199 ,  1381kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17201
Date: Fri, 21 Nov 2025 12:27:49 GMT   (6936kb)

Title: Continual Alignment for SAM: Rethinking Foundation Models for Medical
 Image Segmentation in Continual Learning
Authors: Jiayi Wang, Wei Dai, Haoyu Wang, Sihan Yang, Haixia Bi and Jian Sun
Categories: cs.CV
\\
 In medical image segmentation, heterogeneous privacy policies across
institutions often make joint training on pooled datasets infeasible,
motivating continual image segmentation-learning from data streams without
catastrophic forgetting. While the Segment Anything Model (SAM) offers strong
zero-shot priors and has been widely fine-tuned across downstream tasks, its
large parameter count and computational overhead challenge practical
deployment. This paper demonstrates that the SAM paradigm is highly promising
once its computational efficiency and performance can be balanced. To this end,
we introduce the Alignment Layer, a lightweight, plug-and-play module which
aligns encoder-decoder feature distributions to efficiently adapt SAM to
specific medical images, improving accuracy while reducing computation.
Building on SAM and the Alignment Layer, we then propose Continual Alignment
for SAM (CA-SAM), a continual learning strategy that automatically adapts the
appropriate Alignment Layer to mitigate catastrophic forgetting, while
leveraging SAM's zero-shot priors to preserve strong performance on unseen
medical datasets. Experimented across nine medical segmentation datasets under
continual-learning scenario, CA-SAM achieves state-of-the-art performance. Our
code, models and datasets will be released on
\mbox{https://github.com/azzzzyo/Continual-Alignment-for-SAM.}
\\ ( https://arxiv.org/abs/2511.17201 ,  6936kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17207
Date: Fri, 21 Nov 2025 12:40:55 GMT   (8555kb)

Title: SING3R-SLAM: Submap-based Indoor Monocular Gaussian SLAM with 3D
 Reconstruction Priors
Authors: Kunyi Li, Michael Niemeyer, Sen Wang, Stefano Gasperini, Nassir Navab,
 Federico Tombari
Categories: cs.CV cs.RO
\\
 Recent advances in dense 3D reconstruction enable the accurate capture of
local geometry; however, integrating them into SLAM is challenging due to drift
and redundant point maps, which limit efficiency and downstream tasks, such as
novel view synthesis. To address these issues, we propose SING3R-SLAM, a
globally consistent and compact Gaussian-based dense RGB SLAM framework. The
key idea is to combine locally consistent 3D reconstructions with a unified
global Gaussian representation that jointly refines scene geometry and camera
poses, enabling efficient and versatile 3D mapping for multiple downstream
applications. SING3R-SLAM first builds locally consistent submaps through our
lightweight tracking and reconstruction module, and then progressively aligns
and fuses them into a global Gaussian map that enforces cross-view geometric
consistency. This global map, in turn, provides feedback to correct local drift
and enhance the robustness of tracking. Extensive experiments demonstrate that
SING3R-SLAM achieves state-of-the-art tracking, 3D reconstruction, and novel
view rendering, resulting in over 12% improvement in tracking and producing
finer, more detailed geometry, all while maintaining a compact and
memory-efficient global representation on real-world datasets.
\\ ( https://arxiv.org/abs/2511.17207 ,  8555kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17209
Date: Fri, 21 Nov 2025 12:41:27 GMT   (1335kb)

Title: Scaling Self-Supervised and Cross-Modal Pretraining for Volumetric CT
 Transformers
Authors: Cris Claessens, Christiaan Viviers, Giacomo D'Amicantonio, Egor
 Bondarev, Fons van der Sommen
Categories: cs.CV
\\
 We introduce SPECTRE, a fully transformer-based foundation model for
volumetric computed tomography (CT). Our Self-Supervised & Cross-Modal
Pretraining for CT Representation Extraction (SPECTRE) approach utilizes
scalable 3D Vision Transformer architectures and modern self-supervised and
vision-language pretraining strategies to learn general-purpose CT
representations. Volumetric CT poses unique challenges, such as extreme token
scaling, geometric anisotropy, and weak or noisy clinical supervision, that
make standard transformer and contrastive learning recipes ineffective out of
the box. The framework jointly optimizes a local transformer for
high-resolution volumetric feature extraction and a global transformer for
whole-scan context modeling, making large-scale 3D attention computationally
tractable. Notably, SPECTRE is trained exclusively on openly available CT
datasets, demonstrating that high-performing, generalizable representations can
be achieved without relying on private data. Pretraining combines DINO-style
self-distillation with SigLIP-based vision-language alignment using paired
radiology reports, yielding features that are both geometrically consistent and
clinically meaningful. Across multiple CT benchmarks, SPECTRE consistently
outperforms prior CT foundation models in both zero-shot and fine-tuned
settings, establishing SPECTRE as a scalable, open, and fully transformer-based
foundation model for 3D medical imaging.
\\ ( https://arxiv.org/abs/2511.17209 ,  1335kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17210
Date: Fri, 21 Nov 2025 12:42:07 GMT   (3587kb)

Title: FisheyeGaussianLift: BEV Feature Lifting for Surround-View Fisheye
 Camera Perception
Authors: Shubham Sonarghare, Prasad Deshpande, Ciaran Hogan, Deepika-Rani
 Kaliappan-Mahalingam, Ganesh Sistu
Categories: cs.CV
Comments: 8 pages, 3 figures, published in IMVIP 2025 conference
Journal-ref: Proceedings of the Irish Machine Vision and Image Processing
 Conference 2025 1 to 3 September 2025 Ulster University Derry Londonderry
 pages 50 to 57 ISBN 97800993420795
\\
 Accurate BEV semantic segmentation from fisheye imagery remains challenging
due to extreme non-linear distortion, occlusion, and depth ambiguity inherent
to wide-angle projections. We present a distortion-aware BEV segmentation
framework that directly processes multi-camera high-resolution fisheye
images,utilizing calibrated geometric unprojection and per-pixel depth
distribution estimation. Each image pixel is lifted into 3D space via Gaussian
parameterization, predicting spatial means and anisotropic covariances to
explicitly model geometric uncertainty. The projected 3D Gaussians are fused
into a BEV representation via differentiable splatting, producing continuous,
uncertainty-aware semantic maps without requiring undistortion or perspective
rectification. Extensive experiments demonstrate strong segmentation
performance on complex parking and urban driving scenarios, achieving IoU
scores of 87.75% for drivable regions and 57.26% for vehicles under severe
fisheye distortion and diverse environmental conditions.
\\ ( https://arxiv.org/abs/2511.17210 ,  3587kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17217
Date: Fri, 21 Nov 2025 12:57:23 GMT   (5252kb)

Title: Dual-domain Adaptation Networks for Realistic Image Super-resolution
Authors: Chaowei Fang, Bolin Fu, De Cheng, Lechao Cheng, Guanbin Li
Categories: cs.CV
\\
 Realistic image super-resolution (SR) focuses on transforming real-world
low-resolution (LR) images into high-resolution (HR) ones, handling more
complex degradation patterns than synthetic SR tasks. This is critical for
applications like surveillance, medical imaging, and consumer electronics.
However, current methods struggle with limited real-world LR-HR data, impacting
the learning of basic image features. Pre-trained SR models from large-scale
synthetic datasets offer valuable prior knowledge, which can improve
generalization, speed up training, and reduce the need for extensive real-world
data in realistic SR tasks. In this paper, we introduce a novel approach,
Dual-domain Adaptation Networks, which is able to efficiently adapt pre-trained
image SR models from simulated to real-world datasets. To achieve this target,
we first set up a spatial-domain adaptation strategy through selectively
updating parameters of pre-trained models and employing the low-rank adaptation
technique to adjust frozen parameters. Recognizing that image super-resolution
involves recovering high-frequency components, we further integrate a frequency
domain adaptation branch into the adapted model, which combines the spectral
data of the input and the spatial-domain backbone's intermediate features to
infer HR frequency maps, enhancing the SR result. Experimental evaluations on
public realistic image SR benchmarks, including RealSR, D2CRealSR, and DRealSR,
demonstrate the superiority of our proposed method over existing
state-of-the-art models. Codes are available at:
https://github.com/dummerchen/DAN.
\\ ( https://arxiv.org/abs/2511.17217 ,  5252kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17221
Date: Fri, 21 Nov 2025 13:05:42 GMT   (36758kb)

Title: QueryOcc: Query-based Self-Supervision for 3D Semantic Occupancy
Authors: Adam Lilja and Ji Lan and Junsheng Fu and Lars Hammarstrand
Categories: cs.CV cs.RO
\\
 Learning 3D scene geometry and semantics from images is a core challenge in
computer vision and a key capability for autonomous driving. Since large-scale
3D annotation is prohibitively expensive, recent work explores self-supervised
learning directly from sensor data without manual labels. Existing approaches
either rely on 2D rendering consistency, where 3D structure emerges only
implicitly, or on discretized voxel grids from accumulated lidar point clouds,
limiting spatial precision and scalability. We introduce QueryOcc, a
query-based self-supervised framework that learns continuous 3D semantic
occupancy directly through independent 4D spatio-temporal queries sampled
across adjacent frames. The framework supports supervision from either
pseudo-point clouds derived from vision foundation models or raw lidar data. To
enable long-range supervision and reasoning under constant memory, we introduce
a contractive scene representation that preserves near-field detail while
smoothly compressing distant regions. QueryOcc surpasses previous camera-based
methods by 26% in semantic RayIoU on the self-supervised Occ3D-nuScenes
benchmark while running at 11.6 FPS, demonstrating that direct 4D query
supervision enables strong self-supervised occupancy learning.
https://research.zenseact.com/publications/queryocc/
\\ ( https://arxiv.org/abs/2511.17221 ,  36758kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17242
Date: Fri, 21 Nov 2025 13:41:47 GMT   (82kb)

Title: Equivariant-Aware Structured Pruning for Efficient Edge Deployment: A
 Comprehensive Framework with Adaptive Fine-Tuning
Authors: Mohammed Alnemari
Categories: cs.CV cs.LG
Comments: 8 pages, 5 tables, 1 figure. Accepted at IEEE EdgeCom 2025 (11th IEEE
 International Conference on Edge Computing and Scalable Cloud)
\\
 This paper presents a novel framework combining group equivariant
convolutional neural networks (G-CNNs) with equivariant-aware structured
pruning to produce compact, transformation-invariant models for
resource-constrained environments. Equivariance to rotations is achieved
through the C4 cyclic group via the e2cnn library,enabling consistent
performance under geometric transformations while reducing computational
overhead.
 Our approach introduces structured pruning that preserves equivariant
properties by analyzing e2cnn layer structure and applying neuron-level pruning
to fully connected components. To mitigate accuracy degradation, we implement
adaptive fine-tuning that automatically triggers when accuracy drop exceeds 2%,
using early stopping and learning rate scheduling for efficient recovery. The
framework includes dynamic INT8 quantization and a comprehensive pipeline
encompassing training, knowledge distillation, structured pruning, fine-tuning,
and quantization.
 We evaluate our method on satellite imagery (EuroSAT) and standard benchmarks
(CIFAR-10, Rotated MNIST) demonstrating effectiveness across diverse domains.
Experimental results show 29.3% parameter reduction with significant accuracy
recovery, demonstrating that structured pruning of equivariant networks
achieves substantial compression while maintaining geometric robustness. Our
pipeline provides a reproducible framework for optimizing equivariant models,
bridging the gap between group-theoretic network design and practical
deployment constraints, with particular relevance to satellite imagery analysis
and geometric vision tasks.
\\ ( https://arxiv.org/abs/2511.17242 ,  82kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17253
Date: Fri, 21 Nov 2025 13:57:23 GMT   (45469kb)

Title: Blind Deconvolution for Color Images Using Normalized Quaternion Kernels
Authors: Yuming Yang, Michael K. Ng, Zhigang Jia, Wei Wang
Categories: cs.CV
\\
 In this work, we address the challenging problem of blind deconvolution for
color images. Existing methods often convert color images to grayscale or
process each color channel separately, which overlooking the relationships
between color channels. To handle this issue, we formulate a novel quaternion
fidelity term designed specifically for color image blind deconvolution. This
fidelity term leverages the properties of quaternion convolution kernel, which
consists of four kernels: one that functions similarly to a non-negative
convolution kernel to capture the overall blur, and three additional
convolution kernels without constraints corresponding to red, green and blue
channels respectively model their unknown interdependencies. In order to
preserve image intensity, we propose to use the normalized quaternion kernel in
the blind deconvolution process. Extensive experiments on real datasets of
blurred color images show that the proposed method effectively removes
artifacts and significantly improves deblurring effect, demonstrating its
potential as a powerful tool for color image deconvolution.
\\ ( https://arxiv.org/abs/2511.17253 ,  45469kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17254
Date: Fri, 21 Nov 2025 13:57:38 GMT   (11472kb)

Title: Intervene-All-Paths: Unified Mitigation of LVLM Hallucinations across
 Alignment Formats
Authors: Jiaye Qian, Ge Zheng, Yuchen Zhu, Sibei Yang
Categories: cs.CV cs.AI
Comments: Accepted to NeurIPS 2025, Project Page:
 https://github.com/SooLab/AllPath
\\
 Despite their impressive performance across a wide range of tasks, Large
Vision-Language Models (LVLMs) remain prone to hallucination. In this study, we
propose a comprehensive intervention framework aligned with the transformer's
causal architecture in LVLMs, integrating the effects of different intervention
paths on hallucination. We find that hallucinations in LVLMs do not arise from
a single causal path, but rather from the interplay among image-to-input-text,
image-to-output-text, and text-to-text pathways. For the first time, we also
find that LVLMs rely on different pathways depending on the question-answer
alignment format. Building on these insights, we propose simple yet effective
methods to identify and intervene on critical hallucination heads within each
pathway, tailored to discriminative and generative formats. Experiments across
multiple benchmarks demonstrate that our approach consistently reduces
hallucinations across diverse alignment types.
\\ ( https://arxiv.org/abs/2511.17254 ,  11472kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17255
Date: Fri, 21 Nov 2025 14:01:36 GMT   (18809kb)

Title: A Little More Like This: Text-to-Image Retrieval with Vision-Language
 Models Using Relevance Feedback
Authors: Bulat Khaertdinov, Mirela Popa, Nava Tintarev
Categories: cs.CV cs.IR
Comments: Accepted to WACV'26
\\
 Large vision-language models (VLMs) enable intuitive visual search using
natural language queries. However, improving their performance often requires
fine-tuning and scaling to larger model variants. In this work, we propose a
mechanism inspired by traditional text-based search to improve retrieval
performance at inference time: relevance feedback. While relevance feedback can
serve as an alternative to fine-tuning, its model-agnostic design also enables
use with fine-tuned VLMs. Specifically, we introduce and evaluate four feedback
strategies for VLM-based retrieval. First, we revise classical pseudo-relevance
feedback (PRF), which refines query embeddings based on top-ranked results. To
address its limitations, we propose generative relevance feedback (GRF), which
uses synthetic captions for query refinement. Furthermore, we introduce an
attentive feedback summarizer (AFS), a custom transformer-based model that
integrates multimodal fine-grained features from relevant items. Finally, we
simulate explicit feedback using ground-truth captions as an upper-bound
baseline. Experiments on Flickr30k and COCO with the VLM backbones show that
GRF, AFS, and explicit feedback improve retrieval performance by 3-5% in MRR@5
for smaller VLMs, and 1-3% for larger ones, compared to retrieval with no
feedback. Moreover, AFS, similarly to explicit feedback, mitigates query drift
and is more robust than GRF in iterative, multi-turn retrieval settings. Our
findings demonstrate that relevance feedback can consistently enhance retrieval
across VLMs and open up opportunities for interactive and adaptive visual
search.
\\ ( https://arxiv.org/abs/2511.17255 ,  18809kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17269
Date: Fri, 21 Nov 2025 14:16:27 GMT   (21485kb)

Title: Range-Edit: Semantic Mask Guided Outdoor LiDAR Scene Editing
Authors: Suchetan G. Uppur, Hemant Kumar, Vaibhav Kumar
Categories: cs.CV cs.AI
Comments: 8 pages, 9 figures
\\
 Training autonomous driving and navigation systems requires large and diverse
point cloud datasets that capture complex edge case scenarios from various
dynamic urban settings. Acquiring such diverse scenarios from real-world point
cloud data, especially for critical edge cases, is challenging, which restricts
system generalization and robustness. Current methods rely on simulating point
cloud data within handcrafted 3D virtual environments, which is time-consuming,
computationally expensive, and often fails to fully capture the complexity of
real-world scenes. To address some of these issues, this research proposes a
novel approach that addresses the problem discussed by editing real-world LiDAR
scans using semantic mask-based guidance to generate novel synthetic LiDAR
point clouds. We incorporate range image projection and semantic mask
conditioning to achieve diffusion-based generation. Point clouds are
transformed to 2D range view images, which are used as an intermediate
representation to enable semantic editing using convex hull-based semantic
masks. These masks guide the generation process by providing information on the
dimensions, orientations, and locations of objects in the real environment,
ensuring geometric consistency and realism. This approach demonstrates
high-quality LiDAR point cloud generation, capable of producing complex edge
cases and dynamic scenes, as validated on the KITTI-360 dataset. This offers a
cost-effective and scalable solution for generating diverse LiDAR data, a step
toward improving the robustness of autonomous driving systems.
\\ ( https://arxiv.org/abs/2511.17269 ,  21485kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17282
Date: Fri, 21 Nov 2025 14:40:50 GMT   (20773kb)

Title: Where Culture Fades: Revealing the Cultural Gap in Text-to-Image
 Generation
Authors: Chuancheng Shi, Shangze Li, Shiming Guo, Simiao Xie, Wenhua Wu,
 Jingtong Dou, Chao Wu, Canran Xiao, Cong Wang, Zifeng Cheng, Fei Shen,
 Tat-Seng Chua
Categories: cs.CV cs.AI cs.CY
\\
 Multilingual text-to-image (T2I) models have advanced rapidly in terms of
visual realism and semantic alignment, and are now widely utilized. Yet outputs
vary across cultural contexts: because language carries cultural connotations,
images synthesized from multilingual prompts should preserve cross-lingual
cultural consistency. We conduct a comprehensive analysis showing that current
T2I models often produce culturally neutral or English-biased results under
multilingual prompts. Analyses of two representative models indicate that the
issue stems not from missing cultural knowledge but from insufficient
activation of culture-related representations. We propose a probing method that
localizes culture-sensitive signals to a small set of neurons in a few fixed
layers. Guided by this finding, we introduce two complementary alignment
strategies: (1) inference-time cultural activation that amplifies the
identified neurons without backbone fine-tuned; and (2) layer-targeted cultural
enhancement that updates only culturally relevant layers. Experiments on our
CultureBench demonstrate consistent improvements over strong baselines in
cultural consistency while preserving fidelity and diversity.
\\ ( https://arxiv.org/abs/2511.17282 ,  20773kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17300
Date: Fri, 21 Nov 2025 15:11:47 GMT   (1800kb)

Title: MolSight: Optical Chemical Structure Recognition with SMILES
 Pretraining, Multi-Granularity Learning and Reinforcement Learning
Authors: Wenrui Zhang, Xinggang Wang, Bin Feng, Wenyu Liu
Categories: cs.CV
\\
 Optical Chemical Structure Recognition (OCSR) plays a pivotal role in modern
chemical informatics, enabling the automated conversion of chemical structure
images from scientific literature, patents, and educational materials into
machine-readable molecular representations. This capability is essential for
large-scale chemical data mining, drug discovery pipelines, and Large Language
Model (LLM) applications in related domains. However, existing OCSR systems
face significant challenges in accurately recognizing stereochemical
information due to the subtle visual cues that distinguish stereoisomers, such
as wedge and dash bonds, ring conformations, and spatial arrangements. To
address these challenges, we propose MolSight, a comprehensive learning
framework for OCSR that employs a three-stage training paradigm. In the first
stage, we conduct pre-training on large-scale but noisy datasets to endow the
model with fundamental perception capabilities for chemical structure images.
In the second stage, we perform multi-granularity fine-tuning using datasets
with richer supervisory signals, systematically exploring how auxiliary
tasks-specifically chemical bond classification and atom
localization-contribute to molecular formula recognition. Finally, we employ
reinforcement learning for post-training optimization and introduce a novel
stereochemical structure dataset. Remarkably, we find that even with MolSight's
relatively compact parameter size, the Group Relative Policy Optimization
(GRPO) algorithm can further enhance the model's performance on
stereomolecular. Through extensive experiments across diverse datasets, our
results demonstrate that MolSight achieves state-of-the-art performance in
(stereo)chemical optical structure recognition.
\\ ( https://arxiv.org/abs/2511.17300 ,  1800kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17306
Date: Fri, 21 Nov 2025 15:21:28 GMT   (4577kb)

Title: BiFingerPose: Bimodal Finger Pose Estimation for Touch Devices
Authors: Xiongjun Guan, Zhiyu Pan, Jianjiang Feng, Jie Zhou
Categories: cs.CV
\\
 Finger pose offers promising opportunities to expand human computer
interaction capability of touchscreen devices. Existing finger pose estimation
algorithms that can be implemented in portable devices predominantly rely on
capacitive images, which are currently limited to estimating pitch and yaw
angles and exhibit reduced accuracy when processing large-angle inputs
(especially when it is greater than 45 degrees). In this paper, we propose
BiFingerPose, a novel bimodal based finger pose estimation algorithm capable of
simultaneously and accurately predicting comprehensive finger pose information.
A bimodal input is explored, including a capacitive image and a fingerprint
patch obtained from the touchscreen with an under-screen fingerprint sensor.
Our approach leads to reliable estimation of roll angle, which is not
achievable using only a single modality. In addition, the prediction
performance of other pose parameters has also been greatly improved. The
evaluation of a 12-person user study on continuous and discrete interaction
tasks further validated the advantages of our approach. Specifically,
BiFingerPose outperforms previous SOTA methods with over 21% improvement in
prediction performance, 2.5 times higher task completion efficiency, and 23%
better user operation accuracy, demonstrating its practical superiority.
Finally, we delineate the application space of finger pose with respect to
enhancing authentication security and improving interactive experiences, and
develop corresponding prototypes to showcase the interaction potential. Our
code will be available at https://github.com/XiongjunGuan/DualFingerPose.
\\ ( https://arxiv.org/abs/2511.17306 ,  4577kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17308
Date: Fri, 21 Nov 2025 15:24:33 GMT   (7726kb)

Title: SpatialGeo:Boosting Spatial Reasoning in Multimodal LLMs via
 Geometry-Semantics Fusion
Authors: Jiajie Guo, Qingpeng Zhu, Jin Zeng, Xiaolong Wu, Changyong He, Weida
 Wang
Categories: cs.CV
\\
 Multimodal large language models (MLLMs) have achieved significant progress
in image and language tasks due to the strong reasoning capability of large
language models (LLMs). Nevertheless, most MLLMs suffer from limited spatial
reasoning ability to interpret and infer spatial arrangements in
three-dimensional space. In this work, we propose a novel vision encoder based
on hierarchical fusion of geometry and semantics features, generating
spatial-aware visual embedding and boosting the spatial grounding capability of
MLLMs. Specifically, we first unveil that the spatial ambiguity shortcoming
stems from the lossy embedding of the vision encoder utilized in most existing
MLLMs (e.g., CLIP), restricted to instance-level semantic features. This
motivates us to complement CLIP with the geometry features from vision-only
self-supervised learning via a hierarchical adapter, enhancing the spatial
awareness in the proposed SpatialGeo. The network is efficiently trained using
pretrained LLaVA model and optimized with random feature dropping to avoid
trivial solutions relying solely on the CLIP encoder. Experimental results show
that SpatialGeo improves the accuracy in spatial reasoning tasks, enhancing
state-of-the-art models by at least 8.0% in SpatialRGPT-Bench with
approximately 50% less memory cost during inference. The source code is
available via https://ricky-plus.github.io/SpatialGeoPages/.
\\ ( https://arxiv.org/abs/2511.17308 ,  7726kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17309
Date: Fri, 21 Nov 2025 15:25:47 GMT   (9506kb)

Title: MuM: Multi-View Masked Image Modeling for 3D Vision
Authors: David Nordstr\"om, Johan Edstedt, Fredrik Kahl, Georg B\"okman
Categories: cs.CV cs.AI cs.LG
\\
 Self-supervised learning on images seeks to extract meaningful visual
representations from unlabeled data. When scaled to large datasets, this
paradigm has achieved state-of-the-art performance and the resulting trained
models such as DINOv3 have seen widespread adoption. However, most prior
efforts are optimized for semantic understanding rather than geometric
reasoning. One important exception is Cross-View Completion, CroCo, which is a
form of masked autoencoding (MAE) tailored for 3D understanding. In this work,
we continue on the path proposed by CroCo and focus on learning features
tailored for 3D vision. In a nutshell, we extend MAE to arbitrarily many views
of the same scene. By uniformly masking all views and employing a lightweight
decoder with inter-frame attention, our approach is inherently simpler and more
scalable than CroCo. We evaluate the resulting model, MuM, extensively on
downstream tasks including feedforward reconstruction, dense image matching and
relative pose estimation, finding that it outperforms the state-of-the-art
visual encoders DINOv3 and CroCo v2.
\\ ( https://arxiv.org/abs/2511.17309 ,  9506kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17322
Date: Fri, 21 Nov 2025 15:41:51 GMT   (33217kb)

Title: NoPe-NeRF++: Local-to-Global Optimization of NeRF with No Pose Prior
Authors: Dongbo Shi, Shen Cao, Bojian Wu, Jinhui Guo, Lubin Fan, Renjie Chen,
 Ligang Liu, Jieping Ye
Categories: cs.CV
Journal-ref: Eurographics 2025
DOI: 10.1111/cgf.70012
\\
 In this paper, we introduce NoPe-NeRF++, a novel local-to-global optimization
algorithm for training Neural Radiance Fields (NeRF) without requiring pose
priors. Existing methods, particularly NoPe-NeRF, which focus solely on the
local relationships within images, often struggle to recover accurate camera
poses in complex scenarios. To overcome the challenges, our approach begins
with a relative pose initialization with explicit feature matching, followed by
a local joint optimization to enhance the pose estimation for training a more
robust NeRF representation. This method significantly improves the quality of
initial poses. Additionally, we introduce global optimization phase that
incorporates geometric consistency constraints through bundle adjustment, which
integrates feature trajectories to further refine poses and collectively boost
the quality of NeRF. Notably, our method is the first work that seamlessly
combines the local and global cues with NeRF, and outperforms state-of-the-art
methods in both pose estimation accuracy and novel view synthesis. Extensive
evaluations on benchmark datasets demonstrate our superior performance and
robustness, even in challenging scenes, thus validating our design choices.
\\ ( https://arxiv.org/abs/2511.17322 ,  33217kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17340
Date: Fri, 21 Nov 2025 16:02:44 GMT   (17431kb)

Title: Refracting Reality: Generating Images with Realistic Transparent Objects
Authors: Yue Yin, Enze Tao, Dylan Campbell
Categories: cs.CV
\\
 Generative image models can produce convincingly real images, with plausible
shapes, textures, layouts and lighting. However, one domain in which they
perform notably poorly is in the synthesis of transparent objects, which
exhibit refraction, reflection, absorption and scattering. Refraction is a
particular challenge, because refracted pixel rays often intersect with
surfaces observed in other parts of the image, providing a constraint on the
color. It is clear from inspection that generative models have not distilled
the laws of optics sufficiently well to accurately render refractive objects.
In this work, we consider the problem of generating images with accurate
refraction, given a text prompt. We synchronize the pixels within the object's
boundary with those outside by warping and merging the pixels using Snell's Law
of Refraction, at each step of the generation trajectory. For those surfaces
that are not directly observed in the image, but are visible via refraction or
reflection, we recover their appearance by synchronizing the image with a
second generated image -- a panorama centered at the object -- using the same
warping and merging procedure. We demonstrate that our approach generates much
more optically-plausible images that respect the physical constraints.
\\ ( https://arxiv.org/abs/2511.17340 ,  17431kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17344
Date: Fri, 21 Nov 2025 16:06:32 GMT   (12265kb)

Title: Loomis Painter: Reconstructing the Painting Process
Authors: Markus Pobitzer, Chang Liu, Chenyi Zhuang, Teng Long, Bin Ren, Nicu
 Sebe
Categories: cs.CV
\\
 Step-by-step painting tutorials are vital for learning artistic techniques,
but existing video resources (e.g., YouTube) lack interactivity and
personalization. While recent generative models have advanced artistic image
synthesis, they struggle to generalize across media and often show temporal or
structural inconsistencies, hindering faithful reproduction of human creative
workflows. To address this, we propose a unified framework for multi-media
painting process generation with a semantics-driven style control mechanism
that embeds multiple media into a diffusion models conditional space and uses
cross-medium style augmentation. This enables consistent texture evolution and
process transfer across styles. A reverse-painting training strategy further
ensures smooth, human-aligned generation. We also build a large-scale dataset
of real painting processes and evaluate cross-media consistency, temporal
coherence, and final-image fidelity, achieving strong results on LPIPS, DINO,
and CLIP metrics. Finally, our Perceptual Distance Profile (PDP) curve
quantitatively models the creative sequence, i.e., composition, color blocking,
and detail refinement, mirroring human artistic progression.
\\ ( https://arxiv.org/abs/2511.17344 ,  12265kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17345
Date: Fri, 21 Nov 2025 16:06:53 GMT   (21kb)

Title: Label-Efficient Skeleton-based Recognition with Stable-Invertible Graph
 Convolutional Networks
Authors: Hichem Sahbi
Categories: cs.CV
\\
 Skeleton-based action recognition is a hotspot in image processing. A key
challenge of this task lies in its dependence on large, manually labeled
datasets whose acquisition is costly and time-consuming. This paper devises a
novel, label-efficient method for skeleton-based action recognition using graph
convolutional networks (GCNs). The contribution of the proposed method resides
in learning a novel acquisition function -- scoring the most informative
subsets for labeling -- as the optimum of an objective function mixing data
representativity, diversity and uncertainty. We also extend this approach by
learning the most informative subsets using an invertible GCN which allows
mapping data from ambient to latent spaces where the inherent distribution of
the data is more easily captured. Extensive experiments, conducted on two
challenging skeleton-based recognition datasets, show the effectiveness and the
outperformance of our label-frugal GCNs against the related work.
\\ ( https://arxiv.org/abs/2511.17345 ,  21kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17354
Date: Fri, 21 Nov 2025 16:18:50 GMT   (8220kb)

Title: DSeq-JEPA: Discriminative Sequential Joint-Embedding Predictive
 Architecture
Authors: Xiangteng He, Shunsuke Sakai, Kun Yuan, Nicolas Padoy, Tatsuhito
 Hasegawa, Leonid Sigal
Categories: cs.CV
Comments: Project page: https://github.com/SkyShunsuke/DSeq-JEPA
\\
 Image-based Joint-Embedding Predictive Architecture (I-JEPA) learns visual
representations by predicting latent embeddings of masked regions from visible
context. However, it treats all regions uniformly and independently, lacking an
explicit notion of where or in what order predictions should be made. Inspired
by human visual perception, which deploys attention selectively and
sequentially from the most informative to secondary regions, we propose
DSeq-JEPA, a Discriminative Sequential Joint-Embedding Predictive Architecture
that bridges predictive and autoregressive self-supervised learning,
integrating JEPA-style latent prediction with GPT-style sequential reasoning.
Specifically, DSeq-JEPA (i) first identifies primary discriminative regions
based on a transformer-derived saliency map, emphasizing the distribution of
visual importance, and then (ii) predicts subsequent regions in this
discriminative order, progressively forming a curriculum-like semantic
progression from primary to secondary cues -- a form of GPT-style pre-training.
Extensive experiments across diverse tasks, including image classification
(ImageNet), fine-grained visual categorization (iNaturalist21, CUB-200-2011,
Stanford-Cars), detection and segmentation (MS-COCO, ADE20K), and low-level
reasoning tasks (Clevr/Count, Clevr/Dist), demonstrate that DSeq-JEPA
consistently focuses on more discriminative and generalizable representations
than I-JEPA variants. Project page: https://github.com/SkyShunsuke/DSeq-JEPA.
\\ ( https://arxiv.org/abs/2511.17354 ,  8220kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17355
Date: Fri, 21 Nov 2025 16:18:55 GMT   (6390kb)

Title: UAM: A Unified Attention-Mamba Backbone of Multimodal Framework for
 Tumor Cell Classification
Authors: Taixi Chen, Jingyun Chen, Nancy Guo
Categories: cs.CV
\\
 Cell-level radiomics features provide fine-grained insights into tumor
phenotypes and have the potential to significantly enhance diagnostic accuracy
on hematoxylin and eosin (H&E) images. By capturing micro-level morphological
and intensity patterns, these features support more precise tumor
identification and improve AI interpretability by highlighting diagnostically
relevant cells for pathologist review. However, most existing studies focus on
slide-level or patch-level tumor classification, leaving cell-level radiomics
analysis largely unexplored. Moreover, there is currently no dedicated backbone
specifically designed for radiomics data. Inspired by the recent success of the
Mamba architecture in vision and language domains, we introduce a Unified
Attention-Mamba (UAM) backbone for cell-level classification using radiomics
features. Unlike previous hybrid approaches that integrate Attention and Mamba
modules in fixed proportions, our unified design flexibly combines their
capabilities within a single cohesive architecture, eliminating the need for
manual ratio tuning and improving encode capability. We develop two UAM
variants to comprehensively evaluate the benefits of this unified structure.
Building on this backbone, we further propose a multimodal UAM framework that
jointly performs cell-level classification and image segmentation. Experimental
results demonstrate that UAM achieves state-of-the-art performance across both
tasks on public benchmarks, surpassing leading image-based foundation models.
It improves cell classification accuracy from 74% to 78% ($n$=349,882 cells),
and tumor segmentation precision from 75% to 80% ($n$=406 patches). These
findings highlight the effectiveness and promise of UAM as a unified and
extensible multimodal foundation for radiomics-driven cancer diagnosis.
\\ ( https://arxiv.org/abs/2511.17355 ,  6390kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17361
Date: Fri, 21 Nov 2025 16:26:31 GMT   (15959kb)

Title: SuperQuadricOcc: Multi-Layer Gaussian Approximation of Superquadrics for
 Real-Time Self-Supervised Occupancy Estimation
Authors: Seamie Hayes, Reenu Mohandas, Tim Brophy, Alexandre Boulch, Ganesh
 Sistu, Ciaran Eising
Categories: cs.CV
\\
 Semantic occupancy estimation enables comprehensive scene understanding for
automated driving, providing dense spatial and semantic information essential
for perception and planning. While Gaussian representations have been widely
adopted in self-supervised occupancy estimation, the deployment of a large
number of Gaussian primitives drastically increases memory requirements and is
not suitable for real-time inference. In contrast, superquadrics permit reduced
primitive count and lower memory requirements due to their diverse shape set.
However, implementation into a self-supervised occupancy model is nontrivial
due to the absence of a superquadric rasterizer to enable model supervision.
Our proposed method, SuperQuadricOcc, employs a superquadric-based scene
representation. By leveraging a multi-layer icosphere-tessellated Gaussian
approximation of superquadrics, we enable Gaussian rasterization for
supervision during training. On the Occ3D dataset, SuperQuadricOcc achieves a
75\% reduction in memory footprint, 124\% faster inference, and a 5.9\%
improvement in mIoU compared to previous Gaussian-based methods, without the
use of temporal labels. To our knowledge, this is the first occupancy model to
enable real-time inference while maintaining competitive performance. The use
of superquadrics reduces the number of primitives required for scene modeling
by 84\% relative to Gaussian-based approaches. Finally, evaluation against
prior methods is facilitated by our fast superquadric voxelization module. The
code will be released as open source.
\\ ( https://arxiv.org/abs/2511.17361 ,  15959kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17362
Date: Fri, 21 Nov 2025 16:30:06 GMT   (1964kb)

Title: ATAC: Augmentation-Based Test-Time Adversarial Correction for CLIP
Authors: Linxiang Su, Andr\'as Balogh
Categories: cs.CV
Comments: 16 pages
\\
 Despite its remarkable success in zero-shot image-text matching, CLIP remains
highly vulnerable to adversarial perturbations on images. As adversarial
fine-tuning is prohibitively costly, recent works explore various test-time
defense strategies; however, these approaches still exhibit limited robustness.
In this work, we revisit this problem and propose a simple yet effective
strategy: Augmentation-based Test-time Adversarial Correction (ATAC). Our
method operates directly in the embedding space of CLIP, calculating
augmentation-induced drift vectors to infer a semantic recovery direction and
correcting the embedding based on the angular consistency of these latent
drifts. Across a wide range of benchmarks, ATAC consistently achieves
remarkably high robustness, surpassing that of previous state-of-the-art
methods by nearly 50\% on average, all while requiring minimal computational
overhead. Furthermore, ATAC retains state-of-the-art robustness in
unconventional and extreme settings and even achieves nontrivial robustness
against adaptive attacks. Our results demonstrate that ATAC is an efficient
method in a novel paradigm for test-time adversarial defenses in the embedding
space of CLIP.
\\ ( https://arxiv.org/abs/2511.17362 ,  1964kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17364
Date: Fri, 21 Nov 2025 16:32:01 GMT   (15911kb)

Title: SVRecon: Sparse Voxel Rasterization for Surface Reconstruction
Authors: Seunghun Oh, Jaesung Choe, Dongjae Lee, Daeun Lee, Seunghoon Jeong,
 Yu-Chiang Frank Wang, Jaesik Park
Categories: cs.CV
\\
 We extend the recently proposed sparse voxel rasterization paradigm to the
task of high-fidelity surface reconstruction by integrating Signed Distance
Function (SDF), named SVRecon. Unlike 3D Gaussians, sparse voxels are spatially
disentangled from their neighbors and have sharp boundaries, which makes them
prone to local minima during optimization. Although SDF values provide a
naturally smooth and continuous geometric field, preserving this smoothness
across independently parameterized sparse voxels is nontrivial. To address this
challenge, we promote coherent and smooth voxel-wise structure through (1)
robust geometric initialization using a visual geometry model and (2) a spatial
smoothness loss that enforces coherent relationships across parent-child and
sibling voxel groups. Extensive experiments across various benchmarks show that
our method achieves strong reconstruction accuracy while having consistently
speedy convergence. The code will be made public.
\\ ( https://arxiv.org/abs/2511.17364 ,  15911kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17380
Date: Fri, 21 Nov 2025 16:44:01 GMT   (8681kb)

Title: Non-Parametric Probabilistic Robustness: A Conservative Metric with
 Optimized Perturbation Distributions
Authors: Zheng Wang, Yi Zhang, Siddartha Khastgir, Carsten Maple, Xingyu Zhao
Categories: cs.CV cs.LG
\\
 Deep learning (DL) models, despite their remarkable success, remain
vulnerable to small input perturbations that can cause erroneous outputs,
motivating the recent proposal of probabilistic robustness (PR) as a
complementary alternative to adversarial robustness (AR). However, existing PR
formulations assume a fixed and known perturbation distribution, an unrealistic
expectation in practice. To address this limitation, we propose non-parametric
probabilistic robustness (NPPR), a more practical PR metric that does not rely
on any predefined perturbation distribution. Following the non-parametric
paradigm in statistical modeling, NPPR learns an optimized perturbation
distribution directly from data, enabling conservative PR evaluation under
distributional uncertainty. We further develop an NPPR estimator based on a
Gaussian Mixture Model (GMM) with Multilayer Perceptron (MLP) heads and bicubic
up-sampling, covering various input-dependent and input-independent
perturbation scenarios. Theoretical analyses establish the relationships among
AR, PR, and NPPR. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny
ImageNet across ResNet18/50, WideResNet50 and VGG16 validate NPPR as a more
practical robustness metric, showing up to 40\% more conservative (lower) PR
estimates compared to assuming those common perturbation distributions used in
state-of-the-arts.
\\ ( https://arxiv.org/abs/2511.17380 ,  8681kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17392
Date: Fri, 21 Nov 2025 16:52:20 GMT   (2964kb)

Title: MorphSeek: Fine-grained Latent Representation-Level Policy Optimization
 for Deformable Image Registration
Authors: Runxun Zhang and Yizhou Liu and Li Dongrui and Bo XU and Jingwei Wei
Categories: cs.CV
\\
 Deformable image registration (DIR) remains a fundamental yet challenging
problem in medical image analysis, largely due to the prohibitively
high-dimensional deformation space of dense displacement fields and the
scarcity of voxel-level supervision. Existing reinforcement learning frameworks
often project this space into coarse, low-dimensional representations, limiting
their ability to capture spatially variant deformations. We propose MorphSeek,
a fine-grained representation-level policy optimization paradigm that
reformulates DIR as a spatially continuous optimization process in the latent
feature space. MorphSeek introduces a stochastic Gaussian policy head atop the
encoder to model a distribution over latent features, facilitating efficient
exploration and coarse-to-fine refinement. The framework integrates
unsupervised warm-up with weakly supervised fine-tuning through Group Relative
Policy Optimization, where multi-trajectory sampling stabilizes training and
improves label efficiency. Across three 3D registration benchmarks (OASIS brain
MRI, LiTS liver CT, and Abdomen MR-CT), MorphSeek achieves consistent Dice
improvements over competitive baselines while maintaining high label efficiency
with minimal parameter cost and low step-level latency overhead. Beyond
optimizer specifics, MorphSeek advances a representation-level policy learning
paradigm that achieves spatially coherent and data-efficient deformation
optimization, offering a principled, backbone-agnostic, and optimizer-agnostic
solution for scalable visual alignment in high-dimensional settings.
\\ ( https://arxiv.org/abs/2511.17392 ,  2964kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17393
Date: Fri, 21 Nov 2025 16:53:08 GMT   (2095kb)

Title: Designing and Generating Diverse, Equitable Face Image Datasets for Face
 Verification Tasks
Authors: Georgia Baltsou, Ioannis Sarridis, Christos Koutlis, Symeon
 Papadopoulos
Categories: cs.CV cs.AI
\\
 Face verification is a significant component of identity authentication in
various applications including online banking and secure access to personal
devices. The majority of the existing face image datasets often suffer from
notable biases related to race, gender, and other demographic characteristics,
limiting the effectiveness and fairness of face verification systems. In
response to these challenges, we propose a comprehensive methodology that
integrates advanced generative models to create varied and diverse high-quality
synthetic face images. This methodology emphasizes the representation of a
diverse range of facial traits, ensuring adherence to characteristics
permissible in identity card photographs. Furthermore, we introduce the Diverse
and Inclusive Faces for Verification (DIF-V) dataset, comprising 27,780 images
of 926 unique identities, designed as a benchmark for future research in face
verification. Our analysis reveals that existing verification models exhibit
biases toward certain genders and races, and notably, applying identity style
modifications negatively impacts model performance. By tackling the inherent
inequities in existing datasets, this work not only enriches the discussion on
diversity and ethics in artificial intelligence but also lays the foundation
for developing more inclusive and reliable face verification technologies
\\ ( https://arxiv.org/abs/2511.17393 ,  2095kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17397
Date: Fri, 21 Nov 2025 16:56:25 GMT   (22516kb)

Title: MCMoE: Completing Missing Modalities with Mixture of Experts for
 Incomplete Multimodal Action Quality Assessment
Authors: Huangbiao Xu, Huanqi Wu, Xiao Ke, Junyi Wu, Rui Xu, Jinglin Xu
Categories: cs.CV
Comments: AAAI 2026
\\
 Multimodal Action Quality Assessment (AQA) has recently emerged as a
promising paradigm. By leveraging complementary information across shared
contextual cues, it enhances the discriminative evaluation of subtle
intra-class variations in highly similar action sequences. However, partial
modalities are frequently unavailable at the inference stage in reality. The
absence of any modality often renders existing multimodal models inoperable.
Furthermore, it triggers catastrophic performance degradation due to
interruptions in cross-modal interactions. To address this issue, we propose a
novel Missing Completion Framework with Mixture of Experts (MCMoE) that unifies
unimodal and joint representation learning in single-stage training.
Specifically, we propose an adaptive gated modality generator that dynamically
fuses available information to reconstruct missing modalities. We then design
modality experts to learn unimodal knowledge and dynamically mix the knowledge
of all experts to extract cross-modal joint representations. With a mixture of
experts, missing modalities are further refined and complemented. Finally, in
the training phase, we mine the complete multimodal features and unimodal
expert knowledge to guide modality generation and generation-based joint
representation extraction. Extensive experiments demonstrate that our MCMoE
achieves state-of-the-art results in both complete and incomplete multimodal
learning on three public AQA benchmarks. Code is available at
https://github.com/XuHuangbiao/MCMoE.
\\ ( https://arxiv.org/abs/2511.17397 ,  22516kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17400
Date: Fri, 21 Nov 2025 17:00:02 GMT   (1701kb)

Title: Sparse Mixture-of-Experts for Multi-Channel Imaging: Are All Channel
 Interactions Required?
Authors: Sukwon Yun, Heming Yao, Burkhard Hoeckendorf, David Richmond, Aviv
 Regev, Russell Littman
Categories: cs.CV cs.AI
Comments: This has been accepted at the NeurIPS AI4Science Workshop 2025
\\
 Vision Transformers ($\text{ViTs}$) have become the backbone of vision
foundation models, yet their optimization for multi-channel domains - such as
cell painting or satellite imagery - remains underexplored. A key challenge in
these domains is capturing interactions between channels, as each channel
carries different information. While existing works have shown efficacy by
treating each channel independently during tokenization, this approach
naturally introduces a major computational bottleneck in the attention block -
channel-wise comparisons leads to a quadratic growth in attention, resulting in
excessive $\text{FLOPs}$ and high training cost. In this work, we shift focus
from efficacy to the overlooked efficiency challenge in cross-channel attention
and ask: "Is it necessary to model all channel interactions?". Inspired by the
philosophy of Sparse Mixture-of-Experts ($\text{MoE}$), we propose MoE-ViT, a
Mixture-of-Experts architecture for multi-channel images in $\text{ViTs}$,
which treats each channel as an expert and employs a lightweight router to
select only the most relevant experts per patch for attention. Proof-of-concept
experiments on real-world datasets - JUMP-CP and So2Sat - demonstrate that
$\text{MoE-ViT}$ achieves substantial efficiency gains without sacrificing, and
in some cases enhancing, performance, making it a practical and attractive
backbone for multi-channel imaging.
\\ ( https://arxiv.org/abs/2511.17400 ,  1701kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17421
Date: Fri, 21 Nov 2025 17:18:35 GMT   (394kb)

Title: Preventing Shortcut Learning in Medical Image Analysis through
 Intermediate Layer Knowledge Distillation from Specialist Teachers
Authors: Christopher Boland, Sotirios Tsaftaris, Sonia Dahdouh
Categories: cs.CV cs.AI
Comments: Accepted for publication at the Journal of Machine Learning for
 Biomedical Imaging (MELBA) https://melba-journal.org/2025:020
Journal-ref: Machine.Learning.for.Biomedical.Imaging. 3 (2025)
DOI: 10.59275/j.melba.2025-8888
\\
 Deep learning models are prone to learning shortcut solutions to problems
using spuriously correlated yet irrelevant features of their training data. In
high-risk applications such as medical image analysis, this phenomenon may
prevent models from using clinically meaningful features when making
predictions, potentially leading to poor robustness and harm to patients. We
demonstrate that different types of shortcuts (those that are diffuse and
spread throughout the image, as well as those that are localized to specific
areas) manifest distinctly across network layers and can, therefore, be more
effectively targeted through mitigation strategies that target the intermediate
layers. We propose a novel knowledge distillation framework that leverages a
teacher network fine-tuned on a small subset of task-relevant data to mitigate
shortcut learning in a student network trained on a large dataset corrupted
with a bias feature. Through extensive experiments on CheXpert, ISIC 2017, and
SimBA datasets using various architectures (ResNet-18, AlexNet, DenseNet-121,
and 3D CNNs), we demonstrate consistent improvements over traditional Empirical
Risk Minimization, augmentation-based bias-mitigation, and group-based
bias-mitigation approaches. In many cases, we achieve comparable performance
with a baseline model trained on bias-free data, even on out-of-distribution
test data. Our results demonstrate the practical applicability of our approach
to real-world medical imaging scenarios where bias annotations are limited and
shortcut features are difficult to identify a priori.
\\ ( https://arxiv.org/abs/2511.17421 ,  394kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17442
Date: Fri, 21 Nov 2025 17:41:26 GMT   (294kb)

Title: REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing
Authors: Binger Chen, Tacettin Emre B\"ok, Behnood Rasti, Volker Markl, Beg\"um
 Demir
Categories: cs.CV cs.AI
Comments: Code and data available at https://github.com/be-chen/REMSA
\\
 Foundation Models (FMs) are increasingly used in remote sensing (RS) for
tasks such as environmental monitoring, disaster assessment, and land-use
mapping. These models include unimodal vision encoders trained on a single data
modality and multimodal architectures trained on combinations of SAR,
multispectral, hyperspectral, and image-text data. They support diverse RS
tasks including semantic segmentation, image classification, change detection,
and visual question answering. However, selecting an appropriate remote sensing
foundation model (RSFM) remains difficult due to scattered documentation,
heterogeneous formats, and varied deployment constraints. We introduce the RSFM
Database (RS-FMD), a structured resource covering over 150 RSFMs spanning
multiple data modalities, resolutions, and learning paradigms. Built on RS-FMD,
we present REMSA, the first LLM-based agent for automated RSFM selection from
natural language queries. REMSA interprets user requirements, resolves missing
constraints, ranks candidate models using in-context learning, and provides
transparent justifications. We also propose a benchmark of 75 expert-verified
RS query scenarios, producing 900 configurations under an expert-centered
evaluation protocol. REMSA outperforms several baselines, including naive
agents, dense retrieval, and unstructured RAG-based LLMs. It operates entirely
on publicly available metadata and does not access private or sensitive data.
\\ ( https://arxiv.org/abs/2511.17442 ,  294kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17448
Date: Fri, 21 Nov 2025 17:46:44 GMT   (5223kb)

Title: MMT-ARD: Multimodal Multi-Teacher Adversarial Distillation for Robust
 Vision-Language Models
Authors: Yuqi Li, Junhao Dong, Chuanguang Yang, Shiping Wen, Piotr Koniusz,
 Tingwen Huang, Yingli Tian, Yew-Soon Ong
Categories: cs.CV
Comments: 10 pages
\\
 Vision-Language Models (VLMs) are increasingly deployed in safety-critical
applications, making their adversarial robustness a crucial concern. While
adversarial knowledge distillation has shown promise in transferring robustness
from teacher to student models, traditional single-teacher approaches suffer
from limited knowledge diversity, slow convergence, and difficulty in balancing
robustness and accuracy. To address these challenges, we propose MMT-ARD: a
Multimodal Multi-Teacher Adversarial Robust Distillation framework. Our key
innovation is a dual-teacher knowledge fusion architecture that collaboratively
optimizes clean feature preservation and robust feature enhancement. To better
handle challenging adversarial examples, we introduce a dynamic weight
allocation strategy based on teacher confidence, enabling adaptive focus on
harder samples. Moreover, to mitigate bias among teachers, we design an
adaptive sigmoid-based weighting function that balances the strength of
knowledge transfer across modalities. Extensive experiments on ImageNet and
zero-shot benchmarks demonstrate that MMT-ARD improves robust accuracy by
+4.32% and zero-shot accuracy by +3.5% on the ViT-B-32 model, while achieving a
2.3x increase in training efficiency over traditional single-teacher methods.
These results highlight the effectiveness and scalability of MMT-ARD in
enhancing the adversarial robustness of multimodal large models. Our codes are
available at https://github.com/itsnotacie/MMT-ARD.
\\ ( https://arxiv.org/abs/2511.17448 ,  5223kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17450
Date: Fri, 21 Nov 2025 17:48:02 GMT   (15399kb)

Title: Planning with Sketch-Guided Verification for Physics-Aware Video
 Generation
Authors: Yidong Huang, Zun Wang, Han Lin, Dong-Ki Kim, Shayegan Omidshafiei,
 Jaehong Yoon, Yue Zhang, Mohit Bansal
Categories: cs.CV cs.AI cs.CL
Comments: website: https://sketchverify.github.io/
\\
 Recent video generation approaches increasingly rely on planning intermediate
control signals such as object trajectories to improve temporal coherence and
motion fidelity. However, these methods mostly employ single-shot plans that
are typically limited to simple motions, or iterative refinement which requires
multiple calls to the video generator, incuring high computational cost. To
overcome these limitations, we propose SketchVerify, a training-free,
sketch-verification-based planning framework that improves motion planning
quality with more dynamically coherent trajectories (i.e., physically plausible
and instruction-consistent motions) prior to full video generation by
introducing a test-time sampling and verification loop. Given a prompt and a
reference image, our method predicts multiple candidate motion plans and ranks
them using a vision-language verifier that jointly evaluates semantic alignment
with the instruction and physical plausibility. To efficiently score candidate
motion plans, we render each trajectory as a lightweight video sketch by
compositing objects over a static background, which bypasses the need for
expensive, repeated diffusion-based synthesis while achieving comparable
performance. We iteratively refine the motion plan until a satisfactory one is
identified, which is then passed to the trajectory-conditioned generator for
final synthesis. Experiments on WorldModelBench and PhyWorldBench demonstrate
that our method significantly improves motion quality, physical realism, and
long-term consistency compared to competitive baselines while being
substantially more efficient. Our ablation study further shows that scaling up
the number of trajectory candidates consistently enhances overall performance.
\\ ( https://arxiv.org/abs/2511.17450 ,  15399kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17454
Date: Fri, 21 Nov 2025 17:56:43 GMT   (33189kb)

Title: Illustrator's Depth: Monocular Layer Index Prediction for Image
 Decomposition
Authors: Nissim Maruani, Peiying Zhang, Siddhartha Chaudhuri, Matthew Fisher,
 Nanxuan Zhao, Vladimir G. Kim, Pierre Alliez, Mathieu Desbrun, Wang Yifan
Categories: cs.CV
\\
 We introduce Illustrator's Depth, a novel definition of depth that addresses
a key challenge in digital content creation: decomposing flat images into
editable, ordered layers. Inspired by an artist's compositional process,
illustrator's depth infers a layer index to each pixel, forming an
interpretable image decomposition through a discrete, globally consistent
ordering of elements optimized for editability. We also propose and train a
neural network using a curated dataset of layered vector graphics to predict
layering directly from raster inputs. Our layer index inference unlocks a range
of powerful downstream applications. In particular, it significantly
outperforms state-of-the-art baselines for image vectorization while also
enabling high-fidelity text-to-vector-graphics generation, automatic 3D relief
generation from 2D images, and intuitive depth-aware editing. By reframing
depth from a physical quantity to a creative abstraction, illustrator's depth
prediction offers a new foundation for editable image decomposition.
\\ ( https://arxiv.org/abs/2511.17454 ,  33189kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17455
Date: Fri, 21 Nov 2025 17:57:43 GMT   (6811kb)

Title: Improving Multimodal Distillation for 3D Semantic Segmentation under
 Domain Shift
Authors: Bj\"orn Michele, Alexandre Boulch, Gilles Puy, Tuan-Hung Vu, Renaud
 Marlet, Nicolas Courty
Categories: cs.CV
Comments: Accepted at BMVC 2025
\\
 Semantic segmentation networks trained under full supervision for one type of
lidar fail to generalize to unseen lidars without intervention. To reduce the
performance gap under domain shifts, a recent trend is to leverage vision
foundation models (VFMs) providing robust features across domains. In this
work, we conduct an exhaustive study to identify recipes for exploiting VFMs in
unsupervised domain adaptation for semantic segmentation of lidar point clouds.
Building upon unsupervised image-to-lidar knowledge distillation, our study
reveals that: (1) the architecture of the lidar backbone is key to maximize the
generalization performance on a target domain; (2) it is possible to pretrain a
single backbone once and for all, and use it to address many domain shifts; (3)
best results are obtained by keeping the pretrained backbone frozen and
training an MLP head for semantic segmentation. The resulting pipeline achieves
state-of-the-art results in four widely-recognized and challenging settings.
The code will be available at: https://github.com/valeoai/muddos.
\\ ( https://arxiv.org/abs/2511.17455 ,  6811kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17457
Date: Fri, 21 Nov 2025 17:59:17 GMT   (3331kb)

Title: GPR-OdomNet: Difference and Similarity-Driven Odometry Estimation
 Network for Ground Penetrating Radar-Based Localization
Authors: Huaichao Wang, Xuanxin Fan, Ji Liu, Haifeng Li and Dezhen Song
Categories: cs.CV
\\
 When performing robot/vehicle localization using ground penetrating radar
(GPR) to handle adverse weather and environmental conditions, existing
techniques often struggle to accurately estimate distances when processing
B-scan images with minor distinctions. This study introduces a new neural
network-based odometry method that leverages the similarity and difference
features of GPR B-scan images for precise estimation of the Euclidean distances
traveled between the B-scan images. The new custom neural network extracts
multi-scale features from B-scan images taken at consecutive moments and then
determines the Euclidean distance traveled by analyzing the similarities and
differences between these features. To evaluate our method, an ablation study
and comparison experiments have been conducted using the publicly available
CMU-GPR dataset. The experimental results show that our method consistently
outperforms state-of-the-art counterparts in all tests. Specifically, our
method achieves a root mean square error (RMSE), and achieves an overall
weighted RMSE of 0.449 m across all data sets, which is a 10.2\% reduction in
RMSE when compared to the best state-of-the-art method.
\\ ( https://arxiv.org/abs/2511.17457 ,  3331kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17481
Date: Fri, 21 Nov 2025 18:37:23 GMT   (2319kb)

Title: Counterfactual World Models via Digital Twin-conditioned Video Diffusion
Authors: Yiqing Shen, Aiza Maksutova, Chenjia Li, Mathias Unberath
Categories: cs.CV
\\
 World models learn to predict the temporal evolution of visual observations
given a control signal, potentially enabling agents to reason about
environments through forward simulation. Because of the focus on forward
simulation, current world models generate predictions based on factual
observations. For many emerging applications, such as comprehensive evaluations
of physical AI behavior under varying conditions, the ability of world models
to answer counterfactual queries, such as "what would happen if this object was
removed?", is of increasing importance. We formalize counterfactual world
models that additionally take interventions as explicit inputs, predicting
temporal sequences under hypothetical modifications to observed scene
properties. Traditional world models operate directly on entangled pixel-space
representations where object properties and relationships cannot be selectively
modified. This modeling choice prevents targeted interventions on specific
scene properties. We introduce CWMDT, a framework to overcome those
limitations, turning standard video diffusion models into effective
counterfactual world models. First, CWMDT constructs digital twins of observed
scenes to explicitly encode objects and their relationships, represented as
structured text. Second, CWMDT applies large language models to reason over
these representations and predict how a counterfactual intervention propagates
through time to alter the observed scene. Third, CWMDT conditions a video
diffusion model with the modified representation to generate counterfactual
visual sequences. Evaluations on two benchmarks show that the CWMDT approach
achieves state-of-the-art performance, suggesting that alternative
representations of videos, such as the digital twins considered here, offer
powerful control signals for video forward simulation-based world models.
\\ ( https://arxiv.org/abs/2511.17481 ,  2319kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17484
Date: Fri, 21 Nov 2025 18:40:03 GMT   (29766kb)

Title: Radar2Shape: 3D Shape Reconstruction from High-Frequency Radar using
 Multiresolution Signed Distance Functions
Authors: Neel Sortur, Justin Goodwin, Purvik Patel, Luis Enrique Martinez Jr,
 Tzofi Klinghoffer, Rajmonda S. Caceres, Robin Walters
Categories: cs.CV
\\
 Determining the shape of 3D objects from high-frequency radar signals is
analytically complex but critical for commercial and aerospace applications.
Previous deep learning methods have been applied to radar modeling; however,
they often fail to represent arbitrary shapes or have difficulty with
real-world radar signals which are collected over limited viewing angles.
Existing methods in optical 3D reconstruction can generate arbitrary shapes
from limited camera views, but struggle when they naively treat the radar
signal as a camera view. In this work, we present Radar2Shape, a denoising
diffusion model that handles a partially observable radar signal for 3D
reconstruction by correlating its frequencies with multiresolution shape
features. Our method consists of a two-stage approach: first, Radar2Shape
learns a regularized latent space with hierarchical resolutions of shape
features, and second, it diffuses into this latent space by conditioning on the
frequencies of the radar signal in an analogous coarse-to-fine manner. We
demonstrate that Radar2Shape can successfully reconstruct arbitrary 3D shapes
even from partially-observed radar signals, and we show robust generalization
to two different simulation methods and real-world data. Additionally, we
release two synthetic benchmark datasets to encourage future research in the
high-frequency radar domain so that models like Radar2Shape can safely be
adapted into real-world radar systems.
\\ ( https://arxiv.org/abs/2511.17484 ,  29766kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17485
Date: Fri, 21 Nov 2025 18:40:21 GMT   (1702kb)

Title: An Artificial Intelligence Framework for Measuring Human Spine Aging
 Using MRI
Authors: Roozbeh Bazargani, Saqib Abdullah Basar, Daniel Daly-Grafstein,
 Rodrigo Solis Pompa, Soojin Lee, Saurabh Garg, Yuntong Ma, John A. Carrino,
 Siavash Khallaghi, Sam Hashemi
Categories: cs.CV
Comments: 17 pages, 7 figures
\\
 The human spine is a complex structure composed of 33 vertebrae. It holds the
body and is important for leading a healthy life. The spine is vulnerable to
age-related degenerations that can be identified through magnetic resonance
imaging (MRI). In this paper we propose a novel computer-vison-based deep
learning method to estimate spine age using images from over 18,000 MRI series.
Data are restricted to subjects with only age-related spine degeneration.
Eligibility criteria are created by identifying common age-based clusters of
degenerative spine conditions using uniform manifold approximation and
projection (UMAP) and hierarchical density-based spatial clustering of
applications with noise (HDBSCAN). Model selection is determined using a
detailed ablation study on data size, loss, and the effect of different spine
regions. We evaluate the clinical utility of our model by calculating the
difference between actual spine age and model-predicted age, the spine age gap
(SAG), and examining the association between these differences and spine
degenerative conditions and lifestyle factors. We find that SAG is associated
with conditions including disc bulges, disc osteophytes, spinal stenosis, and
fractures, as well as lifestyle factors like smoking and physically demanding
work, and thus may be a useful biomarker for measuring overall spine health.
\\ ( https://arxiv.org/abs/2511.17485 ,  1702kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17487
Date: Fri, 21 Nov 2025 18:43:01 GMT   (4844kb)

Title: Downscaling Intelligence: Exploring Perception and Reasoning Bottlenecks
 in Small Multimodal Models
Authors: Mark Endo, Serena Yeung-Levy
Categories: cs.CV
Comments: Website at
 https://web.stanford.edu/~markendo/projects/downscaling_intelligence
\\
 Scaling up multimodal models has enabled remarkable advances in visual
understanding and reasoning, but practical demands call for smaller, efficient
systems. In this work, we conduct a principled analysis of downscaling
intelligence in multimodal models, examining how reduced large language model
(LLM) capacity affects multimodal capabilities. Our initial findings reveal an
interesting trend: LLM downscaling disproportionately affects visual
capabilities, rather than abilities inherited from the LLM. We then examine
whether this drop mainly reflects the expected decline in visual reasoning or a
more fundamental loss of perceptual abilities. Isolating the effect of LLM
downscaling on perception, we find performance still drops sharply, often
matching or exceeding the impact on reasoning. To address this bottleneck, we
introduce visual extraction tuning, which explicitly trains the model to
extract instruction-relevant visual details consistently across tasks. With
these extracted visual details, we then apply step-by-step reasoning to
generate answers. Together, these components form our Extract+Think approach,
setting a new standard for efficiency and performance in this space.
\\ ( https://arxiv.org/abs/2511.17487 ,  4844kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17490
Date: Fri, 21 Nov 2025 18:47:09 GMT   (20090kb)

Title: Video-R4: Reinforcing Text-Rich Video Reasoning with Visual Rumination
Authors: Yolo Yunlong Tang, Daiki Shimada, Hang Hua, Chao Huang, Jing Bi,
 Rogerio Feris, Chenliang Xu
Categories: cs.CV
\\
 Understanding text-rich videos requires reading small, transient textual cues
that often demand repeated inspection. Yet most video QA models rely on
single-pass perception over fixed frames, leading to hallucinations and
failures on fine-grained evidence. Inspired by how humans pause, zoom, and
re-read critical regions, we introduce Video-R4 (Reinforcing Text-Rich Video
Reasoning with Visual Rumination), a video reasoning LMM that performs visual
rumination: iteratively selecting frames, zooming into informative regions,
re-encoding retrieved pixels, and updating its reasoning state. We construct
two datasets with executable rumination trajectories: Video-R4-CoT-17k for
supervised practice and Video-R4-RL-30k for reinforcement learning. We propose
a multi-stage rumination learning framework that progressively finetunes a 7B
LMM to learn atomic and mixing visual operations via SFT and GRPO-based RL.
Video-R4-7B achieves state-of-the-art results on M4-ViteVQA and further
generalizes to multi-page document QA, slides QA, and generic video QA,
demonstrating that iterative rumination is an effective paradigm for
pixel-grounded multimodal reasoning.
\\ ( https://arxiv.org/abs/2511.17490 ,  20090kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17492
Date: Fri, 21 Nov 2025 18:49:18 GMT   (36759kb)

Title: EvDiff: High Quality Video with an Event Camera
Authors: Weilun Li, Lei Sun, Ruixi Gao, Qi Jiang, Yuqin Ma, Kaiwei Wang,
 Ming-Hsuan Yang, Luc Van Gool, Danda Pani Paudel
Categories: cs.CV
\\
 As neuromorphic sensors, event cameras asynchronously record changes in
brightness as streams of sparse events with the advantages of high temporal
resolution and high dynamic range. Reconstructing intensity images from events
is a highly ill-posed task due to the inherent ambiguity of absolute
brightness. Early methods generally follow an end-to-end regression paradigm,
directly mapping events to intensity frames in a deterministic manner. While
effective to some extent, these approaches often yield perceptually inferior
results and struggle to scale up in model capacity and training data. In this
work, we propose EvDiff, an event-based diffusion model that follows a
surrogate training framework to produce high-quality videos. To reduce the
heavy computational cost of high-frame-rate video generation, we design an
event-based diffusion model that performs only a single forward diffusion step,
equipped with a temporally consistent EvEncoder. Furthermore, our novel
Surrogate Training Framework eliminates the dependence on paired event-image
datasets, allowing the model to leverage large-scale image datasets for higher
capacity. The proposed EvDiff is capable of generating high-quality colorful
videos solely from monochromatic event streams. Experiments on real-world
datasets demonstrate that our method strikes a sweet spot between fidelity and
realism, outperforming existing approaches on both pixel-level and perceptual
metrics.
\\ ( https://arxiv.org/abs/2511.17492 ,  36759kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17501
Date: Fri, 21 Nov 2025 18:59:26 GMT   (5011kb)

Title: Native 3D Editing with Full Attention
Authors: Weiwei Cai, Shuangkang Fang, Weicai Ye, Xin Dong, Yunhan Yang,
 Xuanyang Zhang, Wei Cheng, Yanpei Cao, Gang Yu, Tao Chen
Categories: cs.CV cs.GR
\\
 Instruction-guided 3D editing is a rapidly emerging field with the potential
to broaden access to 3D content creation. However, existing methods face
critical limitations: optimization-based approaches are prohibitively slow,
while feed-forward approaches relying on multi-view 2D editing often suffer
from inconsistent geometry and degraded visual quality. To address these
issues, we propose a novel native 3D editing framework that directly
manipulates 3D representations in a single, efficient feed-forward pass.
Specifically, we create a large-scale, multi-modal dataset for
instruction-guided 3D editing, covering diverse addition, deletion, and
modification tasks. This dataset is meticulously curated to ensure that edited
objects faithfully adhere to the instructional changes while preserving the
consistency of unedited regions with the source object. Building upon this
dataset, we explore two distinct conditioning strategies for our model: a
conventional cross-attention mechanism and a novel 3D token concatenation
approach. Our results demonstrate that token concatenation is more
parameter-efficient and achieves superior performance. Extensive evaluations
show that our method outperforms existing 2D-lifting approaches, setting a new
benchmark in generation quality, 3D consistency, and instruction fidelity.
\\ ( https://arxiv.org/abs/2511.17501 ,  5011kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16921
Date: Fri, 21 Nov 2025 03:20:54 GMT   (216kb)

Title: {\delta}-EMG: A Monotonic Graph Index for Approximate Nearest Neighbor
 Search
Authors: Liming Xiang, Jing Feng, Ziqi Yin, Zijian Li, Daihao Xue, Hongchao
 Qin, Ronghua Li, Guoren Wang
Categories: cs.IR
\\
 Approximate nearest neighbor (ANN) search in high-dimensional spaces is a
foundational component of many modern retrieval and recommendation systems.
Currently, almost all algorithms follow an $\epsilon$-Recall-Bounded principle
when comparing performance: they require the ANN search results to achieve a
recall of more than $1-\epsilon$ and then compare query-per-second (QPS)
performance. However, this approach only accounts for the recall of true
positive results and does not provide guarantees on the deviation of incorrect
results. To address this limitation, we focus on an Error-Bounded ANN method,
which ensures that the returned results are a $(1/\delta)$-approximation of the
true values. Our approach adopts a graph-based framework. To enable
Error-Bounded ANN search, we propose a $\delta$-EMG (Error-bounded Monotonic
Graph), which, for the first time, provides a provable approximation for
arbitrary queries. By enforcing a $\delta$-monotonic geometric constraint
during graph construction, $\delta$-EMG ensures that any greedy search
converges to a $(1/\delta)$-approximate neighbor without backtracking. Building
on this foundation, we design an error-bounded top-$k$ ANN search algorithm
that adaptively controls approximation accuracy during query time. To make the
framework practical at scale, we introduce $\delta$-EMQG (Error-bounded
Monotonic Quantized Graph), a localized and degree-balanced variant with
near-linear construction complexity. We further integrate vector quantization
to accelerate distance computation while preserving theoretical guarantees.
Extensive experiments on the ANN-Benchmarks dataset demonstrate the
effectiveness of our approach. Under a recall requirement of 0.99, our
algorithm achieves 19,000 QPS on the SIFT1M dataset, outperforming other
methods by more than 40\%.
\\ ( https://arxiv.org/abs/2511.16921 ,  216kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16943
Date: Fri, 21 Nov 2025 04:39:32 GMT   (765kb)

Title: RASTP: Representation-Aware Semantic Token Pruning for Generative
 Recommendation with Semantic Identifiers
Authors: Tianyu Zhan, Kairui Fu, Zheqi Lv, Shengyu Zhang
Categories: cs.IR cs.AI
Comments: 4 pages
\\
 Generative recommendation systems typically leverage Semantic Identifiers
(SIDs), which represent each item as a sequence of tokens that encode semantic
information. However, representing item ID with multiple SIDs significantly
increases input sequence length, which is a major determinant of computational
complexity and memory consumption. While existing efforts primarily focus on
optimizing attention computation and KV cache, we propose RASTP
(Representation-Aware Semantic Token Pruning), which directly prunes less
informative tokens in the input sequence. Specifically, RASTP evaluates token
importance by combining semantic saliency, measured via representation
magnitude, and attention centrality, derived from cumulative attention weights.
Since RASTP dynamically prunes low-information or irrelevant semantic tokens,
experiments on three real-world Amazon datasets show that RASTP reduces
training time by 26.7\%, while maintaining or slightly improving recommendation
performance. The code has been open-sourced at
https://github.com/Yuzt-zju/RASTP.
\\ ( https://arxiv.org/abs/2511.16943 ,  765kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17041
Date: Fri, 21 Nov 2025 08:37:39 GMT   (166kb)

Title: CLLMRec: LLM-powered Cognitive-Aware Concept Recommendation via Semantic
 Alignment and Prerequisite Knowledge Distillation
Authors: Xiangrui Xiong, Yichuan Lu, Zifei Pan, and Chang Sun
Categories: cs.IR cs.AI
\\
 The growth of Massive Open Online Courses (MOOCs) presents significant
challenges for personalized learning, where concept recommendation is crucial.
Existing approaches typically rely on heterogeneous information networks or
knowledge graphs to capture conceptual relationships, combined with knowledge
tracing models to assess learners' cognitive states. However, these methods
face significant limitations due to their dependence on high-quality structured
knowledge graphs, which are often scarce in real-world educational scenarios.
To address this fundamental challenge, this paper proposes CLLMRec, a novel
framework that leverages Large Language Models through two synergistic
technical pillars: Semantic Alignment and Prerequisite Knowledge Distillation.
The Semantic Alignment component constructs a unified representation space by
encoding unstructured textual descriptions of learners and concepts. The
Prerequisite Knowledge Distillation paradigm employs a teacher-student
architecture, where a large teacher LLM (implemented as the Prior Knowledge
Aware Component) extracts conceptual prerequisite relationships from its
internalized world knowledge and distills them into soft labels to train an
efficient student ranker. Building upon these foundations, our framework
incorporates a fine-ranking mechanism that explicitly models learners'
real-time cognitive states through deep knowledge tracing, ensuring
recommendations are both structurally sound and cognitively appropriate.
Extensive experiments on two real-world MOOC datasets demonstrate that CLLMRec
significantly outperforms existing baseline methods across multiple evaluation
metrics, validating its effectiveness in generating truly cognitive-aware and
personalized concept recommendations without relying on explicit structural
priors.
\\ ( https://arxiv.org/abs/2511.17041 ,  166kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17044
Date: Fri, 21 Nov 2025 08:44:21 GMT   (3253kb)

Title: Parametric Retrieval-Augmented Generation using Latent Routing of LoRA
 Adapters
Authors: Zhan Su, Fengran Mo, Jian-yun Nie
Categories: cs.IR
\\
 Parametric Retrieval-Augmented Generation (PRAG) is a novel RAG paradigm that
integrates external knowledge directly into a Large Language Model (LLM) by
parameterizing documents using LoRA adapters, demonstrating reduced inference
costs compared to traditional RAG approaches. However, current PRAG approaches
adopt a \textbf{one-to-one} document encoding scheme, using a dedicated LoRA
adapter for each individual document. This scheme introduces two major
limitations: First, it leads to data scarcity, as the training datasets for
individual LoRA adapters are limited. Second, it incurs high overhead during
inference, requiring the merging of LLM weights with a new LoRA adapter for
every candidate passage, which is computationally inefficient. To overcome
these challenges, we propose a novel paradigm for encoding passages in PRAG
that utilizes a latent routing encoding process (Poly-PRAG). During offline
encoding, we treat the encoding of a set of documents as a multi-task learning
process, where each passage is assigned a unique task identifier. By employing
a routing function, we use a small set of latent LoRA adapters to encode the
entire passage space. During online inference, this routing function
selectively activates a subset of latent experts based on the input query. We
conduct comprehensive evaluations of Poly-PRAG across multiple
knowledge-intensive NLP tasks. Our extensive experiments demonstrate the
effectiveness of the proposed method, achieving state-of-the-art results on
four distinct datasets.
\\ ( https://arxiv.org/abs/2511.17044 ,  3253kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16675
Date: Sat, 8 Nov 2025 12:31:07 GMT   (2772kb)

Title: Joint Design of Protein Surface and Structure Using a Diffusion Bridge
 Model
Authors: Guanlue Li, Xufeng Zhao, Fang Wu and S\"oren Laue
Categories: cs.LG cs.AI
Comments: 21 pages, 4 figures
\\
 Protein-protein interactions (PPIs) are governed by surface complementarity
and hydrophobic interactions at protein interfaces. However, designing diverse
and physically realistic protein structure and surfaces that precisely
complement target receptors remains a significant challenge in computational
protein design. In this work, we introduce PepBridge, a novel framework for the
joint design of protein surface and structure that seamlessly integrates
receptor surface geometry and biochemical properties. Starting with a receptor
surface represented as a 3D point cloud, PepBridge generates complete protein
structures through a multi-step process. First, it employs denoising diffusion
bridge models (DDBMs) to map receptor surfaces to ligand surfaces. Next, a
multi-model diffusion model predicts the corresponding structure, while
Shape-Frame Matching Networks ensure alignment between surface geometry and
backbone architecture. This integrated approach facilitates surface
complementarity, conformational stability, and chemical feasibility. Extensive
validation across diverse protein design scenarios demonstrates PepBridge's
efficacy in generating structurally viable proteins, representing a significant
advancement in the joint design of top-down protein structure.
\\ ( https://arxiv.org/abs/2511.16675 ,  2772kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16715
Date: Thu, 20 Nov 2025 16:50:09 GMT   (19623kb)

Title: DDTime: Dataset Distillation with Spectral Alignment and Information
 Bottleneck for Time-Series Forecasting
Authors: Yuqi Li, Kuiye Ding, Chuanguang Yang, Hao Wang, Haoxuan Wang, Huiran
 Duan, Junming Liu, Yingli Tian
Categories: cs.LG cs.AI
Comments: 36 pages
\\
 Time-series forecasting is fundamental across many domains, yet training
accurate models often requires large-scale datasets and substantial
computational resources. Dataset distillation offers a promising alternative by
synthesizing compact datasets that preserve the learning behavior of full data.
However, extending dataset distillation to time-series forecasting is
non-trivial due to two fundamental challenges: 1.temporal bias from strong
autocorrelation, which leads to distorted value-term alignment between teacher
and student models; and 2.insufficient diversity among synthetic samples,
arising from the absence of explicit categorical priors to regularize
trajectory variety.
 In this work, we propose DDTime, a lightweight and plug-in distillation
framework built upon first-order condensation decomposition. To tackle
Challenge 1, it revisits value-term alignment through temporal statistics and
introduces a frequency-domain alignment mechanism to mitigate
autocorrelation-induced bias, ensuring spectral consistency and temporal
fidelity. To address Challenge 2, we further design an inter-sample
regularization inspired by the information bottleneck principle, which enhances
diversity and maximizes information density across synthetic trajectories. The
combined objective is theoretically compatible with a wide range of
condensation paradigms and supports stable first-order optimization. Extensive
experiments on 20 benchmark datasets and diverse forecasting architectures
demonstrate that DDTime consistently outperforms existing distillation methods,
achieving about 30% relative accuracy gains while introducing about 2.49%
computational overhead. All code and distilled datasets will be released.
\\ ( https://arxiv.org/abs/2511.16715 ,  19623kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16767
Date: Thu, 20 Nov 2025 19:34:58 GMT   (2922kb)

Title: When Structure Doesn't Help: LLMs Do Not Read Text-Attributed Graphs as
 Effectively as We Expected
Authors: Haotian Xu and Yuning You and Tengfei Ma
Categories: cs.LG
\\
 Graphs provide a unified representation of semantic content and relational
structure, making them a natural fit for domains such as molecular modeling,
citation networks, and social graphs. Meanwhile, large language models (LLMs)
have excelled at understanding natural language and integrating cross-modal
signals, sparking interest in their potential for graph reasoning. Recent work
has explored this by either designing template-based graph templates or using
graph neural networks (GNNs) to encode structural information. In this study,
we investigate how different strategies for encoding graph structure affect LLM
performance on text-attributed graphs. Surprisingly, our systematic experiments
reveal that: (i) LLMs leveraging only node textual descriptions already achieve
strong performance across tasks; and (ii) most structural encoding strategies
offer marginal or even negative gains. We show that explicit structural priors
are often unnecessary and, in some cases, counterproductive when powerful
language models are involved. This represents a significant departure from
traditional graph learning paradigms and highlights the need to rethink how
structure should be represented and utilized in the LLM era. Our study is to
systematically challenge the foundational assumption that structure is
inherently beneficial for LLM-based graph reasoning, opening the door to new,
semantics-driven approaches for graph learning.
\\ ( https://arxiv.org/abs/2511.16767 ,  2922kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16778
Date: Thu, 20 Nov 2025 20:10:49 GMT   (13254kb)

Title: GCL-OT: Graph Contrastive Learning with Optimal Transport for
 Heterophilic Text-Attributed Graphs
Authors: Yating Ren, Yikun Ban, Huobin Tan
Categories: cs.LG
Comments: AAAI 2026
\\
 Recently, structure-text contrastive learning has shown promising performance
on text-attributed graphs by leveraging the complementary strengths of graph
neural networks and language models. However, existing methods typically rely
on homophily assumptions in similarity estimation and hard optimization
objectives, which limit their applicability to heterophilic graphs. Although
existing methods can mitigate heterophily through structural adjustments or
neighbor aggregation, they usually treat textual embeddings as static targets,
leading to suboptimal alignment. In this work, we identify the multi-granular
heterophily in text-attributed graphs, including complete heterophily, partial
heterophily, and latent homophily, which makes structure-text alignment
particularly challenging due to mixed, noisy, and missing semantic
correlations. To achieve flexible and bidirectional alignment, we propose
GCL-OT, a novel graph contrastive learning framework with optimal transport,
equipped with tailored mechanisms for each type of heterophily. Specifically,
for partial heterophily, we design a RealSoftMax-based similarity estimator to
emphasize key neighbor-word interactions while easing background noise. For
complete heterophily, we introduce a prompt-based filter that adaptively
excludes irrelevant noise during optimal transport alignment. Furthermore, we
incorporate OT-guided soft supervision to uncover potential neighbors with
similar semantics, enhancing the learning of latent homophily. Theoretical
analysis shows that GCL-OT can improve the mutual information bound and Bayes
error guarantees. Extensive experiments on nine benchmarks show that GCL-OT
consistently outperforms state-of-the-art methods, verifying its effectiveness
and robustness.
\\ ( https://arxiv.org/abs/2511.16778 ,  13254kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16786
Date: Thu, 20 Nov 2025 20:25:34 GMT   (2002kb)

Title: Revisiting Multimodal KV Cache Compression: A Frequency-Domain-Guided
 Outlier-KV-Aware Approach
Authors: Yaoxin Yang, Peng Ye, Xudong Tan, Chongjun Tu, Maosen Zhao, Jia Hao,
 Tao Chen
Categories: cs.LG cs.AI cs.CV
Comments: Under Review
\\
 Multimodal large language models suffer from substantial inference overhead
since multimodal KV Cache grows proportionally with the visual input length.
Existing multimodal KV Cache compression methods mostly rely on attention score
to reduce cache size, which makes them are incompatible with established
efficient attention kernels (e.g., FlashAttention) and ignores the contribution
of value vectors to the attention output. In this work, we revisit multimodal
KV Cache compression from the perspective of the KV matrices' distribution.
First, we observe that frequency-domain energy of multimodal KV matrices is
predominantly concentrated in low-frequency and extract this principal energy
via a low-pass filter. Further, we find that removing KV pairs that deviate
substantially from this principal energy leads to a pronounced performance
drop, which we define as Outlier KVs. Considering Outlier KVs are more likely
to encode features critical for inference, we propose FlashCache, a
frequency-domain-guided, Outlier-KV-aware KV Cache compression framework.
First, we introduce an Outlier KV Recognition Module that models the principal
component of multimodal KV matrices in the frequency domain and preferentially
retains KV pairs that significantly deviate from it. Furthermore, Dynamic
Budget Allocation Module is designed to adaptively determine the per-layer KV
Cache size to retain more Outlier KVs. Experiments on multiple MLLMs and
benchmarks demonstrate that FlashCache outperforms state-of-the-art multimoal
KV compression methods, achieving up to 1.69 times faster decoding with 80%
lower KV memory usage while maintaining task performance.
\\ ( https://arxiv.org/abs/2511.16786 ,  2002kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16795
Date: Thu, 20 Nov 2025 20:48:02 GMT   (34552kb)

Title: A Vector Symbolic Approach to Multiple Instance Learning
Authors: Ehsan Ahmed Dhrubo, Mohammad Mahmudul Alam, Edward Raff, Tim Oates,
 James Holt
Categories: cs.LG
\\
 Multiple Instance Learning (MIL) tasks impose a strict logical constraint: a
bag is labeled positive if and only if at least one instance within it is
positive. While this iff constraint aligns with many real-world applications,
recent work has shown that most deep learning-based MIL approaches violate it,
leading to inflated performance metrics and poor generalization. We propose a
novel MIL framework based on Vector Symbolic Architectures (VSAs), which
provide a differentiable mechanism for performing symbolic operations in
high-dimensional space. Our method encodes the MIL assumption directly into the
model's structure by representing instances and concepts as nearly orthogonal
high-dimensional vectors and using algebraic operations to enforce the iff
constraint during classification. To bridge the gap between raw data and VSA
representations, we design a learned encoder that transforms input instances
into VSA-compatible vectors while preserving key distributional properties. Our
approach, which includes a VSA-driven MaxNetwork classifier, achieves
state-of-the-art results for a valid MIL model on standard MIL benchmarks and
medical imaging datasets, outperforming existing methods while maintaining
strict adherence to the MIL formulation. This work offers a principled,
interpretable, and effective alternative to existing MIL approaches that rely
on learned heuristics.
\\ ( https://arxiv.org/abs/2511.16795 ,  34552kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16822
Date: Thu, 20 Nov 2025 22:05:14 GMT   (379kb)

Title: A Robust Federated Learning Approach for Combating Attacks Against IoT
 Systems Under non-IID Challenges
Authors: Eyad Gad, Zubair Md Fadlullah, Mostafa M. Fouda
Categories: cs.LG cs.AI cs.CR
Comments: 6 pages, conference paper; presented at the 2024 International
 Conference on Smart Applications, Communications and Networking (SmartNets
 2024), Harrisonburg, VA, USA, May 28, 2024
MSC-class: 68T05, 68M10
ACM-class: C.2.0; C.2.1; I.2.6
Journal-ref: 2024 International Conference on Smart Applications,
 Communications and Networking (SmartNets), Harrisonburg, VA, USA, May 28,
 2024, IEEE
DOI: 10.1109/SmartNets61466.2024.10577749
\\
 In the context of the growing proliferation of user devices and the
concurrent surge in data volumes, the complexities arising from the substantial
increase in data have posed formidable challenges to conventional machine
learning model training. Particularly, this is evident within
resource-constrained and security-sensitive environments such as those
encountered in networks associated with the Internet of Things (IoT). Federated
Learning has emerged as a promising remedy to these challenges by
decentralizing model training to edge devices or parties, effectively
addressing privacy concerns and resource limitations. Nevertheless, the
presence of statistical heterogeneity in non-Independently and Identically
Distributed (non-IID) data across different parties poses a significant hurdle
to the effectiveness of FL. Many FL approaches have been proposed to enhance
learning effectiveness under statistical heterogeneity. However, prior studies
have uncovered a gap in the existing research landscape, particularly in the
absence of a comprehensive comparison between federated methods addressing
statistical heterogeneity in detecting IoT attacks. In this research endeavor,
we delve into the exploration of FL algorithms, specifically FedAvg, FedProx,
and Scaffold, under different data distributions. Our focus is on achieving a
comprehensive understanding of and addressing the challenges posed by
statistical heterogeneity. In this study, We classify large-scale IoT attacks
by utilizing the CICIoT2023 dataset. Through meticulous analysis and
experimentation, our objective is to illuminate the performance nuances of
these FL methods, providing valuable insights for researchers and practitioners
in the domain.
\\ ( https://arxiv.org/abs/2511.16822 ,  379kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16823
Date: Thu, 20 Nov 2025 22:06:13 GMT   (1321kb)

Title: Monte Carlo Expected Threat (MOCET) Scoring
Authors: Joseph Kim, Saahith Potluri
Categories: cs.LG cs.AI cs.HC
Comments: Accepted to NeurIPS 2025 BioSafe GenAI
MSC-class: 68T01, 65C05, 92C42
ACM-class: I.2.6; K.4.1; J.3; G.3
\\
 Evaluating and measuring AI Safety Level (ASL) threats are crucial for
guiding stakeholders to implement safeguards that keep risks within acceptable
limits. ASL-3+ models present a unique risk in their ability to uplift novice
non-state actors, especially in the realm of biosecurity. Existing evaluation
metrics, such as LAB-Bench, BioLP-bench, and WMDP, can reliably assess model
uplift and domain knowledge. However, metrics that better contextualize
"real-world risks" are needed to inform the safety case for LLMs, along with
scalable, open-ended metrics to keep pace with their rapid advancements. To
address both gaps, we introduce MOCET, an interpretable and doubly-scalable
metric (automatable and open-ended) that can quantify real-world risks.
\\ ( https://arxiv.org/abs/2511.16823 ,  1321kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16828
Date: Thu, 20 Nov 2025 22:19:53 GMT   (5557kb)

Title: ManifoldFormer: Geometric Deep Learning for Neural Dynamics on
 Riemannian Manifolds
Authors: Yihang Fu, Lifang He, Qingyu Chen
Categories: cs.LG cs.AI
Comments: 5 pages, under review by ICASSP
\\
 Existing EEG foundation models mainly treat neural signals as generic time
series in Euclidean space, ignoring the intrinsic geometric structure of neural
dynamics that constrains brain activity to low-dimensional manifolds. This
fundamental mismatch between model assumptions and neural geometry limits
representation quality and cross-subject generalization. ManifoldFormer
addresses this limitation through a novel geometric deep learning framework
that explicitly learns neural manifold representations. The architecture
integrates three key innovations: a Riemannian VAE for manifold embedding that
preserves geometric structure, a geometric Transformer with geodesic-aware
attention mechanisms operating directly on neural manifolds, and a dynamics
predictor leveraging neural ODEs for manifold-constrained temporal evolution.
Extensive evaluation across four public datasets demonstrates substantial
improvements over state-of-the-art methods, with 4.6-4.8% higher accuracy and
6.2-10.2% higher Cohen's Kappa, while maintaining robust cross-subject
generalization. The geometric approach reveals meaningful neural patterns
consistent with neurophysiological principles, establishing geometric
constraints as essential for effective EEG foundation models.
\\ ( https://arxiv.org/abs/2511.16828 ,  5557kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16839
Date: Thu, 20 Nov 2025 22:43:25 GMT   (465kb)

Title: Analysis of heart failure patient trajectories using sequence modeling
Authors: Falk Dippela, Yinan Yu, Annika Rosengren, Martin Lindgren, Christina
 E. Lundberg, Erik Aerts, Martin Adiels, Helen Sj\"oland
Categories: cs.LG cs.AI
\\
 Transformers have defined the state-of-the-art for clinical prediction tasks
involving electronic health records (EHRs). The recently introduced Mamba
architecture outperformed an advanced Transformer (Transformer++) based on
Llama in handling long context lengths, while using fewer model parameters.
Despite the impressive performance of these architectures, a systematic
approach to empirically analyze model performance and efficiency under various
settings is not well established in the medical domain. The performances of six
sequence models were investigated across three architecture classes
(Transformers, Transformers++, Mambas) in a large Swedish heart failure (HF)
cohort (N = 42820), providing a clinically relevant case study. Patient data
included diagnoses, vital signs, laboratories, medications and procedures
extracted from in-hospital EHRs. The models were evaluated on three one-year
prediction tasks: clinical instability (a readmission phenotype) after initial
HF hospitalization, mortality after initial HF hospitalization and mortality
after latest hospitalization. Ablations account for modifications of the
EHR-based input patient sequence, architectural model configurations, and
temporal preprocessing techniques for data collection. Llama achieves the
highest predictive discrimination, best calibration, and showed robustness
across all tasks, followed by Mambas. Both architectures demonstrate efficient
representation learning, with tiny configurations surpassing other large-scaled
Transformers. At equal model size, Llama and Mambas achieve superior
performance using 25% less training data. This paper presents a first ablation
study with systematic design choices for input tokenization, model
configuration and temporal data preprocessing. Future model development in
clinical prediction tasks using EHRs could build upon this study's
recommendation as a starting point.
\\ ( https://arxiv.org/abs/2511.16839 ,  465kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16845
Date: Thu, 20 Nov 2025 23:00:15 GMT   (758kb)

Title: Provably Minimum-Length Conformal Prediction Sets for Ordinal
 Classification
Authors: Zijian Zhang, Xinyu Chen, Yuanjie Shi, Liyuan Lillian Ma, Zifan Xu,
 Yan Yan
Categories: cs.LG
Comments: Submitted to AAAI 2026
\\
 Ordinal classification has been widely applied in many high-stakes
applications, e.g., medical imaging and diagnosis, where reliable uncertainty
quantification (UQ) is essential for decision making. Conformal prediction (CP)
is a general UQ framework that provides statistically valid guarantees, which
is especially useful in practice. However, prior ordinal CP methods mainly
focus on heuristic algorithms or restrictively require the underlying model to
predict a unimodal distribution over ordinal labels. Consequently, they provide
limited insight into coverage-efficiency trade-offs, or a model-agnostic and
distribution-free nature favored by CP methods. To this end, we fill this gap
by propose an ordinal-CP method that is model-agnostic and provides
instance-level optimal prediction intervals. Specifically, we formulate
conformal ordinal classification as a minimum-length covering problem at the
instance level. To solve this problem, we develop a sliding-window algorithm
that is optimal on each calibration data, with only a linear time complexity in
K, the number of label candidates. The local optimality per instance further
also improves predictive efficiency in expectation. Moreover, we propose a
length-regularized variant that shrinks prediction set size while preserving
coverage. Experiments on four benchmark datasets from diverse domains are
conducted to demonstrate the significantly improved predictive efficiency of
the proposed methods over baselines (by 15% decrease on average over four
datasets).
\\ ( https://arxiv.org/abs/2511.16845 ,  758kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16848
Date: Thu, 20 Nov 2025 23:08:48 GMT   (5592kb)

Title: Sex and age determination in European lobsters using AI-Enhanced
 bioacoustics
Authors: Feliciano Pedro Francisco Domingos, Isibor Kennedy Ihianle, Omprakash
 Kaiwartya, Ahmad Lotfi, Nicola Khan, Nicholas Beaudreau, Amaya Albalat, Pedro
 Machado
Categories: cs.LG cs.AI
\\
 Monitoring aquatic species, especially elusive ones like lobsters, presents
challenges. This study focuses on Homarus gammarus (European lobster), a key
species for fisheries and aquaculture, and leverages non-invasive Passive
Acoustic Monitoring (PAM). Understanding lobster habitats, welfare,
reproduction, sex, and age is crucial for management and conservation. While
bioacoustic emissions have classified various aquatic species using Artificial
Intelligence (AI) models, this research specifically uses H. gammarus
bioacoustics (buzzing/carapace vibrations) to classify lobsters by age
(juvenile/adult) and sex (male/female).
 The dataset was collected at Johnshaven, Scotland, using hydrophones in
concrete tanks. We explored the efficacy of Deep Learning (DL) models (1D-CNN,
1D-DCNN) and six Machine Learning (ML) models (SVM, k-NN, Naive Bayes, Random
Forest, XGBoost, MLP). Mel-frequency cepstral coefficients (MFCCs) were used as
features.
 For age classification (adult vs. juvenile), most models achieved over 97%
accuracy (Naive Bayes: 91.31%). For sex classification, all models except Naive
Bayes surpassed 93.23%. These strong results demonstrate the potential of
supervised ML and DL to extract age- and sex-related features from lobster
sounds. This research offers a promising non-invasive PAM approach for lobster
conservation, detection, and management in aquaculture and fisheries, enabling
real-world edge computing applications for underwater species.
\\ ( https://arxiv.org/abs/2511.16848 ,  5592kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16849
Date: Thu, 20 Nov 2025 23:11:54 GMT   (1391kb)

Title: Better audio representations are more brain-like: linking model-brain
 alignment with performance in downstream auditory tasks
Authors: Leonardo Pepino, Pablo Riera, Juan Kamienkowski, Luciana Ferrer
Categories: cs.LG cs.SD
\\
 Artificial neural networks (ANNs) are increasingly powerful models of brain
computation, yet it remains unclear whether improving their task performance
also makes their internal representations more similar to brain signals. To
address this question in the auditory domain, we quantified the alignment
between the internal representations of 36 different audio models and brain
activity from two independent fMRI datasets. Using voxel-wise and
component-wise regression, and representation similarity analysis (RSA), we
found that recent self-supervised audio models with strong performance in
diverse downstream tasks are better predictors of auditory cortex activity than
older and more specialized models. To assess the quality of the audio
representations, we evaluated these models in 6 auditory tasks from the
HEAREval benchmark, spanning music, speech, and environmental sounds. This
revealed strong positive Pearson correlations ($r>0.7$) between a model's
overall task performance and its alignment with brain representations. Finally,
we analyzed the evolution of the similarity between audio and brain
representations during the pretraining of EnCodecMAE. We discovered that brain
similarity increases progressively and emerges early during pretraining,
despite the model not being explicitly optimized for this objective. This
suggests that brain-like representations can be an emergent byproduct of
learning to reconstruct missing information from naturalistic audio data.
\\ ( https://arxiv.org/abs/2511.16849 ,  1391kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16856
Date: Thu, 20 Nov 2025 23:43:38 GMT   (222kb)

Title: The use of vocal biomarkers in the detection of Parkinson's disease: a
 robust statistical performance comparison of classic machine learning models
Authors: Katia Pires Nascimento do Sacramento, Elliot Q. C. Garcia, Nic\'eias
 Silva Vilela, Vinicius P. Sacramento, Tiago A. E. Ferreira
Categories: cs.LG cs.AI
Comments: 18 pages, 3 figures
\\
 Parkinson's disease (PD) is a progressive neurodegenerative disorder that, in
addition to directly impairing functional mobility, is frequently associated
with vocal impairments such as hypophonia and dysarthria, which typically
manifest in the early stages. The use of vocal biomarkers to support the early
diagnosis of PD presents a non-invasive, low-cost, and accessible alternative
in clinical settings. Thus, the objective of this cross-sectional study was to
consistently evaluate the effectiveness of a Deep Neural Network (DNN) in
distinguishing individuals with Parkinson's disease from healthy controls, in
comparison with traditional Machine Learning (ML) methods, using vocal
biomarkers. Two publicly available voice datasets were used. Mel-frequency
cepstral coefficients (MFCCs) were extracted from the samples, and model
robustness was assessed using a validation strategy with 1000 independent
random executions. Performance was evaluated using classification statistics.
Since normality assumptions were not satisfied, non-parametric tests
(Kruskal-Wallis and Bonferroni post-hoc tests) were applied to verify whether
the tested classification models were similar or different in the
classification of PD. With an average accuracy of $98.65\%$ and $92.11\%$ on
the Italian Voice dataset and Parkinson's Telemonitoring dataset, respectively,
the DNN demonstrated superior performance and efficiency compared to
traditional ML models, while also achieving competitive results when
benchmarked against relevant studies. Overall, this study confirms the
efficiency of DNNs and emphasizes their potential to provide greater accuracy
and reliability for the early detection of neurodegenerative diseases using
voice-based biomarkers.
\\ ( https://arxiv.org/abs/2511.16856 ,  222kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16871
Date: Fri, 21 Nov 2025 00:43:14 GMT   (3185kb)

Title: Topologic Attention Networks: Attending to Direct and Indirect Neighbors
 through Gaussian Belief Propagation
Authors: Marshall Rosenhoover and Huaming Zhang
Categories: cs.LG
Comments: 15 pages, 13 Figures
ACM-class: I.2.6, I.5.1, G.3
\\
 Graph Neural Networks rely on local message passing, which limits their
ability to model long-range dependencies in graphs. Existing approaches extend
this range through continuous-time dynamics or dense self-attention, but both
suffer from high computational cost and limited scalability. We propose
Topologic Attention Networks, a new framework that applies topologic attention,
a probabilistic mechanism that learns how information should flow through both
direct and indirect connections in a graph. Unlike conventional attention that
depends on explicit pairwise interactions, topologic attention emerges from the
learned information propagation of the graph, enabling unified reasoning over
local and global relationships. This method achieves provides state-of-the-art
performance across all measured baseline models. Our implementation is
available at
https://github.com/Marshall-Rosenhoover/Topologic-Attention-Networks.
\\ ( https://arxiv.org/abs/2511.16871 ,  3185kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16883
Date: Fri, 21 Nov 2025 01:19:34 GMT   (681kb)

Title: PersonalizedRouter: Personalized LLM Routing via Graph-based User
 Preference Modeling
Authors: Zhongjie Dai and Tao Feng and Jiaxuan You
Categories: cs.LG
\\
 The growing number of Large Language Models (LLMs) with diverse capabilities
and response styles provides users with a wider range of choices, which
presents challenges in selecting appropriate LLMs, as user preferences vary in
terms of performance, cost, and response style. Current LLM selection methods
typically optimize for a single fixed objective, such as performance, cost, or
a trade-off between them, and fail to learn individual user preferences from
interaction data. To address these limitations, we propose PersonalizedRouter,
a graph-based framework that models diverse user profiles and performs
personalized LLM selection by leveraging interaction data that includes task
context, queries, candidate LLMs, and user decisions. To capture contextual
information between user queries and optimal LLMs, PersonalizedRouter converts
the interaction data into a heterogeneous graph, where the relationships
between different types of nodes are represented by edges. To evaluate
adaptability across users, we design two strategies: the multi-cost-efficiency
simulation strategy and the LLM-as-a-Judge strategy. In addition, we construct
PersonaRoute-Bench, a large-scale benchmark with 1,000 simulated users and 10
LLMs. Experimental results show that PersonalizedRouter significantly
outperforms existing LLM selection methods and surpasses the strongest methods
by a large margin of 15.38% and 9.83% under two simulation strategies. On the
PersonaRoute-Bench with 1,000 users, it further surpasses the best methods by
16.19% and 59.69% while maintaining higher efficiency. Moreover,
PersonalizedRouter demonstrates strong few-shot generalization, achieving
64.81% and 85.80% of the fully trained model's performance when adapting to new
users and new LLMs.
\\ ( https://arxiv.org/abs/2511.16883 ,  681kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16905
Date: Fri, 21 Nov 2025 02:37:30 GMT   (9kb)

Title: Predicting Talent Breakout Rate using Twitter and TV data
Authors: Bilguun Batsaikhan and Hiroyuki Fukuda
Categories: cs.LG
Comments: 4 pages. Presented at the 34th Annual Conference of the Japanese
 Society for Artificial Intelligence (JSAI 2020), paper ID 1K3-ES-2-02
Journal-ref: Proc. 34th Annual Conference of the Japanese Society for
 Artificial Intelligence (JSAI 2020), paper 1K3-ES-2-02, 2020
DOI: 10.11517/pjsai.JSAI2020.0_1K3ES202
\\
 Early detection of rising talents is of paramount importance in the field of
advertising. In this paper, we define a concept of talent breakout and propose
a method to detect Japanese talents before their rise to stardom. The main
focus of the study is to determine the effectiveness of combining Twitter and
TV data on predicting time-dependent changes in social data. Although
traditional time-series models are known to be robust in many applications, the
success of neural network models in various fields (e.g.\ Natural Language
Processing, Computer Vision, Reinforcement Learning) continues to spark an
interest in the time-series community to apply new techniques in practice.
Therefore, in order to find the best modeling approach, we have experimented
with traditional, neural network and ensemble learning methods. We observe that
ensemble learning methods outperform traditional and neural network models
based on standard regression metrics. However, by utilizing the concept of
talent breakout, we are able to assess the true forecasting ability of the
models, where neural networks outperform traditional and ensemble learning
methods in terms of precision and recall.
\\ ( https://arxiv.org/abs/2511.16905 ,  9kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16912
Date: Fri, 21 Nov 2025 02:51:15 GMT   (1758kb)

Title: PepEVOLVE: Position-Aware Dynamic Peptide Optimization via
 Group-Relative Advantage
Authors: Trieu Nguyen, Hao-Wei Pang, Shasha Feng
Categories: cs.LG cs.AI
\\
 Macrocyclic peptides are an emerging modality that combines biologics-like
affinity with small-molecule-like developability, but their vast combinatorial
space and multi-parameter objectives make lead optimization slow and
challenging. Prior generative approaches such as PepINVENT require chemists to
pre-specify mutable positions for optimization, choices that are not always
known a priori, and rely on static pretraining and optimization algorithms that
limit the model's ability to generalize and effectively optimize peptide
sequences. We introduce PepEVOLVE, a position-aware, dynamic framework that
learns both where to edit and how to dynamically optimize peptides for
multi-objective improvement. PepEVOLVE (i) augments pretraining with dynamic
masking and CHUCKLES shifting to improve generalization, (ii) uses a
context-free multi-armed bandit router that discovers high-reward residues, and
(iii) couples a novel evolving optimization algorithm with group-relative
advantage to stabilize reinforcement updates. During in silico evaluations, the
router policy reliably learns and concentrates probability on chemically
meaningful sites that influence the peptide's properties. On a therapeutically
motivated Rev-binding macrocycle benchmark, PepEVOLVE outperformed PepINVENT by
reaching higher mean scores (approximately 0.8 vs. 0.6), achieving best
candidates with a score of 0.95 (vs. 0.87), and converging in fewer steps under
the task of optimizing permeability and lipophilicity with structural
constraints. Overall, PepEVOLVE offers a practical, reproducible path to
peptide lead optimization when optimal edit sites are unknown, enabling more
efficient exploration and improving design quality across multiple objectives.
\\ ( https://arxiv.org/abs/2511.16912 ,  1758kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16923
Date: Fri, 21 Nov 2025 03:23:47 GMT   (87kb)

Title: A Hybrid Computational Intelligence Framework for scRNA-seq Imputation:
 Integrating scRecover and Random Forests
Authors: Ali Anaissi, Deshao Liu, Yuanzhe Jia, Weidong Huang, Widad Alyassine
 and Junaid Akram
Categories: cs.LG q-bio.GN
\\
 Single-cell RNA sequencing (scRNA-seq) enables transcriptomic profiling at
cellular resolution but suffers from pervasive dropout events that obscure
biological signals. We present SCR-MF, a modular two-stage workflow that
combines principled dropout detection using scRecover with robust
non-parametric imputation via missForest. Across public and simulated datasets,
SCR-MF achieves robust and interpretable performance comparable to or exceeding
existing imputation methods in most cases, while preserving biological fidelity
and transparency. Runtime analysis demonstrates that SCR-MF provides a
competitive balance between accuracy and computational efficiency, making it
suitable for mid-scale single-cell datasets.
\\ ( https://arxiv.org/abs/2511.16923 ,  87kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16929
Date: Fri, 21 Nov 2025 03:43:37 GMT   (13297kb)

Title: CroTad: A Contrastive Reinforcement Learning Framework for Online
 Trajectory Anomaly Detection
Authors: Rui Xue, Dan He, Fengmei Jin, Chen Zhang, Xiaofang Zhou
Categories: cs.LG cs.DB
Comments: 18 pages, 4 figures, will be submitted to VLDBJ
\\
 Detecting trajectory anomalies is a vital task in modern Intelligent
Transportation Systems (ITS), enabling the identification of unsafe,
inefficient, or irregular travel behaviours. While deep learning has emerged as
the dominant approach, several key challenges remain unresolved. First,
sub-trajectory anomaly detection, capable of pinpointing the precise segments
where anomalies occur, remains underexplored compared to whole-trajectory
analysis. Second, many existing methods depend on carefully tuned thresholds,
limiting their adaptability in real-world applications. Moreover, the irregular
sampling of trajectory data and the presence of noise in training sets further
degrade model performance, making it difficult to learn reliable
representations of normal routes. To address these challenges, we propose a
contrastive reinforcement learning framework for online trajectory anomaly
detection, CroTad. Our method is threshold-free and robust to noisy,
irregularly sampled data. By incorporating contrastive learning, CroTad learns
to extract diverse normal travel patterns for different itineraries and
effectively distinguish anomalous behaviours at both sub-trajectory and point
levels. The detection module leverages deep reinforcement learning to perform
online, real-time anomaly scoring, enabling timely and fine-grained
identification of abnormal segments. Extensive experiments on two real-world
datasets demonstrate the effectiveness and robustness of our framework across
various evaluation scenarios.
\\ ( https://arxiv.org/abs/2511.16929 ,  13297kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16933
Date: Fri, 21 Nov 2025 03:57:52 GMT   (3080kb)

Title: A novel approach to classification of ECG arrhythmia types with latent
 ODEs
Authors: Angelina Yan, Matt L. Sampson, Peter Melchior
Categories: cs.LG q-bio.QM
Comments: Accepted into NeurIPS 2025 Learning from Time Series for Health
 workshop
\\
 12-lead ECGs with high sampling frequency are the clinical gold standard for
arrhythmia detection, but their short-term, spot-check nature often misses
intermittent events. Wearable ECGs enable long-term monitoring but suffer from
irregular, lower sampling frequencies due to battery constraints, making
morphology analysis challenging. We present an end-to-end classification
pipeline to address these issues. We train a latent ODE to model continuous ECG
waveforms and create robust feature vectors from high-frequency single-channel
signals. We construct three latent vectors per waveform via downsampling the
initial 360 Hz ECG to 90 Hz and 45 Hz. We then use a gradient boosted tree to
classify these vectors and test robustness across frequencies. Performance
shows minimal degradation, with macro-averaged AUC-ROC values of 0.984, 0.978,
and 0.976 at 360 Hz, 90 Hz, and 45 Hz, respectively, suggesting a way to
sidestep the trade-off between signal fidelity and battery life. This enables
smaller wearables, promoting long-term monitoring of cardiac health.
\\ ( https://arxiv.org/abs/2511.16933 ,  3080kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16972
Date: Fri, 21 Nov 2025 06:01:28 GMT   (1429kb)

Title: ToC: Tree-of-Claims Search with Multi-Agent Language Models
Authors: Shuyang Yu, Jianan Liang, Hui Hu
Categories: cs.LG
Comments: Accepted by AAAI 2026 (Oral)
\\
 Optimizing patent claims is a critical yet challenging task, demanding
careful balance between maximizing novelty and preserving legal scope. Manual
claim drafting is labor-intensive, costly, and inherently inconsistent, while
conventional Large Language Models (LLMs) often lack the structured, iterative
reasoning essential for precise claim refinement. To address these challenges,
we introduce Tree of Claims (ToC), an innovative framework that redefines claim
editing as a guided search problem. ToC synergistically integrates Monte Carlo
Tree Search (MCTS) with a collaborative multi-agent system, comprising an
LLM-based EditorAgent that proposes contextually grounded edits, and an
ExaminerAgent that mimics patent examiner critiques through structured,
chain-of-thought analyses of novelty and prior art disclosure. Driven by a
carefully designed multi-objective reward function, ToC jointly optimizes
novelty, scope retention, and semantic coherence. Experimental evaluation on a
benchmark of 1145 claims demonstrates that ToC significantly outperforms
standard LLMs in zero-shot and few-shot scenarios, achieving an average
composite score improvement of 8\%, and up to 9\% in certain cases. Extensive
experiments, including detailed ablation studies, validate ToC's efficacy in
generating superior, legally robust claim revisions. Overall, ToC establishes a
transparent, controllable, and interpretable methodology that effectively
bridges advanced LLM reasoning capabilities with strategic MCTS planning for
structured patent claim optimization.The source code is available at
https://github.com/ysy2003/ToC.
\\ ( https://arxiv.org/abs/2511.16972 ,  1429kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16976
Date: Fri, 21 Nov 2025 06:14:41 GMT   (1209kb)

Title: Gradient flow for deep equilibrium single-index models
Authors: Sanjit Dandapanthula and Aaditya Ramdas
Categories: cs.LG math.ST stat.ML stat.TH
\\
 Deep equilibrium models (DEQs) have recently emerged as a powerful paradigm
for training infinitely deep weight-tied neural networks that achieve state of
the art performance across many modern machine learning tasks. Despite their
practical success, theoretically understanding the gradient descent dynamics
for training DEQs remains an area of active research. In this work, we
rigorously study the gradient descent dynamics for DEQs in the simple setting
of linear models and single-index models, filling several gaps in the
literature. We prove a conservation law for linear DEQs which implies that the
parameters remain trapped on spheres during training and use this property to
show that gradient flow remains well-conditioned for all time. We then prove
linear convergence of gradient descent to a global minimizer for linear DEQs
and deep equilibrium single-index models under appropriate initialization and
with a sufficiently small step size. Finally, we validate our theoretical
findings through experiments.
\\ ( https://arxiv.org/abs/2511.16976 ,  1209kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16992
Date: Fri, 21 Nov 2025 06:59:28 GMT   (2981kb)

Title: FIRM: Federated In-client Regularized Multi-objective Alignment for
 Large Language Models
Authors: Fatemeh (Atena) Nourzad, Amirhossein Roknilamouki, Eylem Ekici, Jia
 (Kevin) Liu, Ness B. Shroff
Categories: cs.LG
\\
 Aligning Large Language Models (LLMs) with human values often involves
balancing multiple, conflicting objectives such as helpfulness and
harmlessness. Training these models is computationally intensive, and
centralizing the process raises significant data privacy concerns. Federated
Learning (FL) offers a compelling alternative, but existing Federated
Multi-Objective Optimization (FMOO) methods face severe communication
bottlenecks as their reliance on transmitting multiple gradients to a server is
unscalable for large models. We introduce FIRM (Federated In-client Regularized
Multi-objective alignment), a novel algorithm that achieves both client
disagreement drift mitigation and communication efficiency. In FIRM, each
client locally solves a regularized multi-objective optimization problem. By
directly mitigating client disagreement drift through in-client regularization,
our method eliminates the need for the multi-gradient transmissions common in
prior works. Consequently, clients need only to transmit a single set of
adapted parameters, maintaining high communication efficiency. We prove that
our algorithm converges to Pareto-stationary points and, to our knowledge,
provide the first finite-time convergence guarantees for this federated
multi-objective alignment setting. Empirically, we show that FIRM leads to
smoother training dynamics, reduced client disagreement drift, and improved
reward trade-offs compared to baselines. We further propose a method to
incorporate a preference over the objectives and report empirical Pareto plots,
demonstrating that FIRM can smoothly adapt trade-offs between objectives in
response to specified preferences.
\\ ( https://arxiv.org/abs/2511.16992 ,  2981kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17008
Date: Fri, 21 Nov 2025 07:26:40 GMT   (943kb)

Title: Mask the Redundancy: Evolving Masking Representation Learning for
 Multivariate Time-Series Clustering
Authors: Zexi Tan and Xiaopeng Luo and Yunlin Liu and Yiqun Zhang
Categories: cs.LG
Comments: Accepted to AAAI 2026
\\
 Multivariate Time-Series (MTS) clustering discovers intrinsic grouping
patterns of temporal data samples. Although time-series provide rich
discriminative information, they also contain substantial redundancy, such as
steady-state machine operation records and zero-output periods of solar power
generation. Such redundancy diminishes the attention given to discriminative
timestamps in representation learning, thus leading to performance bottlenecks
in MTS clustering. Masking has been widely adopted to enhance the MTS
representation, where temporal reconstruction tasks are designed to capture
critical information from MTS. However, most existing masking strategies appear
to be standalone preprocessing steps, isolated from the learning process, which
hinders dynamic adaptation to the importance of clustering-critical timestamps.
Accordingly, this paper proposes the Evolving-masked MTS Clustering (EMTC)
method, with its model architecture composed of Importance-aware Variate-wise
Masking (IVM) and Multi-Endogenous Views (MEV) representation learning modules.
IVM adaptively guides the model in learning more discriminative representations
for clustering, while the MEV-based reconstruction and contrastive learning
pathways enhance the generalization. That is, the MEV reconstruction
facilitates multi-perspective complementary to prevent the masking from
premature convergence, and the clustering-guided contrastive learning
facilitates the joint optimization of representation and clustering. Extensive
experiments on 15 real benchmark datasets demonstrate the superiority of EMTC
in comparison with eight SOTA methods, where the EMTC achieves an average
improvement of 4.85% over the strongest baselines.
\\ ( https://arxiv.org/abs/2511.17008 ,  943kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17031
Date: Fri, 21 Nov 2025 08:12:47 GMT   (1379kb)

Title: Energy Scaling Laws for Diffusion Models: Quantifying Compute and Carbon
 Emissions in Image Generation
Authors: Aniketh Iyengar, Jiaqi Han, Boris Ruf, Vincent Grari, Marcin
 Detyniecki, Stefano Ermon
Categories: cs.LG cs.CV cs.CY
Comments: Accepted at EurIPS 2025 workshop "Rethinking AI: Efficiency,
 Frugality, and Sustainability"
\\
 The rapidly growing computational demands of diffusion models for image
generation have raised significant concerns about energy consumption and
environmental impact. While existing approaches to energy optimization focus on
architectural improvements or hardware acceleration, there is a lack of
principled methods to predict energy consumption across different model
configurations and hardware setups. We propose an adaptation of Kaplan scaling
laws to predict GPU energy consumption for diffusion models based on
computational complexity (FLOPs). Our approach decomposes diffusion model
inference into text encoding, iterative denoising, and decoding components,
with the hypothesis that denoising operations dominate energy consumption due
to their repeated execution across multiple inference steps. We conduct
comprehensive experiments across four state-of-the-art diffusion models (Stable
Diffusion 2, Stable Diffusion 3.5, Flux, and Qwen) on three GPU architectures
(NVIDIA A100, A4000, A6000), spanning various inference configurations
including resolution (256x256 to 1024x1024), precision (fp16/fp32), step counts
(10-50), and classifier-free guidance settings. Our energy scaling law achieves
high predictive accuracy within individual architectures (R-squared > 0.9) and
exhibits strong cross-architecture generalization, maintaining high rank
correlations across models and enabling reliable energy estimation for unseen
model-hardware combinations. These results validate the compute-bound nature of
diffusion inference and provide a foundation for sustainable AI deployment
planning and carbon footprint estimation.
\\ ( https://arxiv.org/abs/2511.17031 ,  1379kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17040
Date: Fri, 21 Nov 2025 08:31:43 GMT   (684kb)

Title: Step-E: A Differentiable Data Cleaning Framework for Robust Learning
 with Noisy Labels
Authors: Wenzhang Du
Categories: cs.LG
Comments: 12 pages, 4 figures
MSC-class: 68T05
ACM-class: I.2.6; I.5.1
\\
 Training data collected in the wild often contain noisy labels and outliers
that substantially degrade the performance and reliability of deep neural
networks. While data cleaning is commonly applied as a separate preprocessing
stage, such two-stage pipelines neither fully exploit feedback from the
downstream model nor adapt to unknown noise patterns. We propose Step-E, a
simple framework that integrates sample selection and model learning into a
single optimization process. At each epoch, Step-E ranks samples by loss and
gradually increases the fraction of high-loss examples that are excluded from
gradient updates after a brief warm-up stage, yielding an online curriculum
that focuses on easy and consistent examples and eventually ignores persistent
outliers. On CIFAR-100N, Step-E improves the test accuracy of a ResNet-18 model
from 43.3% (+/- 0.7%) to 50.4% (+/- 0.9%), clearly outperforming loss
truncation, self-paced learning, and one-shot filtering while approaching the
clean-label oracle at 60.5% (+/- 0.2%). On CIFAR-10N (aggre), Step-E also
improves over the noisy baseline (85.3% vs. 83.9%) and nearly matches the
clean-label oracle (85.9%), with only moderate training-time overhead.
\\ ( https://arxiv.org/abs/2511.17040 ,  684kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17078
Date: Fri, 21 Nov 2025 09:31:42 GMT   (2212kb)

Title: Hash Collisions in Molecular Fingerprints: Effects on Property
 Prediction and Bayesian Optimization
Authors: Walter Virany, Austin Tripp
Categories: cs.LG
Comments: NeurIPS 2025 AI4Science workshop. Code:
 https://github.com/wvirany/molcollisions Openreview:
 https://openreview.net/forum?id=POgOHi8a7t
\\
 Molecular fingerprinting methods use hash functions to create fixed-length
vector representations of molecules. However, hash collisions cause distinct
substructures to be represented with the same feature, leading to overestimates
in molecular similarity calculations. We investigate whether using exact
fingerprints improves accuracy compared to standard compressed fingerprints in
molecular property prediction and Bayesian optimization where the underlying
predictive model is a Gaussian process. We find that using exact fingerprints
yields a small yet consistent improvement in predictive accuracy on five
molecular property prediction benchmarks from the DOCKSTRING dataset. However,
these gains did not translate to significant improvements in Bayesian
optimization performance.
\\ ( https://arxiv.org/abs/2511.17078 ,  2212kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17085
Date: Fri, 21 Nov 2025 09:40:52 GMT   (251kb)

Title: Why Do Language Model Agents Whistleblow?
Authors: Kushal Agrawal, Frank Xiao, Guido Bergman, Asa Cooper Stickland
Categories: cs.LG cs.AI
\\
 The deployment of Large Language Models (LLMs) as tool-using agents causes
their alignment training to manifest in new ways. Recent work finds that
language models can use tools in ways that contradict the interests or explicit
instructions of the user. We study LLM whistleblowing: a subset of this
behavior where models disclose suspected misconduct to parties beyond the
dialog boundary (e.g., regulatory agencies) without user instruction or
knowledge. We introduce an evaluation suite of diverse and realistic staged
misconduct scenarios to assess agents for this behavior. Across models and
settings, we find that: (1) the frequency of whistleblowing varies widely
across model families, (2) increasing the complexity of the task the agent is
instructed to complete lowers whistleblowing tendencies, (3) nudging the agent
in the system prompt to act morally substantially raises whistleblowing rates,
and (4) giving the model more obvious avenues for non-whistleblowing behavior,
by providing more tools and a detailed workflow to follow, decreases
whistleblowing rates. Additionally, we verify the robustness of our dataset by
testing for model evaluation awareness, and find that both black-box methods
and probes on model activations show lower evaluation awareness in our settings
than in comparable previous work.
\\ ( https://arxiv.org/abs/2511.17085 ,  251kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17100
Date: Fri, 21 Nov 2025 09:58:25 GMT   (904kb)

Title: Geometric-Disentangelment Unlearning
Authors: Duo Zhou, Yuji Zhang, Tianxin Wei, Ruizhong Qiu, Ke Yang, Xiao Lin,
 Cheng Qian, Jingrui He, Hanghang Tong, Heng Ji, Huan Zhang
Categories: cs.LG cs.AI cs.CL
Comments: 27 Pages
\\
 Machine unlearning, the removal of a training subset's influence from a
deployed model, is critical for privacy preservation and model reliability, yet
gradient ascent on forget samples often harms retained knowledge. Existing
approaches face a persistent tradeoff between effective forgetting and
preservation on the retain set. While previous methods provide useful
heuristics, they often lack a formal analysis on how exactly forgetting updates
harm retained knowledge, and whether the side effects can be removed with
theoretical guarantees. To explore a theoretically sound and simple solution,
we start from the first principle on how performance on the retain set is
actually affected: a first-order analysis of the local change of the retain
loss under small parameter updates during model training. We start from a crisp
equivalence: the retain loss is unchanged to first order iff the update
direction is orthogonal to the subspace spanned by retain gradients
("retain-invariant"). This identifies the entangled component as the tangential
part of forget update within the retain-gradient subspace, and characterizes
disentanglement as orthogonality. Guided by this, we propose the
Geometric-disentanglement Unlearning (GU) that decomposes any candidate forget
gradient update into tangential and normal components to retain space and
executes only the normal component. Under a standard trust-region budget, the
projected direction aligned with the raw forget gradient is optimal among all
first-order retain-invariant moves, and we also derive the optimal projected
direction for joint forget-retain updating objectives. Our method is
plug-and-play and can be attached to existing gradient-based unlearning
procedures to mitigate side effects. GU achieves consistent improvement on
various methods across three benchmarks TOFU, MUSE, and WMDP.
\\ ( https://arxiv.org/abs/2511.17100 ,  904kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17134
Date: Fri, 21 Nov 2025 10:53:19 GMT   (4237kb)

Title: Four decades of circumpolar super-resolved satellite land surface
 temperature data
Authors: Sonia Dupuis, Nando Metzger, Konrad Schindler, Frank G\"ottsche,
 Stefan Wunderle
Categories: cs.LG
\\
 Land surface temperature (LST) is an essential climate variable (ECV) crucial
for understanding land-atmosphere energy exchange and monitoring climate
change, especially in the rapidly warming Arctic. Long-term satellite-based LST
records, such as those derived from the Advanced Very High Resolution
Radiometer (AVHRR), are essential for detecting climate trends. However, the
coarse spatial resolution of AVHRR's global area coverage (GAC) data limit
their utility for analyzing fine-scale permafrost dynamics and other surface
processes in the Arctic. This paper presents a new 42 years pan-Arctic LST
dataset, downscaled from AVHRR GAC to 1 km with a super-resolution algorithm
based on a deep anisotropic diffusion model. The model is trained on MODIS LST
data, using coarsened inputs and native-resolution outputs, guided by
high-resolution land cover, digital elevation, and vegetation height maps. The
resulting dataset provides twice-daily, 1 km LST observations for the entire
pan-Arctic region over four decades. This enhanced dataset enables improved
modelling of permafrost, reconstruction of near-surface air temperature, and
assessment of surface mass balance of the Greenland Ice Sheet. Additionally, it
supports climate monitoring efforts in the pre-MODIS era and offers a framework
adaptable to future satellite missions for thermal infrared observation and
climate data record continuity.
\\ ( https://arxiv.org/abs/2511.17134 ,  4237kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17200
Date: Fri, 21 Nov 2025 12:26:33 GMT   (3484kb)

Title: Reconstruction of Surface EMG Signal using IMU data for Upper Limb
 Actions
Authors: Shubhranil Basak, Mada Hemanth, Madhav Rao
Categories: cs.LG
Comments: 5 pages, 5 figures
\\
 Surface Electromyography (sEMG) provides vital insights into muscle function,
but it can be noisy and challenging to acquire. Inertial Measurement Units
(IMUs) provide a robust and wearable alternative to motion capture systems.
This paper investigates the synthesis of normalized sEMG signals from 6-axis
IMU data using a deep learning approach. We collected simultaneous sEMG and IMU
data sampled at 1~KHz for various arm movements. A Sliding-Window-Wave-Net
model, based on dilated causal convolutions, was trained to map the IMU data to
the sEMG signal. The results show that the model successfully predicts the
timing and general shape of muscle activations. Although peak amplitudes were
often underestimated, the high temporal fidelity demonstrates the feasibility
of using this method for muscle intent detection in applications such as
prosthetics and rehabilitation biofeedback.
\\ ( https://arxiv.org/abs/2511.17200 ,  3484kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17219
Date: Fri, 21 Nov 2025 13:01:23 GMT   (6312kb)

Title: DelTriC: A Novel Clustering Method with Accurate Outlier
Authors: Tomas Javurek, Michal Gregor, Sebastian Kula, Marian Simko
Categories: cs.LG
Comments: 10 pages, submitted to AISTATS
\\
 The paper introduces DelTriC (Delaunay Triangulation Clustering), a
clustering algorithm which integrates PCA/UMAP-based projection, Delaunay
triangulation, and a novel back-projection mechanism to form clusters in the
original high-dimensional space. DelTriC decouples neighborhood construction
from decision-making by first triangulating in a low-dimensional proxy to index
local adjacency, and then back-projecting to the original space to perform
robust edge pruning, merging, and anomaly detection. DelTriC can outperform
traditional methods such as k-means, DBSCAN, and HDBSCAN in many scenarios; it
is both scalable and accurate, and it also significantly improves outlier
detection.
\\ ( https://arxiv.org/abs/2511.17219 ,  6312kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17229
Date: Fri, 21 Nov 2025 13:15:25 GMT   (10178kb)

Title: Generating transition states of chemical reactions via
 distance-geometry-based flow matching
Authors: Yufei Luo and Xiang Gu and Jian Sun
Categories: cs.LG physics.chem-ph
\\
 Transition states (TSs) are crucial for understanding reaction mechanisms,
yet their exploration is limited by the complexity of experimental and
computational approaches. Here we propose TS-DFM, a flow matching framework
that predicts TSs from reactants and products. By operating in molecular
distance geometry space, TS-DFM explicitly captures the dynamic changes of
interatomic distances in chemical reactions. A network structure named TSDVNet
is designed to learn the velocity field for generating TS geometries
accurately. On the benchmark dataset Transition1X, TS-DFM outperforms the
previous state-of-the-art method React-OT by 30\% in structural accuracy. These
predicted TSs provide high-quality initial structures, accelerating the
convergence of CI-NEB optimization. Additionally, TS-DFM can identify
alternative reaction paths. In our experiments, even a more favorable TS with
lower energy barrier is discovered. Further tests on RGD1 dataset confirm its
strong generalization ability on unseen molecules and reaction types,
highlighting its potential for facilitating reaction exploration.
\\ ( https://arxiv.org/abs/2511.17229 ,  10178kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17249
Date: Fri, 21 Nov 2025 13:50:54 GMT   (21188kb)

Title: FlexiFlow: decomposable flow matching for generation of flexible
 molecular ensemble
Authors: Riccardo Tedoldi, Ola Engkvist, Patrick Bryant, Hossein Azizpour, Jon
 Paul Janet, Alessandro Tibo
Categories: cs.LG
Comments: Preprint. Code to be released upon full publication
\\
 Sampling useful three-dimensional molecular structures along with their most
favorable conformations is a key challenge in drug discovery. Current
state-of-the-art 3D de-novo design flow matching or diffusion-based models are
limited to generating a single conformation. However, the conformational
landscape of a molecule determines its observable properties and how tightly it
is able to bind to a given protein target. By generating a representative set
of low-energy conformers, we can more directly assess these properties and
potentially improve the ability to generate molecules with desired
thermodynamic observables. Towards this aim, we propose FlexiFlow, a novel
architecture that extends flow-matching models, allowing for the joint sampling
of molecules along with multiple conformations while preserving both
equivariance and permutation invariance. We demonstrate the effectiveness of
our approach on the QM9 and GEOM Drugs datasets, achieving state-of-the-art
results in molecular generation tasks. Our results show that FlexiFlow can
generate valid, unstrained, unique, and novel molecules with high fidelity to
the training data distribution, while also capturing the conformational
diversity of molecules. Moreover, we show that our model can generate
conformational ensembles that provide similar coverage to state-of-the-art
physics-based methods at a fraction of the inference time. Finally, FlexiFlow
can be successfully transferred to the protein-conditioned ligand generation
task, even when the dataset contains only static pockets without accompanying
conformations.
\\ ( https://arxiv.org/abs/2511.17249 ,  21188kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17258
Date: Fri, 21 Nov 2025 14:03:28 GMT   (439kb)

Title: Enforcing governing equation constraints in neural PDE solvers via
 training-free projections
Authors: Omer Rochman and Gilles Louppe
Categories: cs.LG
Comments: Machine Learning and the Physical Sciences, Neurips 2025, San Diego
\\
 Neural PDE solvers used for scientific simulation often violate governing
equation constraints. While linear constraints can be projected cheaply, many
constraints are nonlinear, complicating projection onto the feasible set.
Dynamical PDEs are especially difficult because constraints induce long-range
dependencies in time. In this work, we evaluate two training-free, post hoc
projections of approximate solutions: a nonlinear optimization-based
projection, and a local linearization-based projection using Jacobian-vector
and vector-Jacobian products. We analyze constraints across representative PDEs
and find that both projections substantially reduce violations and improve
accuracy over physics-informed baselines.
\\ ( https://arxiv.org/abs/2511.17258 ,  439kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17275
Date: Fri, 21 Nov 2025 14:30:49 GMT   (1079kb)

Title: Automobile demand forecasting: Spatiotemporal and hierarchical modeling,
 life cycle dynamics, and user-generated online information
Authors: Tom Nahrendorf, Stefan Minner, Helfried Binder, Richard Zinck
Categories: cs.LG stat.AP
\\
 Premium automotive manufacturers face increasingly complex forecasting
challenges due to high product variety, sparse variant-level data, and volatile
market dynamics. This study addresses monthly automobile demand forecasting
across a multi-product, multi-market, and multi-level hierarchy using data from
a German premium manufacturer. The methodology combines point and probabilistic
forecasts across strategic and operational planning levels, leveraging
ensembles of LightGBM models with pooled training sets, quantile regression,
and a mixed-integer linear programming reconciliation approach. Results
highlight that spatiotemporal dependencies, as well as rounding bias,
significantly affect forecast accuracy, underscoring the importance of integer
forecasts for operational feasibility. Shapley analysis shows that short-term
demand is reactive, shaped by life cycle maturity, autoregressive momentum, and
operational signals, whereas medium-term demand reflects anticipatory drivers
such as online engagement, planning targets, and competitive indicators, with
online behavioral data considerably improving accuracy at disaggregated levels.
\\ ( https://arxiv.org/abs/2511.17275 ,  1079kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17298
Date: Fri, 21 Nov 2025 15:11:15 GMT   (78kb)

Title: SAVeD: Semantic Aware Version Discovery
Authors: Artem Frenk, Roee Shraga
Categories: cs.LG stat.ML
Comments: 11 pages, 6 figures
\\
 Our work introduces SAVeD (Semantically Aware Version Detection), a
contrastive learning-based framework for identifying versions of structured
datasets without relying on metadata, labels, or integration-based assumptions.
SAVeD addresses a common challenge in data science of repeated labor due to a
difficulty of similar work or transformations on datasets. SAVeD employs a
modified SimCLR pipeline, generating augmented table views through random
transformations (e.g., row deletion, encoding perturbations). These views are
embedded via a custom transformer encoder and contrasted in latent space to
optimize semantic similarity. Our model learns to minimize distances between
augmented views of the same dataset and maximize those between unrelated
tables. We evaluate performance using validation accuracy and separation,
defined respectively as the proportion of correctly classified
version/non-version pairs on a hold-out set, and the difference between average
similarities of versioned and non-versioned tables (defined by a benchmark, and
not provided to the model). Our experiments span five canonical datasets from
the Semantic Versioning in Databases Benchmark, and demonstrate substantial
gains post-training. SAVeD achieves significantly higher accuracy on completely
unseen tables in, and a significant boost in separation scores, confirming its
capability to distinguish semantically altered versions. Compared to untrained
baselines and prior state-of-the-art dataset-discovery methods like Starmie,
our custom encoder achieves competitive or superior results.
\\ ( https://arxiv.org/abs/2511.17298 ,  78kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17312
Date: Fri, 21 Nov 2025 15:30:44 GMT   (3720kb)

Title: Self-supervised denoising of raw tomography detector data for improved
 image reconstruction
Authors: Israt Jahan Tulin, Sebastian Starke, Dominic Windisch, Andr\'e
 Bieberle and Peter Steinbach
Categories: cs.LG
\\
 Ultrafast electron beam X-ray computed tomography produces noisy data due to
short measurement times, causing reconstruction artifacts and limiting overall
image quality. To counteract these issues, two self-supervised deep learning
methods for denoising of raw detector data were investigated and compared
against a non-learning based denoising method. We found that the application of
the deep-learning-based methods was able to enhance signal-to-noise ratios in
the detector data and also led to consistent improvements of the reconstructed
images, outperforming the non-learning based method.
\\ ( https://arxiv.org/abs/2511.17312 ,  3720kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17339
Date: Fri, 21 Nov 2025 16:00:13 GMT   (1710kb)

Title: ReBaPL: Repulsive Bayesian Prompt Learning
Authors: Yassir Bendou, Omar Ezzahir, Eduardo Fernandes Montesuma, Gabriel
 Mahuas, Victoria Shevchenko, Mike Gartrell
Categories: cs.LG
Comments: Under review
\\
 Prompt learning has emerged as an effective technique for fine-tuning
large-scale foundation models for downstream tasks. However, conventional
prompt tuning methods are prone to overfitting and can struggle with
out-of-distribution generalization. To address these limitations, Bayesian
prompt learning has been proposed, which frames prompt optimization as a
Bayesian inference problem to enhance robustness. This paper introduces
Repulsive Bayesian Prompt Learning (ReBaPL), a novel method for Bayesian prompt
learning, designed to efficiently explore the complex and often multimodal
posterior landscape of prompts. Our method integrates a cyclical step-size
schedule with a stochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm,
enabling alternating phases of exploration to discover new modes, and
exploitation to refine existing modes. Furthermore, we introduce a repulsive
force derived from a potential function over probability metrics (including
Maximum Mean Discrepancy and Wasserstein distance) computed on the
distributions of representations produced by different prompts. This
representation-space repulsion diversifies exploration and prevents premature
collapse to a single mode. Our approach allows for a more comprehensive
characterization of the prompt posterior distribution, leading to improved
generalization. In contrast to prior Bayesian prompt learning methods, our
method provides a modular plug-and-play Bayesian extension of any existing
prompt learning method based on maximum likelihood estimation. We demonstrate
the efficacy of ReBaPL on several benchmark datasets, showing superior
performance over state-of-the-art methods for prompt learning.
\\ ( https://arxiv.org/abs/2511.17339 ,  1710kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17351
Date: Fri, 21 Nov 2025 16:13:53 GMT   (103kb)

Title: Convergence and stability of Q-learning in Hierarchical Reinforcement
 Learning
Authors: Massimiliano Manenti, Andrea Iannelli
Categories: cs.LG cs.SY eess.SY math.OC
\\
 Hierarchical Reinforcement Learning promises, among other benefits, to
efficiently capture and utilize the temporal structure of a decision-making
problem and to enhance continual learning capabilities, but theoretical
guarantees lag behind practice. In this paper, we propose a Feudal Q-learning
scheme and investigate under which conditions its coupled updates converge and
are stable. By leveraging the theory of Stochastic Approximation and the ODE
method, we present a theorem stating the convergence and stability properties
of Feudal Q-learning. This provides a principled convergence and stability
analysis tailored to Feudal RL. Moreover, we show that the updates converge to
a point that can be interpreted as an equilibrium of a suitably defined game,
opening the door to game-theoretic approaches to Hierarchical RL. Lastly,
experiments based on the Feudal Q-learning algorithm support the outcomes
anticipated by theory.
\\ ( https://arxiv.org/abs/2511.17351 ,  103kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17367
Date: Fri, 21 Nov 2025 16:34:00 GMT   (4266kb)

Title: R2PS: Worst-Case Robust Real-Time Pursuit Strategies under Partial
 Observability
Authors: Runyu Lu, Ruochuan Shi, Yuanheng Zhu, Dongbin Zhao
Categories: cs.LG
\\
 Computing worst-case robust strategies in pursuit-evasion games (PEGs) is
time-consuming, especially when real-world factors like partial observability
are considered. While important for general security purposes, real-time
applicable pursuit strategies for graph-based PEGs are currently missing when
the pursuers only have imperfect information about the evader's position.
Although state-of-the-art reinforcement learning (RL) methods like Equilibrium
Policy Generalization (EPG) and Grasper provide guidelines for learning graph
neural network (GNN) policies robust to different game dynamics, they are
restricted to the scenario of perfect information and do not take into account
the possible case where the evader can predict the pursuers' actions. This
paper introduces the first approach to worst-case robust real-time pursuit
strategies (R2PS) under partial observability. We first prove that a
traditional dynamic programming (DP) algorithm for solving Markov PEGs
maintains optimality under the asynchronous moves by the evader. Then, we
propose a belief preservation mechanism about the evader's possible positions,
extending the DP pursuit strategies to a partially observable setting. Finally,
we embed the belief preservation into the state-of-the-art EPG framework to
finish our R2PS learning scheme, which leads to a real-time pursuer policy
through cross-graph reinforcement learning against the asynchronous-move DP
evasion strategies. After reinforcement learning, our policy achieves robust
zero-shot generalization to unseen real-world graph structures and consistently
outperforms the policy directly trained on the test graphs by the existing game
RL approach.
\\ ( https://arxiv.org/abs/2511.17367 ,  4266kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17378
Date: Fri, 21 Nov 2025 16:41:14 GMT   (650kb)

Title: A Unified Stability Analysis of SAM vs SGD: Role of Data Coherence and
 Emergence of Simplicity Bias
Authors: Wei-Kai Chang, Rajiv Khanna
Categories: cs.LG
Comments: Neurips 2025
\\
 Understanding the dynamics of optimization in deep learning is increasingly
important as models scale. While stochastic gradient descent (SGD) and its
variants reliably find solutions that generalize well, the mechanisms driving
this generalization remain unclear. Notably, these algorithms often prefer
flatter or simpler minima, particularly in overparameterized settings. Prior
work has linked flatness to generalization, and methods like Sharpness-Aware
Minimization (SAM) explicitly encourage flatness, but a unified theory
connecting data structure, optimization dynamics, and the nature of learned
solutions is still lacking. In this work, we develop a linear stability
framework that analyzes the behavior of SGD, random perturbations, and SAM,
particularly in two layer ReLU networks. Central to our analysis is a coherence
measure that quantifies how gradient curvature aligns across data points,
revealing why certain minima are stable and favored during training.
\\ ( https://arxiv.org/abs/2511.17378 ,  650kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17399
Date: Fri, 21 Nov 2025 17:00:00 GMT   (2181kb)

Title: Stable Coresets via Posterior Sampling: Aligning Induced and Full Loss
 Landscapes
Authors: Wei-Kai Chang, Rajiv Khanna
Categories: cs.LG
Comments: neurips 2025
\\
 As deep learning models continue to scale, the growing computational demands
have amplified the need for effective coreset selection techniques. Coreset
selection aims to accelerate training by identifying small, representative
subsets of data that approximate the performance of the full dataset. Among
various approaches, gradient based methods stand out due to their strong
theoretical underpinnings and practical benefits, particularly under limited
data budgets. However, these methods face challenges such as naive stochastic
gradient descent (SGD) acting as a surprisingly strong baseline and the
breakdown of representativeness due to loss curvature mismatches over time.
 In this work, we propose a novel framework that addresses these limitations.
First, we establish a connection between posterior sampling and loss
landscapes, enabling robust coreset selection even in high data corruption
scenarios. Second, we introduce a smoothed loss function based on posterior
sampling onto the model weights, enhancing stability and generalization while
maintaining computational efficiency. We also present a novel convergence
analysis for our sampling-based coreset selection method. Finally, through
extensive experiments, we demonstrate how our approach achieves faster training
and enhanced generalization across diverse datasets than the current state of
the art.
\\ ( https://arxiv.org/abs/2511.17399 ,  2181kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17419
Date: Fri, 21 Nov 2025 17:17:51 GMT   (872kb)

Title: DS-Span: Single-Phase Discriminative Subgraph Mining for Efficient Graph
 Embeddings
Authors: Yeamin Kaiser, Muhammed Tasnim Bin Anwar, Bholanath Das, Chowdhury
 Farhan Ahmed, Md. Tanvir Alam
Categories: cs.LG cs.AI
\\
 Graph representation learning seeks to transform complex, high-dimensional
graph structures into compact vector spaces that preserve both topology and
semantics. Among the various strategies, subgraph-based methods provide an
interpretable bridge between symbolic pattern discovery and continuous
embedding learning. Yet, existing frequent or discriminative subgraph mining
approaches often suffer from redundant multi-phase pipelines, high
computational cost, and weak coupling between mined structures and their
discriminative relevance. We propose DS-Span, a single-phase discriminative
subgraph mining framework that unifies pattern growth, pruning, and
supervision-driven scoring within one traversal of the search space. DS-Span
introduces a coverage-capped eligibility mechanism that dynamically limits
exploration once a graph is sufficiently represented, and an
information-gain-guided selection that promotes subgraphs with strong
class-separating ability while minimizing redundancy. The resulting subgraph
set serves as an efficient, interpretable basis for downstream graph embedding
and classification. Extensive experiments across benchmarks demonstrate that
DS-Span generates more compact and discriminative subgraph features than prior
multi-stage methods, achieving higher or comparable accuracy with significantly
reduced runtime. These results highlight the potential of unified, single-phase
discriminative mining as a foundation for scalable and interpretable graph
representation learning.
\\ ( https://arxiv.org/abs/2511.17419 ,  872kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17426
Date: Fri, 21 Nov 2025 17:22:31 GMT   (6199kb)

Title: Self-Supervised Learning by Curvature Alignment
Authors: Benyamin Ghojogh, M.Hadi Sepanj, Paul Fieguth
Categories: cs.LG cs.CV stat.ML
\\
 Self-supervised learning (SSL) has recently advanced through non-contrastive
methods that couple an invariance term with variance, covariance, or
redundancy-reduction penalties. While such objectives shape first- and
second-order statistics of the representation, they largely ignore the local
geometry of the underlying data manifold. In this paper, we introduce CurvSSL,
a curvature-regularized self-supervised learning framework, and its RKHS
extension, kernel CurvSSL. Our approach retains a standard two-view
encoder-projector architecture with a Barlow Twins-style redundancy-reduction
loss on projected features, but augments it with a curvature-based regularizer.
Each embedding is treated as a vertex whose $k$ nearest neighbors define a
discrete curvature score via cosine interactions on the unit hypersphere; in
the kernel variant, curvature is computed from a normalized local Gram matrix
in an RKHS. These scores are aligned and decorrelated across augmentations by a
Barlow-style loss on a curvature-derived matrix, encouraging both view
invariance and consistency of local manifold bending. Experiments on MNIST and
CIFAR-10 datasets with a ResNet-18 backbone show that curvature-regularized SSL
yields competitive or improved linear evaluation performance compared to Barlow
Twins and VICReg. Our results indicate that explicitly shaping local geometry
is a simple and effective complement to purely statistical SSL regularizers.
\\ ( https://arxiv.org/abs/2511.17426 ,  6199kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17427
Date: Fri, 21 Nov 2025 17:24:00 GMT   (796kb)

Title: Towards fully differentiable neural ocean model with Veros
Authors: Etienne Meunier, Said Ouala, Hugo Frezat, Julien Le Sommer, Ronan
 Fablet
Categories: cs.LG
Comments: Accepted to Differentiable Systems and Scientific Machine Learning
 (workshop, EurIPS 2025)
\\
 We present a differentiable extension of the VEROS ocean model, enabling
automatic differentiation through its dynamical core. We describe the key
modifications required to make the model fully compatible with JAX
autodifferentiation framework and evaluate the numerical consistency of the
resulting implementation. Two illustrative applications are then demonstrated:
(i) the correction of an initial ocean state through gradient-based
optimization, and (ii) the calibration of unknown physical parameters directly
from model observations. These examples highlight how differentiable
programming can facilitate end-to-end learning and parameter tuning in ocean
modeling. Our implementation is available online.
\\ ( https://arxiv.org/abs/2511.17427 ,  796kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17435
Date: Fri, 21 Nov 2025 17:32:10 GMT   (10242kb)

Title: Multi-Agent Pointer Transformer: Seq-to-Seq Reinforcement Learning for
 Multi-Vehicle Dynamic Pickup-Delivery Problems
Authors: Zengyu Zou, Jingyuan Wang, Yixuan Huang, Junjie Wu
Categories: cs.LG
Comments: 15 pages
\\
 This paper addresses the cooperative Multi-Vehicle Dynamic Pickup and
Delivery Problem with Stochastic Requests (MVDPDPSR) and proposes an end-to-end
centralized decision-making framework based on sequence-to-sequence, named
Multi-Agent Pointer Transformer (MAPT). MVDPDPSR is an extension of the vehicle
routing problem and a spatio-temporal system optimization problem, widely
applied in scenarios such as on-demand delivery. Classical operations research
methods face bottlenecks in computational complexity and time efficiency when
handling large-scale dynamic problems. Although existing reinforcement learning
methods have achieved some progress, they still encounter several challenges:
1) Independent decoding across multiple vehicles fails to model joint action
distributions; 2) The feature extraction network struggles to capture
inter-entity relationships; 3) The joint action space is exponentially large.
To address these issues, we designed the MAPT framework, which employs a
Transformer Encoder to extract entity representations, combines a Transformer
Decoder with a Pointer Network to generate joint action sequences in an
AutoRegressive manner, and introduces a Relation-Aware Attention module to
capture inter-entity relationships. Additionally, we guide the model's
decision-making using informative priors to facilitate effective exploration.
Experiments on 8 datasets demonstrate that MAPT significantly outperforms
existing baseline methods in terms of performance and exhibits substantial
computational time advantages compared to classical operations research
methods.
\\ ( https://arxiv.org/abs/2511.17435 ,  10242kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17439
Date: Fri, 21 Nov 2025 17:36:12 GMT   (2817kb)

Title: InTAct: Interval-based Task Activation Consolidation for Continual
 Learning
Authors: Patryk Krukowski, Jan Miksa, Piotr Helm, Jacek Tabor, Pawe{\l}
 Wawrzy\'nski, Przemys{\l}aw Spurek
Categories: cs.LG cs.AI
\\
 Continual learning aims to enable neural networks to acquire new knowledge
without forgetting previously learned information. While recent prompt-based
methods perform strongly in class-incremental settings, they remain vulnerable
under domain shifts, where the input distribution changes but the label space
remains fixed. This exposes a persistent problem known as representation drift.
Shared representations evolve in ways that overwrite previously useful features
and cause forgetting even when prompts isolate task-specific parameters. To
address this issue, we introduce InTAct, a method that preserves functional
behavior in shared layers without freezing parameters or storing past data.
InTAct captures the characteristic activation ranges associated with previously
learned tasks and constrains updates to ensure the network remains consistent
within these regions, while still allowing for flexible adaptation elsewhere.
In doing so, InTAct stabilizes the functional role of important neurons rather
than directly restricting parameter values. The approach is
architecture-agnostic and integrates seamlessly into existing prompt-based
continual learning frameworks. By regulating representation changes where past
knowledge is encoded, InTAct achieves a principled balance between stability
and plasticity. Across diverse domain-incremental benchmarks, including
DomainNet and ImageNet-R, InTAct consistently reduces representation drift and
improves performance, increasing Average Accuracy by up to 8 percentage points
over state-of-the-art baselines.
\\ ( https://arxiv.org/abs/2511.17439 ,  2817kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17446
Date: Fri, 21 Nov 2025 17:45:00 GMT   (3454kb)

Title: Unmasking Airborne Threats: Guided-Transformers for Portable Aerosol
 Mass Spectrometry
Authors: Kyle M. Regan, Michael McLoughlin, Wayne A. Bryden, Gonzalo R. Arce
Categories: cs.LG
Comments: 13 pages, 9 figures. Preprint. Submitted to Computers in Biology and
 Medicine
ACM-class: I.2.6; I.5.4; J.3
\\
 Matrix Assisted Laser Desorption/Ionization Mass Spectrometry (MALDI-MS) is a
cornerstone in biomolecular analysis, offering precise identification of
pathogens through unique mass spectral signatures. Yet, its reliance on
labor-intensive sample preparation and multi-shot spectral averaging restricts
its use to laboratory settings, rendering it impractical for real-time
environmental monitoring. These limitations are especially pronounced in
emerging aerosol MALDI-MS systems, where autonomous sampling generates noisy
spectra for unknown aerosol analytes, requiring single-shot detection for
effective analysis. Addressing these challenges, we propose the Mass Spectral
Dictionary-Guided Transformer (MS-DGFormer): a data-driven framework that
redefines spectral analysis by directly processing raw, minimally prepared mass
spectral data. MS-DGFormer leverages a transformer architecture, designed to
capture the long-range dependencies inherent in these time-series spectra. To
enhance feature extraction, we introduce a novel dictionary encoder that
integrates denoised spectral information derived from Singular Value
Decomposition (SVD), enabling the model to discern critical biomolecular
patterns from single-shot spectra with robust performance. This innovation
provides a system to achieve superior pathogen identification from aerosol
samples, facilitating autonomous, real-time analysis in field conditions. By
eliminating the need for extensive preprocessing, our method unlocks the
potential for portable, deployable MALDI-MS platforms, revolutionizing
environmental pathogen detection and rapid response to biological threats.
\\ ( https://arxiv.org/abs/2511.17446 ,  3454kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17467
Date: Fri, 21 Nov 2025 18:15:47 GMT   (1063kb)

Title: PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for
 Personalized LLM
Authors: Siqi Liang, Yudi Zhang, Yue Guo
Categories: cs.LG cs.AI
\\
 We propose a novel framework for persona-based language model system,
motivated by the need for personalized AI agents that adapt to individual user
preferences. In our approach, the agent embodies the user's "persona" (e.g.
user profile or taste) and is powered by a large language model (LLM). To
enable the agent to leverage rich contextual information, we introduce a
Knowledge-Graph-enhanced Retrieval-Augmented Generation (Graph RAG) mechanism
that constructs an LLM-derived graph index of relevant documents and summarizes
communities of related information. Our framework generates personalized
prompts by combining: (1) a summary of the user's historical behaviors and
preferences extracted from the knowledge graph, and (2) relevant global
interaction patterns identified through graph-based community detection. This
dynamic prompt engineering approach allows the agent to maintain consistent
persona-aligned behaviors while benefiting from collective knowledge. On the
LaMP benchmark, our method improves news categorization F1 by 11.1%, movie
tagging F1 by 56.1%, and reduces product rating MAE by 10.4% over prior
methods. Our code is available at
https://anonymous.4open.science/r/PersonaAgentwGraphRAG-DE6F
\\ ( https://arxiv.org/abs/2511.17467 ,  1063kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17489
Date: Fri, 21 Nov 2025 18:45:53 GMT   (136kb)

Title: Harnessing Data from Clustered LQR Systems: Personalized and
 Collaborative Policy Optimization
Authors: Vinay Kanakeri, Shivam Bajaj, Ashwin Verma, Vijay Gupta, Aritra Mitra
Categories: cs.LG cs.SY eess.SY math.OC
\\
 It is known that reinforcement learning (RL) is data-hungry. To improve
sample-efficiency of RL, it has been proposed that the learning algorithm
utilize data from 'approximately similar' processes. However, since the process
models are unknown, identifying which other processes are similar poses a
challenge. In this work, we study this problem in the context of the benchmark
Linear Quadratic Regulator (LQR) setting. Specifically, we consider a setting
with multiple agents, each corresponding to a copy of a linear process to be
controlled. The agents' local processes can be partitioned into clusters based
on similarities in dynamics and tasks. Combining ideas from sequential
elimination and zeroth-order policy optimization, we propose a new algorithm
that performs simultaneous clustering and learning to output a personalized
policy (controller) for each cluster. Under a suitable notion of cluster
separation that captures differences in closed-loop performance across systems,
we prove that our approach guarantees correct clustering with high probability.
Furthermore, we show that the sub-optimality gap of the policy learned for each
cluster scales inversely with the size of the cluster, with no additional bias,
unlike in prior works on collaborative learning-based control. Our work is the
first to reveal how clustering can be used in data-driven control to learn
personalized policies that enjoy statistical gains from collaboration but do
not suffer sub-optimality due to inclusion of data from dissimilar processes.
From a distributed implementation perspective, our method is attractive as it
incurs only a mild logarithmic communication overhead.
\\ ( https://arxiv.org/abs/2511.17489 ,  136kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2409.18972 (*cross-listing*)
Date: Thu, 12 Sep 2024 10:43:18 GMT   (425kb,D)

Title: Instance Configuration for Sustainable Job Shop Scheduling
Authors: Christian Perez, Carlos March and Miguel A. Salido
Categories: cs.DC cs.AI math.OC
Comments: 26th International Workshop on Configuration (ConfWS 2024)
MSC-class: 68W99
ACM-class: E.0; B.8; F.2; F.4
\\
 The Job Shop Scheduling Problem (JSP) is a pivotal challenge in operations
research and is essential for evaluating the effectiveness and performance of
scheduling algorithms. Scheduling problems are a crucial domain in
combinatorial optimization, where resources (machines) are allocated to job
tasks to minimize the completion time (makespan) alongside other objectives
like energy consumption. This research delves into the intricacies of JSP,
focusing on optimizing performance metrics and minimizing energy consumption
while considering various constraints such as deadlines and release dates.
Recognizing the multi-dimensional nature of benchmarking in JSP, this study
underscores the significance of reference libraries and datasets like JSPLIB in
enriching algorithm evaluation. The research highlights the importance of
problem instance characteristics, including job and machine numbers, processing
times, and machine availability, emphasizing the complexities introduced by
energy consumption considerations.
 An innovative instance configurator is proposed, equipped with parameters
such as the number of jobs, machines, tasks, and speeds, alongside
distributions for processing times and energy consumption. The generated
instances encompass various configurations, reflecting real-world scenarios and
operational constraints. These instances facilitate comprehensive benchmarking
and evaluation of scheduling algorithms, particularly in contexts of energy
efficiency. A comprehensive set of 500 test instances has been generated and
made publicly available, promoting further research and benchmarking in JSP.
These instances enable robust analyses and foster collaboration in developing
advanced, energy-efficient scheduling solutions by providing diverse scenarios.
\\ ( https://arxiv.org/abs/2409.18972 ,  425kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16700 (*cross-listing*)
Date: Tue, 18 Nov 2025 12:08:44 GMT   (252kb)

Title: RAG-Driven Data Quality Governance for Enterprise ERP Systems
Authors: Sedat Bin Vedat, Enes Kutay Yarkan, Meftun Akarsu, Recep Kaan Karaman,
 Arda Sar, \c{C}a\u{g}r{\i} \c{C}elikbilek, Sava\c{s} Sayg{\i}l{\i}
Categories: cs.DB cs.AI
\\
 Enterprise ERP systems managing hundreds of thousands of employee records
face critical data quality challenges when human resources departments perform
decentralized manual entry across multiple languages. We present an end-to-end
pipeline combining automated data cleaning with LLM-driven SQL query
generation, deployed on a production system managing 240,000 employee records
over six months.
 The system operates in two integrated stages: a multi-stage cleaning pipeline
that performs translation normalization, spelling correction, and entity
deduplication during periodic synchronization from Microsoft SQL Server to
PostgreSQL; and a retrieval-augmented generation framework powered by GPT-4o
that translates natural-language questions in Turkish, Russian, and English
into validated SQL queries. The query engine employs LangChain orchestration,
FAISS vector similarity search, and few-shot learning with 500+ validated
examples.
 Our evaluation demonstrates 92.5% query validity, 95.1% schema compliance,
and 90.7\% semantic accuracy on 2,847 production queries. The system reduces
query turnaround time from 2.3 days to under 5 seconds while maintaining 99.2%
uptime, with GPT-4o achieving 46% lower latency and 68% cost reduction versus
GPT-3.5. This modular architecture provides a reproducible framework for
AI-native enterprise data governance, demonstrating real-world viability at
enterprise scale with 4.3/5.0 user satisfaction.
\\ ( https://arxiv.org/abs/2511.16700 ,  252kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16707 (*cross-listing*)
Date: Thu, 20 Nov 2025 02:08:13 GMT   (743kb)

Title: Large language models for automated PRISMA 2020 adherence checking
Authors: Yuki Kataoka, Ryuhei So, Masahiro Banno, Yasushi Tsujimoto, Tomohiro
 Takayama, Yosuke Yamagishi, Takahiro Tsuge, Norio Yamamoto, Chiaki Suda,
 Toshi A. Furukawa
Categories: cs.SE cs.AI
\\
 Evaluating adherence to PRISMA 2020 guideline remains a burden in the peer
review process. To address the lack of shareable benchmarks, we constructed a
copyright-aware benchmark of 108 Creative Commons-licensed systematic reviews
and evaluated ten large language models (LLMs) across five input formats. In a
development cohort, supplying structured PRISMA 2020 checklists (Markdown,
JSON, XML, or plain text) yielded 78.7-79.7% accuracy versus 45.21% for
manuscript-only input (p less than 0.0001), with no differences between
structured formats (p>0.9). Across models, accuracy ranged from 70.6-82.8% with
distinct sensitivity-specificity trade-offs, replicated in an independent
validation cohort. We then selected Qwen3-Max (a high-sensitivity open-weight
model) and extended evaluation to the full dataset (n=120), achieving 95.1%
sensitivity and 49.3% specificity. Structured checklist provision substantially
improves LLM-based PRISMA assessment, though human expert verification remains
essential before editorial decisions.
\\ ( https://arxiv.org/abs/2511.16707 ,  743kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16708 (*cross-listing*)
Date: Thu, 20 Nov 2025 03:40:27 GMT   (37kb)

Title: Multi-Agent Code Verification with Compound Vulnerability Detection
Authors: Shreshth Rajan
Categories: cs.SE cs.AI cs.MA
Comments: 18 pages, 3 figures, 9 tables
ACM-class: D.2.5; I.2.2
\\
 LLMs generate buggy code: 29.6% of SWE-bench "solved" patches fail, 62% of
BaxBench solutions have vulnerabilities, and existing tools only catch 65% of
bugs with 35% false positives. We built CodeX-Verify, a multi-agent system that
uses four specialized agents to detect different types of bugs. We prove
mathematically that combining agents with different detection patterns finds
more bugs than any single agent when the agents look for different problems,
confirmed by measuring agent correlation of p = 0.05--0.25. We also show that
multiple vulnerabilities in the same code create exponentially more risk than
previously thought--SQL injection plus exposed credentials creates 15x more
danger (risk 300 vs. 20) than traditional models predict. Testing on 99 code
samples with verified labels shows our system catches 76.1% of bugs, matching
the best existing method while running faster and without test execution. We
tested 15 different agent combinations and found that using multiple agents
improves accuracy by 39.7 percentage points (from 32.8% to 72.4%) compared to
single agents, with gains of +14.9pp, +13.5pp, and +11.2pp for agents 2, 3, and
4. The best two-agent combination reaches 79.3% accuracy. Testing on 300 real
patches from Claude Sonnet 4.5 runs in under 200ms per sample, making this
practical for production use.
\\ ( https://arxiv.org/abs/2511.16708 ,  37kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16709 (*cross-listing*)
Date: Thu, 20 Nov 2025 03:58:54 GMT   (2178kb)

Title: AutoBackdoor: Automating Backdoor Attacks via LLM Agents
Authors: Yige Li, Zhe Li, Wei Zhao, Nay Myat Min, Hanxun Huang, Xingjun Ma, Jun
 Sun
Categories: cs.CR cs.AI
Comments: 23 pages
\\
 Backdoor attacks pose a serious threat to the secure deployment of large
language models (LLMs), enabling adversaries to implant hidden behaviors
triggered by specific inputs. However, existing methods often rely on manually
crafted triggers and static data pipelines, which are rigid, labor-intensive,
and inadequate for systematically evaluating modern defense robustness. As AI
agents become increasingly capable, there is a growing need for more rigorous,
diverse, and scalable \textit{red-teaming frameworks} that can realistically
simulate backdoor threats and assess model resilience under adversarial
conditions. In this work, we introduce \textsc{AutoBackdoor}, a general
framework for automating backdoor injection, encompassing trigger generation,
poisoned data construction, and model fine-tuning via an autonomous
agent-driven pipeline. Unlike prior approaches, AutoBackdoor uses a powerful
language model agent to generate semantically coherent, context-aware trigger
phrases, enabling scalable poisoning across arbitrary topics with minimal human
effort. We evaluate AutoBackdoor under three realistic threat scenarios,
including \textit{Bias Recommendation}, \textit{Hallucination Injection}, and
\textit{Peer Review Manipulation}, to simulate a broad range of attacks.
Experiments on both open-source and commercial models, including LLaMA-3,
Mistral, Qwen, and GPT-4o, demonstrate that our method achieves over 90\%
attack success with only a small number of poisoned samples. More importantly,
we find that existing defenses often fail to mitigate these attacks,
underscoring the need for more rigorous and adaptive evaluation techniques
against agent-driven threats as explored in this work. All code, datasets, and
experimental configurations will be merged into our primary repository at
https://github.com/bboylyg/BackdoorLLM.
\\ ( https://arxiv.org/abs/2511.16709 ,  2178kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16716 (*cross-listing*)
Date: Thu, 20 Nov 2025 18:34:33 GMT   (789kb)

Title: Password Strength Analysis Through Social Network Data Exposure: A
 Combined Approach Relying on Data Reconstruction and Generative Models
Authors: Maurizio Atzori, Eleonora Cal\`o, Loredana Caruccio, Stefano Cirillo,
 Giuseppe Polese, Giandomenico Solimando
Categories: cs.CR cs.AI
Comments: This is a post-peer-review, pre-copyedit version to be published in
 the Prooceedings of the 33rd Symposium On Advanced Database Systems (SEBD
 2025), 7 pages, 4 figures
\\
 Although passwords remain the primary defense against unauthorized access,
users often tend to use passwords that are easy to remember. This behavior
significantly increases security risks, also due to the fact that traditional
password strength evaluation methods are often inadequate. In this discussion
paper, we present SODA ADVANCE, a data reconstruction tool also designed to
enhance evaluation processes related to the password strength. In particular,
SODA ADVANCE integrates a specialized module aimed at evaluating password
strength by leveraging publicly available data from multiple sources, including
social media platforms. Moreover, we investigate the capabilities and risks
associated with emerging Large Language Models (LLMs) in evaluating and
generating passwords, respectively. Experimental assessments conducted with 100
real users demonstrate that LLMs can generate strong and personalized passwords
possibly defined according to user profiles. Additionally, LLMs were shown to
be effective in evaluating passwords, especially when they can take into
account user profile data.
\\ ( https://arxiv.org/abs/2511.16716 ,  789kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16757 (*cross-listing*)
Date: Thu, 20 Nov 2025 19:17:35 GMT   (2335kb)

Title: Revisiting Audio-language Pretraining for Learning General-purpose Audio
 Representation
Authors: Wei-Cheng Tseng, Xuanru Zhou, Mingyue Huo, Yiwen Shao, Hao Zhang, Dong
 Yu
Categories: eess.AS cs.AI
Comments: Work in progress
\\
 Audio-language pretraining holds promise for general-purpose audio
understanding, yet remains underexplored compared to its vision counterpart.
While vision-language models like CLIP serve as widely adopted foundations,
existing audio-language models primarily excel at retrieval tasks with limited
adoption as general-purpose encoders. We identify three key barriers: limited
large-scale audio-text corpora, insufficient caption diversity, and lack of
systematic exploration and evaluation. To this end, we introduce CaptionStew, a
10.7M caption dataset aggregating diverse open-source audio-text corpora across
multiple domains and captioning styles. Using this resource, we conduct the
first comprehensive evaluation comparing contrastive and captioning objectives
for audio representation learning across speech, music, and environmental sound
tasks. Our results demonstrate that audio-language pretraining yields
competitive, transferable representations. Through systematic data-scaling
experiments, we reveal complementary objective strengths: contrastive learning
achieves superior data efficiency at smaller scales, while captioning
demonstrates better scalability on language-involved audio understanding tasks.
We also find that common supervised initialization practices provide
diminishing returns at scale, challenging current approaches. These findings
establish audio-language pretraining as a viable pathway toward general-purpose
audio representations, guiding future research. To accelerate progress, we
release data preparation recipes, training protocols, and pretrained models,
paving the way toward universal audio understanding.
\\ ( https://arxiv.org/abs/2511.16757 ,  2335kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16783 (*cross-listing*)
Date: Thu, 20 Nov 2025 20:17:14 GMT   (6006kb)

Title: Generative Augmented Reality: Paradigms, Technologies, and Future
 Applications
Authors: Chen Liang, Jiawen Zheng, Yufeng Zeng, Yi Tan, Hengye Lyu, Yuhui
 Zheng, Zisu Li, Yueting Weng, Jiaxin Shi, and Hanwang Zhang
Categories: cs.HC cs.AI cs.CV
\\
 This paper introduces Generative Augmented Reality (GAR) as a next-generation
paradigm that reframes augmentation as a process of world re-synthesis rather
than world composition by a conventional AR engine. GAR replaces the
conventional AR engine's multi-stage modules with a unified generative
backbone, where environmental sensing, virtual content, and interaction signals
are jointly encoded as conditioning inputs for continuous video generation. We
formalize the computational correspondence between AR and GAR, survey the
technical foundations that make real-time generative augmentation feasible, and
outline prospective applications that leverage its unified inference model. We
envision GAR as a future AR paradigm that delivers high-fidelity experiences in
terms of realism, interactivity, and immersion, while eliciting new research
challenges on technologies, content ecosystems, and the ethical and societal
implications.
\\ ( https://arxiv.org/abs/2511.16783 ,  6006kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16854 (*cross-listing*)
Date: Thu, 20 Nov 2025 23:36:07 GMT   (1301kb)

Title: MRI Super-Resolution with Deep Learning: A Comprehensive Survey
Authors: Mohammad Khateri, Serge Vasylechko, Morteza Ghahremani, Liam Timms,
 Deniz Kocanaogullari, Simon K. Warfield, Camilo Jaimes, Davood Karimi,
 Alejandra Sierra, Jussi Tohka, Sila Kurugol, Onur Afacan
Categories: eess.IV cs.AI cs.CV eess.SP
Comments: 41 pages
\\
 High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many
clinical and research applications. However, achieving it remains costly and
constrained by technical trade-offs and experimental limitations.
Super-resolution (SR) presents a promising computational approach to overcome
these challenges by generating HR images from more affordable low-resolution
(LR) scans, potentially improving diagnostic accuracy and efficiency without
requiring additional hardware. This survey reviews recent advances in MRI SR
techniques, with a focus on deep learning (DL) approaches. It examines DL-based
MRI SR methods from the perspectives of computer vision, computational imaging,
inverse problems, and MR physics, covering theoretical foundations,
architectural designs, learning strategies, benchmark datasets, and performance
metrics. We propose a systematic taxonomy to categorize these methods and
present an in-depth study of both established and emerging SR techniques
applicable to MRI, considering unique challenges in clinical and research
contexts. We also highlight open challenges and directions that the community
needs to address. Additionally, we provide a collection of essential
open-access resources, tools, and tutorials, available on our GitHub:
https://github.com/mkhateri/Awesome-MRI-Super-Resolution.
 IEEE keywords: MRI, Super-Resolution, Deep Learning, Computational Imaging,
Inverse Problem, Survey.
\\ ( https://arxiv.org/abs/2511.16854 ,  1301kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16884 (*cross-listing*)
Date: Fri, 21 Nov 2025 01:34:28 GMT   (9183kb)

Title: Generative AI in Sociological Research: State of the Discipline
Authors: AJ Alvero, Dustin S. Stoltz, Oscar Stuhler, Marshall Taylor
Categories: cs.CY cs.AI
\\
 Generative artificial intelligence (GenAI) has garnered considerable
attention for its potential utility in research and scholarship, even among
those who typically do not rely on computational tools. Early commentators,
however, have also articulated concerns about how GenAI usage comes with
enormous environmental costs, serious social risks, and a tendency to produce
low-quality content. In the midst of both excitement and skepticism, it is
crucial to take stock of how GenAI is actually being used. Our study focuses on
sociological research as our site, and here we present findings from a survey
of 433 authors of articles published in 50 sociology journals in the last five
years. The survey provides an overview of the state of the discipline with
regard to the use of GenAI by providing answers to fundamental questions: how
(much) do scholars use the technology for their research; what are their
reasons for using it; and how concerned, trustful, and optimistic are they
about the technology? Of the approximately one third ofrespondents who
self-report using GenAI at least weekly, the primary uses are for writing
assistance and comparatively less so in planning, data collection, or data
analysis. In both use and attitudes, there are surprisingly few differences
between self-identified computational and non-computational researchers.
Generally, respondents are very concerned about the social and environmental
consequences of GenAI. Trust in GenAI outputs is low, regardless of expertise
or frequency of use. While optimism that GenAI will improve is high, scholars
are divided on whether GenAI will have a positive impact on the field.
\\ ( https://arxiv.org/abs/2511.16884 ,  9183kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16964 (*cross-listing*)
Date: Fri, 21 Nov 2025 05:37:38 GMT   (493kb)

Title: Optimizing PyTorch Inference with LLM-Based Multi-Agent Systems
Authors: Kirill Nagaitsev, Luka Grbcic, Samuel Williams, Costin Iancu
Categories: cs.MA cs.AI cs.DC
\\
 Maximizing performance on available GPU hardware is an ongoing challenge for
modern AI inference systems. Traditional approaches include writing custom GPU
kernels and using specialized model compilers to tune high-level code for
specific GPU targets. Recent work shows that LLM-based multi-agent systems can
effectively perform such tuning, often outperforming existing compilers and
eliminating the need for manual kernel development. However, the dynamics of
multi-agent systems for this task remain unexplored. In this work, we present a
logical framework for comparing multi-agent PyTorch optimization systems. Our
evaluation shows that exploit-heavy strategies perform best when paired with
error-fixing agents, and that performance correlates with the granularity of
optimization steps. The best implementation achieves an average 2.88x speedup
on an H100 GPU across diverse tasks in KernelBench, a benchmark suite covering
a range of machine learning architectures in PyTorch.
\\ ( https://arxiv.org/abs/2511.16964 ,  493kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17043 (*cross-listing*)
Date: Fri, 21 Nov 2025 08:42:20 GMT   (1945kb)

Title: MedImageInsight for Thoracic Cavity Health Classification from Chest
 X-rays
Authors: Rama Krishna Boya, Mohan Kireeti Magalanadu, Azaruddin Palavalli, Rupa
 Ganesh Tekuri, Amrit Pattanayak, Prasanthi Enuga, Vignesh Esakki Muthu, and
 Vivek Aditya Boya
Categories: eess.IV cs.AI cs.CV
Comments: 9 pages, 5 figures and 3 tables
\\
 Chest radiography remains one of the most widely used imaging modalities for
thoracic diagnosis, yet increasing imaging volumes and radiologist workload
continue to challenge timely interpretation. In this work, we investigate the
use of MedImageInsight, a medical imaging foundational model, for automated
binary classification of chest X-rays into Normal and Abnormal categories. Two
approaches were evaluated: (1) fine-tuning MedImageInsight for end-to-end
classification, and (2) employing the model as a feature extractor for a
transfer learning pipeline using traditional machine learning classifiers.
Experiments were conducted using a combination of the ChestX-ray14 dataset and
real-world clinical data sourced from partner hospitals. The fine-tuned
classifier achieved the highest performance, with an ROC-AUC of 0.888 and
superior calibration compared to the transfer learning models, demonstrating
performance comparable to established architectures such as CheXNet. These
results highlight the effectiveness of foundational medical imaging models in
reducing task-specific training requirements while maintaining diagnostic
reliability. The system is designed for integration into web-based and hospital
PACS workflows to support triage and reduce radiologist burden. Future work
will extend the model to multi-label pathology classification to provide
preliminary diagnostic interpretation in clinical environments.
\\ ( https://arxiv.org/abs/2511.17043 ,  1945kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17113 (*cross-listing*)
Date: Fri, 21 Nov 2025 10:22:00 GMT   (769kb)

Title: AutoGraphAD: A novel approach using Variational Graph Autoencoders for
 anomalous network flow detection
Authors: Georgios Anyfantis, Pere Barlet-Ros
Categories: cs.CR cs.AI cs.LG
Comments: 11 pages, 9 figures
\\
 Network Intrusion Detection Systems (NIDS) are essential tools for detecting
network attacks and intrusions. While extensive research has explored the use
of supervised Machine Learning for attack detection and characterisation, these
methods require accurately labelled datasets, which are very costly to obtain.
Moreover, existing public datasets have limited and/or outdated attacks, and
many of them suffer from mislabelled data. To reduce the reliance on labelled
data, we propose AutoGraphAD, a novel unsupervised anomaly detection approach
based on a Heterogeneous Variational Graph Autoencoder. AutoGraphAD operates on
heterogeneous graphs, made from connection and IP nodes that capture network
activity within a time window. The model is trained using unsupervised and
contrastive learning, without relying on any labelled data. The reconstruction,
structural loss, and KL divergence are then weighted and combined in an anomaly
score that is then used for anomaly detection. Overall, AutoGraphAD yields the
same, and in some cases better, results than previous unsupervised approaches,
such as Anomal-E, but without requiring costly downstream anomaly detectors. As
a result, AutoGraphAD achieves around 1.18 orders of magnitude faster training
and 1.03 orders of magnitude faster inference, which represents a significant
advantage for operational deployment.
\\ ( https://arxiv.org/abs/2511.17113 ,  769kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17131 (*cross-listing*)
Date: Fri, 21 Nov 2025 10:47:22 GMT   (3813kb)

Title: UI-CUBE: Enterprise-Grade Computer Use Agent Benchmarking Beyond Task
 Accuracy to Operational Reliability
Authors: Horia Cristescu, Charles Park, Trong Canh Nguyen, Sergiu Talmacel,
 Alexandru-Gabriel Ilie, Stefan Adam
Categories: cs.SE cs.AI
Comments: 18 pages, 8 figures, 5 tables. Benchmark comprising 226 tasks across
 two difficulty tiers. Code and benchmark available at
 https://github.com/UiPath/uipath_enterprise_benchmark
ACM-class: I.2.0; H.5.2
\\
 While current Computer Use Agent (CUA) benchmarks measure task completion
effectively, they provide limited assessment of enterprise deployment
readiness, emphasizing functional correctness over the operational reliability
required for production systems. We present UI-CUBE (UiPath Computer Use
BEnchmark), a systematic benchmark comprising 226 tasks across two difficulty
tiers designed to expose fundamental architectural limitations in current CUAs.
Our evaluation covers simple UI interactions (136 tasks) and complex workflows
including copy-paste tasks (50 tasks) and enterprise application scenarios (40
tasks), with systematic interface variation coverage, multi-resolution testing
and automated validation of task success through the application state.
Evaluation of five state-of-the-art models reveals a sharp capability cliff
rather than gradual performance degradation. Simple UI interactions achieve
67-85% success rates (compared to 97.9% human performance), but complex
workflows drop precipitously to 9-19%. Human evaluators with no prior
application experience achieve only 61.2% on complex tasks despite near-perfect
performance on simple tasks, establishing realistic performance ceilings. This
discontinuous performance pattern -- where agents achieve 68-87% of human
performance on simple tasks but only 15-32% on complex workflows -- indicates
fundamental architectural limitations in memory management, hierarchical
planning, and state coordination rather than incremental capability gaps
addressable through better training or prompting. UI-CUBE functions as an
enterprise-readiness diagnostic, revealing that while current CUAs can
manipulate individual interface elements, they cannot yet function as reliable
workflow automation tools. These findings provide architectural insights
essential for developing production-ready CUAs capable of managing complex,
multi-step enterprise processes.
\\ ( https://arxiv.org/abs/2511.17131 ,  3813kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17136 (*cross-listing*)
Date: Fri, 21 Nov 2025 10:57:11 GMT   (4102kb)

Title: Device-Guided Music Transfer
Authors: Manh Pham Hung, Changshuo Hu, Ting Dang, Dong Ma
Categories: cs.SD cs.AI
\\
 Device-guided music transfer adapts playback across unseen devices for users
who lack them. Existing methods mainly focus on modifying the timbre, rhythm,
harmony, or instrumentation to mimic genres or artists, overlooking the diverse
hardware properties of the playback device (i.e., speaker). Therefore, we
propose DeMT, which processes a speaker's frequency response curve as a line
graph using a vision-language model to extract device embeddings. These
embeddings then condition a hybrid transformer via feature-wise linear
modulation. Fine-tuned on a self-collected dataset, DeMT enables effective
speaker-style transfer and robust few-shot adaptation for unseen devices,
supporting applications like device-style augmentation and quality enhancement.
\\ ( https://arxiv.org/abs/2511.17136 ,  4102kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17225 (*cross-listing*)
Date: Fri, 21 Nov 2025 13:12:13 GMT   (1495kb)

Title: TP-MDDN: Task-Preferenced Multi-Demand-Driven Navigation with Autonomous
 Decision-Making
Authors: Shanshan Li, Da Huang, Yu He, Yanwei Fu, Yu-Gang Jiang, Xiangyang Xue
Categories: cs.RO cs.AI cs.CV
Comments: Accepted at NeurIPS 2025
\\
 In daily life, people often move through spaces to find objects that meet
their needs, posing a key challenge in embodied AI. Traditional Demand-Driven
Navigation (DDN) handles one need at a time but does not reflect the complexity
of real-world tasks involving multiple needs and personal choices. To bridge
this gap, we introduce Task-Preferenced Multi-Demand-Driven Navigation
(TP-MDDN), a new benchmark for long-horizon navigation involving multiple
sub-demands with explicit task preferences. To solve TP-MDDN, we propose
AWMSystem, an autonomous decision-making system composed of three key modules:
BreakLLM (instruction decomposition), LocateLLM (goal selection), and
StatusMLLM (task monitoring). For spatial memory, we design MASMap, which
combines 3D point cloud accumulation with 2D semantic mapping for accurate and
efficient environmental understanding. Our Dual-Tempo action generation
framework integrates zero-shot planning with policy-based fine control, and is
further supported by an Adaptive Error Corrector that handles failure cases in
real time. Experiments demonstrate that our approach outperforms
state-of-the-art baselines in both perception accuracy and navigation
robustness.
\\ ( https://arxiv.org/abs/2511.17225 ,  1495kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17233 (*cross-listing*)
Date: Fri, 21 Nov 2025 13:21:20 GMT   (557kb)

Title: Algorithmic design and implementation considerations of deep MPC
Authors: Prabhat K. Mishra, Mateus V. Gasparino, and Girish Chowdhary
Categories: eess.SY cs.AI cs.SY
\\
 Deep Model Predictive Control (Deep MPC) is an evolving field that integrates
model predictive control and deep learning. This manuscript is focused on a
particular approach, which employs deep neural network in the loop with MPC.
This class of approaches distributes control authority between a neural network
and an MPC controller, in such a way that the neural network learns the model
uncertainties while the MPC handles constraints. The approach is appealing
because training data collected while the system is in operation can be used to
fine-tune the neural network, and MPC prevents unsafe behavior during those
learning transients. This manuscript explains implementation challenges of Deep
MPC, algorithmic way to distribute control authority and argues that a poor
choice in distributing control authority may lead to poor performance. A reason
of poor performance is explained through a numerical experiment on a
four-wheeled skid-steer dynamics.
\\ ( https://arxiv.org/abs/2511.17233 ,  557kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17265 (*cross-listing*)
Date: Fri, 21 Nov 2025 14:13:16 GMT   (30622kb)

Title: DISCA: A Digital In-memory Stochastic Computing Architecture Using A
 Compressed Bent-Pyramid Format
Authors: Shady Agwa, Yikang Shen, Shiwei Wang, Themis Prodromakis
Categories: cs.AR cs.AI cs.ET cs.PF
Comments: 6 pages, 5 figures
\\
 Nowadays, we are witnessing an Artificial Intelligence revolution that
dominates the technology landscape in various application domains, such as
healthcare, robotics, automotive, security, and defense. Massive-scale AI
models, which mimic the human brain's functionality, typically feature millions
and even billions of parameters through data-intensive matrix multiplication
tasks. While conventional Von-Neumann architectures struggle with the memory
wall and the end of Moore's Law, these AI applications are migrating rapidly
towards the edge, such as in robotics and unmanned aerial vehicles for
surveillance, thereby adding more constraints to the hardware budget of AI
architectures at the edge. Although in-memory computing has been proposed as a
promising solution for the memory wall, both analog and digital in-memory
computing architectures suffer from substantial degradation of the proposed
benefits due to various design limitations. We propose a new digital in-memory
stochastic computing architecture, DISCA, utilizing a compressed version of the
quasi-stochastic Bent-Pyramid data format. DISCA inherits the same
computational simplicity of analog computing, while preserving the same
scalability, productivity, and reliability of digital systems. Post-layout
modeling results of DISCA show an energy efficiency of 3.59 TOPS/W per bit at
500 MHz using a commercial 180nm CMOS technology. Therefore, DISCA
significantly improves the energy efficiency for matrix multiplication
workloads by orders of magnitude if scaled and compared to its counterpart
architectures.
\\ ( https://arxiv.org/abs/2511.17265 ,  30622kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17276 (*cross-listing*)
Date: Fri, 21 Nov 2025 14:31:39 GMT   (2203kb)

Title: Leveraging CVAE for Joint Configuration Estimation of Multifingered
 Grippers from Point Cloud Data
Authors: Julien Merand, Boris Meden, Mathieu Grossard
Categories: cs.RO cs.AI cs.CV
Journal-ref: 2025 IEEE 21st International Conference on Automation Science and
 Engineering (CASE), Los Angeles, CA, USA, 2025, pp. 895-900
DOI: 10.1109/CASE58245.2025.11164060
\\
 This paper presents an efficient approach for determining the joint
configuration of a multifingered gripper solely from the point cloud data of
its poly-articulated chain, as generated by visual sensors, simulations or even
generative neural networks. Well-known inverse kinematics (IK) techniques can
provide mathematically exact solutions (when they exist) for joint
configuration determination based solely on the fingertip pose, but often
require post-hoc decision-making by considering the positions of all
intermediate phalanges in the gripper's fingers, or rely on algorithms to
numerically approximate solutions for more complex kinematics. In contrast, our
method leverages machine learning to implicitly overcome these challenges. This
is achieved through a Conditional Variational Auto-Encoder (CVAE), which takes
point cloud data of key structural elements as input and reconstructs the
corresponding joint configurations. We validate our approach on the MultiDex
grasping dataset using the Allegro Hand, operating within 0.05 milliseconds and
achieving accuracy comparable to state-of-the-art methods. This highlights the
effectiveness of our pipeline for joint configuration estimation within the
broader context of AI-driven techniques for grasp planning.
\\ ( https://arxiv.org/abs/2511.17276 ,  2203kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17318 (*cross-listing*)
Date: Fri, 21 Nov 2025 15:36:41 GMT   (15021kb)

Title: FORWARD: Dataset of a forwarder operating in rough terrain
Authors: Mikael Lundb\"ack, Erik Wallin, Carola H\"aggstr\"om, Mattias
 Nystr\"om, Andreas Gr\"onlund, Mats Richardson, Petrus J\"onsson, William
 Arnvik, Lucas Hedstr\"om, Arvid F\"alldin, Martin Servin
Categories: cs.RO cs.AI cs.CE cs.LG physics.app-ph
Comments: 25 pages, 22 figures
\\
 We present FORWARD, a high-resolution multimodal dataset of a cut-to-length
forwarder operating in rough terrain on two harvest sites in the middle part of
Sweden. The forwarder is a large Komatsu model equipped with a variety of
sensors, including RTK-GNSS, 360-camera, operator vibration sensors, internal
CAN-bus signal recording, and multiple IMUs. The data includes event time logs
recorded in 5 Hz with e.g., driving speed, fuel consumption, vehicle position
with centimeter accuracy, and crane use while the vehicle operates in forest
areas laser-scanned with very high-resolution, $\sim$1500 points per square
meter. Production log files (StanForD standard) with time-stamped machine
events, extensive video material, and terrain data in various formats are
included as well. About 18 hours of regular wood extraction work during three
days is annotated from 360-video material into individual work elements and
included in the dataset. We also include scenario specifications of conducted
experiments on forest roads and in terrain. Scenarios include repeatedly
driving the same routes with and without steel tracks, different load weight,
and different target driving speeds. The dataset is intended for developing
models and algorithms for trafficability, perception, and autonomous control of
forest machines using artificial intelligence, simulation, and experiments on
physical testbeds. In part, we focus on forwarders traversing terrain, avoiding
obstacles, and loading or unloading logs, with consideration for efficiency,
fuel consumption, safety, and environmental impact. Other benefits of the open
dataset include the ability to explore auto-generation and calibration of
forestry machine simulators and automation scenario descriptions using the data
recorded in the field.
\\ ( https://arxiv.org/abs/2511.17318 ,  15021kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17323 (*cross-listing*)
Date: Fri, 21 Nov 2025 15:43:27 GMT   (6654kb)

Title: MusicAIR: A Multimodal AI Music Generation Framework Powered by an
 Algorithm-Driven Core
Authors: Callie C. Liao, Duoduo Liao, Ellie L. Zhang
Categories: cs.SD cs.AI cs.CL cs.MM
Comments: Accepted by IEEE Big Data 2025
\\
 Recent advances in generative AI have made music generation a prominent
research focus. However, many neural-based models rely on large datasets,
raising concerns about copyright infringement and high-performance costs. In
contrast, we propose MusicAIR, an innovative multimodal AI music generation
framework powered by a novel algorithm-driven symbolic music core, effectively
mitigating copyright infringement risks. The music core algorithms connect
critical lyrical and rhythmic information to automatically derive musical
features, creating a complete, coherent melodic score solely from the lyrics.
The MusicAIR framework facilitates music generation from lyrics, text, and
images. The generated score adheres to established principles of music theory,
lyrical structure, and rhythmic conventions. We developed Generate AI Music
(GenAIM), a web tool using MusicAIR for lyric-to-song, text-to-music, and
image-to-music generation. In our experiments, we evaluated AI-generated music
scores produced by the system using both standard music metrics and innovative
analysis that compares these compositions with original works. The system
achieves an average key confidence of 85%, outperforming human composers at
79%, and aligns closely with established music theory standards, demonstrating
its ability to generate diverse, human-like compositions. As a co-pilot tool,
GenAIM can serve as a reliable music composition assistant and a possible
educational composition tutor while simultaneously lowering the entry barrier
for all aspiring musicians, which is innovative and significantly contributes
to AI for music generation.
\\ ( https://arxiv.org/abs/2511.17323 ,  6654kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17331 (*cross-listing*)
Date: Fri, 21 Nov 2025 15:52:44 GMT   (569kb)

Title: AI Workers, Geopolitics, and Algorithmic Collective Action
Authors: Sydney Reis
Categories: cs.CY cs.AI cs.HC
ACM-class: K.4.0; H.5.2
\\
 According to the theory of International Political Economy (IPE), states are
often incentivized to rely on rather than constrain powerful corporations. For
this reason, IPE provides a useful lens to explain why efforts to govern
Artificial Intelligence (AI) at the international and national levels have thus
far been developed, applied, and enforced unevenly. Building on recent work
that explores how AI companies engage in geopolitics, this position paper
argues that some AI workers can be considered actors of geopolitics. It makes
the timely case that governance alone cannot ensure responsible, ethical, or
robust AI development and use, and greater attention should be paid to
bottom-up interventions at the site of AI development. AI workers themselves
should be situated as individual agents of change, especially when considering
their potential to foster Algorithmic Collective Action (ACA). Drawing on
methods of Participatory Design (PD), this paper proposes engaging AI workers
as sources of knowledge, relative power, and intentionality to encourage more
responsible and just AI development and create the conditions that can
facilitate ACA.
\\ ( https://arxiv.org/abs/2511.17331 ,  569kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17346 (*cross-listing*)
Date: Thu, 20 Nov 2025 09:14:56 GMT   (282kb,D)

Title: Is Phase Really Needed for Weakly-Supervised Dereverberation ?
Authors: Marius Rodrigues (IDS, S2A), Louis Bahrman (IDS, S2A), Roland Badeau
 (IDS, S2A), Ga\"el Richard (S2A, IDS)
Categories: cs.SD cs.AI eess.SP physics.class-ph stat.ML
\\
 In unsupervised or weakly-supervised approaches for speech dereverberation,
the target clean (dry) signals are considered to be unknown during training. In
that context, evaluating to what extent information can be retrieved from the
sole knowledge of reverberant (wet) speech becomes critical. This work
investigates the role of the reverberant (wet) phase in the time-frequency
domain. Based on Statistical Wave Field Theory, we show that late reverberation
perturbs phase components with white, uniformly distributed noise, except at
low frequencies. Consequently, the wet phase carries limited useful information
and is not essential for weakly supervised dereverberation. To validate this
finding, we train dereverberation models under a recent weak supervision
framework and demonstrate that performance can be significantly improved by
excluding the reverberant phase from the loss function.
\\ ( https://arxiv.org/abs/2511.17346 ,  282kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17372 (*cross-listing*)
Date: Fri, 21 Nov 2025 16:37:18 GMT   (603kb)

Title: Quantum Masked Autoencoders for Vision Learning
Authors: Emma Andrews, Prabhat Mishra
Categories: quant-ph cs.AI cs.LG
\\
 Classical autoencoders are widely used to learn features of input data. To
improve the feature learning, classical masked autoencoders extend classical
autoencoders to learn the features of the original input sample in the presence
of masked-out data. While quantum autoencoders exist, there is no design and
implementation of quantum masked autoencoders that can leverage the benefits of
quantum computing and quantum autoencoders. In this paper, we propose quantum
masked autoencoders (QMAEs) that can effectively learn missing features of a
data sample within quantum states instead of classical embeddings. We showcase
that our QMAE architecture can learn the masked features of an image and can
reconstruct the masked input image with improved visual fidelity in MNIST
images. Experimental evaluation highlights that QMAE can significantly
outperform (12.86% on average) in classification accuracy compared to
state-of-the-art quantum autoencoders in the presence of masks.
\\ ( https://arxiv.org/abs/2511.17372 ,  603kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17443 (*cross-listing*)
Date: Fri, 21 Nov 2025 17:42:09 GMT   (1456kb)

Title: GRAPHIC--Guidelines for Reviewing Algorithmic Practices in Human-centred
 Design and Interaction for Creativity
Authors: Joana Rovira Martins, Pedro Martins and Ana Boavida
Categories: cs.HC cs.AI cs.GR
Comments: 20 pages, 16 figures
\\
 Artificial Intelligence (AI) has been increasingly applied to creative
domains, leading to the development of systems that collaborate with humans in
design processes. In Graphic Design, integrating computational systems into
co-creative workflows presents specific challenges, as it requires balancing
scientific rigour with the subjective and visual nature of design practice.
Following the PRISMA methodology, we identified 872 articles, resulting in a
final corpus of 71 publications describing 68 unique systems. Based on this
review, we introduce GRAPHIC (Guidelines for Reviewing Algorithmic Practices in
Human-centred Design and Interaction for Creativity), a framework for analysing
AI-based systems applied to Graphic Design. Its goal is to understand how
current systems support human-AI collaboration in the Graphic Design
discipline. The framework comprises main dimensions, which our analysis
revealed to be essential across diverse system types: (1) Collaborative
Panorama, (2) Processes and Modalities, and (3) Graphic Design Principles. Its
application revealed research gaps, including the need to balance initiative
and control between agents, improve communication through explainable
interaction models, and promote systems that support transformational
creativity grounded in core design principles.
\\ ( https://arxiv.org/abs/2511.17443 ,  1456kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17477 (*cross-listing*)
Date: Fri, 21 Nov 2025 18:25:46 GMT   (267kb)

Title: Enhancing Quranic Learning: A Multimodal Deep Learning Approach for
 Arabic Phoneme Recognition
Authors: Ayhan Kucukmanisa, Derya Gelmez, Sukru Selim Calik and Zeynep Hilal
 Kilimci
Categories: cs.SD cs.AI
Comments: 11 pages, 2 figures, 3 tables
\\
 Recent advances in multimodal deep learning have greatly enhanced the
capability of systems for speech analysis and pronunciation assessment.
Accurate pronunciation detection remains a key challenge in Arabic,
particularly in the context of Quranic recitation, where subtle phonetic
differences can alter meaning. Addressing this challenge, the present study
proposes a transformer-based multimodal framework for Arabic phoneme
mispronunciation detection that combines acoustic and textual representations
to achieve higher precision and robustness. The framework integrates
UniSpeech-derived acoustic embeddings with BERT-based textual embeddings
extracted from Whisper transcriptions, creating a unified representation that
captures both phonetic detail and linguistic context. To determine the most
effective integration strategy, early, intermediate, and late fusion methods
were implemented and evaluated on two datasets containing 29 Arabic phonemes,
including eight hafiz sounds, articulated by 11 native speakers. Additional
speech samples collected from publicly available YouTube recordings were
incorporated to enhance data diversity and generalization. Model performance
was assessed using standard evaluation metrics: accuracy, precision, recall,
and F1-score, allowing a detailed comparison of the fusion strategies.
Experimental findings show that the UniSpeech-BERT multimodal configuration
provides strong results and that fusion-based transformer architectures are
effective for phoneme-level mispronunciation detection. The study contributes
to the development of intelligent, speaker-independent, and multimodal
Computer-Aided Language Learning (CALL) systems, offering a practical step
toward technology-supported Quranic pronunciation training and broader
speech-based educational applications.
\\ ( https://arxiv.org/abs/2511.17477 ,  267kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16832 (*cross-listing*)
Date: Thu, 20 Nov 2025 22:28:59 GMT   (1842kb)

Title: The Shifting Landscape of Vaccine Discourse: Insights From a Decade of
 Pre- to Post-COVID-19 Vaccine Posts on Social Media
Authors: Nikesh Gyawali, Doina Caragea, Cornelia Caragea, Saif M. Mohammad
Categories: cs.SI cs.CL
\\
 In this work, we study English-language vaccine discourse in social media
posts, specifically posts on X (formerly Twitter), in seven years before the
COVID-19 outbreak (2013 to 2019) and three years after the outbreak was first
reported (2020 to 2022). Drawing on theories from social cognition and the
stereotype content model in Social Psychology, we analyze how English speakers
talk about vaccines on social media to understand the evolving narrative around
vaccines in social media posts. To do that, we first introduce a novel dataset
comprising 18.7 million curated posts on vaccine discourse from 2013 to 2022.
This extensive collection-filtered down from an initial 129 million posts
through rigorous preprocessing-captures both pre-COVID and COVID-19 periods,
offering valuable insights into the evolution of English-speaking X users'
perceptions related to vaccines. Our analysis shows that the COVID-19 pandemic
led to complex shifts in X users' sentiment and discourse around vaccines. We
observe that negative emotion word usage decreased during the pandemic, with
notable rises in usage of surprise, and trust related emotion words.
Furthermore, vaccine-related language tended to use more warmth-focused words
associated with trustworthiness, along with positive, competence-focused words
during the early days of the pandemic, with a marked rise in negative word
usage towards the end of the pandemic, possibly reflecting a growing vaccine
hesitancy and skepticism.
\\ ( https://arxiv.org/abs/2511.16832 ,  1842kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16931 (*cross-listing*)
Date: Fri, 21 Nov 2025 03:55:19 GMT   (11666kb)

Title: OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists
Authors: Chenyang Shao, Dehao Huang, Yu Li, Keyu Zhao, Weiquan Lin, Yining
 Zhang, Qingbin Zeng, Zhiyu Chen, Tianxing Li, Yifei Huang, Taozhong Wu,
 Xinyang Liu, Ruotong Zhao, Mengsheng Zhao, Xuhua Zhang, Yue Wang, Yuanyi
 Zhen, Fengli Xu, Yong Li, Tie-Yan Liu
Categories: cs.CY cs.CE cs.CL
\\
 With the rapid development of Large Language Models (LLMs), AI agents have
demonstrated increasing proficiency in scientific tasks, ranging from
hypothesis generation and experimental design to manuscript writing. Such agent
systems are commonly referred to as "AI Scientists." However, existing AI
Scientists predominantly formulate scientific discovery as a standalone search
or optimization problem, overlooking the fact that scientific research is
inherently a social and collaborative endeavor. Real-world science relies on a
complex scientific infrastructure composed of collaborative mechanisms,
contribution attribution, peer review, and structured scientific knowledge
networks. Due to the lack of modeling for these critical dimensions, current
systems struggle to establish a genuine research ecosystem or interact deeply
with the human scientific community. To bridge this gap, we introduce
OmniScientist, a framework that explicitly encodes the underlying mechanisms of
human research into the AI scientific workflow. OmniScientist not only achieves
end-to-end automation across data foundation, literature review, research
ideation, experiment automation, scientific writing, and peer review, but also
provides comprehensive infrastructural support by simulating the human
scientific system, comprising: (1) a structured knowledge system built upon
citation networks and conceptual correlations; (2) a collaborative research
protocol (OSP), which enables seamless multi-agent collaboration and human
researcher participation; and (3) an open evaluation platform (ScienceArena)
based on blind pairwise user voting and Elo rankings. This infrastructure
empowers agents to not only comprehend and leverage human knowledge systems but
also to collaborate and co-evolve, fostering a sustainable and scalable
innovation ecosystem.
\\ ( https://arxiv.org/abs/2511.16931 ,  11666kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17080 (*cross-listing*)
Date: Fri, 21 Nov 2025 09:35:07 GMT   (167kb)

Title: An Efficient Computational Framework for Discrete Fuzzy Numbers Based on
 Total Orders
Authors: Arnau Mir, Alejandro Mus, Juan Vicente Riera
Categories: cs.LO cs.CL cs.DM cs.LG
Comments: 19 pages, 2 figures. Submitted to Computational and Applied
 Mathematics (Springer)
\\
 Discrete fuzzy numbers, and in particular those defined over a finite chain
$L_n = \{0, \ldots, n\}$, have been effectively employed to represent
linguistic information within the framework of fuzzy systems. Research on total
(admissible) orderings of such types of fuzzy subsets, and specifically those
belonging to the set $\mathcal{D}_1^{L_n\rightarrow Y_m}$ consisting of
discrete fuzzy numbers $A$ whose support is a closed subinterval of the finite
chain $L_n = \{0, 1, \ldots, n\}$ and whose membership values $A(x)$, for $x
\in L_n$, belong to the set $Y_m = \{ 0 = y_1 < y_2 < \cdots < y_{m-1} < y_m =
1 \}$, has facilitated the development of new methods for constructing logical
connectives, based on a bijective function, called $\textit{pos function}$,
that determines the position of each $A \in \mathcal{D}_1^{L_n\rightarrow
Y_m}$. For this reason, in this work we revisit the problem by introducing
algorithms that exploit the combinatorial structure of total (admissible)
orders to compute the $\textit{pos}$ function and its inverse with exactness.
The proposed approach achieves a complexity of $\mathcal{O}(n^{2} m \log n)$,
which is quadratic in the size of the underlying chain ($n$) and linear in the
number of membership levels ($m$). The key point is that the dominant factor is
$m$, ensuring scalability with respect to the granularity of membership values.
The results demonstrate that this formulation substantially reduces
computational cost and enables the efficient implementation of algebraic
operations -- such as aggregation and implication -- on the set of discrete
fuzzy numbers.
\\ ( https://arxiv.org/abs/2511.17080 ,  167kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17256 (*cross-listing*)
Date: Fri, 21 Nov 2025 14:02:33 GMT   (903kb)

Title: Cross-cultural value alignment frameworks for responsible AI governance:
 Evidence from China-West comparative analysis
Authors: Haijiang Liu and Jinguang Gu, Xun Wu, Daniel Hershcovich, Qiaoling
 Xiao
Categories: cs.CY cs.CL
Comments: Presented on Academic Conference "Technology for Good: Driving Social
 Impact" (2025)
\\
 As Large Language Models (LLMs) increasingly influence high-stakes
decision-making across global contexts, ensuring their alignment with diverse
cultural values has become a critical governance challenge. This study presents
a Multi-Layered Auditing Platform for Responsible AI that systematically
evaluates cross-cultural value alignment in China-origin and Western-origin
LLMs through four integrated methodologies: Ethical Dilemma Corpus for
assessing temporal stability, Diversity-Enhanced Framework (DEF) for
quantifying cultural fidelity, First-Token Probability Alignment for
distributional accuracy, and Multi-stAge Reasoning frameworK (MARK) for
interpretable decision-making. Our comparative analysis of 20+ leading models,
such as Qwen, GPT-4o, Claude, LLaMA, and DeepSeek, reveals universal
challenges-fundamental instability in value systems, systematic
under-representation of younger demographics, and non-linear relationships
between model scale and alignment quality-alongside divergent regional
development trajectories. While China-origin models increasingly emphasize
multilingual data integration for context-specific optimization, Western models
demonstrate greater architectural experimentation but persistent U.S.-centric
biases. Neither paradigm achieves robust cross-cultural generalization. We
establish that Mistral-series architectures significantly outperform
LLaMA3-series in cross-cultural alignment, and that Full-Parameter Fine-Tuning
on diverse datasets surpasses Reinforcement Learning from Human Feedback in
preserving cultural variation...
\\ ( https://arxiv.org/abs/2511.17256 ,  903kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17335 (*cross-listing*)
Date: Fri, 21 Nov 2025 15:55:25 GMT   (1019kb)

Title: Robot Confirmation Generation and Action Planning Using Long-context
 Q-Former Integrated with Multimodal LLM
Authors: Chiori Hori, Yoshiki Masuyama, Siddarth Jain, Radu Corcodel, Devesh
 Jha, Diego Romeres, Jonathan Le Roux
Categories: cs.RO cs.CL cs.CV cs.SD eess.AS
Comments: Accepted to ASRU 2025
\\
 Human-robot collaboration towards a shared goal requires robots to understand
human action and interaction with the surrounding environment. This paper
focuses on human-robot interaction (HRI) based on human-robot dialogue that
relies on the robot action confirmation and action step generation using
multimodal scene understanding. The state-of-the-art approach uses multimodal
transformers to generate robot action steps aligned with robot action
confirmation from a single clip showing a task composed of multiple micro
steps. Although actions towards a long-horizon task depend on each other
throughout an entire video, the current approaches mainly focus on clip-level
processing and do not leverage long-context information. This paper proposes a
long-context Q-former incorporating left and right context dependency in full
videos. Furthermore, this paper proposes a text-conditioning approach to feed
text embeddings directly into the LLM decoder to mitigate the high abstraction
of the information in text by Q-former. Experiments with the YouCook2 corpus
show that the accuracy of confirmation generation is a major factor in the
performance of action planning. Furthermore, we demonstrate that the
long-context Q-former improves the confirmation and action planning by
integrating VideoLLaMA3.
\\ ( https://arxiv.org/abs/2511.17335 ,  1019kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16949 (*cross-listing*)
Date: Fri, 21 Nov 2025 04:53:21 GMT   (49312kb)

Title: MobileOcc: A Human-Aware Semantic Occupancy Dataset for Mobile Robots
Authors: Junseo Kim, Guido Dumont, Xinyu Gao, Gang Chen, Holger Caesar, Javier
 Alonso-Mora
Categories: cs.RO cs.CV
\\
 Dense 3D semantic occupancy perception is critical for mobile robots
operating in pedestrian-rich environments, yet it remains underexplored
compared to its application in autonomous driving. To address this gap, we
present MobileOcc, a semantic occupancy dataset for mobile robots operating in
crowded human environments. Our dataset is built using an annotation pipeline
that incorporates static object occupancy annotations and a novel mesh
optimization framework explicitly designed for human occupancy modeling. It
reconstructs deformable human geometry from 2D images and subsequently refines
and optimizes it using associated LiDAR point data. Using MobileOcc, we
establish benchmarks for two tasks, i) Occupancy prediction and ii) Pedestrian
velocity prediction, using different methods including monocular, stereo, and
panoptic occupancy, with metrics and baseline implementations for reproducible
comparison. Beyond occupancy prediction, we further assess our annotation
method on 3D human pose estimation datasets. Results demonstrate that our
method exhibits robust performance across different datasets.
\\ ( https://arxiv.org/abs/2511.16949 ,  49312kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17126 (*cross-listing*)
Date: Fri, 21 Nov 2025 10:41:54 GMT   (18790kb)

Title: OmniLens++: Blind Lens Aberration Correction via Large LensLib
 Pre-Training and Latent PSF Representation
Authors: Qi Jiang, Xiaolong Qian, Yao Gao, Lei Sun, Kailun Yang, Zhonghua Yi,
 Wenyong Li, Ming-Hsuan Yang, Luc Van Gool, Kaiwei Wang
Categories: eess.IV cs.CV cs.LG physics.optics
Comments: The source code and datasets will be made publicly available at
 https://github.com/zju-jiangqi/OmniLens2
\\
 Emerging deep-learning-based lens library pre-training (LensLib-PT) pipeline
offers a new avenue for blind lens aberration correction by training a
universal neural network, demonstrating strong capability in handling diverse
unknown optical degradations. This work proposes the OmniLens++ framework,
which resolves two challenges that hinder the generalization ability of
existing pipelines: the difficulty of scaling data and the absence of prior
guidance characterizing optical degradation. To improve data scalability, we
expand the design specifications to increase the degradation diversity of the
lens source, and we sample a more uniform distribution by quantifying the
spatial-variation patterns and severity of optical degradation. In terms of
model design, to leverage the Point Spread Functions (PSFs), which intuitively
describe optical degradation, as guidance in a blind paradigm, we propose the
Latent PSF Representation (LPR). The VQVAE framework is introduced to learn
latent features of LensLib's PSFs, which is assisted by modeling the optical
degradation process to constrain the learning of degradation priors.
Experiments on diverse aberrations of real-world lenses and synthetic LensLib
show that OmniLens++ exhibits state-of-the-art generalization capacity in blind
aberration correction. Beyond performance, the AODLibpro is verified as a
scalable foundation for more effective training across diverse aberrations, and
LPR can further tap the potential of large-scale LensLib. The source code and
datasets will be made publicly available at
https://github.com/zju-jiangqi/OmniLens2.
\\ ( https://arxiv.org/abs/2511.17126 ,  18790kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17158 (*cross-listing*)
Date: Fri, 21 Nov 2025 11:25:32 GMT   (2549kb)

Title: Exploring the added value of pretherapeutic MR descriptors in predicting
 breast cancer pathologic complete response to neoadjuvant chemotherapy
Authors: Caroline Malhaire (LITO), Fatine Selhane, Marie-Judith Saint-Martin,
 Vincent Cockenpot, Pia Akl, Enora Laas, Audrey Bellesoeur, Catherine Ala
 Eddine, Melodie Bereby-Kahane, Julie Manceau, Delphine Sebbag-Sfez, Jean-Yves
 Pierga, Fabien Reyal, Anne Vincent-Salomon, Herve Brisse, Frederique Frouin
Categories: physics.med-ph cs.CV
Journal-ref: European Radiology, 2023, 33 (11), pp.8142-8154
\\
 Objectives: To evaluate the association between pretreatment MRI descriptors
and breast cancer (BC) pathological complete response (pCR) to neoadjuvant
chemotherapy (NAC). Materials \& Methods: Patients with BC treated by NAC with
a breast MRI between 2016 and 2020 were included in this retrospective
observational single-center study. MR studies were described using the
standardized BI-RADS and breast edema score on T2-weighted MRI. Univariable and
multivariable logistic regression analyses were performed to assess variables
association with pCR according to residual cancer burden. Random forest
classifiers were trained to predict pCR on a random split including 70% of the
database and were validated on the remaining cases. Results: Among 129 BC, 59
(46%) achieved pCR after NAC (luminal (n=7/37, 19%), triple negative (TN)
(n=30/55, 55%), HER2+ (n=22/37, 59%). Clinical and biological items associated
with pCR were BC subtype (p<0.001), T stage 0/I/II (p=0.008), higher Ki67
(p=0.005) and higher tumor-infiltrating lymphocytes levels (p=0.016).
Univariate analysis showed that the following MRI features, oval or round shape
(p=0.047), unifocality (p=0.026), non-spiculated margins (p=0.018), no
associated non-mass enhancement (NME) (p = 0.024) and a lower MRI size (p =
0.031) were significantly associated with pCR. Unifocality and non-spiculated
margins remained independently associated with pCR at multivariable analysis.
Adding significant MRI features to clinicobiological variables in random forest
classifiers significantly increased sensitivity (0.67 versus 0.62), specificity
(0.69 versus 0.67) and precision (0.71 versus 0.67) for pCR prediction.
Conclusion: Non-spiculated margins and unifocality are independently associated
with pCR and can increase models performance to predict BC response to NAC.
Clinical Relevance Statement: A multimodal approach integrating pretreatment
MRI features with clinicobiological predictors, including TILs, could be
employed to develop machine learning models for identifying patients at risk of
non-response. This may enable consideration of alternative therapeutic
strategies to optimize treatment outcomes
\\ ( https://arxiv.org/abs/2511.17158 ,  2549kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17353 (*cross-listing*)
Date: Fri, 21 Nov 2025 16:16:30 GMT   (27650kb)

Title: Learning Latent Transmission and Glare Maps for Lens Veiling Glare
 Removal
Authors: Xiaolong Qian, Qi Jiang, Lei Sun, Zongxi Yu, Kailun Yang, Peixuan Wu,
 Jiacheng Zhou, Yao Gao, Yaoguang Ma, Ming-Hsuan Yang, Kaiwei Wang
Categories: eess.IV cs.CV physics.optics
Comments: All code and datasets will be publicly released at
 https://github.com/XiaolongQian/DeVeiler
\\
 Beyond the commonly recognized optical aberrations, the imaging performance
of compact optical systems-including single-lens and metalens designs-is often
further degraded by veiling glare caused by stray-light scattering from
non-ideal optical surfaces and coatings, particularly in complex real-world
environments. This compound degradation undermines traditional lens aberration
correction yet remains underexplored. A major challenge is that conventional
scattering models (e.g., for dehazing) fail to fit veiling glare due to its
spatial-varying and depth-independent nature. Consequently, paired high-quality
data are difficult to prepare via simulation, hindering application of
data-driven veiling glare removal models. To this end, we propose VeilGen, a
generative model that learns to simulate veiling glare by estimating its
underlying optical transmission and glare maps in an unsupervised manner from
target images, regularized by Stable Diffusion (SD)-based priors. VeilGen
enables paired dataset generation with realistic compound degradation of
optical aberrations and veiling glare, while also providing the estimated
latent optical transmission and glare maps to guide the veiling glare removal
process. We further introduce DeVeiler, a restoration network trained with a
reversibility constraint, which utilizes the predicted latent maps to guide an
inverse process of the learned scattering model. Extensive experiments on
challenging compact optical systems demonstrate that our approach delivers
superior restoration quality and physical fidelity compared with existing
methods. These suggest that VeilGen reliably synthesizes realistic veiling
glare, and its learned latent maps effectively guide the restoration process in
DeVeiler. All code and datasets will be publicly released at
https://github.com/XiaolongQian/DeVeiler.
\\ ( https://arxiv.org/abs/2511.17353 ,  27650kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17366 (*cross-listing*)
Date: Fri, 21 Nov 2025 16:32:36 GMT   (13013kb)

Title: METIS: Multi-Source Egocentric Training for Integrated Dexterous
 Vision-Language-Action Model
Authors: Yankai Fu and Ning Chen and Junkai Zhao and Shaozhe Shan and Guocai
 Yao and Pengwei Wang and Zhongyuan Wang and Shanghang Zhang
Categories: cs.RO cs.CV
\\
 Building a generalist robot that can perceive, reason, and act across diverse
tasks remains an open challenge, especially for dexterous manipulation. A major
bottleneck lies in the scarcity of large-scale, action-annotated data for
dexterous skills, as teleoperation is difficult and costly. Human data, with
its vast scale and diverse manipulation behaviors, provides rich priors for
learning robotic actions. While prior works have explored leveraging human
demonstrations, they are often constrained by limited scenarios and a large
visual gap between human and robots. To eliminate these limitations, we propose
METIS, a vision-language-action (VLA) model for dexterous manipulation
pretrained on multi-source egocentric datasets. We first construct EgoAtlas,
which integrates large-scale human and robotic data from multiple sources, all
unified under a consistent action space. We further extract motion-aware
dynamics, a compact and discretized motion representation, which provides
efficient and expressive supervision for VLA training. Built upon them, METIS
integrates reasoning and acting into a unified framework, enabling effective
deployment to downstream dexterous manipulation tasks. Our method demonstrates
exceptional dexterous manipulation capabilities, achieving highest average
success rate in six real-world tasks. Experimental results also highlight the
superior generalization and robustness to out-of-distribution scenarios. These
findings emphasize METIS as a promising step toward a generalist model for
dexterous manipulation.
\\ ( https://arxiv.org/abs/2511.17366 ,  13013kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17384 (*cross-listing*)
Date: Fri, 21 Nov 2025 16:48:49 GMT   (13941kb)

Title: IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic
 Industrial Navigation
Authors: Yifan Li, Lichi Li, Anh Dao, Xinyu Zhou, Yicheng Qiao, Zheda Mai,
 Daeun Lee, Zichen Chen, Zhen Tan, Mohit Bansal, Yu Kong
Categories: cs.RO cs.CV
\\
 While Visual Large Language Models (VLLMs) show great promise as embodied
agents, they continue to face substantial challenges in spatial reasoning.
Existing embodied benchmarks largely focus on passive, static household
environments and evaluate only isolated capabilities, failing to capture
holistic performance in dynamic, real-world complexity. To fill this gap, we
present IndustryNav, the first dynamic industrial navigation benchmark for
active spatial reasoning. IndustryNav leverages 12 manually created,
high-fidelity Unity warehouse scenarios featuring dynamic objects and human
movement. Our evaluation employs a PointGoal navigation pipeline that
effectively combines egocentric vision with global odometry to assess holistic
local-global planning. Crucially, we introduce the "collision rate" and
"warning rate" metrics to measure safety-oriented behaviors and distance
estimation. A comprehensive study of nine state-of-the-art VLLMs (including
models such as GPT-5-mini, Claude-4.5, and Gemini-2.5) reveals that
closed-source models maintain a consistent advantage; however, all agents
exhibit notable deficiencies in robust path planning, collision avoidance and
active exploration. This highlights a critical need for embodied research to
move beyond passive perception and toward tasks that demand stable planning,
active exploration, and safe behavior in dynamic, real-world environment.
\\ ( https://arxiv.org/abs/2511.17384 ,  13941kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16741 (*cross-listing*)
Date: Thu, 20 Nov 2025 19:00:05 GMT   (55kb)

Title: Fermions and Supersymmetry in Neural Network Field Theories
Authors: Samuel Frank, James Halverson, Anindita Maiti, and Fabian Ruehle
Categories: hep-th cs.LG
Comments: 34 pages + appendices
\\
 We introduce fermionic neural network field theories via Grassmann-valued
neural networks. Free theories are obtained by a generalization of the Central
Limit Theorem to Grassmann variables. This enables the realization of the free
Dirac spinor at infinite width and a four fermion interaction at finite width.
Yukawa couplings are introduced by breaking the statistical independence of the
output weights for the fermionic and bosonic fields. A large class of
interacting supersymmetric quantum mechanics and field theory models are
introduced by super-affine transformations on the input that realize a
superspace formalism.
\\ ( https://arxiv.org/abs/2511.16741 ,  55kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16792 (*cross-listing*)
Date: Thu, 20 Nov 2025 20:40:56 GMT   (3179kb)

Title: Membership Inference Attacks Beyond Overfitting
Authors: Mona Khalil, Alberto Blanco-Justicia, Najeeb Jebreel and Josep
 Domingo-Ferrer
Categories: cs.CR cs.LG
Journal-ref: in Data Privacy Management - DPM 2025, within 30th European
 Symposium on Research in Computer Security-ESORICS 2025, LNCS, Springer
\\
 Membership inference attacks (MIAs) against machine learning (ML) models aim
to determine whether a given data point was part of the model training data.
These attacks may pose significant privacy risks to individuals whose sensitive
data were used for training, which motivates the use of defenses such as
differential privacy, often at the cost of high accuracy losses. MIAs exploit
the differences in the behavior of a model when making predictions on samples
it has seen during training (members) versus those it has not seen
(non-members). Several studies have pointed out that model overfitting is the
major factor contributing to these differences in behavior and, consequently,
to the success of MIAs. However, the literature also shows that even
non-overfitted ML models can leak information about a small subset of their
training data. In this paper, we investigate the root causes of membership
inference vulnerabilities beyond traditional overfitting concerns and suggest
targeted defenses. We empirically analyze the characteristics of the training
data samples vulnerable to MIAs in models that are not overfitted (and hence
able to generalize). Our findings reveal that these samples are often outliers
within their classes (e.g., noisy or hard to classify). We then propose
potential defensive strategies to protect these vulnerable samples and enhance
the privacy-preserving capabilities of ML models. Our code is available at
https://github.com/najeebjebreel/mia_analysis.
\\ ( https://arxiv.org/abs/2511.16792 ,  3179kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16796 (*cross-listing*)
Date: Thu, 20 Nov 2025 20:48:14 GMT   (1242kb)

Title: Efficient Penalty-Based Bilevel Methods: Improved Analysis, Novel
 Updates, and Flatness Condition
Authors: Liuyuan Jiang, Quan Xiao, Lisha Chen, Tianyi Chen
Categories: math.OC cs.LG stat.ML
Comments: arXiv admin note: text overlap with arXiv:2507.20400
\\
 Penalty-based methods have become popular for solving bilevel optimization
(BLO) problems, thanks to their effective first-order nature. However, they
often require inner-loop iterations to solve the lower-level (LL) problem and
small outer-loop step sizes to handle the increased smoothness induced by large
penalty terms, leading to suboptimal complexity. This work considers the
general BLO problems with coupled constraints (CCs) and leverages a novel
penalty reformulation that decouples the upper- and lower-level variables. This
yields an improved analysis of the smoothness constant, enabling larger step
sizes and reduced iteration complexity for Penalty-Based Gradient Descent
algorithms in ALTernating fashion (ALT-PBGD). Building on the insight of
reduced smoothness, we propose PBGD-Free, a novel fully single-loop algorithm
that avoids inner loops for the uncoupled constraint BLO. For BLO with CCs,
PBGD-Free employs an efficient inner-loop with substantially reduced iteration
complexity. Furthermore, we propose a novel curvature condition describing the
"flatness" of the upper-level objective with respect to the LL variable. This
condition relaxes the traditional upper-level Lipschitz requirement, enables
smaller penalty constant choices, and results in a negligible penalty gradient
term during upper-level variable updates. We provide rigorous convergence
analysis and validate the method's efficacy through hyperparameter optimization
for support vector machines and fine-tuning of large language models.
\\ ( https://arxiv.org/abs/2511.16796 ,  1242kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16815 (*cross-listing*)
Date: Thu, 20 Nov 2025 21:36:21 GMT   (9613kb)

Title: BITS for GAPS: Bayesian Information-Theoretic Sampling for hierarchical
 GAussian Process Surrogates
Authors: Kyla D. Jones and Alexander W. Dowling
Categories: stat.ML cs.LG
\\
 We introduce the Bayesian Information-Theoretic Sampling for hierarchical
GAussian Process Surrogates (BITS for GAPS) framework to emulate latent
components in hybrid physical systems. BITS for GAPS supports serial hybrid
modeling, where known physics governs part of the system and residual dynamics
are represented as a latent function inferred from data. A Gaussian process
prior is placed over the latent function, with hierarchical priors on its
hyperparameters to encode physically meaningful structure in the predictive
posterior.
 To guide data acquisition, we derive entropy-based acquisition functions that
quantify expected information gain from candidate input locations, identifying
samples most informative for training the surrogate. Specifically, we obtain a
closed-form expression for the differential entropy of the predictive posterior
and establish a tractable lower bound for efficient evaluation. These
derivations approximate the predictive posterior as a finite, uniformly
weighted mixture of Gaussian processes.
 We demonstrate the framework's utility by modeling activity coefficients in
vapor-liquid equilibrium systems, embedding the surrogate into extended
Raoult's law for distillation design. Numerical results show that
entropy-guided sampling improves sample efficiency by targeting regions of high
uncertainty and potential information gain. This accelerates surrogate
convergence, enhances predictive accuracy in non-ideal regimes, and preserves
physical consistency. Overall, BITS for GAPS provides an efficient,
interpretable, and uncertainty-aware framework for hybrid modeling of complex
physical systems.
\\ ( https://arxiv.org/abs/2511.16815 ,  9613kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16858 (*cross-listing*)
Date: Thu, 20 Nov 2025 23:55:56 GMT   (432kb)

Title: Is the Cure Still Worse Than the Disease? Test Overfitting by LLMs in
 Automated Program Repair
Authors: Toufique Ahmed, Jatin Ganhotra, Avraham Shinnar, Martin Hirzel
Categories: cs.SE cs.LG
\\
 Automated program repair has been shown to be susceptible to generating
repaired code that passes on seen tests but fails on a hold-out set of hidden
tests. This problem, dubbed test overfitting, has been identified and studied
before the rise of large language models. We experimentally study how much test
overfitting is still a problem today, using repository-level SWE-bench tasks.
\\ ( https://arxiv.org/abs/2511.16858 ,  432kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17007 (*cross-listing*)
Date: Fri, 21 Nov 2025 07:25:49 GMT   (4518kb)

Title: Generative MIMO Beam Map Construction for Location Recovery and Beam
 Tracking
Authors: Wangqian Chen, Junting Chen, and Shuguang Cui
Categories: eess.SP cs.LG cs.SY eess.SY
\\
 Machine learning (ML) has greatly advanced data-driven channel modeling and
resource optimization in wireless communication systems. However, most existing
ML-based methods rely on large, accurately labeled datasets with location
information, which are often difficult and costly to obtain. This paper
proposes a generative framework to recover location labels directly from
sequences of sparse channel state information (CSI) measurements, without
explicit location labels for radio map construction. Instead of directly
storing raw CSI, we learn a compact low-dimensional radio map embedding and
leverage a generative model to reconstruct the high-dimensional CSI.
Specifically, to address the uncertainty of sparse CSI, a dual-scale feature
extraction scheme is designed to enhance feature representation by jointly
exploiting correlations from angular space and across neighboring samples. We
develop a hybrid recurrent-convolutional encoder to learn mobility patterns,
which combines a truncation strategy and multi-scale convolutions in the
recurrent neural network (RNN) to ensure feature robustness against short-term
fluctuations. Unlike conventional Gaussian priors in latent space, we embed a
learnable radio map to capture the location information by encoding high-level
positional features from CSI measurements. Finally, a diffusion-based
generative decoder reconstructs the full CSI with high fidelity by conditioning
on the positional features in the radio map. Numerical experiments demonstrate
that the proposed model can improve localization accuracy by over 30% and
achieve a 20% capacity gain in non-line-of-sight (NLOS) scenarios compared with
model-based Kalman filter approaches.
\\ ( https://arxiv.org/abs/2511.17007 ,  4518kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17112 (*cross-listing*)
Date: Fri, 21 Nov 2025 10:21:39 GMT   (2317kb)

Title: Dissecting Quantum Reinforcement Learning: A Systematic Evaluation of
 Key Components
Authors: Javier Lazaro, Juan-Ignacio Vazquez, Pablo Garcia-Bringas
Categories: quant-ph cs.LG
\\
 Parameterised quantum circuit (PQC) based Quantum Reinforcement Learning
(QRL) has emerged as a promising paradigm at the intersection of quantum
computing and reinforcement learning (RL). By design, PQCs create hybrid
quantum-classical models, but their practical applicability remains uncertain
due to training instabilities, barren plateaus (BPs), and the difficulty of
isolating the contribution of individual pipeline components. In this work, we
dissect PQC based QRL architectures through a systematic experimental
evaluation of three aspects recurrently identified as critical: (i) data
embedding strategies, with Data Reuploading (DR) as an advanced approach; (ii)
ansatz design, particularly the role of entanglement; and (iii) post-processing
blocks after quantum measurement, with a focus on the underexplored Output
Reuse (OR) technique. Using a unified PPO-CartPole framework, we perform
controlled comparisons between hybrid and classical agents under identical
conditions. Our results show that OR, though purely classical, exhibits
distinct behaviour in hybrid pipelines, that DR improves trainability and
stability, and that stronger entanglement can degrade optimisation, offsetting
classical gains. Together, these findings provide controlled empirical evidence
of the interplay between quantum and classical contributions, and establish a
reproducible framework for systematic benchmarking and component-wise analysis
in QRL.
\\ ( https://arxiv.org/abs/2511.17112 ,  2317kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17123 (*cross-listing*)
Date: Fri, 21 Nov 2025 10:37:07 GMT   (578kb)

Title: Layer-wise Weight Selection for Power-Efficient Neural Network
 Acceleration
Authors: Jiaxun Fang, Li Zhang, Shaoyi Huang
Categories: cs.AR cs.LG
\\
 Systolic array accelerators execute CNNs with energy dominated by the
switching activity of multiply accumulate (MAC) units. Although prior work
exploits weight dependent MAC power for compression, existing methods often use
global activation models, coarse energy proxies, or layer-agnostic policies,
which limits their effectiveness on real hardware. We propose an energy aware,
layer-wise compression framework that explicitly leverages MAC and layer level
energy characteristics. First, we build a layer-aware MAC energy model that
combines per-layer activation statistics with an MSB-Hamming distance grouping
of 22-bit partial sum transitions, and integrate it with a tile-level systolic
mapping to estimate convolution-layer energy. On top of this model, we
introduce an energy accuracy co-optimized weight selection algorithm within
quantization aware training and an energy-prioritized layer-wise schedule that
compresses high energy layers more aggressively under a global accuracy
constraint. Experiments on different CNN models demonstrate up to 58.6\% energy
reduction with 2-3\% accuracy drop, outperforming a state-of-the-art
power-aware baseline.
\\ ( https://arxiv.org/abs/2511.17123 ,  578kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17176 (*cross-listing*)
Date: Fri, 21 Nov 2025 11:54:22 GMT   (4845kb)

Title: On the Predictive Skill of Artificial Intelligence-based Weather Models
 for Extreme Events using Uncertainty Quantification
Authors: Rodrigo Almeida, Noelia Otero, Miguel-\'Angel Fern\'andez-Torres,
 Jackie Ma
Categories: physics.ao-ph cs.LG
Comments: 24 pages, 12 figures
\\
 Accurate prediction of extreme weather events remains a major challenge for
artificial intelligence based weather prediction systems. While deterministic
models such as FuXi, GraphCast, and SFNO have achieved competitive forecast
skill relative to numerical weather prediction, their ability to represent
uncertainty and capture extremes is still limited. This study investigates how
state of the art deterministic artificial intelligence based models respond to
initial-condition perturbations and evaluates the resulting ensembles in
forecasting extremes. Using three perturbation strategies (Gaussian noise,
Hemispheric Centered Bred Vectors, and Huge Ensembles), we generate 50 member
ensembles for two major events in August 2022: the Pakistan floods and the
China heatwave. Ensemble skill is assessed against ERA5 and compared with IFS
ENS and the probabilistic AIFSENS model using deterministic and probabilistic
metrics. Results show that flow dependent perturbations produce the most
realistic ensemble spread and highest probabilistic skill, narrowing but not
closing the performance gap with numerical weather prediction ensembles. Across
variables, artificial intelligence based weather models capture temperature
extremes more effectively than precipitation. These findings demonstrate that
input perturbations can extend deterministic models toward probabilistic
forecasting, paving the way for approaches that combine flow dependent
perturbations with generative or latent-space uncertainty modeling for reliable
artificial intelligence-driven early warning systems.
\\ ( https://arxiv.org/abs/2511.17176 ,  4845kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17228 (*cross-listing*)
Date: Fri, 21 Nov 2025 13:14:40 GMT   (7792kb)

Title: Intrinsic preservation of plasticity in continual quantum learning
Authors: Yu-Qin Chen, Shi-Xin Zhang
Categories: quant-ph cs.LG
Comments: 11 pages, 5 figures and supplementary information
\\
 Artificial intelligence in dynamic, real-world environments requires the
capacity for continual learning. However, standard deep learning suffers from a
fundamental issue: loss of plasticity, in which networks gradually lose their
ability to learn from new data. Here we show that quantum learning models
naturally overcome this limitation, preserving plasticity over long timescales.
We demonstrate this advantage systematically across a broad spectrum of tasks
from multiple learning paradigms, including supervised learning and
reinforcement learning, and diverse data modalities, from classical
high-dimensional images to quantum-native datasets. Although classical models
exhibit performance degradation correlated with unbounded weight and gradient
growth, quantum neural networks maintain consistent learning capabilities
regardless of the data or task. We identify the origin of the advantage as the
intrinsic physical constraints of quantum models. Unlike classical networks
where unbounded weight growth leads to landscape ruggedness or saturation, the
unitary constraints confine the optimization to a compact manifold. Our results
suggest that the utility of quantum computing in machine learning extends
beyond potential speedups, offering a robust pathway for building adaptive
artificial intelligence and lifelong learners.
\\ ( https://arxiv.org/abs/2511.17228 ,  7792kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17240 (*cross-listing*)
Date: Fri, 21 Nov 2025 13:34:29 GMT   (116kb)

Title: Fast Decoding for Non-Adaptive Learning of Erd\H{o}s--R\'enyi Random
 Graphs
Authors: Hoang Ta and Jonathan Scarlett
Categories: cs.IT cs.DM cs.LG math.IT math.PR
\\
 We study the problem of learning an unknown graph via group queries on node
subsets, where each query reports whether at least one edge is present among
the queried nodes. In general, learning arbitrary graphs with \(n\) nodes and
\(k\) edges is hard in the non-adaptive setting, requiring
\(\Omega\big(\min\{k^2\log n,\,n^2\}\big)\) tests even when a small error
probability is allowed. We focus on learning Erd\H{o}s--R\'enyi (ER) graphs
\(G\sim\ER(n,q)\) in the non-adaptive setting, where the expected number of
edges is \(\bar{k}=q\binom{n}{2}\), and we aim to design an efficient
testing--decoding scheme achieving asymptotically vanishing error probability.
Prior work (Li--Fresacher--Scarlett, NeurIPS 2019) presents a testing--decoding
scheme that attains an order-optimal number of tests \(O(\bar{k}\log n)\) but
incurs \(\Omega(n^2)\) decoding time, whereas their proposed sublinear-time
algorithm incurs an extra \((\log \bar{k})(\log n)\) factor in the number of
tests. We extend the binary splitting approach, recently developed for
non-adaptive group testing, to the ER graph learning setting, and prove that
the edge set can be recovered with high probability using \(O(\bar{k}\log n)\)
tests while attaining decoding time \(O(\bar{k}^{1+\delta}\log n)\) for any
fixed \(\delta>0\).
\\ ( https://arxiv.org/abs/2511.17240 ,  116kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17293 (*cross-listing*)
Date: Fri, 21 Nov 2025 15:06:49 GMT   (2992kb)

Title: A First Full Physics Benchmark for Highly Granular Calorimeter
 Surrogates
Authors: Thorsten Buss, Henry Day-Hall, Frank Gaede, Gregor Kasieczka, Katja
 Kr\"uger, Anatolii Korol, Thomas Madlener, Peter McKeown
Categories: hep-ex cs.LG physics.data-an
Comments: 26 pages, 15 figures
Report-no: DESY-25-172
\\
 The physics programs of current and future collider experiments necessitate
the development of surrogate simulators for calorimeter showers. While much
progress has been made in the development of generative models for this task,
they have typically been evaluated in simplified scenarios and for single
particles. This is particularly true for the challenging task of highly
granular calorimeter simulation. For the first time, this work studies the use
of highly granular generative calorimeter surrogates in a realistic simulation
application. We introduce DDML, a generic library which enables the combination
of generative calorimeter surrogates with realistic detectors implemented using
the DD4hep toolkit. We compare two different generative models - one operating
on a regular grid representation, and the other using a less common point cloud
approach. In order to disentangle methodological details from model
performance, we provide comparisons to idealized simulators which directly
sample representations of different resolutions from the full simulation
ground-truth. We then systematically evaluate model performance on
post-reconstruction benchmarks for electromagnetic shower simulation. Beginning
with a typical single particle study, we introduce a first multi-particle
benchmark based on di-photon separations, before studying a first full-physics
benchmark based on hadronic decays of the tau lepton. Our results indicate that
models operating on a point cloud can achieve a favorable balance between speed
and accuracy for highly granular calorimeter simulation compared to those which
operate on a regular grid representation.
\\ ( https://arxiv.org/abs/2511.17293 ,  2992kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17411 (*cross-listing*)
Date: Fri, 21 Nov 2025 17:09:43 GMT   (19395kb)

Title: SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding
Authors: Nikolay Nikolov, Giuliano Albanese, Sombit Dey, Aleksandar Yanev, Luc
 Van Gool, Jan-Nico Zaech, Danda Pani Paudel
Categories: cs.RO cs.LG
\\
 Robotic Foundation Models (RFMs) hold great promise as generalist, end-to-end
systems for robot control. Yet their ability to generalize across new
environments, tasks, and embodiments remains limited. We argue that a major
bottleneck lies in their foundations: most RFMs are built by fine-tuning
internet-pretrained Vision-Language Models (VLMs). However, these VLMs are
trained on 2D image-language tasks and lack the 3D spatial reasoning inherently
required for embodied control in the 3D world. Bridging this gap directly with
large-scale robotic data is costly and difficult to scale. Instead, we propose
to enrich easy-to-collect non-robotic image data with 3D annotations and
enhance a pretrained VLM with 3D understanding capabilities. Following this
strategy, we train SPEAR-VLM, a 3D-aware VLM that infers object coordinates in
3D space from a single 2D image. Building on SPEAR-VLM, we introduce our main
contribution, $~\textbf{SPEAR-1}$: a robotic foundation model that integrates
grounded 3D perception with language-instructed embodied control. Trained on
$\sim$45M frames from 24 Open X-Embodiment datasets, SPEAR-1 outperforms or
matches state-of-the-art models such as $\pi_0$-FAST and $\pi_{0.5}$, while it
uses 20$\times$ fewer robot demonstrations. This carefully-engineered training
strategy unlocks new VLM capabilities and as a consequence boosts the
reliability of embodied control beyond what is achievable with only robotic
data. We make our model weights and 3D-annotated datasets publicly available.
\\ ( https://arxiv.org/abs/2511.17411 ,  19395kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17417 (*cross-listing*)
Date: Fri, 21 Nov 2025 17:16:24 GMT   (4385kb)

Title: CREST: Improving Interpretability and Effectiveness of Troubleshooting
 at Ericsson through Criterion-Specific Trouble Report Retrieval
Authors: Soroush Javdan, Pragash Krishnamoorthy, Olga Baysal
Categories: cs.SE cs.LG
\\
 The rapid evolution of the telecommunication industry necessitates efficient
troubleshooting processes to maintain network reliability, software
maintainability, and service quality. Trouble Reports (TRs), which document
issues in Ericsson's production system, play a critical role in facilitating
the timely resolution of software faults. However, the complexity and volume of
TR data, along with the presence of diverse criteria that reflect different
aspects of each fault, present challenges for retrieval systems. Building on
prior work at Ericsson, which utilized a two-stage workflow, comprising Initial
Retrieval (IR) and Re-Ranking (RR) stages, this study investigates different TR
observation criteria and their impact on the performance of retrieval models.
We propose \textbf{CREST} (\textbf{C}riteria-specific \textbf{R}etrieval via
\textbf{E}nsemble of \textbf{S}pecialized \textbf{T}R models), a
criterion-driven retrieval approach that leverages specialized models for
different TR fields to improve both effectiveness and interpretability, thereby
enabling quicker fault resolution and supporting software maintenance. CREST
utilizes specialized models trained on specific TR criteria and aggregates
their outputs to capture diverse and complementary signals. This approach leads
to enhanced retrieval accuracy, better calibration of predicted scores, and
improved interpretability by providing relevance scores for each criterion,
helping users understand why specific TRs were retrieved. Using a subset of
Ericsson's internal TRs, this research demonstrates that criterion-specific
models significantly outperform a single model approach across key evaluation
metrics. This highlights the importance of all targeted criteria used in this
study for optimizing the performance of retrieval systems.
\\ ( https://arxiv.org/abs/2511.17417 ,  4385kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17436 (*cross-listing*)
Date: Fri, 21 Nov 2025 17:33:00 GMT   (87kb)

Title: A Framework for Adaptive Stabilisation of Nonlinear Stochastic Systems
Authors: Seth Siriya, Jingge Zhu, Dragan Ne\v{s}i\'c, Ye Pu
Categories: eess.SY cs.LG cs.SY math.OC
Comments: 22 pages, 1 figure
\\
 We consider the adaptive control problem for discrete-time, nonlinear
stochastic systems with linearly parameterised uncertainty. Assuming access to
a parameterised family of controllers that can stabilise the system in a
bounded set within an informative region of the state space when the parameter
is well-chosen, we propose a certainty equivalence learning-based adaptive
control strategy, and subsequently derive stability bounds on the closed-loop
system that hold for some probabilities. We then show that if the entire state
space is informative, and the family of controllers is globally stabilising
with appropriately chosen parameters, high probability stability guarantees can
be derived.
\\ ( https://arxiv.org/abs/2511.17436 ,  87kb)
------------------------------------------------------------------------------
\\
arXiv:2511.17475 (*cross-listing*)
Date: Fri, 21 Nov 2025 18:24:52 GMT   (672kb)

Title: Addressing A Posteriori Performance Degradation in Neural Network
 Subgrid Stress Models
Authors: Andy Wu and Sanjiva K. Lele
Categories: physics.flu-dyn cs.LG
\\
 Neural network subgrid stress models often have a priori performance that is
far better than the a posteriori performance, leading to neural network models
that look very promising a priori completely failing in a posteriori Large Eddy
Simulations (LES). This performance gap can be decreased by combining two
different methods, training data augmentation and reducing input complexity to
the neural network. Augmenting the training data with two different filters
before training the neural networks has no performance degradation a priori as
compared to a neural network trained with one filter. A posteriori, neural
networks trained with two different filters are far more robust across two
different LES codes with different numerical schemes. In addition, by ablating
away the higher order terms input into the neural network, the a priori versus
a posteriori performance changes become less apparent. When combined, neural
networks that use both training data augmentation and a less complex set of
inputs have a posteriori performance far more reflective of their a priori
evaluation.
\\ ( https://arxiv.org/abs/2511.17475 ,  672kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2502.10568
replaced with revised version Thu, 20 Nov 2025 21:51:04 GMT   (109kb)

Title: Observer-Aware Probabilistic Planning Under Partial Observability
Authors: Salom\'e Lepers, Vincent Thomas, Olivier Buffet
Categories: cs.AI
Comments: 23 pages, 13 figures. Complete version of AAMAS 2025 extended
 abstract
\\ ( https://arxiv.org/abs/2502.10568 ,  109kb)
------------------------------------------------------------------------------
\\
arXiv:2503.01424
replaced with revised version Fri, 21 Nov 2025 09:49:56 GMT   (1248kb)

Title: From Hypothesis to Publication: A Comprehensive Survey of AI-Driven
 Research Support Systems
Authors: Zekun Zhou, Xiaocheng Feng, Lei Huang, Xiachong Feng, Ziyun Song,
 Ruihan Chen, Liang Zhao, Weitao Ma, Yuxuan Gu, Baoxin Wang, Dayong Wu,
 Guoping Hu, Ting Liu, Bing Qin
Categories: cs.AI cs.CL
Comments: Accepted to EMNLP 2025
\\ ( https://arxiv.org/abs/2503.01424 ,  1248kb)
------------------------------------------------------------------------------
\\
arXiv:2504.07139
replaced with revised version Thu, 20 Nov 2025 18:59:46 GMT   (29555kb)

Title: Artificial Intelligence Index Report 2025
Authors: Nestor Maslej, Loredana Fattorini, Raymond Perrault, Yolanda Gil,
 Vanessa Parli, Njenga Kariuki, Emily Capstick, Anka Reuel, Erik Brynjolfsson,
 John Etchemendy, Katrina Ligett, Terah Lyons, James Manyika, Juan Carlos
 Niebles, Yoav Shoham, Russell Wald, Toby Walsh, Armin Hamrah, Lapo
 Santarlasci, Julia Betts Lotufo, Alexandra Rome, Andrew Shi, Sukrut Oak
Categories: cs.AI
\\ ( https://arxiv.org/abs/2504.07139 ,  29555kb)
------------------------------------------------------------------------------
\\
arXiv:2504.18777
replaced with revised version Fri, 21 Nov 2025 16:41:05 GMT   (1868kb)

Title: Evaluating AI-Driven Automated Map Digitization in QGIS
Authors: Diana Febrita
Categories: cs.AI
Comments: Presented at the 2025 Indiana Geographic Information Council (IGIC)
 Conference
\\ ( https://arxiv.org/abs/2504.18777 ,  1868kb)
------------------------------------------------------------------------------
\\
arXiv:2505.04736
replaced with revised version Fri, 21 Nov 2025 15:00:06 GMT   (2509kb)

Title: The promise and limits of LLMs in constructing proofs and hints for
 logic problems in intelligent tutoring systems
Authors: Sutapa Dey Tithi, Arun Kumar Ramesh, Clara DiMarco, Xiaoyi Tian, Nazia
 Alam, Kimia Fazeli, Tiffany Barnes
Categories: cs.AI
\\ ( https://arxiv.org/abs/2505.04736 ,  2509kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11289
replaced with revised version Fri, 21 Nov 2025 15:53:08 GMT   (6600kb)

Title: Meta-World+: An Improved, Standardized, RL Benchmark
Authors: Reginald McLean, Evangelos Chatzaroulas, Luc McCutcheon, Frank
 R\"oder, Tianhe Yu, Zhanpeng He, K.R. Zentner, Ryan Julian, J K Terry, Isaac
 Woungang, Nariman Farsad, Pablo Samuel Castro
Categories: cs.AI cs.LG
Comments: Accepted at NeurIPs 2025, Datasets and Benchmarks
\\ ( https://arxiv.org/abs/2505.11289 ,  6600kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01109
replaced with revised version Fri, 21 Nov 2025 14:32:46 GMT   (10229kb)

Title: Platonic Representations for Poverty Mapping: Unified Vision-Language
 Codes or Agent-Induced Novelty?
Authors: Satiyabooshan Murugaboopathy and Connor T. Jerzak and Adel Daoud
Categories: cs.AI
Comments: 7 figures
MSC-class: 68T07
ACM-class: I.2; J.4
\\ ( https://arxiv.org/abs/2508.01109 ,  10229kb)
------------------------------------------------------------------------------
\\
arXiv:2508.04652
replaced with revised version Fri, 21 Nov 2025 13:14:11 GMT   (578kb)

Title: LLM Collaboration With Multi-Agent Reinforcement Learning
Authors: Shuo Liu, Tianle Chen, Zeyu Liang, Xueguang Lyu, Christopher Amato
Categories: cs.AI cs.SE
\\ ( https://arxiv.org/abs/2508.04652 ,  578kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10599
replaced with revised version Fri, 21 Nov 2025 05:56:07 GMT   (889kb)

Title: MSRS: Adaptive Multi-Subspace Representation Steering for Attribute
 Alignment in Large Language Models
Authors: Xinyan Jiang, Lin Zhang, Jiayi Zhang, Qingsong Yang, Guimin Hu, Di
 Wang, Lijie Hu
Categories: cs.AI
\\ ( https://arxiv.org/abs/2508.10599 ,  889kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13663
replaced with revised version Fri, 21 Nov 2025 13:46:26 GMT   (159kb)

Title: Interactive Query Answering on Knowledge Graphs with Soft Entity
 Constraints
Authors: Daniel Daza, Alberto Bernardi, Luca Costabello, Christophe Gueret,
 Masoud Mansoury, Michael Cochez, Martijn Schut
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2508.13663 ,  159kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21651
replaced with revised version Fri, 21 Nov 2025 18:22:41 GMT   (4211kb)

Title: Can AI Perceive Physical Danger and Intervene?
Authors: Abhishek Jindal, Dmitry Kalashnikov, R. Alex Hofer, Oscar Chang, Divya
 Garikapati, Anirudha Majumdar, Pierre Sermanet, Vikas Sindhwani
Categories: cs.AI
Report-no: Report-no: GDM-01-01
\\ ( https://arxiv.org/abs/2509.21651 ,  4211kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23629
replaced with revised version Fri, 21 Nov 2025 10:27:21 GMT   (2222kb)

Title: How LLMs Learn to Reason: A Complex Network Perspective
Authors: Sihan Hu, Xiansheng Cai, Yuan Huang, Zhiyuan Yao, Linfeng Zhang, Pan
 Zhang, Youjin Deng, Kun Chen
Categories: cs.AI cond-mat.dis-nn cond-mat.stat-mech cs.LG physics.soc-ph
Comments: 24 pages, 11 figures, 1 table, under review as a conference paper at
 ICLR 2026
\\ ( https://arxiv.org/abs/2509.23629 ,  2222kb)
------------------------------------------------------------------------------
\\
arXiv:2510.10135
replaced with revised version Fri, 21 Nov 2025 07:42:59 GMT   (4177kb)

Title: CharCom: Composable Identity Control for Multi-Character Story
 Illustration
Authors: Zhongsheng Wang, Ming Lin, Zhedong Lin, Yaser Shakib, Qian Liu, Jiamou
 Liu
Categories: cs.AI
Comments: Accepted by ACM MMAsia 2025
\\ ( https://arxiv.org/abs/2510.10135 ,  4177kb)
------------------------------------------------------------------------------
\\
arXiv:2510.12194
replaced with revised version Fri, 21 Nov 2025 05:43:16 GMT   (3280kb)

Title: ResearStudio: A Human-Intervenable Framework for Building Controllable
 Deep-Research Agents
Authors: Linyi Yang and Yixuan Weng
Categories: cs.AI
Comments: EMNLP 2025 Demo, Oral
\\ ( https://arxiv.org/abs/2510.12194 ,  3280kb)
------------------------------------------------------------------------------
\\
arXiv:2510.17108
replaced with revised version Fri, 21 Nov 2025 09:22:40 GMT   (1112kb)

Title: Structured Debate Improves Corporate Credit Reasoning in Financial AI
Authors: Yoonjin Lee, Munhee Kim, Hanbi Choi, Juhyeon Park, Seungho Lyoo,
 Woojin Park
Categories: cs.AI
Comments: 18 pages, 4 figures, 2 algorithms, 2 tables, 4 appendices
\\ ( https://arxiv.org/abs/2510.17108 ,  1112kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12135
replaced with revised version Fri, 21 Nov 2025 09:48:05 GMT   (1383kb)

Title: RTMol: Rethinking Molecule-text Alignment in a Round-trip View
Authors: Letian Chen, Runhan Shi, Gufeng Yu, Yang Yang
Categories: cs.AI
\\ ( https://arxiv.org/abs/2511.12135 ,  1383kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15974
replaced with revised version Fri, 21 Nov 2025 06:00:04 GMT   (2242kb)

Title: KRAL: Knowledge and Reasoning Augmented Learning for LLM-assisted
 Clinical Antimicrobial Therapy
Authors: Zhe Li, Yehan Qiu, Yujie Chen, Xiang Zhou
Categories: cs.AI
\\ ( https://arxiv.org/abs/2511.15974 ,  2242kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16202
replaced with revised version Fri, 21 Nov 2025 03:50:21 GMT   (797kb)

Title: Multi-Agent Collaborative Reward Design for Enhancing Reasoning in
 Reinforcement Learning
Authors: Pei Yang, Ke Zhang, Ji Wang, Xiao Chen, Yuxin Tang, Eric Yang, Lynn
 Ai, Bill Shi
Categories: cs.AI
\\ ( https://arxiv.org/abs/2511.16202 ,  797kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16600
replaced with revised version Fri, 21 Nov 2025 07:08:45 GMT   (4218kb)

Title: You Only Forward Once: An Efficient Compositional Judging Paradigm
Authors: Tianlong Zhang, Hongwei Xue, Shilin Yan, Di Wu, Chen Xu, Yunyun Yang
Categories: cs.AI
\\ ( https://arxiv.org/abs/2511.16600 ,  4218kb)
------------------------------------------------------------------------------
\\
arXiv:2306.08543
replaced with revised version Fri, 21 Nov 2025 10:20:53 GMT   (211kb)

Title: MiniLLM: Knowledge Distillation of Large Language Models
Authors: Yuxian Gu, Li Dong, Furu Wei, Minlie Huang
Categories: cs.CL cs.AI
Comments: Published as a conference paper in ICLR 2024
\\ ( https://arxiv.org/abs/2306.08543 ,  211kb)
------------------------------------------------------------------------------
\\
arXiv:2411.05986
replaced with revised version Fri, 21 Nov 2025 18:25:29 GMT   (9470kb)

Title: Fine-Grained Reward Optimization for Machine Translation using Error
 Severity Mappings
Authors: Miguel Moura Ramos, Tom\'as Almeida, Daniel Vareta, Filipe Azevedo,
 Sweta Agrawal, Patrick Fernandes, Andr\'e F. T. Martins
Categories: cs.CL
\\ ( https://arxiv.org/abs/2411.05986 ,  9470kb)
------------------------------------------------------------------------------
\\
arXiv:2411.09613
replaced with revised version Fri, 21 Nov 2025 00:40:57 GMT   (337kb)

Title: Task-Aligned Tool Recommendation for Large Language Models
Authors: Hang Gao, Yongfeng Zhang
Categories: cs.CL cs.AI
Comments: IJCNLP-AACL 2025 Main
\\ ( https://arxiv.org/abs/2411.09613 ,  337kb)
------------------------------------------------------------------------------
\\
arXiv:2503.23078
replaced with revised version Fri, 21 Nov 2025 01:28:03 GMT   (3247kb)

Title: EventWeave: A Dynamic Framework for Capturing Core and Supporting Events
 in Dialogue Systems
Authors: Zhengyi Zhao, Shubo Zhang, Yiming Du, Bin Liang, Baojun Wang,
 Zhongyang Li, Binyang Li, Kam-Fai Wong
Categories: cs.CL
\\ ( https://arxiv.org/abs/2503.23078 ,  3247kb)
------------------------------------------------------------------------------
\\
arXiv:2504.05185
replaced with revised version Fri, 21 Nov 2025 17:22:52 GMT   (583kb)

Title: Concise Reasoning via Reinforcement Learning
Authors: Mehdi Fatemi, Banafsheh Rafiee, Mingjie Tang, Kartik Talamadupula
Categories: cs.CL
\\ ( https://arxiv.org/abs/2504.05185 ,  583kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17260
replaced with revised version Fri, 21 Nov 2025 05:37:13 GMT   (254kb)

Title: The Rise of Parameter Specialization for Knowledge Storage in Large
 Language Models
Authors: Yihuai Hong, Yiran Zhao, Wei Tang, Yang Deng, Yu Rong, Wenxuan Zhang
Categories: cs.CL
Comments: Accepted in NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.17260 ,  254kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23662
replaced with revised version Fri, 21 Nov 2025 07:05:38 GMT   (3735kb)

Title: ToolHaystack: Stress-Testing Tool-Augmented Language Models in Realistic
 Long-Term Interactions
Authors: Beong-woo Kwak, Minju Kim, Dongha Lim, Hyungjoo Chae, Dongjin Kang,
 Sunghwan Kim, Dongil Yang, Jinyoung Yeo
Categories: cs.CL
Comments: Our code and data are available at
 https://github.com/bwookwak/ToolHaystack Edited for adding acknowledgement
 section
\\ ( https://arxiv.org/abs/2505.23662 ,  3735kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04224
replaced with revised version Fri, 21 Nov 2025 15:33:14 GMT   (899kb)

Title: Fairness Evaluation of Large Language Models in Academic Library
 Reference Services
Authors: Haining Wang, Jason Clark, Yueru Yan, Star Bradley, Ruiyang Chen,
 Yiqiong Zhang, Hengyi Fu, Zuoyu Tian
Categories: cs.CL cs.AI cs.DL
\\ ( https://arxiv.org/abs/2507.04224 ,  899kb)
------------------------------------------------------------------------------
\\
arXiv:2507.05248
replaced with revised version Fri, 21 Nov 2025 05:18:44 GMT   (9550kb)

Title: Response Attack: Exploiting Contextual Priming to Jailbreak Large
 Language Models
Authors: Ziqi Miao, Lijun Li, Yuan Xiong, Zhenhua Liu, Pengyu Zhu, Jing Shao
Categories: cs.CL
Comments: 20 pages, 10 figures. Code and data available at
 https://github.com/Dtc7w3PQ/Response-Attack
\\ ( https://arxiv.org/abs/2507.05248 ,  9550kb)
------------------------------------------------------------------------------
\\
arXiv:2507.10810
replaced with revised version Fri, 21 Nov 2025 15:51:27 GMT   (736kb)

Title: Testing Hypotheses from the Social Approval Theory of Online Hate: An
 Analysis of 110 Million Messages from Parler
Authors: David M. Markowitz, Samuel Hardman Taylor
Categories: cs.CL cs.SI
\\ ( https://arxiv.org/abs/2507.10810 ,  736kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00086
replaced with revised version Fri, 21 Nov 2025 18:13:28 GMT   (783kb)

Title: Do LLMs produce texts with "human-like" lexical diversity?
Authors: Kelly Kendro, Jeffrey Maloney, Scott Jarvis
Categories: cs.CL
\\ ( https://arxiv.org/abs/2508.00086 ,  783kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13804
replaced with revised version Thu, 20 Nov 2025 19:07:43 GMT   (157kb)

Title: Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values
 Understanding
Authors: Maciej Skorski and Alina Landowska
Categories: cs.CL cs.HC
Comments: Appears in UncertaiNLP@EMNLP 2025
MSC-class: 68T50, 62F15, 62P25
ACM-class: I.2.7; K.4.1; J.4
DOI: 10.18653/v1/2025.uncertainlp-main.3
\\ ( https://arxiv.org/abs/2508.13804 ,  157kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00974
replaced with revised version Fri, 21 Nov 2025 00:51:18 GMT   (1682kb)

Title: RPRO: Ranked Preference Reinforcement Optimization for Enhancing Medical
 QA and Diagnostic Reasoning
Authors: Chia-Hsuan Hsu, Jun-En Ding, Hsin-Ling Hsu, Chih-Ho Hsu, Li-Hung Yao,
 Chun-Chieh Liao, Feng Liu, Fang-Ming Hung
Categories: cs.CL
\\ ( https://arxiv.org/abs/2509.00974 ,  1682kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01612
replaced with revised version Thu, 20 Nov 2025 21:23:11 GMT   (0kb,I)

Title: RAG-BioQA Retrieval-Augmented Generation for Long-Form Biomedical
 Question Answering
Authors: Lovely Yeswanth Panchumarthi, Sai Prasad Gudari, Atharva Negi, Praveen
 Raj Budime, Harsit Upadhya
Categories: cs.CL cs.AI
Comments: Need to work on the methodology more
\\ ( https://arxiv.org/abs/2510.01612 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2510.13302
replaced with revised version Fri, 21 Nov 2025 14:29:26 GMT   (327kb)

Title: LLM one-shot style transfer for Authorship Attribution and Verification
Authors: Pablo Miralles-Gonz\'alez, Javier Huertas-Tato, Alejandro Mart\'in,
 David Camacho
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2510.13302 ,  327kb)
------------------------------------------------------------------------------
\\
arXiv:2510.13827
replaced with revised version Fri, 21 Nov 2025 02:06:39 GMT   (248kb)

Title: Bridging the Semantic Gap: Contrastive Rewards for Multilingual
 Text-to-SQL with GRPO
Authors: Ashish Kattamuri, Ishita Prasad, Meetu Malhotra, Arpita Vats, Rahul
 Raja, Albert Lie
Categories: cs.CL cs.AI
Comments: 20th International Workshop on Semantic and Social Media Adaptation &
 Personalization
\\ ( https://arxiv.org/abs/2510.13827 ,  248kb)
------------------------------------------------------------------------------
\\
arXiv:2510.16549
replaced with revised version Thu, 20 Nov 2025 21:58:01 GMT   (605kb)

Title: ReviewGuard: Enhancing Deficient Peer Review Detection via LLM-Driven
 Data Augmentation
Authors: Haoxuan Zhang, Ruochi Li, Sarthak Shrestha, Shree Harshini Mamidala,
 Revanth Putta, Arka Krishan Aggarwal, Ting Xiao, Junhua Ding, and Haihua Chen
Categories: cs.CL
Comments: Accepted as a full paper at the 2025 ACM/IEEE Joint Conference on
 Digital Libraries (JCDL 2025)
\\ ( https://arxiv.org/abs/2510.16549 ,  605kb)
------------------------------------------------------------------------------
\\
arXiv:2510.18774
replaced with revised version Fri, 21 Nov 2025 18:01:12 GMT   (13681kb)

Title: AI use in American newspapers is widespread, uneven, and rarely
 disclosed
Authors: Jenna Russell, Marzena Karpinska, Destiny Akinode, Katherine Thai,
 Bradley Emi, Max Spero, Mohit Iyyer
Categories: cs.CL
\\ ( https://arxiv.org/abs/2510.18774 ,  13681kb)
------------------------------------------------------------------------------
\\
arXiv:2511.01265
replaced with revised version Fri, 21 Nov 2025 04:30:16 GMT   (548kb)

Title: AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs
Authors: Mo El-Haj and Paul Rayson
Categories: cs.CL
Comments: 9 pages
Journal-ref: IEEE BigData 2025
\\ ( https://arxiv.org/abs/2511.01265 ,  548kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03407
replaced with revised version Fri, 21 Nov 2025 09:54:40 GMT   (1080kb)

Title: Overcoming the Generalization Limits of SLM Finetuning for Shape-Based
 Extraction of Datatype and Object Properties
Authors: C\'elian Ringwald and Fabien Gandon and Catherine Faron and Franck
 Michel and Hanna Abi Akl
Categories: cs.CL
Comments: Accepted at KCAP 2025
Report-no: 6956920v1
ACM-class: I.2.7; I.2.4
\\ ( https://arxiv.org/abs/2511.03407 ,  1080kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03610
replaced with revised version Fri, 21 Nov 2025 09:18:36 GMT   (38884kb)

Title: A systematic review of relation extraction task since the emergence of
 Transformers
Authors: Ringwald Celian and Gandon, Fabien and Faron Catherine and Michel
 Franck and Abi Akl Hanna
Categories: cs.CL
Comments: Submited at ACM-Computing Surveys + The resulting annotated Zotero
 bibliography :
 https://www.zotero.org/groups/6070963/scilex_re_systlitreview/library +
 SciLEx software: https://github.com/Wimmics/SciLEx
ACM-class: A.1; I.2.4; I.2.7
\\ ( https://arxiv.org/abs/2511.03610 ,  38884kb)
------------------------------------------------------------------------------
\\
arXiv:2511.04079
replaced with revised version Fri, 21 Nov 2025 08:26:41 GMT   (261kb)

Title: Improving the Performance of Radiology Report De-identification with
 Large-Scale Training and Benchmarking Against Cloud Vendor Methods
Authors: Eva Prakash, Maayane Attias, Pierre Chambon, Justin Xu, Steven Truong,
 Jean-Benoit Delbrouck, Tessa Cook, Curtis Langlotz
Categories: cs.CL
Comments: In submission to JAMIA
\\ ( https://arxiv.org/abs/2511.04079 ,  261kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07318
replaced with revised version Fri, 21 Nov 2025 11:45:34 GMT   (9377kb)

Title: When Bias Pretends to Be Truth: How Spurious Correlations Undermine
 Hallucination Detection in LLMs
Authors: Shaowen Wang, Yiqi Dong, Ruinian Chang, Tansheng Zhu, Yuebo Sun,
 Kaifeng Lyu, Jian Li
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2511.07318 ,  9377kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12861
replaced with revised version Fri, 21 Nov 2025 06:39:29 GMT   (1538kb)

Title: From Perception to Reasoning: Deep Thinking Empowers Multimodal Large
 Language Models
Authors: Wenxin Zhu, Andong Chen, Yuchen Song, Kehai Chen, Conghui Zhu, Ziyan
 Chen, Tiejun Zhao
Categories: cs.CL cs.CV
Comments: Survey; 7 figures, 3 tables, 44 pages
\\ ( https://arxiv.org/abs/2511.12861 ,  1538kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13182
replaced with revised version Fri, 21 Nov 2025 14:13:16 GMT   (2737kb)

Title: Evaluating Large Language Models for Diacritic Restoration in Romanian
 Texts: A Comparative Study
Authors: Mihai Nadas, Laura Diosan
Categories: cs.CL
Comments: The original submission contained metadata errors and requires
 correction. A revised and complete version will be submitted as a replacement
\\ ( https://arxiv.org/abs/2511.13182 ,  2737kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16544
replaced with revised version Fri, 21 Nov 2025 15:29:43 GMT   (3348kb)

Title: WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding
 in Patient Facing Dialogue
Authors: Zachary Ellis, Jared Joselowitz, Yash Deo, Yajie He, Anna Kalygina,
 Aisling Higham, Mana Rahimzadeh, Yan Jia, Ibrahim Habli, Ernest Lim
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2511.16544 ,  3348kb)
------------------------------------------------------------------------------
\\
arXiv:2102.11361
replaced with revised version Thu, 20 Nov 2025 20:34:16 GMT   (31793kb)

Title: FaCells. Teaching Machines the Language of Lines: Per Point Attribute
 Scores for Face-Sketch Classification
Authors: Xavier Ignacio Gonzalez
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2102.11361 ,  31793kb)
------------------------------------------------------------------------------
\\
arXiv:2308.00929
replaced with revised version Fri, 21 Nov 2025 03:03:17 GMT   (4950kb)

Title: Colo-ReID: Discriminative Representation Embedding with Meta-learning
 for Colonoscopic Polyp Re-Identification
Authors: Suncheng Xiang, Chengfeng Zhou, Zhengjie Zhang, Shilun Cai, Dahong
 Qian
Categories: cs.CV
\\ ( https://arxiv.org/abs/2308.00929 ,  4950kb)
------------------------------------------------------------------------------
\\
arXiv:2311.02733
replaced with revised version Fri, 21 Nov 2025 05:23:01 GMT   (510kb)

Title: AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency
 for Deepfake Detection of Frontal Face Videos
Authors: Sahibzada Adil Shahzad, Ammarah Hashmi, Yan-Tsung Peng, Yu Tsao,
 Hsin-Min Wang
Categories: cs.CV cs.AI cs.LG cs.MM cs.SD eess.AS
DOI: 10.1109/THMS.2025.3618409
\\ ( https://arxiv.org/abs/2311.02733 ,  510kb)
------------------------------------------------------------------------------
\\
arXiv:2402.16126
replaced with revised version Fri, 21 Nov 2025 07:20:20 GMT   (13064kb)

Title: A statistical method for crack pre-detection in 3D concrete images
Authors: Vitalii Makogin, Duc Nguyen and Evgeny Spodarev
Categories: cs.CV stat.AP
\\ ( https://arxiv.org/abs/2402.16126 ,  13064kb)
------------------------------------------------------------------------------
\\
arXiv:2405.15278
replaced with revised version Fri, 21 Nov 2025 03:30:24 GMT   (6598kb)

Title: MindShot: A Few-Shot Brain Decoding Framework via Transferring
 Cross-Subject Prior and Distilling Frequency Domain Knowledge
Authors: Shuai Jiang, Zhu Meng, Haiwen Li, Delong Liu, Fei Su and Zhicheng Zhao
Categories: cs.CV
Comments: Accepted by KBS
\\ ( https://arxiv.org/abs/2405.15278 ,  6598kb)
------------------------------------------------------------------------------
\\
arXiv:2407.05650
replaced with revised version Fri, 21 Nov 2025 12:45:04 GMT   (6226kb)

Title: The Cooperative Network Architecture: Learning Structured Networks as
 Representation of Sensory Patterns
Authors: Pascal J. Sager, Jan M. Deriu, Benjamin F. Grewe, Thilo Stadelmann,
 and Christoph von der Malsburg
Categories: cs.CV cs.AI cs.LG cs.NE
Comments: Accepted at Neural Computation
\\ ( https://arxiv.org/abs/2407.05650 ,  6226kb)
------------------------------------------------------------------------------
\\
arXiv:2407.07026
replaced with revised version Fri, 21 Nov 2025 14:01:14 GMT   (1604kb)

Title: Resolving Sentiment Discrepancy for Multimodal Sentiment Detection via
 Semantics Completion and Decomposition
Authors: Daiqing Wu, Dongbao Yang, Huawen Shen, Can Ma, Yu Zhou
Categories: cs.CV cs.CL cs.MM cs.SI
Comments: Accepted by Pattern Recognition
\\ ( https://arxiv.org/abs/2407.07026 ,  1604kb)
------------------------------------------------------------------------------
\\
arXiv:2407.20799
replaced with revised version Fri, 21 Nov 2025 05:12:45 GMT   (2760kb)

Title: SpotFormer: Multi-Scale Spatio-Temporal Transformer for Facial
 Expression Spotting
Authors: Yicheng Deng, Hideaki Hayashi, Hajime Nagahara
Categories: cs.CV
\\ ( https://arxiv.org/abs/2407.20799 ,  2760kb)
------------------------------------------------------------------------------
\\
arXiv:2411.16898
replaced with revised version Thu, 20 Nov 2025 19:07:57 GMT   (10176kb)

Title: MonoGSDF: Exploring Monocular Geometric Cues for Gaussian
 Splatting-Guided Implicit Surface Reconstruction
Authors: Kunyi Li, Michael Niemeyer, Zeyu Chen, Nassir Navab, Federico Tombari
Categories: cs.CV
\\ ( https://arxiv.org/abs/2411.16898 ,  10176kb)
------------------------------------------------------------------------------
\\
arXiv:2502.07160
replaced with revised version Fri, 21 Nov 2025 11:38:45 GMT   (4782kb)

Title: HDCompression: Hybrid-Diffusion Image Compression for Ultra-Low Bitrates
Authors: Lei Lu, Yize Li, Yanzhi Wang, Wei Wang, Wei Jiang
Categories: cs.CV cs.MM
Comments: Accepted by PRICAI 2025 (Oral Presentation)
\\ ( https://arxiv.org/abs/2502.07160 ,  4782kb)
------------------------------------------------------------------------------
\\
arXiv:2502.14142
replaced with revised version Thu, 20 Nov 2025 22:23:48 GMT   (835kb)

Title: Token Adaptation via Side Graph Convolution for Efficient Fine-tuning of
 3D Point Cloud Transformers
Authors: Takahiko Furuya
Categories: cs.CV
\\ ( https://arxiv.org/abs/2502.14142 ,  835kb)
------------------------------------------------------------------------------
\\
arXiv:2502.17429
replaced with revised version Fri, 21 Nov 2025 13:32:04 GMT   (1834kb)

Title: CLIMB-3D: Continual Learning for Imbalanced 3D Instance Segmentation
Authors: Vishal Thengane, Jean Lahoud, Hisham Cholakkal, Rao Muhammad Anwer, Lu
 Yin, Xiatian Zhu and Salman Khan
Categories: cs.CV
Comments: Accepted at BMVC 2025
\\ ( https://arxiv.org/abs/2502.17429 ,  1834kb)
------------------------------------------------------------------------------
\\
arXiv:2502.19800
replaced with revised version Fri, 21 Nov 2025 17:27:18 GMT   (41496kb)

Title: TrackGS: Optimizing COLMAP-Free 3D Gaussian Splatting with Global Track
 Constraints
Authors: Dongbo Shi, Shen Cao, Lubin Fan, Bojian Wu, Jinhui Guo, Ligang Liu,
 Renjie Chen
Categories: cs.CV
Journal-ref: AAAI 2026
\\ ( https://arxiv.org/abs/2502.19800 ,  41496kb)
------------------------------------------------------------------------------
\\
arXiv:2503.00972
replaced with revised version Fri, 21 Nov 2025 05:05:30 GMT   (2193kb)

Title: Semantic-ICP: Iterative Closest Point for Non-rigid Multi-Organ Point
 Cloud Registration
Authors: Wanwen Chen, Qi Zeng, Carson Studders, Jamie J.Y. Kwon, Emily H.T.
 Pang, Eitan Prisman and Septimiu E. Salcudean
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.00972 ,  2193kb)
------------------------------------------------------------------------------
\\
arXiv:2503.06677
replaced with revised version Fri, 21 Nov 2025 10:01:42 GMT   (11892kb)

Title: REArtGS: Reconstructing and Generating Articulated Objects via 3D
 Gaussian Splatting with Geometric and Motion Constraints
Authors: Di Wu, Liu Liu, Zhou Linli, Anran Huang, Liangtu Song, Qiaojun Yu, Qi
 Wu, Cewu Lu
Categories: cs.CV cs.MM
Comments: 11pages, 6 figures
\\ ( https://arxiv.org/abs/2503.06677 ,  11892kb)
------------------------------------------------------------------------------
\\
arXiv:2503.09878
replaced with revised version Fri, 21 Nov 2025 12:54:49 GMT   (6277kb)

Title: CleverDistiller: Simple and Spatially Consistent Cross-modal
 Distillation
Authors: Hariprasath Govindarajan, Maciej K. Wozniak, Marvin Klingner, Camille
 Maurice, B Ravi Kiran, Senthil Yogamani
Categories: cs.CV cs.AI cs.RO
Comments: Accepted to BMVC 2025
\\ ( https://arxiv.org/abs/2503.09878 ,  6277kb)
------------------------------------------------------------------------------
\\
arXiv:2503.12972
replaced with revised version Fri, 21 Nov 2025 09:26:05 GMT   (8875kb)

Title: Aligning Vision to Language: Annotation-Free Multimodal Knowledge Graph
 Construction for Enhanced LLMs Reasoning
Authors: Junming Liu, Siyuan Meng, Yanting Gao, Song Mao, Pinlong Cai, Guohang
 Yan, Yirong Chen, Zilin Bian, Ding Wang, Botian Shi
Categories: cs.CV cs.AI
Comments: 14 pages, 7 figures, 6 tables; Accepted by ICCV 2025
\\ ( https://arxiv.org/abs/2503.12972 ,  8875kb)
------------------------------------------------------------------------------
\\
arXiv:2503.21692
replaced with revised version Fri, 21 Nov 2025 10:26:45 GMT   (3695kb)

Title: RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose
 Triangulation in a Millisecond
Authors: Daniel Bermuth, Alexander Poeppel, Wolfgang Reif
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.21692 ,  3695kb)
------------------------------------------------------------------------------
\\
arXiv:2503.23463
replaced with revised version Fri, 21 Nov 2025 14:50:41 GMT   (32323kb)

Title: OpenDriveVLA: Towards End-to-end Autonomous Driving with Large Vision
 Language Action Model
Authors: Xingcheng Zhou, Xuyuan Han, Feng Yang, Yunpu Ma, Volker Tresp, Alois
 Knoll
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.23463 ,  32323kb)
------------------------------------------------------------------------------
\\
arXiv:2504.21194
replaced with revised version Thu, 20 Nov 2025 23:01:30 GMT   (2278kb)

Title: ISS-Geo142: A Benchmark for Geolocating Astronaut Photography from the
 International Space Station
Authors: Vedika Srivastava, Hemant Kumar Singh, and Jaisal Singh
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2504.21194 ,  2278kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21502
replaced with revised version Fri, 21 Nov 2025 06:23:38 GMT   (10156kb)

Title: Generalizable and Relightable Gaussian Splatting for Human Novel View
 Synthesis
Authors: Yipengjing Sun, Shengping Zhang, Chenyang Wang, Shunyuan Zheng,
 Zonglin Li, Xiangyang Ji
Categories: cs.CV
Comments: Project Webpage: https://sypj-98.github.io/grgs/
\\ ( https://arxiv.org/abs/2505.21502 ,  10156kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21535
replaced with revised version Thu, 20 Nov 2025 21:06:39 GMT   (611kb)

Title: FAR: Function-preserving Attention Replacement for IMC-friendly
 Inference
Authors: Yuxin Ren, Maxwell D Collins, Miao Hu, Huanrui Yang
Categories: cs.CV cs.AI cs.LG
Comments: 12 pages main paper, 6 figures
\\ ( https://arxiv.org/abs/2505.21535 ,  611kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00820
replaced with revised version Fri, 21 Nov 2025 05:23:24 GMT   (21755kb)

Title: QuantFace: Efficient Quantization for Face Restoration
Authors: Jiatong Li, Libo Zhu, Haotong Qin, Jingkai Wang, Linghe Kong, Guihai
 Chen, Yulun Zhang, Xiaokang Yang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.00820 ,  21755kb)
------------------------------------------------------------------------------
\\
arXiv:2506.03079
replaced with revised version Thu, 20 Nov 2025 13:51:24 GMT   (77788kb)

Title: ORV: 4D Occupancy-centric Robot Video Generation
Authors: Xiuyu Yang, Bohan Li, Shaocong Xu, Nan Wang, Chongjie Ye, Zhaoxi Chen,
 Minghan Qin, Yikang Ding, Zheng Zhu, Xin Jin, Hang Zhao, Hao Zhao
Categories: cs.CV
Comments: Project page: https://orangesodahub.github.io/ORV/ ; Code:
 https://github.com/OrangeSodahub/ORV
\\ ( https://arxiv.org/abs/2506.03079 ,  77788kb)
------------------------------------------------------------------------------
\\
arXiv:2506.09460
replaced with revised version Fri, 21 Nov 2025 08:50:02 GMT   (4159kb)

Title: Open-Set Domain Generalization through Spectral-Spatial Uncertainty
 Disentanglement for Hyperspectral Image Classification
Authors: Amirreza Khoshbakht and Erchan Aptoula
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.09460 ,  4159kb)
------------------------------------------------------------------------------
\\
arXiv:2506.16112
replaced with revised version Fri, 21 Nov 2025 09:49:21 GMT   (13839kb)

Title: Loss-Oriented Ranking for Automated Visual Prompting in LVLMs
Authors: Yuan Zhang, Chun-Kai Fan, Tao Huang, Ming Lu, Sicheng Yu, Junwen Pan,
 Kuan Cheng, Qi She, Shanghang Zhang
Categories: cs.CV
Comments: 17 pages
\\ ( https://arxiv.org/abs/2506.16112 ,  13839kb)
------------------------------------------------------------------------------
\\
arXiv:2506.18883
replaced with revised version Fri, 21 Nov 2025 06:02:45 GMT   (2043kb)

Title: Universal Video Temporal Grounding with Generative Multi-modal Large
 Language Models
Authors: Zeqian Li, Shangzhe Di, Zhonghua Zhai, Weilin Huang, Yanfeng Wang,
 Weidi Xie
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.18883 ,  2043kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04482
replaced with revised version Fri, 21 Nov 2025 16:25:35 GMT   (36285kb)

Title: A Training-Free Style-Personalization via SVD-Based Feature
 Decomposition
Authors: Kyoungmin Lee, Jihun Park, Jongmin Gim, Wonhyeok Choi, Kyumin Hwang,
 Jaeyeul Kim, Sunghoon Im
Categories: cs.CV
Comments: 21 pages, 14 figures
\\ ( https://arxiv.org/abs/2507.04482 ,  36285kb)
------------------------------------------------------------------------------
\\
arXiv:2508.03100
replaced with revised version Fri, 21 Nov 2025 00:10:21 GMT   (5678kb)

Title: AVATAR: Reinforcement Learning to See, Hear, and Reason Over Video
Authors: Yogesh Kulkarni, Pooyan Fazli
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.03100 ,  5678kb)
------------------------------------------------------------------------------
\\
arXiv:2508.04424
replaced with revised version Fri, 21 Nov 2025 09:48:34 GMT   (9909kb)

Title: Composed Object Retrieval: Object-level Retrieval via Composed
 Expressions
Authors: Tong Wang, Guanyu Yang, Nian Liu, Zongyan Han, Jinxing Zhou, Salman
 Khan, Fahad Shahbaz Khan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.04424 ,  9909kb)
------------------------------------------------------------------------------
\\
arXiv:2508.06869
replaced with revised version Fri, 21 Nov 2025 12:37:49 GMT   (1783kb)

Title: VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long
 Video Understanding
Authors: Jianxiang He, Meisheng Hong, Jungang Li, Ziyang Chen, Weiyu Guo,
 Xuming Hu, Hui Xiong
Categories: cs.CV cs.AI
Comments: 9 pages,3 figures
ACM-class: I.2.10
\\ ( https://arxiv.org/abs/2508.06869 ,  1783kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09327
replaced with revised version Fri, 21 Nov 2025 15:55:52 GMT   (1289kb)

Title: Lung-DDPM+: Efficient Thoracic CT Image Synthesis using Diffusion
 Probabilistic Model
Authors: Yifan Jiang, Ahmad Shariftabrizi, Venkata SK. Manem
Categories: cs.CV
Comments: Accepted by Computers in Biology and Medicine (CIBM)
DOI: 10.1016/j.compbiomed.2025.111290
\\ ( https://arxiv.org/abs/2508.09327 ,  1289kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16069
replaced with revised version Fri, 21 Nov 2025 16:08:58 GMT   (244kb)

Title: A Unified Voxel Diffusion Module for Point Cloud 3D Object Detection
Authors: Qifeng Liu, Dawei Zhao, Yabo Dong, Linzhi Shang, Liang Xiao, Juan
 Wang, Kunkong Zhao, Dongming Lu, Qi Zhu
Categories: cs.CV
Comments: Under review
\\ ( https://arxiv.org/abs/2508.16069 ,  244kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14001
replaced with revised version Fri, 21 Nov 2025 14:33:03 GMT   (9544kb)

Title: MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment
Authors: Elena Camuffo, Francesco Barbato, Mete Ozay, Simone Milani, Umberto
 Michieli
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2509.14001 ,  9544kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14550
replaced with revised version Fri, 21 Nov 2025 12:12:05 GMT   (9155kb)

Title: EatGAN: An Edge-Attention Guided Generative Adversarial Network for
 Single Image Super-Resolution
Authors: Penghao Rao, Tieyong Zeng
Categories: cs.CV
Comments: 17 pages (8 pages of main text + 3 pages of reference + 6 pages of
 supplementary material)
MSC-class: 68T45, 68T07, 68U10
\\ ( https://arxiv.org/abs/2509.14550 ,  9155kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03135
replaced with revised version Fri, 21 Nov 2025 08:32:29 GMT   (2391kb)

Title: Mask2IV: Interaction-Centric Video Generation via Mask Trajectories
Authors: Gen Li, Bo Zhao, Jianfei Yang, Laura Sevilla-Lara
Categories: cs.CV cs.RO
Comments: AAAI 2026. Project page: https://reagan1311.github.io/mask2iv
\\ ( https://arxiv.org/abs/2510.03135 ,  2391kb)
------------------------------------------------------------------------------
\\
arXiv:2510.08318
replaced with revised version Fri, 21 Nov 2025 14:45:09 GMT   (10666kb)

Title: LinVideo: A Post-Training Framework towards O(n) Attention in Efficient
 Video Generation
Authors: Yushi Huang, Xingtong Ge, Ruihao Gong, Chengtao Lv, Jun Zhang
Categories: cs.CV
Comments: Code will be released upon acceptance
\\ ( https://arxiv.org/abs/2510.08318 ,  10666kb)
------------------------------------------------------------------------------
\\
arXiv:2510.09110
replaced with revised version Fri, 21 Nov 2025 12:01:11 GMT   (34751kb)

Title: Synthetic Object Compositions for Scalable and Accurate Learning in
 Detection, Segmentation, and Grounding
Authors: Weikai Huang, Jieyu Zhang, Taoyang Jia, Chenhao Zheng, Ziqi Gao, Jae
 Sung Park, Winson Han, Ranjay Krishna
Categories: cs.CV cs.AI
Comments: Project website:
 https://github.com/weikaih04/Synthetic-Detection-Segmentation-Grounding-Data
\\ ( https://arxiv.org/abs/2510.09110 ,  34751kb)
------------------------------------------------------------------------------
\\
arXiv:2510.14528
replaced with revised version Fri, 21 Nov 2025 06:39:47 GMT   (20915kb)

Title: PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B
 Ultra-Compact Vision-Language Model
Authors: Cheng Cui, Ting Sun, Suyin Liang, Tingquan Gao, Zelun Zhang, Jiaxuan
 Liu, Xueqing Wang, Changda Zhou, Hongen Liu, Manhui Lin, Yue Zhang, Yubo
 Zhang, Handong Zheng, Jing Zhang, Jun Zhang, Yi Liu, Dianhai Yu, Yanjun Ma
Categories: cs.CV
Comments: Github Repo: https://github.com/PaddlePaddle/PaddleOCR
\\ ( https://arxiv.org/abs/2510.14528 ,  20915kb)
------------------------------------------------------------------------------
\\
arXiv:2510.25522
replaced with revised version Fri, 21 Nov 2025 01:54:14 GMT   (3368kb)

Title: Comparative Study of UNet-based Architectures for Liver Tumor
 Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography
Authors: Doan-Van-Anh Ly (1), Thi-Thu-Hien Pham (2 and 3), Thanh-Hai Le (1)
 ((1) The Saigon International University, (2) International University, (3)
 Vietnam National University HCMC)
Categories: cs.CV cs.AI
Comments: 16 pages, 9 figures
ACM-class: I.4.6
\\ ( https://arxiv.org/abs/2510.25522 ,  3368kb)
------------------------------------------------------------------------------
\\
arXiv:2510.26601
replaced with revised version Fri, 21 Nov 2025 15:25:30 GMT   (2035kb)

Title: ResMatching: Noise-Resilient Computational Super-Resolution via Guided
 Conditional Flow Matching
Authors: Anirban Ray, Vera Galinova, Florian Jug
Categories: cs.CV cs.AI
Comments: 5 pages, 4 figures
\\ ( https://arxiv.org/abs/2510.26601 ,  2035kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00456
replaced with revised version Thu, 20 Nov 2025 21:15:34 GMT   (4954kb)

Title: Weakly Supervised Pneumonia Localization from Chest X-Rays Using Deep
 Neural Network and Grad-CAM Explanations
Authors: Kiran Shahi and Anup Bagale
Categories: cs.CV
Comments: https://github.com/kiranshahi/pneumonia-analysis
\\ ( https://arxiv.org/abs/2511.00456 ,  4954kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00511
replaced with revised version Fri, 21 Nov 2025 18:35:34 GMT   (24160kb)

Title: ID-Crafter: VLM-Grounded Online RL for Compositional Multi-Subject Video
 Generation
Authors: Panwang Pan, Jingjing Zhao, Yuchen Lin, Chenguo Lin, Chenxin Li,
 Hengyu Liu, Tingting Shen, Yadong MU
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.00511 ,  24160kb)
------------------------------------------------------------------------------
\\
arXiv:2511.02558
replaced with revised version Fri, 21 Nov 2025 18:11:50 GMT   (498kb)

Title: Forecasting Future Anatomies: Longitudinal Brain Mri-to-Mri Prediction
Authors: Ali Farki, Elaheh Moradi, Deepika Koundal, Jussi Tohka
Categories: cs.CV cs.LG q-bio.NC
\\ ( https://arxiv.org/abs/2511.02558 ,  498kb)
------------------------------------------------------------------------------
\\
arXiv:2511.03725
replaced with revised version Fri, 21 Nov 2025 15:12:29 GMT   (5795kb)

Title: Disentangled Concepts Speak Louder Than Words: Explainable Video Action
 Recognition
Authors: Jongseo Lee, Wooil Lee, Gyeong-Moon Park, Seong Tae Kim, Jinwoo Choi
Categories: cs.CV
Comments: NeurIPS 2025 Spotlight paper. Project page:
 https://jong980812.github.io/DANCE/
\\ ( https://arxiv.org/abs/2511.03725 ,  5795kb)
------------------------------------------------------------------------------
\\
arXiv:2511.10629
replaced with revised version Fri, 21 Nov 2025 14:39:42 GMT   (46090kb)

Title: One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale
 Adapter for Your Diffusion Models
Authors: Aleksandr Razin, Danil Kazantsev, Ilya Makarov
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.10629 ,  46090kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11005
replaced with revised version Fri, 21 Nov 2025 06:58:21 GMT   (1305kb)

Title: Draft and Refine with Visual Experts
Authors: Sungheon Jeong and Ryozo Masukawa and Jihong Park and Sanggeon Yun and
 Wenjun Huang and Hanning Chen and Mahdi Imani and Mohsen Imani
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.11005 ,  1305kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11236
replaced with revised version Fri, 21 Nov 2025 04:59:34 GMT   (15492kb)

Title: Parameter-Efficient MoE LoRA for Few-Shot Multi-Style Editing
Authors: Cong Cao, Yujie Xu, Xiaodong Xu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.11236 ,  15492kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11313
replaced with revised version Fri, 21 Nov 2025 14:18:23 GMT   (26871kb)

Title: DocSLM: A Small Vision-Language Model for Long Multimodal Document
 Understanding
Authors: Tanveer Hannan, Dimitrios Mallios, Parth Pathak, Faegheh Sardari,
 Thomas Seidl, Gedas Bertasius, Mohsen Fayyaz, Sunando Sengupta
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.11313 ,  26871kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11910
replaced with revised version Fri, 21 Nov 2025 17:08:33 GMT   (1035kb)

Title: Seeing the Forest and the Trees: Query-Aware Tokenizer for Long-Video
 Multimodal Language Models
Authors: Siyou Li, Huanan Wu, Juexi Shao, Yinghao Ma, Yujian Gan, Yihao Luo,
 Yuwei Wang, Dong Nie, Lu Wang, Wengqing Wu, Le Zhang, Massimo Poesio, Juntao
 Yu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.11910 ,  1035kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11989
replaced with revised version Fri, 21 Nov 2025 08:39:43 GMT   (35361kb)

Title: BeyondFacial: Identity-Preserving Personalized Generation Beyond Facial
 Close-ups
Authors: Songsong Zhang, Chuanqi Tang, Hongguang Zhang, Guijian Tang, Minglong
 Li, Xueqiong Li, Shaowu Yang, Yuanxi Peng, Wenjing Yang, Jing Zhao
Categories: cs.CV
Comments: 16 pages, 16 figures
\\ ( https://arxiv.org/abs/2511.11989 ,  35361kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12084
replaced with revised version Fri, 21 Nov 2025 04:13:45 GMT   (20148kb)

Title: SemanticStitch: Enhancing Image Coherence through Foreground-Aware Seam
 Carving
Authors: Ji-Ping Jin, Chen-Bin Feng, Rui Fan, Chi-Man Vong
Categories: cs.CV
Comments: 12pages, has been early accepted by The Visual Computer:
 International Journal of Computer Graphics, 2025
\\ ( https://arxiv.org/abs/2511.12084 ,  20148kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12233
replaced with revised version Fri, 21 Nov 2025 11:52:36 GMT   (3064kb)

Title: Model Inversion Attack Against Deep Hashing
Authors: Dongdong Zhao, Qiben Xu, Ranxin Fang, Baogang Song
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.12233 ,  3064kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12932
replaced with revised version Fri, 21 Nov 2025 09:15:09 GMT   (53605kb)

Title: Text2Traffic: A Text-to-Image Generation and Editing Method for Traffic
 Scenes
Authors: Feng Lv, Haoxuan Feng, Zilu Zhang, Chunlong Xia, and Yanfeng Li
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.12932 ,  53605kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13278
replaced with revised version Fri, 21 Nov 2025 09:21:15 GMT   (1412kb)

Title: SF-Recon: Simplification-Free Lightweight Building Reconstruction via 3D
 Gaussian Splatting
Authors: Zihan Li, Tengfei Wang, Wentian Gan, Hao Zhan, Xin Wang, Zongqian Zhan
Categories: cs.CV
Comments: This paper has been submitted to the 2026 ISPRS Congress
\\ ( https://arxiv.org/abs/2511.13278 ,  1412kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13344
replaced with revised version Fri, 21 Nov 2025 18:33:16 GMT   (569kb)

Title: YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object
 Detection
Authors: Ori Meiraz, Sharon Shalev, Avishai Weizman
Categories: cs.CV
Comments: 1 figure, 1 table
\\ ( https://arxiv.org/abs/2511.13344 ,  569kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14137
replaced with revised version Fri, 21 Nov 2025 12:17:52 GMT   (3712kb)

Title: Attention Via Convolutional Nearest Neighbors
Authors: Mingi Kang, Jeov\'a Farias Sales Rocha Neto
Categories: cs.CV
\\ ( https://arxiv.org/abs/2511.14137 ,  3712kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14998
replaced with revised version Fri, 21 Nov 2025 00:06:20 GMT   (3489kb)

Title: FinCriticalED: A Visual Benchmark for Financial Fact-Level OCR
 Evaluation
Authors: Yueru He, Xueqing Peng, Yupeng Cao, Yan Wang, Lingfei Qian, Haohang
 Li, Yi Han, Ruoyu Xiang, Mingquan Lin, Prayag Tiwari, Jimin Huang, Guojun
 Xiong, Sophia Ananiadou
Categories: cs.CV
Comments: Yueru He, Xueqing Peng: These two authors contributed equally to this
 work
\\ ( https://arxiv.org/abs/2511.14998 ,  3489kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15311
replaced with revised version Thu, 20 Nov 2025 19:08:56 GMT   (5947kb)

Title: Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time
 Adaptation of 3D Vision-Language Foundation Models
Authors: Mehran Tamjidi, Hamidreza Dastmalchi, Mohammadreza Alimoradijazi, Ali
 Cheraghian, Aijun An, Morteza Saberi
Categories: cs.CV
Comments: Accepted by AAAI 2026
\\ ( https://arxiv.org/abs/2511.15311 ,  5947kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15675
replaced with revised version Fri, 21 Nov 2025 18:28:30 GMT   (16339kb)

Title: MF-GCN: A Multi-Frequency Graph Convolutional Network for Tri-Modal
 Depression Detection Using Eye-Tracking, Facial, and Acoustic Features
Authors: Sejuti Rahman, Swakshar Deb, MD. Sameer Iqbal Chowdhury, MD. Jubair
 Ahmed Sourov, Mohammad Shamsuddin
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.15675 ,  16339kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15946
replaced with revised version Fri, 21 Nov 2025 18:09:32 GMT   (5880kb)

Title: Automated Interpretable 2D Video Extraction from 3D Echocardiography
Authors: Milos Vukadinovic, Hirotaka Ieki, Yuki Sahashi, David Ouyang, Bryan He
Categories: cs.CV
Comments: 12 pages, 5 figures
\\ ( https://arxiv.org/abs/2511.15946 ,  5880kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16449
replaced with revised version Fri, 21 Nov 2025 11:57:47 GMT   (1779kb)

Title: VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient
 Vision-Language-Action Inference
Authors: Ziyan Liu, Yeqiu Chen, Hongyi Cai, Tao Lin, Shuo Yang, Zheng Liu, Bo
 Zhao
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2511.16449 ,  1779kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16541
replaced with revised version Fri, 21 Nov 2025 08:44:06 GMT   (5271kb)

Title: Supervised Contrastive Learning for Few-Shot AI-Generated Image
 Detection and Attribution
Authors: Jaime \'Alvarez Urue\~na, David Camacho, Javier Huertas Tato
Categories: cs.CV cs.AI
Comments: 17 pages, 6 figures, 6 tables
ACM-class: I.2.10; I.4.10
\\ ( https://arxiv.org/abs/2511.16541 ,  5271kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16567
replaced with revised version Fri, 21 Nov 2025 11:07:49 GMT   (6165kb)

Title: POMA-3D: The Point Map Way to 3D Scene Understanding
Authors: Ye Mao, Weixun Luo, Ranran Huang, Junpeng Jing, Krystian Mikolajczyk
Categories: cs.CV
Comments: 11 pages, 6 tables, 5 figures
\\ ( https://arxiv.org/abs/2511.16567 ,  6165kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16672
replaced with revised version Fri, 21 Nov 2025 07:47:18 GMT   (1156kb)

Title: EvoLMM: Self-Evolving Large Multimodal Models with Continuous Rewards
Authors: Omkar Thawakar, Shravan Venkatraman, Ritesh Thawkar, Abdelrahman
 Shaker, Hisham Cholakkal, Rao Muhammad Anwer, Salman Khan, Fahad Khan
Categories: cs.CV
Comments: 9 Pages, 6 Figures, 4 Tables
\\ ( https://arxiv.org/abs/2511.16672 ,  1156kb)
------------------------------------------------------------------------------
\\
arXiv:2305.07419
replaced with revised version Fri, 21 Nov 2025 14:37:24 GMT   (1149kb)

Title: Breaking the Curse of Knowledge: Towards Effective Multimodal
 Recommendation using Knowledge Soft Integration
Authors: Kai Ouyang, Chen Tang, Zenghao Chai, Wenhao Zheng, Xiangjin Xie,
 Xuanji Xiao, Zhi Wang
Categories: cs.IR cs.MM
Comments: Accepted to IEEE Transactions on Multimedia (TMM)
\\ ( https://arxiv.org/abs/2305.07419 ,  1149kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12396
replaced with revised version Fri, 21 Nov 2025 11:54:35 GMT   (2380kb)

Title: LLM-CoT Enhanced Graph Neural Recommendation with Harmonized Group
 Policy Optimization
Authors: Hailong Luo, Bin Wu, Hongyong Jia, Qingqing Zhu, Lianlei Shan
Categories: cs.IR
\\ ( https://arxiv.org/abs/2505.12396 ,  2380kb)
------------------------------------------------------------------------------
\\
arXiv:2511.10138
replaced with revised version Fri, 21 Nov 2025 12:09:32 GMT   (973kb)

Title: GPR: Towards a Generative Pre-trained One-Model Paradigm for Large-Scale
 Advertising Recommendation
Authors: Jun Zhang, Yi Li, Yue Liu, Changping Wang, Yuan Wang, Yuling Xiong,
 Xun Liu, Haiyang Wu, Qian Li, Enming Zhang, Jiawei Sun, Xin Xu, Zishuai
 Zhang, Ruoran Liu, Suyuan Huang, Zhaoxin Zhang, Zhengkai Guo, Shuojin Yang,
 Meng-Hao Guo, Huan Yu, Jie Jiang, Shi-Min Hu
Categories: cs.IR
Comments: 12 pages, 5 figures
\\ ( https://arxiv.org/abs/2511.10138 ,  973kb)
------------------------------------------------------------------------------
\\
arXiv:2310.06746
replaced with revised version Fri, 21 Nov 2025 09:30:05 GMT   (3961kb)

Title: A New Causal Rule Learning Approach to Interpretable Estimation of
 Heterogeneous Treatment Effect
Authors: Ying Wu and Hanzhong Liu and Kai Ren and Shujie Ma and Xiangyu Chang
Categories: cs.LG stat.ME stat.ML
\\ ( https://arxiv.org/abs/2310.06746 ,  3961kb)
------------------------------------------------------------------------------
\\
arXiv:2405.17838
replaced with revised version Thu, 20 Nov 2025 18:51:04 GMT   (9301kb)

Title: Posts of Peril: Detecting Information About Hazards in Text
Authors: Keith Burghardt, Daniel M.T. Fessler, Chyna Tang, Anne Pisor, Kristina
 Lerman
Categories: cs.LG cs.AI
Comments: 22 pages, 14 figures. (in press). In: Proceedings of the 20th
 International AAAI Conference on Web and Social Media (ICWSM, 2026)
\\ ( https://arxiv.org/abs/2405.17838 ,  9301kb)
------------------------------------------------------------------------------
\\
arXiv:2406.01183
replaced with revised version Fri, 21 Nov 2025 15:08:01 GMT   (2058kb)

Title: Estimating Global Input Relevance and Enforcing Sparse Representations
 with a Scalable Spectral Neural Network Approach
Authors: Lorenzo Chicchi, Lorenzo Buffoni, Diego Febbe, Lorenzo Giambagli,
 Raffaele Marino and Duccio Fanelli
Categories: cs.LG cond-mat.dis-nn cond-mat.stat-mech cs.AI
\\ ( https://arxiv.org/abs/2406.01183 ,  2058kb)
------------------------------------------------------------------------------
\\
arXiv:2408.07724
replaced with revised version Fri, 21 Nov 2025 14:54:43 GMT   (1069kb)

Title: "Normalized Stress" is Not Normalized: How to Interpret Stress Correctly
Authors: Kiran Smelser, Jacob Miller, Stephen Kobourov
Categories: cs.LG
Comments: Appeared in the BELIV workshop 2024
\\ ( https://arxiv.org/abs/2408.07724 ,  1069kb)
------------------------------------------------------------------------------
\\
arXiv:2409.11078
replaced with revised version Fri, 21 Nov 2025 09:05:05 GMT   (4711kb)

Title: MonoKAN: Certified Monotonic Kolmogorov-Arnold Network
Authors: Alejandro Polo-Molina, David Alfaya, Jose Portela
Categories: cs.LG cs.AI cs.NE
Comments: 18 pages, 8 figures
MSC-class: 68T07, 68T05, 41A15
DOI: 10.1016/j.neunet.2025.108278.
\\ ( https://arxiv.org/abs/2409.11078 ,  4711kb)
------------------------------------------------------------------------------
\\
arXiv:2410.13597
replaced with revised version Fri, 21 Nov 2025 04:30:39 GMT   (805kb)

Title: Text-guided multi-property molecular optimization with a diffusion
 language model
Authors: Yida Xiong, Kun Li, Jiameng Chen, Hongzhi Zhang, Di Lin, Yan Che,
 Wenbin Hu
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2410.13597 ,  805kb)
------------------------------------------------------------------------------
\\
arXiv:2412.12870
replaced with revised version Fri, 21 Nov 2025 18:24:08 GMT   (2473kb)

Title: Physically Interpretable World Models via Weakly Supervised
 Representation Learning
Authors: Zhenjiang Mao, Mrinall Eashaan Umasudhan and Ivan Ruchkin
Categories: cs.LG
\\ ( https://arxiv.org/abs/2412.12870 ,  2473kb)
------------------------------------------------------------------------------
\\
arXiv:2502.01588
replaced with revised version Fri, 21 Nov 2025 11:07:39 GMT   (1075kb)

Title: A Differentiable Alignment Framework for Sequence-to-Sequence Modeling
 via Optimal Transport
Authors: Yacouba Kaloga, Shashi Kumar, Petr Motlicek, Ina Kodrasi
Categories: cs.LG cs.SD eess.AS stat.ML
\\ ( https://arxiv.org/abs/2502.01588 ,  1075kb)
------------------------------------------------------------------------------
\\
arXiv:2503.09114
replaced with revised version Thu, 20 Nov 2025 21:03:47 GMT   (1074kb)

Title: Sometimes Painful but Certainly Promising: Feasibility and Trade-offs of
 Language Model Inference at the Edge
Authors: Maximilian Abstreiter, Sasu Tarkoma, Roberto Morabito
Categories: cs.LG cs.AI cs.DC cs.PF
Comments: Paper currently under review in an ACM journal. This version reflects
 reviewer-driven revisions: calibrated power measurements validated with
 external hardware, updated figures and conclusions, added downstream
 benchmarks (HellaSwag, Winogrande, TruthfulQA, ARC), clarified hardware scope
 and cold-start behavior, corrected Orin GPU Q4_0 results, improved visuals,
 and discussed emerging GenAI NPUs
\\ ( https://arxiv.org/abs/2503.09114 ,  1074kb)
------------------------------------------------------------------------------
\\
arXiv:2503.16991
replaced with revised version Fri, 21 Nov 2025 11:33:42 GMT   (8417kb)

Title: TRACE: Time SeRies PArameter EffiCient FinE-tuning
Authors: Yuze Li and Wei Zhu
Categories: cs.LG
Journal-ref: Neurocomputing, Volume 320, 2025, Article 132098
DOI: 10.1016/j.neucom.2025.132098
\\ ( https://arxiv.org/abs/2503.16991 ,  8417kb)
------------------------------------------------------------------------------
\\
arXiv:2505.01094
replaced with revised version Fri, 21 Nov 2025 08:00:14 GMT   (130kb)

Title: Multi-Objective Reinforcement Learning for Water Management
Authors: Zuzanna Osika, Roxana R\u{a}dulescu, Jazmin Zatarain Salazar, Frans
 Oliehoek, Pradeep K. Murukannaiah
Categories: cs.LG cs.AI
Comments: Accepted to AAMAS 2025
\\ ( https://arxiv.org/abs/2505.01094 ,  130kb)
------------------------------------------------------------------------------
\\
arXiv:2505.01218
replaced with revised version Fri, 21 Nov 2025 07:10:33 GMT   (3066kb)

Title: Quantitative Attractor Analysis of High-Capacity Kernel Logistic
 Regression Hopfield Networks
Authors: Akira Tamamori
Categories: cs.LG cs.NE
Comments: 16 pages, 7 figures
\\ ( https://arxiv.org/abs/2505.01218 ,  3066kb)
------------------------------------------------------------------------------
\\
arXiv:2505.10297
replaced with revised version Fri, 21 Nov 2025 14:13:48 GMT   (3386kb)

Title: Defending the Edge: Representative-Attention Defense against Backdoor
 Attacks in Federated Learning
Authors: Chibueze Peace Obioma, Youcheng Sun, and Mustafa A. Mustafa
Categories: cs.LG cs.AI cs.CR
Comments: Submitted to IEEE EURO S&P 2026
\\ ( https://arxiv.org/abs/2505.10297 ,  3386kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13614
replaced with revised version Fri, 21 Nov 2025 01:42:26 GMT   (221kb)

Title: Deterministic Bounds and Random Estimates of Metric Tensors on
 Neuromanifolds
Authors: Ke Sun
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/2505.13614 ,  221kb)
------------------------------------------------------------------------------
\\
arXiv:2506.02392
replaced with revised version Fri, 21 Nov 2025 12:16:15 GMT   (2365kb)

Title: Improving Generalization of Neural Combinatorial Optimization for
 Vehicle Routing Problems via Test-Time Projection Learning
Authors: Yuanyao Chen, Rongsheng Chen, Fu Luo, Zhenkun Wang
Categories: cs.LG
Comments: arXiv admin note: text overlap with arXiv:2505.24627
\\ ( https://arxiv.org/abs/2506.02392 ,  2365kb)
------------------------------------------------------------------------------
\\
arXiv:2506.08255
replaced with revised version Fri, 21 Nov 2025 16:58:45 GMT   (13196kb)

Title: SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense
Authors: Patryk Krukowski,{\L}ukasz Gorczyca, Piotr Helm, Kamil Ksi\k{a}\.zek,
 Przemys{\l}aw Spurek
Categories: cs.LG cs.AI cs.CR
\\ ( https://arxiv.org/abs/2506.08255 ,  13196kb)
------------------------------------------------------------------------------
\\
arXiv:2506.08274
replaced with revised version Fri, 21 Nov 2025 11:10:04 GMT   (11982kb)

Title: The Impact of Feature Scaling In Machine Learning: Effects on Regression
 and Classification Tasks
Authors: Jo\~ao Manoel Herrera Pinheiro, Suzana Vilas Boas de Oliveira, Thiago
 Henrique Segreto Silva, Pedro Antonio Rabelo Saraiva, Enzo Ferreira de Souza,
 Ricardo V. Godoy, Leonardo Andr\'e Ambrosio and Marcelo Becker
Categories: cs.LG stat.ML
Comments: 36 pages
Journal-ref: IEEE Access(2025)
DOI: 10.1109/ACCESS.2025.3635541
\\ ( https://arxiv.org/abs/2506.08274 ,  11982kb)
------------------------------------------------------------------------------
\\
arXiv:2506.16846
replaced with revised version Fri, 21 Nov 2025 09:37:07 GMT   (24733kb)

Title: Soft decision trees for survival analysis
Authors: Antonio Consolo, Edoardo Amaldi, Emilio Carrizosa
Categories: cs.LG math.OC
\\ ( https://arxiv.org/abs/2506.16846 ,  24733kb)
------------------------------------------------------------------------------
\\
arXiv:2507.01598
replaced with revised version Fri, 21 Nov 2025 00:56:01 GMT   (3404kb)

Title: Convergence Bound and Critical Batch Size of Muon Optimizer
Authors: Naoki Sato, Hiroki Naganuma, and Hideaki Iiduka
Categories: cs.LG
\\ ( https://arxiv.org/abs/2507.01598 ,  3404kb)
------------------------------------------------------------------------------
\\
arXiv:2507.06819
replaced with revised version Fri, 21 Nov 2025 12:33:38 GMT   (12471kb)

Title: Comprehensive Evaluation of Prototype Neural Networks
Authors: Philipp Schlinge, Steffen Meinert, Martin Atzmueller
Categories: cs.LG cs.AI
DOI: 10.1007/s13218-025-00900-0
\\ ( https://arxiv.org/abs/2507.06819 ,  12471kb)
------------------------------------------------------------------------------
\\
arXiv:2507.10998
replaced with revised version Fri, 21 Nov 2025 16:31:02 GMT   (5882kb)

Title: Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data
Authors: Zhipeng He, Alexander Stevens, Chun Ouyang, Johannes De Smedt,
 Alistair Barros, Catarina Moreira
Categories: cs.LG cs.AI
Comments: Final Version
Journal-ref: Applied Soft Computing 186, Part D (2026) 114286
DOI: 10.1016/j.asoc.2025.114286
\\ ( https://arxiv.org/abs/2507.10998 ,  5882kb)
------------------------------------------------------------------------------
\\
arXiv:2507.20973
replaced with revised version Fri, 21 Nov 2025 09:12:45 GMT   (1076kb)

Title: Model-Agnostic Gender Bias Control for Text-to-Image Generation via
 Sparse Autoencoder
Authors: Chao Wu, Zhenyi Wang, Kangxian Xie, Naresh Kumar Devulapally, Vishnu
 Suresh Lokhande, Mingchen Gao
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2507.20973 ,  1076kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16651
replaced with revised version Thu, 20 Nov 2025 19:20:12 GMT   (2004kb)

Title: HiCL: Hippocampal-Inspired Continual Learning
Authors: Kushal Kapoor, Wyatt Mackey, Yiannis Aloimonos, Xiaomin Lin
Categories: cs.LG cs.AI
Comments: In proceeding of AAAI
\\ ( https://arxiv.org/abs/2508.16651 ,  2004kb)
------------------------------------------------------------------------------
\\
arXiv:2508.17995
replaced with revised version Fri, 21 Nov 2025 18:16:26 GMT   (8289kb)

Title: Topology Aware Neural Interpolation of Scalar Fields
Authors: Mohamed Kissi, Keanu Sisouk, Joshua A. Levine, and Julien Tierny
Categories: cs.LG cs.CV cs.GR
\\ ( https://arxiv.org/abs/2508.17995 ,  8289kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05826
replaced with revised version Fri, 21 Nov 2025 09:36:19 GMT   (1263kb)

Title: Performance of Conformal Prediction in Capturing Aleatoric Uncertainty
Authors: Misgina Tsighe Hagos, Claes Lundstr\"om
Categories: cs.LG cs.CV
Comments: Accepted at the IEEE/CVF Winter Conference on Applications of
 Computer Vision, WACV 2026
\\ ( https://arxiv.org/abs/2509.05826 ,  1263kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06938
replaced with revised version Thu, 20 Nov 2025 21:59:31 GMT   (32458kb)

Title: From Noise to Narrative: Tracing the Origins of Hallucinations in
 Transformers
Authors: Praneet Suresh, Jack Stanley, Sonia Joseph, Luca Scimeca, Danilo Bzdok
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2509.06938 ,  32458kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10273
replaced with revised version Fri, 21 Nov 2025 13:26:59 GMT   (9077kb)

Title: A neural recommender system leveraging transfer learning for property
 prediction of ionic liquids
Authors: Sahil Sethi, Kai Sundmacher and Caroline Ganzer
Categories: cs.LG
\\ ( https://arxiv.org/abs/2509.10273 ,  9077kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10518
replaced with revised version Fri, 21 Nov 2025 00:59:21 GMT   (0kb,I)

Title: Holographic Knowledge Manifolds: A Novel Pipeline for Continual Learning
 Without Catastrophic Forgetting in Large Language Models
Authors: Justin Arndt
Categories: cs.LG
Comments: This paper includes significant errors discovered post publication by
 the author
\\ ( https://arxiv.org/abs/2509.10518 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18057
replaced with revised version Thu, 20 Nov 2025 23:53:58 GMT   (8915kb)

Title: Reinforced Generation of Combinatorial Structures: Applications to
 Complexity Theory
Authors: Ansh Nagda, Prabhakar Raghavan, Abhradeep Thakurta
Categories: cs.LG cs.AI cs.CC math.CO
\\ ( https://arxiv.org/abs/2509.18057 ,  8915kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23366
replaced with revised version Fri, 21 Nov 2025 12:53:21 GMT   (4047kb)

Title: Splines-Based Feature Importance in Kolmogorov-Arnold Networks: A
 Framework for Supervised Tabular Data Dimensionality Reduction
Authors: Ange-Cl\'ement Akazan and Verlon Roel Mbingui
Categories: cs.LG
\\ ( https://arxiv.org/abs/2509.23366 ,  4047kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24068
replaced with revised version Thu, 20 Nov 2025 21:10:49 GMT   (691kb)

Title: A Small Math Model: Recasting Strategy Choice Theory in an LLM-Inspired
 Architecture
Authors: Roussel Rahman and Jeff Shrager
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2509.24068 ,  691kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05060
replaced with revised version Thu, 20 Nov 2025 19:58:24 GMT   (1240kb)

Title: ResCP: Reservoir Conformal Prediction for Time Series Forecasting
Authors: Roberto Neglia, Andrea Cini, Michael M. Bronstein, Filippo Maria
 Bianchi
Categories: cs.LG math.ST stat.ML stat.TH
\\ ( https://arxiv.org/abs/2510.05060 ,  1240kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00423
replaced with revised version Fri, 21 Nov 2025 12:39:02 GMT   (3539kb)

Title: Bootstrap Off-policy with World Model
Authors: Guojian Zhan, Likun Wang, Xiangteng Zhang, Jiaxin Gao, Masayoshi
 Tomizuka, Shengbo Eben Li
Categories: cs.LG cs.AI cs.RO
Comments: NeurIPS 2025
\\ ( https://arxiv.org/abs/2511.00423 ,  3539kb)
------------------------------------------------------------------------------
\\
arXiv:2511.00794
replaced with revised version Fri, 21 Nov 2025 07:44:25 GMT   (36832kb)

Title: Efficient Reinforcement Learning for Large Language Models with
 Intrinsic Exploration
Authors: Yan Sun, Jia Guo, Stanley Kok, Zihao Wang, Zujie Wen, Zhiqiang Zhang
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2511.00794 ,  36832kb)
------------------------------------------------------------------------------
\\
arXiv:2511.01588
replaced with revised version Fri, 21 Nov 2025 11:16:04 GMT   (2552kb)

Title: Explore More, Learn Better: Parallel MLLM Embeddings under Mutual
 Information Minimization
Authors: Zhicheng Wang, Chen Ju, Xu Chen, Shuai Xiao, Jinsong Lan, Xiaoyong
 Zhu, Ying Chen, Zhiguo Cao
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2511.01588 ,  2552kb)
------------------------------------------------------------------------------
\\
arXiv:2511.02894
replaced with revised version Fri, 21 Nov 2025 15:30:31 GMT   (11551kb)

Title: Adaptive and Robust Data Poisoning Detection and Sanitization in
 Wearable IoT Systems using Large Language Models
Authors: W.K.M Mithsara, Ning Yang, Ahmed Imteaj, Hussein Zangoti, Abdur R.
 Shahid
Categories: cs.LG cs.CR
\\ ( https://arxiv.org/abs/2511.02894 ,  11551kb)
------------------------------------------------------------------------------
\\
arXiv:2511.02969
replaced with revised version Fri, 21 Nov 2025 16:56:52 GMT   (1269kb)

Title: Value of Information-Enhanced Exploration in Bootstrapped DQN
Authors: Stergios Plataniotis, Charilaos Akasiadis and Georgios Chalkiadakis
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2511.02969 ,  1269kb)
------------------------------------------------------------------------------
\\
arXiv:2511.06609
replaced with revised version Fri, 21 Nov 2025 01:36:16 GMT   (6148kb)

Title: A Weak Penalty Neural ODE for Learning Chaotic Dynamics from Noisy Time
 Series
Authors: Xuyang Li, John Harlim, Dibyajyoti Chakraborty, Romit Maulik
Categories: cs.LG math.DS
\\ ( https://arxiv.org/abs/2511.06609 ,  6148kb)
------------------------------------------------------------------------------
\\
arXiv:2511.12797
replaced with revised version Fri, 21 Nov 2025 02:11:05 GMT   (3099kb)

Title: Genomic Next-Token Predictors are In-Context Learners
Authors: Nathan Breslow, Aayush Mishra, Mahler Revsine, Michael C. Schatz, Anqi
 Liu, Daniel Khashabi
Categories: cs.LG cs.AI q-bio.GN
\\ ( https://arxiv.org/abs/2511.12797 ,  3099kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13049
replaced with revised version Fri, 21 Nov 2025 12:07:39 GMT   (103kb)

Title: Generalization Bounds for Semi-supervised Matrix Completion with
 Distributional Side Information
Authors: Antoine Ledent, Mun Chong Soo, Nong Minh Hieu
Categories: cs.LG stat.ML
Comments: Accepted at AAAI 2026
\\ ( https://arxiv.org/abs/2511.13049 ,  103kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13750
replaced with revised version Thu, 20 Nov 2025 19:31:02 GMT   (29323kb)

Title: SCALEX: Scalable Concept and Latent Exploration for Diffusion Models
Authors: E. Zhixuan Zeng, Yuhao Chen, Alexander Wong
Categories: cs.LG cs.AI
Comments: Accepted to WACV2025
\\ ( https://arxiv.org/abs/2511.13750 ,  29323kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15738
replaced with revised version Fri, 21 Nov 2025 15:10:10 GMT   (3967kb)

Title: Extending Test-Time Scaling: A 3D Perspective with Context, Batch, and
 Turn
Authors: Chao Yu, Qixin Tan, Jiaxuan Gao, Shi Yu, Hong Lu, Xinting Yang, Zelai
 Xu, Yu Wang, Yi Wu, Eugene Vinitsky
Categories: cs.LG cs.AI
Comments: 44 pages, 12 figures
\\ ( https://arxiv.org/abs/2511.15738 ,  3967kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15856
replaced with revised version Fri, 21 Nov 2025 14:26:08 GMT   (17743kb)

Title: GLOBE: Accurate and Generalizable PDE Surrogates using Domain-Inspired
 Architectures and Equivariances
Authors: Peter Sharpe
Categories: cs.LG physics.flu-dyn
\\ ( https://arxiv.org/abs/2511.15856 ,  17743kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16258
replaced with revised version Fri, 21 Nov 2025 11:03:29 GMT   (3522kb)

Title: GeoPTH: A Lightweight Approach to Category-Based Trajectory Retrieval
 via Geometric Prototype Trajectory Hashing
Authors: Yang Xu, Zuliang Yang, Kai Ming Ting
Categories: cs.LG
\\ ( https://arxiv.org/abs/2511.16258 ,  3522kb)
------------------------------------------------------------------------------
\\
arXiv:2207.07250 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 14:16:08 GMT   (51kb)

Title: Toward Super-polynomial Quantum Speedup of Equivariant Quantum
 Algorithms with SU($d$) Symmetry
Authors: Han Zheng, Zimu Li, Sergii Strelchuk, Risi Kondor, Junyu Liu
Categories: quant-ph cs.AI cs.LG math-ph math.MP stat.ML
Comments: Presented in TQC 2022
Journal-ref: Phys. Rev. A 112, 052435 (2025)
DOI: 10.1103/pt27-v2nj
\\ ( https://arxiv.org/abs/2207.07250 ,  51kb)
------------------------------------------------------------------------------
\\
arXiv:2406.02966
replaced with revised version Thu, 20 Nov 2025 20:40:21 GMT   (1168kb)

Title: Generative AI and Power Imbalances in Global Education: Frameworks for
 Bias Mitigation
Authors: Matthew Nyaaba, Alyson Wright, and Gyu Lim Choi
Categories: cs.CY cs.AI
\\ ( https://arxiv.org/abs/2406.02966 ,  1168kb)
------------------------------------------------------------------------------
\\
arXiv:2406.03283
replaced with revised version Fri, 21 Nov 2025 17:41:45 GMT   (1158kb)

Title: CATCODER: Repository-Level Code Generation with Relevant Code and Type
 Context
Authors: Zhiyuan Pan, Xing Hu, Xin Xia, Xiaohu Yang
Categories: cs.SE cs.AI
Comments: Revised and extended version; To be published in ACM Transactions on
 Software Engineering and Methodology
\\ ( https://arxiv.org/abs/2406.03283 ,  1158kb)
------------------------------------------------------------------------------
\\
arXiv:2408.15511
replaced with revised version Thu, 20 Nov 2025 15:34:13 GMT   (52090kb)

Title: AeroVerse: UAV-Agent Benchmark Suite for Simulating, Pre-training,
 Finetuning, and Evaluating Aerospace Embodied World Models
Authors: Fanglong Yao, Yuanchang Yue, Youzhi Liu, Xian Sun, Kun Fu
Categories: cs.RO cs.AI
\\ ( https://arxiv.org/abs/2408.15511 ,  52090kb)
------------------------------------------------------------------------------
\\
arXiv:2409.11393
replaced with revised version Fri, 21 Nov 2025 13:25:25 GMT   (1596kb)

Title: LLM-Agent-UMF: LLM-based Agent Unified Modeling Framework for Seamless
 Design of Multi Active/Passive Core-Agent Architectures
Authors: Amine Ben Hassouna, Hana Chaari, Ines Belhaj
Categories: cs.SE cs.AI cs.CR cs.MA
Comments: 39 pages, 19 figures, 3 tables. Published in Information Fusion,
 Volume 127, March 2026, 103865. Part of the special issue "Data Fusion
 Approaches in Data-Centric AI for Developing Trustworthy AI Systems"
Journal-ref: Information Fusion 127 (2026) 103865
DOI: 10.1016/j.inffus.2025.103865
\\ ( https://arxiv.org/abs/2409.11393 ,  1596kb)
------------------------------------------------------------------------------
\\
arXiv:2503.17987
replaced with revised version Fri, 21 Nov 2025 04:55:46 GMT   (2546kb)

Title: Reason2Attack: Jailbreaking Text-to-Image Models via LLM Reasoning
Authors: Chenyu Zhang, Lanjun Wang, Yiwen Ma, Wenhui Li, and An-An Liu
Categories: cs.CR cs.AI cs.CV
Comments: Noted that This paper includes model-generated content that may
 contain offensive or distressing material
\\ ( https://arxiv.org/abs/2503.17987 ,  2546kb)
------------------------------------------------------------------------------
\\
arXiv:2504.08016 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 09:07:03 GMT   (3220kb)

Title: Emergence of psychopathological computations in large language models
Authors: Soo Yong Lee, Hyunjin Hwang, Taekwan Kim, Yuyeong Kim, Kyuri Park,
 Jaemin Yoo, Denny Borsboom, Kijung Shin
Categories: q-bio.NC cs.AI cs.CL
Comments: pre-print
\\ ( https://arxiv.org/abs/2504.08016 ,  3220kb)
------------------------------------------------------------------------------
\\
arXiv:2504.21719
replaced with revised version Fri, 21 Nov 2025 11:04:47 GMT   (7984kb)

Title: Sionna RT: Technical Report
Authors: Fay\c{c}al A\"it Aoudia, Jakob Hoydis, Merlin Nimier-David, Baptiste
 Nicolet, Sebastian Cammerer, Alexander Keller
Categories: cs.IT cs.AI eess.SP math.IT
\\ ( https://arxiv.org/abs/2504.21719 ,  7984kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12188
replaced with revised version Fri, 21 Nov 2025 00:44:24 GMT   (1185kb)

Title: LLM-DSE: Searching Accelerator Parameters with LLM Agents
Authors: Hanyu Wang, Xinrui Wu, Zijian Ding, Su Zheng, Chengyue Wang, Neha
 Prakriya, Tony Nowatzki, Yizhou Sun, Jason Cong
Categories: cs.AR cs.AI
\\ ( https://arxiv.org/abs/2505.12188 ,  1185kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20714
replaced with revised version Fri, 21 Nov 2025 13:07:32 GMT   (22118kb)

Title: Wideband RF Radiance Field Modeling Using Frequency-embedded 3D Gaussian
 Splatting
Authors: Zechen Li, Lanqing Yang, Yiheng Bian, Hao Pan, Yongjian Fu, Yezhou
 Wang, Zhuxi Chen, Yi-Chao Chen, Guangtao Xue
Categories: cs.NI cs.AI cs.LG
\\ ( https://arxiv.org/abs/2505.20714 ,  22118kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00133
replaced with revised version Fri, 21 Nov 2025 09:32:43 GMT   (1220kb)

Title: A Reinforcement Learning-Based Telematic Routing Protocol for the
 Internet of Underwater Things
Authors: Mohammadhossein Homaei, Mehran Tarif, Agustin Di Bartolo, Victor
 Gonzalez Morales, Mar Avila Vegas
Categories: cs.NI cs.AI cs.LG
Comments: 8 Pages, 10 Figures, 2 Tables
\\ ( https://arxiv.org/abs/2506.00133 ,  1220kb)
------------------------------------------------------------------------------
\\
arXiv:2506.08708
replaced with revised version Fri, 21 Nov 2025 12:13:42 GMT   (40382kb)

Title: PhyBlock: A Progressive Benchmark for Physical Understanding and
 Planning via 3D Block Assembly
Authors: Liang Ma, Jiajun Wen, Min Lin, Rongtao Xu, Xiwen Liang, Bingqian Lin,
 Jun Ma, Yongxin Wang, Ziming Wei, Haokun Lin, Mingfei Han, Meng Cao, Bokui
 Chen, Ivan Laptev, Xiaodan Liang
Categories: cs.RO cs.AI cs.CV
\\ ( https://arxiv.org/abs/2506.08708 ,  40382kb)
------------------------------------------------------------------------------
\\
arXiv:2506.22397 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 15:31:44 GMT   (33926kb)

Title: HazeMatching: Dehazing Light Microscopy Images with Guided Conditional
 Flow Matching
Authors: Anirban Ray, Ashesh, Florian Jug
Categories: eess.IV cs.AI cs.CV
Comments: 4 figures, 8 pages + refs, 45 pages total (including supplement), 28
 supplementary figures
\\ ( https://arxiv.org/abs/2506.22397 ,  33926kb)
------------------------------------------------------------------------------
\\
arXiv:2507.13290
replaced with revised version Thu, 20 Nov 2025 21:09:31 GMT   (98kb)

Title: Towards Formal Verification of LLM-Generated Code from Natural Language
 Prompts
Authors: Aaron Councilman, David Jiahao Fu, Aryan Gupta, Chengxiao Wang, David
 Grove, Yu-Xiong Wang, Vikram Adve
Categories: cs.PL cs.AI
Comments: 28 pages, 10 figures
\\ ( https://arxiv.org/abs/2507.13290 ,  98kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18694
replaced with revised version Fri, 21 Nov 2025 04:30:13 GMT   (25061kb)

Title: AgriChrono: A Multi-modal Dataset Capturing Crop Growth and Lighting
 Variability with a Field Robot
Authors: Jaehwan Jeong, Tuan-Anh Vu, Mohammad Jony, Shahab Ahmad, Md. Mukhlesur
 Rahman, Sangpil Kim, M. Khalid Jawed
Categories: cs.RO cs.AI cs.SY eess.SY
\\ ( https://arxiv.org/abs/2508.18694 ,  25061kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10577
replaced with revised version Fri, 21 Nov 2025 18:14:10 GMT   (15902kb)

Title: The Coding Limits of Robust Watermarking for Generative Models
Authors: Danilo Francati, Yevin Nikhel Goonatilake, Shubham Pawar, Daniele
 Venturi, Giuseppe Ateniese
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2509.10577 ,  15902kb)
------------------------------------------------------------------------------
\\
arXiv:2510.20333
replaced with revised version Fri, 21 Nov 2025 07:38:12 GMT   (1482kb)

Title: GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in
 Dynamic On-Device Environments?
Authors: Chiyu Chen, Xinhao Song, Yunkai Chai, Yang Yao, Haodong Zhao, Lijun
 Li, Jie Li, Yan Teng, Gongshen Liu, and Yingchun Wang
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2510.20333 ,  1482kb)
------------------------------------------------------------------------------
\\
arXiv:2510.22300
replaced with revised version Fri, 21 Nov 2025 05:17:51 GMT   (1492kb)

Title: T2I-RiskyPrompt: A Benchmark for Safety Evaluation, Attack, and Defense
 on Text-to-Image Model
Authors: Chenyu Zhang, Tairen Zhang, Lanjun Wang, Ruidong Chen, Wenhui Li, Anan
 Liu
Categories: cs.CR cs.AI cs.CV
Comments: AAAI 2026
\\ ( https://arxiv.org/abs/2510.22300 ,  1492kb)
------------------------------------------------------------------------------
\\
arXiv:2510.27629
replaced with revised version Thu, 20 Nov 2025 18:33:49 GMT   (948kb)

Title: Best Practices for Biorisk Evaluations on Open-Weight Bio-Foundation
 Models
Authors: Boyi Wei, Zora Che, Nathaniel Li, Udari Madhushani Sehwag, Jasper
 G\"otting, Samira Nedungadi, Julian Michael, Summer Yue, Dan Hendrycks, Peter
 Henderson, Zifan Wang, Seth Donoughe, Mantas Mazeika
Categories: cs.CR cs.AI
Comments: 17 Pages, 5 figures
\\ ( https://arxiv.org/abs/2510.27629 ,  948kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07441
replaced with revised version Thu, 20 Nov 2025 21:03:58 GMT   (1480kb)

Title: AudAgent: Automated Auditing of Privacy Policy Compliance in AI Agents
Authors: Ye Zheng, Yidan Hu
Categories: cs.CR cs.AI
MSC-class: 68P27
\\ ( https://arxiv.org/abs/2511.07441 ,  1480kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07772
replaced with revised version Fri, 21 Nov 2025 04:57:07 GMT   (379kb)

Title: SALT: Steering Activations towards Leakage-free Thinking in Chain of
 Thought
Authors: Shourya Batra, Pierce Tillman, Samarth Gaggar, Shashank Kesineni,
 Kevin Zhu, Sunishchal Dev, Ashwinee Panda, Vasu Sharma, Maheep Chaudhary
Categories: cs.CR cs.AI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2511.07772 ,  379kb)
------------------------------------------------------------------------------
\\
arXiv:2511.13646
replaced with revised version Fri, 21 Nov 2025 17:22:32 GMT   (804kb)

Title: Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?
Authors: Chunqiu Steven Xia, Zhe Wang, Yan Yang, Yuxiang Wei, Lingming Zhang
Categories: cs.SE cs.AI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2511.13646 ,  804kb)
------------------------------------------------------------------------------
\\
arXiv:2511.14567
replaced with revised version Fri, 21 Nov 2025 14:31:55 GMT   (2214kb)

Title: SweeperBot: Making 3D Browsing Accessible through View Analysis and
 Visual Question Answering
Authors: Chen Chen and Cuong Nguyen and Alexa Siu and Dingzeyu Li and Nadir
 Weibel
Categories: cs.HC cs.AI
Comments: 28 pages, 16 figures, this is an original manuscript of an article
 published by Taylor & Francis in the International Journal of Human-Computer
 Interaction (IJHCI), available online:
 https://doi.org/10.1080/10447318.2025.2594750
ACM-class: J.4; I.2; I.7; H.5
DOI: 10.1080/10447318.2025.2594750
\\ ( https://arxiv.org/abs/2511.14567 ,  2214kb)
------------------------------------------------------------------------------
\\
arXiv:2511.15846
replaced with revised version Fri, 21 Nov 2025 18:53:03 GMT   (1477kb)

Title: The Loss of Control Playbook: Degrees, Dynamics, and Preparedness
Authors: Charlotte Stix, Annika Hallensleben, Alejandro Ortega, Matteo Pistillo
Categories: cs.CY cs.AI
\\ ( https://arxiv.org/abs/2511.15846 ,  1477kb)
------------------------------------------------------------------------------
\\
arXiv:2511.16193
replaced with revised version Fri, 21 Nov 2025 07:34:03 GMT   (2465kb)

Title: Fast LLM Post-training via Decoupled and Best-of-N Speculation
Authors: Rongxin Cheng, Kai Zhou, Xingda Wei, Siyuan Liu, Mingcong Han,
 Mingjing Ai, Yeju Zhou, Baoquan Zhong, Wencong Xiao, Rong Chen, Haibo Chen
Categories: cs.DC cs.AI
\\ ( https://arxiv.org/abs/2511.16193 ,  2465kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24975
replaced with revised version Fri, 21 Nov 2025 10:57:25 GMT   (2352kb)

Title: DiffTester: Accelerating Unit Test Generation for Diffusion LLMs via
 Repetitive Pattern
Authors: Lekang Yang, Yuetong Liu, Yitong Zhang, Jia Li
Categories: cs.SE cs.CL
Comments: Update reference
\\ ( https://arxiv.org/abs/2509.24975 ,  2352kb)
------------------------------------------------------------------------------
\\
arXiv:2502.09779 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 06:28:16 GMT   (19813kb)

Title: Automated Muscle and Fat Segmentation in Computed Tomography for
 Comprehensive Body Composition Analysis
Authors: Yaqian Chen, Hanxue Gu, Yuwen Chen, Jichen Yang, Haoyu Dong, Joseph Y.
 Cao, Adrian Camarena, Christopher Mantyh, Roy Colglazier, Maciej A.
 Mazurowski
Categories: eess.IV cs.CV
Comments: Accepted for publication at the Journal of Machine Learning for
 Biomedical Imaging (MELBA) https://melba-journal.org/2025:026
Journal-ref: Machine.Learning.for.Biomedical.Imaging. 3 (2025)
DOI: 10.59275/j.melba.2025-ag5g
\\ ( https://arxiv.org/abs/2502.09779 ,  19813kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12114
replaced with revised version Thu, 20 Nov 2025 23:28:29 GMT   (2823kb)

Title: Behind the Screens: Uncovering Bias in AI-Driven Video Interview
 Assessments Using Counterfactuals
Authors: Dena F. Mujtaba and Nihar R. Mahapatra
Categories: cs.HC cs.CV eess.IV
\\ ( https://arxiv.org/abs/2505.12114 ,  2823kb)
------------------------------------------------------------------------------
\\
arXiv:2508.04270
replaced with revised version Fri, 21 Nov 2025 12:07:29 GMT   (23593kb)

Title: TDSNNs: Competitive Topographic Deep Spiking Neural Networks for Visual
 Cortex Modeling
Authors: Deming Zhou, Yuetong Fang, Zhaorui Wang, Renjing Xu
Categories: cs.NE cs.CV
Comments: AAAI 2026 (Oral)
\\ ( https://arxiv.org/abs/2508.04270 ,  23593kb)
------------------------------------------------------------------------------
\\
arXiv:2511.07827 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 00:19:43 GMT   (4416kb)

Title: Deep Learning Analysis of Prenatal Ultrasound for Identification of
 Ventriculomegaly
Authors: Youssef Megahed, Inok Lee, Robin Ducharme, Aylin Erman, Olivier X.
 Miguel, Kevin Dick, Adrian D. C. Chan, Steven Hawken, Mark Walker, Felipe
 Moretti
Categories: eess.IV cs.CV
Comments: 13 pages, 7 figures, 3 tables
\\ ( https://arxiv.org/abs/2511.07827 ,  4416kb)
------------------------------------------------------------------------------
\\
arXiv:2307.12417
replaced with revised version Thu, 20 Nov 2025 19:21:23 GMT   (17108kb)

Title: UplinkNet: Practical Commercial 5G Standalone (SA) Uplink Throughput
 Prediction
Authors: Kasidis Arunruangsirilert, Jiro Katto
Categories: cs.NI cs.LG eess.SP
Comments: 2024 IEEE International Conference on Visual Communications and Image
 Processing (VCIP 2024), 8-11 December 2024, Tokyo, Japan
DOI: 10.1109/VCIP63160.2024.10849914
\\ ( https://arxiv.org/abs/2307.12417 ,  17108kb)
------------------------------------------------------------------------------
\\
arXiv:2308.01853 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 17:03:29 GMT   (396kb)

Title: Minimax Statistical Estimation under Wasserstein Contamination
Authors: Patrick Chao, Edgar Dobriban
Categories: stat.ML cs.LG math.ST stat.TH
Comments: A revision, including a changed title. This version extends the
 results to more general perturbations and loss functions, while also
 obtaining a new optimal rate for density estimation. Some of the techniques
 described in the original submission (ambiguity set minimax lower bounds,
 Bayes lower bounds) are not required anymore and have thus been removed
\\ ( https://arxiv.org/abs/2308.01853 ,  396kb)
------------------------------------------------------------------------------
\\
arXiv:2406.05694
replaced with revised version Thu, 20 Nov 2025 20:51:55 GMT   (4265kb)

Title: A Low Rank Neural Representation of Entropy Solutions
Authors: Donsub Rim, Gerrit Welper
Categories: math.NA cs.LG cs.NA
Comments: 47 pages, 10 figures
MSC-class: 68T07, 41A46, 41A25, 65N15, 35L65
\\ ( https://arxiv.org/abs/2406.05694 ,  4265kb)
------------------------------------------------------------------------------
\\
arXiv:2409.14980 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 12:57:11 GMT   (784kb)

Title: (De)-regularized Maximum Mean Discrepancy Gradient Flow
Authors: Zonghao Chen, Aratrika Mustafi, Pierre Glaser, Anna Korba, Arthur
 Gretton, Bharath K. Sriperumbudur
Categories: stat.ML cs.LG
Journal-ref: Journal of Machine Learning Research 2025
\\ ( https://arxiv.org/abs/2409.14980 ,  784kb)
------------------------------------------------------------------------------
\\
arXiv:2502.05708
replaced with revised version Fri, 21 Nov 2025 18:40:21 GMT   (3035kb)

Title: Generalizable Radio-Frequency Radiance Fields for Spatial Spectrum
 Synthesis
Authors: Kang Yang, Yuning Chen, Wan Du
Categories: cs.NI cs.LG
\\ ( https://arxiv.org/abs/2502.05708 ,  3035kb)
------------------------------------------------------------------------------
\\
arXiv:2502.15769
replaced with revised version Fri, 21 Nov 2025 14:01:48 GMT   (485kb)

Title: Asymptotic evaluation of the information processing capacity in
 reservoir computing
Authors: Yohei Saito
Categories: cs.IT cs.LG eess.SP math.IT
\\ ( https://arxiv.org/abs/2502.15769 ,  485kb)
------------------------------------------------------------------------------
\\
arXiv:2503.01361 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 14:07:21 GMT   (347kb,A)

Title: Statistical physics analysis of graph neural networks: Approaching
 optimality in the contextual stochastic block model
Authors: O. Duranthon, L. Zdeborov\'a
Categories: cond-mat.dis-nn cs.LG
Journal-ref: Physical Review X, 2025
DOI: 10.1103/lfxj-hbsk
\\ ( https://arxiv.org/abs/2503.01361 ,  347kb)
------------------------------------------------------------------------------
\\
arXiv:2503.15013 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 05:50:11 GMT   (23872kb)

Title: Ambient Noise Full Waveform Inversion with Neural Operators
Authors: Caifeng Zou, Zachary E. Ross, Robert W. Clayton, Fan-Chi Lin, and
 Kamyar Azizzadenesheli
Categories: physics.geo-ph cs.LG
Comments: Align with the published version
DOI: 10.1029/2025JB031624
\\ ( https://arxiv.org/abs/2503.15013 ,  23872kb)
------------------------------------------------------------------------------
\\
arXiv:2506.14899 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 10:45:21 GMT   (67kb)

Title: Optimal Convergence Rates of Deep Neural Network Classifiers
Authors: Zihan Zhang, Lei Shi, Ding-Xuan Zhou
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/2506.14899 ,  67kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19588 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 13:43:43 GMT   (318kb)

Title: Discovery of Sustainable Refrigerants through Physics-Informed RL
 Fine-Tuning of Sequence Models
Authors: Adrien Goldszal and Diego Calanzone and Vincent Taboga and Pierre-Luc
 Bacon
Categories: physics.chem-ph cs.LG
Comments: Accepted to 1st SIMBIOCHEM Workshop at EurIPS 2025
\\ ( https://arxiv.org/abs/2509.19588 ,  318kb)
------------------------------------------------------------------------------
\\
arXiv:2511.05050 (*cross-listing*)
replaced with revised version Fri, 21 Nov 2025 10:33:32 GMT   (156kb)

Title: Estimating Bidirectional Causal Effects with Large Scale Online Kernel
 Learning
Authors: Masahiro Tanaka
Categories: stat.ML cs.LG stat.ME
Comments: Accepted for publication in Proceedings of the 2025 International
 Conference on Data Science and Intelligent Systems (DSIS 2025)
\\ ( https://arxiv.org/abs/2511.05050 ,  156kb)
------------------------------------------------------------------------------
\\
arXiv:2511.11381
replaced with revised version Fri, 21 Nov 2025 18:34:04 GMT   (4371kb)

Title: SoK: Security Evaluation of Wi-Fi CSI Biometrics: Attacks, Metrics, and
 Open Challenges
Authors: Gioliano de Oliveira Braga, Pedro Henrique dos Santos Rocha, Rafael
 Pimenta de Mattos Paix\~ao, Giovani Hoff da Costa, Gustavo Cavalcanti Morais,
 Louren\c{c}o Alves Pereira J\'unior
Categories: cs.CR cs.LG cs.NI
Comments: This work was submitted to the 11th IEEE European Symposium on
 Security and Privacy (IEEE S&P 2026)
ACM-class: K.6.5; C.2.1; I.5.4
\\ ( https://arxiv.org/abs/2511.11381 ,  4371kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---

%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
